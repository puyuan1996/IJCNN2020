---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.00067216775
Z variance train             0.69231623
KL Divergence                0.15007588
KL Loss                      0.015007588
QF Loss                      72.00627
VF Loss                      4.348541
Policy Loss                  -2.0539703
Q Predictions Mean           0.0046742754
Q Predictions Std            0.00078647234
Q Predictions Max            0.0068198126
Q Predictions Min            0.0025699805
V Predictions Mean           0.00083554036
V Predictions Std            0.0008371301
V Predictions Max            0.0042383783
V Predictions Min            -0.0017800751
Log Pis Mean                 -2.0363827
Log Pis Std                  0.3649491
Log Pis Max                  -0.8460885
Log Pis Min                  -3.0406342
Policy mu Mean               0.0006062304
Policy mu Std                0.00081670156
Policy mu Max                0.002711602
Policy mu Min                -0.0007597279
Policy log std Mean          -0.00023992085
Policy log std Std           0.0010433691
Policy log std Max           0.0016407097
Policy log std Min           -0.0020184107
Z mean eval                  0.026589826
Z variance eval              0.58883274
total_rewards                [ 10.72945366  68.61138194  25.47627802  78.48916957 111.0681504
  68.71519553  71.02865102  53.91281892  76.12110143  86.24953234]
total_rewards_mean           65.0401732832683
total_rewards_std            27.519028569256268
total_rewards_max            111.06815040000205
total_rewards_min            10.729453660002095
Number of train steps total  1000
Number of env steps total    7000
Number of rollouts total     0
Train Time (s)               30.266317098401487
(Previous) Eval Time (s)     0
Sample Time (s)              18.66422809381038
Epoch Time (s)               48.930545192211866
Total Train Time (s)         50.147329138591886
Epoch                        0
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:03:33.660380 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #0 | Epoch Duration: 50.15370488166809
2020-01-11 00:03:33.660588 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #0 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026486132
Z variance train             0.5903282
KL Divergence                0.29706055
KL Loss                      0.029706055
QF Loss                      34.711502
VF Loss                      2.4369445
Policy Loss                  -11.049603
Q Predictions Mean           9.537714
Q Predictions Std            7.677554
Q Predictions Max            27.861734
Q Predictions Min            -4.0885653
V Predictions Mean           12.102646
V Predictions Std            7.694116
V Predictions Max            29.96802
V Predictions Min            -2.249002
Log Pis Mean                 -1.9468197
Log Pis Std                  0.43420827
Log Pis Max                  -0.6750458
Log Pis Min                  -4.080131
Policy mu Mean               0.118608646
Policy mu Std                0.18478025
Policy mu Max                0.51896757
Policy mu Min                -0.20461713
Policy log std Mean          -0.1465586
Policy log std Std           0.018457707
Policy log std Max           -0.10941944
Policy log std Min           -0.19813466
Z mean eval                  0.024042394
Z variance eval              0.25257763
total_rewards                [ 50.7037914   62.81042554  43.96765189 145.87490541  52.51174958
  52.85819597  44.93183341  51.03613993  67.12139962  49.80038516]
total_rewards_mean           62.16164779134645
total_rewards_std            28.719945170134505
total_rewards_max            145.87490541039116
total_rewards_min            43.96765188847565
Number of train steps total  2000
Number of env steps total    12000
Number of rollouts total     0
Train Time (s)               30.551251977682114
(Previous) Eval Time (s)     1.2226963778957725
Sample Time (s)              14.15927161090076
Epoch Time (s)               45.933219966478646
Total Train Time (s)         95.68928926018998
Epoch                        1
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:04:19.200332 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #1 | Epoch Duration: 45.539597272872925
2020-01-11 00:04:19.200482 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #1 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020069977
Z variance train             0.25330886
KL Divergence                1.5675302
KL Loss                      0.15675302
QF Loss                      23.363625
VF Loss                      4.00715
Policy Loss                  -15.868343
Q Predictions Mean           14.25014
Q Predictions Std            16.985588
Q Predictions Max            87.621544
Q Predictions Min            -2.1960828
V Predictions Mean           16.331642
V Predictions Std            17.15512
V Predictions Max            90.395966
V Predictions Min            -1.2345359
Log Pis Mean                 -1.8471296
Log Pis Std                  0.7442659
Log Pis Max                  2.1220274
Log Pis Min                  -3.5090992
Policy mu Mean               0.119315974
Policy mu Std                0.29050696
Policy mu Max                1.1860263
Policy mu Min                -0.20023996
Policy log std Mean          -0.16520812
Policy log std Std           0.08339335
Policy log std Max           -0.0895555
Policy log std Min           -0.47853282
Z mean eval                  0.067188725
Z variance eval              0.114167534
total_rewards                [157.1765336  140.54934948  55.03791369 116.81095278 127.07140418
 160.73595885  80.92397529 120.53764774 218.41199314 127.72134702]
total_rewards_mean           130.49770757649475
total_rewards_std            42.324675918123624
total_rewards_max            218.41199313507593
total_rewards_min            55.037913693286356
Number of train steps total  3000
Number of env steps total    17000
Number of rollouts total     0
Train Time (s)               30.81093100924045
(Previous) Eval Time (s)     0.8287718379870057
Sample Time (s)              12.930747710168362
Epoch Time (s)               44.570450557395816
Total Train Time (s)         141.64522658567876
Epoch                        2
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:05:05.157376 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #2 | Epoch Duration: 45.95677852630615
2020-01-11 00:05:05.157564 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #2 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.067518875
Z variance train             0.116938636
KL Divergence                3.1876185
KL Loss                      0.31876186
QF Loss                      57.723198
VF Loss                      4.614026
Policy Loss                  -23.647322
Q Predictions Mean           22.086952
Q Predictions Std            28.976866
Q Predictions Max            124.38506
Q Predictions Min            -3.9004679
V Predictions Mean           23.687431
V Predictions Std            28.803547
V Predictions Max            119.30259
V Predictions Min            -2.4792495
Log Pis Mean                 -1.6242768
Log Pis Std                  1.145045
Log Pis Max                  3.7015705
Log Pis Min                  -4.026188
Policy mu Mean               0.15994398
Policy mu Std                0.39753592
Policy mu Max                1.9366829
Policy mu Min                -1.0006168
Policy log std Mean          -0.20459491
Policy log std Std           0.11222951
Policy log std Max           -0.09863344
Policy log std Min           -0.6472589
Z mean eval                  0.05569253
Z variance eval              0.0396292
total_rewards                [181.73167884 325.76735876 332.79807604 312.17847332 265.86070045
 320.97785562 333.30114132 337.98443743 343.26532291 314.59269965]
total_rewards_mean           306.84577443346905
total_rewards_std            46.52839567899935
total_rewards_max            343.2653229060602
total_rewards_min            181.7316788399396
Number of train steps total  4000
Number of env steps total    22000
Number of rollouts total     0
Train Time (s)               30.97315056808293
(Previous) Eval Time (s)     2.2147550024092197
Sample Time (s)              14.7225031577982
Epoch Time (s)               47.91040872829035
Total Train Time (s)         191.48868996463716
Epoch                        3
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:05:55.000414 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #3 | Epoch Duration: 49.84272599220276
2020-01-11 00:05:55.000527 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #3 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.052979954
Z variance train             0.04750199
KL Divergence                5.2634926
KL Loss                      0.52634925
QF Loss                      30.629953
VF Loss                      10.056182
Policy Loss                  -37.728107
Q Predictions Mean           35.263237
Q Predictions Std            45.10834
Q Predictions Max            158.05803
Q Predictions Min            -6.647296
V Predictions Mean           37.235188
V Predictions Std            45.25705
V Predictions Max            162.9658
V Predictions Min            -4.6033573
Log Pis Mean                 -1.6713634
Log Pis Std                  1.0045797
Log Pis Max                  3.518489
Log Pis Min                  -4.572224
Policy mu Mean               0.07883921
Policy mu Std                0.41208878
Policy mu Max                1.7045779
Policy mu Min                -1.3869996
Policy log std Mean          -0.23548935
Policy log std Std           0.15103857
Policy log std Max           -0.10515492
Policy log std Min           -0.7930541
Z mean eval                  0.039729945
Z variance eval              0.02122881
total_rewards                [338.01553251 345.99971842 363.97199003 326.61074589 329.82174669
 352.46384769 348.38026709 364.8159058  346.53015006 348.87465184]
total_rewards_mean           346.54845560236
total_rewards_std            11.964301726644019
total_rewards_max            364.81590580369647
total_rewards_min            326.61074589305395
Number of train steps total  5000
Number of env steps total    27000
Number of rollouts total     0
Train Time (s)               30.91683672880754
(Previous) Eval Time (s)     4.146769751794636
Sample Time (s)              17.83284359658137
Epoch Time (s)               52.896450077183545
Total Train Time (s)         244.40614677919075
Epoch                        4
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:06:47.922804 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #4 | Epoch Duration: 52.9221773147583
2020-01-11 00:06:47.922973 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #4 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040154435
Z variance train             0.020558018
KL Divergence                7.2814655
KL Loss                      0.72814655
QF Loss                      71.89789
VF Loss                      15.360215
Policy Loss                  -59.465797
Q Predictions Mean           54.87498
Q Predictions Std            64.03212
Q Predictions Max            195.68477
Q Predictions Min            -3.9964855
V Predictions Mean           59.548306
V Predictions Std            65.7031
V Predictions Max            201.1116
V Predictions Min            -1.8115464
Log Pis Mean                 -1.2948047
Log Pis Std                  1.6206936
Log Pis Max                  5.790661
Log Pis Min                  -5.0501575
Policy mu Mean               0.042854417
Policy mu Std                0.5730834
Policy mu Max                1.8084648
Policy mu Min                -1.7233307
Policy log std Mean          -0.31780607
Policy log std Std           0.2326935
Policy log std Max           -0.09871339
Policy log std Min           -0.959804
Z mean eval                  0.033475537
Z variance eval              0.007966122
total_rewards                [326.95803816 302.95757156 309.42459662 339.50769619 354.11402378
 346.3899378  338.31319332 228.27500099 332.15318015 319.38044389]
total_rewards_mean           319.7473682454518
total_rewards_std            34.04076580788102
total_rewards_max            354.114023780601
total_rewards_min            228.27500098795974
Number of train steps total  6000
Number of env steps total    32000
Number of rollouts total     0
Train Time (s)               31.05026436271146
(Previous) Eval Time (s)     4.172175330109894
Sample Time (s)              20.12335371831432
Epoch Time (s)               55.34579341113567
Total Train Time (s)         299.7451312430203
Epoch                        5
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:07:43.260634 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #5 | Epoch Duration: 55.337509632110596
2020-01-11 00:07:43.260874 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #5 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033154573
Z variance train             0.007984597
KL Divergence                9.672311
KL Loss                      0.9672311
QF Loss                      57.98923
VF Loss                      22.852116
Policy Loss                  -85.0979
Q Predictions Mean           82.79522
Q Predictions Std            90.0113
Q Predictions Max            246.27472
Q Predictions Min            -4.9879575
V Predictions Mean           87.58327
V Predictions Std            91.92745
V Predictions Max            251.69647
V Predictions Min            -1.396944
Log Pis Mean                 -1.255902
Log Pis Std                  1.4037503
Log Pis Max                  5.1215224
Log Pis Min                  -4.230089
Policy mu Mean               -0.013409392
Policy mu Std                0.55258393
Policy mu Max                1.9710511
Policy mu Min                -2.262724
Policy log std Mean          -0.33995116
Policy log std Std           0.2647097
Policy log std Max           -0.08971545
Policy log std Min           -1.063372
Z mean eval                  0.013656305
Z variance eval              0.0034099296
total_rewards                [139.68282841 213.88376781 125.13856606 380.82961259 215.06469718
 178.93932176 202.34113442 121.94905037 253.19269069 147.6645665 ]
total_rewards_mean           197.86862357821948
total_rewards_std            73.77361620873354
total_rewards_max            380.8296125941042
total_rewards_min            121.94905037228276
Number of train steps total  7000
Number of env steps total    37000
Number of rollouts total     0
Train Time (s)               31.12620525388047
(Previous) Eval Time (s)     4.16357495682314
Sample Time (s)              19.13850288465619
Epoch Time (s)               54.4282830953598
Total Train Time (s)         352.9875934673473
Epoch                        6
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:08:36.504483 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #6 | Epoch Duration: 53.243449449539185
2020-01-11 00:08:36.504692 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #6 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013534734
Z variance train             0.0038681298
KL Divergence                11.413842
KL Loss                      1.1413842
QF Loss                      1104.6996
VF Loss                      52.092834
Policy Loss                  -122.09263
Q Predictions Mean           121.43369
Q Predictions Std            111.34866
Q Predictions Max            294.0912
Q Predictions Min            -5.482259
V Predictions Mean           123.18318
V Predictions Std            110.830734
V Predictions Max            305.21786
V Predictions Min            -3.3779616
Log Pis Mean                 -1.0154151
Log Pis Std                  1.5755054
Log Pis Max                  5.391894
Log Pis Min                  -4.6098323
Policy mu Mean               0.098006405
Policy mu Std                0.59597176
Policy mu Max                2.2863178
Policy mu Min                -2.0584974
Policy log std Mean          -0.37136593
Policy log std Std           0.25527292
Policy log std Max           -0.09182305
Policy log std Min           -1.1069276
Z mean eval                  0.020454485
Z variance eval              0.0047339336
total_rewards                [344.20516794 380.87847963 337.12361165 345.46694721 374.4848553
 358.04673378 359.10480144 373.01338427 351.71799566 367.03334781]
total_rewards_mean           359.1075324688133
total_rewards_std            13.834004577359156
total_rewards_max            380.8784796343999
total_rewards_min            337.1236116452436
Number of train steps total  8000
Number of env steps total    42000
Number of rollouts total     0
Train Time (s)               30.957914346829057
(Previous) Eval Time (s)     2.9783410849049687
Sample Time (s)              18.39092287234962
Epoch Time (s)               52.327178304083645
Total Train Time (s)         406.9947889158502
Epoch                        7
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:09:30.513431 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #7 | Epoch Duration: 54.008514404296875
2020-01-11 00:09:30.513720 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #7 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021985117
Z variance train             0.00496152
KL Divergence                10.943558
KL Loss                      1.0943558
QF Loss                      193.29425
VF Loss                      31.89183
Policy Loss                  -143.3478
Q Predictions Mean           134.57956
Q Predictions Std            132.83595
Q Predictions Max            418.5353
Q Predictions Min            -6.3230085
V Predictions Mean           144.8086
V Predictions Std            136.53387
V Predictions Max            429.95297
V Predictions Min            -3.0050507
Log Pis Mean                 -0.6575785
Log Pis Std                  1.9374475
Log Pis Max                  5.7303543
Log Pis Min                  -3.5885582
Policy mu Mean               0.041861888
Policy mu Std                0.7744956
Policy mu Max                2.6696968
Policy mu Min                -2.9084284
Policy log std Mean          -0.38086614
Policy log std Std           0.26366436
Policy log std Max           -0.08355616
Policy log std Min           -1.3645941
Z mean eval                  0.018341873
Z variance eval              0.0027775117
total_rewards                [377.77724731 358.97863555 371.47248713 322.25011534 342.03450296
 332.31847284 354.02584965 380.10411668 333.01174874 413.86803544]
total_rewards_mean           358.5841211647861
total_rewards_std            26.481543174570014
total_rewards_max            413.868035441015
total_rewards_min            322.25011533865904
Number of train steps total  9000
Number of env steps total    47000
Number of rollouts total     0
Train Time (s)               30.491495749913156
(Previous) Eval Time (s)     4.659355406183749
Sample Time (s)              18.995000021532178
Epoch Time (s)               54.14585117762908
Total Train Time (s)         461.4029626818374
Epoch                        8
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:10:24.921783 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #8 | Epoch Duration: 54.407862186431885
2020-01-11 00:10:24.921963 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #8 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01693942
Z variance train             0.0029205817
KL Divergence                12.177782
KL Loss                      1.2177782
QF Loss                      116.348404
VF Loss                      39.78348
Policy Loss                  -152.65735
Q Predictions Mean           151.03244
Q Predictions Std            159.28876
Q Predictions Max            431.54877
Q Predictions Min            -6.5703034
V Predictions Mean           153.2069
V Predictions Std            158.33836
V Predictions Max            435.04224
V Predictions Min            -4.950321
Log Pis Mean                 -0.96140635
Log Pis Std                  1.577533
Log Pis Max                  6.8227468
Log Pis Min                  -3.0115077
Policy mu Mean               0.035351045
Policy mu Std                0.6464163
Policy mu Max                2.3996582
Policy mu Min                -2.2788572
Policy log std Mean          -0.38710818
Policy log std Std           0.29957744
Policy log std Max           -0.05154278
Policy log std Min           -1.3839762
Z mean eval                  0.021627951
Z variance eval              0.0039802454
total_rewards                [404.32071664 378.75462928 372.70872742 356.84093448 382.65578642
 393.97171139 405.00449185 369.80228273 374.78216231 353.563065  ]
total_rewards_mean           379.2404507526183
total_rewards_std            16.835680445660536
total_rewards_max            405.0044918503393
total_rewards_min            353.5630649982128
Number of train steps total  10000
Number of env steps total    52000
Number of rollouts total     0
Train Time (s)               31.25347454380244
(Previous) Eval Time (s)     4.921055952087045
Sample Time (s)              20.65163559280336
Epoch Time (s)               56.826166088692844
Total Train Time (s)         517.4146692045033
Epoch                        9
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:11:20.935502 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #9 | Epoch Duration: 56.0134003162384
2020-01-11 00:11:20.935700 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #9 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023848275
Z variance train             0.003224215
KL Divergence                11.9057045
KL Loss                      1.1905705
QF Loss                      200.73874
VF Loss                      24.301039
Policy Loss                  -213.94704
Q Predictions Mean           210.72092
Q Predictions Std            179.49612
Q Predictions Max            540.6157
Q Predictions Min            -5.509858
V Predictions Mean           214.39047
V Predictions Std            178.84833
V Predictions Max            534.1483
V Predictions Min            -3.0511007
Log Pis Mean                 -0.625914
Log Pis Std                  1.8416772
Log Pis Max                  5.750698
Log Pis Min                  -7.0729184
Policy mu Mean               0.014301524
Policy mu Std                0.7495782
Policy mu Max                1.9598318
Policy mu Min                -2.6007967
Policy log std Mean          -0.4461236
Policy log std Std           0.31856567
Policy log std Max           -0.040748
Policy log std Min           -1.4069445
Z mean eval                  0.027410949
Z variance eval              0.0015943951
total_rewards                [360.80448484 372.87660524 358.18630051 371.11752373 372.84796566
 360.94159398 346.92487913 363.78807955 366.10463379 371.9387199 ]
total_rewards_mean           364.55307863324555
total_rewards_std            7.855587102892538
total_rewards_max            372.8766052368387
total_rewards_min            346.92487913339187
Number of train steps total  11000
Number of env steps total    57000
Number of rollouts total     0
Train Time (s)               30.695216118358076
(Previous) Eval Time (s)     4.107905561104417
Sample Time (s)              18.682986243627965
Epoch Time (s)               53.48610792309046
Total Train Time (s)         569.8724958491512
Epoch                        10
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:12:13.394578 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #10 | Epoch Duration: 52.45866513252258
2020-01-11 00:12:13.394839 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #10 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026634583
Z variance train             0.0014713766
KL Divergence                13.8498535
KL Loss                      1.3849853
QF Loss                      486.24908
VF Loss                      93.144264
Policy Loss                  -213.89627
Q Predictions Mean           211.7992
Q Predictions Std            192.93625
Q Predictions Max            562.59845
Q Predictions Min            -5.109295
V Predictions Mean           220.07202
V Predictions Std            196.04474
V Predictions Max            542.54553
V Predictions Min            -1.6983359
Log Pis Mean                 -0.33868498
Log Pis Std                  1.9856404
Log Pis Max                  9.49097
Log Pis Min                  -3.5368352
Policy mu Mean               0.19926171
Policy mu Std                0.7811649
Policy mu Max                2.782279
Policy mu Min                -2.6969247
Policy log std Mean          -0.46474442
Policy log std Std           0.31855854
Policy log std Max           -0.10308256
Policy log std Min           -1.4426233
Z mean eval                  0.009853052
Z variance eval              0.0024030185
total_rewards                [347.90114548 321.07522934 324.59316686 333.77624525 319.9000828
 346.11374596 328.55125689 382.26344863 351.83004561 369.66564323]
total_rewards_mean           342.56700100503105
total_rewards_std            20.023594760905723
total_rewards_max            382.2634486315861
total_rewards_min            319.9000827981535
Number of train steps total  12000
Number of env steps total    62000
Number of rollouts total     0
Train Time (s)               30.889728923793882
(Previous) Eval Time (s)     3.0801622890867293
Sample Time (s)              18.702479977160692
Epoch Time (s)               52.672371190041304
Total Train Time (s)         623.436172563117
Epoch                        11
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:13:06.959266 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #11 | Epoch Duration: 53.56427836418152
2020-01-11 00:13:06.959445 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #11 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011617202
Z variance train             0.0017070044
KL Divergence                13.702921
KL Loss                      1.3702921
QF Loss                      331.64233
VF Loss                      86.62389
Policy Loss                  -240.39279
Q Predictions Mean           230.20569
Q Predictions Std            224.72351
Q Predictions Max            632.6059
Q Predictions Min            -8.41765
V Predictions Mean           235.70386
V Predictions Std            222.91397
V Predictions Max            616.6725
V Predictions Min            -3.247944
Log Pis Mean                 -0.40799206
Log Pis Std                  2.2126088
Log Pis Max                  9.70751
Log Pis Min                  -4.987379
Policy mu Mean               0.014830362
Policy mu Std                0.7760613
Policy mu Max                2.4482808
Policy mu Min                -3.6118011
Policy log std Mean          -0.43816814
Policy log std Std           0.33740208
Policy log std Max           -0.073311076
Policy log std Min           -1.4838591
Z mean eval                  0.012093007
Z variance eval              0.00241483
total_rewards                [329.31339862 307.6705747  258.17676928 388.66256502 303.91139806
 858.18741403 313.42714045 340.08871053 164.59515893 321.81057413]
total_rewards_mean           358.5843703741329
total_rewards_std            175.6112509928135
total_rewards_max            858.1874140260925
total_rewards_min            164.59515892627547
Number of train steps total  13000
Number of env steps total    67000
Number of rollouts total     0
Train Time (s)               30.82227645115927
(Previous) Eval Time (s)     3.9716894887387753
Sample Time (s)              18.040620107203722
Epoch Time (s)               52.834586047101766
Total Train Time (s)         679.1444779089652
Epoch                        12
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:14:02.668968 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #12 | Epoch Duration: 55.709367752075195
2020-01-11 00:14:02.669217 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #12 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01216197
Z variance train             0.0022220968
KL Divergence                12.97816
KL Loss                      1.297816
QF Loss                      237.79529
VF Loss                      67.9396
Policy Loss                  -274.54974
Q Predictions Mean           268.87433
Q Predictions Std            234.93434
Q Predictions Max            686.9146
Q Predictions Min            -6.858407
V Predictions Mean           269.71362
V Predictions Std            233.67123
V Predictions Max            671.1424
V Predictions Min            -4.802189
Log Pis Mean                 -0.13226542
Log Pis Std                  2.3266609
Log Pis Max                  8.310453
Log Pis Min                  -4.6699295
Policy mu Mean               0.25396398
Policy mu Std                0.85059184
Policy mu Max                2.669519
Policy mu Min                -2.936451
Policy log std Mean          -0.46895972
Policy log std Std           0.31780523
Policy log std Max           -0.09384453
Policy log std Min           -1.5005872
Z mean eval                  0.009370426
Z variance eval              0.004009909
total_rewards                [320.09688443 310.54622509 323.99171879 333.11759977 325.88755476
 311.96005009 313.12404346 324.99188998 331.31369554 325.71140049]
total_rewards_mean           322.0741062383587
total_rewards_std            7.526559401492273
total_rewards_max            333.1175997685075
total_rewards_min            310.5462250855529
Number of train steps total  14000
Number of env steps total    72000
Number of rollouts total     0
Train Time (s)               31.032932445872575
(Previous) Eval Time (s)     6.846145196817815
Sample Time (s)              20.473794294521213
Epoch Time (s)               58.3528719372116
Total Train Time (s)         733.8671323363669
Epoch                        13
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:14:57.392756 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #13 | Epoch Duration: 54.72339606285095
2020-01-11 00:14:57.392894 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #13 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.00987216
Z variance train             0.004145436
KL Divergence                11.850637
KL Loss                      1.1850637
QF Loss                      273.58286
VF Loss                      31.767653
Policy Loss                  -262.30438
Q Predictions Mean           260.6338
Q Predictions Std            259.68176
Q Predictions Max            746.6887
Q Predictions Min            -8.814343
V Predictions Mean           261.87476
V Predictions Std            259.30945
V Predictions Max            734.0703
V Predictions Min            -5.2544
Log Pis Mean                 -0.5694754
Log Pis Std                  1.9385861
Log Pis Max                  8.500201
Log Pis Min                  -4.473015
Policy mu Mean               0.16300912
Policy mu Std                0.7197198
Policy mu Max                2.021441
Policy mu Min                -2.5900042
Policy log std Mean          -0.4503893
Policy log std Std           0.3501393
Policy log std Max           -0.014051929
Policy log std Min           -1.5211142
Z mean eval                  0.008957582
Z variance eval              0.0026167887
total_rewards                [296.91738307 314.30222688 289.49394308 292.90863362 296.22182023
 317.00214317 314.79808835 305.45517955 297.52770185 321.11458037]
total_rewards_mean           304.57417001725497
total_rewards_std            10.814426922108469
total_rewards_max            321.1145803715063
total_rewards_min            289.4939430785715
Number of train steps total  15000
Number of env steps total    77000
Number of rollouts total     0
Train Time (s)               30.919219001196325
(Previous) Eval Time (s)     3.2163559240289032
Sample Time (s)              17.73497967561707
Epoch Time (s)               51.8705546008423
Total Train Time (s)         785.1884572324343
Epoch                        14
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:15:48.714253 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #14 | Epoch Duration: 51.321258783340454
2020-01-11 00:15:48.714413 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #14 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011045639
Z variance train             0.002568997
KL Divergence                13.183407
KL Loss                      1.3183407
QF Loss                      710.43945
VF Loss                      88.49152
Policy Loss                  -302.43417
Q Predictions Mean           300.3154
Q Predictions Std            270.27765
Q Predictions Max            788.7538
Q Predictions Min            -5.03804
V Predictions Mean           307.61316
V Predictions Std            271.19217
V Predictions Max            791.2388
V Predictions Min            0.5292738
Log Pis Mean                 -0.11441173
Log Pis Std                  2.182102
Log Pis Max                  7.792965
Log Pis Min                  -3.5240893
Policy mu Mean               0.21568088
Policy mu Std                0.83071893
Policy mu Max                2.2832828
Policy mu Min                -3.0028055
Policy log std Mean          -0.4752915
Policy log std Std           0.3297881
Policy log std Max           -0.07329056
Policy log std Min           -1.6337264
Z mean eval                  0.020112883
Z variance eval              0.0032170124
total_rewards                [298.87539425 296.10532066 307.39683515 297.72013823 322.86649825
 305.62741715 297.28366395 296.19472967 288.38802339 305.03156234]
total_rewards_mean           301.54895830380593
total_rewards_std            8.882056277781558
total_rewards_max            322.86649825278516
total_rewards_min            288.38802338803987
Number of train steps total  16000
Number of env steps total    82000
Number of rollouts total     0
Train Time (s)               31.105909927282482
(Previous) Eval Time (s)     2.6667452650144696
Sample Time (s)              17.706172281876206
Epoch Time (s)               51.47882747417316
Total Train Time (s)         837.6405712449923
Epoch                        15
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:16:41.168102 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #15 | Epoch Duration: 52.453561782836914
2020-01-11 00:16:41.168276 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #15 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020393986
Z variance train             0.0039881403
KL Divergence                12.226855
KL Loss                      1.2226856
QF Loss                      1019.88434
VF Loss                      76.470985
Policy Loss                  -332.90912
Q Predictions Mean           329.082
Q Predictions Std            296.29337
Q Predictions Max            826.2245
Q Predictions Min            -2.6181242
V Predictions Mean           335.94678
V Predictions Std            299.85123
V Predictions Max            822.94
V Predictions Min            -2.355661
Log Pis Mean                 -0.32781228
Log Pis Std                  2.0666573
Log Pis Max                  5.631875
Log Pis Min                  -4.20846
Policy mu Mean               0.2374204
Policy mu Std                0.78249353
Policy mu Max                2.4577897
Policy mu Min                -2.6808796
Policy log std Mean          -0.48388842
Policy log std Std           0.3615335
Policy log std Max           -0.0657296
Policy log std Min           -1.7053568
Z mean eval                  0.014547816
Z variance eval              0.0021805756
total_rewards                [296.86172311 295.55370847 307.19775922 286.47594017 281.50244621
 283.36911875 295.23838427 302.96918246 302.96359234 292.28624814]
total_rewards_mean           294.44181031419777
total_rewards_std            8.20920873059584
total_rewards_max            307.1977592196281
total_rewards_min            281.50244620992373
Number of train steps total  17000
Number of env steps total    87000
Number of rollouts total     0
Train Time (s)               30.757525188848376
(Previous) Eval Time (s)     3.6411369792185724
Sample Time (s)              17.02162070851773
Epoch Time (s)               51.42028287658468
Total Train Time (s)         888.4438684671186
Epoch                        16
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:17:31.971710 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #16 | Epoch Duration: 50.80330777168274
2020-01-11 00:17:31.971861 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #16 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012177665
Z variance train             0.0027766451
KL Divergence                13.109672
KL Loss                      1.3109672
QF Loss                      299.53464
VF Loss                      100.70416
Policy Loss                  -328.2709
Q Predictions Mean           327.2192
Q Predictions Std            307.13824
Q Predictions Max            844.59717
Q Predictions Min            -6.0918818
V Predictions Mean           332.48755
V Predictions Std            309.48193
V Predictions Max            859.48065
V Predictions Min            -2.4687605
Log Pis Mean                 -0.5109077
Log Pis Std                  1.9726111
Log Pis Max                  8.835842
Log Pis Min                  -6.2381363
Policy mu Mean               0.12479818
Policy mu Std                0.76115525
Policy mu Max                2.7282813
Policy mu Min                -2.9532928
Policy log std Mean          -0.48569503
Policy log std Std           0.36504662
Policy log std Max           -0.09506688
Policy log std Min           -1.7687562
Z mean eval                  0.0071532503
Z variance eval              0.0036396317
total_rewards                [289.46333751 308.11481542 355.32121829 311.50004946 310.99786085
 303.71427859 310.03478528 316.68873113 311.45315321 311.73800788]
total_rewards_mean           312.90262376417246
total_rewards_std            15.772437464790753
total_rewards_max            355.32121829468434
total_rewards_min            289.46333751036445
Number of train steps total  18000
Number of env steps total    92000
Number of rollouts total     0
Train Time (s)               31.184879643376917
(Previous) Eval Time (s)     3.0238808933645487
Sample Time (s)              16.66138250147924
Epoch Time (s)               50.870143038220704
Total Train Time (s)         939.3826386556029
Epoch                        17
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:18:22.912475 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #17 | Epoch Duration: 50.94048094749451
2020-01-11 00:18:22.912675 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #17 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010559486
Z variance train             0.003698045
KL Divergence                12.478775
KL Loss                      1.2478775
QF Loss                      300.9643
VF Loss                      165.81744
Policy Loss                  -365.95535
Q Predictions Mean           358.04352
Q Predictions Std            325.9021
Q Predictions Max            937.0292
Q Predictions Min            -9.404067
V Predictions Mean           358.90765
V Predictions Std            326.0642
V Predictions Max            927.39905
V Predictions Min            -10.252751
Log Pis Mean                 -0.1470456
Log Pis Std                  2.2275198
Log Pis Max                  9.399709
Log Pis Min                  -4.1196647
Policy mu Mean               0.17056869
Policy mu Std                0.845202
Policy mu Max                2.5610836
Policy mu Min                -3.0525258
Policy log std Mean          -0.46375498
Policy log std Std           0.33094493
Policy log std Max           -0.068964496
Policy log std Min           -1.5260706
Z mean eval                  0.014631769
Z variance eval              0.0019942634
total_rewards                [284.04596725 298.42559837 440.33578543 270.77011832 272.92225598
 376.01755906 353.03710581 328.53108797 275.23618489 266.94121972]
total_rewards_mean           316.62628828128135
total_rewards_std            54.668230727328435
total_rewards_max            440.33578542988806
total_rewards_min            266.94121972235786
Number of train steps total  19000
Number of env steps total    97000
Number of rollouts total     0
Train Time (s)               30.573476111050695
(Previous) Eval Time (s)     3.093845194671303
Sample Time (s)              17.56938245985657
Epoch Time (s)               51.23670376557857
Total Train Time (s)         993.0627624737099
Epoch                        18
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:19:16.594213 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #18 | Epoch Duration: 53.68135690689087
2020-01-11 00:19:16.594484 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #18 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0129647525
Z variance train             0.0025176604
KL Divergence                13.898653
KL Loss                      1.3898653
QF Loss                      208.8899
VF Loss                      57.608032
Policy Loss                  -423.43253
Q Predictions Mean           414.90433
Q Predictions Std            330.8148
Q Predictions Max            941.99615
Q Predictions Min            -4.6779146
V Predictions Mean           424.94147
V Predictions Std            332.65216
V Predictions Max            963.4605
V Predictions Min            -4.3648553
Log Pis Mean                 0.0703865
Log Pis Std                  2.3725986
Log Pis Max                  8.446959
Log Pis Min                  -5.9490557
Policy mu Mean               0.20994897
Policy mu Std                0.8837473
Policy mu Max                2.8246577
Policy mu Min                -3.2157826
Policy log std Mean          -0.5307341
Policy log std Std           0.36750728
Policy log std Max           0.10250901
Policy log std Min           -1.7375216
Z mean eval                  0.01508114
Z variance eval              0.0026094366
total_rewards                [243.39952962 234.19541811 331.96893247 238.82075159 237.43219321
 236.26713037 246.30153782 244.95204013 322.02579252 244.52382418]
total_rewards_mean           257.9887150017973
total_rewards_std            34.78856438072496
total_rewards_max            331.96893247493534
total_rewards_min            234.1954181067187
Number of train steps total  20000
Number of env steps total    102000
Number of rollouts total     0
Train Time (s)               30.901774981059134
(Previous) Eval Time (s)     5.538151722867042
Sample Time (s)              20.261274322867393
Epoch Time (s)               56.70120102679357
Total Train Time (s)         1047.4024943951517
Epoch                        19
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:20:10.935065 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #19 | Epoch Duration: 54.34042048454285
2020-01-11 00:20:10.935258 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #19 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015555275
Z variance train             0.0021721101
KL Divergence                14.480497
KL Loss                      1.4480498
QF Loss                      894.19855
VF Loss                      134.1813
Policy Loss                  -427.25894
Q Predictions Mean           428.62836
Q Predictions Std            348.7698
Q Predictions Max            989.5991
Q Predictions Min            -9.522605
V Predictions Mean           429.63947
V Predictions Std            347.27405
V Predictions Max            1002.62195
V Predictions Min            -6.913979
Log Pis Mean                 0.012089705
Log Pis Std                  2.3262792
Log Pis Max                  7.5767083
Log Pis Min                  -6.1201057
Policy mu Mean               0.21219264
Policy mu Std                0.8794355
Policy mu Max                2.5567722
Policy mu Min                -3.0479074
Policy log std Mean          -0.49228302
Policy log std Std           0.34452847
Policy log std Max           0.13123608
Policy log std Min           -1.6048397
Z mean eval                  0.009666761
Z variance eval              0.0024845689
total_rewards                [227.93519846 356.95627711 344.58142553 371.61312361 326.15694766
 372.80015516 372.49034629 355.09167259 324.2188262  338.52905625]
total_rewards_mean           339.03730288588224
total_rewards_std            40.81570389936506
total_rewards_max            372.8001551642663
total_rewards_min            227.93519845584262
Number of train steps total  21000
Number of env steps total    107000
Number of rollouts total     0
Train Time (s)               31.286493041086942
(Previous) Eval Time (s)     3.1770517085678875
Sample Time (s)              16.561402721796185
Epoch Time (s)               51.024947471451014
Total Train Time (s)         1099.4036838538013
Epoch                        20
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:21:02.937180 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #20 | Epoch Duration: 52.001784563064575
2020-01-11 00:21:02.937359 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #20 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008960179
Z variance train             0.0039261905
KL Divergence                13.105944
KL Loss                      1.3105944
QF Loss                      346.94208
VF Loss                      137.21852
Policy Loss                  -402.1077
Q Predictions Mean           398.00882
Q Predictions Std            362.66177
Q Predictions Max            1014.78436
Q Predictions Min            -2.616018
V Predictions Mean           396.22913
V Predictions Std            359.8111
V Predictions Max            1010.8875
V Predictions Min            -1.22385
Log Pis Mean                 0.30960923
Log Pis Std                  2.7117162
Log Pis Max                  12.7488365
Log Pis Min                  -3.7034965
Policy mu Mean               0.31459486
Policy mu Std                0.97446966
Policy mu Max                3.7505453
Policy mu Min                -3.3939703
Policy log std Mean          -0.46885923
Policy log std Std           0.32442164
Policy log std Max           -0.04180853
Policy log std Min           -1.6075326
Z mean eval                  0.0151794795
Z variance eval              0.0031596601
total_rewards                [330.45300851 280.8643118  330.64202765 305.12590478 336.80860899
 332.80863505 334.09407252 338.16004174 320.849776   334.85367164]
total_rewards_mean           324.46600586744455
total_rewards_std            17.240304519563438
total_rewards_max            338.1600417396629
total_rewards_min            280.8643118024641
Number of train steps total  22000
Number of env steps total    112000
Number of rollouts total     0
Train Time (s)               30.853313592262566
(Previous) Eval Time (s)     4.153577511198819
Sample Time (s)              18.551423602737486
Epoch Time (s)               53.55831470619887
Total Train Time (s)         1152.6337358844467
Epoch                        21
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:21:56.168437 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #21 | Epoch Duration: 53.230939865112305
2020-01-11 00:21:56.168617 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #21 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015542218
Z variance train             0.0032668188
KL Divergence                13.710399
KL Loss                      1.3710399
QF Loss                      246.49614
VF Loss                      105.714134
Policy Loss                  -440.88672
Q Predictions Mean           436.8363
Q Predictions Std            372.6268
Q Predictions Max            1014.665
Q Predictions Min            -3.812631
V Predictions Mean           438.2798
V Predictions Std            373.71277
V Predictions Max            1014.98627
V Predictions Min            -4.843983
Log Pis Mean                 0.14721015
Log Pis Std                  2.2868228
Log Pis Max                  6.839848
Log Pis Min                  -5.4935284
Policy mu Mean               0.14677991
Policy mu Std                0.9222208
Policy mu Max                2.3691926
Policy mu Min                -2.8837905
Policy log std Mean          -0.49256492
Policy log std Std           0.3352093
Policy log std Max           -0.033198237
Policy log std Min           -1.643299
Z mean eval                  0.022784347
Z variance eval              0.004148795
total_rewards                [311.53478051 336.79998274 331.68960599 248.00751376 309.6545871
 349.7501717  327.42237195 332.25349668 321.2331816  320.83928573]
total_rewards_mean           318.9184977772358
total_rewards_std            26.194146409432722
total_rewards_max            349.75017170080764
total_rewards_min            248.0075137644055
Number of train steps total  23000
Number of env steps total    117000
Number of rollouts total     0
Train Time (s)               30.97728577395901
(Previous) Eval Time (s)     3.8258934770710766
Sample Time (s)              17.87233171192929
Epoch Time (s)               52.67551096295938
Total Train Time (s)         1205.0869304388762
Epoch                        22
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:22:48.623110 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #22 | Epoch Duration: 52.454357862472534
2020-01-11 00:22:48.623330 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #22 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022985097
Z variance train             0.004145743
KL Divergence                12.443979
KL Loss                      1.244398
QF Loss                      577.3473
VF Loss                      167.72879
Policy Loss                  -422.85773
Q Predictions Mean           416.10983
Q Predictions Std            376.9387
Q Predictions Max            1081.5902
Q Predictions Min            -4.5096207
V Predictions Mean           418.60245
V Predictions Std            376.23605
V Predictions Max            1081.7595
V Predictions Min            -0.7020532
Log Pis Mean                 -0.015296986
Log Pis Std                  2.3421314
Log Pis Max                  7.9732947
Log Pis Min                  -3.977352
Policy mu Mean               0.17545652
Policy mu Std                0.90752953
Policy mu Max                2.6652794
Policy mu Min                -3.617496
Policy log std Mean          -0.513906
Policy log std Std           0.33978063
Policy log std Max           -0.1029358
Policy log std Min           -1.5609468
Z mean eval                  0.022446882
Z variance eval              0.003707102
total_rewards                [386.79962206 338.44555982 338.37311127 343.51040917 355.47925189
 362.33935406 325.46187248 323.58898439 353.47517324 382.69684378]
total_rewards_mean           351.01701821518157
total_rewards_std            20.53722734889764
total_rewards_max            386.7996220571438
total_rewards_min            323.5889843857965
Number of train steps total  24000
Number of env steps total    122000
Number of rollouts total     0
Train Time (s)               31.02459511719644
(Previous) Eval Time (s)     3.604439546354115
Sample Time (s)              17.32811971893534
Epoch Time (s)               51.957154382485896
Total Train Time (s)         1257.4713065158576
Epoch                        23
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:23:41.008353 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #23 | Epoch Duration: 52.38488793373108
2020-01-11 00:23:41.008531 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #23 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016045231
Z variance train             0.0026514053
KL Divergence                13.616076
KL Loss                      1.3616077
QF Loss                      542.9874
VF Loss                      356.55014
Policy Loss                  -423.34283
Q Predictions Mean           418.0861
Q Predictions Std            383.36072
Q Predictions Max            1135.8944
Q Predictions Min            -1.8445054
V Predictions Mean           432.5445
V Predictions Std            387.68396
V Predictions Max            1153.549
V Predictions Min            0.40957195
Log Pis Mean                 0.18792313
Log Pis Std                  2.5318983
Log Pis Max                  9.260107
Log Pis Min                  -4.720354
Policy mu Mean               0.17178535
Policy mu Std                0.93149287
Policy mu Max                3.4388082
Policy mu Min                -3.137384
Policy log std Mean          -0.49718508
Policy log std Std           0.330777
Policy log std Max           -0.09326147
Policy log std Min           -1.8451307
Z mean eval                  0.009941803
Z variance eval              0.0027275742
total_rewards                [283.40634447 338.83637271 371.19306609 360.61961376 371.38001066
 347.35798206 365.74363707 340.12423022 279.67597756 354.11827315]
total_rewards_mean           341.2455507748794
total_rewards_std            31.822580542432412
total_rewards_max            371.3800106645187
total_rewards_min            279.67597755713575
Number of train steps total  25000
Number of env steps total    127000
Number of rollouts total     0
Train Time (s)               31.02185179013759
(Previous) Eval Time (s)     4.03179980115965
Sample Time (s)              18.44332126248628
Epoch Time (s)               53.49697285378352
Total Train Time (s)         1311.2012164588086
Epoch                        24
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:24:34.739831 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #24 | Epoch Duration: 53.73115611076355
2020-01-11 00:24:34.740002 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #24 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.009273192
Z variance train             0.0028040374
KL Divergence                13.248844
KL Loss                      1.3248844
QF Loss                      348.94165
VF Loss                      143.83151
Policy Loss                  -472.5628
Q Predictions Mean           460.8576
Q Predictions Std            383.32645
Q Predictions Max            1114.8417
Q Predictions Min            -10.486504
V Predictions Mean           466.5805
V Predictions Std            386.381
V Predictions Max            1121.8552
V Predictions Min            -5.369672
Log Pis Mean                 -0.06873852
Log Pis Std                  2.2335446
Log Pis Max                  8.1433325
Log Pis Min                  -3.9616342
Policy mu Mean               0.105436295
Policy mu Std                0.8971972
Policy mu Max                2.3771963
Policy mu Min                -3.0812485
Policy log std Mean          -0.51075214
Policy log std Std           0.3358122
Policy log std Max           -0.029186666
Policy log std Min           -1.7052565
Z mean eval                  0.0146221295
Z variance eval              0.0028928132
total_rewards                [407.03259064 398.02624186 401.22884443 398.77142189 399.36008113
 400.27949352 405.85246585 400.2925652  398.40553655 407.50552928]
total_rewards_mean           401.6754770346157
total_rewards_std            3.492851692112797
total_rewards_max            407.5055292794449
total_rewards_min            398.02624185876857
Number of train steps total  26000
Number of env steps total    132000
Number of rollouts total     0
Train Time (s)               31.00897043943405
(Previous) Eval Time (s)     4.26568323886022
Sample Time (s)              18.039444601163268
Epoch Time (s)               53.31409827945754
Total Train Time (s)         1364.1599161326885
Epoch                        25
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:25:27.699231 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #25 | Epoch Duration: 52.95906662940979
2020-01-11 00:25:27.699407 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #25 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017328728
Z variance train             0.003023696
KL Divergence                12.75169
KL Loss                      1.275169
QF Loss                      1207.0298
VF Loss                      133.29762
Policy Loss                  -457.49478
Q Predictions Mean           451.3156
Q Predictions Std            387.4695
Q Predictions Max            1085.8154
Q Predictions Min            -8.135998
V Predictions Mean           456.21704
V Predictions Std            387.04977
V Predictions Max            1085.2192
V Predictions Min            -4.171123
Log Pis Mean                 0.089330465
Log Pis Std                  2.2598414
Log Pis Max                  8.83801
Log Pis Min                  -3.9074874
Policy mu Mean               0.06965207
Policy mu Std                0.93398863
Policy mu Max                2.7268634
Policy mu Min                -3.3424194
Policy log std Mean          -0.46498737
Policy log std Std           0.30979747
Policy log std Max           -0.013594255
Policy log std Min           -1.8511921
Z mean eval                  0.047910657
Z variance eval              0.0012366495
total_rewards                [378.58134022 388.1397153  401.16132886 391.66099001 383.58280656
 394.20939749 389.02938785 401.70548244 395.99991579 409.25337324]
total_rewards_mean           393.33237377542827
total_rewards_std            8.681501176436667
total_rewards_max            409.2533732405475
total_rewards_min            378.5813402233587
Number of train steps total  27000
Number of env steps total    137000
Number of rollouts total     0
Train Time (s)               31.186848196201026
(Previous) Eval Time (s)     3.9103721026331186
Sample Time (s)              18.610969222150743
Epoch Time (s)               53.70818952098489
Total Train Time (s)         1417.945911932271
Epoch                        26
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:26:21.487637 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #26 | Epoch Duration: 53.788097858428955
2020-01-11 00:26:21.487845 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #26 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.22125919
Z variance train             0.00016094383
KL Divergence                20.31233
KL Loss                      2.031233
QF Loss                      244.09926
VF Loss                      75.47821
Policy Loss                  -380.62308
Q Predictions Mean           380.42505
Q Predictions Std            362.9953
Q Predictions Max            992.5324
Q Predictions Min            -5.656588
V Predictions Mean           381.657
V Predictions Std            363.17572
V Predictions Max            1002.5655
V Predictions Min            -4.9657516
Log Pis Mean                 -0.19717792
Log Pis Std                  2.3961902
Log Pis Max                  9.900117
Log Pis Min                  -4.00106
Policy mu Mean               0.10513414
Policy mu Std                0.8852379
Policy mu Max                2.96289
Policy mu Min                -3.341849
Policy log std Mean          -0.44189084
Policy log std Std           0.3247873
Policy log std Max           -0.06652616
Policy log std Min           -1.7844372
Z mean eval                  0.016944692
Z variance eval              0.0018227197
total_rewards                [401.68419374 403.76670443 408.09857808 391.87865125 420.03976996
 380.57382544 387.35103597 372.27948544 388.14012974 479.24198655]
total_rewards_mean           403.30543605926937
total_rewards_std            28.577350434019316
total_rewards_max            479.24198654529056
total_rewards_min            372.27948544358304
Number of train steps total  28000
Number of env steps total    142000
Number of rollouts total     0
Train Time (s)               31.10644420888275
(Previous) Eval Time (s)     3.989936748985201
Sample Time (s)              17.00082544889301
Epoch Time (s)               52.09720640676096
Total Train Time (s)         1470.250926275272
Epoch                        27
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:27:13.794560 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #27 | Epoch Duration: 52.30648064613342
2020-01-11 00:27:13.794903 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #27 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018125767
Z variance train             0.0018507794
KL Divergence                13.46458
KL Loss                      1.346458
QF Loss                      237.5816
VF Loss                      83.322525
Policy Loss                  -475.32327
Q Predictions Mean           469.2472
Q Predictions Std            400.64688
Q Predictions Max            1054.2881
Q Predictions Min            -17.620562
V Predictions Mean           478.0259
V Predictions Std            402.2712
V Predictions Max            1084.8195
V Predictions Min            0.61724925
Log Pis Mean                 -0.14952382
Log Pis Std                  2.2319546
Log Pis Max                  7.5013647
Log Pis Min                  -3.822588
Policy mu Mean               0.05035368
Policy mu Std                0.84610504
Policy mu Max                2.1938477
Policy mu Min                -2.597177
Policy log std Mean          -0.475908
Policy log std Std           0.33406273
Policy log std Max           0.031357393
Policy log std Min           -1.7646899
Z mean eval                  0.010996924
Z variance eval              0.0014375532
total_rewards                [381.15588588 380.85046119 385.97907279 377.61675352 388.41769277
 368.32102885 402.48043836 410.39366142 378.04350957 390.85708912]
total_rewards_mean           386.41155934738333
total_rewards_std            11.791999491995277
total_rewards_max            410.39366142122265
total_rewards_min            368.3210288514177
Number of train steps total  29000
Number of env steps total    147000
Number of rollouts total     0
Train Time (s)               30.887153584044427
(Previous) Eval Time (s)     4.198899383656681
Sample Time (s)              19.49817061703652
Epoch Time (s)               54.58422358473763
Total Train Time (s)         1524.958276316058
Epoch                        28
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:28:08.506264 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #28 | Epoch Duration: 54.71116304397583
2020-01-11 00:28:08.506478 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #28 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010844424
Z variance train             0.0014420912
KL Divergence                14.085743
KL Loss                      1.4085743
QF Loss                      201.99173
VF Loss                      65.17075
Policy Loss                  -468.16547
Q Predictions Mean           463.59207
Q Predictions Std            404.93518
Q Predictions Max            1061.2974
Q Predictions Min            -15.182414
V Predictions Mean           470.49115
V Predictions Std            408.73892
V Predictions Max            1072.9232
V Predictions Min            -4.245168
Log Pis Mean                 -0.27152377
Log Pis Std                  2.1742623
Log Pis Max                  7.6923637
Log Pis Min                  -5.8435726
Policy mu Mean               0.076188
Policy mu Std                0.8643588
Policy mu Max                2.211442
Policy mu Min                -3.033147
Policy log std Mean          -0.49033418
Policy log std Std           0.33260688
Policy log std Max           -0.07119796
Policy log std Min           -1.8961402
Z mean eval                  0.016529249
Z variance eval              0.0014575211
total_rewards                [342.68721043 373.07869796 397.52843262 369.65815473 383.71260404
 377.51832663 375.05137665 373.67720208 369.74045667 384.7994992 ]
total_rewards_mean           374.74519610135894
total_rewards_std            13.382529510117278
total_rewards_max            397.52843261926756
total_rewards_min            342.6872104295711
Number of train steps total  30000
Number of env steps total    152000
Number of rollouts total     0
Train Time (s)               31.69575296714902
(Previous) Eval Time (s)     4.325495254248381
Sample Time (s)              17.908303215168417
Epoch Time (s)               53.929551436565816
Total Train Time (s)         1578.5166424275376
Epoch                        29
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:29:02.062825 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #29 | Epoch Duration: 53.55612301826477
2020-01-11 00:29:02.063123 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #29 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017448004
Z variance train             0.0014601656
KL Divergence                13.951802
KL Loss                      1.3951802
QF Loss                      690.0321
VF Loss                      186.52634
Policy Loss                  -451.66937
Q Predictions Mean           447.06146
Q Predictions Std            389.26968
Q Predictions Max            1057.7792
Q Predictions Min            -7.164452
V Predictions Mean           460.8907
V Predictions Std            398.29785
V Predictions Max            1078.3116
V Predictions Min            -3.0483637
Log Pis Mean                 -0.11743279
Log Pis Std                  2.2592676
Log Pis Max                  8.103357
Log Pis Min                  -4.3840346
Policy mu Mean               0.24293499
Policy mu Std                0.9047879
Policy mu Max                2.8818517
Policy mu Min                -2.6595993
Policy log std Mean          -0.4827005
Policy log std Std           0.33470267
Policy log std Max           0.05555238
Policy log std Min           -2.5311236
Z mean eval                  0.030848708
Z variance eval              0.0025139495
total_rewards                [398.7558299  386.14131948 396.0303838  391.58068769 392.44318667
 395.91665581 382.61142915 383.16443361 391.4140338  401.58473886]
total_rewards_mean           391.96426987680604
total_rewards_std            6.085491791408053
total_rewards_max            401.58473885593236
total_rewards_min            382.61142915487835
Number of train steps total  31000
Number of env steps total    157000
Number of rollouts total     0
Train Time (s)               31.327548041008413
(Previous) Eval Time (s)     3.951726029161364
Sample Time (s)              17.470294954720885
Epoch Time (s)               52.74956902489066
Total Train Time (s)         1631.544985102024
Epoch                        30
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:29:55.092431 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #30 | Epoch Duration: 53.02912616729736
2020-01-11 00:29:55.092602 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #30 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029291237
Z variance train             0.0024534704
KL Divergence                12.741919
KL Loss                      1.2741919
QF Loss                      260.21075
VF Loss                      63.85291
Policy Loss                  -432.16946
Q Predictions Mean           435.13214
Q Predictions Std            407.561
Q Predictions Max            1053.7372
Q Predictions Min            -5.670738
V Predictions Mean           433.34375
V Predictions Std            405.1307
V Predictions Max            1047.5709
V Predictions Min            -8.252671
Log Pis Mean                 -0.57693756
Log Pis Std                  1.9213294
Log Pis Max                  4.957113
Log Pis Min                  -4.762366
Policy mu Mean               0.15816686
Policy mu Std                0.7476674
Policy mu Max                2.3937945
Policy mu Min                -2.2305768
Policy log std Mean          -0.43399644
Policy log std Std           0.3058613
Policy log std Max           -0.08917895
Policy log std Min           -1.6437988
Z mean eval                  0.012098837
Z variance eval              0.0019430649
total_rewards                [424.45760595 397.77952394 408.29719855 360.15720122 385.09376056
 330.43881249 389.80660436 392.07207997 383.08035313 369.27459462]
total_rewards_mean           384.04577347887823
total_rewards_std            24.84363234664852
total_rewards_max            424.45760595148903
total_rewards_min            330.4388124875426
Number of train steps total  32000
Number of env steps total    162000
Number of rollouts total     0
Train Time (s)               31.0230303988792
(Previous) Eval Time (s)     4.231009128969163
Sample Time (s)              18.371494887862355
Epoch Time (s)               53.62553441571072
Total Train Time (s)         1685.23361052759
Epoch                        31
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:30:48.781868 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #31 | Epoch Duration: 53.68913435935974
2020-01-11 00:30:48.782067 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #31 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011560408
Z variance train             0.0019746523
KL Divergence                13.178093
KL Loss                      1.3178093
QF Loss                      299.78064
VF Loss                      104.576195
Policy Loss                  -494.9163
Q Predictions Mean           498.15765
Q Predictions Std            405.72614
Q Predictions Max            1077.7842
Q Predictions Min            -5.1254687
V Predictions Mean           499.48257
V Predictions Std            405.71738
V Predictions Max            1073.1155
V Predictions Min            -10.097398
Log Pis Mean                 -0.17616086
Log Pis Std                  2.0161285
Log Pis Max                  8.735632
Log Pis Min                  -3.67942
Policy mu Mean               0.030925259
Policy mu Std                0.8472323
Policy mu Max                2.2830265
Policy mu Min                -2.72207
Policy log std Mean          -0.49123994
Policy log std Std           0.33355504
Policy log std Max           0.021430135
Policy log std Min           -1.8553516
Z mean eval                  0.006766683
Z variance eval              0.0017754879
total_rewards                [370.91701639 323.54556988 367.46054567 366.03237054 357.38404205
 377.87433839 364.07105235 349.70485652 369.61723375 385.24501862]
total_rewards_mean           363.18520441728054
total_rewards_std            16.178385247094198
total_rewards_max            385.24501861635423
total_rewards_min            323.5455698768926
Number of train steps total  33000
Number of env steps total    167000
Number of rollouts total     0
Train Time (s)               31.29992320621386
(Previous) Eval Time (s)     4.29428030597046
Sample Time (s)              17.672971955500543
Epoch Time (s)               53.267175467684865
Total Train Time (s)         1737.917074399069
Epoch                        32
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:31:41.475970 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #32 | Epoch Duration: 52.69376492500305
2020-01-11 00:31:41.476157 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #32 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.007030219
Z variance train             0.0017351804
KL Divergence                13.453959
KL Loss                      1.3453959
QF Loss                      193.27481
VF Loss                      100.514534
Policy Loss                  -473.23947
Q Predictions Mean           475.5237
Q Predictions Std            407.65143
Q Predictions Max            1087.1815
Q Predictions Min            -4.9669657
V Predictions Mean           467.7988
V Predictions Std            402.5984
V Predictions Max            1075.9922
V Predictions Min            -12.469202
Log Pis Mean                 -0.40412444
Log Pis Std                  2.0529194
Log Pis Max                  7.623161
Log Pis Min                  -4.8923135
Policy mu Mean               0.09295226
Policy mu Std                0.81244206
Policy mu Max                2.9223483
Policy mu Min                -2.3183165
Policy log std Mean          -0.436674
Policy log std Std           0.3080034
Policy log std Max           0.108532324
Policy log std Min           -1.5913409
Z mean eval                  0.022178914
Z variance eval              0.0016632213
total_rewards                [ 367.61914884  383.98969068 1031.30462595  384.59845556 1030.00447603
  390.02316767  373.77140012  384.03320811  400.34487946  397.21162308]
total_rewards_mean           514.290067550088
total_rewards_std            258.34499053017214
total_rewards_max            1031.3046259543573
total_rewards_min            367.61914883886413
Number of train steps total  34000
Number of env steps total    172000
Number of rollouts total     0
Train Time (s)               31.158570700790733
(Previous) Eval Time (s)     3.7205462949350476
Sample Time (s)              18.066939444746822
Epoch Time (s)               52.9460564404726
Total Train Time (s)         1796.5140845365822
Epoch                        33
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:32:40.064110 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #33 | Epoch Duration: 58.58783197402954
2020-01-11 00:32:40.064233 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #33 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023352532
Z variance train             0.0016894769
KL Divergence                13.547924
KL Loss                      1.3547925
QF Loss                      1063.1152
VF Loss                      212.7399
Policy Loss                  -521.093
Q Predictions Mean           513.17816
Q Predictions Std            408.20746
Q Predictions Max            1098.158
Q Predictions Min            -5.657163
V Predictions Mean           512.9009
V Predictions Std            408.553
V Predictions Max            1087.5999
V Predictions Min            -3.3401923
Log Pis Mean                 -0.25499922
Log Pis Std                  2.1099625
Log Pis Max                  6.026663
Log Pis Min                  -4.267336
Policy mu Mean               0.02464638
Policy mu Std                0.8750543
Policy mu Max                3.5597358
Policy mu Min                -2.945334
Policy log std Mean          -0.46388555
Policy log std Std           0.30169913
Policy log std Max           0.118610725
Policy log std Min           -1.6547372
Z mean eval                  0.0069880695
Z variance eval              0.0015144234
total_rewards                [445.95064128 415.0899617  401.32389561 392.69706621 398.20925704
 417.74717045 412.36068641 473.78800932 408.35730532 433.02288491]
total_rewards_mean           419.85468782725076
total_rewards_std            23.51201569505809
total_rewards_max            473.78800932061966
total_rewards_min            392.6970662134078
Number of train steps total  35000
Number of env steps total    177000
Number of rollouts total     0
Train Time (s)               30.9265018212609
(Previous) Eval Time (s)     9.36198962200433
Sample Time (s)              21.01395480101928
Epoch Time (s)               61.30244624428451
Total Train Time (s)         1852.712184804026
Epoch                        34
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:33:36.264319 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #34 | Epoch Duration: 56.19997549057007
2020-01-11 00:33:36.264516 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #34 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0070521696
Z variance train             0.0015261436
KL Divergence                13.808952
KL Loss                      1.3808953
QF Loss                      369.03384
VF Loss                      51.51282
Policy Loss                  -425.5688
Q Predictions Mean           421.4417
Q Predictions Std            403.76562
Q Predictions Max            1078.8711
Q Predictions Min            -3.7709444
V Predictions Mean           423.97388
V Predictions Std            405.94424
V Predictions Max            1073.2999
V Predictions Min            -13.785236
Log Pis Mean                 -0.17924759
Log Pis Std                  2.2517152
Log Pis Max                  7.2949705
Log Pis Min                  -5.314374
Policy mu Mean               -0.14083456
Policy mu Std                0.86631554
Policy mu Max                2.292055
Policy mu Min                -3.49895
Policy log std Mean          -0.4461278
Policy log std Std           0.309995
Policy log std Max           0.016562998
Policy log std Min           -1.7955793
Z mean eval                  0.008979342
Z variance eval              0.00090930436
total_rewards                [390.79937064 388.33469363 363.29192037 314.31594985 376.40772244
 382.43017235 379.59792721 383.83741095 357.65297513 337.44662211]
total_rewards_mean           367.41147646725585
total_rewards_std            23.53468868916618
total_rewards_max            390.7993706390932
total_rewards_min            314.3159498528787
Number of train steps total  36000
Number of env steps total    182000
Number of rollouts total     0
Train Time (s)               30.871914794202894
(Previous) Eval Time (s)     4.259186799172312
Sample Time (s)              17.58856489835307
Epoch Time (s)               52.719666491728276
Total Train Time (s)         1905.0024074614048
Epoch                        35
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:34:28.557995 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #35 | Epoch Duration: 52.29330658912659
2020-01-11 00:34:28.558255 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #35 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029964263
Z variance train             0.0012361059
KL Divergence                14.314242
KL Loss                      1.4314243
QF Loss                      641.86646
VF Loss                      207.13226
Policy Loss                  -479.62827
Q Predictions Mean           479.6767
Q Predictions Std            411.0401
Q Predictions Max            1096.494
Q Predictions Min            -6.404221
V Predictions Mean           474.47363
V Predictions Std            405.21463
V Predictions Max            1069.7542
V Predictions Min            -0.67681706
Log Pis Mean                 -0.117517665
Log Pis Std                  2.3384883
Log Pis Max                  9.951172
Log Pis Min                  -5.635852
Policy mu Mean               0.08653506
Policy mu Std                0.9073831
Policy mu Max                3.688937
Policy mu Min                -3.231535
Policy log std Mean          -0.45366713
Policy log std Std           0.30097392
Policy log std Max           0.063622564
Policy log std Min           -2.1565058
Z mean eval                  0.020007525
Z variance eval              0.0009673002
total_rewards                [401.19699937 340.33953622 409.84967596 406.01354288 480.85460359
 407.69393005 423.45379632 351.36598708 383.6607996  423.34063104]
total_rewards_mean           402.77695021010777
total_rewards_std            37.337158190547484
total_rewards_max            480.85460358802334
total_rewards_min            340.33953622395313
Number of train steps total  37000
Number of env steps total    187000
Number of rollouts total     0
Train Time (s)               31.207388519775122
(Previous) Eval Time (s)     3.832511610817164
Sample Time (s)              17.808892035856843
Epoch Time (s)               52.84879216644913
Total Train Time (s)         1958.303358425852
Epoch                        36
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:35:21.857923 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #36 | Epoch Duration: 53.29951333999634
2020-01-11 00:35:21.858096 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #36 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017121172
Z variance train             0.0006081685
KL Divergence                16.076267
KL Loss                      1.6076268
QF Loss                      1124.7457
VF Loss                      200.35693
Policy Loss                  -474.28107
Q Predictions Mean           470.62152
Q Predictions Std            412.7868
Q Predictions Max            1059.7347
Q Predictions Min            -7.943347
V Predictions Mean           469.79935
V Predictions Std            409.39758
V Predictions Max            1051.4642
V Predictions Min            -0.86224335
Log Pis Mean                 -0.5484702
Log Pis Std                  2.080963
Log Pis Max                  11.329817
Log Pis Min                  -4.793499
Policy mu Mean               0.011908243
Policy mu Std                0.8168767
Policy mu Max                2.6322987
Policy mu Min                -3.5442636
Policy log std Mean          -0.44588318
Policy log std Std           0.31711233
Policy log std Max           0.16566156
Policy log std Min           -1.6008172
Z mean eval                  0.007786234
Z variance eval              0.0008306196
total_rewards                [ 564.30470749  653.36045072 1054.61836003  650.87140617  633.41647028
  395.21083768  517.14865557  412.02040222  401.12689183  355.73651915]
total_rewards_mean           563.7814701154392
total_rewards_std            196.14803668483768
total_rewards_max            1054.6183600294182
total_rewards_min            355.7365191493991
Number of train steps total  38000
Number of env steps total    192000
Number of rollouts total     0
Train Time (s)               30.90919113298878
(Previous) Eval Time (s)     4.282910958863795
Sample Time (s)              18.436517019290477
Epoch Time (s)               53.62861911114305
Total Train Time (s)         2014.8635015101172
Epoch                        37
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:36:18.419911 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #37 | Epoch Duration: 56.56166958808899
2020-01-11 00:36:18.420111 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #37 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0075560203
Z variance train             0.00086189306
KL Divergence                15.234495
KL Loss                      1.5234495
QF Loss                      964.2453
VF Loss                      106.9009
Policy Loss                  -453.74847
Q Predictions Mean           452.7658
Q Predictions Std            410.25003
Q Predictions Max            1056.5842
Q Predictions Min            -7.004784
V Predictions Mean           454.98224
V Predictions Std            412.41254
V Predictions Max            1055.306
V Predictions Min            -0.78340864
Log Pis Mean                 -0.4653784
Log Pis Std                  2.0328126
Log Pis Max                  5.790124
Log Pis Min                  -5.7127986
Policy mu Mean               -0.0040944167
Policy mu Std                0.77909476
Policy mu Max                2.472923
Policy mu Min                -2.2655997
Policy log std Mean          -0.43484864
Policy log std Std           0.31429806
Policy log std Max           0.10429676
Policy log std Min           -2.0083482
Z mean eval                  0.020848796
Z variance eval              0.00066763035
total_rewards                [535.57006911 414.55379852 499.42033372 414.35594904 655.5557805
 421.90432588 419.11385817 417.61133081 422.36402331 417.90602196]
total_rewards_mean           461.8355491022188
total_rewards_std            75.98028134948346
total_rewards_max            655.5557804992662
total_rewards_min            414.355949040707
Number of train steps total  39000
Number of env steps total    197000
Number of rollouts total     0
Train Time (s)               31.077694503124803
(Previous) Eval Time (s)     7.215649134013802
Sample Time (s)              21.754135325551033
Epoch Time (s)               60.04747896268964
Total Train Time (s)         2072.745675492566
Epoch                        38
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:37:16.305444 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #38 | Epoch Duration: 57.88518810272217
2020-01-11 00:37:16.305636 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #38 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020610657
Z variance train             0.0006733915
KL Divergence                15.842235
KL Loss                      1.5842235
QF Loss                      1425.5134
VF Loss                      160.53195
Policy Loss                  -495.13776
Q Predictions Mean           491.81583
Q Predictions Std            414.222
Q Predictions Max            1062.3888
Q Predictions Min            -8.099921
V Predictions Mean           494.2477
V Predictions Std            416.52313
V Predictions Max            1059.8345
V Predictions Min            -5.3694835
Log Pis Mean                 -0.57324165
Log Pis Std                  2.056398
Log Pis Max                  10.087476
Log Pis Min                  -5.0865293
Policy mu Mean               -0.017907029
Policy mu Std                0.7702984
Policy mu Max                2.6786902
Policy mu Min                -2.7915816
Policy log std Mean          -0.43336746
Policy log std Std           0.2915368
Policy log std Max           0.15718539
Policy log std Min           -2.2248154
Z mean eval                  0.02179817
Z variance eval              0.0006813138
total_rewards                [843.39061139 613.29343393 415.4787592  712.42776912 525.40095502
 713.66253454 774.36432175 420.24477904 408.44984509 438.48998491]
total_rewards_mean           586.5202993992315
total_rewards_std            157.56356356795507
total_rewards_max            843.3906113912093
total_rewards_min            408.44984509418373
Number of train steps total  40000
Number of env steps total    202000
Number of rollouts total     0
Train Time (s)               31.537933100946248
(Previous) Eval Time (s)     5.053042381070554
Sample Time (s)              19.421061523724347
Epoch Time (s)               56.01203700574115
Total Train Time (s)         2133.399352164939
Epoch                        39
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:38:16.958556 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #39 | Epoch Duration: 60.652743339538574
2020-01-11 00:38:16.958917 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #39 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021872466
Z variance train             0.00066442916
KL Divergence                15.898125
KL Loss                      1.5898125
QF Loss                      323.1114
VF Loss                      110.516685
Policy Loss                  -468.1059
Q Predictions Mean           468.68286
Q Predictions Std            411.92856
Q Predictions Max            1234.6155
Q Predictions Min            -0.83733016
V Predictions Mean           471.5882
V Predictions Std            411.42987
V Predictions Max            1286.0983
V Predictions Min            -5.0889735
Log Pis Mean                 -0.49027914
Log Pis Std                  2.2796288
Log Pis Max                  10.884975
Log Pis Min                  -4.459349
Policy mu Mean               0.01112398
Policy mu Std                0.8158896
Policy mu Max                3.0041153
Policy mu Min                -3.0258389
Policy log std Mean          -0.42656478
Policy log std Std           0.2873702
Policy log std Max           0.17487758
Policy log std Min           -2.5704658
Z mean eval                  0.01758308
Z variance eval              0.00066005206
total_rewards                [470.00641547 776.49141052 570.14110216 413.29288806 585.56722622
 622.65172514 411.01809512 569.67478476 571.55472746 621.55691875]
total_rewards_mean           561.1955293680086
total_rewards_std            103.61939922653295
total_rewards_max            776.4914105201648
total_rewards_min            411.0180951240786
Number of train steps total  41000
Number of env steps total    207000
Number of rollouts total     0
Train Time (s)               30.719848528970033
(Previous) Eval Time (s)     9.693436589092016
Sample Time (s)              21.99465480586514
Epoch Time (s)               62.40793992392719
Total Train Time (s)         2191.3512603654526
Epoch                        40
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:39:14.913270 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #40 | Epoch Duration: 57.95413088798523
2020-01-11 00:39:14.913521 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #40 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018203741
Z variance train             0.0006466334
KL Divergence                15.985527
KL Loss                      1.5985527
QF Loss                      3241.0405
VF Loss                      132.72
Policy Loss                  -528.8356
Q Predictions Mean           527.2318
Q Predictions Std            396.6688
Q Predictions Max            1165.5415
Q Predictions Min            -1.0638237
V Predictions Mean           534.54535
V Predictions Std            397.65018
V Predictions Max            1194.7821
V Predictions Min            -4.619233
Log Pis Mean                 -0.2525292
Log Pis Std                  2.1947477
Log Pis Max                  8.757261
Log Pis Min                  -6.8027697
Policy mu Mean               -0.117398314
Policy mu Std                0.88014066
Policy mu Max                3.047647
Policy mu Min                -3.2479868
Policy log std Mean          -0.45345142
Policy log std Std           0.29834956
Policy log std Max           0.25619477
Policy log std Min           -1.4831046
Z mean eval                  0.018949335
Z variance eval              0.000684743
total_rewards                [ 660.68620319  626.55138262  671.25562949  615.27433683 1092.78802415
  676.01894419  659.71533925 1086.20783201 1076.8561033   698.3014795 ]
total_rewards_mean           786.3655274538702
total_rewards_std            196.98100960441434
total_rewards_max            1092.7880241511536
total_rewards_min            615.2743368328912
Number of train steps total  42000
Number of env steps total    212000
Number of rollouts total     0
Train Time (s)               31.30603581527248
(Previous) Eval Time (s)     5.239308009855449
Sample Time (s)              21.566738773602992
Epoch Time (s)               58.11208259873092
Total Train Time (s)         2256.9853255809285
Epoch                        41
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:40:20.548635 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #41 | Epoch Duration: 65.63492178916931
2020-01-11 00:40:20.548874 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #41 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019158658
Z variance train             0.00067935826
KL Divergence                15.9186
KL Loss                      1.59186
QF Loss                      623.31995
VF Loss                      117.309296
Policy Loss                  -484.2644
Q Predictions Mean           482.95874
Q Predictions Std            411.17657
Q Predictions Max            1049.473
Q Predictions Min            -6.303493
V Predictions Mean           486.0427
V Predictions Std            411.0929
V Predictions Max            1040.2462
V Predictions Min            -2.926685
Log Pis Mean                 -0.41600257
Log Pis Std                  2.1641994
Log Pis Max                  10.733356
Log Pis Min                  -5.236029
Policy mu Mean               -0.031235255
Policy mu Std                0.8462809
Policy mu Max                2.7721674
Policy mu Min                -2.8721342
Policy log std Mean          -0.43709424
Policy log std Std           0.30152828
Policy log std Max           0.060325623
Policy log std Min           -2.1021278
Z mean eval                  0.017079968
Z variance eval              0.0007377393
total_rewards                [1054.33445903 1052.8752632  1051.23145683 1055.05017216 1051.1728552
 1054.91453856 1050.11700652 1047.93866835 1048.83112699 1058.2891832 ]
total_rewards_mean           1052.4754730043787
total_rewards_std            3.0440698407784037
total_rewards_max            1058.2891832043927
total_rewards_min            1047.9386683484015
Number of train steps total  43000
Number of env steps total    217000
Number of rollouts total     0
Train Time (s)               31.295208150986582
(Previous) Eval Time (s)     12.76176326815039
Sample Time (s)              22.374186872970313
Epoch Time (s)               66.43115829210728
Total Train Time (s)         2341.1746093872935
Epoch                        42
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:41:44.738408 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #42 | Epoch Duration: 84.18936824798584
2020-01-11 00:41:44.738588 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #42 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016680008
Z variance train             0.0007373608
KL Divergence                15.748104
KL Loss                      1.5748104
QF Loss                      242.34439
VF Loss                      182.83475
Policy Loss                  -485.6198
Q Predictions Mean           481.70593
Q Predictions Std            418.10025
Q Predictions Max            1215.1146
Q Predictions Min            -1.9283656
V Predictions Mean           479.20035
V Predictions Std            412.0178
V Predictions Max            1110.9779
V Predictions Min            -0.6758576
Log Pis Mean                 -0.2430895
Log Pis Std                  2.108046
Log Pis Max                  8.054844
Log Pis Min                  -3.7438548
Policy mu Mean               -0.0072797164
Policy mu Std                0.86089426
Policy mu Max                2.7516472
Policy mu Min                -2.9370792
Policy log std Mean          -0.4375131
Policy log std Std           0.29798275
Policy log std Max           0.27783918
Policy log std Min           -1.6102867
Z mean eval                  0.019031167
Z variance eval              0.00075017323
total_rewards                [1074.82963779 1075.06801428  913.3949596  1067.55422886 1070.16636029
 1058.16714547 1074.10204995  688.13912913 1066.30910335 1078.50964286]
total_rewards_mean           1016.6240271597329
total_rewards_std            119.22701801662213
total_rewards_max            1078.5096428623133
total_rewards_min            688.1391291342089
Number of train steps total  44000
Number of env steps total    222000
Number of rollouts total     0
Train Time (s)               32.92713957140222
(Previous) Eval Time (s)     30.519660626072437
Sample Time (s)              24.032133617904037
Epoch Time (s)               87.4789338153787
Total Train Time (s)         2425.7082920060493
Epoch                        43
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:43:09.274474 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #43 | Epoch Duration: 84.5357449054718
2020-01-11 00:43:09.274708 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #43 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019179525
Z variance train             0.0007500694
KL Divergence                15.75379
KL Loss                      1.575379
QF Loss                      332.28223
VF Loss                      152.20834
Policy Loss                  -541.8977
Q Predictions Mean           538.0144
Q Predictions Std            395.9982
Q Predictions Max            1016.6448
Q Predictions Min            -12.593231
V Predictions Mean           546.4218
V Predictions Std            393.4602
V Predictions Max            1010.9325
V Predictions Min            -5.5291924
Log Pis Mean                 -0.22432706
Log Pis Std                  2.1876755
Log Pis Max                  14.870672
Log Pis Min                  -3.7674565
Policy mu Mean               -0.029364645
Policy mu Std                0.877241
Policy mu Max                2.665508
Policy mu Min                -3.7733722
Policy log std Mean          -0.45900163
Policy log std Std           0.29182893
Policy log std Max           0.13694386
Policy log std Min           -1.694942
Z mean eval                  0.0078042373
Z variance eval              0.00095414306
total_rewards                [645.04365375 586.88154676 704.44750447 647.5892187  949.53832423
 596.64436558 644.22877983 786.32716622 550.43223234 697.04635305]
total_rewards_mean           680.8179144940412
total_rewards_std            109.90766256771127
total_rewards_max            949.5383242323137
total_rewards_min            550.4322323405836
Number of train steps total  45000
Number of env steps total    227000
Number of rollouts total     0
Train Time (s)               33.801489882636815
(Previous) Eval Time (s)     27.576133941765875
Sample Time (s)              24.786661015357822
Epoch Time (s)               86.16428483976051
Total Train Time (s)         2494.4098094897345
Epoch                        44
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:44:17.977906 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #44 | Epoch Duration: 68.70304012298584
2020-01-11 00:44:17.978157 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #44 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0073753423
Z variance train             0.0009522155
KL Divergence                15.46591
KL Loss                      1.546591
QF Loss                      267.87628
VF Loss                      68.755035
Policy Loss                  -575.6378
Q Predictions Mean           573.1882
Q Predictions Std            392.95847
Q Predictions Max            1185.2496
Q Predictions Min            -1.4287397
V Predictions Mean           574.2631
V Predictions Std            392.01904
V Predictions Max            1200.8546
V Predictions Min            -2.5196507
Log Pis Mean                 -0.010231668
Log Pis Std                  2.2763343
Log Pis Max                  7.909764
Log Pis Min                  -5.4604015
Policy mu Mean               0.09048071
Policy mu Std                0.8824534
Policy mu Max                3.053651
Policy mu Min                -2.7378118
Policy log std Mean          -0.46679756
Policy log std Std           0.2824738
Policy log std Max           0.25043386
Policy log std Min           -1.4571798
Z mean eval                  0.008174429
Z variance eval              0.00091927825
total_rewards                [ 996.15973468 1093.03802594  511.8757438  1200.83760637  859.61204713
 1103.86313684  715.30971189  660.21954443  762.13410018  660.23442467]
total_rewards_mean           856.3284075925136
total_rewards_std            219.0600534100779
total_rewards_max            1200.837606366654
total_rewards_min            511.87574380070663
Number of train steps total  46000
Number of env steps total    232000
Number of rollouts total     0
Train Time (s)               34.11998029705137
(Previous) Eval Time (s)     10.114527266006917
Sample Time (s)              23.87363829324022
Epoch Time (s)               68.1081458562985
Total Train Time (s)         2567.655966144521
Epoch                        45
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:45:31.232063 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #45 | Epoch Duration: 73.253746509552
2020-01-11 00:45:31.232255 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #45 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008301256
Z variance train             0.0009158294
KL Divergence                15.281789
KL Loss                      1.5281789
QF Loss                      552.4818
VF Loss                      425.96454
Policy Loss                  -579.8713
Q Predictions Mean           570.13934
Q Predictions Std            387.0546
Q Predictions Max            1147.84
Q Predictions Min            -2.32923
V Predictions Mean           578.5204
V Predictions Std            387.77664
V Predictions Max            1180.6787
V Predictions Min            -3.2872303
Log Pis Mean                 0.1930779
Log Pis Std                  2.574314
Log Pis Max                  11.5966015
Log Pis Min                  -5.455398
Policy mu Mean               -0.04128931
Policy mu Std                0.9902593
Policy mu Max                2.9325473
Policy mu Min                -3.3533397
Policy log std Mean          -0.4717238
Policy log std Std           0.30777153
Policy log std Max           0.2965299
Policy log std Min           -1.6283073
Z mean eval                  0.0069436273
Z variance eval              0.0011693143
total_rewards                [1310.98814645 1032.19998098 1128.35741372 1328.56683541 1091.10101406
 1117.62065712  831.52224428 1253.89426432 1635.79111759 1218.03901127]
total_rewards_mean           1194.8080685197042
total_rewards_std            202.3444692594237
total_rewards_max            1635.7911175869267
total_rewards_min            831.5222442844729
Number of train steps total  47000
Number of env steps total    237000
Number of rollouts total     0
Train Time (s)               32.72781116422266
(Previous) Eval Time (s)     15.259648301638663
Sample Time (s)              23.967951292637736
Epoch Time (s)               71.95541075849906
Total Train Time (s)         2642.7857887758873
Epoch                        46
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:46:46.356776 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #46 | Epoch Duration: 75.12437844276428
2020-01-11 00:46:46.356967 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #46 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.007941226
Z variance train             0.0011719877
KL Divergence                14.735023
KL Loss                      1.4735023
QF Loss                      947.97314
VF Loss                      128.91722
Policy Loss                  -613.21234
Q Predictions Mean           613.4119
Q Predictions Std            404.87003
Q Predictions Max            1213.9735
Q Predictions Min            -4.429108
V Predictions Mean           619.4674
V Predictions Std            406.2687
V Predictions Max            1193.6292
V Predictions Min            -4.4499235
Log Pis Mean                 0.25282156
Log Pis Std                  2.4550974
Log Pis Max                  9.909151
Log Pis Min                  -4.8970695
Policy mu Mean               0.060189266
Policy mu Std                1.0104872
Policy mu Max                2.4632356
Policy mu Min                -2.8978374
Policy log std Mean          -0.5050967
Policy log std Std           0.31053454
Policy log std Max           0.022112176
Policy log std Min           -2.0864747
Z mean eval                  0.005602873
Z variance eval              0.001209155
total_rewards                [ 580.31357605 1153.98010152 1555.71463485  292.72457667 1623.39220122
  961.51826331 1581.05094549  678.19131078 1284.05120109 1379.85793752]
total_rewards_mean           1109.0794748503229
total_rewards_std            441.1550044432718
total_rewards_max            1623.3922012217843
total_rewards_min            292.72457667420116
Number of train steps total  48000
Number of env steps total    242000
Number of rollouts total     0
Train Time (s)               33.301151604857296
(Previous) Eval Time (s)     18.428226646967232
Sample Time (s)              24.991101620718837
Epoch Time (s)               76.72047987254336
Total Train Time (s)         2718.7449759445153
Epoch                        47
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:48:02.319258 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #47 | Epoch Duration: 75.96210145950317
2020-01-11 00:48:02.319607 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #47 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.006282703
Z variance train             0.0012061064
KL Divergence                14.788509
KL Loss                      1.478851
QF Loss                      5816.2354
VF Loss                      108.34141
Policy Loss                  -584.6928
Q Predictions Mean           586.3573
Q Predictions Std            416.3191
Q Predictions Max            1303.1548
Q Predictions Min            -7.0387964
V Predictions Mean           584.79785
V Predictions Std            412.7734
V Predictions Max            1271.1204
V Predictions Min            -0.3827562
Log Pis Mean                 0.28346968
Log Pis Std                  2.5638516
Log Pis Max                  10.916031
Log Pis Min                  -4.2849827
Policy mu Mean               -0.1604052
Policy mu Std                1.0147368
Policy mu Max                2.7928748
Policy mu Min                -3.716891
Policy log std Mean          -0.47765175
Policy log std Std           0.301177
Policy log std Max           0.17214274
Policy log std Min           -1.7009182
Z mean eval                  0.0055786027
Z variance eval              0.0014024947
total_rewards                [ 735.48810309 1106.69341787  833.66605504  693.41853936  761.60789308
  517.6872695   810.82544254  625.8120457  1118.20507229 1107.31201098]
total_rewards_mean           831.0715849450435
total_rewards_std            202.0864715758059
total_rewards_max            1118.20507228694
total_rewards_min            517.6872694985158
Number of train steps total  49000
Number of env steps total    247000
Number of rollouts total     0
Train Time (s)               32.598390767816454
(Previous) Eval Time (s)     17.669457965996116
Sample Time (s)              24.691927782725543
Epoch Time (s)               74.95977651653811
Total Train Time (s)         2787.7608395460993
Epoch                        48
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:49:11.337332 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #48 | Epoch Duration: 69.01746416091919
2020-01-11 00:49:11.337606 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #48 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.005394737
Z variance train             0.001402125
KL Divergence                14.333792
KL Loss                      1.4333792
QF Loss                      276.29785
VF Loss                      143.21072
Policy Loss                  -638.7753
Q Predictions Mean           632.7413
Q Predictions Std            432.81982
Q Predictions Max            1325.95
Q Predictions Min            -4.162385
V Predictions Mean           640.4403
V Predictions Std            434.44534
V Predictions Max            1348.7319
V Predictions Min            -5.3792424
Log Pis Mean                 0.47173536
Log Pis Std                  2.642879
Log Pis Max                  8.5369005
Log Pis Min                  -5.814853
Policy mu Mean               -0.096892975
Policy mu Std                1.0832471
Policy mu Max                3.4365265
Policy mu Min                -2.82996
Policy log std Mean          -0.48599792
Policy log std Std           0.31187856
Policy log std Max           0.074042544
Policy log std Min           -1.5003042
Z mean eval                  0.0119470535
Z variance eval              0.001322934
total_rewards                [391.62338484 391.50720967 351.09360195 375.92286555 462.83505004
 557.25628267 430.51835859 395.11148966 454.34522557 660.94599154]
total_rewards_mean           447.11594600803016
total_rewards_std            90.32938580660627
total_rewards_max            660.945991540686
total_rewards_min            351.09360194739065
Number of train steps total  50000
Number of env steps total    252000
Number of rollouts total     0
Train Time (s)               33.18805130710825
(Previous) Eval Time (s)     11.726714645978063
Sample Time (s)              23.2647539624013
Epoch Time (s)               68.17951991548762
Total Train Time (s)         2852.3666979600675
Epoch                        49
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:50:15.945462 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #49 | Epoch Duration: 64.60751056671143
2020-01-11 00:50:15.945921 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #49 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012904605
Z variance train             0.0013254599
KL Divergence                14.498644
KL Loss                      1.4498644
QF Loss                      545.1288
VF Loss                      196.80708
Policy Loss                  -645.65564
Q Predictions Mean           639.5864
Q Predictions Std            449.34573
Q Predictions Max            1478.3423
Q Predictions Min            -6.9395013
V Predictions Mean           641.95166
V Predictions Std            444.974
V Predictions Max            1465.4551
V Predictions Min            -2.543223
Log Pis Mean                 0.49532342
Log Pis Std                  2.67569
Log Pis Max                  9.79902
Log Pis Min                  -6.5837326
Policy mu Mean               0.030898482
Policy mu Std                1.0957218
Policy mu Max                3.047399
Policy mu Min                -3.4774177
Policy log std Mean          -0.49561754
Policy log std Std           0.29420212
Policy log std Max           0.25143173
Policy log std Min           -1.6433544
Z mean eval                  0.013208436
Z variance eval              0.0012859309
total_rewards                [318.79312377 317.28542801 351.61487082 320.3093022  314.59228275
 300.09209434 321.68331285 350.3133796  272.86412186 324.54883815]
total_rewards_mean           319.2096754342229
total_rewards_std            21.428860498646348
total_rewards_max            351.6148708215449
total_rewards_min            272.8641218575868
Number of train steps total  51000
Number of env steps total    257000
Number of rollouts total     0
Train Time (s)               33.83064079191536
(Previous) Eval Time (s)     8.154267358127981
Sample Time (s)              23.498113424051553
Epoch Time (s)               65.48302157409489
Total Train Time (s)         2914.5417062356137
Epoch                        50
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:51:18.121245 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #50 | Epoch Duration: 62.175065994262695
2020-01-11 00:51:18.121450 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #50 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0132830115
Z variance train             0.0012857384
KL Divergence                14.4138155
KL Loss                      1.4413816
QF Loss                      1751.9941
VF Loss                      223.28635
Policy Loss                  -648.7714
Q Predictions Mean           640.9083
Q Predictions Std            475.3338
Q Predictions Max            1611.3523
Q Predictions Min            -6.811528
V Predictions Mean           648.7905
V Predictions Std            478.04095
V Predictions Max            1591.861
V Predictions Min            -6.345121
Log Pis Mean                 0.5379626
Log Pis Std                  2.384349
Log Pis Max                  6.3802614
Log Pis Min                  -4.538206
Policy mu Mean               0.16607715
Policy mu Std                1.0668693
Policy mu Max                3.1375542
Policy mu Min                -2.7205148
Policy log std Mean          -0.5249744
Policy log std Std           0.31355926
Policy log std Max           -0.05270475
Policy log std Min           -1.835839
Z mean eval                  0.0060366825
Z variance eval              0.0011030554
total_rewards                [291.20396181 307.61285352 293.39690871 278.47620891 294.53536989
 296.7779132  304.79750308 435.9076425  272.99948262 322.84988784]
total_rewards_mean           309.8557732063801
total_rewards_std            44.10910363476431
total_rewards_max            435.907642502588
total_rewards_min            272.9994826156554
Number of train steps total  52000
Number of env steps total    262000
Number of rollouts total     0
Train Time (s)               34.37928920472041
(Previous) Eval Time (s)     4.84591996204108
Sample Time (s)              19.43523713806644
Epoch Time (s)               58.66044630482793
Total Train Time (s)         2972.8144738203846
Epoch                        51
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:52:16.401582 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #51 | Epoch Duration: 58.27991271018982
2020-01-11 00:52:16.402101 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #51 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0066265045
Z variance train             0.0011258225
KL Divergence                14.605666
KL Loss                      1.4605666
QF Loss                      1805.7914
VF Loss                      181.16667
Policy Loss                  -661.84216
Q Predictions Mean           665.8543
Q Predictions Std            466.6607
Q Predictions Max            1412.9454
Q Predictions Min            -0.44355023
V Predictions Mean           655.17334
V Predictions Std            460.11954
V Predictions Max            1390.5885
V Predictions Min            -1.3376765
Log Pis Mean                 0.8076565
Log Pis Std                  2.6567628
Log Pis Max                  9.812515
Log Pis Min                  -4.2483068
Policy mu Mean               0.1768055
Policy mu Std                1.0767741
Policy mu Max                2.6586916
Policy mu Min                -3.1082494
Policy log std Mean          -0.56149274
Policy log std Std           0.32043388
Policy log std Max           -0.077040836
Policy log std Min           -1.8337822
Z mean eval                  0.013157794
Z variance eval              0.0010150315
total_rewards                [593.41418518 656.91146394 572.69258633 448.41094714 699.09083144
 585.157675   458.29474793 459.20240334 504.61654547 503.13768855]
total_rewards_mean           548.0929074318894
total_rewards_std            82.75729625424579
total_rewards_max            699.090831436869
total_rewards_min            448.41094714436144
Number of train steps total  53000
Number of env steps total    267000
Number of rollouts total     0
Train Time (s)               32.818832895252854
(Previous) Eval Time (s)     4.465014923829585
Sample Time (s)              18.67249727481976
Epoch Time (s)               55.9563450939022
Total Train Time (s)         3030.2132916981354
Epoch                        52
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:53:13.795455 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #52 | Epoch Duration: 57.39301538467407
2020-01-11 00:53:13.795648 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #52 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1276865
Z variance train             0.0004786143
KL Divergence                16.791937
KL Loss                      1.6791937
QF Loss                      480.37363
VF Loss                      284.3929
Policy Loss                  -669.827
Q Predictions Mean           659.57074
Q Predictions Std            490.9723
Q Predictions Max            1376.0245
Q Predictions Min            -3.2806551
V Predictions Mean           661.5211
V Predictions Std            485.32953
V Predictions Max            1375.9788
V Predictions Min            -1.1344771
Log Pis Mean                 0.54245156
Log Pis Std                  2.4828062
Log Pis Max                  9.578029
Log Pis Min                  -3.8570852
Policy mu Mean               0.14885168
Policy mu Std                1.0584339
Policy mu Max                2.3618767
Policy mu Min                -3.5092347
Policy log std Mean          -0.5616519
Policy log std Std           0.3214532
Policy log std Max           -0.06280181
Policy log std Min           -2.0784798
Z mean eval                  0.016386785
Z variance eval              0.001259702
total_rewards                [660.61537384 504.00046391 363.70537812 380.49937549 715.50257336
 361.80281444 511.6830289  489.6228843  426.61024931 384.41316166]
total_rewards_mean           479.8455303345562
total_rewards_std            117.95688635365326
total_rewards_max            715.5025733643446
total_rewards_min            361.8028144404594
Number of train steps total  54000
Number of env steps total    272000
Number of rollouts total     0
Train Time (s)               33.18364604283124
(Previous) Eval Time (s)     5.901396485976875
Sample Time (s)              20.50651355087757
Epoch Time (s)               59.59155607968569
Total Train Time (s)         3089.4101512669586
Epoch                        53
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:54:12.993722 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #53 | Epoch Duration: 59.19793128967285
2020-01-11 00:54:12.993903 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #53 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07126595
Z variance train             0.0010168867
KL Divergence                15.156977
KL Loss                      1.5156977
QF Loss                      424.6672
VF Loss                      189.93784
Policy Loss                  -654.21216
Q Predictions Mean           650.92487
Q Predictions Std            497.1149
Q Predictions Max            1423.8806
Q Predictions Min            -4.95456
V Predictions Mean           649.88776
V Predictions Std            493.21542
V Predictions Max            1425.8726
V Predictions Min            -2.4624543
Log Pis Mean                 0.24259791
Log Pis Std                  2.4275596
Log Pis Max                  10.665002
Log Pis Min                  -8.202391
Policy mu Mean               0.2519474
Policy mu Std                0.96048546
Policy mu Max                3.038214
Policy mu Min                -3.1175933
Policy log std Mean          -0.5099802
Policy log std Std           0.3269542
Policy log std Max           0.1835213
Policy log std Min           -2.6549017
Z mean eval                  0.1409862
Z variance eval              0.00067488453
total_rewards                [469.5452364  366.24507826 447.61912834 477.74687874 523.64530147
 485.73890238 527.59507793 496.90858629 476.85744636 457.71563558]
total_rewards_mean           472.96172717356575
total_rewards_std            43.131446161648725
total_rewards_max            527.5950779335527
total_rewards_min            366.24507825714556
Number of train steps total  55000
Number of env steps total    277000
Number of rollouts total     0
Train Time (s)               33.47103785723448
(Previous) Eval Time (s)     5.507436879910529
Sample Time (s)              22.52935842005536
Epoch Time (s)               61.507833157200366
Total Train Time (s)         3151.0380693543702
Epoch                        54
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:55:14.625540 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #54 | Epoch Duration: 61.631460189819336
2020-01-11 00:55:14.625875 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #54 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04286558
Z variance train             0.0010204457
KL Divergence                15.035196
KL Loss                      1.5035197
QF Loss                      729.645
VF Loss                      225.7493
Policy Loss                  -705.087
Q Predictions Mean           704.38245
Q Predictions Std            479.7529
Q Predictions Max            1355.7588
Q Predictions Min            -6.881857
V Predictions Mean           713.5945
V Predictions Std            484.17838
V Predictions Max            1369.0981
V Predictions Min            -5.9819636
Log Pis Mean                 0.4419515
Log Pis Std                  2.4332654
Log Pis Max                  7.8446317
Log Pis Min                  -3.5479252
Policy mu Mean               -0.09107516
Policy mu Std                1.0652219
Policy mu Max                2.669562
Policy mu Min                -3.3137586
Policy log std Mean          -0.50889224
Policy log std Std           0.30510864
Policy log std Max           -0.031163603
Policy log std Min           -1.5492303
Z mean eval                  0.020236496
Z variance eval              0.0010760453
total_rewards                [679.50706077 686.78089241 502.20459552 638.20037763 718.58623234
 763.65045206 657.80831914 800.21992654 505.18960184 497.58267756]
total_rewards_mean           644.9730135799939
total_rewards_std            104.11632519647137
total_rewards_max            800.2199265393165
total_rewards_min            497.5826775571885
Number of train steps total  56000
Number of env steps total    282000
Number of rollouts total     0
Train Time (s)               31.39984830794856
(Previous) Eval Time (s)     5.630359496921301
Sample Time (s)              22.10134366294369
Epoch Time (s)               59.13155146781355
Total Train Time (s)         3211.227071161382
Epoch                        55
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:56:14.815670 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #55 | Epoch Duration: 60.1895854473114
2020-01-11 00:56:14.815906 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #55 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0148523105
Z variance train             0.0010121533
KL Divergence                14.944286
KL Loss                      1.4944286
QF Loss                      296.6045
VF Loss                      76.971794
Policy Loss                  -672.623
Q Predictions Mean           669.0842
Q Predictions Std            485.0215
Q Predictions Max            1431.5719
Q Predictions Min            -2.583983
V Predictions Mean           672.5532
V Predictions Std            484.68567
V Predictions Max            1418.733
V Predictions Min            -5.2903886
Log Pis Mean                 0.3695451
Log Pis Std                  2.7224383
Log Pis Max                  17.155062
Log Pis Min                  -5.6903095
Policy mu Mean               0.008962276
Policy mu Std                1.07047
Policy mu Max                2.9923506
Policy mu Min                -4.203392
Policy log std Mean          -0.4677404
Policy log std Std           0.28586742
Policy log std Max           -0.00920555
Policy log std Min           -1.6902573
Z mean eval                  0.007909606
Z variance eval              0.0012720788
total_rewards                [435.45105208 780.89294386 421.45290605 723.52902873 723.14544782
 663.34583438 648.50452245 760.9684184  414.75268696 741.10566097]
total_rewards_mean           631.3148501689951
total_rewards_std            140.9962026803928
total_rewards_max            780.8929438566071
total_rewards_min            414.7526869553621
Number of train steps total  57000
Number of env steps total    287000
Number of rollouts total     0
Train Time (s)               31.16271449998021
(Previous) Eval Time (s)     6.688016295898706
Sample Time (s)              23.17025839071721
Epoch Time (s)               61.020989186596125
Total Train Time (s)         3272.2608599532396
Epoch                        56
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:57:15.851649 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #56 | Epoch Duration: 61.03556275367737
2020-01-11 00:57:15.851901 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #56 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0066080675
Z variance train             0.0012507694
KL Divergence                14.423075
KL Loss                      1.4423075
QF Loss                      438.5935
VF Loss                      189.257
Policy Loss                  -681.401
Q Predictions Mean           676.38605
Q Predictions Std            498.82266
Q Predictions Max            1416.183
Q Predictions Min            -1.9917153
V Predictions Mean           683.68823
V Predictions Std            500.54385
V Predictions Max            1430.9712
V Predictions Min            -3.4151459
Log Pis Mean                 0.54228616
Log Pis Std                  2.86828
Log Pis Max                  9.891985
Log Pis Min                  -5.294687
Policy mu Mean               -0.0076140915
Policy mu Std                1.1154399
Policy mu Max                2.6287086
Policy mu Min                -3.9637392
Policy log std Mean          -0.4764351
Policy log std Std           0.31648323
Policy log std Max           0.16076206
Policy log std Min           -3.1579227
Z mean eval                  0.018042907
Z variance eval              0.00080229586
total_rewards                [614.07984859 442.92788532 732.72423192 686.38969465 648.54174602
 878.21941881 732.61259642 442.6276061  652.57042237 436.13640362]
total_rewards_mean           626.6829853827574
total_rewards_std            139.4841998459565
total_rewards_max            878.2194188118642
total_rewards_min            436.1364036234581
Number of train steps total  58000
Number of env steps total    292000
Number of rollouts total     0
Train Time (s)               31.081735833082348
(Previous) Eval Time (s)     6.702255124691874
Sample Time (s)              22.698567289859056
Epoch Time (s)               60.48255824763328
Total Train Time (s)         3332.210783584509
Epoch                        57
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:58:15.801769 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #57 | Epoch Duration: 59.949700355529785
2020-01-11 00:58:15.801952 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #57 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021378515
Z variance train             0.0008604334
KL Divergence                15.326987
KL Loss                      1.5326988
QF Loss                      371.67554
VF Loss                      351.7643
Policy Loss                  -752.0422
Q Predictions Mean           746.744
Q Predictions Std            487.4466
Q Predictions Max            1396.6703
Q Predictions Min            -5.773396
V Predictions Mean           749.3158
V Predictions Std            484.67743
V Predictions Max            1377.5337
V Predictions Min            0.9760708
Log Pis Mean                 0.7722759
Log Pis Std                  2.771618
Log Pis Max                  10.373615
Log Pis Min                  -4.3057055
Policy mu Mean               0.061329428
Policy mu Std                1.0974007
Policy mu Max                2.9691856
Policy mu Min                -2.7985532
Policy log std Mean          -0.51926893
Policy log std Std           0.3171377
Policy log std Max           -0.027607322
Policy log std Min           -2.3021908
Z mean eval                  0.031505097
Z variance eval              0.0011870381
total_rewards                [454.06293839 550.11946803 437.32088559 697.18243685 493.76738756
 724.66251644 539.29537323 383.21431402 731.3943596  667.17533045]
total_rewards_mean           567.8195010166162
total_rewards_std            121.91101985977967
total_rewards_max            731.3943596009668
total_rewards_min            383.21431402390726
Number of train steps total  59000
Number of env steps total    297000
Number of rollouts total     0
Train Time (s)               31.481764622032642
(Previous) Eval Time (s)     6.169091887772083
Sample Time (s)              22.631619510706514
Epoch Time (s)               60.28247602051124
Total Train Time (s)         3392.015953788534
Epoch                        58
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:59:15.608961 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #58 | Epoch Duration: 59.806862592697144
2020-01-11 00:59:15.609139 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #58 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06421672
Z variance train             0.0007530224
KL Divergence                15.942972
KL Loss                      1.5942973
QF Loss                      377.9356
VF Loss                      258.76105
Policy Loss                  -751.81824
Q Predictions Mean           747.7313
Q Predictions Std            501.3705
Q Predictions Max            1453.651
Q Predictions Min            -15.332188
V Predictions Mean           760.06335
V Predictions Std            506.0627
V Predictions Max            1437.9054
V Predictions Min            -15.200192
Log Pis Mean                 0.8086957
Log Pis Std                  2.6529286
Log Pis Max                  8.904385
Log Pis Min                  -5.7753634
Policy mu Mean               0.26067734
Policy mu Std                1.0740137
Policy mu Max                3.0164099
Policy mu Min                -3.6079044
Policy log std Mean          -0.5255332
Policy log std Std           0.29860818
Policy log std Max           -0.06463641
Policy log std Min           -1.9814183
Z mean eval                  0.027769078
Z variance eval              0.0016517384
total_rewards                [ 950.33452046  937.94732959  566.39188211  851.83828331  810.56763261
  778.16128706  767.92416703  914.10800196 1061.1149288   466.36504466]
total_rewards_mean           810.4753077596588
total_rewards_std            170.85782460888973
total_rewards_max            1061.11492879951
total_rewards_min            466.3650446617518
Number of train steps total  60000
Number of env steps total    302000
Number of rollouts total     0
Train Time (s)               31.36582115571946
(Previous) Eval Time (s)     5.693167405202985
Sample Time (s)              20.76628078846261
Epoch Time (s)               57.82526934938505
Total Train Time (s)         3451.526709727943
Epoch                        59
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:00:15.120487 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #59 | Epoch Duration: 59.511213541030884
2020-01-11 01:00:15.120656 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #59 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02212281
Z variance train             0.0015556604
KL Divergence                13.894184
KL Loss                      1.3894185
QF Loss                      611.13806
VF Loss                      180.83426
Policy Loss                  -674.2611
Q Predictions Mean           670.40845
Q Predictions Std            504.92108
Q Predictions Max            1404.4917
Q Predictions Min            -1.3641644
V Predictions Mean           680.6055
V Predictions Std            510.5884
V Predictions Max            1401.9547
V Predictions Min            -3.9198847
Log Pis Mean                 0.14569211
Log Pis Std                  2.4161055
Log Pis Max                  7.5019436
Log Pis Min                  -5.56964
Policy mu Mean               0.062931456
Policy mu Std                0.9681023
Policy mu Max                2.5022619
Policy mu Min                -2.8600776
Policy log std Mean          -0.5280597
Policy log std Std           0.31950954
Policy log std Max           -0.06287205
Policy log std Min           -2.3251002
Z mean eval                  0.08285327
Z variance eval              0.0010647115
total_rewards                [1253.52426335  657.63538207  797.25881463  985.80231653 1004.10038672
  878.95558252  749.40003321  661.26637561  709.22896587  654.93975252]
total_rewards_mean           835.2111873021637
total_rewards_std            186.29650098120783
total_rewards_max            1253.5242633484118
total_rewards_min            654.9397525236384
Number of train steps total  61000
Number of env steps total    307000
Number of rollouts total     0
Train Time (s)               31.231100158765912
(Previous) Eval Time (s)     7.378777622710913
Sample Time (s)              23.24499191250652
Epoch Time (s)               61.854869693983346
Total Train Time (s)         3514.4721240792423
Epoch                        60
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:01:18.067844 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #60 | Epoch Duration: 62.94703555107117
2020-01-11 01:01:18.068029 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #60 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011694898
Z variance train             0.0016812154
KL Divergence                13.712099
KL Loss                      1.37121
QF Loss                      667.14197
VF Loss                      375.0576
Policy Loss                  -790.885
Q Predictions Mean           790.5891
Q Predictions Std            486.84058
Q Predictions Max            1414.5477
Q Predictions Min            -9.064528
V Predictions Mean           792.8632
V Predictions Std            484.60083
V Predictions Max            1412.042
V Predictions Min            -5.126882
Log Pis Mean                 0.36773175
Log Pis Std                  2.57514
Log Pis Max                  10.198542
Log Pis Min                  -5.0026627
Policy mu Mean               0.09008274
Policy mu Std                1.0207013
Policy mu Max                2.7796292
Policy mu Min                -3.0476563
Policy log std Mean          -0.5610225
Policy log std Std           0.30612394
Policy log std Max           -0.057932943
Policy log std Min           -1.6662318
Z mean eval                  0.020314928
Z variance eval              0.0018041827
total_rewards                [646.84803829 582.06909012 571.71685189 591.58602469 486.65407805
 473.7212713  423.66624893 557.87696721 762.91155784 483.24134119]
total_rewards_mean           558.029146951453
total_rewards_std            93.59795921966152
total_rewards_max            762.9115578445447
total_rewards_min            423.66624893004507
Number of train steps total  62000
Number of env steps total    312000
Number of rollouts total     0
Train Time (s)               31.493689644150436
(Previous) Eval Time (s)     8.470638540107757
Sample Time (s)              21.462174843531102
Epoch Time (s)               61.426503027789295
Total Train Time (s)         3572.9928049426526
Epoch                        61
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:02:16.590538 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #61 | Epoch Duration: 58.52234888076782
2020-01-11 01:02:16.590755 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #61 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022499418
Z variance train             0.0017833102
KL Divergence                13.641309
KL Loss                      1.3641309
QF Loss                      352.55225
VF Loss                      127.82372
Policy Loss                  -730.04865
Q Predictions Mean           729.4281
Q Predictions Std            519.75323
Q Predictions Max            1384.0275
Q Predictions Min            0.46840376
V Predictions Mean           731.3386
V Predictions Std            520.4699
V Predictions Max            1376.179
V Predictions Min            -5.4875693
Log Pis Mean                 0.25048006
Log Pis Std                  2.4994845
Log Pis Max                  7.157368
Log Pis Min                  -5.2465096
Policy mu Mean               -0.06617579
Policy mu Std                0.9900397
Policy mu Max                2.5575252
Policy mu Min                -2.9018793
Policy log std Mean          -0.4839824
Policy log std Std           0.2986476
Policy log std Max           0.025300324
Policy log std Min           -1.7874955
Z mean eval                  0.00857982
Z variance eval              0.0029986857
total_rewards                [524.72998563 923.82513717 654.05987368 605.07779474 656.80721144
 398.44049016 439.84735365 425.11363116 616.0441963  917.12671146]
total_rewards_mean           616.1072385392551
total_rewards_std            176.57754441263793
total_rewards_max            923.825137169239
total_rewards_min            398.4404901562977
Number of train steps total  63000
Number of env steps total    317000
Number of rollouts total     0
Train Time (s)               30.941952290013433
(Previous) Eval Time (s)     5.566187494900078
Sample Time (s)              21.24373529618606
Epoch Time (s)               57.75187508109957
Total Train Time (s)         3632.025810590945
Epoch                        62
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:03:15.624583 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #62 | Epoch Duration: 59.03367853164673
2020-01-11 01:03:15.624755 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #62 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.009281611
Z variance train             0.003185695
KL Divergence                12.027058
KL Loss                      1.2027057
QF Loss                      286.81186
VF Loss                      487.53668
Policy Loss                  -788.0916
Q Predictions Mean           784.1164
Q Predictions Std            477.4464
Q Predictions Max            1362.6965
Q Predictions Min            -3.4443202
V Predictions Mean           789.6776
V Predictions Std            476.95728
V Predictions Max            1358.4011
V Predictions Min            0.6655785
Log Pis Mean                 0.49855292
Log Pis Std                  2.5079625
Log Pis Max                  9.58994
Log Pis Min                  -5.724534
Policy mu Mean               -0.057365905
Policy mu Std                1.047396
Policy mu Max                3.025392
Policy mu Min                -2.7296438
Policy log std Mean          -0.527575
Policy log std Std           0.27934143
Policy log std Max           -0.087637976
Policy log std Min           -1.5525432
Z mean eval                  0.010754364
Z variance eval              0.00244996
total_rewards                [1208.84973794 1077.02060377  758.31297947 1036.50992113 1054.520992
 1066.96576639  805.15209483  704.21553164 1095.87406445 1011.35599826]
total_rewards_mean           981.8777689875387
total_rewards_std            157.5575226207541
total_rewards_max            1208.8497379402334
total_rewards_min            704.2155316383561
Number of train steps total  64000
Number of env steps total    322000
Number of rollouts total     0
Train Time (s)               32.018822450656444
(Previous) Eval Time (s)     6.847640388645232
Sample Time (s)              21.68060906464234
Epoch Time (s)               60.547071903944016
Total Train Time (s)         3695.564263682347
Epoch                        63
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:04:19.164567 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #63 | Epoch Duration: 63.539676666259766
2020-01-11 01:04:19.164731 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #63 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010669112
Z variance train             0.0026476898
KL Divergence                12.502518
KL Loss                      1.2502518
QF Loss                      363.98004
VF Loss                      166.1805
Policy Loss                  -758.2341
Q Predictions Mean           753.5973
Q Predictions Std            511.67157
Q Predictions Max            1466.68
Q Predictions Min            -11.006378
V Predictions Mean           752.56946
V Predictions Std            508.83813
V Predictions Max            1438.9419
V Predictions Min            -7.612322
Log Pis Mean                 0.27790082
Log Pis Std                  2.4819834
Log Pis Max                  7.969019
Log Pis Min                  -6.4028616
Policy mu Mean               0.039999295
Policy mu Std                1.030988
Policy mu Max                2.8776696
Policy mu Min                -3.8426816
Policy log std Mean          -0.4937675
Policy log std Std           0.2888306
Policy log std Max           0.12938601
Policy log std Min           -1.6174095
Z mean eval                  0.01274925
Z variance eval              0.0019846843
total_rewards                [992.8245172  772.90290406 892.82891711 558.29115089 691.33156065
 688.40055808 736.94088572 751.42697053 771.41505879 758.51704959]
total_rewards_mean           761.4879572638173
total_rewards_std            111.02303299139808
total_rewards_max            992.8245172041177
total_rewards_min            558.2911508944269
Number of train steps total  65000
Number of env steps total    327000
Number of rollouts total     0
Train Time (s)               31.109445872250944
(Previous) Eval Time (s)     9.83993616187945
Sample Time (s)              22.42264032550156
Epoch Time (s)               63.372022359631956
Total Train Time (s)         3756.5216640122235
Epoch                        64
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:05:20.123221 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #64 | Epoch Duration: 60.95832538604736
2020-01-11 01:05:20.123395 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #64 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019101772
Z variance train             0.0022646855
KL Divergence                12.866789
KL Loss                      1.2866789
QF Loss                      250.11778
VF Loss                      101.89681
Policy Loss                  -760.42346
Q Predictions Mean           757.59045
Q Predictions Std            502.99884
Q Predictions Max            1450.7306
Q Predictions Min            -8.148287
V Predictions Mean           763.76074
V Predictions Std            506.50778
V Predictions Max            1428.1176
V Predictions Min            -7.7807918
Log Pis Mean                 0.310915
Log Pis Std                  2.3448212
Log Pis Max                  10.8513155
Log Pis Min                  -4.331533
Policy mu Mean               -0.012735858
Policy mu Std                0.96478987
Policy mu Max                2.9788294
Policy mu Min                -3.595997
Policy log std Mean          -0.479926
Policy log std Std           0.26606455
Policy log std Max           -0.024235398
Policy log std Min           -1.892073
Z mean eval                  0.020636056
Z variance eval              0.0018704139
total_rewards                [ 777.70641028  713.96285828 1069.11247475 1097.68360266  748.74200421
  718.39529188  678.19071053  921.80396077  739.68207681  487.65943944]
total_rewards_mean           795.2938829606852
total_rewards_std            175.74705285932288
total_rewards_max            1097.6836026571455
total_rewards_min            487.6594394358865
Number of train steps total  66000
Number of env steps total    332000
Number of rollouts total     0
Train Time (s)               31.650733227841556
(Previous) Eval Time (s)     7.42591840820387
Sample Time (s)              23.518520957324654
Epoch Time (s)               62.59517259337008
Total Train Time (s)         3819.907425425481
Epoch                        65
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:06:23.510684 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #65 | Epoch Duration: 63.387146949768066
2020-01-11 01:06:23.510871 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #65 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008304285
Z variance train             0.0023049046
KL Divergence                12.840621
KL Loss                      1.2840621
QF Loss                      1668.5383
VF Loss                      189.12218
Policy Loss                  -778.6342
Q Predictions Mean           769.49426
Q Predictions Std            499.07126
Q Predictions Max            1449.6244
Q Predictions Min            -3.9259238
V Predictions Mean           774.60034
V Predictions Std            499.83353
V Predictions Max            1430.0084
V Predictions Min            -4.380612
Log Pis Mean                 0.078560546
Log Pis Std                  2.222578
Log Pis Max                  9.384537
Log Pis Min                  -4.359651
Policy mu Mean               0.07032568
Policy mu Std                0.9349534
Policy mu Max                3.3084471
Policy mu Min                -2.8348837
Policy log std Mean          -0.49113455
Policy log std Std           0.29109958
Policy log std Max           0.08830714
Policy log std Min           -2.0632534
Z mean eval                  0.05337767
Z variance eval              0.0012164356
total_rewards                [ 332.78996513  325.96166233  889.31844551  316.83509071  307.10505611
  315.3350863  1053.83780734  950.03916935  315.41625041 1157.85534987]
total_rewards_mean           596.4493883066306
total_rewards_std            346.0878374320564
total_rewards_max            1157.8553498671708
total_rewards_min            307.1050561136909
Number of train steps total  67000
Number of env steps total    337000
Number of rollouts total     0
Train Time (s)               31.384595174808055
(Previous) Eval Time (s)     8.217567430343479
Sample Time (s)              22.61632253602147
Epoch Time (s)               62.218485141173005
Total Train Time (s)         3880.4420325411484
Epoch                        66
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:07:24.051558 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #66 | Epoch Duration: 60.540539503097534
2020-01-11 01:07:24.051933 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #66 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09451671
Z variance train             0.0009227355
KL Divergence                15.299358
KL Loss                      1.5299358
QF Loss                      450.07898
VF Loss                      282.70825
Policy Loss                  -834.71686
Q Predictions Mean           837.6764
Q Predictions Std            506.93265
Q Predictions Max            1430.3066
Q Predictions Min            -5.239202
V Predictions Mean           828.2705
V Predictions Std            500.94745
V Predictions Max            1440.1556
V Predictions Min            -2.5690415
Log Pis Mean                 -0.0047813617
Log Pis Std                  2.2098413
Log Pis Max                  6.495639
Log Pis Min                  -5.3794928
Policy mu Mean               -0.11629158
Policy mu Std                0.97232085
Policy mu Max                2.4990995
Policy mu Min                -2.7223532
Policy log std Mean          -0.48173702
Policy log std Std           0.27164614
Policy log std Max           0.042959124
Policy log std Min           -1.7332486
Z mean eval                  0.032155506
Z variance eval              0.0011887092
total_rewards                [336.7611165  323.22406675 299.46565988 312.83438002 300.96855401
 310.04944526 298.56757561 315.54996935 294.38349538 306.90902807]
total_rewards_mean           309.8713290842909
total_rewards_std            12.273447111915644
total_rewards_max            336.76111649820587
total_rewards_min            294.3834953839776
Number of train steps total  68000
Number of env steps total    342000
Number of rollouts total     0
Train Time (s)               31.62238711118698
(Previous) Eval Time (s)     6.539289727807045
Sample Time (s)              19.86421667272225
Epoch Time (s)               58.025893511716276
Total Train Time (s)         3936.040702425409
Epoch                        67
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:08:19.648234 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #67 | Epoch Duration: 55.59601187705994
2020-01-11 01:08:19.648671 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #67 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033181917
Z variance train             0.0019084985
KL Divergence                13.606923
KL Loss                      1.3606924
QF Loss                      333.5932
VF Loss                      133.26894
Policy Loss                  -746.77234
Q Predictions Mean           743.4722
Q Predictions Std            498.7202
Q Predictions Max            1381.7119
Q Predictions Min            3.0030072
V Predictions Mean           742.3531
V Predictions Std            497.09445
V Predictions Max            1379.6682
V Predictions Min            -6.990604
Log Pis Mean                 0.11849083
Log Pis Std                  2.3379273
Log Pis Max                  7.693313
Log Pis Min                  -6.9380302
Policy mu Mean               -0.019548817
Policy mu Std                0.9742273
Policy mu Max                2.3056097
Policy mu Min                -2.7071874
Policy log std Mean          -0.47153234
Policy log std Std           0.25299624
Policy log std Max           0.053500324
Policy log std Min           -1.5719966
Z mean eval                  0.016407618
Z variance eval              0.0020756007
total_rewards                [ 835.31426873  685.62396687  720.83101398  973.65559143  678.55862964
 1009.52480531  906.39827424 1089.70839244  618.64950353 1077.65711605]
total_rewards_mean           859.5921562230939
total_rewards_std            167.06956306599363
total_rewards_max            1089.708392438297
total_rewards_min            618.6495035320695
Number of train steps total  69000
Number of env steps total    347000
Number of rollouts total     0
Train Time (s)               30.596093985717744
(Previous) Eval Time (s)     4.109112571924925
Sample Time (s)              18.658722328953445
Epoch Time (s)               53.36392888659611
Total Train Time (s)         3993.9751551947556
Epoch                        68
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:09:17.583616 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #68 | Epoch Duration: 57.9346239566803
2020-01-11 01:09:17.583806 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #68 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.009480854
Z variance train             0.0019010201
KL Divergence                13.596428
KL Loss                      1.3596429
QF Loss                      1269.157
VF Loss                      259.6372
Policy Loss                  -782.6272
Q Predictions Mean           774.44775
Q Predictions Std            492.31015
Q Predictions Max            1369.9094
Q Predictions Min            -8.863169
V Predictions Mean           773.5824
V Predictions Std            490.9816
V Predictions Max            1374.0774
V Predictions Min            1.1250168
Log Pis Mean                 0.20037505
Log Pis Std                  2.3623977
Log Pis Max                  7.902253
Log Pis Min                  -6.0504065
Policy mu Mean               0.055386472
Policy mu Std                0.9921385
Policy mu Max                2.8480666
Policy mu Min                -2.7020178
Policy log std Mean          -0.5201041
Policy log std Std           0.28352213
Policy log std Max           -0.06965852
Policy log std Min           -2.7261484
Z mean eval                  0.038042754
Z variance eval              0.001704944
total_rewards                [ 870.86404267 1074.4619616  1115.42980378 1113.13379595 1088.97133589
  942.93872364 1087.03207096 1366.50599289  906.27195768 1100.59911486]
total_rewards_mean           1066.62087999194
total_rewards_std            132.64192322944976
total_rewards_max            1366.5059928944386
total_rewards_min            870.8640426702385
Number of train steps total  70000
Number of env steps total    352000
Number of rollouts total     0
Train Time (s)               31.494613281916827
(Previous) Eval Time (s)     8.679420141037554
Sample Time (s)              22.53777665225789
Epoch Time (s)               62.71181007521227
Total Train Time (s)         4058.2756252372637
Epoch                        69
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:10:21.885923 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #69 | Epoch Duration: 64.30197429656982
2020-01-11 01:10:21.886119 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #69 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026807666
Z variance train             0.002058089
KL Divergence                13.506817
KL Loss                      1.3506817
QF Loss                      671.3554
VF Loss                      208.5358
Policy Loss                  -733.62415
Q Predictions Mean           735.1608
Q Predictions Std            507.56186
Q Predictions Max            1390.2574
Q Predictions Min            0.3635904
V Predictions Mean           743.4796
V Predictions Std            510.48053
V Predictions Max            1392.8088
V Predictions Min            -2.27598
Log Pis Mean                 0.22617735
Log Pis Std                  2.4122834
Log Pis Max                  9.007364
Log Pis Min                  -4.6253033
Policy mu Mean               0.12278219
Policy mu Std                0.9789453
Policy mu Max                2.83339
Policy mu Min                -2.7591357
Policy log std Mean          -0.49733317
Policy log std Std           0.2813553
Policy log std Max           -0.033547938
Policy log std Min           -2.5759645
Z mean eval                  0.022122907
Z variance eval              0.0015506411
total_rewards                [1025.1958049   844.98160586 1121.6243285  1316.68945962 1015.18870462
 1181.00333802 1027.0136124  1033.63097383 1083.67894685 1040.92105137]
total_rewards_mean           1068.9927825973834
total_rewards_std            116.48199993560426
total_rewards_max            1316.6894596231532
total_rewards_min            844.9816058589533
Number of train steps total  71000
Number of env steps total    357000
Number of rollouts total     0
Train Time (s)               31.32272315490991
(Previous) Eval Time (s)     10.269289507996291
Sample Time (s)              21.876023137476295
Epoch Time (s)               63.468035800382495
Total Train Time (s)         4121.771725390572
Epoch                        70
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:11:25.383495 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #70 | Epoch Duration: 63.49723482131958
2020-01-11 01:11:25.383671 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #70 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018825267
Z variance train             0.0023146826
KL Divergence                13.158678
KL Loss                      1.3158678
QF Loss                      602.7284
VF Loss                      297.56937
Policy Loss                  -789.33636
Q Predictions Mean           788.301
Q Predictions Std            509.19888
Q Predictions Max            1567.1266
Q Predictions Min            -10.405205
V Predictions Mean           801.8342
V Predictions Std            511.721
V Predictions Max            1611.5106
V Predictions Min            -1.0062444
Log Pis Mean                 0.2781535
Log Pis Std                  2.6064217
Log Pis Max                  11.967303
Log Pis Min                  -7.763087
Policy mu Mean               0.029620431
Policy mu Std                1.050583
Policy mu Max                3.5161495
Policy mu Min                -2.986843
Policy log std Mean          -0.49513957
Policy log std Std           0.26761314
Policy log std Max           0.13411108
Policy log std Min           -1.6262171
Z mean eval                  0.020689083
Z variance eval              0.0015698613
total_rewards                [ 954.51614012  994.98313063  981.85330259 1175.97478139 1163.82245797
 1582.65648286  915.3223554  1713.79500499 1110.91960985 1189.43751258]
total_rewards_mean           1178.3280778384585
total_rewards_std            254.27761635000033
total_rewards_max            1713.795004990802
total_rewards_min            915.3223554045527
Number of train steps total  72000
Number of env steps total    362000
Number of rollouts total     0
Train Time (s)               31.43752789637074
(Previous) Eval Time (s)     10.298181657679379
Sample Time (s)              22.26599535997957
Epoch Time (s)               64.00170491402969
Total Train Time (s)         4186.476533967536
Epoch                        71
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:12:30.089801 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #71 | Epoch Duration: 64.70599460601807
2020-01-11 01:12:30.089974 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #71 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016782245
Z variance train             0.0018791826
KL Divergence                13.652192
KL Loss                      1.3652192
QF Loss                      547.53046
VF Loss                      321.82132
Policy Loss                  -749.09937
Q Predictions Mean           751.20667
Q Predictions Std            519.6049
Q Predictions Max            1499.6562
Q Predictions Min            -3.2553952
V Predictions Mean           749.78015
V Predictions Std            519.8207
V Predictions Max            1499.1902
V Predictions Min            -9.32043
Log Pis Mean                 0.31850487
Log Pis Std                  2.4776187
Log Pis Max                  10.806456
Log Pis Min                  -3.954931
Policy mu Mean               0.042050827
Policy mu Std                1.0113819
Policy mu Max                3.566072
Policy mu Min                -2.8920844
Policy log std Mean          -0.48962042
Policy log std Std           0.27842608
Policy log std Max           0.094392955
Policy log std Min           -1.9028971
Z mean eval                  0.009741169
Z variance eval              0.0019277697
total_rewards                [1143.16103992 1135.94723439 1176.88002977 1322.47960539 1107.45943054
 1114.83318705 1199.58228322 1078.01368911 1101.1731     1215.01935892]
total_rewards_mean           1159.4548958299206
total_rewards_std            68.64435233099096
total_rewards_max            1322.4796053949622
total_rewards_min            1078.013689106309
Number of train steps total  73000
Number of env steps total    367000
Number of rollouts total     0
Train Time (s)               31.443903686013073
(Previous) Eval Time (s)     11.002163383178413
Sample Time (s)              21.776600126177073
Epoch Time (s)               64.22266719536856
Total Train Time (s)         4250.634960200172
Epoch                        72
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:13:34.248948 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #72 | Epoch Duration: 64.15883302688599
2020-01-11 01:13:34.249085 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #72 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017724615
Z variance train             0.0021817626
KL Divergence                13.321863
KL Loss                      1.3321863
QF Loss                      315.03937
VF Loss                      137.10445
Policy Loss                  -781.28973
Q Predictions Mean           776.95184
Q Predictions Std            498.29303
Q Predictions Max            1508.915
Q Predictions Min            -6.5622296
V Predictions Mean           788.8929
V Predictions Std            502.64703
V Predictions Max            1517.3031
V Predictions Min            -2.8486407
Log Pis Mean                 0.24624509
Log Pis Std                  2.3653996
Log Pis Max                  12.623093
Log Pis Min                  -3.4361799
Policy mu Mean               0.06330961
Policy mu Std                0.9905411
Policy mu Max                2.8542328
Policy mu Min                -2.8379235
Policy log std Mean          -0.49610648
Policy log std Std           0.27862906
Policy log std Max           0.05723363
Policy log std Min           -2.8141112
Z mean eval                  0.0070994594
Z variance eval              0.002298297
total_rewards                [1086.11152474 1230.84942282 1191.06665384 1442.17662256 1496.0513037
 1445.96329483 1624.07609379 1403.6878408  1433.84442554 1327.15916216]
total_rewards_mean           1368.0986344793018
total_rewards_std            151.79141552074066
total_rewards_max            1624.076093788728
total_rewards_min            1086.1115247402247
Number of train steps total  74000
Number of env steps total    372000
Number of rollouts total     0
Train Time (s)               31.423165574204177
(Previous) Eval Time (s)     10.938011326361448
Sample Time (s)              22.271591797936708
Epoch Time (s)               64.63276869850233
Total Train Time (s)         4316.501613960136
Epoch                        73
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:14:40.118305 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #73 | Epoch Duration: 65.86909294128418
2020-01-11 01:14:40.118512 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #73 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010154422
Z variance train             0.0021545368
KL Divergence                13.286583
KL Loss                      1.3286583
QF Loss                      442.48236
VF Loss                      439.04172
Policy Loss                  -777.6672
Q Predictions Mean           774.0048
Q Predictions Std            489.29858
Q Predictions Max            1525.3619
Q Predictions Min            -13.225188
V Predictions Mean           793.05725
V Predictions Std            495.62228
V Predictions Max            1544.5486
V Predictions Min            -4.2592397
Log Pis Mean                 0.3263125
Log Pis Std                  2.6179802
Log Pis Max                  8.621355
Log Pis Min                  -5.836443
Policy mu Mean               -0.070278786
Policy mu Std                1.0595624
Policy mu Max                3.025901
Policy mu Min                -2.766285
Policy log std Mean          -0.47898176
Policy log std Std           0.24719015
Policy log std Max           0.004855603
Policy log std Min           -1.531194
Z mean eval                  0.013097537
Z variance eval              0.0024721618
total_rewards                [1185.04394977 1109.15559606 1204.51784339  881.07814025  940.39908986
 1192.38429864 1193.24773267 1368.7360765  1214.79140257 1683.40033411]
total_rewards_mean           1197.2754463835363
total_rewards_std            209.76092998102257
total_rewards_max            1683.400334109613
total_rewards_min            881.0781402474882
Number of train steps total  75000
Number of env steps total    377000
Number of rollouts total     0
Train Time (s)               31.79815114568919
(Previous) Eval Time (s)     12.174002449028194
Sample Time (s)              23.065914426464587
Epoch Time (s)               67.03806802118197
Total Train Time (s)         4382.365161696915
Epoch                        74
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:15:45.984712 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #74 | Epoch Duration: 65.86604619026184
2020-01-11 01:15:45.984943 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #74 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025134081
Z variance train             0.0014033881
KL Divergence                14.543957
KL Loss                      1.4543957
QF Loss                      842.2291
VF Loss                      179.6433
Policy Loss                  -793.29065
Q Predictions Mean           792.1283
Q Predictions Std            490.90103
Q Predictions Max            1536.8287
Q Predictions Min            -17.458288
V Predictions Mean           798.9232
V Predictions Std            493.92297
V Predictions Max            1564.4417
V Predictions Min            -7.4096413
Log Pis Mean                 0.29471433
Log Pis Std                  2.384367
Log Pis Max                  9.831301
Log Pis Min                  -5.602939
Policy mu Mean               -0.025374943
Policy mu Std                1.0031145
Policy mu Max                2.5997133
Policy mu Min                -4.062233
Policy log std Mean          -0.5163262
Policy log std Std           0.2757732
Policy log std Max           0.06623718
Policy log std Min           -1.5370729
Z mean eval                  0.03444399
Z variance eval              0.0015825762
total_rewards                [1012.64385768 1415.57237598 1161.23549578 1167.33817787 1095.65423969
 1522.8998677  1127.38255776 1320.56011829 1066.208815   1080.94758705]
total_rewards_mean           1197.0443092790865
total_rewards_std            158.45814879399816
total_rewards_max            1522.8998676985134
total_rewards_min            1012.6438576783357
Number of train steps total  76000
Number of env steps total    382000
Number of rollouts total     0
Train Time (s)               31.36084604077041
(Previous) Eval Time (s)     11.00166973983869
Sample Time (s)              22.32602625573054
Epoch Time (s)               64.68854203633964
Total Train Time (s)         4447.253034575842
Epoch                        75
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:16:50.874010 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #75 | Epoch Duration: 64.88891077041626
2020-01-11 01:16:50.874191 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #75 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030768896
Z variance train             0.002287762
KL Divergence                12.981104
KL Loss                      1.2981104
QF Loss                      348.99365
VF Loss                      221.52884
Policy Loss                  -808.2331
Q Predictions Mean           802.07556
Q Predictions Std            531.8084
Q Predictions Max            1535.1605
Q Predictions Min            -4.507143
V Predictions Mean           801.2579
V Predictions Std            529.42444
V Predictions Max            1527.7922
V Predictions Min            -16.434614
Log Pis Mean                 -0.18129408
Log Pis Std                  2.1925
Log Pis Max                  8.272032
Log Pis Min                  -5.533373
Policy mu Mean               0.12888506
Policy mu Std                0.91122484
Policy mu Max                2.4103394
Policy mu Min                -2.9503508
Policy log std Mean          -0.50271213
Policy log std Std           0.2831264
Policy log std Max           0.07771206
Policy log std Min           -1.5894712
Z mean eval                  0.02731445
Z variance eval              0.0011684456
total_rewards                [1176.1795622  1367.79950953 2167.74057867 1698.22062401 1318.61467503
 1099.67702101 1146.98463153 1287.57037688 1412.18601751 1439.12498526]
total_rewards_mean           1411.4097981649825
total_rewards_std            300.55709688838954
total_rewards_max            2167.740578672304
total_rewards_min            1099.6770210120926
Number of train steps total  77000
Number of env steps total    387000
Number of rollouts total     0
Train Time (s)               31.409025099128485
(Previous) Eval Time (s)     11.20170378498733
Sample Time (s)              22.34369611321017
Epoch Time (s)               64.95442499732599
Total Train Time (s)         4513.993155005388
Epoch                        76
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:17:57.615975 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #76 | Epoch Duration: 66.7416443824768
2020-01-11 01:17:57.616167 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #76 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012428267
Z variance train             0.0017563545
KL Divergence                13.62034
KL Loss                      1.3620341
QF Loss                      199.15878
VF Loss                      129.92934
Policy Loss                  -885.9191
Q Predictions Mean           885.167
Q Predictions Std            471.16086
Q Predictions Max            1531.6536
Q Predictions Min            -19.336206
V Predictions Mean           887.928
V Predictions Std            472.771
V Predictions Max            1533.244
V Predictions Min            -2.8604336
Log Pis Mean                 0.32702368
Log Pis Std                  2.2099469
Log Pis Max                  7.4440784
Log Pis Min                  -5.6652594
Policy mu Mean               -0.07728443
Policy mu Std                1.0317098
Policy mu Max                3.379962
Policy mu Min                -2.9532652
Policy log std Mean          -0.5102547
Policy log std Std           0.26179108
Policy log std Max           0.08963713
Policy log std Min           -1.7031031
Z mean eval                  0.014059802
Z variance eval              0.001897957
total_rewards                [1376.72976453 1180.38568559 1202.48803629 1210.05823747 1178.55897849
 1116.03230701 1099.51470025 1770.60548198 1347.93756421 1084.26692183]
total_rewards_mean           1256.657767765814
total_rewards_std            194.4485365523653
total_rewards_max            1770.6054819781514
total_rewards_min            1084.2669218319627
Number of train steps total  78000
Number of env steps total    392000
Number of rollouts total     0
Train Time (s)               31.51836326625198
(Previous) Eval Time (s)     12.988589238375425
Sample Time (s)              23.443101861979812
Epoch Time (s)               67.95005436660722
Total Train Time (s)         4581.0362294930965
Epoch                        77
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:19:04.660641 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #77 | Epoch Duration: 67.04433107376099
2020-01-11 01:19:04.660837 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #77 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010168153
Z variance train             0.0015404861
KL Divergence                13.809985
KL Loss                      1.3809985
QF Loss                      247.0293
VF Loss                      135.7162
Policy Loss                  -851.93506
Q Predictions Mean           849.7954
Q Predictions Std            483.80548
Q Predictions Max            1511.6836
Q Predictions Min            -1.9839754
V Predictions Mean           851.7127
V Predictions Std            483.49988
V Predictions Max            1497.5851
V Predictions Min            -3.4640884
Log Pis Mean                 0.13308555
Log Pis Std                  2.2332082
Log Pis Max                  11.355452
Log Pis Min                  -4.446882
Policy mu Mean               0.13686442
Policy mu Std                1.0033568
Policy mu Max                2.6455035
Policy mu Min                -2.706985
Policy log std Mean          -0.51334494
Policy log std Std           0.2694237
Policy log std Max           0.059546232
Policy log std Min           -1.5577946
Z mean eval                  0.019035283
Z variance eval              0.0018632918
total_rewards                [1205.16877778 1479.86741528 2057.8084619  1830.39277451 2622.97527767
 1752.42837965  921.61316615 2107.43991795 1762.83910463 2553.191423  ]
total_rewards_mean           1829.3724698531958
total_rewards_std            512.7750881463405
total_rewards_max            2622.975277672923
total_rewards_min            921.6131661477202
Number of train steps total  79000
Number of env steps total    397000
Number of rollouts total     0
Train Time (s)               32.090118386782706
(Previous) Eval Time (s)     12.082529908046126
Sample Time (s)              22.08201861847192
Epoch Time (s)               66.25466691330075
Total Train Time (s)         4652.488008960616
Epoch                        78
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:20:16.119440 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #78 | Epoch Duration: 71.45846033096313
2020-01-11 01:20:16.119808 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #78 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016813055
Z variance train             0.0016547047
KL Divergence                13.547575
KL Loss                      1.3547575
QF Loss                      304.68292
VF Loss                      286.4366
Policy Loss                  -871.6414
Q Predictions Mean           870.8637
Q Predictions Std            490.00912
Q Predictions Max            1528.9888
Q Predictions Min            0.4923563
V Predictions Mean           877.271
V Predictions Std            491.353
V Predictions Max            1514.511
V Predictions Min            -2.5182214
Log Pis Mean                 0.12022966
Log Pis Std                  2.176725
Log Pis Max                  9.239218
Log Pis Min                  -7.0981417
Policy mu Mean               0.055216506
Policy mu Std                0.93479276
Policy mu Max                2.9123473
Policy mu Min                -2.9619231
Policy log std Mean          -0.51823336
Policy log std Std           0.3176981
Policy log std Max           0.04851547
Policy log std Min           -2.6613398
Z mean eval                  0.009747882
Z variance eval              0.0021744755
total_rewards                [ 883.3194256   788.2411783  1123.33388971 2204.54285886 1058.90456964
 1413.18448979 1174.36227532 2036.05964484  891.96108344 1106.94892401]
total_rewards_mean           1268.0858339510173
total_rewards_std            459.0222434718531
total_rewards_max            2204.5428588582695
total_rewards_min            788.2411782978362
Number of train steps total  80000
Number of env steps total    402000
Number of rollouts total     0
Train Time (s)               30.953146771062165
(Previous) Eval Time (s)     17.28601965121925
Sample Time (s)              22.617318596225232
Epoch Time (s)               70.85648501850665
Total Train Time (s)         4718.078984173946
Epoch                        79
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:21:21.706517 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #79 | Epoch Duration: 65.58640885353088
2020-01-11 01:21:21.706701 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #79 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.007033372
Z variance train             0.0016472448
KL Divergence                13.555009
KL Loss                      1.3555009
QF Loss                      261.27197
VF Loss                      123.97095
Policy Loss                  -813.284
Q Predictions Mean           814.5185
Q Predictions Std            498.36646
Q Predictions Max            1492.6022
Q Predictions Min            -10.312973
V Predictions Mean           820.68774
V Predictions Std            499.3599
V Predictions Max            1499.1785
V Predictions Min            -3.2310882
Log Pis Mean                 -0.120335594
Log Pis Std                  2.144758
Log Pis Max                  7.3237233
Log Pis Min                  -5.731972
Policy mu Mean               -0.011150241
Policy mu Std                0.9548342
Policy mu Max                2.2241046
Policy mu Min                -2.734702
Policy log std Mean          -0.51597756
Policy log std Std           0.27359483
Policy log std Max           0.012973756
Policy log std Min           -2.0290756
Z mean eval                  0.007490759
Z variance eval              0.0019618578
total_rewards                [845.90730474 868.72697972 830.11064717 863.74734496 819.66326106
 836.31846541 822.88755176 824.01078193 832.62395766 818.43072392]
total_rewards_mean           836.2427018332615
total_rewards_std            16.958672435824877
total_rewards_max            868.7269797194188
total_rewards_min            818.430723918431
Number of train steps total  81000
Number of env steps total    407000
Number of rollouts total     0
Train Time (s)               31.403785394970328
(Previous) Eval Time (s)     12.015607735142112
Sample Time (s)              22.313319814857095
Epoch Time (s)               65.73271294496953
Total Train Time (s)         4779.433374679182
Epoch                        80
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:22:23.062642 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #80 | Epoch Duration: 61.355796813964844
2020-01-11 01:22:23.062819 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #80 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013426033
Z variance train             0.0017697432
KL Divergence                13.405304
KL Loss                      1.3405304
QF Loss                      447.90417
VF Loss                      76.44153
Policy Loss                  -899.9414
Q Predictions Mean           894.1543
Q Predictions Std            478.78873
Q Predictions Max            1536.6621
Q Predictions Min            -8.494236
V Predictions Mean           895.1316
V Predictions Std            478.55002
V Predictions Max            1528.3599
V Predictions Min            -1.3120627
Log Pis Mean                 0.25109297
Log Pis Std                  2.3770628
Log Pis Max                  6.9896994
Log Pis Min                  -6.3815613
Policy mu Mean               -0.0040169246
Policy mu Std                0.989384
Policy mu Max                2.7000132
Policy mu Min                -2.583014
Policy log std Mean          -0.5375115
Policy log std Std           0.27322596
Policy log std Max           0.11547369
Policy log std Min           -1.844747
Z mean eval                  0.0097289225
Z variance eval              0.001931315
total_rewards                [1159.65206219 1093.71256871 1188.68133728 1585.55217632  906.93820434
  924.82033707  875.19382099 1148.32258412 1199.39215278  954.50415461]
total_rewards_mean           1103.6769398418699
total_rewards_std            199.7422087406249
total_rewards_max            1585.5521763246286
total_rewards_min            875.1938209941194
Number of train steps total  82000
Number of env steps total    412000
Number of rollouts total     0
Train Time (s)               31.466589097399265
(Previous) Eval Time (s)     7.6383731393143535
Sample Time (s)              23.4339695321396
Epoch Time (s)               62.53893176885322
Total Train Time (s)         4844.00432806788
Epoch                        81
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:23:27.635502 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #81 | Epoch Duration: 64.5725462436676
2020-01-11 01:23:27.635685 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #81 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.00979561
Z variance train             0.0020379785
KL Divergence                13.063165
KL Loss                      1.3063165
QF Loss                      456.12448
VF Loss                      89.4091
Policy Loss                  -870.21246
Q Predictions Mean           870.9765
Q Predictions Std            493.84488
Q Predictions Max            1502.6112
Q Predictions Min            -5.296627
V Predictions Mean           872.4357
V Predictions Std            494.08362
V Predictions Max            1514.3762
V Predictions Min            -2.2664464
Log Pis Mean                 0.38485035
Log Pis Std                  2.4860933
Log Pis Max                  10.189152
Log Pis Min                  -5.3357153
Policy mu Mean               0.076570265
Policy mu Std                0.99864584
Policy mu Max                3.1190677
Policy mu Min                -2.9895542
Policy log std Mean          -0.50420284
Policy log std Std           0.26829955
Policy log std Max           0.04571426
Policy log std Min           -2.6078765
Z mean eval                  0.007717899
Z variance eval              0.0022676713
total_rewards                [1136.15164934  946.82812999 1845.3248556  1504.40368804 1030.3921109
  717.79702515 1708.55143478 1139.35969156  724.8502599  1468.80597099]
total_rewards_mean           1222.2464816247968
total_rewards_std            373.3552734499414
total_rewards_max            1845.3248556018266
total_rewards_min            717.7970251461156
Number of train steps total  83000
Number of env steps total    417000
Number of rollouts total     0
Train Time (s)               31.26290381187573
(Previous) Eval Time (s)     9.671654162928462
Sample Time (s)              22.749144858215004
Epoch Time (s)               63.6837028330192
Total Train Time (s)         4908.9885408151895
Epoch                        82
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:24:32.621354 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #82 | Epoch Duration: 64.98553204536438
2020-01-11 01:24:32.621531 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #82 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.007693514
Z variance train             0.002264909
KL Divergence                12.843893
KL Loss                      1.2843894
QF Loss                      226.2541
VF Loss                      147.4461
Policy Loss                  -809.74817
Q Predictions Mean           811.199
Q Predictions Std            511.55188
Q Predictions Max            1467.3164
Q Predictions Min            -4.015317
V Predictions Mean           816.3312
V Predictions Std            512.3095
V Predictions Max            1463.8407
V Predictions Min            0.32846692
Log Pis Mean                 0.07735446
Log Pis Std                  2.3831837
Log Pis Max                  8.887301
Log Pis Min                  -5.7062573
Policy mu Mean               0.10358039
Policy mu Std                0.9836594
Policy mu Max                2.9183323
Policy mu Min                -3.3919742
Policy log std Mean          -0.4855753
Policy log std Std           0.25205833
Policy log std Max           -0.023383707
Policy log std Min           -1.410835
Z mean eval                  0.02175486
Z variance eval              0.0021033813
total_rewards                [1155.69259626  891.44171574 1445.45453356 1178.39009495 1162.48558571
  885.10234914  881.06795308 1219.69533318  871.78582201 1391.083219  ]
total_rewards_mean           1108.2199202629583
total_rewards_std            205.07589039232198
total_rewards_max            1445.4545335590092
total_rewards_min            871.7858220076955
Number of train steps total  84000
Number of env steps total    422000
Number of rollouts total     0
Train Time (s)               31.564379969146103
(Previous) Eval Time (s)     10.973135863430798
Sample Time (s)              22.74877089681104
Epoch Time (s)               65.28628672938794
Total Train Time (s)         4971.8013225840405
Epoch                        83
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:25:35.435287 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #83 | Epoch Duration: 62.813628911972046
2020-01-11 01:25:35.435447 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #83 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019946242
Z variance train             0.0022457193
KL Divergence                12.872098
KL Loss                      1.2872099
QF Loss                      3545.627
VF Loss                      123.90202
Policy Loss                  -877.6844
Q Predictions Mean           878.8412
Q Predictions Std            481.58502
Q Predictions Max            1491.688
Q Predictions Min            2.4494889
V Predictions Mean           881.282
V Predictions Std            479.75854
V Predictions Max            1479.7229
V Predictions Min            1.1895474
Log Pis Mean                 0.13109231
Log Pis Std                  2.2522461
Log Pis Max                  10.875055
Log Pis Min                  -5.0117335
Policy mu Mean               0.02872453
Policy mu Std                0.97181314
Policy mu Max                2.2999525
Policy mu Min                -3.187965
Policy log std Mean          -0.49574864
Policy log std Std           0.24881615
Policy log std Max           0.0076474845
Policy log std Min           -1.539907
Z mean eval                  0.020298792
Z variance eval              0.002458829
total_rewards                [1387.61354901 1070.93705192 1107.1185647  1035.73562711  742.68597702
 1073.26224821 1095.27433432  871.4984189  1205.75789445  834.72201433]
total_rewards_mean           1042.4605679955966
total_rewards_std            177.99426803884077
total_rewards_max            1387.6135490053578
total_rewards_min            742.6859770186628
Number of train steps total  85000
Number of env steps total    427000
Number of rollouts total     0
Train Time (s)               31.769790476188064
(Previous) Eval Time (s)     8.500165699981153
Sample Time (s)              21.8416740456596
Epoch Time (s)               62.11163022182882
Total Train Time (s)         5035.0862955185585
Epoch                        84
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:26:38.722449 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #84 | Epoch Duration: 63.28687286376953
2020-01-11 01:26:38.722630 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #84 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020768797
Z variance train             0.002452422
KL Divergence                12.720631
KL Loss                      1.2720631
QF Loss                      1007.9204
VF Loss                      218.19693
Policy Loss                  -818.8082
Q Predictions Mean           818.2969
Q Predictions Std            512.52563
Q Predictions Max            1502.5402
Q Predictions Min            -5.555147
V Predictions Mean           825.18677
V Predictions Std            513.4906
V Predictions Max            1495.6072
V Predictions Min            -6.471518
Log Pis Mean                 0.1303769
Log Pis Std                  2.2832582
Log Pis Max                  8.0998
Log Pis Min                  -5.232876
Policy mu Mean               0.12526198
Policy mu Std                0.9866556
Policy mu Max                2.9477358
Policy mu Min                -3.5001736
Policy log std Mean          -0.48344764
Policy log std Std           0.25399995
Policy log std Max           0.14464122
Policy log std Min           -1.7325139
Z mean eval                  0.0073595108
Z variance eval              0.0018511948
total_rewards                [1114.72698126 1375.92922992  844.77707907 1403.12803057 1064.69619187
 1167.1007297   715.90893601  851.8536043   896.52582045  842.95451277]
total_rewards_mean           1027.7601115931745
total_rewards_std            224.39222838520337
total_rewards_max            1403.128030567321
total_rewards_min            715.908936009038
Number of train steps total  86000
Number of env steps total    432000
Number of rollouts total     0
Train Time (s)               31.492939424235374
(Previous) Eval Time (s)     9.675104631111026
Sample Time (s)              23.52046369900927
Epoch Time (s)               64.68850775435567
Total Train Time (s)         5099.824258409906
Epoch                        85
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:27:43.463724 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #85 | Epoch Duration: 64.74090242385864
2020-01-11 01:27:43.464127 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #85 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.007890135
Z variance train             0.0020698805
KL Divergence                13.065715
KL Loss                      1.3065715
QF Loss                      440.82306
VF Loss                      111.3824
Policy Loss                  -905.06665
Q Predictions Mean           901.4717
Q Predictions Std            490.04712
Q Predictions Max            1514.3685
Q Predictions Min            -2.725556
V Predictions Mean           901.17175
V Predictions Std            486.6594
V Predictions Max            1512.5597
V Predictions Min            -7.278631
Log Pis Mean                 0.041158788
Log Pis Std                  2.172872
Log Pis Max                  7.0919976
Log Pis Min                  -6.7412696
Policy mu Mean               0.06839908
Policy mu Std                0.94800216
Policy mu Max                2.2806888
Policy mu Min                -3.7320824
Policy log std Mean          -0.5093548
Policy log std Std           0.25812623
Policy log std Max           0.015432626
Policy log std Min           -1.7090722
Z mean eval                  0.0108152535
Z variance eval              0.002125056
total_rewards                [1521.82936888 1287.30262728 1005.11987812 2294.20626997 2374.03963302
 1550.03856068 1219.7801953  1410.846115   1157.640141   1198.89716702]
total_rewards_mean           1501.9699956259685
total_rewards_std            445.2124998311151
total_rewards_max            2374.039633016704
total_rewards_min            1005.119878122935
Number of train steps total  87000
Number of env steps total    437000
Number of rollouts total     0
Train Time (s)               31.77139124367386
(Previous) Eval Time (s)     9.727115091402084
Sample Time (s)              22.39181673899293
Epoch Time (s)               63.890323074068874
Total Train Time (s)         5168.422714191955
Epoch                        86
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:28:52.062987 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #86 | Epoch Duration: 68.59861588478088
2020-01-11 01:28:52.063179 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #86 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.009912269
Z variance train             0.0021044088
KL Divergence                13.039084
KL Loss                      1.3039085
QF Loss                      679.26556
VF Loss                      418.2909
Policy Loss                  -861.4526
Q Predictions Mean           862.59247
Q Predictions Std            489.74518
Q Predictions Max            1510.045
Q Predictions Min            -9.152622
V Predictions Mean           861.9542
V Predictions Std            486.43396
V Predictions Max            1513.0566
V Predictions Min            -9.212145
Log Pis Mean                 0.109326385
Log Pis Std                  2.3513267
Log Pis Max                  10.254009
Log Pis Min                  -5.1941214
Policy mu Mean               -0.057378203
Policy mu Std                0.9585965
Policy mu Max                3.3064177
Policy mu Min                -3.3855746
Policy log std Mean          -0.5149319
Policy log std Std           0.26780355
Policy log std Max           0.11290464
Policy log std Min           -1.6227
Z mean eval                  0.01293206
Z variance eval              0.0019956785
total_rewards                [1681.4818042   866.91776046 1230.15256447 1077.68383764  913.44996114
  928.07771708 1167.90176567 1186.39195768 1019.14955868  801.50395505]
total_rewards_mean           1087.2710882080385
total_rewards_std            240.90142369939682
total_rewards_max            1681.481804204744
total_rewards_min            801.5039550475959
Number of train steps total  88000
Number of env steps total    442000
Number of rollouts total     0
Train Time (s)               31.617398218717426
(Previous) Eval Time (s)     14.435133035294712
Sample Time (s)              22.889202072285116
Epoch Time (s)               68.94173332629725
Total Train Time (s)         5232.391100123525
Epoch                        87
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:29:56.033038 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #87 | Epoch Duration: 63.969643354415894
2020-01-11 01:29:56.033216 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #87 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012802782
Z variance train             0.0020159376
KL Divergence                13.148251
KL Loss                      1.314825
QF Loss                      350.1645
VF Loss                      119.817375
Policy Loss                  -855.3724
Q Predictions Mean           850.6399
Q Predictions Std            506.87363
Q Predictions Max            1496.7561
Q Predictions Min            -11.986508
V Predictions Mean           856.529
V Predictions Std            506.83142
V Predictions Max            1497.1401
V Predictions Min            -6.596675
Log Pis Mean                 0.39219403
Log Pis Std                  2.4654973
Log Pis Max                  10.224598
Log Pis Min                  -4.23029
Policy mu Mean               0.05868764
Policy mu Std                1.0310618
Policy mu Max                3.5924568
Policy mu Min                -3.7309525
Policy log std Mean          -0.49916187
Policy log std Std           0.24938706
Policy log std Max           -0.034018934
Policy log std Min           -1.8085735
Z mean eval                  0.012215394
Z variance eval              0.0019036133
total_rewards                [ 957.26273937  944.35094163  861.2156244  1008.24784435  974.35626433
  909.59560492 1158.2267635  1218.43914692  970.99218058  952.77372978]
total_rewards_mean           995.5460839777828
total_rewards_std            104.26300730374737
total_rewards_max            1218.439146918012
total_rewards_min            861.215624399277
Number of train steps total  89000
Number of env steps total    447000
Number of rollouts total     0
Train Time (s)               31.643891985993832
(Previous) Eval Time (s)     9.462700068950653
Sample Time (s)              22.41064176009968
Epoch Time (s)               63.517233815044165
Total Train Time (s)         5296.295418729074
Epoch                        88
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:30:59.939039 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #88 | Epoch Duration: 63.905688524246216
2020-01-11 01:30:59.939265 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #88 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01192291
Z variance train             0.001906851
KL Divergence                13.2299
KL Loss                      1.3229901
QF Loss                      172.85223
VF Loss                      74.824524
Policy Loss                  -968.2468
Q Predictions Mean           964.0812
Q Predictions Std            458.47687
Q Predictions Max            1474.8116
Q Predictions Min            -1.1929598
V Predictions Mean           966.2399
V Predictions Std            458.1229
V Predictions Max            1480.1213
V Predictions Min            1.6590388
Log Pis Mean                 0.11693842
Log Pis Std                  2.038889
Log Pis Max                  7.2629285
Log Pis Min                  -4.2082148
Policy mu Mean               0.045507
Policy mu Std                0.94387466
Policy mu Max                2.521125
Policy mu Min                -2.9267676
Policy log std Mean          -0.5457818
Policy log std Std           0.23910682
Policy log std Max           -0.0788185
Policy log std Min           -1.2462089
Z mean eval                  0.014460057
Z variance eval              0.0016414418
total_rewards                [1002.24287013  753.35008728  783.86871208 1041.64408785  765.0958413
  677.64744298  852.85775309 1078.91210079 1212.14686152  896.69208905]
total_rewards_mean           906.4457846065188
total_rewards_std            162.60755578738534
total_rewards_max            1212.1468615228343
total_rewards_min            677.647442976689
Number of train steps total  90000
Number of env steps total    452000
Number of rollouts total     0
Train Time (s)               32.36880490090698
(Previous) Eval Time (s)     9.85084390686825
Sample Time (s)              23.822597857564688
Epoch Time (s)               66.04224666533992
Total Train Time (s)         5361.2582878149115
Epoch                        89
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:32:04.903795 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #89 | Epoch Duration: 64.96438837051392
2020-01-11 01:32:04.903971 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #89 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014257215
Z variance train             0.0016415722
KL Divergence                13.585992
KL Loss                      1.3585992
QF Loss                      260.9606
VF Loss                      92.72293
Policy Loss                  -920.5367
Q Predictions Mean           918.8608
Q Predictions Std            466.6095
Q Predictions Max            1473.135
Q Predictions Min            -5.3920064
V Predictions Mean           920.9646
V Predictions Std            464.8609
V Predictions Max            1486.102
V Predictions Min            -0.94995606
Log Pis Mean                 0.095254615
Log Pis Std                  2.0250447
Log Pis Max                  6.601141
Log Pis Min                  -3.353747
Policy mu Mean               0.09392005
Policy mu Std                0.9389872
Policy mu Max                2.5276284
Policy mu Min                -2.6576536
Policy log std Mean          -0.54684836
Policy log std Std           0.27725142
Policy log std Max           -0.02295664
Policy log std Min           -2.564147
Z mean eval                  0.009020289
Z variance eval              0.0016588818
total_rewards                [1009.88563422 1068.95647462  865.79629628 1066.01462245  981.62088128
 1431.56709133 1047.20708948  864.92073661 1082.39717365 1163.72997854]
total_rewards_mean           1058.2095978450839
total_rewards_std            152.96972770163626
total_rewards_max            1431.5670913340616
total_rewards_min            864.9207366087513
Number of train steps total  91000
Number of env steps total    457000
Number of rollouts total     0
Train Time (s)               31.483999819960445
(Previous) Eval Time (s)     8.772689851932228
Sample Time (s)              22.320017922203988
Epoch Time (s)               62.57670759409666
Total Train Time (s)         5425.226176760625
Epoch                        90
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:33:08.874894 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #90 | Epoch Duration: 63.970781087875366
2020-01-11 01:33:08.875066 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #90 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.009362815
Z variance train             0.0016512328
KL Divergence                13.616643
KL Loss                      1.3616643
QF Loss                      302.5418
VF Loss                      171.60153
Policy Loss                  -918.0151
Q Predictions Mean           914.0497
Q Predictions Std            472.37317
Q Predictions Max            1479.5912
Q Predictions Min            -1.9380076
V Predictions Mean           920.6102
V Predictions Std            472.1
V Predictions Max            1490.9613
V Predictions Min            -4.9070115
Log Pis Mean                 0.2878632
Log Pis Std                  2.2554817
Log Pis Max                  9.164811
Log Pis Min                  -4.0039034
Policy mu Mean               -0.039846707
Policy mu Std                0.9905584
Policy mu Max                2.4390252
Policy mu Min                -3.0417495
Policy log std Mean          -0.5148705
Policy log std Std           0.2553078
Policy log std Max           0.06181094
Policy log std Min           -1.7987607
Z mean eval                  0.033403683
Z variance eval              0.0013173174
total_rewards                [1004.17211116  818.30917595 1167.03566662  775.62058169  783.77677439
  792.29228119  810.22620012 1005.93999768 1012.69197384  867.77596965]
total_rewards_mean           903.7840732296241
total_rewards_std            127.39293251123706
total_rewards_max            1167.0356666233413
total_rewards_min            775.6205816942269
Number of train steps total  92000
Number of env steps total    462000
Number of rollouts total     0
Train Time (s)               32.05762562062591
(Previous) Eval Time (s)     10.166423537768424
Sample Time (s)              23.114543164148927
Epoch Time (s)               65.33859232254326
Total Train Time (s)         5488.133574598003
Epoch                        91
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:34:11.784015 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #91 | Epoch Duration: 62.90881395339966
2020-01-11 01:34:11.784180 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #91 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03407365
Z variance train             0.0013433394
KL Divergence                14.140879
KL Loss                      1.4140879
QF Loss                      600.09735
VF Loss                      472.69186
Policy Loss                  -935.4282
Q Predictions Mean           934.75745
Q Predictions Std            482.04083
Q Predictions Max            1499.633
Q Predictions Min            -32.511223
V Predictions Mean           920.9086
V Predictions Std            471.05627
V Predictions Max            1458.9097
V Predictions Min            -9.049575
Log Pis Mean                 0.4744028
Log Pis Std                  2.4034493
Log Pis Max                  11.567973
Log Pis Min                  -4.103875
Policy mu Mean               0.22935063
Policy mu Std                1.044198
Policy mu Max                2.8662715
Policy mu Min                -3.4793854
Policy log std Mean          -0.52536696
Policy log std Std           0.24400237
Policy log std Max           -0.10761523
Policy log std Min           -2.0504932
Z mean eval                  0.029012615
Z variance eval              0.0010401064
total_rewards                [1043.58149074 1084.32458849 1115.79194094 1139.82440417 1080.58346574
 1041.16298042 1079.13112694 1110.23843874 1054.42269483 1123.27540918]
total_rewards_mean           1087.23365401814
total_rewards_std            32.60752515528708
total_rewards_max            1139.824404173238
total_rewards_min            1041.1629804205377
Number of train steps total  93000
Number of env steps total    467000
Number of rollouts total     0
Train Time (s)               31.850151481106877
(Previous) Eval Time (s)     7.736316933296621
Sample Time (s)              23.300294027663767
Epoch Time (s)               62.886762442067266
Total Train Time (s)         5553.249309998006
Epoch                        92
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:35:16.901534 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #92 | Epoch Duration: 65.11720395088196
2020-01-11 01:35:16.901819 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #92 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031234369
Z variance train             0.0011780863
KL Divergence                14.531319
KL Loss                      1.4531319
QF Loss                      559.00195
VF Loss                      482.99936
Policy Loss                  -855.1383
Q Predictions Mean           854.6156
Q Predictions Std            514.6335
Q Predictions Max            1490.4679
Q Predictions Min            -2.5477972
V Predictions Mean           853.9388
V Predictions Std            514.0193
V Predictions Max            1487.567
V Predictions Min            -1.1299796
Log Pis Mean                 0.14073314
Log Pis Std                  2.3515759
Log Pis Max                  9.669829
Log Pis Min                  -7.0590506
Policy mu Mean               0.052252848
Policy mu Std                1.0062621
Policy mu Max                2.7093644
Policy mu Min                -2.8722568
Policy log std Mean          -0.4999589
Policy log std Std           0.2593289
Policy log std Max           -0.028355777
Policy log std Min           -1.5693216
Z mean eval                  0.020225603
Z variance eval              0.0011011355
total_rewards                [1197.72886007 1153.61241682  961.57662225 1432.89513509 1235.01845758
  858.48288617 1163.51770983 1020.78617073  974.67210655 1292.42759919]
total_rewards_mean           1129.0717964291493
total_rewards_std            165.39619781088655
total_rewards_max            1432.8951350902162
total_rewards_min            858.4828861701278
Number of train steps total  94000
Number of env steps total    472000
Number of rollouts total     0
Train Time (s)               31.81351183867082
(Previous) Eval Time (s)     9.966473799198866
Sample Time (s)              23.015888893045485
Epoch Time (s)               64.79587453091517
Total Train Time (s)         5618.7912335763685
Epoch                        93
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:36:22.444640 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #93 | Epoch Duration: 65.54251909255981
2020-01-11 01:36:22.444801 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #93 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017859295
Z variance train             0.0012236324
KL Divergence                14.431528
KL Loss                      1.4431528
QF Loss                      310.47638
VF Loss                      76.23008
Policy Loss                  -956.6449
Q Predictions Mean           960.8329
Q Predictions Std            476.5083
Q Predictions Max            1499.5713
Q Predictions Min            -2.6768885
V Predictions Mean           959.72003
V Predictions Std            475.46234
V Predictions Max            1494.0891
V Predictions Min            -5.759401
Log Pis Mean                 -0.102732584
Log Pis Std                  2.1646538
Log Pis Max                  10.677504
Log Pis Min                  -6.324951
Policy mu Mean               0.10966608
Policy mu Std                0.94623625
Policy mu Max                2.7924013
Policy mu Min                -2.6524963
Policy log std Mean          -0.50290996
Policy log std Std           0.23769008
Policy log std Max           0.08944374
Policy log std Min           -1.4772
Z mean eval                  0.013829392
Z variance eval              0.0010933122
total_rewards                [1098.97335723 1115.64045151 1163.52516359 1198.10772951 2010.81108863
 1129.18321116 1750.12133988  863.61018885 1086.48041612 1385.25478075]
total_rewards_mean           1280.1707727228236
total_rewards_std            328.6047237543722
total_rewards_max            2010.811088630986
total_rewards_min            863.610188850211
Number of train steps total  95000
Number of env steps total    477000
Number of rollouts total     0
Train Time (s)               33.25271926727146
(Previous) Eval Time (s)     10.712838226929307
Sample Time (s)              21.660434399265796
Epoch Time (s)               65.62599189346656
Total Train Time (s)         5686.169601794332
Epoch                        94
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:37:29.825027 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #94 | Epoch Duration: 67.38009643554688
2020-01-11 01:37:29.825207 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #94 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018138617
Z variance train             0.0010951319
KL Divergence                14.7215805
KL Loss                      1.4721581
QF Loss                      404.79877
VF Loss                      353.41006
Policy Loss                  -922.0232
Q Predictions Mean           924.6403
Q Predictions Std            483.24344
Q Predictions Max            1503.9126
Q Predictions Min            1.5329049
V Predictions Mean           916.9834
V Predictions Std            475.2736
V Predictions Max            1473.274
V Predictions Min            -0.72471243
Log Pis Mean                 0.25277364
Log Pis Std                  2.2370248
Log Pis Max                  8.93886
Log Pis Min                  -3.7883162
Policy mu Mean               -0.121196
Policy mu Std                0.9763951
Policy mu Max                2.884083
Policy mu Min                -3.0474718
Policy log std Mean          -0.5394779
Policy log std Std           0.27804032
Policy log std Max           0.04213476
Policy log std Min           -2.8299005
Z mean eval                  0.021651944
Z variance eval              0.0009470541
total_rewards                [ 810.46560497  808.60919776 1040.99631882  975.90939662 1133.88825862
  916.22904852 1423.02066593 1411.47959028  809.91805247  926.01793828]
total_rewards_mean           1025.6534072265633
total_rewards_std            219.78259161003186
total_rewards_max            1423.020665933415
total_rewards_min            808.6091977587329
Number of train steps total  96000
Number of env steps total    482000
Number of rollouts total     0
Train Time (s)               33.71264647319913
(Previous) Eval Time (s)     12.466601382941008
Sample Time (s)              23.471799463499337
Epoch Time (s)               69.65104731963947
Total Train Time (s)         5753.026650275104
Epoch                        95
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:38:36.685287 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #95 | Epoch Duration: 66.85990810394287
2020-01-11 01:38:36.685586 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #95 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06886276
Z variance train             0.00065710203
KL Divergence                15.951253
KL Loss                      1.5951253
QF Loss                      2165.5723
VF Loss                      113.55574
Policy Loss                  -929.61725
Q Predictions Mean           921.537
Q Predictions Std            489.54715
Q Predictions Max            1518.7256
Q Predictions Min            -5.215741
V Predictions Mean           924.5666
V Predictions Std            488.75717
V Predictions Max            1510.3959
V Predictions Min            -1.1582923
Log Pis Mean                 0.16443692
Log Pis Std                  2.254801
Log Pis Max                  7.483056
Log Pis Min                  -4.9655495
Policy mu Mean               0.12006706
Policy mu Std                0.96220016
Policy mu Max                2.431352
Policy mu Min                -2.8178074
Policy log std Mean          -0.5234497
Policy log std Std           0.26318198
Policy log std Max           0.056001604
Policy log std Min           -2.3880308
Z mean eval                  0.022966508
Z variance eval              0.0010918772
total_rewards                [1198.72644799 1183.55949719 1668.99107119 1792.64522713 2204.16901574
 1696.044638   1220.4940331  2112.01204799 1434.26728619 1636.87429136]
total_rewards_mean           1614.7783555862802
total_rewards_std            344.003494673982
total_rewards_max            2204.1690157353255
total_rewards_min            1183.55949719388
Number of train steps total  97000
Number of env steps total    487000
Number of rollouts total     0
Train Time (s)               33.836236209608614
(Previous) Eval Time (s)     9.675077143125236
Sample Time (s)              24.31315773818642
Epoch Time (s)               67.82447109092027
Total Train Time (s)         5826.952252194285
Epoch                        96
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:39:50.612519 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #96 | Epoch Duration: 73.9267508983612
2020-01-11 01:39:50.612764 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #96 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03567039
Z variance train             0.0007874484
KL Divergence                15.631966
KL Loss                      1.5631965
QF Loss                      488.1927
VF Loss                      217.98645
Policy Loss                  -954.1416
Q Predictions Mean           950.42194
Q Predictions Std            490.33347
Q Predictions Max            1517.2834
Q Predictions Min            -18.004505
V Predictions Mean           958.8661
V Predictions Std            487.4953
V Predictions Max            1532.365
V Predictions Min            -11.519532
Log Pis Mean                 0.04435505
Log Pis Std                  2.168882
Log Pis Max                  6.5609894
Log Pis Min                  -7.8746643
Policy mu Mean               0.042441454
Policy mu Std                0.9482875
Policy mu Max                3.0335221
Policy mu Min                -2.6882374
Policy log std Mean          -0.5229489
Policy log std Std           0.23791681
Policy log std Max           0.057401985
Policy log std Min           -1.3074883
Z mean eval                  0.0117344055
Z variance eval              0.0012394619
total_rewards                [1031.0293527  1040.10098418 1152.42034316 1117.5631509  1072.29004639
 1158.1505026  1093.39467724 1086.24699005 1691.67325605 1031.7149575 ]
total_rewards_mean           1147.4584260758872
total_rewards_std            186.54767859111558
total_rewards_max            1691.6732560459147
total_rewards_min            1031.0293526990413
Number of train steps total  98000
Number of env steps total    492000
Number of rollouts total     0
Train Time (s)               33.81611088523641
(Previous) Eval Time (s)     15.776909321080893
Sample Time (s)              25.25420886138454
Epoch Time (s)               74.84722906770185
Total Train Time (s)         5896.782498312648
Epoch                        97
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:41:00.444836 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #97 | Epoch Duration: 69.83192205429077
2020-01-11 01:41:00.445020 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #97 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04794135
Z variance train             0.0008316368
KL Divergence                15.545271
KL Loss                      1.5545272
QF Loss                      310.09665
VF Loss                      67.42382
Policy Loss                  -859.08356
Q Predictions Mean           857.1975
Q Predictions Std            523.0993
Q Predictions Max            1504.4767
Q Predictions Min            0.78168625
V Predictions Mean           860.15405
V Predictions Std            522.5147
V Predictions Max            1502.8868
V Predictions Min            -1.565119
Log Pis Mean                 0.20794436
Log Pis Std                  2.4024534
Log Pis Max                  14.04647
Log Pis Min                  -5.453374
Policy mu Mean               0.082537435
Policy mu Std                0.99803865
Policy mu Max                2.5659482
Policy mu Min                -3.717324
Policy log std Mean          -0.4977709
Policy log std Std           0.24735421
Policy log std Max           -0.050432533
Policy log std Min           -2.1671329
Z mean eval                  0.016070912
Z variance eval              0.002277123
total_rewards                [ 970.93289687  737.90312944  756.30074998  808.39818128  738.84852541
  764.79789354  747.94155705  824.02960986  763.8432846  1001.84675715]
total_rewards_mean           811.4842585189823
total_rewards_std            91.67931323048276
total_rewards_max            1001.8467571467795
total_rewards_min            737.9031294362889
Number of train steps total  99000
Number of env steps total    497000
Number of rollouts total     0
Train Time (s)               33.32095331698656
(Previous) Eval Time (s)     10.761138008441776
Sample Time (s)              22.761999771930277
Epoch Time (s)               66.84409109735861
Total Train Time (s)         5960.977595235221
Epoch                        98
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:42:04.642387 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #98 | Epoch Duration: 64.19719910621643
2020-01-11 01:42:04.642705 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #98 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018149147
Z variance train             0.0017917445
KL Divergence                13.825418
KL Loss                      1.3825419
QF Loss                      691.9581
VF Loss                      274.33353
Policy Loss                  -995.7742
Q Predictions Mean           999.8718
Q Predictions Std            458.8944
Q Predictions Max            1520.8417
Q Predictions Min            -3.381932
V Predictions Mean           999.08997
V Predictions Std            455.8987
V Predictions Max            1531.1494
V Predictions Min            -5.1862965
Log Pis Mean                 0.23543598
Log Pis Std                  2.3372786
Log Pis Max                  7.480425
Log Pis Min                  -5.125511
Policy mu Mean               0.11607114
Policy mu Std                0.99426603
Policy mu Max                2.7553232
Policy mu Min                -2.5973055
Policy log std Mean          -0.52305984
Policy log std Std           0.23712839
Policy log std Max           0.035289466
Policy log std Min           -1.7541351
Z mean eval                  0.012622738
Z variance eval              0.0011727272
total_rewards                [1053.41895598 1124.79219607 1108.79332268  856.82291657 1354.29795621
 1208.43389295  393.49938217  795.04946884  865.47380326  859.43781434]
total_rewards_mean           962.0019709069032
total_rewards_std            255.5383168921733
total_rewards_max            1354.2979562126013
total_rewards_min            393.4993821667225
Number of train steps total  100000
Number of env steps total    502000
Number of rollouts total     0
Train Time (s)               34.16481985012069
(Previous) Eval Time (s)     8.113880421966314
Sample Time (s)              24.35885852528736
Epoch Time (s)               66.63755879737437
Total Train Time (s)         6029.260368510149
Epoch                        99
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:43:12.926915 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #99 | Epoch Duration: 68.28403043746948
2020-01-11 01:43:12.927104 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #99 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012731562
Z variance train             0.0011949895
KL Divergence                14.802018
KL Loss                      1.4802018
QF Loss                      221.15836
VF Loss                      598.1226
Policy Loss                  -857.20605
Q Predictions Mean           854.57666
Q Predictions Std            530.5059
Q Predictions Max            1479.5503
Q Predictions Min            -2.0196698
V Predictions Mean           864.32983
V Predictions Std            532.27405
V Predictions Max            1489.5452
V Predictions Min            -0.87474144
Log Pis Mean                 0.05592817
Log Pis Std                  2.3937132
Log Pis Max                  10.335213
Log Pis Min                  -5.83091
Policy mu Mean               0.025314668
Policy mu Std                0.93900675
Policy mu Max                3.0524676
Policy mu Min                -2.7970018
Policy log std Mean          -0.4980363
Policy log std Std           0.24881119
Policy log std Max           0.030123949
Policy log std Min           -1.5395782
Z mean eval                  0.010627092
Z variance eval              0.0010576872
total_rewards                [1081.04033697 1126.9291906  1066.32017191  839.21027302  796.21651442
 1087.02433734 1101.1804578  1101.93953252  775.61349118 1104.37412912]
total_rewards_mean           1007.9848434870686
total_rewards_std            135.37578870692928
total_rewards_max            1126.9291906032329
total_rewards_min            775.6134911755183
Number of train steps total  101000
Number of env steps total    507000
Number of rollouts total     0
Train Time (s)               33.75759833958
(Previous) Eval Time (s)     9.760002400260419
Sample Time (s)              23.202021580655128
Epoch Time (s)               66.71962232049555
Total Train Time (s)         6095.658438066021
Epoch                        100
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:44:19.327143 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #100 | Epoch Duration: 66.39988040924072
2020-01-11 01:44:19.327380 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #100 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010745599
Z variance train             0.0010647671
KL Divergence                15.129033
KL Loss                      1.5129033
QF Loss                      224.59308
VF Loss                      102.225815
Policy Loss                  -983.4997
Q Predictions Mean           981.09705
Q Predictions Std            461.38846
Q Predictions Max            1502.7727
Q Predictions Min            -2.1860068
V Predictions Mean           981.1459
V Predictions Std            461.70706
V Predictions Max            1496.8069
V Predictions Min            -4.3754644
Log Pis Mean                 0.19917378
Log Pis Std                  2.1216347
Log Pis Max                  5.905014
Log Pis Min                  -6.0393095
Policy mu Mean               0.041675553
Policy mu Std                0.9586781
Policy mu Max                2.0890608
Policy mu Min                -2.7547505
Policy log std Mean          -0.52827066
Policy log std Std           0.22823149
Policy log std Max           0.07673365
Policy log std Min           -1.7429187
Z mean eval                  0.009477219
Z variance eval              0.0018274244
total_rewards                [2380.82987256 1089.06667126 2735.36109594 1925.35005476 1503.42111913
  917.8726716  1064.16163616 1096.99631729 1143.6499148   836.02629137]
total_rewards_mean           1469.273564487004
total_rewards_std            624.6137590778219
total_rewards_max            2735.361095944931
total_rewards_min            836.0262913689496
Number of train steps total  102000
Number of env steps total    512000
Number of rollouts total     0
Train Time (s)               33.36952882958576
(Previous) Eval Time (s)     9.439816783182323
Sample Time (s)              22.500459812115878
Epoch Time (s)               65.30980542488396
Total Train Time (s)         6165.670403817669
Epoch                        101
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:45:29.341404 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #101 | Epoch Duration: 70.0138771533966
2020-01-11 01:45:29.341598 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #101 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008847183
Z variance train             0.0019921542
KL Divergence                13.3415
KL Loss                      1.3341501
QF Loss                      220.8188
VF Loss                      125.787476
Policy Loss                  -962.3565
Q Predictions Mean           960.0532
Q Predictions Std            472.4936
Q Predictions Max            1487.3656
Q Predictions Min            -3.6634276
V Predictions Mean           968.9022
V Predictions Std            476.40802
V Predictions Max            1505.0991
V Predictions Min            -18.767315
Log Pis Mean                 0.011219576
Log Pis Std                  2.1681519
Log Pis Max                  8.104784
Log Pis Min                  -5.630805
Policy mu Mean               0.0033746052
Policy mu Std                0.92211115
Policy mu Max                2.2906702
Policy mu Min                -2.7298732
Policy log std Mean          -0.51415545
Policy log std Std           0.25229496
Policy log std Max           0.0747931
Policy log std Min           -1.3646758
Z mean eval                  0.021660987
Z variance eval              0.0019831683
total_rewards                [1486.84098754 2029.48252211 1177.16776616 2230.76969192 1161.94119712
 1218.35822212 1300.35902147  992.27560116 1238.70524369 1215.85482417]
total_rewards_mean           1405.1755077454586
total_rewards_std            383.2900876246911
total_rewards_max            2230.7696919173277
total_rewards_min            992.2756011555817
Number of train steps total  103000
Number of env steps total    517000
Number of rollouts total     0
Train Time (s)               34.31761211436242
(Previous) Eval Time (s)     14.143534916918725
Sample Time (s)              24.187862779945135
Epoch Time (s)               72.64900981122628
Total Train Time (s)         6237.954852198716
Epoch                        102
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:46:41.627169 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #102 | Epoch Duration: 72.28542304039001
2020-01-11 01:46:41.627401 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #102 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017929986
Z variance train             0.0012380076
KL Divergence                14.512064
KL Loss                      1.4512064
QF Loss                      261.75452
VF Loss                      220.21602
Policy Loss                  -1025.3983
Q Predictions Mean           1021.08405
Q Predictions Std            431.94202
Q Predictions Max            1490.8137
Q Predictions Min            -6.1909366
V Predictions Mean           1033.9553
V Predictions Std            435.79156
V Predictions Max            1509.32
V Predictions Min            1.5803217
Log Pis Mean                 0.003188569
Log Pis Std                  2.1496902
Log Pis Max                  7.5045414
Log Pis Min                  -4.554944
Policy mu Mean               0.05273543
Policy mu Std                0.9507221
Policy mu Max                2.7057173
Policy mu Min                -2.8289225
Policy log std Mean          -0.5000009
Policy log std Std           0.23116581
Policy log std Max           -0.03442976
Policy log std Min           -1.3620254
Z mean eval                  0.018061666
Z variance eval              0.0016015526
total_rewards                [1123.27542204  882.97411062  796.32750657  808.75611302 1149.39192397
  775.28966708  807.04713287  830.17929384  785.72241759 1174.23659774]
total_rewards_mean           913.3200185340696
total_rewards_std            157.15286877439206
total_rewards_max            1174.2365977416982
total_rewards_min            775.2896670806596
Number of train steps total  104000
Number of env steps total    522000
Number of rollouts total     0
Train Time (s)               34.7415113337338
(Previous) Eval Time (s)     13.779544027987868
Sample Time (s)              22.900415294338018
Epoch Time (s)               71.42147065605968
Total Train Time (s)         6304.212262670975
Epoch                        103
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:47:47.886743 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #103 | Epoch Duration: 66.25920343399048
2020-01-11 01:47:47.886938 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #103 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018045453
Z variance train             0.0015321343
KL Divergence                13.97187
KL Loss                      1.3971871
QF Loss                      143.14517
VF Loss                      28.294626
Policy Loss                  -917.3627
Q Predictions Mean           913.36163
Q Predictions Std            510.7743
Q Predictions Max            1482.5435
Q Predictions Min            -7.559407
V Predictions Mean           917.9226
V Predictions Std            510.94925
V Predictions Max            1483.9368
V Predictions Min            -0.11566776
Log Pis Mean                 -0.1409874
Log Pis Std                  2.3216097
Log Pis Max                  7.6011267
Log Pis Min                  -6.743245
Policy mu Mean               0.18212384
Policy mu Std                0.8983779
Policy mu Max                2.493927
Policy mu Min                -2.5537271
Policy log std Mean          -0.46647587
Policy log std Std           0.24525611
Policy log std Max           -0.032290548
Policy log std Min           -2.0126965
Z mean eval                  0.027275309
Z variance eval              0.0017315928
total_rewards                [ 920.13899629 1477.90630306 1139.59190555  803.3044665  1105.85236756
 1091.96167644 1183.09835106 1124.08115542 1076.34791308 1142.77055172]
total_rewards_mean           1106.505368668791
total_rewards_std            165.6226310246535
total_rewards_max            1477.9063030617597
total_rewards_min            803.3044665024076
Number of train steps total  105000
Number of env steps total    527000
Number of rollouts total     0
Train Time (s)               33.28197474125773
(Previous) Eval Time (s)     8.616980074904859
Sample Time (s)              23.020951377227902
Epoch Time (s)               64.91990619339049
Total Train Time (s)         6370.758280471433
Epoch                        104
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:48:54.434533 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #104 | Epoch Duration: 66.54744601249695
2020-01-11 01:48:54.434708 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #104 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027328696
Z variance train             0.001758058
KL Divergence                13.716352
KL Loss                      1.3716353
QF Loss                      216.89896
VF Loss                      112.12624
Policy Loss                  -979.4075
Q Predictions Mean           981.2284
Q Predictions Std            468.57178
Q Predictions Max            1517.9386
Q Predictions Min            5.524415
V Predictions Mean           975.57056
V Predictions Std            464.79117
V Predictions Max            1506.1978
V Predictions Min            -1.3507693
Log Pis Mean                 0.28185996
Log Pis Std                  2.1859288
Log Pis Max                  10.155451
Log Pis Min                  -4.083769
Policy mu Mean               0.1519512
Policy mu Std                0.9747481
Policy mu Max                2.7047873
Policy mu Min                -2.7454667
Policy log std Mean          -0.51879615
Policy log std Std           0.22896229
Policy log std Max           -0.046785444
Policy log std Min           -1.7922152
Z mean eval                  0.019482056
Z variance eval              0.0016099891
total_rewards                [ 762.30619344  868.44781794  817.59831327 1089.08628722  806.37416036
  885.85931568  892.85491258  933.26663542 1574.17283794 1004.64277602]
total_rewards_mean           963.4609249862795
total_rewards_std            223.1162254600721
total_rewards_max            1574.1728379358337
total_rewards_min            762.3061934428648
Number of train steps total  106000
Number of env steps total    532000
Number of rollouts total     0
Train Time (s)               34.14280361775309
(Previous) Eval Time (s)     10.24418007908389
Sample Time (s)              23.838899445254356
Epoch Time (s)               68.22588314209133
Total Train Time (s)         6436.753278219141
Epoch                        105
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:50:00.432125 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #105 | Epoch Duration: 65.99725317955017
2020-01-11 01:50:00.432420 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #105 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019384975
Z variance train             0.001609223
KL Divergence                13.90644
KL Loss                      1.390644
QF Loss                      499.0935
VF Loss                      229.6997
Policy Loss                  -972.93365
Q Predictions Mean           965.25507
Q Predictions Std            493.30667
Q Predictions Max            1500.6
Q Predictions Min            0.10610901
V Predictions Mean           971.6338
V Predictions Std            493.27808
V Predictions Max            1487.0618
V Predictions Min            -4.3692403
Log Pis Mean                 0.21251963
Log Pis Std                  2.3802717
Log Pis Max                  12.9635315
Log Pis Min                  -8.335793
Policy mu Mean               0.22220965
Policy mu Std                0.9496714
Policy mu Max                2.7015574
Policy mu Min                -4.388223
Policy log std Mean          -0.52017844
Policy log std Std           0.2540037
Policy log std Max           0.019965827
Policy log std Min           -3.0706735
Z mean eval                  0.012951192
Z variance eval              0.0018327773
total_rewards                [1139.72297691 1058.13214405 1211.37689463 1198.3937168   922.90527293
  995.2089207  1032.58918588 1160.15421108 1108.21646959 1042.06374833]
total_rewards_mean           1086.8763540907378
total_rewards_std            88.10519102582708
total_rewards_max            1211.3768946292867
total_rewards_min            922.9052729293337
Number of train steps total  107000
Number of env steps total    537000
Number of rollouts total     0
Train Time (s)               33.069417480845004
(Previous) Eval Time (s)     8.015081253834069
Sample Time (s)              24.740153032820672
Epoch Time (s)               65.82465176749974
Total Train Time (s)         6504.712927740067
Epoch                        106
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:51:08.397144 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #106 | Epoch Duration: 67.96456027030945
2020-01-11 01:51:08.397329 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #106 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012617676
Z variance train             0.001833617
KL Divergence                13.450167
KL Loss                      1.3450167
QF Loss                      759.28174
VF Loss                      184.43983
Policy Loss                  -991.39764
Q Predictions Mean           987.5134
Q Predictions Std            483.28915
Q Predictions Max            1502.1486
Q Predictions Min            -2.3341398
V Predictions Mean           993.27954
V Predictions Std            483.37042
V Predictions Max            1500.9554
V Predictions Min            -5.1127625
Log Pis Mean                 0.37622398
Log Pis Std                  2.5568733
Log Pis Max                  11.339369
Log Pis Min                  -9.890125
Policy mu Mean               0.15554148
Policy mu Std                1.0392725
Policy mu Max                2.9970255
Policy mu Min                -3.689248
Policy log std Mean          -0.49208865
Policy log std Std           0.21747003
Policy log std Max           -0.047822267
Policy log std Min           -1.2452459
Z mean eval                  0.011603707
Z variance eval              0.0016242331
total_rewards                [ 760.54749602  925.75947125 1252.28330473  706.1623829  1020.79460553
  890.70960883 1212.69989254  730.90157547  707.57243803  990.25120886]
total_rewards_mean           919.7681984139017
total_rewards_std            190.8156383818579
total_rewards_max            1252.2833047331062
total_rewards_min            706.1623828977014
Number of train steps total  108000
Number of env steps total    542000
Number of rollouts total     0
Train Time (s)               31.593544751871377
(Previous) Eval Time (s)     10.154605692252517
Sample Time (s)              22.15481018135324
Epoch Time (s)               63.902960625477135
Total Train Time (s)         6566.410501252394
Epoch                        107
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:52:10.093063 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #107 | Epoch Duration: 61.695589780807495
2020-01-11 01:52:10.093232 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #107 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010829398
Z variance train             0.0016203185
KL Divergence                13.802398
KL Loss                      1.3802398
QF Loss                      489.73624
VF Loss                      128.92796
Policy Loss                  -967.3972
Q Predictions Mean           971.15906
Q Predictions Std            497.86884
Q Predictions Max            1503.4077
Q Predictions Min            -0.3071857
V Predictions Mean           967.0712
V Predictions Std            496.78827
V Predictions Max            1491.3262
V Predictions Min            0.976771
Log Pis Mean                 -0.123985104
Log Pis Std                  2.0737488
Log Pis Max                  7.3593416
Log Pis Min                  -7.769611
Policy mu Mean               -0.033286553
Policy mu Std                0.92722505
Policy mu Max                2.9589982
Policy mu Min                -2.6603951
Policy log std Mean          -0.5194501
Policy log std Std           0.2494176
Policy log std Max           0.03711191
Policy log std Min           -2.4801733
Z mean eval                  0.0072403015
Z variance eval              0.0015764972
total_rewards                [1184.22699996 1099.4267088  1006.15147707 1218.75750837 1131.9265278
 1526.81988576 1603.66466617 1139.33548132 1125.8603057   880.27686892]
total_rewards_mean           1191.6446429863577
total_rewards_std            208.17898673669035
total_rewards_max            1603.6646661650022
total_rewards_min            880.276868922361
Number of train steps total  109000
Number of env steps total    547000
Number of rollouts total     0
Train Time (s)               31.85256846016273
(Previous) Eval Time (s)     7.946938368026167
Sample Time (s)              22.916978663299233
Epoch Time (s)               62.71648549148813
Total Train Time (s)         6632.811935564037
Epoch                        108
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:53:16.496962 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #108 | Epoch Duration: 66.40355181694031
2020-01-11 01:53:16.497229 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #108 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008448534
Z variance train             0.0015779635
KL Divergence                13.890661
KL Loss                      1.3890661
QF Loss                      131.78809
VF Loss                      80.18514
Policy Loss                  -1013.1224
Q Predictions Mean           1009.84503
Q Predictions Std            479.7524
Q Predictions Max            1518.4558
Q Predictions Min            -2.3330834
V Predictions Mean           1011.3644
V Predictions Std            479.6034
V Predictions Max            1529.8358
V Predictions Min            -2.988908
Log Pis Mean                 0.31016046
Log Pis Std                  2.205797
Log Pis Max                  9.19971
Log Pis Min                  -4.7290864
Policy mu Mean               0.18374185
Policy mu Std                0.95442104
Policy mu Max                2.5133212
Policy mu Min                -2.8305504
Policy log std Mean          -0.5472869
Policy log std Std           0.23303412
Policy log std Max           0.053530037
Policy log std Min           -1.5770117
Z mean eval                  0.008200803
Z variance eval              0.0015558015
total_rewards                [801.49261531 904.15435311 702.50098206 938.49129322 688.22085034
 696.40087664 896.26149366 833.60437523 682.54209654 831.19552244]
total_rewards_mean           797.4864458549042
total_rewards_std            93.7365883673198
total_rewards_max            938.491293224179
total_rewards_min            682.5420965361272
Number of train steps total  110000
Number of env steps total    552000
Number of rollouts total     0
Train Time (s)               31.700272218789905
(Previous) Eval Time (s)     11.633648635819554
Sample Time (s)              22.801928830333054
Epoch Time (s)               66.13584968494251
Total Train Time (s)         6694.758695269469
Epoch                        109
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:54:18.445168 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #109 | Epoch Duration: 61.94774055480957
2020-01-11 01:54:18.445413 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #109 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008092205
Z variance train             0.0015548945
KL Divergence                13.844961
KL Loss                      1.3844961
QF Loss                      691.4214
VF Loss                      160.86823
Policy Loss                  -1033.1864
Q Predictions Mean           1033.2225
Q Predictions Std            460.27295
Q Predictions Max            1513.2151
Q Predictions Min            1.7893885
V Predictions Mean           1030.9226
V Predictions Std            457.79642
V Predictions Max            1507.943
V Predictions Min            2.564065
Log Pis Mean                 0.26034713
Log Pis Std                  2.3488784
Log Pis Max                  12.682526
Log Pis Min                  -7.245051
Policy mu Mean               0.07682493
Policy mu Std                1.0151522
Policy mu Max                3.5277069
Policy mu Min                -2.7887485
Policy log std Mean          -0.5245591
Policy log std Std           0.20884138
Policy log std Max           -0.045301497
Policy log std Min           -1.4345143
Z mean eval                  0.016714945
Z variance eval              0.0016846436
total_rewards                [ 802.96543593 1246.0451244   964.67585912 1263.02579462 1603.07140317
 2154.16954287 2054.17811607  841.69319733  811.0983756  1143.41190862]
total_rewards_mean           1288.4334757728175
total_rewards_std            471.8324152917686
total_rewards_max            2154.16954287151
total_rewards_min            802.9654359293417
Number of train steps total  111000
Number of env steps total    557000
Number of rollouts total     0
Train Time (s)               31.529237180016935
(Previous) Eval Time (s)     7.445179554168135
Sample Time (s)              22.307517387904227
Epoch Time (s)               61.2819341220893
Total Train Time (s)         6760.718669323251
Epoch                        110
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:55:24.409272 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #110 | Epoch Duration: 65.96370077133179
2020-01-11 01:55:24.409479 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #110 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016989443
Z variance train             0.0016737959
KL Divergence                13.682011
KL Loss                      1.3682011
QF Loss                      295.04462
VF Loss                      90.42953
Policy Loss                  -951.11804
Q Predictions Mean           948.6094
Q Predictions Std            508.60175
Q Predictions Max            1501.9841
Q Predictions Min            -15.134637
V Predictions Mean           950.6682
V Predictions Std            508.07608
V Predictions Max            1505.6381
V Predictions Min            -1.0697842
Log Pis Mean                 -0.042695656
Log Pis Std                  2.2331426
Log Pis Max                  9.966654
Log Pis Min                  -5.6170077
Policy mu Mean               0.10561854
Policy mu Std                0.9156268
Policy mu Max                2.519543
Policy mu Min                -2.7819824
Policy log std Mean          -0.48613802
Policy log std Std           0.23123394
Policy log std Max           0.09880236
Policy log std Min           -1.6014508
Z mean eval                  0.04268862
Z variance eval              0.0011291627
total_rewards                [ 848.86560949  824.35284993  799.78178822  940.67419065  779.21194508
 1032.98221122  955.33891964  933.63083592  834.4258445   893.72719935]
total_rewards_mean           884.2991394003593
total_rewards_std            76.40477503973841
total_rewards_max            1032.9822112173936
total_rewards_min            779.2119450837499
Number of train steps total  112000
Number of env steps total    562000
Number of rollouts total     0
Train Time (s)               31.45728185493499
(Previous) Eval Time (s)     12.126643673982471
Sample Time (s)              22.30430812621489
Epoch Time (s)               65.88823365513235
Total Train Time (s)         6822.522842367645
Epoch                        111
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:56:26.212460 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #111 | Epoch Duration: 61.80284309387207
2020-01-11 01:56:26.212623 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #111 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.009135414
Z variance train             0.0013981713
KL Divergence                14.003866
KL Loss                      1.4003867
QF Loss                      321.65356
VF Loss                      129.5885
Policy Loss                  -1061.7946
Q Predictions Mean           1058.8318
Q Predictions Std            450.30643
Q Predictions Max            1537.9702
Q Predictions Min            -25.696146
V Predictions Mean           1060.4144
V Predictions Std            451.0991
V Predictions Max            1539.2686
V Predictions Min            0.2953688
Log Pis Mean                 0.013834212
Log Pis Std                  2.0880165
Log Pis Max                  7.6142282
Log Pis Min                  -4.228244
Policy mu Mean               0.0764847
Policy mu Std                0.96776295
Policy mu Max                2.7572238
Policy mu Min                -2.8520598
Policy log std Mean          -0.531804
Policy log std Std           0.22034629
Policy log std Max           -0.08760491
Policy log std Min           -1.3813384
Z mean eval                  0.009055641
Z variance eval              0.0016115576
total_rewards                [867.6121118  819.08610971 793.26626337 749.48555734 900.25007791
 775.73692357 953.90158756 981.47990175 952.60033006 832.66367326]
total_rewards_mean           862.6082536320897
total_rewards_std            77.42609367552701
total_rewards_max            981.4799017475374
total_rewards_min            749.4855573355663
Number of train steps total  113000
Number of env steps total    567000
Number of rollouts total     0
Train Time (s)               31.90718658687547
(Previous) Eval Time (s)     8.040906261187047
Sample Time (s)              22.84487554524094
Epoch Time (s)               62.792968393303454
Total Train Time (s)         6884.801952536218
Epoch                        112
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:57:28.495923 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #112 | Epoch Duration: 62.283164262771606
2020-01-11 01:57:28.496168 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #112 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011062532
Z variance train             0.0016459872
KL Divergence                13.572202
KL Loss                      1.3572202
QF Loss                      539.84546
VF Loss                      274.71826
Policy Loss                  -1041.6558
Q Predictions Mean           1033.0587
Q Predictions Std            453.85544
Q Predictions Max            1493.1555
Q Predictions Min            -14.646104
V Predictions Mean           1046.5106
V Predictions Std            455.56097
V Predictions Max            1505.0175
V Predictions Min            -17.428938
Log Pis Mean                 0.048997186
Log Pis Std                  2.2342577
Log Pis Max                  10.909004
Log Pis Min                  -4.709262
Policy mu Mean               -0.06394284
Policy mu Std                0.9552868
Policy mu Max                2.6709878
Policy mu Min                -2.9991903
Policy log std Mean          -0.53993183
Policy log std Std           0.23929082
Policy log std Max           -0.0038309395
Policy log std Min           -2.1355834
Z mean eval                  0.008140296
Z variance eval              0.0016350994
total_rewards                [1281.81980268 1137.31861802 1671.95708321  928.0485219   896.86039362
  974.03900847  985.43084841  989.34906392 1284.68939328  925.30125252]
total_rewards_mean           1107.4813986039183
total_rewards_std            231.8889902696665
total_rewards_max            1671.9570832095817
total_rewards_min            896.860393615103
Number of train steps total  114000
Number of env steps total    572000
Number of rollouts total     0
Train Time (s)               31.94055645726621
(Previous) Eval Time (s)     7.530748903285712
Sample Time (s)              23.137207354418933
Epoch Time (s)               62.60851271497086
Total Train Time (s)         6949.604610180017
Epoch                        113
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:58:33.301581 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #113 | Epoch Duration: 64.80521893501282
2020-01-11 01:58:33.301777 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #113 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008288813
Z variance train             0.0016486241
KL Divergence                13.617985
KL Loss                      1.3617985
QF Loss                      2001.7429
VF Loss                      56.82103
Policy Loss                  -1020.3516
Q Predictions Mean           1015.3799
Q Predictions Std            476.88037
Q Predictions Max            1521.6047
Q Predictions Min            -0.1374065
V Predictions Mean           1021.7202
V Predictions Std            475.31165
V Predictions Max            1523.7004
V Predictions Min            2.4700902
Log Pis Mean                 0.18895474
Log Pis Std                  2.0905404
Log Pis Max                  11.214855
Log Pis Min                  -4.331553
Policy mu Mean               0.036425058
Policy mu Std                0.9887475
Policy mu Max                2.8246982
Policy mu Min                -2.991194
Policy log std Mean          -0.49842724
Policy log std Std           0.21370628
Policy log std Max           0.035796106
Policy log std Min           -1.4759556
Z mean eval                  0.015475534
Z variance eval              0.0013729368
total_rewards                [1677.44637227  958.68321869  961.84656614 1440.52658615 1459.64932547
  887.19238969  968.19748319 1478.05502065  972.80825869 1153.14542592]
total_rewards_mean           1195.755064685905
total_rewards_std            273.98969730715925
total_rewards_max            1677.44637227445
total_rewards_min            887.1923896924401
Number of train steps total  115000
Number of env steps total    577000
Number of rollouts total     0
Train Time (s)               31.790207100100815
(Previous) Eval Time (s)     9.727124707773328
Sample Time (s)              22.560329841915518
Epoch Time (s)               64.07766164978966
Total Train Time (s)         7014.309342572931
Epoch                        114
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:59:38.007949 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #114 | Epoch Duration: 64.70601773262024
2020-01-11 01:59:38.008131 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #114 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015547663
Z variance train             0.0013700814
KL Divergence                14.0515995
KL Loss                      1.40516
QF Loss                      287.18512
VF Loss                      78.48245
Policy Loss                  -1011.66205
Q Predictions Mean           1008.13184
Q Predictions Std            510.14926
Q Predictions Max            1515.8433
Q Predictions Min            -5.0808
V Predictions Mean           1014.0708
V Predictions Std            511.37708
V Predictions Max            1510.49
V Predictions Min            0.37170532
Log Pis Mean                 -0.20607594
Log Pis Std                  1.9849283
Log Pis Max                  7.4775534
Log Pis Min                  -4.1443925
Policy mu Mean               0.054511327
Policy mu Std                0.8475437
Policy mu Max                3.1883266
Policy mu Min                -2.6019433
Policy log std Mean          -0.49054408
Policy log std Std           0.2257095
Policy log std Max           -0.058217615
Policy log std Min           -1.7167727
Z mean eval                  0.014993245
Z variance eval              0.0014653915
total_rewards                [1435.15428169  820.26897686  866.18700241 1902.4692132  1181.27613579
  794.93408225  833.96754469 1131.64166479 1047.67393243 1077.46990812]
total_rewards_mean           1109.1042742234683
total_rewards_std            326.0468409247047
total_rewards_max            1902.4692132021805
total_rewards_min            794.9340822545124
Number of train steps total  116000
Number of env steps total    582000
Number of rollouts total     0
Train Time (s)               31.322141360957175
(Previous) Eval Time (s)     10.355155729223043
Sample Time (s)              23.576901051215827
Epoch Time (s)               65.25419814139605
Total Train Time (s)         7078.48516667122
Epoch                        115
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:00:42.185586 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #115 | Epoch Duration: 64.17728352546692
2020-01-11 02:00:42.185895 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #115 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01451539
Z variance train             0.001468579
KL Divergence                13.938511
KL Loss                      1.3938512
QF Loss                      245.79144
VF Loss                      100.586174
Policy Loss                  -992.7171
Q Predictions Mean           989.5813
Q Predictions Std            500.59622
Q Predictions Max            1524.6428
Q Predictions Min            -2.6442692
V Predictions Mean           989.60065
V Predictions Std            495.90366
V Predictions Max            1514.2711
V Predictions Min            5.390441
Log Pis Mean                 0.21993822
Log Pis Std                  2.3564339
Log Pis Max                  11.930284
Log Pis Min                  -4.3432837
Policy mu Mean               -0.00259092
Policy mu Std                0.9796575
Policy mu Max                2.7239077
Policy mu Min                -3.4738917
Policy log std Mean          -0.5216593
Policy log std Std           0.22766137
Policy log std Max           -0.06410721
Policy log std Min           -1.5279131
Z mean eval                  0.009273229
Z variance eval              0.00206452
total_rewards                [1111.98644972 1035.60006304 1238.27061794 1239.91473158 1826.27743152
 1993.06849418 1619.41011631 1095.05145751 1024.56308453 1496.63897356]
total_rewards_mean           1368.0781419887976
total_rewards_std            328.9683607911398
total_rewards_max            1993.0684941769957
total_rewards_min            1024.5630845349986
Number of train steps total  117000
Number of env steps total    587000
Number of rollouts total     0
Train Time (s)               32.01394703518599
(Previous) Eval Time (s)     9.277897550258785
Sample Time (s)              22.013478544540703
Epoch Time (s)               63.30532312998548
Total Train Time (s)         7145.506930813193
Epoch                        116
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:01:49.209388 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #116 | Epoch Duration: 67.02325630187988
2020-01-11 02:01:49.209634 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #116 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.009221818
Z variance train             0.0019789413
KL Divergence                13.236684
KL Loss                      1.3236684
QF Loss                      168.23112
VF Loss                      74.95471
Policy Loss                  -1028.6224
Q Predictions Mean           1028.6199
Q Predictions Std            487.58572
Q Predictions Max            1530.9756
Q Predictions Min            -0.861689
V Predictions Mean           1026.7671
V Predictions Std            485.44928
V Predictions Max            1534.4541
V Predictions Min            1.2374693
Log Pis Mean                 0.060008246
Log Pis Std                  2.2461417
Log Pis Max                  9.123295
Log Pis Min                  -4.4950957
Policy mu Mean               0.12183096
Policy mu Std                0.9527239
Policy mu Max                2.4727228
Policy mu Min                -2.9915226
Policy log std Mean          -0.51585686
Policy log std Std           0.21483397
Policy log std Max           -0.050372154
Policy log std Min           -1.4722829
Z mean eval                  0.016673477
Z variance eval              0.001946444
total_rewards                [ 848.42547586  903.73756898  978.03548575  859.26697477 1244.65548667
  852.29219786  837.34932892  992.12633252 1364.22582809  995.13785719]
total_rewards_mean           987.5252536615277
total_rewards_std            170.8357559200066
total_rewards_max            1364.2258280940725
total_rewards_min            837.3493289173757
Number of train steps total  118000
Number of env steps total    592000
Number of rollouts total     0
Train Time (s)               32.26851281709969
(Previous) Eval Time (s)     12.995484303683043
Sample Time (s)              24.06397003447637
Epoch Time (s)               69.3279671552591
Total Train Time (s)         7210.774957962334
Epoch                        117
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:02:54.479106 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #117 | Epoch Duration: 65.26930952072144
2020-01-11 02:02:54.479371 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #117 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016226519
Z variance train             0.002125504
KL Divergence                13.204731
KL Loss                      1.3204731
QF Loss                      1043.7128
VF Loss                      346.11328
Policy Loss                  -1016.4578
Q Predictions Mean           1011.1964
Q Predictions Std            483.6621
Q Predictions Max            1523.4613
Q Predictions Min            3.2530553
V Predictions Mean           1015.4494
V Predictions Std            482.36826
V Predictions Max            1520.1779
V Predictions Min            2.275794
Log Pis Mean                 -0.07876699
Log Pis Std                  2.1004462
Log Pis Max                  8.503837
Log Pis Min                  -4.980546
Policy mu Mean               0.08329234
Policy mu Std                0.9053098
Policy mu Max                2.2758927
Policy mu Min                -2.9102068
Policy log std Mean          -0.5086896
Policy log std Std           0.22149362
Policy log std Max           0.037820965
Policy log std Min           -1.453189
Z mean eval                  0.058757216
Z variance eval              0.0009230355
total_rewards                [ 730.76809159 1006.85919106  807.98808839  833.62713744  868.52086976
  978.55959487  784.7608058  1026.97854438  762.14905847  995.76230848]
total_rewards_mean           879.5973690246686
total_rewards_std            106.53950947890264
total_rewards_max            1026.9785443794717
total_rewards_min            730.7680915943478
Number of train steps total  119000
Number of env steps total    597000
Number of rollouts total     0
Train Time (s)               31.45408810582012
(Previous) Eval Time (s)     8.936473555862904
Sample Time (s)              22.484086482785642
Epoch Time (s)               62.874648144468665
Total Train Time (s)         7272.924173371866
Epoch                        118
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:03:56.630186 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #118 | Epoch Duration: 62.15067219734192
2020-01-11 02:03:56.630356 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #118 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010931804
Z variance train             0.0017212725
KL Divergence                13.751047
KL Loss                      1.3751048
QF Loss                      2518.4634
VF Loss                      377.49515
Policy Loss                  -1077.3207
Q Predictions Mean           1078.9214
Q Predictions Std            429.3936
Q Predictions Max            1503.7627
Q Predictions Min            -3.7190237
V Predictions Mean           1091.5303
V Predictions Std            432.1722
V Predictions Max            1521.4424
V Predictions Min            -1.8837973
Log Pis Mean                 -0.21515378
Log Pis Std                  1.8923036
Log Pis Max                  7.850074
Log Pis Min                  -4.655223
Policy mu Mean               0.18547674
Policy mu Std                0.85460854
Policy mu Max                2.5870388
Policy mu Min                -3.014444
Policy log std Mean          -0.5453106
Policy log std Std           0.20907035
Policy log std Max           -0.09279969
Policy log std Min           -1.430069
Z mean eval                  0.012085396
Z variance eval              0.0017969297
total_rewards                [1165.96091262 1663.76497942  988.31370779  910.86825532 1014.96234906
 1223.30021179  769.82974238 1238.82025182  873.75449372 1028.39999046]
total_rewards_mean           1087.7974894370695
total_rewards_std            239.9935045382131
total_rewards_max            1663.764979418189
total_rewards_min            769.829742377509
Number of train steps total  120000
Number of env steps total    602000
Number of rollouts total     0
Train Time (s)               32.22008751705289
(Previous) Eval Time (s)     8.212185979355127
Sample Time (s)              23.628883763682097
Epoch Time (s)               64.06115726009011
Total Train Time (s)         7338.607638916001
Epoch                        119
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:05:02.316695 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #119 | Epoch Duration: 65.68618369102478
2020-01-11 02:05:02.316938 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #119 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011970672
Z variance train             0.001778977
KL Divergence                13.660357
KL Loss                      1.3660358
QF Loss                      206.19165
VF Loss                      60.030304
Policy Loss                  -1043.1838
Q Predictions Mean           1043.4774
Q Predictions Std            478.01807
Q Predictions Max            1519.6721
Q Predictions Min            -21.861252
V Predictions Mean           1045.1467
V Predictions Std            477.79724
V Predictions Max            1527.0188
V Predictions Min            -2.6772637
Log Pis Mean                 -0.15610294
Log Pis Std                  2.1155884
Log Pis Max                  7.9033093
Log Pis Min                  -5.350089
Policy mu Mean               0.043104205
Policy mu Std                0.8936925
Policy mu Max                2.4064407
Policy mu Min                -2.7718704
Policy log std Mean          -0.501295
Policy log std Std           0.22287525
Policy log std Max           -0.05186519
Policy log std Min           -1.7888964
Z mean eval                  0.011831638
Z variance eval              0.0017116113
total_rewards                [1142.43588791  944.23003823 1668.88321525 1067.91301149 1142.62645714
 1379.65639854  923.71748611 1021.34486893  857.91446688  843.40694431]
total_rewards_mean           1099.2128774804596
total_rewards_std            243.40272171678808
total_rewards_max            1668.8832152535392
total_rewards_min            843.4069443147115
Number of train steps total  121000
Number of env steps total    607000
Number of rollouts total     0
Train Time (s)               32.66987591981888
(Previous) Eval Time (s)     9.836816066876054
Sample Time (s)              21.942647963296622
Epoch Time (s)               64.44933994999155
Total Train Time (s)         7403.225088127889
Epoch                        120
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:06:06.935377 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #120 | Epoch Duration: 64.61825370788574
2020-01-11 02:06:06.935580 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #120 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0118683595
Z variance train             0.0017128948
KL Divergence                13.917116
KL Loss                      1.3917116
QF Loss                      282.35452
VF Loss                      62.985203
Policy Loss                  -1055.2391
Q Predictions Mean           1051.001
Q Predictions Std            490.9184
Q Predictions Max            1565.3699
Q Predictions Min            -11.997095
V Predictions Mean           1057.0337
V Predictions Std            490.88235
V Predictions Max            1564.0338
V Predictions Min            -9.97756
Log Pis Mean                 -0.23499975
Log Pis Std                  2.1617177
Log Pis Max                  6.923059
Log Pis Min                  -5.2501483
Policy mu Mean               0.045189787
Policy mu Std                0.89145917
Policy mu Max                2.7126646
Policy mu Min                -2.9016523
Policy log std Mean          -0.5412433
Policy log std Std           0.23407833
Policy log std Max           -0.036788553
Policy log std Min           -2.1023076
Z mean eval                  0.01767407
Z variance eval              0.0016832463
total_rewards                [1124.18841713 1325.28796452 1040.84836894 1478.40515231 1082.20065149
  961.208122   1112.01452466 1260.34118245 1263.13284769 1208.52747807]
total_rewards_mean           1185.6154709249117
total_rewards_std            144.4137174601429
total_rewards_max            1478.405152314057
total_rewards_min            961.208121995494
Number of train steps total  122000
Number of env steps total    612000
Number of rollouts total     0
Train Time (s)               31.783707682043314
(Previous) Eval Time (s)     10.00541721796617
Sample Time (s)              22.732796298805624
Epoch Time (s)               64.52192119881511
Total Train Time (s)         7468.762702585198
Epoch                        121
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:07:12.475273 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #121 | Epoch Duration: 65.53948760032654
2020-01-11 02:07:12.475467 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #121 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017513977
Z variance train             0.0016843078
KL Divergence                13.981091
KL Loss                      1.3981091
QF Loss                      440.8786
VF Loss                      125.94873
Policy Loss                  -1036.0515
Q Predictions Mean           1035.9849
Q Predictions Std            484.4045
Q Predictions Max            1519.9005
Q Predictions Min            -2.996539
V Predictions Mean           1042.4412
V Predictions Std            485.39343
V Predictions Max            1525.6715
V Predictions Min            -6.3103323
Log Pis Mean                 0.06647447
Log Pis Std                  2.196917
Log Pis Max                  10.151892
Log Pis Min                  -5.1187773
Policy mu Mean               0.12844642
Policy mu Std                0.94118476
Policy mu Max                2.9590824
Policy mu Min                -2.643815
Policy log std Mean          -0.5328174
Policy log std Std           0.21844201
Policy log std Max           -0.08885679
Policy log std Min           -1.6272638
Z mean eval                  0.012329834
Z variance eval              0.0017302148
total_rewards                [ 995.71491849 1005.33221669  925.55423987  990.21178289 1016.65062101
 1298.72461017  997.92673395  835.66985421 1436.32673363 1226.64386169]
total_rewards_mean           1072.8755572610949
total_rewards_std            176.30856362341683
total_rewards_max            1436.3267336331758
total_rewards_min            835.669854213437
Number of train steps total  123000
Number of env steps total    617000
Number of rollouts total     0
Train Time (s)               32.313166114035994
(Previous) Eval Time (s)     11.022679736837745
Sample Time (s)              23.584591909777373
Epoch Time (s)               66.92043776065111
Total Train Time (s)         7534.365878439043
Epoch                        122
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:08:18.080220 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #122 | Epoch Duration: 65.60460186004639
2020-01-11 02:08:18.080393 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #122 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0129089635
Z variance train             0.0017307943
KL Divergence                13.722155
KL Loss                      1.3722155
QF Loss                      635.80786
VF Loss                      69.57859
Policy Loss                  -1089.138
Q Predictions Mean           1085.6304
Q Predictions Std            458.99582
Q Predictions Max            1528.2812
Q Predictions Min            -4.787218
V Predictions Mean           1085.3481
V Predictions Std            456.61636
V Predictions Max            1523.0677
V Predictions Min            -1.7210218
Log Pis Mean                 -0.053543538
Log Pis Std                  2.1846259
Log Pis Max                  9.933333
Log Pis Min                  -6.101736
Policy mu Mean               0.025762396
Policy mu Std                0.917331
Policy mu Max                3.4539566
Policy mu Min                -2.869881
Policy log std Mean          -0.52169913
Policy log std Std           0.22796501
Policy log std Max           -0.08212507
Policy log std Min           -2.3520281
Z mean eval                  0.015246754
Z variance eval              0.0016154039
total_rewards                [1242.0887118  1169.28458305 1098.29842333  970.04427224 1011.58971346
 1249.17467487 1053.19260164 1154.05729458 1082.53864536 1119.26219718]
total_rewards_mean           1114.9531117513638
total_rewards_std            86.89275209952413
total_rewards_max            1249.174674873941
total_rewards_min            970.0442722430818
Number of train steps total  124000
Number of env steps total    622000
Number of rollouts total     0
Train Time (s)               31.219034072943032
(Previous) Eval Time (s)     9.70650112722069
Sample Time (s)              23.1221858356148
Epoch Time (s)               64.04772103577852
Total Train Time (s)         7598.996479134541
Epoch                        123
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:09:22.712727 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #123 | Epoch Duration: 64.63220429420471
2020-01-11 02:09:22.712888 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #123 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015395123
Z variance train             0.0016244797
KL Divergence                13.915152
KL Loss                      1.3915151
QF Loss                      197.46732
VF Loss                      101.53409
Policy Loss                  -1119.317
Q Predictions Mean           1115.4585
Q Predictions Std            399.31577
Q Predictions Max            1511.0533
Q Predictions Min            3.5539765
V Predictions Mean           1122.3577
V Predictions Std            400.1233
V Predictions Max            1536.6407
V Predictions Min            1.114053
Log Pis Mean                 0.30531174
Log Pis Std                  2.2960312
Log Pis Max                  7.66455
Log Pis Min                  -6.310295
Policy mu Mean               0.088049956
Policy mu Std                1.0101148
Policy mu Max                2.7015157
Policy mu Min                -2.8733459
Policy log std Mean          -0.55193347
Policy log std Std           0.22570477
Policy log std Max           0.040087074
Policy log std Min           -1.3799541
Z mean eval                  0.018248988
Z variance eval              0.001615212
total_rewards                [3091.3024236  1814.37070346 3136.05861814 3178.82015366 3120.52652446
 3030.91416771 1986.54756373 3078.0928091  3041.94961754 2993.06512787]
total_rewards_mean           2847.164770924867
total_rewards_std            477.6431725648466
total_rewards_max            3178.8201536566667
total_rewards_min            1814.3707034579345
Number of train steps total  125000
Number of env steps total    627000
Number of rollouts total     0
Train Time (s)               32.0307574570179
(Previous) Eval Time (s)     10.290649722795933
Sample Time (s)              22.5216928855516
Epoch Time (s)               64.84310006536543
Total Train Time (s)         7681.379150646273
Epoch                        124
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:10:45.097709 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #124 | Epoch Duration: 82.38468503952026
2020-01-11 02:10:45.097896 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #124 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018059835
Z variance train             0.0016155426
KL Divergence                13.847304
KL Loss                      1.3847305
QF Loss                      199.93582
VF Loss                      115.62548
Policy Loss                  -1026.727
Q Predictions Mean           1027.0938
Q Predictions Std            511.29782
Q Predictions Max            1530.3448
Q Predictions Min            -16.421013
V Predictions Mean           1032.9229
V Predictions Std            514.20764
V Predictions Max            1537.3065
V Predictions Min            -3.608399
Log Pis Mean                 -0.2282278
Log Pis Std                  1.9597675
Log Pis Max                  8.105992
Log Pis Min                  -6.0172253
Policy mu Mean               0.04942952
Policy mu Std                0.8547444
Policy mu Max                2.268026
Policy mu Min                -2.70035
Policy log std Mean          -0.5171315
Policy log std Std           0.23748271
Policy log std Max           -0.048618317
Policy log std Min           -2.442593
Z mean eval                  0.022705799
Z variance eval              0.0017171141
total_rewards                [ 897.95830468 1466.61330131  943.91387915 1523.02171503 1165.16729781
  999.72729963 1275.07590261  720.83717253  833.33153805  924.11237068]
total_rewards_mean           1074.9758781480718
total_rewards_std            257.49568548003083
total_rewards_max            1523.0217150297815
total_rewards_min            720.8371725289066
Number of train steps total  126000
Number of env steps total    632000
Number of rollouts total     0
Train Time (s)               31.79499982483685
(Previous) Eval Time (s)     27.831907426938415
Sample Time (s)              23.926759398542345
Epoch Time (s)               83.55366665031761
Total Train Time (s)         7746.586953735445
Epoch                        125
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:11:50.310923 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #125 | Epoch Duration: 65.21285891532898
2020-01-11 02:11:50.311236 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #125 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022087822
Z variance train             0.0017171638
KL Divergence                13.603188
KL Loss                      1.3603188
QF Loss                      178.37726
VF Loss                      59.778786
Policy Loss                  -1085.6147
Q Predictions Mean           1086.7635
Q Predictions Std            466.2519
Q Predictions Max            1547.7196
Q Predictions Min            -0.9122055
V Predictions Mean           1088.7854
V Predictions Std            466.35287
V Predictions Max            1549.8896
V Predictions Min            3.1541278
Log Pis Mean                 -0.083429605
Log Pis Std                  2.11071
Log Pis Max                  10.514832
Log Pis Min                  -8.5966835
Policy mu Mean               0.0044377837
Policy mu Std                0.9272685
Policy mu Max                2.4478002
Policy mu Min                -2.740712
Policy log std Mean          -0.5235311
Policy log std Std           0.21823291
Policy log std Max           -0.024350852
Policy log std Min           -1.3167577
Z mean eval                  0.027093718
Z variance eval              0.0016332308
total_rewards                [1232.29553049 1001.34619582 1057.33657748  990.54198711 1445.59970695
  910.40507342 1007.55399618  931.83650466 1519.85203681 2029.15428172]
total_rewards_mean           1212.5921890646537
total_rewards_std            338.5380222016996
total_rewards_max            2029.1542817231116
total_rewards_min            910.4050734217466
Number of train steps total  127000
Number of env steps total    637000
Number of rollouts total     0
Train Time (s)               31.711685802787542
(Previous) Eval Time (s)     9.49073030706495
Sample Time (s)              23.585667585022748
Epoch Time (s)               64.78808369487524
Total Train Time (s)         7813.051162790041
Epoch                        126
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:12:56.776013 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #126 | Epoch Duration: 66.46455216407776
2020-01-11 02:12:56.776199 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #126 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027351957
Z variance train             0.0016324859
KL Divergence                13.695583
KL Loss                      1.3695583
QF Loss                      161.58911
VF Loss                      96.52931
Policy Loss                  -1049.4938
Q Predictions Mean           1041.0474
Q Predictions Std            475.79773
Q Predictions Max            1516.7845
Q Predictions Min            -21.905752
V Predictions Mean           1044.1725
V Predictions Std            475.17636
V Predictions Max            1517.8745
V Predictions Min            -0.002569884
Log Pis Mean                 -0.020739269
Log Pis Std                  2.3514006
Log Pis Max                  7.8385196
Log Pis Min                  -7.695715
Policy mu Mean               0.066449724
Policy mu Std                0.93088025
Policy mu Max                2.5813413
Policy mu Min                -2.6500175
Policy log std Mean          -0.52150506
Policy log std Std           0.21453507
Policy log std Max           0.04557553
Policy log std Min           -1.3102447
Z mean eval                  0.012843115
Z variance eval              0.0016933011
total_rewards                [1064.44530441  989.45170221 1003.11378628 1255.84439534  935.80663597
  864.47740887  925.91154156  927.7477426   961.57217496 1023.43264149]
total_rewards_mean           995.1803333684662
total_rewards_std            102.33311182777095
total_rewards_max            1255.8443953382994
total_rewards_min            864.4774088694196
Number of train steps total  128000
Number of env steps total    642000
Number of rollouts total     0
Train Time (s)               32.01371492398903
(Previous) Eval Time (s)     11.1668521608226
Sample Time (s)              23.155731444247067
Epoch Time (s)               66.3362985290587
Total Train Time (s)         7876.307691602036
Epoch                        127
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:14:00.034386 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #127 | Epoch Duration: 63.25804305076599
2020-01-11 02:14:00.034567 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #127 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0123462435
Z variance train             0.0016924407
KL Divergence                13.580257
KL Loss                      1.3580258
QF Loss                      256.22903
VF Loss                      80.07342
Policy Loss                  -1100.7764
Q Predictions Mean           1097.5273
Q Predictions Std            474.6948
Q Predictions Max            1546.8074
Q Predictions Min            -23.039097
V Predictions Mean           1099.1545
V Predictions Std            469.70007
V Predictions Max            1536.4891
V Predictions Min            -5.969883
Log Pis Mean                 -0.12799023
Log Pis Std                  2.1039052
Log Pis Max                  8.467161
Log Pis Min                  -4.025258
Policy mu Mean               0.104334675
Policy mu Std                0.9034049
Policy mu Max                3.5620549
Policy mu Min                -2.7611837
Policy log std Mean          -0.5273661
Policy log std Std           0.21659991
Policy log std Max           0.0076779723
Policy log std Min           -1.3160105
Z mean eval                  0.015624769
Z variance eval              0.0016820973
total_rewards                [1007.88707922 1002.4017447  1490.86148528 1119.30237918 1415.09822203
  951.76976872  859.67539289  811.89596691  998.51515215 2046.90859195]
total_rewards_mean           1170.4315783037002
total_rewards_std            359.23577458534027
total_rewards_max            2046.9085919497152
total_rewards_min            811.8959669072943
Number of train steps total  129000
Number of env steps total    647000
Number of rollouts total     0
Train Time (s)               31.793992259074003
(Previous) Eval Time (s)     8.08826394379139
Sample Time (s)              23.521880402695388
Epoch Time (s)               63.40413660556078
Total Train Time (s)         7942.368080222048
Epoch                        128
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:15:06.097769 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #128 | Epoch Duration: 66.0630521774292
2020-01-11 02:15:06.097991 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #128 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015586875
Z variance train             0.0016809234
KL Divergence                13.6012535
KL Loss                      1.3601254
QF Loss                      356.72693
VF Loss                      65.860374
Policy Loss                  -1104.6504
Q Predictions Mean           1098.835
Q Predictions Std            464.39743
Q Predictions Max            1534.7969
Q Predictions Min            -2.285679
V Predictions Mean           1102.739
V Predictions Std            460.22305
V Predictions Max            1535.6562
V Predictions Min            -0.32931232
Log Pis Mean                 -0.03930609
Log Pis Std                  2.1082976
Log Pis Max                  7.512782
Log Pis Min                  -4.600913
Policy mu Mean               0.063700974
Policy mu Std                0.91338825
Policy mu Max                2.3199298
Policy mu Min                -2.8945458
Policy log std Mean          -0.5119919
Policy log std Std           0.21633683
Policy log std Max           0.041646123
Policy log std Min           -1.4545312
Z mean eval                  0.015268716
Z variance eval              0.0013930784
total_rewards                [1053.00218473 1169.91598951 1913.35414711 1702.18257839 1901.95221959
 1051.73911483 1262.5338404  1187.21822124 1500.59488015 1371.42027503]
total_rewards_mean           1411.3913450984762
total_rewards_std            312.28931060417364
total_rewards_max            1913.3541471064375
total_rewards_min            1051.739114834511
Number of train steps total  130000
Number of env steps total    652000
Number of rollouts total     0
Train Time (s)               31.74748288700357
(Previous) Eval Time (s)     10.746805590111762
Sample Time (s)              22.963151883799583
Epoch Time (s)               65.45744036091492
Total Train Time (s)         8009.873048410751
Epoch                        129
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:16:13.604613 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #129 | Epoch Duration: 67.50646448135376
2020-01-11 02:16:13.604813 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #129 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046057582
Z variance train             0.0007900768
KL Divergence                15.520246
KL Loss                      1.5520246
QF Loss                      215.34293
VF Loss                      84.93751
Policy Loss                  -1095.1459
Q Predictions Mean           1103.97
Q Predictions Std            479.9296
Q Predictions Max            1541.096
Q Predictions Min            -1.3844973
V Predictions Mean           1100.2502
V Predictions Std            477.6922
V Predictions Max            1525.0085
V Predictions Min            -0.88358516
Log Pis Mean                 0.029625587
Log Pis Std                  2.180784
Log Pis Max                  9.290806
Log Pis Min                  -3.906745
Policy mu Mean               0.057418276
Policy mu Std                0.9102106
Policy mu Max                2.4005349
Policy mu Min                -2.8779821
Policy log std Mean          -0.5133588
Policy log std Std           0.21424018
Policy log std Max           0.037441283
Policy log std Min           -1.1997708
Z mean eval                  0.021067237
Z variance eval              0.0015261802
total_rewards                [ 916.5314996  1077.47891811 1527.61776493 1233.4896156  1252.93973757
 1042.30601526  811.88514634  938.97215523 1128.15535992  824.79562036]
total_rewards_mean           1075.4171832922434
total_rewards_std            209.9977716821851
total_rewards_max            1527.6177649319316
total_rewards_min            811.8851463431739
Number of train steps total  131000
Number of env steps total    657000
Number of rollouts total     0
Train Time (s)               31.599049620795995
(Previous) Eval Time (s)     12.795523267704993
Sample Time (s)              23.822846819646657
Epoch Time (s)               68.21741970814764
Total Train Time (s)         8074.889944231138
Epoch                        130
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:17:18.625832 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #130 | Epoch Duration: 65.02080631256104
2020-01-11 02:17:18.626110 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #130 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021214763
Z variance train             0.0015263979
KL Divergence                13.995815
KL Loss                      1.3995816
QF Loss                      233.77408
VF Loss                      108.56071
Policy Loss                  -1128.8438
Q Predictions Mean           1125.7745
Q Predictions Std            438.0885
Q Predictions Max            1512.2703
Q Predictions Min            -1.6888558
V Predictions Mean           1129.0588
V Predictions Std            433.1278
V Predictions Max            1517.5148
V Predictions Min            1.2967297
Log Pis Mean                 -0.16153136
Log Pis Std                  2.304201
Log Pis Max                  19.053461
Log Pis Min                  -5.0771065
Policy mu Mean               0.098629914
Policy mu Std                0.912838
Policy mu Max                3.7670798
Policy mu Min                -4.252835
Policy log std Mean          -0.48573756
Policy log std Std           0.2145571
Policy log std Max           0.07967913
Policy log std Min           -1.3581557
Z mean eval                  0.020006867
Z variance eval              0.0016193573
total_rewards                [ 885.83716716 1213.92403192  985.10023659 1227.29713998 1249.21894491
  885.97046411  889.46123102 1460.93137624  926.30039292  999.19585253]
total_rewards_mean           1072.3236837373543
total_rewards_std            190.68223139038432
total_rewards_max            1460.931376241995
total_rewards_min            885.8371671632615
Number of train steps total  132000
Number of env steps total    662000
Number of rollouts total     0
Train Time (s)               32.026851159054786
(Previous) Eval Time (s)     9.598528574220836
Sample Time (s)              21.41695816628635
Epoch Time (s)               63.04233789956197
Total Train Time (s)         8138.212771337479
Epoch                        131
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:18:21.951696 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #131 | Epoch Duration: 63.3254029750824
2020-01-11 02:18:21.951934 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #131 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017586488
Z variance train             0.0015880767
KL Divergence                14.106812
KL Loss                      1.4106811
QF Loss                      250.30316
VF Loss                      79.826775
Policy Loss                  -1119.0839
Q Predictions Mean           1119.0684
Q Predictions Std            448.68872
Q Predictions Max            1542.8663
Q Predictions Min            -14.19904
V Predictions Mean           1123.5068
V Predictions Std            448.49512
V Predictions Max            1540.8086
V Predictions Min            0.2475358
Log Pis Mean                 -0.22174433
Log Pis Std                  2.0676436
Log Pis Max                  13.9396515
Log Pis Min                  -4.506854
Policy mu Mean               0.09107027
Policy mu Std                0.90115273
Policy mu Max                3.2324157
Policy mu Min                -3.4135888
Policy log std Mean          -0.5046299
Policy log std Std           0.19194019
Policy log std Max           -0.030393153
Policy log std Min           -1.2080388
Z mean eval                  0.01691896
Z variance eval              0.0015055025
total_rewards                [1255.93626665 1226.4256134   798.57386774 1246.75034858  988.84103603
 1093.96007174 1222.21989395 1121.10467407 1043.88040501 1460.97361253]
total_rewards_mean           1145.8665789696652
total_rewards_std            171.1381798334614
total_rewards_max            1460.9736125283175
total_rewards_min            798.5738677352253
Number of train steps total  133000
Number of env steps total    667000
Number of rollouts total     0
Train Time (s)               31.67612946825102
(Previous) Eval Time (s)     9.881253705359995
Sample Time (s)              22.843150994274765
Epoch Time (s)               64.40053416788578
Total Train Time (s)         8202.804516378324
Epoch                        132
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:19:26.545134 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #132 | Epoch Duration: 64.5930392742157
2020-01-11 02:19:26.545331 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #132 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014798391
Z variance train             0.0015891099
KL Divergence                14.151285
KL Loss                      1.4151286
QF Loss                      1472.8776
VF Loss                      187.55847
Policy Loss                  -1050.7665
Q Predictions Mean           1054.4376
Q Predictions Std            490.16327
Q Predictions Max            1576.1765
Q Predictions Min            -2.7531085
V Predictions Mean           1057.824
V Predictions Std            489.032
V Predictions Max            1556.7987
V Predictions Min            0.13479814
Log Pis Mean                 -0.050401293
Log Pis Std                  2.0559227
Log Pis Max                  7.9995832
Log Pis Min                  -4.1298976
Policy mu Mean               0.06857737
Policy mu Std                0.91409016
Policy mu Max                3.0459328
Policy mu Min                -2.9179468
Policy log std Mean          -0.5026011
Policy log std Std           0.20979375
Policy log std Max           0.014392406
Policy log std Min           -2.0109737
Z mean eval                  0.016826982
Z variance eval              0.0015584504
total_rewards                [ 975.06289096  960.56118638 1116.5784696   978.1735507   950.03503938
  890.09596029  984.59178379 1225.338373   1000.25853358  962.14213889]
total_rewards_mean           1004.2837926557065
total_rewards_std            91.15052347176005
total_rewards_max            1225.3383730004186
total_rewards_min            890.0959602859305
Number of train steps total  134000
Number of env steps total    672000
Number of rollouts total     0
Train Time (s)               31.924224191810936
(Previous) Eval Time (s)     10.07342731487006
Sample Time (s)              23.26737629622221
Epoch Time (s)               65.2650278029032
Total Train Time (s)         8266.787122534588
Epoch                        133
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:20:30.530622 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #133 | Epoch Duration: 63.985063314437866
2020-01-11 02:20:30.530928 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #133 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015390855
Z variance train             0.0015933393
KL Divergence                14.128984
KL Loss                      1.4128984
QF Loss                      252.45724
VF Loss                      120.06457
Policy Loss                  -1075.5894
Q Predictions Mean           1075.1816
Q Predictions Std            477.25504
Q Predictions Max            1553.3939
Q Predictions Min            -6.59834
V Predictions Mean           1073.0684
V Predictions Std            476.63107
V Predictions Max            1550.9075
V Predictions Min            -4.444785
Log Pis Mean                 -0.068266466
Log Pis Std                  2.2081182
Log Pis Max                  10.214832
Log Pis Min                  -5.500793
Policy mu Mean               0.047657
Policy mu Std                0.9232386
Policy mu Max                2.9028888
Policy mu Min                -2.9898388
Policy log std Mean          -0.52107555
Policy log std Std           0.21787234
Policy log std Max           -0.05681795
Policy log std Min           -1.2294834
Z mean eval                  0.014705306
Z variance eval              0.0015269419
total_rewards                [1089.5373155   979.62881071  990.82031134  885.0923078   943.66586988
 1016.98226895 1083.8663667   214.70146496  221.57564457 1016.91953423]
total_rewards_mean           844.2789894637992
total_rewards_std            318.2215683217179
total_rewards_max            1089.537315501101
total_rewards_min            214.70146495552885
Number of train steps total  135000
Number of env steps total    677000
Number of rollouts total     0
Train Time (s)               31.773135277908295
(Previous) Eval Time (s)     8.793094544205815
Sample Time (s)              23.585431691259146
Epoch Time (s)               64.15166151337326
Total Train Time (s)         8329.96267484082
Epoch                        134
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:21:33.707731 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #134 | Epoch Duration: 63.176637172698975
2020-01-11 02:21:33.707919 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #134 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016254012
Z variance train             0.001527548
KL Divergence                14.08346
KL Loss                      1.408346
QF Loss                      210.57605
VF Loss                      135.45732
Policy Loss                  -1075.7476
Q Predictions Mean           1073.4312
Q Predictions Std            486.16772
Q Predictions Max            1554.2354
Q Predictions Min            1.1889468
V Predictions Mean           1077.2822
V Predictions Std            487.9692
V Predictions Max            1538.5144
V Predictions Min            1.1557292
Log Pis Mean                 -0.033922765
Log Pis Std                  2.077246
Log Pis Max                  8.842713
Log Pis Min                  -3.6738021
Policy mu Mean               0.038814675
Policy mu Std                0.9459272
Policy mu Max                2.126219
Policy mu Min                -2.6603866
Policy log std Mean          -0.49519607
Policy log std Std           0.21293014
Policy log std Max           0.00076186657
Policy log std Min           -1.3259228
Z mean eval                  0.026346311
Z variance eval              0.0024716132
total_rewards                [1249.69371951 2015.18809462 1070.15344583 1233.87089633 1009.54501684
  962.67338826 1767.70059657 1126.19993378 1377.15388907 1440.25487557]
total_rewards_mean           1325.2433856371738
total_rewards_std            322.1153129199985
total_rewards_max            2015.1880946178053
total_rewards_min            962.6733882631788
Number of train steps total  136000
Number of env steps total    682000
Number of rollouts total     0
Train Time (s)               32.195932070259005
(Previous) Eval Time (s)     7.817748700268567
Sample Time (s)              21.581694283057004
Epoch Time (s)               61.595375053584576
Total Train Time (s)         8396.060298169032
Epoch                        135
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:22:39.807123 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #135 | Epoch Duration: 66.09906840324402
2020-01-11 02:22:39.807307 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #135 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022377674
Z variance train             0.0023321467
KL Divergence                12.958223
KL Loss                      1.2958224
QF Loss                      186.32964
VF Loss                      75.649345
Policy Loss                  -1094.3286
Q Predictions Mean           1092.6653
Q Predictions Std            484.50314
Q Predictions Max            1556.4602
Q Predictions Min            1.60994
V Predictions Mean           1097.2922
V Predictions Std            483.88892
V Predictions Max            1561.4612
V Predictions Min            -0.605034
Log Pis Mean                 -0.15767732
Log Pis Std                  2.080028
Log Pis Max                  5.974038
Log Pis Min                  -4.519341
Policy mu Mean               -0.032017186
Policy mu Std                0.9612328
Policy mu Max                2.5208
Policy mu Min                -2.7472763
Policy log std Mean          -0.49401116
Policy log std Std           0.21356142
Policy log std Max           -0.073637396
Policy log std Min           -1.9510163
Z mean eval                  0.023493739
Z variance eval              0.0016458919
total_rewards                [1366.74805725  819.4284877   989.34918756 1250.93333859 1004.31985358
 1055.92406976 1043.56497161 1055.96253274 1208.56202397  996.56054428]
total_rewards_mean           1079.1353067042012
total_rewards_std            148.07195660572512
total_rewards_max            1366.7480572470963
total_rewards_min            819.4284877026794
Number of train steps total  137000
Number of env steps total    687000
Number of rollouts total     0
Train Time (s)               31.422259150072932
(Previous) Eval Time (s)     12.321143839973956
Sample Time (s)              22.167293888982385
Epoch Time (s)               65.91069687902927
Total Train Time (s)         8459.31156805437
Epoch                        136
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:23:43.059554 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #136 | Epoch Duration: 63.25211715698242
2020-01-11 02:23:43.059702 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #136 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022252506
Z variance train             0.0016476798
KL Divergence                14.052269
KL Loss                      1.405227
QF Loss                      160.4147
VF Loss                      100.99997
Policy Loss                  -1125.8035
Q Predictions Mean           1127.2888
Q Predictions Std            448.78918
Q Predictions Max            1566.8356
Q Predictions Min            4.5001607
V Predictions Mean           1128.6871
V Predictions Std            448.0559
V Predictions Max            1582.7733
V Predictions Min            5.2531447
Log Pis Mean                 -0.036351476
Log Pis Std                  1.9810696
Log Pis Max                  9.466751
Log Pis Min                  -4.243911
Policy mu Mean               0.14876775
Policy mu Std                0.93047667
Policy mu Max                2.588105
Policy mu Min                -2.673803
Policy log std Mean          -0.5382506
Policy log std Std           0.22203092
Policy log std Max           -0.036919326
Policy log std Min           -2.41738
Z mean eval                  0.023236426
Z variance eval              0.0016241223
total_rewards                [ 957.99463939  998.10470473  876.34680534  959.43521562  913.58395961
  965.71348835  838.65248991 1557.11096856  843.87608818 1240.55376621]
total_rewards_mean           1015.1372125901191
total_rewards_std            210.64236093247212
total_rewards_max            1557.1109685571516
total_rewards_min            838.6524899089094
Number of train steps total  138000
Number of env steps total    692000
Number of rollouts total     0
Train Time (s)               32.056252853013575
(Previous) Eval Time (s)     9.662224673200399
Sample Time (s)              21.30139728449285
Epoch Time (s)               63.019874810706824
Total Train Time (s)         8520.202054053545
Epoch                        137
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:24:43.953276 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #137 | Epoch Duration: 60.89345574378967
2020-01-11 02:24:43.953470 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #137 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023260122
Z variance train             0.0016201793
KL Divergence                14.001175
KL Loss                      1.4001175
QF Loss                      305.24103
VF Loss                      109.60048
Policy Loss                  -1065.1849
Q Predictions Mean           1060.2
Q Predictions Std            500.9794
Q Predictions Max            1521.0714
Q Predictions Min            -0.4840059
V Predictions Mean           1059.9497
V Predictions Std            499.37634
V Predictions Max            1520.3585
V Predictions Min            -2.6481729
Log Pis Mean                 -0.3127696
Log Pis Std                  1.9705745
Log Pis Max                  6.5834074
Log Pis Min                  -6.3089104
Policy mu Mean               -0.050938338
Policy mu Std                0.85247725
Policy mu Max                2.1245449
Policy mu Min                -2.736879
Policy log std Mean          -0.50858396
Policy log std Std           0.23663357
Policy log std Max           0.012720495
Policy log std Min           -2.0591342
Z mean eval                  0.01032948
Z variance eval              0.0014423814
total_rewards                [1007.2353069   923.85626856  988.83053934  983.76682459  960.14522743
 1008.2383383   995.43137756  885.37526288 1147.07533748  993.6939248 ]
total_rewards_mean           989.3648407847113
total_rewards_std            64.49365975655012
total_rewards_max            1147.075337480885
total_rewards_min            885.3752628788711
Number of train steps total  139000
Number of env steps total    697000
Number of rollouts total     0
Train Time (s)               31.687164755072445
(Previous) Eval Time (s)     7.535514818970114
Sample Time (s)              23.72973948577419
Epoch Time (s)               62.95241905981675
Total Train Time (s)         8584.83386451751
Epoch                        138
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:25:48.587027 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #138 | Epoch Duration: 64.6334183216095
2020-01-11 02:25:48.587222 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #138 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010466443
Z variance train             0.0014414487
KL Divergence                14.151023
KL Loss                      1.4151024
QF Loss                      207.97652
VF Loss                      53.89387
Policy Loss                  -1085.4331
Q Predictions Mean           1084.3425
Q Predictions Std            504.501
Q Predictions Max            1569.3674
Q Predictions Min            -10.66863
V Predictions Mean           1088.4402
V Predictions Std            504.64124
V Predictions Max            1575.6262
V Predictions Min            1.6608382
Log Pis Mean                 -0.081983976
Log Pis Std                  1.9284226
Log Pis Max                  8.8258915
Log Pis Min                  -4.2245474
Policy mu Mean               0.113812216
Policy mu Std                0.90557796
Policy mu Max                3.3643744
Policy mu Min                -3.124855
Policy log std Mean          -0.52858514
Policy log std Std           0.21824995
Policy log std Max           0.011799425
Policy log std Min           -1.5021102
Z mean eval                  0.024133513
Z variance eval              0.0018093595
total_rewards                [1269.11631713 1163.16166823  986.51324944  925.94148856  906.32656931
 2119.75848316 1191.12943261 1538.76501007 1049.82780727 1271.03144125]
total_rewards_mean           1242.1571467032982
total_rewards_std            344.0470696756804
total_rewards_max            2119.758483159519
total_rewards_min            906.3265693097735
Number of train steps total  140000
Number of env steps total    702000
Number of rollouts total     0
Train Time (s)               31.939455308020115
(Previous) Eval Time (s)     9.216172656975687
Sample Time (s)              22.586457064840943
Epoch Time (s)               63.742085029836744
Total Train Time (s)         8650.460208999924
Epoch                        139
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:26:54.215740 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #139 | Epoch Duration: 65.62836980819702
2020-01-11 02:26:54.215930 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #139 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021963112
Z variance train             0.001802989
KL Divergence                13.6556015
KL Loss                      1.3655602
QF Loss                      187.4055
VF Loss                      72.75143
Policy Loss                  -1158.4702
Q Predictions Mean           1154.532
Q Predictions Std            445.96625
Q Predictions Max            1560.8317
Q Predictions Min            -0.86276424
V Predictions Mean           1155.2891
V Predictions Std            443.3539
V Predictions Max            1561.4086
V Predictions Min            -0.6853879
Log Pis Mean                 -0.119441755
Log Pis Std                  2.021242
Log Pis Max                  7.6361527
Log Pis Min                  -4.5075126
Policy mu Mean               0.036712572
Policy mu Std                0.92920727
Policy mu Max                2.6860754
Policy mu Min                -3.224966
Policy log std Mean          -0.5307305
Policy log std Std           0.22231744
Policy log std Max           0.018395424
Policy log std Min           -2.1945643
Z mean eval                  0.015064272
Z variance eval              0.0016907919
total_rewards                [ 986.65333895  957.35968759  873.45816665  750.96211925  853.04486664
  992.35757213 1430.06834432  998.69282346 1237.84408208 1480.24543749]
total_rewards_mean           1056.0686438556652
total_rewards_std            232.89746628663895
total_rewards_max            1480.245437490138
total_rewards_min            750.9621192506816
Number of train steps total  141000
Number of env steps total    707000
Number of rollouts total     0
Train Time (s)               31.669038340914994
(Previous) Eval Time (s)     11.102014233823866
Sample Time (s)              21.703532130923122
Epoch Time (s)               64.47458470566198
Total Train Time (s)         8712.49100044882
Epoch                        140
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:27:56.250313 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #140 | Epoch Duration: 62.034231185913086
2020-01-11 02:27:56.250551 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #140 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014619894
Z variance train             0.0016893176
KL Divergence                14.015877
KL Loss                      1.4015877
QF Loss                      1550.4269
VF Loss                      166.37427
Policy Loss                  -1086.9323
Q Predictions Mean           1085.4636
Q Predictions Std            451.39908
Q Predictions Max            1524.3085
Q Predictions Min            -5.8275833
V Predictions Mean           1093.579
V Predictions Std            451.66043
V Predictions Max            1531.9261
V Predictions Min            1.1801574
Log Pis Mean                 -0.011393227
Log Pis Std                  2.301458
Log Pis Max                  10.275006
Log Pis Min                  -6.836024
Policy mu Mean               0.070665285
Policy mu Std                0.9660585
Policy mu Max                2.5220861
Policy mu Min                -4.2592936
Policy log std Mean          -0.52632034
Policy log std Std           0.19821753
Policy log std Max           0.016811907
Policy log std Min           -1.1308477
Z mean eval                  0.021601828
Z variance eval              0.0016279578
total_rewards                [ 940.49781357  940.16650472  870.55569913  935.45396321  851.8616626
  865.27639823 1175.35818035  994.80397085 1239.31528236 1328.62605277]
total_rewards_mean           1014.1915527792138
total_rewards_std            161.9161407903804
total_rewards_max            1328.6260527686827
total_rewards_min            851.8616625975167
Number of train steps total  142000
Number of env steps total    712000
Number of rollouts total     0
Train Time (s)               32.23410216299817
(Previous) Eval Time (s)     8.661319759208709
Sample Time (s)              22.876424768473953
Epoch Time (s)               63.77184669068083
Total Train Time (s)         8776.283825888764
Epoch                        141
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:29:00.046721 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #141 | Epoch Duration: 63.79597043991089
2020-01-11 02:29:00.047117 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #141 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024936765
Z variance train             0.0016593415
KL Divergence                14.054287
KL Loss                      1.4054288
QF Loss                      189.94601
VF Loss                      135.53122
Policy Loss                  -1162.9542
Q Predictions Mean           1158.3235
Q Predictions Std            424.8971
Q Predictions Max            1524.9083
Q Predictions Min            -3.10632
V Predictions Mean           1155.8667
V Predictions Std            423.28925
V Predictions Max            1521.4252
V Predictions Min            -7.424117
Log Pis Mean                 -0.066910215
Log Pis Std                  2.0850089
Log Pis Max                  6.88352
Log Pis Min                  -5.124253
Policy mu Mean               0.05544686
Policy mu Std                0.8951602
Policy mu Max                2.302074
Policy mu Min                -3.2486963
Policy log std Mean          -0.5092408
Policy log std Std           0.20027943
Policy log std Max           -0.06868714
Policy log std Min           -1.8642217
Z mean eval                  0.024106368
Z variance eval              0.0017915476
total_rewards                [1154.11653958  980.42257388  865.59644822  852.70646171  845.8711434
  943.28030163  932.28499118  882.23459005  961.18089785  912.3647786 ]
total_rewards_mean           933.005872609206
total_rewards_std            85.80585704461609
total_rewards_max            1154.1165395753353
total_rewards_min            845.8711434023546
Number of train steps total  143000
Number of env steps total    717000
Number of rollouts total     0
Train Time (s)               32.21273138420656
(Previous) Eval Time (s)     8.685017402749509
Sample Time (s)              24.426672723609954
Epoch Time (s)               65.32442151056603
Total Train Time (s)         8840.773917476181
Epoch                        142
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:30:04.536692 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #142 | Epoch Duration: 64.48926591873169
2020-01-11 02:30:04.536818 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #142 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02410973
Z variance train             0.0017827522
KL Divergence                13.999377
KL Loss                      1.3999377
QF Loss                      117.91435
VF Loss                      386.0344
Policy Loss                  -1115.4022
Q Predictions Mean           1111.6218
Q Predictions Std            476.61166
Q Predictions Max            1548.9629
Q Predictions Min            -22.090763
V Predictions Mean           1107.1511
V Predictions Std            471.46274
V Predictions Max            1534.4401
V Predictions Min            1.5736642
Log Pis Mean                 -0.21447274
Log Pis Std                  2.099544
Log Pis Max                  10.369804
Log Pis Min                  -4.3692555
Policy mu Mean               0.092188336
Policy mu Std                0.8871827
Policy mu Max                3.1210384
Policy mu Min                -3.8015597
Policy log std Mean          -0.4957912
Policy log std Std           0.20893121
Policy log std Max           -0.065077126
Policy log std Min           -2.2626143
Z mean eval                  0.03251758
Z variance eval              0.0012963241
total_rewards                [ 935.59632102  865.93029873 1151.61499597 1014.74887581  995.32856337
  982.8574746   873.87905805  749.06465787 1229.66451992 1065.90097441]
total_rewards_mean           986.4585739741073
total_rewards_std            134.07942026339808
total_rewards_max            1229.6645199166403
total_rewards_min            749.0646578669277
Number of train steps total  144000
Number of env steps total    722000
Number of rollouts total     0
Train Time (s)               31.96341977501288
(Previous) Eval Time (s)     7.849527840036899
Sample Time (s)              23.19672228489071
Epoch Time (s)               63.00966989994049
Total Train Time (s)         8904.817998351064
Epoch                        143
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:31:08.583575 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #143 | Epoch Duration: 64.04663634300232
2020-01-11 02:31:08.583758 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #143 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013593738
Z variance train             0.0017267701
KL Divergence                13.794836
KL Loss                      1.3794836
QF Loss                      159.02899
VF Loss                      102.35739
Policy Loss                  -1103.041
Q Predictions Mean           1102.2595
Q Predictions Std            490.39093
Q Predictions Max            1545.9955
Q Predictions Min            -10.193071
V Predictions Mean           1106.3901
V Predictions Std            491.00568
V Predictions Max            1559.0421
V Predictions Min            -2.1841512
Log Pis Mean                 -0.026578352
Log Pis Std                  2.2570271
Log Pis Max                  12.943605
Log Pis Min                  -4.2776327
Policy mu Mean               0.08885745
Policy mu Std                0.9415504
Policy mu Max                3.0354717
Policy mu Min                -4.151617
Policy log std Mean          -0.49791202
Policy log std Std           0.21758266
Policy log std Max           0.06673643
Policy log std Min           -1.2992808
Z mean eval                  0.03757129
Z variance eval              0.00144975
total_rewards                [ 695.55750866  953.95350362  988.80726091  907.55571436 1149.03877936
 1097.34973194  872.01180711  880.87488071  970.14637414 1031.40544286]
total_rewards_mean           954.6701003666519
total_rewards_std            121.27142126480955
total_rewards_max            1149.038779357187
total_rewards_min            695.5575086558259
Number of train steps total  145000
Number of env steps total    727000
Number of rollouts total     0
Train Time (s)               32.23869073903188
(Previous) Eval Time (s)     8.886194634716958
Sample Time (s)              22.520929171703756
Epoch Time (s)               63.645814545452595
Total Train Time (s)         8968.587399057578
Epoch                        144
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:32:12.354927 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #144 | Epoch Duration: 63.77103066444397
2020-01-11 02:32:12.355108 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #144 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03813706
Z variance train             0.0014661832
KL Divergence                14.036195
KL Loss                      1.4036195
QF Loss                      409.80847
VF Loss                      126.52938
Policy Loss                  -1124.5155
Q Predictions Mean           1125.9808
Q Predictions Std            476.1405
Q Predictions Max            1557.5885
Q Predictions Min            -3.3315349
V Predictions Mean           1123.9165
V Predictions Std            474.0261
V Predictions Max            1550.3617
V Predictions Min            2.0773807
Log Pis Mean                 -0.060688138
Log Pis Std                  2.1653895
Log Pis Max                  11.354614
Log Pis Min                  -6.908784
Policy mu Mean               0.03941046
Policy mu Std                0.927443
Policy mu Max                2.6053662
Policy mu Min                -3.0441794
Policy log std Mean          -0.5305688
Policy log std Std           0.22746797
Policy log std Max           0.00045883656
Policy log std Min           -1.3570514
Z mean eval                  0.022274897
Z variance eval              0.001713339
total_rewards                [ 997.48713116 1120.83300106 1002.05932429  985.81446206 1226.90505926
  874.43829768 1004.5075137   944.01639835  994.65204265  992.04405836]
total_rewards_mean           1014.2757288564783
total_rewards_std            91.25374546299918
total_rewards_max            1226.9050592609135
total_rewards_min            874.438297678115
Number of train steps total  146000
Number of env steps total    732000
Number of rollouts total     0
Train Time (s)               33.484447611961514
(Previous) Eval Time (s)     9.011088322848082
Sample Time (s)              23.585103118792176
Epoch Time (s)               66.08063905360177
Total Train Time (s)         9034.97848110227
Epoch                        145
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:33:18.748645 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #145 | Epoch Duration: 66.39338517189026
2020-01-11 02:33:18.748840 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #145 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022392755
Z variance train             0.0017226379
KL Divergence                13.7425585
KL Loss                      1.3742559
QF Loss                      537.3234
VF Loss                      83.53306
Policy Loss                  -1113.0579
Q Predictions Mean           1111.9443
Q Predictions Std            486.09775
Q Predictions Max            1574.8451
Q Predictions Min            -1.2274263
V Predictions Mean           1114.8966
V Predictions Std            484.24612
V Predictions Max            1564.5591
V Predictions Min            1.5343192
Log Pis Mean                 -0.15018943
Log Pis Std                  2.1602833
Log Pis Max                  11.130956
Log Pis Min                  -4.1002836
Policy mu Mean               0.06908145
Policy mu Std                0.9141255
Policy mu Max                3.603528
Policy mu Min                -3.2571576
Policy log std Mean          -0.5267949
Policy log std Std           0.22607028
Policy log std Max           0.091864884
Policy log std Min           -1.4337041
Z mean eval                  0.03592139
Z variance eval              0.0020061175
total_rewards                [910.6655009  863.70074444 830.88863749 973.56001609 986.29521341
 910.40187556 885.43964919 928.47964571 924.09737742 887.64102577]
total_rewards_mean           910.116968597937
total_rewards_std            44.61714857995639
total_rewards_max            986.2952134145911
total_rewards_min            830.8886374858342
Number of train steps total  147000
Number of env steps total    737000
Number of rollouts total     0
Train Time (s)               34.01703254878521
(Previous) Eval Time (s)     9.32347134128213
Sample Time (s)              24.377818550914526
Epoch Time (s)               67.71832244098186
Total Train Time (s)         9102.011581293773
Epoch                        146
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:34:25.784027 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #146 | Epoch Duration: 67.03504300117493
2020-01-11 02:34:25.784226 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #146 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036247797
Z variance train             0.002028045
KL Divergence                13.283173
KL Loss                      1.3283173
QF Loss                      146.4082
VF Loss                      57.934437
Policy Loss                  -1090.7396
Q Predictions Mean           1090.2544
Q Predictions Std            484.54437
Q Predictions Max            1563.2632
Q Predictions Min            -5.01447
V Predictions Mean           1089.3008
V Predictions Std            481.15088
V Predictions Max            1546.6172
V Predictions Min            -3.993529
Log Pis Mean                 -0.10526712
Log Pis Std                  2.024103
Log Pis Max                  8.330046
Log Pis Min                  -6.2170286
Policy mu Mean               0.043930043
Policy mu Std                0.8800344
Policy mu Max                2.5802085
Policy mu Min                -2.8506653
Policy log std Mean          -0.5192392
Policy log std Std           0.21191722
Policy log std Max           0.021837294
Policy log std Min           -1.3466656
Z mean eval                  0.019367706
Z variance eval              0.0023469757
total_rewards                [ 995.82028508  888.64653977  825.64669797 1040.17847813 1498.53806628
 1125.02505239 1146.55980237 1074.50165285 1061.47160855 1078.40852238]
total_rewards_mean           1073.479670578226
total_rewards_std            170.75310290536763
total_rewards_max            1498.5380662804018
total_rewards_min            825.6466979689776
Number of train steps total  148000
Number of env steps total    742000
Number of rollouts total     0
Train Time (s)               34.63062167633325
(Previous) Eval Time (s)     8.639778611715883
Sample Time (s)              24.48816874437034
Epoch Time (s)               67.75856903241947
Total Train Time (s)         9171.011742530856
Epoch                        147
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:35:34.786206 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #147 | Epoch Duration: 69.00184226036072
2020-01-11 02:35:34.786383 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #147 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020414758
Z variance train             0.0023176833
KL Divergence                12.904889
KL Loss                      1.290489
QF Loss                      116.3688
VF Loss                      49.62477
Policy Loss                  -1163.9741
Q Predictions Mean           1162.0864
Q Predictions Std            455.75076
Q Predictions Max            1575.0217
Q Predictions Min            -14.094016
V Predictions Mean           1162.6145
V Predictions Std            453.7599
V Predictions Max            1568.1598
V Predictions Min            -5.096978
Log Pis Mean                 0.1256409
Log Pis Std                  2.2678745
Log Pis Max                  7.5365753
Log Pis Min                  -4.8253207
Policy mu Mean               0.11441631
Policy mu Std                0.9663314
Policy mu Max                2.5394478
Policy mu Min                -2.8041778
Policy log std Mean          -0.52939266
Policy log std Std           0.19902548
Policy log std Max           0.08175337
Policy log std Min           -1.4258593
Z mean eval                  0.012845146
Z variance eval              0.0016355619
total_rewards                [1672.38911927 1222.12278751  776.66623469 1650.06951522 1126.50461943
 1882.77987501 1206.55923479 2888.9420787  1262.45509002 1283.72081348]
total_rewards_mean           1497.2209368110719
total_rewards_std            552.9086905319452
total_rewards_max            2888.9420787048775
total_rewards_min            776.666234694763
Number of train steps total  149000
Number of env steps total    747000
Number of rollouts total     0
Train Time (s)               33.94494484690949
(Previous) Eval Time (s)     9.882628375198692
Sample Time (s)              24.46060854010284
Epoch Time (s)               68.28818176221102
Total Train Time (s)         9242.375353171024
Epoch                        148
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:36:46.151903 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #148 | Epoch Duration: 71.36538171768188
2020-01-11 02:36:46.152086 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #148 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012961557
Z variance train             0.0016354322
KL Divergence                13.950365
KL Loss                      1.3950366
QF Loss                      238.651
VF Loss                      148.81987
Policy Loss                  -1140.1407
Q Predictions Mean           1139.1627
Q Predictions Std            471.55948
Q Predictions Max            1573.4106
Q Predictions Min            -4.0655165
V Predictions Mean           1137.632
V Predictions Std            469.65213
V Predictions Max            1556.7141
V Predictions Min            -2.1743968
Log Pis Mean                 -0.09253504
Log Pis Std                  1.9876825
Log Pis Max                  7.3330965
Log Pis Min                  -3.8363338
Policy mu Mean               -0.011713549
Policy mu Std                0.8833755
Policy mu Max                1.9942364
Policy mu Min                -2.7423966
Policy log std Mean          -0.509006
Policy log std Std           0.21502149
Policy log std Max           0.08081412
Policy log std Min           -1.1738708
Z mean eval                  0.022599597
Z variance eval              0.0013974231
total_rewards                [1002.08617055 1006.12443843  891.66691219  908.34205193 1061.34321968
 1007.10340267  909.05384162 1160.37594449 1126.44481722 1258.42928265]
total_rewards_mean           1033.0970081421058
total_rewards_std            113.93158512545239
total_rewards_max            1258.4292826470967
total_rewards_min            891.6669121861175
Number of train steps total  150000
Number of env steps total    752000
Number of rollouts total     0
Train Time (s)               34.33861857512966
(Previous) Eval Time (s)     12.959418845828623
Sample Time (s)              24.137303370516747
Epoch Time (s)               71.43534079147503
Total Train Time (s)         9310.583664242178
Epoch                        149
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:37:54.362545 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #149 | Epoch Duration: 68.2103168964386
2020-01-11 02:37:54.362726 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #149 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022225056
Z variance train             0.0013870082
KL Divergence                14.278221
KL Loss                      1.4278221
QF Loss                      498.87897
VF Loss                      148.00597
Policy Loss                  -1181.4376
Q Predictions Mean           1182.5493
Q Predictions Std            443.99686
Q Predictions Max            1577.4073
Q Predictions Min            -6.198615
V Predictions Mean           1179.7666
V Predictions Std            441.42117
V Predictions Max            1571.8497
V Predictions Min            -1.3403441
Log Pis Mean                 -0.09096472
Log Pis Std                  2.2957106
Log Pis Max                  7.9831734
Log Pis Min                  -7.5750246
Policy mu Mean               0.015365372
Policy mu Std                0.9444148
Policy mu Max                2.61584
Policy mu Min                -2.8695076
Policy log std Mean          -0.5679126
Policy log std Std           0.23409571
Policy log std Max           0.06273842
Policy log std Min           -2.1170967
Z mean eval                  0.011730927
Z variance eval              0.001383075
total_rewards                [1116.5691148  1540.482643   1016.98887579 1647.54937032 1480.85065729
 1666.72037956 1824.59617697 1152.43183665  845.61322446 1515.9554851 ]
total_rewards_mean           1380.775776392312
total_rewards_std            307.3092601975548
total_rewards_max            1824.5961769655637
total_rewards_min            845.6132244561746
Number of train steps total  151000
Number of env steps total    757000
Number of rollouts total     0
Train Time (s)               34.5641750600189
(Previous) Eval Time (s)     9.734052354004234
Sample Time (s)              24.711429277434945
Epoch Time (s)               69.00965669145808
Total Train Time (s)         9383.080249832943
Epoch                        150
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:39:06.862204 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #150 | Epoch Duration: 72.49933314323425
2020-01-11 02:39:06.862443 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #150 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.009992419
Z variance train             0.0013177438
KL Divergence                14.2871
KL Loss                      1.42871
QF Loss                      125.426895
VF Loss                      36.46852
Policy Loss                  -1155.5652
Q Predictions Mean           1151.766
Q Predictions Std            452.4718
Q Predictions Max            1603.1581
Q Predictions Min            -3.4662418
V Predictions Mean           1155.7604
V Predictions Std            451.1774
V Predictions Max            1590.4988
V Predictions Min            -3.7125375
Log Pis Mean                 -0.207773
Log Pis Std                  2.2918239
Log Pis Max                  8.612979
Log Pis Min                  -4.658949
Policy mu Mean               0.1844142
Policy mu Std                0.92289925
Policy mu Max                2.749727
Policy mu Min                -2.8181484
Policy log std Mean          -0.500974
Policy log std Std           0.21123973
Policy log std Max           0.03984925
Policy log std Min           -1.5014651
Z mean eval                  0.042260822
Z variance eval              0.0013389693
total_rewards                [1236.38887226 1183.84659025 1408.15469488  978.67180688  935.33794892
 1839.03621232  990.88421581 1179.6961598  1546.54213744  999.91131496]
total_rewards_mean           1229.84699535169
total_rewards_std            277.069137833026
total_rewards_max            1839.0362123192585
total_rewards_min            935.3379489169056
Number of train steps total  152000
Number of env steps total    762000
Number of rollouts total     0
Train Time (s)               33.91960447607562
(Previous) Eval Time (s)     13.223262486048043
Sample Time (s)              23.108038195874542
Epoch Time (s)               70.2509051579982
Total Train Time (s)         9450.34835522715
Epoch                        151
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:40:14.137566 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #151 | Epoch Duration: 67.27496576309204
2020-01-11 02:40:14.137754 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #151 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04225129
Z variance train             0.0013389539
KL Divergence                14.355278
KL Loss                      1.4355278
QF Loss                      212.96883
VF Loss                      334.93634
Policy Loss                  -1161.9191
Q Predictions Mean           1157.9492
Q Predictions Std            447.04724
Q Predictions Max            1562.8617
Q Predictions Min            -4.6391277
V Predictions Mean           1161.9147
V Predictions Std            447.321
V Predictions Max            1567.2898
V Predictions Min            -1.9039073
Log Pis Mean                 -0.14270574
Log Pis Std                  2.0753992
Log Pis Max                  8.665043
Log Pis Min                  -4.462556
Policy mu Mean               -0.029715637
Policy mu Std                0.89934397
Policy mu Max                2.9811416
Policy mu Min                -3.2578526
Policy log std Mean          -0.5460405
Policy log std Std           0.20642187
Policy log std Max           -0.025905848
Policy log std Min           -1.4076335
Z mean eval                  0.012303724
Z variance eval              0.0012354504
total_rewards                [1109.67493693 1468.60660691  962.5840583  1084.01610046 1141.35407094
 1448.69658027 1262.99668976  819.6607187  1104.21051226 1601.52449247]
total_rewards_mean           1200.3324766994751
total_rewards_std            231.17937734203983
total_rewards_max            1601.524492472812
total_rewards_min            819.6607186984152
Number of train steps total  153000
Number of env steps total    767000
Number of rollouts total     0
Train Time (s)               33.871064921841025
(Previous) Eval Time (s)     10.246957691852003
Sample Time (s)              23.50172087782994
Epoch Time (s)               67.61974349152297
Total Train Time (s)         9518.840075651184
Epoch                        152
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:41:22.626537 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #152 | Epoch Duration: 68.4886360168457
2020-01-11 02:41:22.626723 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #152 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011565666
Z variance train             0.0012501361
KL Divergence                14.36974
KL Loss                      1.4369739
QF Loss                      182.5547
VF Loss                      85.53025
Policy Loss                  -1144.8667
Q Predictions Mean           1145.2582
Q Predictions Std            475.04855
Q Predictions Max            1579.312
Q Predictions Min            0.9407519
V Predictions Mean           1142.8035
V Predictions Std            471.50626
V Predictions Max            1568.4683
V Predictions Min            3.1575208
Log Pis Mean                 -0.05090271
Log Pis Std                  2.154989
Log Pis Max                  7.6590314
Log Pis Min                  -5.0839996
Policy mu Mean               0.079305984
Policy mu Std                0.9169918
Policy mu Max                2.9085128
Policy mu Min                -3.0830595
Policy log std Mean          -0.5400305
Policy log std Std           0.22086015
Policy log std Max           -0.03250286
Policy log std Min           -1.466485
Z mean eval                  0.030932505
Z variance eval              0.0018277382
total_rewards                [ 826.91317542  991.74063144  973.83703735 1039.66326068  977.91109487
  810.23186978 1163.33841823  937.97639161  818.00675964  966.48346675]
total_rewards_mean           950.6102105769263
total_rewards_std            104.48088593740502
total_rewards_max            1163.3384182264103
total_rewards_min            810.2318697785684
Number of train steps total  154000
Number of env steps total    772000
Number of rollouts total     0
Train Time (s)               34.64985147723928
(Previous) Eval Time (s)     11.115458138752729
Sample Time (s)              23.66784378979355
Epoch Time (s)               69.43315340578556
Total Train Time (s)         9586.09092500247
Epoch                        153
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:42:29.880062 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #153 | Epoch Duration: 67.25316429138184
2020-01-11 02:42:29.880356 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #153 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03069464
Z variance train             0.0018334286
KL Divergence                13.44719
KL Loss                      1.344719
QF Loss                      669.9773
VF Loss                      102.20446
Policy Loss                  -1142.5718
Q Predictions Mean           1137.5984
Q Predictions Std            469.05844
Q Predictions Max            1584.9438
Q Predictions Min            -0.7305142
V Predictions Mean           1143.3472
V Predictions Std            468.04163
V Predictions Max            1573.042
V Predictions Min            -0.35233453
Log Pis Mean                 -0.08575159
Log Pis Std                  1.9173423
Log Pis Max                  6.5394754
Log Pis Min                  -7.323475
Policy mu Mean               0.13703
Policy mu Std                0.9190072
Policy mu Max                2.9382873
Policy mu Min                -2.7992818
Policy log std Mean          -0.5186376
Policy log std Std           0.21783699
Policy log std Max           -0.025734007
Policy log std Min           -2.128956
Z mean eval                  0.01905819
Z variance eval              0.0020681866
total_rewards                [1068.7906627  1016.58188075 1086.72532528  983.47332301  899.66685469
  955.55921439 1427.27101188 1129.30215646  984.80793489 1251.19826281]
total_rewards_mean           1080.3376626862296
total_rewards_std            149.30263945989955
total_rewards_max            1427.271011880522
total_rewards_min            899.6668546890319
Number of train steps total  155000
Number of env steps total    777000
Number of rollouts total     0
Train Time (s)               35.129442216362804
(Previous) Eval Time (s)     8.935064958874136
Sample Time (s)              23.79149858094752
Epoch Time (s)               67.85600575618446
Total Train Time (s)         9654.628371952567
Epoch                        154
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:43:38.419673 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #154 | Epoch Duration: 68.53915810585022
2020-01-11 02:43:38.419855 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #154 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018220693
Z variance train             0.0021291682
KL Divergence                13.0869465
KL Loss                      1.3086947
QF Loss                      231.5283
VF Loss                      54.208054
Policy Loss                  -1117.5521
Q Predictions Mean           1115.8281
Q Predictions Std            477.94174
Q Predictions Max            1591.4575
Q Predictions Min            -0.4207336
V Predictions Mean           1116.9033
V Predictions Std            476.94183
V Predictions Max            1589.9524
V Predictions Min            0.8598393
Log Pis Mean                 -0.14286941
Log Pis Std                  2.0816925
Log Pis Max                  9.763349
Log Pis Min                  -4.6748934
Policy mu Mean               0.023701243
Policy mu Std                0.90863734
Policy mu Max                2.207135
Policy mu Min                -3.0282626
Policy log std Mean          -0.50809
Policy log std Std           0.20133008
Policy log std Max           0.020836204
Policy log std Min           -1.107835
Z mean eval                  0.007439308
Z variance eval              0.0024936176
total_rewards                [ 875.42592465  897.18047121  824.80289873  938.13615953 1006.84297991
  919.83896891  986.22308656 1734.34160703  853.23737489  900.35155114]
total_rewards_mean           993.6381022567375
total_rewards_std            252.5066484880669
total_rewards_max            1734.341607033933
total_rewards_min            824.8028987254937
Number of train steps total  156000
Number of env steps total    782000
Number of rollouts total     0
Train Time (s)               33.83133052196354
(Previous) Eval Time (s)     9.617834809236228
Sample Time (s)              22.14186864439398
Epoch Time (s)               65.59103397559375
Total Train Time (s)         9719.647977400105
Epoch                        155
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:44:43.441861 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #155 | Epoch Duration: 65.02185678482056
2020-01-11 02:44:43.442068 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #155 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0075409366
Z variance train             0.002413615
KL Divergence                12.849287
KL Loss                      1.2849287
QF Loss                      244.60321
VF Loss                      89.244095
Policy Loss                  -1179.1903
Q Predictions Mean           1180.1685
Q Predictions Std            445.50513
Q Predictions Max            1600.7212
Q Predictions Min            2.312743
V Predictions Mean           1173.6387
V Predictions Std            441.4421
V Predictions Max            1585.2684
V Predictions Min            3.1013207
Log Pis Mean                 -0.11381708
Log Pis Std                  2.015345
Log Pis Max                  6.7040253
Log Pis Min                  -4.2660694
Policy mu Mean               0.08519436
Policy mu Std                0.87503016
Policy mu Max                2.438555
Policy mu Min                -2.864214
Policy log std Mean          -0.5510889
Policy log std Std           0.21077916
Policy log std Max           -0.05335614
Policy log std Min           -1.2496068
Z mean eval                  0.03335584
Z variance eval              0.0023012985
total_rewards                [ 919.1385375   993.49180386  955.67656009  860.29410019  881.46762097
  965.20568483  993.37151498 1104.46324335 1049.84448637  916.68999422]
total_rewards_mean           963.9643546357116
total_rewards_std            71.21774097130118
total_rewards_max            1104.463243352941
total_rewards_min            860.2941001942864
Number of train steps total  157000
Number of env steps total    787000
Number of rollouts total     0
Train Time (s)               34.226571006234735
(Previous) Eval Time (s)     9.04832270508632
Sample Time (s)              24.55489746434614
Epoch Time (s)               67.8297911756672
Total Train Time (s)         9787.418751846999
Epoch                        156
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:45:51.214745 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #156 | Epoch Duration: 67.77251434326172
2020-01-11 02:45:51.214942 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #156 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032457225
Z variance train             0.00232813
KL Divergence                12.81654
KL Loss                      1.281654
QF Loss                      258.52686
VF Loss                      72.21067
Policy Loss                  -1164.9691
Q Predictions Mean           1167.7078
Q Predictions Std            465.44495
Q Predictions Max            1583.3341
Q Predictions Min            -4.372687
V Predictions Mean           1169.4358
V Predictions Std            466.0361
V Predictions Max            1585.7662
V Predictions Min            -0.57356846
Log Pis Mean                 -0.3874173
Log Pis Std                  1.9129814
Log Pis Max                  9.770425
Log Pis Min                  -4.6432924
Policy mu Mean               0.11579952
Policy mu Std                0.8212315
Policy mu Max                2.41662
Policy mu Min                -2.77793
Policy log std Mean          -0.49492785
Policy log std Std           0.19572817
Policy log std Max           -0.07353625
Policy log std Min           -1.3350805
Z mean eval                  0.013481183
Z variance eval              0.0022516071
total_rewards                [ 992.05754471  994.45285115  878.04275001  876.49631816  963.10793379
  867.50517601 1114.30370422  957.33042113  895.01503876  912.76071178]
total_rewards_mean           945.1072449703051
total_rewards_std            72.47268889121776
total_rewards_max            1114.3037042164538
total_rewards_min            867.5051760067843
Number of train steps total  158000
Number of env steps total    792000
Number of rollouts total     0
Train Time (s)               33.57272712001577
(Previous) Eval Time (s)     8.990664785727859
Sample Time (s)              23.854134530760348
Epoch Time (s)               66.41752643650398
Total Train Time (s)         9853.207034992054
Epoch                        157
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:46:57.005378 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #157 | Epoch Duration: 65.79029583930969
2020-01-11 02:46:57.005555 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #157 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014352898
Z variance train             0.002252064
KL Divergence                12.804736
KL Loss                      1.2804736
QF Loss                      140.39648
VF Loss                      65.495735
Policy Loss                  -1177.1869
Q Predictions Mean           1177.0203
Q Predictions Std            434.98233
Q Predictions Max            1594.4474
Q Predictions Min            -1.6907897
V Predictions Mean           1181.0787
V Predictions Std            435.05414
V Predictions Max            1599.7043
V Predictions Min            1.3481437
Log Pis Mean                 0.016384713
Log Pis Std                  2.1262536
Log Pis Max                  7.7495794
Log Pis Min                  -5.3262596
Policy mu Mean               0.05625074
Policy mu Std                0.9385168
Policy mu Max                2.367797
Policy mu Min                -2.9750724
Policy log std Mean          -0.53660053
Policy log std Std           0.20597944
Policy log std Max           -0.08279714
Policy log std Min           -1.4893237
Z mean eval                  0.022671968
Z variance eval              0.002030371
total_rewards                [ 851.34053147 1143.02305387 1250.95976627  967.88637948 1037.64759022
  945.0299845  1113.66884134 1017.94008279 1266.2201108  1004.27805078]
total_rewards_mean           1059.7994391514521
total_rewards_std            126.24600430592717
total_rewards_max            1266.2201107973012
total_rewards_min            851.3405314709142
Number of train steps total  159000
Number of env steps total    797000
Number of rollouts total     0
Train Time (s)               32.24847837211564
(Previous) Eval Time (s)     8.363049047999084
Sample Time (s)              22.9375017574057
Epoch Time (s)               63.549029177520424
Total Train Time (s)         9917.337859147228
Epoch                        158
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:48:01.138585 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #158 | Epoch Duration: 64.13288450241089
2020-01-11 02:48:01.138780 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #158 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022983113
Z variance train             0.0019891083
KL Divergence                13.084796
KL Loss                      1.3084797
QF Loss                      167.14384
VF Loss                      68.59516
Policy Loss                  -1157.5245
Q Predictions Mean           1158.0669
Q Predictions Std            458.72836
Q Predictions Max            1558.518
Q Predictions Min            -3.5488281
V Predictions Mean           1161.3214
V Predictions Std            457.86597
V Predictions Max            1554.4521
V Predictions Min            -0.32653993
Log Pis Mean                 -0.10908072
Log Pis Std                  2.1864412
Log Pis Max                  7.244917
Log Pis Min                  -5.5393057
Policy mu Mean               -0.01799501
Policy mu Std                0.92561644
Policy mu Max                2.5359704
Policy mu Min                -3.0085936
Policy log std Mean          -0.50537956
Policy log std Std           0.2043081
Policy log std Max           -0.038294226
Policy log std Min           -1.2538384
Z mean eval                  0.026312307
Z variance eval              0.0016537437
total_rewards                [ 999.20055021 1030.27540083  979.95024531  879.43605094  994.59583218
 1004.3003778   905.7796709  1043.42089746  909.33904661 1408.54756731]
total_rewards_mean           1015.484563955219
total_rewards_std            141.2084439904867
total_rewards_max            1408.5475673141982
total_rewards_min            879.4360509359242
Number of train steps total  160000
Number of env steps total    802000
Number of rollouts total     0
Train Time (s)               31.764187314081937
(Previous) Eval Time (s)     8.946556789334863
Sample Time (s)              23.653412462212145
Epoch Time (s)               64.36415656562895
Total Train Time (s)         9981.62545317784
Epoch                        159
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:49:05.428782 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #159 | Epoch Duration: 64.28985166549683
2020-01-11 02:49:05.428992 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #159 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025868708
Z variance train             0.0015176199
KL Divergence                13.744755
KL Loss                      1.3744755
QF Loss                      222.52975
VF Loss                      99.171715
Policy Loss                  -1190.8853
Q Predictions Mean           1190.0833
Q Predictions Std            444.57938
Q Predictions Max            1572.8976
Q Predictions Min            -20.456188
V Predictions Mean           1190.6868
V Predictions Std            440.9239
V Predictions Max            1558.7142
V Predictions Min            2.4558206
Log Pis Mean                 -0.026873834
Log Pis Std                  2.1183105
Log Pis Max                  11.145397
Log Pis Min                  -6.4419074
Policy mu Mean               0.05840504
Policy mu Std                0.9120917
Policy mu Max                3.3253546
Policy mu Min                -2.849456
Policy log std Mean          -0.52110547
Policy log std Std           0.2042402
Policy log std Max           -0.005350977
Policy log std Min           -1.9465225
Z mean eval                  0.06275093
Z variance eval              0.0015194642
total_rewards                [ 881.85721117  949.78806217 1033.99318699  899.84092173  985.04738501
 1188.17371425 1545.74345415  861.21209538 1122.13330302 1065.57391195]
total_rewards_mean           1053.3363245811474
total_rewards_std            192.6567177790183
total_rewards_max            1545.7434541486284
total_rewards_min            861.212095383715
Number of train steps total  161000
Number of env steps total    807000
Number of rollouts total     0
Train Time (s)               31.942639411892742
(Previous) Eval Time (s)     8.871933659072965
Sample Time (s)              23.176668773405254
Epoch Time (s)               63.99124184437096
Total Train Time (s)         10044.971779344603
Epoch                        160
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:50:08.778023 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #160 | Epoch Duration: 63.34887933731079
2020-01-11 02:50:08.778203 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #160 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06266405
Z variance train             0.0015145978
KL Divergence                13.778329
KL Loss                      1.3778329
QF Loss                      304.63184
VF Loss                      87.773926
Policy Loss                  -1158.4413
Q Predictions Mean           1156.3059
Q Predictions Std            470.2344
Q Predictions Max            1577.7876
Q Predictions Min            -1.8915505
V Predictions Mean           1161.4006
V Predictions Std            469.85022
V Predictions Max            1579.6615
V Predictions Min            1.9923182
Log Pis Mean                 0.18145756
Log Pis Std                  2.0625749
Log Pis Max                  8.0125675
Log Pis Min                  -3.7951062
Policy mu Mean               0.09894744
Policy mu Std                0.976364
Policy mu Max                3.6831417
Policy mu Min                -2.8344631
Policy log std Mean          -0.52519685
Policy log std Std           0.21532704
Policy log std Max           0.008324772
Policy log std Min           -1.392672
Z mean eval                  0.016937252
Z variance eval              0.0015020979
total_rewards                [1013.0151292   973.91776506 1264.1425361   932.87992659 1022.02560235
  964.34121923 1000.7859076   855.06311253 1542.00755673  925.87651137]
total_rewards_mean           1049.4055266769121
total_rewards_std            193.06669248383014
total_rewards_max            1542.007556733392
total_rewards_min            855.0631125299639
Number of train steps total  162000
Number of env steps total    812000
Number of rollouts total     0
Train Time (s)               32.355863044038415
(Previous) Eval Time (s)     8.229258480016142
Sample Time (s)              23.763073867186904
Epoch Time (s)               64.34819539124146
Total Train Time (s)         10110.710867359303
Epoch                        161
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:51:14.517540 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #161 | Epoch Duration: 65.73921036720276
2020-01-11 02:51:14.517687 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #161 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016519764
Z variance train             0.0015178814
KL Divergence                13.775839
KL Loss                      1.3775839
QF Loss                      426.28732
VF Loss                      53.485115
Policy Loss                  -1155.3094
Q Predictions Mean           1155.1321
Q Predictions Std            471.26324
Q Predictions Max            1569.4204
Q Predictions Min            -6.681658
V Predictions Mean           1157.6326
V Predictions Std            470.6126
V Predictions Max            1577.5399
V Predictions Min            -3.2240736
Log Pis Mean                 -0.06330331
Log Pis Std                  2.1335387
Log Pis Max                  8.101987
Log Pis Min                  -5.607666
Policy mu Mean               -0.02486766
Policy mu Std                0.9259794
Policy mu Max                1.9781936
Policy mu Min                -2.855693
Policy log std Mean          -0.51511097
Policy log std Std           0.22296545
Policy log std Max           0.008851081
Policy log std Min           -1.5296106
Z mean eval                  0.08178347
Z variance eval              0.0019531073
total_rewards                [994.85299028 996.42711241 910.58092509 863.25352361 975.82589815
 933.66734871 977.11723379 782.73570095 868.73145537 897.45609294]
total_rewards_mean           920.0648281285387
total_rewards_std            65.80030252388528
total_rewards_max            996.4271124065261
total_rewards_min            782.7357009460525
Number of train steps total  163000
Number of env steps total    817000
Number of rollouts total     0
Train Time (s)               32.89521724823862
(Previous) Eval Time (s)     9.6199762490578
Sample Time (s)              24.20323918107897
Epoch Time (s)               66.7184326783754
Total Train Time (s)         10176.302926116623
Epoch                        162
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:52:20.112964 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #162 | Epoch Duration: 65.5951635837555
2020-01-11 02:52:20.113198 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #162 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08202026
Z variance train             0.001952796
KL Divergence                13.296255
KL Loss                      1.3296255
QF Loss                      327.97467
VF Loss                      75.35312
Policy Loss                  -1240.8937
Q Predictions Mean           1237.7721
Q Predictions Std            409.54755
Q Predictions Max            1567.8262
Q Predictions Min            -0.21940899
V Predictions Mean           1236.208
V Predictions Std            407.2998
V Predictions Max            1565.3809
V Predictions Min            -1.202186
Log Pis Mean                 -0.028271839
Log Pis Std                  2.288511
Log Pis Max                  9.169273
Log Pis Min                  -4.9043064
Policy mu Mean               0.15150334
Policy mu Std                0.9486651
Policy mu Max                2.3350284
Policy mu Min                -2.7860594
Policy log std Mean          -0.49439415
Policy log std Std           0.19153753
Policy log std Max           0.09190628
Policy log std Min           -1.9602811
Z mean eval                  0.046110712
Z variance eval              0.0016364867
total_rewards                [1013.61115293 1124.66741389  988.75964727 1508.1091636  1006.66183406
  937.0741393   751.66773443 1237.98803425  862.03450612 1809.3498778 ]
total_rewards_mean           1123.9923503639825
total_rewards_std            302.76730842068633
total_rewards_max            1809.3498777965758
total_rewards_min            751.667734429658
Number of train steps total  164000
Number of env steps total    822000
Number of rollouts total     0
Train Time (s)               31.908923513721675
(Previous) Eval Time (s)     8.496354431845248
Sample Time (s)              23.792611959390342
Epoch Time (s)               64.19788990495726
Total Train Time (s)         10242.438720433973
Epoch                        163
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:53:26.250968 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #163 | Epoch Duration: 66.13762283325195
2020-01-11 02:53:26.251145 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #163 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.21411943
Z variance train             0.0003247737
KL Divergence                18.44077
KL Loss                      1.844077
QF Loss                      5004.4653
VF Loss                      347.761
Policy Loss                  -1053.4102
Q Predictions Mean           1047.8728
Q Predictions Std            467.5161
Q Predictions Max            1478.4309
Q Predictions Min            -14.800253
V Predictions Mean           1058.9481
V Predictions Std            468.877
V Predictions Max            1493.1489
V Predictions Min            -5.0089946
Log Pis Mean                 0.0020930693
Log Pis Std                  1.954437
Log Pis Max                  8.265749
Log Pis Min                  -3.2046356
Policy mu Mean               0.027605379
Policy mu Std                0.88369805
Policy mu Max                3.5107718
Policy mu Min                -2.7365994
Policy log std Mean          -0.50937265
Policy log std Std           0.21541655
Policy log std Max           0.0743908
Policy log std Min           -1.5899204
Z mean eval                  0.03287933
Z variance eval              0.0011563533
total_rewards                [1222.66745847  998.73296038 1416.45847092 1233.85457261  966.22968945
  869.37612758 1500.36650138  966.73984767 1429.55989735 1191.62598479]
total_rewards_mean           1179.5611510595468
total_rewards_std            211.23543232478397
total_rewards_max            1500.366501379141
total_rewards_min            869.3761275797995
Number of train steps total  165000
Number of env steps total    827000
Number of rollouts total     0
Train Time (s)               31.90722512314096
(Previous) Eval Time (s)     10.435774583835155
Sample Time (s)              23.251319643575698
Epoch Time (s)               65.59431935055181
Total Train Time (s)         10307.782875370234
Epoch                        164
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:54:31.597450 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #164 | Epoch Duration: 65.3461434841156
2020-01-11 02:54:31.597642 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #164 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04985113
Z variance train             0.0008747627
KL Divergence                15.304364
KL Loss                      1.5304364
QF Loss                      61.628952
VF Loss                      48.585625
Policy Loss                  -1172.6688
Q Predictions Mean           1172.9761
Q Predictions Std            482.6611
Q Predictions Max            1592.0695
Q Predictions Min            3.5693533
V Predictions Mean           1175.3448
V Predictions Std            482.53168
V Predictions Max            1595.013
V Predictions Min            3.4673338
Log Pis Mean                 -0.28641227
Log Pis Std                  2.0614402
Log Pis Max                  6.7643833
Log Pis Min                  -5.07686
Policy mu Mean               0.1566955
Policy mu Std                0.8922589
Policy mu Max                2.6068175
Policy mu Min                -2.868167
Policy log std Mean          -0.5249688
Policy log std Std           0.20435825
Policy log std Max           0.008461058
Policy log std Min           -1.5713608
Z mean eval                  0.0134224715
Z variance eval              0.00084858446
total_rewards                [ 899.64824551  922.7187144  1063.59442815  899.59561338  927.50406152
  902.80832386  967.82617435 1479.9388357   910.55355263  994.92759256]
total_rewards_mean           996.9115542064322
total_rewards_std            168.5756504496552
total_rewards_max            1479.9388357010341
total_rewards_min            899.5956133845445
Number of train steps total  166000
Number of env steps total    832000
Number of rollouts total     0
Train Time (s)               31.955539382062852
(Previous) Eval Time (s)     10.187267936766148
Sample Time (s)              22.739173708949238
Epoch Time (s)               64.88198102777824
Total Train Time (s)         10371.99454966141
Epoch                        165
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:55:35.812630 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #165 | Epoch Duration: 64.21484327316284
2020-01-11 02:55:35.812821 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #165 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014593206
Z variance train             0.0008198007
KL Divergence                15.433794
KL Loss                      1.5433794
QF Loss                      174.41794
VF Loss                      137.69814
Policy Loss                  -1176.9686
Q Predictions Mean           1176.3425
Q Predictions Std            438.24823
Q Predictions Max            1570.1227
Q Predictions Min            -1.4662818
V Predictions Mean           1184.5173
V Predictions Std            440.312
V Predictions Max            1580.916
V Predictions Min            5.8628745
Log Pis Mean                 -0.25674587
Log Pis Std                  1.8489176
Log Pis Max                  6.1500964
Log Pis Min                  -4.4428434
Policy mu Mean               0.07875836
Policy mu Std                0.87414384
Policy mu Max                3.421553
Policy mu Min                -2.6141124
Policy log std Mean          -0.5084769
Policy log std Std           0.19861858
Policy log std Max           0.11601809
Policy log std Min           -1.458339
Z mean eval                  0.012815359
Z variance eval              0.0007508278
total_rewards                [ 933.93395074 1415.44000659 1005.65157079  893.77318934  874.46875864
 1066.47992094  827.77438217 1954.01476954  897.22120596 1024.9588081 ]
total_rewards_mean           1089.3716562804752
total_rewards_std            328.56783272536927
total_rewards_max            1954.014769537033
total_rewards_min            827.7743821693828
Number of train steps total  167000
Number of env steps total    837000
Number of rollouts total     0
Train Time (s)               31.87170336395502
(Previous) Eval Time (s)     9.519797233864665
Sample Time (s)              23.02362021477893
Epoch Time (s)               64.41512081259862
Total Train Time (s)         10436.839960678946
Epoch                        166
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:56:40.659242 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #166 | Epoch Duration: 64.84624981880188
2020-01-11 02:56:40.659424 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #166 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010923174
Z variance train             0.00077130605
KL Divergence                15.654102
KL Loss                      1.5654103
QF Loss                      119.9467
VF Loss                      125.46437
Policy Loss                  -1160.4878
Q Predictions Mean           1161.9844
Q Predictions Std            460.49524
Q Predictions Max            1596.9537
Q Predictions Min            1.4355139
V Predictions Mean           1167.6239
V Predictions Std            460.1787
V Predictions Max            1595.3137
V Predictions Min            2.4354436
Log Pis Mean                 -0.12770636
Log Pis Std                  2.0311778
Log Pis Max                  7.6012306
Log Pis Min                  -5.360734
Policy mu Mean               0.0130330175
Policy mu Std                0.9161353
Policy mu Max                2.3769386
Policy mu Min                -2.695329
Policy log std Mean          -0.5304399
Policy log std Std           0.213107
Policy log std Max           0.045544207
Policy log std Min           -1.7217859
Z mean eval                  0.016299678
Z variance eval              0.001006265
total_rewards                [ 996.50315945 1250.87622364 1000.08334149  994.08270175  938.30518259
  983.73767522 1423.85850283  839.73179489 1527.43086563 1008.26520009]
total_rewards_mean           1096.2874647582255
total_rewards_std            213.9947764320436
total_rewards_max            1527.4308656339826
total_rewards_min            839.7317948854512
Number of train steps total  168000
Number of env steps total    842000
Number of rollouts total     0
Train Time (s)               32.69128482788801
(Previous) Eval Time (s)     9.950610937085003
Sample Time (s)              23.399582700338215
Epoch Time (s)               66.04147846531123
Total Train Time (s)         10503.085648749024
Epoch                        167
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:57:46.907041 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #167 | Epoch Duration: 66.24748754501343
2020-01-11 02:57:46.907275 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #167 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011727573
Z variance train             0.0009906318
KL Divergence                14.933744
KL Loss                      1.4933745
QF Loss                      301.41876
VF Loss                      196.93938
Policy Loss                  -1224.728
Q Predictions Mean           1221.7017
Q Predictions Std            391.83432
Q Predictions Max            1584.3046
Q Predictions Min            -9.375557
V Predictions Mean           1223.3201
V Predictions Std            390.754
V Predictions Max            1588.9225
V Predictions Min            -6.2256823
Log Pis Mean                 0.014686834
Log Pis Std                  2.3092892
Log Pis Max                  10.456488
Log Pis Min                  -4.2686305
Policy mu Mean               0.050743774
Policy mu Std                0.95146024
Policy mu Max                3.5891275
Policy mu Min                -2.7753189
Policy log std Mean          -0.47180033
Policy log std Std           0.18788591
Policy log std Max           0.10562304
Policy log std Min           -1.5007932
Z mean eval                  0.013590524
Z variance eval              0.000783553
total_rewards                [1338.38754489 1077.06468954 1355.31512204 1634.1345945  1222.33330535
 1154.42752179 1389.20761909 1004.78039798 1686.01723737 1024.21326402]
total_rewards_mean           1288.58812965622
total_rewards_std            226.26993707717523
total_rewards_max            1686.017237365669
total_rewards_min            1004.780397976774
Number of train steps total  169000
Number of env steps total    847000
Number of rollouts total     0
Train Time (s)               32.775944008957595
(Previous) Eval Time (s)     10.15631252201274
Sample Time (s)              22.973338816780597
Epoch Time (s)               65.90559534775093
Total Train Time (s)         10570.731982507277
Epoch                        168
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:58:54.554867 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #168 | Epoch Duration: 67.64745450019836
2020-01-11 02:58:54.555007 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #168 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013880414
Z variance train             0.0007876082
KL Divergence                15.576896
KL Loss                      1.5576895
QF Loss                      335.46112
VF Loss                      75.38687
Policy Loss                  -1201.4603
Q Predictions Mean           1199.3955
Q Predictions Std            425.3018
Q Predictions Max            1606.1165
Q Predictions Min            0.53256196
V Predictions Mean           1202.5168
V Predictions Std            424.5903
V Predictions Max            1603.8003
V Predictions Min            4.5965934
Log Pis Mean                 -0.058981165
Log Pis Std                  2.1541324
Log Pis Max                  8.44669
Log Pis Min                  -5.17161
Policy mu Mean               0.10190459
Policy mu Std                0.9010989
Policy mu Max                2.6511717
Policy mu Min                -3.0713274
Policy log std Mean          -0.5328023
Policy log std Std           0.2344052
Policy log std Max           0.12215203
Policy log std Min           -2.388114
Z mean eval                  0.027000476
Z variance eval              0.000747279
total_rewards                [1739.6310517  1100.83087023 1280.44726672 1580.37654682 1192.75460834
 1006.3008241  2267.59138808 1554.27465793 1259.36986739 1151.54080103]
total_rewards_mean           1413.311788232213
total_rewards_std            361.3698832318848
total_rewards_max            2267.591388075277
total_rewards_min            1006.3008240969176
Number of train steps total  170000
Number of env steps total    852000
Number of rollouts total     0
Train Time (s)               32.502840633969754
(Previous) Eval Time (s)     11.89782206621021
Sample Time (s)              23.40414070012048
Epoch Time (s)               67.80480340030044
Total Train Time (s)         10639.116828487255
Epoch                        169
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:00:02.944239 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #169 | Epoch Duration: 68.38900017738342
2020-01-11 03:00:02.944706 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #169 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027193759
Z variance train             0.0007510163
KL Divergence                15.705618
KL Loss                      1.5705618
QF Loss                      180.73851
VF Loss                      84.968666
Policy Loss                  -1183.4937
Q Predictions Mean           1179.4897
Q Predictions Std            439.8979
Q Predictions Max            1557.9015
Q Predictions Min            -9.863665
V Predictions Mean           1184.1709
V Predictions Std            438.40045
V Predictions Max            1556.1198
V Predictions Min            -4.3047175
Log Pis Mean                 -0.16588603
Log Pis Std                  2.2198606
Log Pis Max                  6.815064
Log Pis Min                  -5.5454803
Policy mu Mean               0.05330235
Policy mu Std                0.8901841
Policy mu Max                2.5375514
Policy mu Min                -2.8484373
Policy log std Mean          -0.53926885
Policy log std Std           0.22685412
Policy log std Max           -0.011700124
Policy log std Min           -2.1683948
Z mean eval                  0.005351482
Z variance eval              0.0004398643
total_rewards                [ 889.57823888 1168.61055205  846.62092059  995.6256517  1035.01841366
 1368.73851899 1749.80518397  898.40494822  975.44014378 1000.08810074]
total_rewards_mean           1092.7930672582424
total_rewards_std            262.37152563647993
total_rewards_max            1749.8051839724355
total_rewards_min            846.6209205865437
Number of train steps total  171000
Number of env steps total    857000
Number of rollouts total     0
Train Time (s)               32.296152513008565
(Previous) Eval Time (s)     12.481619941070676
Sample Time (s)              21.941435592249036
Epoch Time (s)               66.71920804632828
Total Train Time (s)         10703.438854776789
Epoch                        170
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:01:07.269189 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #170 | Epoch Duration: 64.32420539855957
2020-01-11 03:01:07.269389 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #170 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0054815197
Z variance train             0.00043976057
KL Divergence                16.945934
KL Loss                      1.6945934
QF Loss                      174.93326
VF Loss                      26.038128
Policy Loss                  -1207.0386
Q Predictions Mean           1202.9762
Q Predictions Std            434.64505
Q Predictions Max            1613.098
Q Predictions Min            2.275726
V Predictions Mean           1207.8634
V Predictions Std            433.5963
V Predictions Max            1608.4141
V Predictions Min            5.7403345
Log Pis Mean                 -0.055189103
Log Pis Std                  2.1034098
Log Pis Max                  7.739984
Log Pis Min                  -5.604174
Policy mu Mean               0.012884599
Policy mu Std                0.927597
Policy mu Max                2.8350058
Policy mu Min                -2.6745572
Policy log std Mean          -0.5199836
Policy log std Std           0.20702125
Policy log std Max           -0.0444763
Policy log std Min           -1.5319936
Z mean eval                  0.010328864
Z variance eval              0.00031962333
total_rewards                [ 996.3128276   997.21693575 1015.01675361 1370.81039746 1236.30812436
 1098.45279669  980.12886167  971.1447357   936.22480163 2250.35944483]
total_rewards_mean           1185.1975679293391
total_rewards_std            378.0203422050085
total_rewards_max            2250.3594448323015
total_rewards_min            936.2248016290425
Number of train steps total  172000
Number of env steps total    862000
Number of rollouts total     0
Train Time (s)               32.30528573086485
(Previous) Eval Time (s)     10.086330767720938
Sample Time (s)              22.97445551957935
Epoch Time (s)               65.36607201816514
Total Train Time (s)         10769.575104251504
Epoch                        171
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:02:13.409072 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #171 | Epoch Duration: 66.1394579410553
2020-01-11 03:02:13.409372 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #171 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010276309
Z variance train             0.0003195089
KL Divergence                17.870682
KL Loss                      1.7870682
QF Loss                      188.4719
VF Loss                      48.912872
Policy Loss                  -1174.0148
Q Predictions Mean           1171.8279
Q Predictions Std            449.8642
Q Predictions Max            1586.7289
Q Predictions Min            2.7257798
V Predictions Mean           1175.0621
V Predictions Std            448.5657
V Predictions Max            1574.63
V Predictions Min            2.6048448
Log Pis Mean                 0.050277494
Log Pis Std                  2.1976876
Log Pis Max                  8.212402
Log Pis Min                  -4.5494967
Policy mu Mean               0.053346436
Policy mu Std                0.91160774
Policy mu Max                2.7215254
Policy mu Min                -2.6457212
Policy log std Mean          -0.5054322
Policy log std Std           0.21488355
Policy log std Max           0.04834193
Policy log std Min           -1.586854
Z mean eval                  0.020149577
Z variance eval              0.00030101434
total_rewards                [1126.64283009 1138.58863928 1030.55207951  840.02873902  901.90064736
  892.90572266  876.75913491  859.70379299  937.5515124   889.93249218]
total_rewards_mean           949.4565590403324
total_rewards_std            104.0200608778485
total_rewards_max            1138.5886392846514
total_rewards_min            840.0287390196825
Number of train steps total  173000
Number of env steps total    867000
Number of rollouts total     0
Train Time (s)               32.18964773789048
(Previous) Eval Time (s)     10.85940046608448
Sample Time (s)              22.94533134577796
Epoch Time (s)               65.99437954975292
Total Train Time (s)         10832.864987418521
Epoch                        172
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:03:16.701490 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #172 | Epoch Duration: 63.29192781448364
2020-01-11 03:03:16.701728 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #172 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018484954
Z variance train             0.0003184406
KL Divergence                18.183233
KL Loss                      1.8183234
QF Loss                      101.61709
VF Loss                      43.662453
Policy Loss                  -1245.3994
Q Predictions Mean           1245.6699
Q Predictions Std            395.75555
Q Predictions Max            1565.9215
Q Predictions Min            -0.24734238
V Predictions Mean           1247.8079
V Predictions Std            394.96738
V Predictions Max            1563.0712
V Predictions Min            1.2322531
Log Pis Mean                 -0.11838508
Log Pis Std                  1.9115018
Log Pis Max                  5.9355073
Log Pis Min                  -7.186826
Policy mu Mean               0.14084104
Policy mu Std                0.8877131
Policy mu Max                2.1618724
Policy mu Min                -2.7114527
Policy log std Mean          -0.50057846
Policy log std Std           0.18495473
Policy log std Max           -0.0039975345
Policy log std Min           -1.2068406
Z mean eval                  0.5532387
Z variance eval              0.00047735497
total_rewards                [1797.06247114 1291.61055466 1012.69969318 1010.59449431  942.85482626
 1021.23613949 1210.62225541 1025.62337108 1130.77660568 1224.46237694]
total_rewards_mean           1166.7542788155588
total_rewards_std            236.3830883025725
total_rewards_max            1797.0624711414036
total_rewards_min            942.8548262635386
Number of train steps total  174000
Number of env steps total    872000
Number of rollouts total     0
Train Time (s)               32.49945333786309
(Previous) Eval Time (s)     8.156593186315149
Sample Time (s)              23.4858988635242
Epoch Time (s)               64.14194538770244
Total Train Time (s)         10899.603781049605
Epoch                        173
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:04:23.443136 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #173 | Epoch Duration: 66.7412416934967
2020-01-11 03:04:23.443387 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #173 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.5573218
Z variance train             0.00047911247
KL Divergence                19.415697
KL Loss                      1.9415697
QF Loss                      266.50696
VF Loss                      529.04
Policy Loss                  -1363.6152
Q Predictions Mean           1364.7194
Q Predictions Std            471.2712
Q Predictions Max            1753.824
Q Predictions Min            0.32666823
V Predictions Mean           1361.3247
V Predictions Std            473.70026
V Predictions Max            1760.902
V Predictions Min            -4.0972643
Log Pis Mean                 -0.2008174
Log Pis Std                  2.0625508
Log Pis Max                  8.593806
Log Pis Min                  -5.581519
Policy mu Mean               0.020520186
Policy mu Std                0.88369745
Policy mu Max                2.3605878
Policy mu Min                -2.8228168
Policy log std Mean          -0.5170262
Policy log std Std           0.18504278
Policy log std Max           -0.014407456
Policy log std Min           -1.3691537
Z mean eval                  0.26806396
Z variance eval              0.0005766886
total_rewards                [1307.85106665  997.1484394   976.82789336 1005.9847935   970.10964926
 1072.74704904 1542.846252   1241.42328796  994.76423582 1815.91236291]
total_rewards_mean           1192.5615029910225
total_rewards_std            273.7603096222822
total_rewards_max            1815.9123629132616
total_rewards_min            970.1096492649509
Number of train steps total  175000
Number of env steps total    877000
Number of rollouts total     0
Train Time (s)               32.28633315721527
(Previous) Eval Time (s)     10.755562321748585
Sample Time (s)              22.637701945379376
Epoch Time (s)               65.67959742434323
Total Train Time (s)         10965.389397603925
Epoch                        174
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:05:29.232652 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #174 | Epoch Duration: 65.7890977859497
2020-01-11 03:05:29.232844 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #174 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.3180077
Z variance train             0.00056407525
KL Divergence                18.703558
KL Loss                      1.8703558
QF Loss                      597.03546
VF Loss                      50.918243
Policy Loss                  -1222.5524
Q Predictions Mean           1217.0017
Q Predictions Std            532.64404
Q Predictions Max            1683.1324
Q Predictions Min            -2.4119318
V Predictions Mean           1219.9526
V Predictions Std            529.55945
V Predictions Max            1685.255
V Predictions Min            0.06563905
Log Pis Mean                 -0.14483154
Log Pis Std                  2.070891
Log Pis Max                  7.8317075
Log Pis Min                  -5.471417
Policy mu Mean               0.07516799
Policy mu Std                0.8968072
Policy mu Max                2.7586527
Policy mu Min                -2.7470126
Policy log std Mean          -0.5048607
Policy log std Std           0.19810176
Policy log std Max           0.014367163
Policy log std Min           -1.5234674
Z mean eval                  0.23722406
Z variance eval              0.000663628
total_rewards                [1156.14562703  907.80098797  819.63336027  815.26130777  695.06053474
  913.36817251  991.24052475  884.53989704 1013.15570206 1147.03860532]
total_rewards_mean           934.3244719459417
total_rewards_std            138.60166401612392
total_rewards_max            1156.1456270261838
total_rewards_min            695.0605347387084
Number of train steps total  176000
Number of env steps total    882000
Number of rollouts total     0
Train Time (s)               32.52976000867784
(Previous) Eval Time (s)     10.864715160802007
Sample Time (s)              23.098863881547004
Epoch Time (s)               66.49333905102685
Total Train Time (s)         11029.5767025752
Epoch                        175
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:06:33.422092 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #175 | Epoch Duration: 64.18908166885376
2020-01-11 03:06:33.422372 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #175 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.21925588
Z variance train             0.00067032565
KL Divergence                18.446445
KL Loss                      1.8446445
QF Loss                      3464.476
VF Loss                      106.44945
Policy Loss                  -1293.1332
Q Predictions Mean           1288.9291
Q Predictions Std            437.96417
Q Predictions Max            1663.7366
Q Predictions Min            1.4734576
V Predictions Mean           1287.6302
V Predictions Std            434.9983
V Predictions Max            1660.9054
V Predictions Min            4.35674
Log Pis Mean                 0.0978683
Log Pis Std                  1.9801986
Log Pis Max                  10.617777
Log Pis Min                  -4.218561
Policy mu Mean               0.15313572
Policy mu Std                0.9313064
Policy mu Max                3.5067785
Policy mu Min                -2.9522796
Policy log std Mean          -0.53599674
Policy log std Std           0.1798171
Policy log std Max           -0.107829005
Policy log std Min           -1.2326325
Z mean eval                  0.1040773
Z variance eval              0.0005187575
total_rewards                [1001.7285066  1214.21718877  698.98167615  934.25531495  937.51696478
  870.54251183  869.49561395  848.81153988  999.33917926  698.24234781]
total_rewards_mean           907.3130843981573
total_rewards_std            143.71102145945886
total_rewards_max            1214.2171887703553
total_rewards_min            698.2423478123471
Number of train steps total  177000
Number of env steps total    887000
Number of rollouts total     0
Train Time (s)               32.42857667990029
(Previous) Eval Time (s)     8.560132476035506
Sample Time (s)              23.1469628312625
Epoch Time (s)               64.1356719871983
Total Train Time (s)         11093.474036360625
Epoch                        176
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:07:37.321454 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #176 | Epoch Duration: 63.89879655838013
2020-01-11 03:07:37.321761 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #176 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10912237
Z variance train             0.00051844504
KL Divergence                18.259174
KL Loss                      1.8259175
QF Loss                      271.0055
VF Loss                      250.85167
Policy Loss                  -1251.7816
Q Predictions Mean           1251.1438
Q Predictions Std            399.80698
Q Predictions Max            1600.9094
Q Predictions Min            -3.9303722
V Predictions Mean           1251.0444
V Predictions Std            395.56903
V Predictions Max            1600.5947
V Predictions Min            -4.8727756
Log Pis Mean                 -0.103718355
Log Pis Std                  1.8861147
Log Pis Max                  9.5829315
Log Pis Min                  -4.270714
Policy mu Mean               0.02954173
Policy mu Std                0.9115256
Policy mu Max                2.9375367
Policy mu Min                -2.6751232
Policy log std Mean          -0.5335297
Policy log std Std           0.18443833
Policy log std Max           -0.03317198
Policy log std Min           -1.5391932
Z mean eval                  0.06109202
Z variance eval              0.0010497737
total_rewards                [1150.59918685 1255.50655749 1180.22261967  825.15458328 2143.052482
 1003.98411744 1168.91325692 1073.85207795  963.47988052 1103.91922795]
total_rewards_mean           1186.8683990078202
total_rewards_std            339.78234732878104
total_rewards_max            2143.0524820021947
total_rewards_min            825.1545832794673
Number of train steps total  178000
Number of env steps total    892000
Number of rollouts total     0
Train Time (s)               31.784067566972226
(Previous) Eval Time (s)     8.322925394866616
Sample Time (s)              22.92149540502578
Epoch Time (s)               63.02848836686462
Total Train Time (s)         11158.588453907054
Epoch                        177
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:08:42.439854 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #177 | Epoch Duration: 65.11791014671326
2020-01-11 03:08:42.440047 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #177 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0645781
Z variance train             0.0010498922
KL Divergence                16.991325
KL Loss                      1.6991326
QF Loss                      547.7027
VF Loss                      124.28879
Policy Loss                  -1239.554
Q Predictions Mean           1239.554
Q Predictions Std            411.37125
Q Predictions Max            1592.1603
Q Predictions Min            -12.124715
V Predictions Mean           1237.4967
V Predictions Std            406.10947
V Predictions Max            1578.8319
V Predictions Min            -4.8653216
Log Pis Mean                 0.022349387
Log Pis Std                  2.4631855
Log Pis Max                  16.452408
Log Pis Min                  -5.7743506
Policy mu Mean               0.16912161
Policy mu Std                0.9700435
Policy mu Max                3.4594917
Policy mu Min                -3.1639097
Policy log std Mean          -0.5080468
Policy log std Std           0.18488091
Policy log std Max           -0.073845655
Policy log std Min           -1.8868705
Z mean eval                  0.029369373
Z variance eval              0.0014539117
total_rewards                [1804.34478428 3159.35661817 2338.86581748 1811.99307394 2034.02172401
 1227.72129148 1157.37565148 3137.64091601  976.81378754 3084.0493823 ]
total_rewards_mean           2073.2183046699733
total_rewards_std            793.904515236963
total_rewards_max            3159.3566181741016
total_rewards_min            976.8137875420285
Number of train steps total  179000
Number of env steps total    897000
Number of rollouts total     0
Train Time (s)               32.203729269094765
(Previous) Eval Time (s)     10.412008038256317
Sample Time (s)              23.031472694594413
Epoch Time (s)               65.6472100019455
Total Train Time (s)         11233.212560554035
Epoch                        178
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:09:57.064674 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #178 | Epoch Duration: 74.62440276145935
2020-01-11 03:09:57.064962 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #178 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028415645
Z variance train             0.0014324964
KL Divergence                16.605183
KL Loss                      1.6605183
QF Loss                      409.55878
VF Loss                      336.61908
Policy Loss                  -1153.6993
Q Predictions Mean           1165.3477
Q Predictions Std            465.52576
Q Predictions Max            1586.9006
Q Predictions Min            -0.5658852
V Predictions Mean           1166.6089
V Predictions Std            462.81213
V Predictions Max            1575.2206
V Predictions Min            -7.7459555
Log Pis Mean                 -0.3291961
Log Pis Std                  2.1184676
Log Pis Max                  7.6494193
Log Pis Min                  -6.630984
Policy mu Mean               -0.091994606
Policy mu Std                0.8681291
Policy mu Max                2.2850764
Policy mu Min                -2.770722
Policy log std Mean          -0.49746016
Policy log std Std           0.1983123
Policy log std Max           -0.015901893
Policy log std Min           -1.7781099
Z mean eval                  0.032861974
Z variance eval              0.00054828747
total_rewards                [ 974.93614298 1001.00159935 1215.70571968 1069.66826072  895.30343428
 1237.06437149 3025.06565101 1534.00109665 1961.43836057 1135.30638603]
total_rewards_mean           1404.9491022766015
total_rewards_std            617.0943654224598
total_rewards_max            3025.0656510133063
total_rewards_min            895.3034342812725
Number of train steps total  180000
Number of env steps total    902000
Number of rollouts total     0
Train Time (s)               32.768794290255755
(Previous) Eval Time (s)     19.388894994277507
Sample Time (s)              22.446081303525716
Epoch Time (s)               74.60377058805898
Total Train Time (s)         11301.329411391634
Epoch                        179
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:11:05.183314 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #179 | Epoch Duration: 68.1181743144989
2020-01-11 03:11:05.183549 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #179 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028945308
Z variance train             0.00055246253
KL Divergence                18.534994
KL Loss                      1.8534994
QF Loss                      151.18181
VF Loss                      75.83807
Policy Loss                  -1150.671
Q Predictions Mean           1155.5
Q Predictions Std            489.97513
Q Predictions Max            1568.0764
Q Predictions Min            2.2832985
V Predictions Mean           1154.3911
V Predictions Std            490.90387
V Predictions Max            1559.8561
V Predictions Min            -3.8886223
Log Pis Mean                 -0.10274693
Log Pis Std                  2.2212353
Log Pis Max                  8.94339
Log Pis Min                  -6.7982273
Policy mu Mean               0.032457832
Policy mu Std                0.90543485
Policy mu Max                2.5797768
Policy mu Min                -2.844975
Policy log std Mean          -0.51330656
Policy log std Std           0.18980753
Policy log std Max           -0.03006512
Policy log std Min           -1.5862195
Z mean eval                  0.017787507
Z variance eval              0.000997106
total_rewards                [ 979.2930945   967.73851099  835.96576927 1001.13801    2147.2378498
 1812.02751125 1474.1565182  1333.30401451  941.19230451  819.98620805]
total_rewards_mean           1231.2039791089587
total_rewards_std            429.0859992114608
total_rewards_max            2147.2378498017606
total_rewards_min            819.9862080515453
Number of train steps total  181000
Number of env steps total    907000
Number of rollouts total     0
Train Time (s)               32.17868913523853
(Previous) Eval Time (s)     12.902993639931083
Sample Time (s)              23.704524809960276
Epoch Time (s)               68.78620758512989
Total Train Time (s)         11368.83822321985
Epoch                        180
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:12:12.694733 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #180 | Epoch Duration: 67.51103043556213
2020-01-11 03:12:12.694942 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #180 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017981086
Z variance train             0.0009959583
KL Divergence                17.38117
KL Loss                      1.7381171
QF Loss                      118.32744
VF Loss                      34.291927
Policy Loss                  -1168.9552
Q Predictions Mean           1167.4587
Q Predictions Std            452.73764
Q Predictions Max            1598.0707
Q Predictions Min            2.303052
V Predictions Mean           1170.484
V Predictions Std            452.33444
V Predictions Max            1592.5123
V Predictions Min            3.657099
Log Pis Mean                 -0.20061794
Log Pis Std                  2.0858479
Log Pis Max                  8.306456
Log Pis Min                  -7.4200897
Policy mu Mean               0.023565814
Policy mu Std                0.90786487
Policy mu Max                2.3059418
Policy mu Min                -2.7327404
Policy log std Mean          -0.50071
Policy log std Std           0.1957841
Policy log std Max           -0.06642085
Policy log std Min           -1.0992162
Z mean eval                  0.022049021
Z variance eval              0.0010918978
total_rewards                [1940.68853831 1048.47546413 1121.55831005 1006.24195491 1734.55426143
  955.61487932 2156.19840302 1242.19854078 1246.20806892 1000.79902374]
total_rewards_mean           1345.2537444619904
total_rewards_std            413.23995870185433
total_rewards_max            2156.198403021069
total_rewards_min            955.6148793247577
Number of train steps total  182000
Number of env steps total    912000
Number of rollouts total     0
Train Time (s)               32.52501734998077
(Previous) Eval Time (s)     11.627473948989064
Sample Time (s)              23.70241148583591
Epoch Time (s)               67.85490278480574
Total Train Time (s)         11437.76887892466
Epoch                        181
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:13:21.627861 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #181 | Epoch Duration: 68.9327745437622
2020-01-11 03:13:21.628067 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #181 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022124952
Z variance train             0.0010923925
KL Divergence                16.151894
KL Loss                      1.6151894
QF Loss                      126.67406
VF Loss                      61.56687
Policy Loss                  -1207.0509
Q Predictions Mean           1207.7065
Q Predictions Std            418.1675
Q Predictions Max            1548.6277
Q Predictions Min            -3.7068646
V Predictions Mean           1209.236
V Predictions Std            418.50684
V Predictions Max            1550.1367
V Predictions Min            4.2642026
Log Pis Mean                 -0.04871227
Log Pis Std                  2.090192
Log Pis Max                  10.110956
Log Pis Min                  -5.2606773
Policy mu Mean               0.028040959
Policy mu Std                0.89977306
Policy mu Max                2.9577134
Policy mu Min                -2.7277162
Policy log std Mean          -0.5219279
Policy log std Std           0.19001532
Policy log std Max           0.034612685
Policy log std Min           -1.1610558
Z mean eval                  0.008242262
Z variance eval              0.0015004596
total_rewards                [1407.59135202 1640.66960387  913.42278884  903.04059008  973.03633078
 2481.6879224  1845.65627546  974.51594047  996.08813808  994.77999781]
total_rewards_mean           1313.0488939811821
total_rewards_std            502.53771554469813
total_rewards_max            2481.6879224037452
total_rewards_min            903.0405900799715
Number of train steps total  183000
Number of env steps total    917000
Number of rollouts total     0
Train Time (s)               32.31495871441439
(Previous) Eval Time (s)     12.705004959367216
Sample Time (s)              23.536941229831427
Epoch Time (s)               68.55690490361303
Total Train Time (s)         11505.237611125223
Epoch                        182
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:14:29.099657 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #182 | Epoch Duration: 67.47144889831543
2020-01-11 03:14:29.099971 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #182 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.009687484
Z variance train             0.0015009886
KL Divergence                14.894338
KL Loss                      1.4894338
QF Loss                      287.05457
VF Loss                      42.006176
Policy Loss                  -1220.9447
Q Predictions Mean           1218.8324
Q Predictions Std            414.89728
Q Predictions Max            1562.4824
Q Predictions Min            -0.22795376
V Predictions Mean           1218.4749
V Predictions Std            412.33417
V Predictions Max            1558.4572
V Predictions Min            -1.9515865
Log Pis Mean                 -0.33189708
Log Pis Std                  2.2443066
Log Pis Max                  9.138112
Log Pis Min                  -7.3278184
Policy mu Mean               0.040665302
Policy mu Std                0.9161256
Policy mu Max                2.8775737
Policy mu Min                -3.6581242
Policy log std Mean          -0.5079884
Policy log std Std           0.17783907
Policy log std Max           -0.07996076
Policy log std Min           -1.2671875
Z mean eval                  0.013928227
Z variance eval              0.0018431122
total_rewards                [ 856.85882815 2078.54469408 1045.26387568 1043.79525519 1028.93265218
 1543.8233126  1630.71164815  853.88800695  856.30871674  938.76584649]
total_rewards_mean           1187.6892836218
total_rewards_std            396.9339769938836
total_rewards_max            2078.5446940825964
total_rewards_min            853.8880069480832
Number of train steps total  184000
Number of env steps total    922000
Number of rollouts total     0
Train Time (s)               32.39464753726497
(Previous) Eval Time (s)     11.619229008909315
Sample Time (s)              23.04928716039285
Epoch Time (s)               67.06316370656714
Total Train Time (s)         11570.628446147311
Epoch                        183
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:15:34.493279 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #183 | Epoch Duration: 65.39308071136475
2020-01-11 03:15:34.493472 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #183 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014634274
Z variance train             0.0018448827
KL Divergence                13.74142
KL Loss                      1.374142
QF Loss                      1868.8491
VF Loss                      339.1683
Policy Loss                  -1165.5237
Q Predictions Mean           1167.2034
Q Predictions Std            431.17142
Q Predictions Max            1550.4313
Q Predictions Min            1.7275636
V Predictions Mean           1164.2513
V Predictions Std            427.27493
V Predictions Max            1537.394
V Predictions Min            -1.3318008
Log Pis Mean                 0.02900245
Log Pis Std                  2.3259776
Log Pis Max                  9.551468
Log Pis Min                  -5.6556478
Policy mu Mean               0.10620997
Policy mu Std                0.9347099
Policy mu Max                2.8718545
Policy mu Min                -3.2859147
Policy log std Mean          -0.5203266
Policy log std Std           0.2041898
Policy log std Max           -0.04038143
Policy log std Min           -1.6765584
Z mean eval                  0.020953897
Z variance eval              0.0023233662
total_rewards                [ 990.57120171 1767.18162073 1162.47327813  900.42438756  974.74648312
  991.26613838 1217.17433083 1001.83717801 1102.24228129 1477.6191185 ]
total_rewards_mean           1158.5536018268062
total_rewards_std            256.910987636102
total_rewards_max            1767.181620725042
total_rewards_min            900.4243875647596
Number of train steps total  185000
Number of env steps total    927000
Number of rollouts total     0
Train Time (s)               32.41678704181686
(Previous) Eval Time (s)     9.948818061035126
Sample Time (s)              23.978217012714595
Epoch Time (s)               66.34382211556658
Total Train Time (s)         11637.48419875605
Epoch                        184
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:16:41.349628 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #184 | Epoch Duration: 66.85603475570679
2020-01-11 03:16:41.349751 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #184 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022506122
Z variance train             0.0023281886
KL Divergence                12.930206
KL Loss                      1.2930206
QF Loss                      119.63407
VF Loss                      368.75757
Policy Loss                  -1210.5715
Q Predictions Mean           1205.1406
Q Predictions Std            457.75208
Q Predictions Max            1579.0159
Q Predictions Min            4.074231
V Predictions Mean           1205.0166
V Predictions Std            452.1678
V Predictions Max            1575.043
V Predictions Min            3.2449691
Log Pis Mean                 -0.3383971
Log Pis Std                  1.9981589
Log Pis Max                  13.206297
Log Pis Min                  -4.9169426
Policy mu Mean               0.033608656
Policy mu Std                0.8404126
Policy mu Max                2.6495323
Policy mu Min                -3.1257102
Policy log std Mean          -0.51027185
Policy log std Std           0.18260504
Policy log std Max           -0.060727358
Policy log std Min           -1.2911803
Z mean eval                  0.020918103
Z variance eval              0.002633528
total_rewards                [3188.26785609 2044.66249749 1778.78402789 1626.85113317 1329.72112315
 3110.92981326 1271.55961825 3173.7475031  2327.68965387 3270.16753513]
total_rewards_mean           2312.2380761393224
total_rewards_std            770.6931391807443
total_rewards_max            3270.167535130662
total_rewards_min            1271.559618251743
Number of train steps total  186000
Number of env steps total    932000
Number of rollouts total     0
Train Time (s)               31.924570519011468
(Previous) Eval Time (s)     10.460678342264146
Sample Time (s)              23.942527399864048
Epoch Time (s)               66.32777626113966
Total Train Time (s)         11714.885345715564
Epoch                        185
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:17:58.753473 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #185 | Epoch Duration: 77.40360379219055
2020-01-11 03:17:58.753654 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #185 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0208669
Z variance train             0.002634307
KL Divergence                12.683533
KL Loss                      1.2683533
QF Loss                      135.2431
VF Loss                      37.591915
Policy Loss                  -1166.1395
Q Predictions Mean           1163.9515
Q Predictions Std            454.37274
Q Predictions Max            1553.5259
Q Predictions Min            0.63921773
V Predictions Mean           1165.1969
V Predictions Std            452.65762
V Predictions Max            1554.777
V Predictions Min            0.21407446
Log Pis Mean                 -0.12085298
Log Pis Std                  2.1158597
Log Pis Max                  7.2855434
Log Pis Min                  -4.769036
Policy mu Mean               -0.05969608
Policy mu Std                0.8843588
Policy mu Max                2.413131
Policy mu Min                -2.766073
Policy log std Mean          -0.5035582
Policy log std Std           0.20191526
Policy log std Max           -0.06773317
Policy log std Min           -1.6671633
Z mean eval                  0.019811083
Z variance eval              0.0028715916
total_rewards                [2155.82214953  974.385483   1592.98292379 3209.72523853 1828.23426173
 1256.97996557 1511.96741781  740.06494111 1293.59052398 1863.23261609]
total_rewards_mean           1642.6985521149695
total_rewards_std            659.8131967181881
total_rewards_max            3209.7252385275883
total_rewards_min            740.0649411063075
Number of train steps total  187000
Number of env steps total    937000
Number of rollouts total     0
Train Time (s)               32.62081643473357
(Previous) Eval Time (s)     21.53613673336804
Sample Time (s)              22.828926508314908
Epoch Time (s)               76.98587967641652
Total Train Time (s)         11785.574661088176
Epoch                        186
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:19:09.445347 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #186 | Epoch Duration: 70.69155740737915
2020-01-11 03:19:09.445528 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #186 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019016873
Z variance train             0.0028760426
KL Divergence                12.414953
KL Loss                      1.2414954
QF Loss                      186.75305
VF Loss                      233.86536
Policy Loss                  -1194.8307
Q Predictions Mean           1197.0614
Q Predictions Std            473.87015
Q Predictions Max            1587.8568
Q Predictions Min            -2.0461867
V Predictions Mean           1199.437
V Predictions Std            471.47318
V Predictions Max            1593.8116
V Predictions Min            -1.3467346
Log Pis Mean                 -0.14402233
Log Pis Std                  2.2363982
Log Pis Max                  8.055583
Log Pis Min                  -6.362528
Policy mu Mean               0.032011148
Policy mu Std                0.9147179
Policy mu Max                2.116799
Policy mu Min                -2.7212548
Policy log std Mean          -0.50127417
Policy log std Std           0.1859368
Policy log std Max           -0.08722633
Policy log std Min           -1.8100996
Z mean eval                  0.0055469745
Z variance eval              0.0032249764
total_rewards                [2356.62954884 1844.10836255 1589.65614525 1926.51705055 1299.47398457
 1377.27906758 1268.3256963  2131.7371415  1203.47904164 1530.22999452]
total_rewards_mean           1652.7436033306326
total_rewards_std            374.93307732414763
total_rewards_max            2356.629548844288
total_rewards_min            1203.4790416402927
Number of train steps total  188000
Number of env steps total    942000
Number of rollouts total     0
Train Time (s)               31.240564563311636
(Previous) Eval Time (s)     15.241476716008037
Sample Time (s)              22.708541677799076
Epoch Time (s)               69.19058295711875
Total Train Time (s)         11854.915526831057
Epoch                        187
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:20:18.788984 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #187 | Epoch Duration: 69.3433198928833
2020-01-11 03:20:18.789155 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #187 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0048082145
Z variance train             0.0032344207
KL Divergence                12.152761
KL Loss                      1.2152761
QF Loss                      153.13162
VF Loss                      61.851852
Policy Loss                  -1150.3292
Q Predictions Mean           1146.178
Q Predictions Std            482.9197
Q Predictions Max            1568.5677
Q Predictions Min            -10.499268
V Predictions Mean           1146.9198
V Predictions Std            481.336
V Predictions Max            1566.3291
V Predictions Min            -1.5769612
Log Pis Mean                 -0.37104183
Log Pis Std                  2.1629193
Log Pis Max                  7.2077723
Log Pis Min                  -4.757771
Policy mu Mean               0.005138611
Policy mu Std                0.86934704
Policy mu Max                2.3918786
Policy mu Min                -2.887571
Policy log std Mean          -0.52073574
Policy log std Std           0.21191545
Policy log std Max           -0.040313214
Policy log std Min           -1.79977
Z mean eval                  0.007783021
Z variance eval              0.0028751087
total_rewards                [ 945.27489507 1252.49407727 1690.14212223 1678.94949651 1006.95831624
 1464.39858812  983.12275236 1109.66392098  973.53770863  907.02249073]
total_rewards_mean           1201.156436814029
total_rewards_std            289.2659843638838
total_rewards_max            1690.1421222316194
total_rewards_min            907.0224907294343
Number of train steps total  189000
Number of env steps total    947000
Number of rollouts total     0
Train Time (s)               32.04051895905286
(Previous) Eval Time (s)     15.393889674916863
Sample Time (s)              23.574643636122346
Epoch Time (s)               71.00905227009207
Total Train Time (s)         11921.896917278413
Epoch                        188
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:21:25.773327 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #188 | Epoch Duration: 66.98403406143188
2020-01-11 03:21:25.773527 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #188 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008335526
Z variance train             0.0028764005
KL Divergence                12.326464
KL Loss                      1.2326463
QF Loss                      198.64871
VF Loss                      115.961365
Policy Loss                  -1197.7882
Q Predictions Mean           1196.919
Q Predictions Std            440.96362
Q Predictions Max            1591.2035
Q Predictions Min            5.142582
V Predictions Mean           1193.5044
V Predictions Std            435.72754
V Predictions Max            1577.2349
V Predictions Min            -2.967859
Log Pis Mean                 -0.12126254
Log Pis Std                  2.0962548
Log Pis Max                  14.654613
Log Pis Min                  -6.03995
Policy mu Mean               0.049923625
Policy mu Std                0.92376816
Policy mu Max                2.399307
Policy mu Min                -4.8985066
Policy log std Mean          -0.5120639
Policy log std Std           0.18817541
Policy log std Max           -0.08899504
Policy log std Min           -1.4282717
Z mean eval                  0.018493272
Z variance eval              0.002893468
total_rewards                [2092.37157812 1295.43184031 1541.2706911  1117.89952234 1446.38698464
 1014.00618945 1915.66217243 1025.24368963 1421.11958559 1920.91228702]
total_rewards_mean           1479.0304540651216
total_rewards_std            368.33154266214
total_rewards_max            2092.3715781221263
total_rewards_min            1014.0061894538954
Number of train steps total  190000
Number of env steps total    952000
Number of rollouts total     0
Train Time (s)               32.603341513779014
(Previous) Eval Time (s)     11.368542871903628
Sample Time (s)              23.880937930196524
Epoch Time (s)               67.85282231587917
Total Train Time (s)         11992.037773618475
Epoch                        189
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:22:35.916298 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #189 | Epoch Duration: 70.1426248550415
2020-01-11 03:22:35.916501 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #189 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018066768
Z variance train             0.002892519
KL Divergence                12.324162
KL Loss                      1.2324162
QF Loss                      170.69284
VF Loss                      103.40668
Policy Loss                  -1177.4672
Q Predictions Mean           1179.5737
Q Predictions Std            444.47653
Q Predictions Max            1553.3049
Q Predictions Min            -2.0462878
V Predictions Mean           1174.3126
V Predictions Std            442.31445
V Predictions Max            1537.6089
V Predictions Min            -1.5188024
Log Pis Mean                 -0.1911332
Log Pis Std                  2.1366718
Log Pis Max                  8.136047
Log Pis Min                  -4.0905623
Policy mu Mean               0.059953183
Policy mu Std                0.896384
Policy mu Max                2.8326128
Policy mu Min                -2.6877866
Policy log std Mean          -0.4982334
Policy log std Std           0.20304142
Policy log std Max           -0.06902793
Policy log std Min           -1.5500749
Z mean eval                  0.014143085
Z variance eval              0.0030290086
total_rewards                [1255.85223183  979.29081739 1226.46638157 1272.18171671 2379.26784637
 1006.19624379 1771.10392101  980.90465192 1242.96900831 1037.3386953 ]
total_rewards_mean           1315.1571514202592
total_rewards_std            419.02637562721435
total_rewards_max            2379.2678463697157
total_rewards_min            979.2908173855785
Number of train steps total  191000
Number of env steps total    957000
Number of rollouts total     0
Train Time (s)               32.40905013261363
(Previous) Eval Time (s)     13.658033846877515
Sample Time (s)              23.361056481022388
Epoch Time (s)               69.42814046051353
Total Train Time (s)         12059.275792998727
Epoch                        190
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:23:43.157949 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #190 | Epoch Duration: 67.24128866195679
2020-01-11 03:23:43.158269 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #190 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014377721
Z variance train             0.003028099
KL Divergence                12.12814
KL Loss                      1.2128141
QF Loss                      284.20203
VF Loss                      84.62216
Policy Loss                  -1193.2092
Q Predictions Mean           1183.4487
Q Predictions Std            434.65625
Q Predictions Max            1574.7393
Q Predictions Min            -20.76606
V Predictions Mean           1188.463
V Predictions Std            428.24362
V Predictions Max            1566.8293
V Predictions Min            1.9315419
Log Pis Mean                 -0.10851313
Log Pis Std                  2.1927679
Log Pis Max                  7.2415533
Log Pis Min                  -5.413657
Policy mu Mean               0.008710452
Policy mu Std                0.94348186
Policy mu Max                3.4486654
Policy mu Min                -3.1555734
Policy log std Mean          -0.5179394
Policy log std Std           0.19840428
Policy log std Max           0.08191386
Policy log std Min           -1.1871569
Z mean eval                  0.013654003
Z variance eval              0.0028380672
total_rewards                [ 928.84234301 1177.90480267 2045.07521684  824.66147142 1462.64327224
 1264.00751342 1966.74178796  950.08865459 1106.11439302 3169.13237946]
total_rewards_mean           1489.5211834632369
total_rewards_std            685.605176784787
total_rewards_max            3169.132379460695
total_rewards_min            824.661471418567
Number of train steps total  192000
Number of env steps total    962000
Number of rollouts total     0
Train Time (s)               31.916598895099014
(Previous) Eval Time (s)     11.470850876998156
Sample Time (s)              23.739870194811374
Epoch Time (s)               67.12731996690854
Total Train Time (s)         12128.37262456771
Epoch                        191
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:24:52.259267 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #191 | Epoch Duration: 69.10068845748901
2020-01-11 03:24:52.259593 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #191 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013624063
Z variance train             0.0028506485
KL Divergence                12.362348
KL Loss                      1.2362348
QF Loss                      153.09406
VF Loss                      330.0028
Policy Loss                  -1258.6559
Q Predictions Mean           1253.9786
Q Predictions Std            401.65942
Q Predictions Max            1566.9147
Q Predictions Min            -13.160859
V Predictions Mean           1260.001
V Predictions Std            397.3831
V Predictions Max            1563.7377
V Predictions Min            0.69533885
Log Pis Mean                 -0.36918604
Log Pis Std                  2.1255734
Log Pis Max                  16.806675
Log Pis Min                  -5.72427
Policy mu Mean               0.06928282
Policy mu Std                0.8583668
Policy mu Max                2.5063202
Policy mu Min                -4.321377
Policy log std Mean          -0.51247364
Policy log std Std           0.19257726
Policy log std Max           -0.007873714
Policy log std Min           -1.7851135
Z mean eval                  0.026447365
Z variance eval              0.0027314574
total_rewards                [3294.92378989 3116.28791785 1840.28251556 3229.67763563 1039.9685838
 1022.85794784 1038.0361348  1123.70651048 1004.670766   1601.2200702 ]
total_rewards_mean           1831.1631872041962
total_rewards_std            943.1289302306839
total_rewards_max            3294.9237898855513
total_rewards_min            1004.6707659984445
Number of train steps total  193000
Number of env steps total    967000
Number of rollouts total     0
Train Time (s)               32.78661653166637
(Previous) Eval Time (s)     13.443844594992697
Sample Time (s)              23.762368492782116
Epoch Time (s)               69.99282961944118
Total Train Time (s)         12202.148008584976
Epoch                        192
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:26:06.037821 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #192 | Epoch Duration: 73.77798819541931
2020-01-11 03:26:06.038002 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #192 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026885573
Z variance train             0.0027284615
KL Divergence                12.443641
KL Loss                      1.2443641
QF Loss                      206.06154
VF Loss                      51.952843
Policy Loss                  -1177.4254
Q Predictions Mean           1174.5752
Q Predictions Std            453.11398
Q Predictions Max            1556.7382
Q Predictions Min            -7.353804
V Predictions Mean           1173.5566
V Predictions Std            447.9937
V Predictions Max            1553.2853
V Predictions Min            3.2951655
Log Pis Mean                 -0.24466808
Log Pis Std                  2.1452563
Log Pis Max                  12.717401
Log Pis Min                  -5.085195
Policy mu Mean               0.1099424
Policy mu Std                0.88011706
Policy mu Max                4.2856174
Policy mu Min                -2.563917
Policy log std Mean          -0.5099714
Policy log std Std           0.19671723
Policy log std Max           -0.082832575
Policy log std Min           -1.302316
Z mean eval                  0.011353497
Z variance eval              0.0029019397
total_rewards                [2086.49452376 3152.45935444 2630.3007548  3136.87826504 1014.90772591
 3042.17301302 3121.39839849 1286.91097071 1682.93191643 1026.2835089 ]
total_rewards_mean           2218.073843150523
total_rewards_std            861.456369796937
total_rewards_max            3152.459354443667
total_rewards_min            1014.9077259147047
Number of train steps total  194000
Number of env steps total    972000
Number of rollouts total     0
Train Time (s)               32.35005473671481
(Previous) Eval Time (s)     17.228622530121356
Sample Time (s)              21.89304142119363
Epoch Time (s)               71.4717186880298
Total Train Time (s)         12277.818994265515
Epoch                        193
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:27:21.710454 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #193 | Epoch Duration: 75.67232155799866
2020-01-11 03:27:21.710626 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #193 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011614869
Z variance train             0.0028945399
KL Divergence                12.216087
KL Loss                      1.2216088
QF Loss                      177.12416
VF Loss                      96.641266
Policy Loss                  -1209.6272
Q Predictions Mean           1207.9792
Q Predictions Std            433.14767
Q Predictions Max            1601.2341
Q Predictions Min            2.7258015
V Predictions Mean           1203.7671
V Predictions Std            430.2452
V Predictions Max            1585.6245
V Predictions Min            0.66318285
Log Pis Mean                 -0.09881626
Log Pis Std                  2.284417
Log Pis Max                  9.394926
Log Pis Min                  -5.3147106
Policy mu Mean               0.0359655
Policy mu Std                0.9083923
Policy mu Max                2.4998147
Policy mu Min                -2.6249945
Policy log std Mean          -0.5226696
Policy log std Std           0.21088511
Policy log std Max           0.015922546
Policy log std Min           -1.5883924
Z mean eval                  0.050608702
Z variance eval              0.002042165
total_rewards                [1032.24201943 1578.15648508 1853.07484892 1148.16311714 3134.47439174
 3071.28143024 1004.88275531 3174.18746224 1011.77322871 1575.33739252]
total_rewards_mean           1858.357313133504
total_rewards_std            873.0220549769876
total_rewards_max            3174.187462238127
total_rewards_min            1004.8827553113597
Number of train steps total  195000
Number of env steps total    977000
Number of rollouts total     0
Train Time (s)               33.98608610732481
(Previous) Eval Time (s)     21.428918472025543
Sample Time (s)              22.9063814105466
Epoch Time (s)               78.32138598989695
Total Train Time (s)         12352.668471637182
Epoch                        194
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:28:36.562913 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #194 | Epoch Duration: 74.85215258598328
2020-01-11 03:28:36.563098 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #194 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.053120695
Z variance train             0.0023562605
KL Divergence                12.749533
KL Loss                      1.2749532
QF Loss                      190.52342
VF Loss                      80.748474
Policy Loss                  -1197.4832
Q Predictions Mean           1200.8917
Q Predictions Std            420.73395
Q Predictions Max            1577.1765
Q Predictions Min            3.0444589
V Predictions Mean           1194.7166
V Predictions Std            417.773
V Predictions Max            1564.7002
V Predictions Min            1.4429079
Log Pis Mean                 -0.26800227
Log Pis Std                  2.0258498
Log Pis Max                  6.8612905
Log Pis Min                  -4.9957347
Policy mu Mean               -0.012706511
Policy mu Std                0.87578946
Policy mu Max                2.376091
Policy mu Min                -3.0812933
Policy log std Mean          -0.5038492
Policy log std Std           0.21378012
Policy log std Max           -0.03447926
Policy log std Min           -1.7155697
Z mean eval                  0.041248538
Z variance eval              0.0018027602
total_rewards                [1773.29902775 2747.19805219 1314.06286822 1982.43976335 2944.65597135
 1282.61377661 1823.6292997   963.94091859 1325.09226335 3122.33502434]
total_rewards_mean           1927.9266965445622
total_rewards_std            724.9310354547789
total_rewards_max            3122.335024342719
total_rewards_min            963.940918592092
Number of train steps total  196000
Number of env steps total    982000
Number of rollouts total     0
Train Time (s)               34.22530283778906
(Previous) Eval Time (s)     17.959343222901225
Sample Time (s)              23.926676894072443
Epoch Time (s)               76.11132295476273
Total Train Time (s)         12430.190401267726
Epoch                        195
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:29:54.087298 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #195 | Epoch Duration: 77.52403283119202
2020-01-11 03:29:54.087484 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #195 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.038983095
Z variance train             0.0018064954
KL Divergence                13.429141
KL Loss                      1.3429141
QF Loss                      159.63614
VF Loss                      187.33875
Policy Loss                  -1217.8242
Q Predictions Mean           1221.1887
Q Predictions Std            437.22516
Q Predictions Max            1583.1647
Q Predictions Min            -2.6732812
V Predictions Mean           1228.175
V Predictions Std            437.18436
V Predictions Max            1582.0153
V Predictions Min            0.21733925
Log Pis Mean                 -0.022592459
Log Pis Std                  2.2228167
Log Pis Max                  8.507908
Log Pis Min                  -5.9737477
Policy mu Mean               -0.20480156
Policy mu Std                0.9284098
Policy mu Max                2.08056
Policy mu Min                -3.086259
Policy log std Mean          -0.5158797
Policy log std Std           0.19746825
Policy log std Max           0.03216076
Policy log std Min           -1.5322299
Z mean eval                  0.024616929
Z variance eval              0.001532899
total_rewards                [3024.95223529 1517.98629366 3180.16428022 1046.97917667 1847.03665239
 1296.35567625 1810.64195346  987.57990069  983.19706538 1290.21783839]
total_rewards_mean           1698.5111072402228
total_rewards_std            761.051125962628
total_rewards_max            3180.1642802204115
total_rewards_min            983.1970653788045
Number of train steps total  197000
Number of env steps total    987000
Number of rollouts total     0
Train Time (s)               35.03308336017653
(Previous) Eval Time (s)     19.37169587612152
Sample Time (s)              24.747306934557855
Epoch Time (s)               79.15208617085591
Total Train Time (s)         12506.828197172377
Epoch                        196
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:31:10.728354 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #196 | Epoch Duration: 76.64073133468628
2020-01-11 03:31:10.728548 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #196 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02800464
Z variance train             0.001522234
KL Divergence                13.977217
KL Loss                      1.3977216
QF Loss                      386.05048
VF Loss                      156.62613
Policy Loss                  -1246.1301
Q Predictions Mean           1245.0793
Q Predictions Std            394.258
Q Predictions Max            1578.041
Q Predictions Min            -5.871871
V Predictions Mean           1242.6775
V Predictions Std            390.34113
V Predictions Max            1567.8969
V Predictions Min            -1.2574283
Log Pis Mean                 -0.2797184
Log Pis Std                  1.964537
Log Pis Max                  9.341995
Log Pis Min                  -4.7043357
Policy mu Mean               0.03115577
Policy mu Std                0.8675877
Policy mu Max                3.1674416
Policy mu Min                -2.584064
Policy log std Mean          -0.4957473
Policy log std Std           0.18524279
Policy log std Max           0.07234022
Policy log std Min           -1.3942894
Z mean eval                  0.02318455
Z variance eval              0.0017843607
total_rewards                [1823.98310641 2732.35269792 2266.79016478  201.14523214 1204.95685868
 1931.88349243 1806.19032919 1544.4151727   198.49481608 1501.86918923]
total_rewards_mean           1521.2081059557936
total_rewards_std            771.8399783442968
total_rewards_max            2732.35269792173
total_rewards_min            198.49481607579918
Number of train steps total  198000
Number of env steps total    992000
Number of rollouts total     0
Train Time (s)               34.67744483426213
(Previous) Eval Time (s)     16.859963693656027
Sample Time (s)              23.874445585533977
Epoch Time (s)               75.41185411345214
Total Train Time (s)         12578.70943867322
Epoch                        197
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:32:22.611609 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #197 | Epoch Duration: 71.88292288780212
2020-01-11 03:32:22.611788 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #197 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023538053
Z variance train             0.0017823598
KL Divergence                13.525833
KL Loss                      1.3525833
QF Loss                      583.33624
VF Loss                      171.146
Policy Loss                  -1154.6683
Q Predictions Mean           1155.9738
Q Predictions Std            489.1032
Q Predictions Max            1565.655
Q Predictions Min            -9.484184
V Predictions Mean           1157.8037
V Predictions Std            490.24753
V Predictions Max            1576.7739
V Predictions Min            -1.121738
Log Pis Mean                 -0.053615443
Log Pis Std                  2.1027806
Log Pis Max                  8.965125
Log Pis Min                  -4.320204
Policy mu Mean               -0.03043648
Policy mu Std                0.9186943
Policy mu Max                2.898023
Policy mu Min                -2.836758
Policy log std Mean          -0.487824
Policy log std Std           0.2079988
Policy log std Max           0.023851424
Policy log std Min           -1.2862394
Z mean eval                  0.015503081
Z variance eval              0.0017332544
total_rewards                [1109.40210632 2140.59228305 1519.93793746 1076.2585644  2093.19192011
 1014.78560379 3138.28310625 1016.78754709 1541.90152291 1408.42356828]
total_rewards_mean           1605.956415965607
total_rewards_std            643.857852955423
total_rewards_max            3138.2831062515643
total_rewards_min            1014.7856037930378
Number of train steps total  199000
Number of env steps total    997000
Number of rollouts total     0
Train Time (s)               34.26530104968697
(Previous) Eval Time (s)     13.330710561014712
Sample Time (s)              23.513192788232118
Epoch Time (s)               71.1092043989338
Total Train Time (s)         12652.084450684022
Epoch                        198
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:33:35.989982 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #198 | Epoch Duration: 73.37802934646606
2020-01-11 03:33:35.990274 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #198 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015788795
Z variance train             0.0017296709
KL Divergence                13.688587
KL Loss                      1.3688587
QF Loss                      136.66144
VF Loss                      159.49503
Policy Loss                  -1188.7394
Q Predictions Mean           1184.1682
Q Predictions Std            480.66257
Q Predictions Max            1593.482
Q Predictions Min            -18.341297
V Predictions Mean           1181.3363
V Predictions Std            478.48633
V Predictions Max            1596.7177
V Predictions Min            -0.38254702
Log Pis Mean                 -0.030029483
Log Pis Std                  2.042969
Log Pis Max                  6.104021
Log Pis Min                  -4.465418
Policy mu Mean               0.051089723
Policy mu Std                0.93803287
Policy mu Max                2.474129
Policy mu Min                -2.7669675
Policy log std Mean          -0.49988183
Policy log std Std           0.18857446
Policy log std Max           -0.084764004
Policy log std Min           -1.4039204
Z mean eval                  0.018116843
Z variance eval              0.001176515
total_rewards                [2314.00349198 1448.66698747  971.98911435 1629.70782341 1839.06111479
  974.22606655 1018.40161148  995.11554659 2574.51210261 1652.13523222]
total_rewards_mean           1541.7819091443848
total_rewards_std            547.6647216989223
total_rewards_max            2574.5121026067486
total_rewards_min            971.9891143489531
Number of train steps total  200000
Number of env steps total    1002000
Number of rollouts total     0
Train Time (s)               34.956593442708254
(Previous) Eval Time (s)     15.599121518898755
Sample Time (s)              23.811608073767275
Epoch Time (s)               74.36732303537428
Total Train Time (s)         12726.03547937423
Epoch                        199
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:34:49.945554 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #199 | Epoch Duration: 73.95511388778687
2020-01-11 03:34:49.945688 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #199 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016999979
Z variance train             0.0011799017
KL Divergence                14.674641
KL Loss                      1.4674641
QF Loss                      116.09908
VF Loss                      128.46019
Policy Loss                  -1227.3966
Q Predictions Mean           1226.6924
Q Predictions Std            419.1303
Q Predictions Max            1582.2637
Q Predictions Min            -2.6594892
V Predictions Mean           1223.2052
V Predictions Std            416.69904
V Predictions Max            1575.4137
V Predictions Min            2.685093
Log Pis Mean                 -0.18817404
Log Pis Std                  1.9839466
Log Pis Max                  7.7432084
Log Pis Min                  -6.1993113
Policy mu Mean               0.058279827
Policy mu Std                0.8757294
Policy mu Max                2.8645449
Policy mu Min                -2.9505818
Policy log std Mean          -0.4973952
Policy log std Std           0.18451029
Policy log std Max           -0.02807349
Policy log std Min           -1.307089
Z mean eval                  0.023268156
Z variance eval              0.0013035142
total_rewards                [3271.6040755  1022.25863769  980.38595988 1002.72053749  978.17954846
  901.43502487 1149.25852029 2354.45479439 2027.5470935   984.0740725 ]
total_rewards_mean           1467.1918264577214
total_rewards_std            768.2131445414349
total_rewards_max            3271.6040754968635
total_rewards_min            901.4350248662748
Number of train steps total  201000
Number of env steps total    1007000
Number of rollouts total     0
Train Time (s)               34.10852917609736
(Previous) Eval Time (s)     15.186522143892944
Sample Time (s)              23.597891725599766
Epoch Time (s)               72.89294304559007
Total Train Time (s)         12797.508189278655
Epoch                        200
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:36:01.421253 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #200 | Epoch Duration: 71.47545289993286
2020-01-11 03:36:01.421435 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #200 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023173254
Z variance train             0.0013006323
KL Divergence                14.547354
KL Loss                      1.4547354
QF Loss                      142.76117
VF Loss                      66.714355
Policy Loss                  -1242.8683
Q Predictions Mean           1238.9403
Q Predictions Std            391.59058
Q Predictions Max            1586.1766
Q Predictions Min            0.94719476
V Predictions Mean           1242.633
V Predictions Std            390.4152
V Predictions Max            1593.0961
V Predictions Min            4.7524176
Log Pis Mean                 0.23464271
Log Pis Std                  2.049382
Log Pis Max                  6.970715
Log Pis Min                  -6.325634
Policy mu Mean               -0.08601827
Policy mu Std                0.96689373
Policy mu Max                2.205608
Policy mu Min                -2.4915032
Policy log std Mean          -0.5041302
Policy log std Std           0.18639977
Policy log std Max           -0.016802073
Policy log std Min           -1.5430939
Z mean eval                  0.020324668
Z variance eval              0.0011638285
total_rewards                [ 995.55985241 3115.60761175 2517.52633081 1544.72983622  974.92672548
 2963.46720464 3068.7259393  1592.75100492 3076.7341721  1886.45060212]
total_rewards_mean           2173.647927975448
total_rewards_std            829.8415416642245
total_rewards_max            3115.607611752874
total_rewards_min            974.9267254775629
Number of train steps total  202000
Number of env steps total    1012000
Number of rollouts total     0
Train Time (s)               34.25992871914059
(Previous) Eval Time (s)     13.768670903984457
Sample Time (s)              22.760722475592047
Epoch Time (s)               70.7893220987171
Total Train Time (s)         12876.119791011792
Epoch                        201
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:37:20.037947 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #201 | Epoch Duration: 78.61637020111084
2020-01-11 03:37:20.038140 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #201 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018895522
Z variance train             0.0011679882
KL Divergence                14.898067
KL Loss                      1.4898068
QF Loss                      117.021164
VF Loss                      51.769962
Policy Loss                  -1229.862
Q Predictions Mean           1229.781
Q Predictions Std            417.6766
Q Predictions Max            1586.357
Q Predictions Min            -1.7248828
V Predictions Mean           1231.4976
V Predictions Std            417.06033
V Predictions Max            1591.7288
V Predictions Min            3.8076377
Log Pis Mean                 -0.09818219
Log Pis Std                  2.0661616
Log Pis Max                  7.1374054
Log Pis Min                  -3.5569992
Policy mu Mean               -0.051967368
Policy mu Std                0.87762266
Policy mu Max                2.6880043
Policy mu Min                -2.704781
Policy log std Mean          -0.50388175
Policy log std Std           0.18542652
Policy log std Max           -0.0020374358
Policy log std Min           -1.6534133
Z mean eval                  0.030904796
Z variance eval              0.0013534982
total_rewards                [1019.81266804 2775.57614863  981.9677245  1164.62994207 2669.60584663
  992.99158848 1115.44048043 2424.86013295  960.67021342 2163.68863007]
total_rewards_mean           1626.9243375225337
total_rewards_std            737.3638108963505
total_rewards_max            2775.576148634796
total_rewards_min            960.6702134202354
Number of train steps total  203000
Number of env steps total    1017000
Number of rollouts total     0
Train Time (s)               34.981767563614994
(Previous) Eval Time (s)     21.595390308182687
Sample Time (s)              25.11333484854549
Epoch Time (s)               81.69049272034317
Total Train Time (s)         12950.784556264058
Epoch                        202
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:38:34.705044 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #202 | Epoch Duration: 74.66672253608704
2020-01-11 03:38:34.705350 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #202 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031108122
Z variance train             0.0013590375
KL Divergence                14.550158
KL Loss                      1.4550158
QF Loss                      126.58194
VF Loss                      117.914276
Policy Loss                  -1218.4641
Q Predictions Mean           1215.5425
Q Predictions Std            433.3045
Q Predictions Max            1568.8826
Q Predictions Min            0.31437355
V Predictions Mean           1211.9539
V Predictions Std            429.59805
V Predictions Max            1567.3613
V Predictions Min            2.7299771
Log Pis Mean                 0.030022092
Log Pis Std                  2.071895
Log Pis Max                  7.9381104
Log Pis Min                  -4.815683
Policy mu Mean               0.16983156
Policy mu Std                0.9398599
Policy mu Max                2.8608494
Policy mu Min                -2.6624093
Policy log std Mean          -0.4987104
Policy log std Std           0.19512004
Policy log std Max           -0.07012305
Policy log std Min           -1.753272
Z mean eval                  0.017645365
Z variance eval              0.0015832105
total_rewards                [3174.53221978 1330.96418956 1692.12621832 2367.8069977  1039.03459311
 2415.01735252 1361.40712219 1068.27427827 1270.2927032  1377.84918011]
total_rewards_mean           1709.7304854771712
total_rewards_std            671.2519031836927
total_rewards_max            3174.5322197839605
total_rewards_min            1039.0345931116556
Number of train steps total  204000
Number of env steps total    1022000
Number of rollouts total     0
Train Time (s)               34.537951150909066
(Previous) Eval Time (s)     14.571191100869328
Sample Time (s)              23.85914665926248
Epoch Time (s)               72.96828891104087
Total Train Time (s)         13024.882518510334
Epoch                        203
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:39:48.805137 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #203 | Epoch Duration: 74.09960985183716
2020-01-11 03:39:48.805342 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #203 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017732898
Z variance train             0.0015840002
KL Divergence                14.10298
KL Loss                      1.410298
QF Loss                      221.0911
VF Loss                      43.115387
Policy Loss                  -1247.4174
Q Predictions Mean           1245.4968
Q Predictions Std            392.58545
Q Predictions Max            1586.0054
Q Predictions Min            1.9942012
V Predictions Mean           1247.71
V Predictions Std            390.41678
V Predictions Max            1583.3635
V Predictions Min            -6.818566
Log Pis Mean                 -0.077285156
Log Pis Std                  2.0851011
Log Pis Max                  6.4867167
Log Pis Min                  -4.090596
Policy mu Mean               0.0358057
Policy mu Std                0.89976096
Policy mu Max                3.2825074
Policy mu Min                -3.269732
Policy log std Mean          -0.49657726
Policy log std Std           0.18911907
Policy log std Max           -0.068384826
Policy log std Min           -1.3054323
Z mean eval                  0.23263256
Z variance eval              0.0017084792
total_rewards                [2087.62621083  995.66468498 3276.28371659 2906.89158491 3005.23350349
 1464.48247985 1587.37052321  984.47236787 2457.35544754 3226.20829707]
total_rewards_mean           2199.1588816348944
total_rewards_std            853.3856870925788
total_rewards_max            3276.283716585758
total_rewards_min            984.4723678736018
Number of train steps total  205000
Number of env steps total    1027000
Number of rollouts total     0
Train Time (s)               34.672382913995534
(Previous) Eval Time (s)     15.702138016931713
Sample Time (s)              23.63302112556994
Epoch Time (s)               74.00754205649719
Total Train Time (s)         13102.657563535031
Epoch                        204
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:41:06.583001 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #204 | Epoch Duration: 77.77752208709717
2020-01-11 03:41:06.583179 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #204 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025057886
Z variance train             0.0014343166
KL Divergence                14.084213
KL Loss                      1.4084214
QF Loss                      205.5065
VF Loss                      132.72731
Policy Loss                  -1264.3595
Q Predictions Mean           1261.3782
Q Predictions Std            395.0593
Q Predictions Max            1584.8926
Q Predictions Min            -30.780056
V Predictions Mean           1263.5308
V Predictions Std            393.02798
V Predictions Max            1594.5491
V Predictions Min            2.856171
Log Pis Mean                 -0.121876486
Log Pis Std                  2.0362182
Log Pis Max                  8.878868
Log Pis Min                  -4.6427794
Policy mu Mean               0.009471598
Policy mu Std                0.8940939
Policy mu Max                2.4301975
Policy mu Min                -3.7090487
Policy log std Mean          -0.501784
Policy log std Std           0.18552415
Policy log std Max           -0.0035151243
Policy log std Min           -1.1225761
Z mean eval                  0.100170515
Z variance eval              0.0018823694
total_rewards                [2120.13625231  980.13677625 2131.8121096  3175.86105071 3287.71236397
 3231.00541025 1492.95877896 2688.91951594 1060.96564768 1603.44160325]
total_rewards_mean           2177.294950892602
total_rewards_std            841.6985677478201
total_rewards_max            3287.712363972309
total_rewards_min            980.1367762549514
Number of train steps total  206000
Number of env steps total    1032000
Number of rollouts total     0
Train Time (s)               34.68563881609589
(Previous) Eval Time (s)     19.471759513951838
Sample Time (s)              24.38645103480667
Epoch Time (s)               78.5438493648544
Total Train Time (s)         13181.244412508328
Epoch                        205
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:42:25.174603 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #205 | Epoch Duration: 78.59127140045166
2020-01-11 03:42:25.174802 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #205 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10100838
Z variance train             0.001879346
KL Divergence                13.597113
KL Loss                      1.3597113
QF Loss                      89.151535
VF Loss                      111.01951
Policy Loss                  -1233.2925
Q Predictions Mean           1233.3247
Q Predictions Std            389.1326
Q Predictions Max            1556.4648
Q Predictions Min            1.802242
V Predictions Mean           1240.629
V Predictions Std            390.5048
V Predictions Max            1557.5913
V Predictions Min            5.552917
Log Pis Mean                 -0.25381887
Log Pis Std                  2.0645006
Log Pis Max                  6.117346
Log Pis Min                  -5.624899
Policy mu Mean               -0.041087303
Policy mu Std                0.8754756
Policy mu Max                2.116456
Policy mu Min                -2.568796
Policy log std Mean          -0.47577682
Policy log std Std           0.18588912
Policy log std Max           -0.07883182
Policy log std Min           -1.1583086
Z mean eval                  0.04259815
Z variance eval              0.0019778605
total_rewards                [3097.49316646 1390.80520835 2892.42313483 3142.75419124 3118.31247518
 3133.67306905  874.48436569 3134.74099753  994.62685267 2897.51340309]
total_rewards_mean           2467.682686410653
total_rewards_std            916.362933253868
total_rewards_max            3142.7541912422703
total_rewards_min            874.4843656857034
Number of train steps total  207000
Number of env steps total    1037000
Number of rollouts total     0
Train Time (s)               32.80293134087697
(Previous) Eval Time (s)     19.518788470886648
Sample Time (s)              22.650255947373807
Epoch Time (s)               74.97197575913742
Total Train Time (s)         13260.450293194503
Epoch                        206
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:43:44.382220 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #206 | Epoch Duration: 79.20726704597473
2020-01-11 03:43:44.382465 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #206 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043433256
Z variance train             0.001976102
KL Divergence                13.326544
KL Loss                      1.3326544
QF Loss                      166.34705
VF Loss                      69.13062
Policy Loss                  -1243.1699
Q Predictions Mean           1244.9875
Q Predictions Std            375.8142
Q Predictions Max            1558.1196
Q Predictions Min            -2.8630428
V Predictions Mean           1242.0245
V Predictions Std            374.8391
V Predictions Max            1555.7125
V Predictions Min            0.28456825
Log Pis Mean                 -0.110003084
Log Pis Std                  2.0650468
Log Pis Max                  5.965447
Log Pis Min                  -4.8240185
Policy mu Mean               -0.078561254
Policy mu Std                0.9038
Policy mu Max                3.1549428
Policy mu Min                -3.5366306
Policy log std Mean          -0.47897327
Policy log std Std           0.18842967
Policy log std Max           -0.06486118
Policy log std Min           -1.3031706
Z mean eval                  0.029927636
Z variance eval              0.0017314147
total_rewards                [1006.33832634  893.86940742 1323.19939162  836.41513163 2150.17909817
 1024.3398522   913.27522742  992.96187369  991.22611368  986.4690479 ]
total_rewards_mean           1111.8273470071135
total_rewards_std            367.2605822851295
total_rewards_max            2150.179098174171
total_rewards_min            836.4151316333816
Number of train steps total  208000
Number of env steps total    1042000
Number of rollouts total     0
Train Time (s)               32.54613654408604
(Previous) Eval Time (s)     23.753747661598027
Sample Time (s)              22.676763174124062
Epoch Time (s)               78.97664737980813
Total Train Time (s)         13325.956935908645
Epoch                        207
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:44:49.891328 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #207 | Epoch Duration: 65.50869178771973
2020-01-11 03:44:49.891504 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #207 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030659938
Z variance train             0.0017293297
KL Divergence                13.616629
KL Loss                      1.3616629
QF Loss                      170.82454
VF Loss                      145.84663
Policy Loss                  -1272.6116
Q Predictions Mean           1272.3481
Q Predictions Std            382.94016
Q Predictions Max            1591.4269
Q Predictions Min            2.105215
V Predictions Mean           1276.8854
V Predictions Std            383.69055
V Predictions Max            1597.0264
V Predictions Min            1.5318031
Log Pis Mean                 -0.20356455
Log Pis Std                  1.8502688
Log Pis Max                  5.907042
Log Pis Min                  -5.146513
Policy mu Mean               0.062346756
Policy mu Std                0.8629704
Policy mu Max                2.1044557
Policy mu Min                -2.6414106
Policy log std Mean          -0.516893
Policy log std Std           0.1790375
Policy log std Max           -0.10527578
Policy log std Min           -1.2502918
Z mean eval                  0.014584573
Z variance eval              0.0016977256
total_rewards                [1210.76894603  675.78703755 3129.83030695 1217.29576819  985.41609292
 1241.69656609  795.00127145 1331.34658995  906.24226809  969.75209898]
total_rewards_mean           1246.313694620226
total_rewards_std            659.2706749839416
total_rewards_max            3129.830306953404
total_rewards_min            675.7870375495568
Number of train steps total  209000
Number of env steps total    1047000
Number of rollouts total     0
Train Time (s)               32.58967105997726
(Previous) Eval Time (s)     10.285508322995156
Sample Time (s)              21.175076172687113
Epoch Time (s)               64.05025555565953
Total Train Time (s)         13391.312875553966
Epoch                        208
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:45:55.250003 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #208 | Epoch Duration: 65.3583619594574
2020-01-11 03:45:55.250205 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #208 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014418544
Z variance train             0.0017013786
KL Divergence                13.607401
KL Loss                      1.3607401
QF Loss                      226.56424
VF Loss                      107.461334
Policy Loss                  -1268.0454
Q Predictions Mean           1261.3025
Q Predictions Std            398.53412
Q Predictions Max            1571.4238
Q Predictions Min            1.2517599
V Predictions Mean           1271.1428
V Predictions Std            401.6321
V Predictions Max            1594.3618
V Predictions Min            -2.4980283
Log Pis Mean                 -0.33551317
Log Pis Std                  1.7439759
Log Pis Max                  6.333357
Log Pis Min                  -4.67553
Policy mu Mean               0.07647696
Policy mu Std                0.83977
Policy mu Max                2.4673686
Policy mu Min                -2.6417034
Policy log std Mean          -0.49405324
Policy log std Std           0.18385601
Policy log std Max           -0.036769688
Policy log std Min           -1.4725884
Z mean eval                  0.008226733
Z variance eval              0.001769644
total_rewards                [1764.15339181  456.16103836  974.68212886 1028.18396073 2793.28123559
  930.3687474  3075.37365317  201.56517146 1076.97945359 1005.61470797]
total_rewards_mean           1330.6363488920922
total_rewards_std            892.1468510683242
total_rewards_max            3075.373653166884
total_rewards_min            201.56517146006797
Number of train steps total  210000
Number of env steps total    1052000
Number of rollouts total     0
Train Time (s)               32.557115567848086
(Previous) Eval Time (s)     11.593289927579463
Sample Time (s)              22.78905849950388
Epoch Time (s)               66.93946399493143
Total Train Time (s)         13459.0732394699
Epoch                        209
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:47:03.011433 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #209 | Epoch Duration: 67.76109647750854
2020-01-11 03:47:03.011576 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #209 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008158268
Z variance train             0.0017709933
KL Divergence                13.572355
KL Loss                      1.3572356
QF Loss                      77.67961
VF Loss                      31.203308
Policy Loss                  -1244.9563
Q Predictions Mean           1243.3618
Q Predictions Std            406.78726
Q Predictions Max            1572.8123
Q Predictions Min            2.6629605
V Predictions Mean           1245.8748
V Predictions Std            404.80463
V Predictions Max            1579.405
V Predictions Min            3.630656
Log Pis Mean                 -0.41749167
Log Pis Std                  1.9905385
Log Pis Max                  7.1593037
Log Pis Min                  -4.4327
Policy mu Mean               0.043631732
Policy mu Std                0.8344491
Policy mu Max                2.678685
Policy mu Min                -2.720705
Policy log std Mean          -0.4781841
Policy log std Std           0.19898333
Policy log std Max           0.028838605
Policy log std Min           -1.7310916
Z mean eval                  0.011275977
Z variance eval              0.0017636422
total_rewards                [ 955.74600784  705.51580578 1712.54935689  214.92760101 1179.08786714
  874.75477173 1289.35790027  611.33914363 1054.02514526 2467.62654682]
total_rewards_mean           1106.4930146377167
total_rewards_std            594.8720431145399
total_rewards_max            2467.6265468194874
total_rewards_min            214.9276010119543
Number of train steps total  211000
Number of env steps total    1057000
Number of rollouts total     0
Train Time (s)               32.67363090766594
(Previous) Eval Time (s)     12.414636936970055
Sample Time (s)              21.319335801526904
Epoch Time (s)               66.4076036461629
Total Train Time (s)         13522.727283380926
Epoch                        210
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:48:06.670319 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #210 | Epoch Duration: 63.65851330757141
2020-01-11 03:48:06.670704 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #210 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01051779
Z variance train             0.0017658519
KL Divergence                13.562447
KL Loss                      1.3562447
QF Loss                      198.49576
VF Loss                      56.193707
Policy Loss                  -1236.6007
Q Predictions Mean           1239.8794
Q Predictions Std            443.2857
Q Predictions Max            1627.8281
Q Predictions Min            6.2770886
V Predictions Mean           1239.3517
V Predictions Std            444.41037
V Predictions Max            1632.85
V Predictions Min            1.8889005
Log Pis Mean                 -0.42843193
Log Pis Std                  1.9531114
Log Pis Max                  6.618271
Log Pis Min                  -4.801468
Policy mu Mean               0.027389785
Policy mu Std                0.8462531
Policy mu Max                2.3084476
Policy mu Min                -2.7846155
Policy log std Mean          -0.4717163
Policy log std Std           0.18217842
Policy log std Max           0.009310663
Policy log std Min           -1.124519
Z mean eval                  0.036714014
Z variance eval              0.0019200144
total_rewards                [819.98599109 463.03506503 785.76416089 430.13447755 705.84167675
 201.28357017 665.43292551 460.00590484 766.90838192 582.56116107]
total_rewards_mean           588.0953314811482
total_rewards_std            187.4348486758025
total_rewards_max            819.9859910850264
total_rewards_min            201.28357016648766
Number of train steps total  212000
Number of env steps total    1062000
Number of rollouts total     0
Train Time (s)               33.70676553295925
(Previous) Eval Time (s)     9.665194456931204
Sample Time (s)              23.642635563854128
Epoch Time (s)               67.01459555374458
Total Train Time (s)         13585.997721490916
Epoch                        211
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:49:09.942380 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #211 | Epoch Duration: 63.2714569568634
2020-01-11 03:49:09.942580 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #211 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03647175
Z variance train             0.0019214904
KL Divergence                13.397612
KL Loss                      1.3397611
QF Loss                      75.48088
VF Loss                      62.385685
Policy Loss                  -1272.6643
Q Predictions Mean           1274.5571
Q Predictions Std            371.75342
Q Predictions Max            1625.2365
Q Predictions Min            2.7316194
V Predictions Mean           1275.1243
V Predictions Std            370.61398
V Predictions Max            1625.546
V Predictions Min            0.63284355
Log Pis Mean                 -0.40096575
Log Pis Std                  1.8909492
Log Pis Max                  6.211441
Log Pis Min                  -6.431894
Policy mu Mean               -0.05372804
Policy mu Std                0.86833936
Policy mu Max                2.2231386
Policy mu Min                -2.9230244
Policy log std Mean          -0.48603797
Policy log std Std           0.17657797
Policy log std Max           0.06077522
Policy log std Min           -1.2539839
Z mean eval                  0.022677267
Z variance eval              0.0021904665
total_rewards                [591.67363099 420.32187293 661.49601109 610.32260418 887.35142899
 192.99207296  18.89336971 652.69255305 655.9736784  424.36166174]
total_rewards_mean           511.6078884023871
total_rewards_std            240.99373752352562
total_rewards_max            887.3514289926225
total_rewards_min            18.89336970636012
Number of train steps total  213000
Number of env steps total    1067000
Number of rollouts total     0
Train Time (s)               32.51645279210061
(Previous) Eval Time (s)     5.921771047171205
Sample Time (s)              19.82446401519701
Epoch Time (s)               58.26268785446882
Total Train Time (s)         13643.125975230243
Epoch                        212
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:50:07.073590 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #212 | Epoch Duration: 57.130784034729004
2020-01-11 03:50:07.073870 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #212 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022058595
Z variance train             0.002185834
KL Divergence                13.017111
KL Loss                      1.3017111
QF Loss                      140.8595
VF Loss                      33.925606
Policy Loss                  -1281.1282
Q Predictions Mean           1283.5873
Q Predictions Std            399.7824
Q Predictions Max            1579.3022
Q Predictions Min            2.3370667
V Predictions Mean           1278.1439
V Predictions Std            398.04184
V Predictions Max            1572.9432
V Predictions Min            4.517834
Log Pis Mean                 -0.39564377
Log Pis Std                  1.8153527
Log Pis Max                  6.4145665
Log Pis Min                  -5.743714
Policy mu Mean               0.024495617
Policy mu Std                0.8254433
Policy mu Max                1.9543307
Policy mu Min                -2.7742224
Policy log std Mean          -0.5117927
Policy log std Std           0.1812075
Policy log std Max           -0.029254913
Policy log std Min           -1.1990516
Z mean eval                  0.013368905
Z variance eval              0.0025293694
total_rewards                [ 193.45548738 1094.1099296     4.30426149  567.34272518  205.91396275
  434.68493111 1210.77392421  200.35607572  633.90750934  599.75060843]
total_rewards_mean           514.4599415222422
total_rewards_std            375.32847861038834
total_rewards_max            1210.7739242108626
total_rewards_min            4.304261485821845
Number of train steps total  214000
Number of env steps total    1072000
Number of rollouts total     0
Train Time (s)               32.7391717559658
(Previous) Eval Time (s)     4.7895510559901595
Sample Time (s)              19.76363790873438
Epoch Time (s)               57.29236072069034
Total Train Time (s)         13701.094590263441
Epoch                        213
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:51:05.044667 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #213 | Epoch Duration: 57.9706244468689
2020-01-11 03:51:05.044844 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #213 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013214206
Z variance train             0.0025303978
KL Divergence                12.571934
KL Loss                      1.2571934
QF Loss                      204.81552
VF Loss                      59.628853
Policy Loss                  -1305.829
Q Predictions Mean           1305.0757
Q Predictions Std            304.32712
Q Predictions Max            1574.1796
Q Predictions Min            5.822961
V Predictions Mean           1306.5409
V Predictions Std            303.54074
V Predictions Max            1574.4697
V Predictions Min            6.7226887
Log Pis Mean                 0.009407628
Log Pis Std                  2.145683
Log Pis Max                  8.471709
Log Pis Min                  -5.045229
Policy mu Mean               0.12529899
Policy mu Std                0.9080056
Policy mu Max                2.7869165
Policy mu Min                -2.4938395
Policy log std Mean          -0.5324206
Policy log std Std           0.18068232
Policy log std Max           -0.11198306
Policy log std Min           -1.4808313
Z mean eval                  0.047974706
Z variance eval              0.003619209
total_rewards                [295.57415234   8.5637569  572.09568678 430.26480078 204.40977169
 193.05712012  13.31738498 317.71204965 208.18910675 673.00585085]
total_rewards_mean           291.6189680856084
total_rewards_std            206.37217610332334
total_rewards_max            673.0058508493398
total_rewards_min            8.56375690262535
Number of train steps total  215000
Number of env steps total    1077000
Number of rollouts total     0
Train Time (s)               32.926595989149064
(Previous) Eval Time (s)     5.46751292841509
Sample Time (s)              21.901793260127306
Epoch Time (s)               60.29590217769146
Total Train Time (s)         13759.014895315748
Epoch                        214
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:52:02.968191 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #214 | Epoch Duration: 57.92319989204407
2020-01-11 03:52:02.968424 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #214 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.052358307
Z variance train             0.0036465817
KL Divergence                12.054414
KL Loss                      1.2054414
QF Loss                      133.14835
VF Loss                      133.02383
Policy Loss                  -1242.9854
Q Predictions Mean           1243.0048
Q Predictions Std            373.4239
Q Predictions Max            1600.7639
Q Predictions Min            -4.809393
V Predictions Mean           1250.8969
V Predictions Std            374.382
V Predictions Max            1609.5552
V Predictions Min            1.0727009
Log Pis Mean                 -0.2810046
Log Pis Std                  1.8229539
Log Pis Max                  7.1720023
Log Pis Min                  -4.6585383
Policy mu Mean               0.023200043
Policy mu Std                0.82383305
Policy mu Max                2.667416
Policy mu Min                -2.761385
Policy log std Mean          -0.5134254
Policy log std Std           0.16173404
Policy log std Max           -0.108661145
Policy log std Min           -1.2709892
Z mean eval                  0.038067944
Z variance eval              0.0034948483
total_rewards                [543.43377568 566.34118009 191.48888445 274.01295559 331.03517697
 621.60273232 324.20097991 344.33536211 339.62108426 370.45498702]
total_rewards_mean           390.6527118394384
total_rewards_std            131.88821831861196
total_rewards_max            621.6027323207883
total_rewards_min            191.4888844463046
Number of train steps total  216000
Number of env steps total    1082000
Number of rollouts total     0
Train Time (s)               32.605213499162346
(Previous) Eval Time (s)     3.0944563690572977
Sample Time (s)              19.492234737612307
Epoch Time (s)               55.19190460583195
Total Train Time (s)         13814.634207842406
Epoch                        215
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:52:58.589353 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #215 | Epoch Duration: 55.62076783180237
2020-01-11 03:52:58.589530 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #215 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011378332
Z variance train             0.0039356975
KL Divergence                11.7092
KL Loss                      1.17092
QF Loss                      615.57007
VF Loss                      166.12473
Policy Loss                  -1238.327
Q Predictions Mean           1227.9792
Q Predictions Std            430.63232
Q Predictions Max            1622.9802
Q Predictions Min            1.8587419
V Predictions Mean           1232.4512
V Predictions Std            428.88425
V Predictions Max            1626.3655
V Predictions Min            4.746866
Log Pis Mean                 -0.25423467
Log Pis Std                  2.0540729
Log Pis Max                  8.28324
Log Pis Min                  -5.0596323
Policy mu Mean               -0.029428093
Policy mu Std                0.8721068
Policy mu Max                2.6511955
Policy mu Min                -2.6408286
Policy log std Mean          -0.50868636
Policy log std Std           0.16717829
Policy log std Max           -0.06884092
Policy log std Min           -1.0713892
Z mean eval                  0.022203712
Z variance eval              0.0022565038
total_rewards                [448.60331724 339.49526191 579.25208469   6.85089657  49.5697851
 212.65307697  10.33433296 192.14051611 250.47908476   9.65467738]
total_rewards_mean           209.9033033691531
total_rewards_std            189.47933123371695
total_rewards_max            579.252084686163
total_rewards_min            6.850896569952407
Number of train steps total  217000
Number of env steps total    1087000
Number of rollouts total     0
Train Time (s)               32.34052914194763
(Previous) Eval Time (s)     3.5230083391070366
Sample Time (s)              18.375830090604722
Epoch Time (s)               54.239367571659386
Total Train Time (s)         13868.202561412472
Epoch                        216
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:53:52.160929 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #216 | Epoch Duration: 53.571264028549194
2020-01-11 03:53:52.161098 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #216 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021812217
Z variance train             0.0022539296
KL Divergence                12.935299
KL Loss                      1.2935299
QF Loss                      74.74376
VF Loss                      35.819588
Policy Loss                  -1263.5383
Q Predictions Mean           1263.9062
Q Predictions Std            356.6809
Q Predictions Max            1597.7294
Q Predictions Min            0.9001338
V Predictions Mean           1259.8102
V Predictions Std            355.15338
V Predictions Max            1586.8589
V Predictions Min            0.22077858
Log Pis Mean                 -0.327499
Log Pis Std                  1.8685049
Log Pis Max                  5.7177906
Log Pis Min                  -4.2369375
Policy mu Mean               -0.03323902
Policy mu Std                0.82385373
Policy mu Max                2.1203094
Policy mu Min                -2.9603865
Policy log std Mean          -0.5014668
Policy log std Std           0.17792799
Policy log std Max           -0.075089425
Policy log std Min           -1.4062877
Z mean eval                  0.007935012
Z variance eval              0.0015112167
total_rewards                [152.90860305 464.91015732 200.17992624  10.38774942 210.37817903
  11.36681099 418.86593723 210.0199365  558.65517872 221.75779544]
total_rewards_mean           245.94302739453124
total_rewards_std            173.21663733135878
total_rewards_max            558.6551787186223
total_rewards_min            10.387749424454654
Number of train steps total  218000
Number of env steps total    1092000
Number of rollouts total     0
Train Time (s)               32.92175732599571
(Previous) Eval Time (s)     2.854534226935357
Sample Time (s)              18.661732469219714
Epoch Time (s)               54.438024022150785
Total Train Time (s)         13922.755125795957
Epoch                        217
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:54:46.715824 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #217 | Epoch Duration: 54.55459117889404
2020-01-11 03:54:46.716003 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #217 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010263377
Z variance train             0.0015212817
KL Divergence                13.847073
KL Loss                      1.3847073
QF Loss                      281.00952
VF Loss                      237.36691
Policy Loss                  -1248.3774
Q Predictions Mean           1248.1611
Q Predictions Std            400.73444
Q Predictions Max            1578.5265
Q Predictions Min            2.7644887
V Predictions Mean           1248.6965
V Predictions Std            401.81213
V Predictions Max            1583.8833
V Predictions Min            -5.6731057
Log Pis Mean                 -0.25422195
Log Pis Std                  2.0060074
Log Pis Max                  7.897271
Log Pis Min                  -4.7944145
Policy mu Mean               0.089642435
Policy mu Std                0.87730795
Policy mu Max                3.6340435
Policy mu Min                -2.657425
Policy log std Mean          -0.48945686
Policy log std Std           0.17435637
Policy log std Max           -0.09782985
Policy log std Min           -1.0873404
Z mean eval                  0.035034154
Z variance eval              0.0014566726
total_rewards                [194.77600308 234.54493012 243.41584089 287.88151508 512.02014207
 525.50622669 361.84619991 212.59651199 376.01785221 362.26836381]
total_rewards_mean           331.08735858348535
total_rewards_std            112.23494369637555
total_rewards_max            525.5062266859159
total_rewards_min            194.7760030767082
Number of train steps total  219000
Number of env steps total    1097000
Number of rollouts total     0
Train Time (s)               32.39227351732552
(Previous) Eval Time (s)     2.9707770249806345
Sample Time (s)              18.552665625698864
Epoch Time (s)               53.91571616800502
Total Train Time (s)         13977.901405600831
Epoch                        218
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:55:41.865247 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #218 | Epoch Duration: 55.14910340309143
2020-01-11 03:55:41.865439 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #218 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034561858
Z variance train             0.0014564167
KL Divergence                14.122078
KL Loss                      1.4122078
QF Loss                      166.3154
VF Loss                      139.16022
Policy Loss                  -1301.4181
Q Predictions Mean           1300.489
Q Predictions Std            398.7032
Q Predictions Max            1638.2142
Q Predictions Min            4.60362
V Predictions Mean           1308.8257
V Predictions Std            401.4357
V Predictions Max            1649.2245
V Predictions Min            4.4917207
Log Pis Mean                 -0.1676309
Log Pis Std                  1.865614
Log Pis Max                  6.747891
Log Pis Min                  -5.1857386
Policy mu Mean               0.087786674
Policy mu Std                0.8714722
Policy mu Max                2.1689572
Policy mu Min                -2.67222
Policy log std Mean          -0.50743526
Policy log std Std           0.17802161
Policy log std Max           -0.06338978
Policy log std Min           -1.0512309
Z mean eval                  0.030719712
Z variance eval              0.0014089653
total_rewards                [556.42434772 196.48052336 257.0341836  219.46984984  43.74002687
 203.29081297 443.67532699 219.11368384  12.5726941  189.58786328]
total_rewards_mean           234.13893125801937
total_rewards_std            154.4138670507784
total_rewards_max            556.4243477188915
total_rewards_min            12.572694104164587
Number of train steps total  220000
Number of env steps total    1102000
Number of rollouts total     0
Train Time (s)               32.586755481082946
(Previous) Eval Time (s)     4.203815183136612
Sample Time (s)              17.588774194009602
Epoch Time (s)               54.37934485822916
Total Train Time (s)         14031.416945092846
Epoch                        219
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:56:35.383303 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #219 | Epoch Duration: 53.51771855354309
2020-01-11 03:56:35.383507 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #219 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013031645
Z variance train             0.0015179099
KL Divergence                13.94985
KL Loss                      1.3949851
QF Loss                      97.93785
VF Loss                      84.01117
Policy Loss                  -1313.0577
Q Predictions Mean           1315.314
Q Predictions Std            384.86386
Q Predictions Max            1651.443
Q Predictions Min            1.7058215
V Predictions Mean           1308.5466
V Predictions Std            382.22614
V Predictions Max            1643.6549
V Predictions Min            4.824306
Log Pis Mean                 -0.1376502
Log Pis Std                  1.8144494
Log Pis Max                  7.525122
Log Pis Min                  -5.589406
Policy mu Mean               0.02868844
Policy mu Std                0.8652761
Policy mu Max                2.424176
Policy mu Min                -2.5270293
Policy log std Mean          -0.50210685
Policy log std Std           0.190717
Policy log std Max           -0.08502191
Policy log std Min           -1.786006
Z mean eval                  0.015828636
Z variance eval              0.0012816044
total_rewards                [312.04547002  14.86870181 251.31833522 234.87401756  28.92003445
 191.55620211   6.72595446 289.54634958 224.39836886 196.05760616]
total_rewards_mean           175.03110402210376
total_rewards_std            109.43809962551659
total_rewards_max            312.0454700150773
total_rewards_min            6.725954461776397
Number of train steps total  221000
Number of env steps total    1107000
Number of rollouts total     0
Train Time (s)               32.21103408141062
(Previous) Eval Time (s)     3.3418953330256045
Sample Time (s)              18.021620948798954
Epoch Time (s)               53.574550363235176
Total Train Time (s)         14084.283719316125
Epoch                        220
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:57:28.253111 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #220 | Epoch Duration: 52.86946630477905
2020-01-11 03:57:28.253284 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #220 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015650228
Z variance train             0.0012798756
KL Divergence                14.39264
KL Loss                      1.439264
QF Loss                      166.61877
VF Loss                      129.49997
Policy Loss                  -1281.5011
Q Predictions Mean           1282.6685
Q Predictions Std            370.0548
Q Predictions Max            1595.7915
Q Predictions Min            -0.10094097
V Predictions Mean           1286.196
V Predictions Std            367.27982
V Predictions Max            1597.8334
V Predictions Min            2.2946756
Log Pis Mean                 -0.06415342
Log Pis Std                  2.1547668
Log Pis Max                  9.257061
Log Pis Min                  -5.3264885
Policy mu Mean               -0.08072273
Policy mu Std                0.9279979
Policy mu Max                2.5359504
Policy mu Min                -3.0832384
Policy log std Mean          -0.5110193
Policy log std Std           0.18402193
Policy log std Max           0.0026780963
Policy log std Min           -1.5552859
Z mean eval                  0.009670686
Z variance eval              0.0014428229
total_rewards                [194.0769009  197.41977539 361.94218372 206.06353753 192.75080476
 186.47134364 202.40490833 199.77069767 177.69418022 189.15785408]
total_rewards_mean           210.77521862438653
total_rewards_std            50.989447845897104
total_rewards_max            361.9421837215296
total_rewards_min            177.6941802204676
Number of train steps total  222000
Number of env steps total    1112000
Number of rollouts total     0
Train Time (s)               32.475458960048854
(Previous) Eval Time (s)     2.636517711915076
Sample Time (s)              16.53467743145302
Epoch Time (s)               51.64665410341695
Total Train Time (s)         14136.200836455915
Epoch                        221
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:58:20.172278 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #221 | Epoch Duration: 51.918776988983154
2020-01-11 03:58:20.172639 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #221 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045606356
Z variance train             0.0012772387
KL Divergence                14.475246
KL Loss                      1.4475247
QF Loss                      295.7721
VF Loss                      198.55365
Policy Loss                  -1269.4808
Q Predictions Mean           1263.2773
Q Predictions Std            394.703
Q Predictions Max            1642.6797
Q Predictions Min            5.52252
V Predictions Mean           1274.5972
V Predictions Std            393.70062
V Predictions Max            1646.2583
V Predictions Min            7.217606
Log Pis Mean                 0.12209296
Log Pis Std                  2.2241333
Log Pis Max                  11.137041
Log Pis Min                  -4.9689674
Policy mu Mean               0.051379025
Policy mu Std                0.9333685
Policy mu Max                2.9505997
Policy mu Min                -3.856933
Policy log std Mean          -0.4946917
Policy log std Std           0.1783407
Policy log std Max           -0.03942445
Policy log std Min           -1.4082541
Z mean eval                  0.01694935
Z variance eval              0.0015414779
total_rewards                [215.83682879 461.14150321 378.07746498 455.13219875 389.74237756
 223.20601183 223.31857569 567.16285048 227.94469614 209.43474325]
total_rewards_mean           335.0997250682298
total_rewards_std            124.69694426040259
total_rewards_max            567.1628504839522
total_rewards_min            209.43474325216667
Number of train steps total  223000
Number of env steps total    1117000
Number of rollouts total     0
Train Time (s)               32.139795020222664
(Previous) Eval Time (s)     2.9083144878968596
Sample Time (s)              16.37744714645669
Epoch Time (s)               51.42555665457621
Total Train Time (s)         14188.56686240714
Epoch                        222
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:59:12.541269 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #222 | Epoch Duration: 52.368443727493286
2020-01-11 03:59:12.541561 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #222 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014851895
Z variance train             0.0015487068
KL Divergence                13.895591
KL Loss                      1.3895591
QF Loss                      204.79497
VF Loss                      40.005188
Policy Loss                  -1298.7557
Q Predictions Mean           1294.4436
Q Predictions Std            369.0724
Q Predictions Max            1615.9056
Q Predictions Min            1.6354504
V Predictions Mean           1298.6277
V Predictions Std            369.7498
V Predictions Max            1619.2218
V Predictions Min            3.9950213
Log Pis Mean                 -0.18932232
Log Pis Std                  1.9307463
Log Pis Max                  5.6979046
Log Pis Min                  -5.576292
Policy mu Mean               -0.0960206
Policy mu Std                0.90900147
Policy mu Max                2.4953988
Policy mu Min                -2.617163
Policy log std Mean          -0.48144364
Policy log std Std           0.1785664
Policy log std Max           -0.014633715
Policy log std Min           -1.3383523
Z mean eval                  0.31412482
Z variance eval              0.0019704676
total_rewards                [204.75602149 553.97005424 627.66077549  14.11821787 476.75820403
 214.44913621 215.25321291 200.76266845 264.89298695 622.12426699]
total_rewards_mean           339.4745544639425
total_rewards_std            201.90809819688053
total_rewards_max            627.6607754928136
total_rewards_min            14.118217871768827
Number of train steps total  224000
Number of env steps total    1122000
Number of rollouts total     0
Train Time (s)               31.969830831047148
(Previous) Eval Time (s)     3.8508705222047865
Sample Time (s)              16.387629914097488
Epoch Time (s)               52.20833126734942
Total Train Time (s)         14240.961697734427
Epoch                        223
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:00:04.941088 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #223 | Epoch Duration: 52.39936280250549
2020-01-11 04:00:04.941430 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #223 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023645634
Z variance train             0.0022740797
KL Divergence                13.153368
KL Loss                      1.3153368
QF Loss                      156.8616
VF Loss                      61.351418
Policy Loss                  -1272.6761
Q Predictions Mean           1271.2378
Q Predictions Std            411.0969
Q Predictions Max            1611.0275
Q Predictions Min            -13.6281595
V Predictions Mean           1276.892
V Predictions Std            408.93015
V Predictions Max            1617.1378
V Predictions Min            -9.2037735
Log Pis Mean                 -0.31962737
Log Pis Std                  1.9441489
Log Pis Max                  11.23616
Log Pis Min                  -4.7690163
Policy mu Mean               0.054276157
Policy mu Std                0.8638104
Policy mu Max                2.2643712
Policy mu Min                -2.744764
Policy log std Mean          -0.48452207
Policy log std Std           0.17318669
Policy log std Max           -0.04585746
Policy log std Min           -1.0819176
Z mean eval                  0.02404597
Z variance eval              0.002343303
total_rewards                [144.89520499 220.97776106 199.55189854   3.07274014  14.25668719
 558.91188587   8.63605923 194.97791732   6.48047665 202.05837062]
total_rewards_mean           155.3819001592607
total_rewards_std            161.17293353718935
total_rewards_max            558.9118858670379
total_rewards_min            3.0727401428991836
Number of train steps total  225000
Number of env steps total    1127000
Number of rollouts total     0
Train Time (s)               32.15449493331835
(Previous) Eval Time (s)     4.0416345237754285
Sample Time (s)              19.227646886836737
Epoch Time (s)               55.42377634393051
Total Train Time (s)         14294.285233017523
Epoch                        224
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:00:58.270352 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #224 | Epoch Duration: 53.32860970497131
2020-01-11 04:00:58.270774 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #224 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024268115
Z variance train             0.002342165
KL Divergence                13.18894
KL Loss                      1.318894
QF Loss                      110.777405
VF Loss                      82.97477
Policy Loss                  -1337.7623
Q Predictions Mean           1337.9944
Q Predictions Std            278.92606
Q Predictions Max            1602.9047
Q Predictions Min            1.5025953
V Predictions Mean           1334.7872
V Predictions Std            277.5394
V Predictions Max            1602.9336
V Predictions Min            -1.8759899
Log Pis Mean                 -0.012071248
Log Pis Std                  2.009755
Log Pis Max                  10.179168
Log Pis Min                  -4.686816
Policy mu Mean               0.103372715
Policy mu Std                0.92040175
Policy mu Max                2.4639468
Policy mu Min                -2.818831
Policy log std Mean          -0.50284463
Policy log std Std           0.15714017
Policy log std Max           -0.10887897
Policy log std Min           -1.2828523
Z mean eval                  0.01237455
Z variance eval              0.0021958523
total_rewards                [462.03198442 457.38082346 450.24545067   6.65151914   6.87678885
 262.24554682 261.04550851 252.86317152  16.0062198  476.07754524]
total_rewards_mean           265.14245584380905
total_rewards_std            187.14736123739786
total_rewards_max            476.0775452361052
total_rewards_min            6.651519135738013
Number of train steps total  226000
Number of env steps total    1132000
Number of rollouts total     0
Train Time (s)               32.673210768029094
(Previous) Eval Time (s)     1.9461469310335815
Sample Time (s)              17.05143326241523
Epoch Time (s)               51.670790961477906
Total Train Time (s)         14347.303446357604
Epoch                        225
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:01:51.287174 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #225 | Epoch Duration: 53.01608657836914
2020-01-11 04:01:51.287396 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #225 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012241775
Z variance train             0.0021942868
KL Divergence                13.207744
KL Loss                      1.3207744
QF Loss                      132.22229
VF Loss                      59.02487
Policy Loss                  -1340.9115
Q Predictions Mean           1341.3506
Q Predictions Std            340.93854
Q Predictions Max            1659.5895
Q Predictions Min            1.2173522
V Predictions Mean           1344.7573
V Predictions Std            343.14423
V Predictions Max            1664.9861
V Predictions Min            1.7539078
Log Pis Mean                 -0.27203786
Log Pis Std                  2.1708908
Log Pis Max                  12.916452
Log Pis Min                  -4.970916
Policy mu Mean               -0.050155044
Policy mu Std                0.8841407
Policy mu Max                2.7865982
Policy mu Min                -3.7263439
Policy log std Mean          -0.5051189
Policy log std Std           0.16404659
Policy log std Max           0.20206451
Policy log std Min           -1.5207827
Z mean eval                  0.31584337
Z variance eval              0.00213148
total_rewards                [215.07026849 236.72793571 203.50133375  27.15208976 218.70499353
  15.50029309 211.56819785 193.6316722  218.07845721  39.1927758 ]
total_rewards_mean           157.9128017379212
total_rewards_std            86.31429921703732
total_rewards_max            236.72793570516382
total_rewards_min            15.500293089131688
Number of train steps total  227000
Number of env steps total    1137000
Number of rollouts total     0
Train Time (s)               33.10321337077767
(Previous) Eval Time (s)     3.2911783107556403
Sample Time (s)              16.985983293503523
Epoch Time (s)               53.38037497503683
Total Train Time (s)         14399.866511037573
Epoch                        226
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:02:43.852845 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #226 | Epoch Duration: 52.565282106399536
2020-01-11 04:02:43.853026 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #226 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.3251353
Z variance train             0.0021326577
KL Divergence                13.76041
KL Loss                      1.376041
QF Loss                      178.78122
VF Loss                      138.27977
Policy Loss                  -1411.6998
Q Predictions Mean           1410.4719
Q Predictions Std            430.15143
Q Predictions Max            1770.2404
Q Predictions Min            3.395587
V Predictions Mean           1404.8735
V Predictions Std            428.86206
V Predictions Max            1755.9325
V Predictions Min            2.4490716
Log Pis Mean                 -0.18429819
Log Pis Std                  2.095985
Log Pis Max                  11.559625
Log Pis Min                  -5.8938017
Policy mu Mean               0.1260656
Policy mu Std                0.9143453
Policy mu Max                2.2444131
Policy mu Min                -3.052838
Policy log std Mean          -0.48497665
Policy log std Std           0.16594547
Policy log std Max           -0.06722084
Policy log std Min           -1.6844292
Z mean eval                  0.27209026
Z variance eval              0.0019823727
total_rewards                [225.46391262 228.20534709 360.78952079 204.44795202 260.49906551
 209.65687048 217.64141784 485.67406317 341.23786205 198.16600086]
total_rewards_mean           273.1782012446022
total_rewards_std            89.102353866707
total_rewards_max            485.67406316675
total_rewards_min            198.1660008617169
Number of train steps total  228000
Number of env steps total    1142000
Number of rollouts total     0
Train Time (s)               32.81261128373444
(Previous) Eval Time (s)     2.4757722970098257
Sample Time (s)              16.354799972381443
Epoch Time (s)               51.64318355312571
Total Train Time (s)         14452.600326161832
Epoch                        227
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:03:36.589535 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #227 | Epoch Duration: 52.736364126205444
2020-01-11 04:03:36.589723 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #227 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.2741758
Z variance train             0.0019820216
KL Divergence                13.76123
KL Loss                      1.3761231
QF Loss                      188.38803
VF Loss                      52.56033
Policy Loss                  -1411.3506
Q Predictions Mean           1410.2693
Q Predictions Std            385.71298
Q Predictions Max            1709.3862
Q Predictions Min            7.3700247
V Predictions Mean           1408.6931
V Predictions Std            384.8845
V Predictions Max            1710.6602
V Predictions Min            7.6336775
Log Pis Mean                 0.04351326
Log Pis Std                  2.0475855
Log Pis Max                  7.454721
Log Pis Min                  -4.398767
Policy mu Mean               -0.0315916
Policy mu Std                0.94273376
Policy mu Max                1.9419616
Policy mu Min                -2.7023141
Policy log std Mean          -0.502881
Policy log std Std           0.16294144
Policy log std Max           -0.076977134
Policy log std Min           -1.6344585
Z mean eval                  0.07726194
Z variance eval              0.0020229123
total_rewards                [454.49411557 184.0422781   15.16593192 328.86675824  11.19803969
  58.5236209   12.09595562  43.01617077 170.64866919  10.35635764]
total_rewards_mean           128.84078976440443
total_rewards_std            147.5112389399052
total_rewards_max            454.49411556812606
total_rewards_min            10.35635763768201
Number of train steps total  229000
Number of env steps total    1147000
Number of rollouts total     0
Train Time (s)               32.914001126307994
(Previous) Eval Time (s)     3.5686220210045576
Sample Time (s)              16.702110496349633
Epoch Time (s)               53.184733643662184
Total Train Time (s)         14504.092981082853
Epoch                        228
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:04:28.084377 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #228 | Epoch Duration: 51.49451661109924
2020-01-11 04:04:28.084543 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #228 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09477186
Z variance train             0.002131114
KL Divergence                13.094402
KL Loss                      1.3094403
QF Loss                      129.01944
VF Loss                      48.96127
Policy Loss                  -1317.0806
Q Predictions Mean           1315.7817
Q Predictions Std            406.06818
Q Predictions Max            1631.5148
Q Predictions Min            4.4973474
V Predictions Mean           1320.3451
V Predictions Std            406.3974
V Predictions Max            1643.4596
V Predictions Min            3.4871442
Log Pis Mean                 -0.27393404
Log Pis Std                  2.1154451
Log Pis Max                  10.839375
Log Pis Min                  -3.757303
Policy mu Mean               0.032549918
Policy mu Std                0.9020558
Policy mu Max                2.3623576
Policy mu Min                -2.7790735
Policy log std Mean          -0.4717426
Policy log std Std           0.16694023
Policy log std Max           -0.031034231
Policy log std Min           -0.97751355
Z mean eval                  0.09077716
Z variance eval              0.002112768
total_rewards                [423.9653207   13.09602628 312.57025361 396.24840249  12.03567097
   7.53938578   9.77596502   8.19718278  11.62710387   9.0172101 ]
total_rewards_mean           120.40725215961243
total_rewards_std            170.3622487186748
total_rewards_max            423.96532069747605
total_rewards_min            7.539385779276113
Number of train steps total  230000
Number of env steps total    1152000
Number of rollouts total     0
Train Time (s)               32.975674154702574
(Previous) Eval Time (s)     1.878095380961895
Sample Time (s)              19.53155832691118
Epoch Time (s)               54.38532786257565
Total Train Time (s)         14558.008901293855
Epoch                        229
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:05:22.003429 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #229 | Epoch Duration: 53.91875410079956
2020-01-11 04:05:22.003598 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #229 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023055157
Z variance train             0.0020284741
KL Divergence                13.14278
KL Loss                      1.314278
QF Loss                      283.4331
VF Loss                      212.45566
Policy Loss                  -1280.5945
Q Predictions Mean           1279.3441
Q Predictions Std            354.2332
Q Predictions Max            1589.1868
Q Predictions Min            1.0601401
V Predictions Mean           1283.7395
V Predictions Std            346.16013
V Predictions Max            1602.4808
V Predictions Min            6.3933644
Log Pis Mean                 -0.093061976
Log Pis Std                  2.0870867
Log Pis Max                  9.134045
Log Pis Min                  -4.7800756
Policy mu Mean               0.017733509
Policy mu Std                0.9381872
Policy mu Max                2.6594753
Policy mu Min                -3.8533852
Policy log std Mean          -0.5377098
Policy log std Std           0.17093953
Policy log std Max           0.013251454
Policy log std Min           -1.4908737
Z mean eval                  0.1056429
Z variance eval              0.0024199828
total_rewards                [526.43510542  14.87282397   9.92583965 411.40193885  21.55381081
 393.55716643 404.87480375 525.04409978 378.44736417  12.61655985]
total_rewards_mean           269.87295126815184
total_rewards_std            213.7099456957281
total_rewards_max            526.4351054181095
total_rewards_min            9.925839646111436
Number of train steps total  231000
Number of env steps total    1157000
Number of rollouts total     0
Train Time (s)               32.173768635839224
(Previous) Eval Time (s)     1.4112068908289075
Sample Time (s)              17.860063459258527
Epoch Time (s)               51.44503898592666
Total Train Time (s)         14611.011347123887
Epoch                        230
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:06:15.008586 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #230 | Epoch Duration: 53.00484538078308
2020-01-11 04:06:15.008777 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #230 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 7.37625
Z variance train             0.005419663
KL Divergence                162.77315
KL Loss                      16.277315
QF Loss                      369.0769
VF Loss                      55.141136
Policy Loss                  -320.67276
Q Predictions Mean           319.5244
Q Predictions Std            62.145756
Q Predictions Max            363.54404
Q Predictions Min            -8.071311
V Predictions Mean           323.2724
V Predictions Std            62.360558
V Predictions Max            366.18622
V Predictions Min            -14.313235
Log Pis Mean                 -1.0408587
Log Pis Std                  1.2318101
Log Pis Max                  3.789506
Log Pis Min                  -5.801927
Policy mu Mean               -0.12569503
Policy mu Std                0.64224136
Policy mu Max                1.5375018
Policy mu Min                -1.6644479
Policy log std Mean          -0.38727298
Policy log std Std           0.13528238
Policy log std Max           0.01397264
Policy log std Min           -0.94192445
Z mean eval                  0.08870278
Z variance eval              0.0026397456
total_rewards                [323.16687402 415.61580972 458.95611698 396.55989083 309.98899571
 527.39979353 353.57939209 448.63951921 489.11977709 492.73429115]
total_rewards_mean           421.576046033145
total_rewards_std            70.97529893786121
total_rewards_max            527.3997935291401
total_rewards_min            309.9889957095162
Number of train steps total  232000
Number of env steps total    1162000
Number of rollouts total     0
Train Time (s)               32.33348611090332
(Previous) Eval Time (s)     2.9707003817893565
Sample Time (s)              19.885005382355303
Epoch Time (s)               55.18919187504798
Total Train Time (s)         14668.145089671947
Epoch                        231
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:07:12.145409 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #231 | Epoch Duration: 57.13648581504822
2020-01-11 04:07:12.145581 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #231 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08894712
Z variance train             0.002640728
KL Divergence                12.599506
KL Loss                      1.2599506
QF Loss                      463.09384
VF Loss                      61.62351
Policy Loss                  -1304.6609
Q Predictions Mean           1301.564
Q Predictions Std            351.76413
Q Predictions Max            1626.9883
Q Predictions Min            -3.692496
V Predictions Mean           1302.7312
V Predictions Std            350.23596
V Predictions Max            1622.6635
V Predictions Min            3.9624033
Log Pis Mean                 0.025312915
Log Pis Std                  2.1656203
Log Pis Max                  11.531657
Log Pis Min                  -5.605026
Policy mu Mean               -0.02777456
Policy mu Std                0.9691898
Policy mu Max                2.5180542
Policy mu Min                -3.1030269
Policy log std Mean          -0.4824818
Policy log std Std           0.16721764
Policy log std Max           0.055675805
Policy log std Min           -1.178468
Z mean eval                  0.09119971
Z variance eval              0.0034702986
total_rewards                [441.39182921 473.54391911 360.40605649 497.01808964 468.60526202
 534.88242228 333.19031308 329.86671167 521.65988724 444.89271959]
total_rewards_mean           440.5457210318449
total_rewards_std            71.24694614914112
total_rewards_max            534.882422281689
total_rewards_min            329.86671166796
Number of train steps total  233000
Number of env steps total    1167000
Number of rollouts total     0
Train Time (s)               32.341053823940456
(Previous) Eval Time (s)     4.917722147889435
Sample Time (s)              18.23660256387666
Epoch Time (s)               55.49537853570655
Total Train Time (s)         14723.106348155532
Epoch                        232
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:08:07.109893 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #232 | Epoch Duration: 54.9641649723053
2020-01-11 04:08:07.110118 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #232 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.20541696
Z variance train             0.0018652243
KL Divergence                13.709711
KL Loss                      1.3709711
QF Loss                      380.10306
VF Loss                      146.4725
Policy Loss                  -1104.834
Q Predictions Mean           1107.5842
Q Predictions Std            345.18243
Q Predictions Max            1425.3423
Q Predictions Min            1.7050016
V Predictions Mean           1106.537
V Predictions Std            343.97076
V Predictions Max            1418.5427
V Predictions Min            3.1770465
Log Pis Mean                 0.08480793
Log Pis Std                  2.2373397
Log Pis Max                  6.3492317
Log Pis Min                  -5.0814857
Policy mu Mean               -0.194411
Policy mu Std                0.96731716
Policy mu Max                2.322957
Policy mu Min                -2.8273532
Policy log std Mean          -0.5000214
Policy log std Std           0.18437067
Policy log std Max           -0.03418687
Policy log std Min           -1.5432982
Z mean eval                  0.09923313
Z variance eval              0.0026373889
total_rewards                [522.49265134 485.66898266 280.56104877 479.87064114 514.1750772
 469.74705469 481.44581504 478.35415432 542.71384673 451.74920593]
total_rewards_mean           470.6778477828955
total_rewards_std            68.37663451793168
total_rewards_max            542.7138467283668
total_rewards_min            280.5610487699328
Number of train steps total  234000
Number of env steps total    1172000
Number of rollouts total     0
Train Time (s)               32.05539345089346
(Previous) Eval Time (s)     4.386237065773457
Sample Time (s)              19.40201623365283
Epoch Time (s)               55.84364675031975
Total Train Time (s)         14779.852359621786
Epoch                        233
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:09:03.860024 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #233 | Epoch Duration: 56.74968910217285
2020-01-11 04:09:03.860185 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #233 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08601832
Z variance train             0.0025297585
KL Divergence                12.689791
KL Loss                      1.2689791
QF Loss                      252.14536
VF Loss                      252.81007
Policy Loss                  -1253.6011
Q Predictions Mean           1252.8566
Q Predictions Std            445.51816
Q Predictions Max            1605.0518
Q Predictions Min            -18.381676
V Predictions Mean           1253.4373
V Predictions Std            447.00784
V Predictions Max            1616.9423
V Predictions Min            -8.434365
Log Pis Mean                 -0.06233874
Log Pis Std                  2.0642262
Log Pis Max                  8.589604
Log Pis Min                  -5.1501374
Policy mu Mean               -0.023016071
Policy mu Std                0.9488425
Policy mu Max                2.1050677
Policy mu Min                -2.8789468
Policy log std Mean          -0.45721972
Policy log std Std           0.14700313
Policy log std Max           0.05013451
Policy log std Min           -1.0250301
Z mean eval                  7.3253126
Z variance eval              0.002890885
total_rewards                [342.86041702 489.54335318 335.97367008 346.05680261 375.94715888
 339.17422975 498.66516919 505.43603286 341.4386815  459.9600547 ]
total_rewards_mean           403.50555697698894
total_rewards_std            70.93928145028772
total_rewards_max            505.43603285918863
total_rewards_min            335.9736700757025
Number of train steps total  235000
Number of env steps total    1177000
Number of rollouts total     0
Train Time (s)               32.678757505025715
(Previous) Eval Time (s)     5.29200670029968
Sample Time (s)              19.412372060120106
Epoch Time (s)               57.3831362654455
Total Train Time (s)         14836.720112642273
Epoch                        234
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:10:00.730029 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #234 | Epoch Duration: 56.86970138549805
2020-01-11 04:10:00.730197 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #234 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6366141
Z variance train             0.0018251756
KL Divergence                14.52086
KL Loss                      1.452086
QF Loss                      1488.4729
VF Loss                      729.3784
Policy Loss                  -794.68506
Q Predictions Mean           778.58777
Q Predictions Std            233.21873
Q Predictions Max            1134.8318
Q Predictions Min            -8.777688
V Predictions Mean           799.9365
V Predictions Std            232.50534
V Predictions Max            1127.6113
V Predictions Min            3.563206
Log Pis Mean                 0.69814533
Log Pis Std                  1.933804
Log Pis Max                  6.6680584
Log Pis Min                  -4.7169952
Policy mu Mean               -0.020064272
Policy mu Std                1.1184044
Policy mu Max                2.734336
Policy mu Min                -2.7330813
Policy log std Mean          -0.5537452
Policy log std Std           0.175096
Policy log std Max           -0.045329154
Policy log std Min           -1.2171179
Z mean eval                  0.107176915
Z variance eval              0.002720732
total_rewards                [335.87691466 528.89869349 432.59711282 535.64898678 293.54546148
 314.95616857 394.4912382  500.43522673 475.75147557 360.87647158]
total_rewards_mean           417.30777498963334
total_rewards_std            85.52532471244945
total_rewards_max            535.6489867841905
total_rewards_min            293.54546148175973
Number of train steps total  236000
Number of env steps total    1182000
Number of rollouts total     0
Train Time (s)               32.73356126481667
(Previous) Eval Time (s)     4.7782661519013345
Sample Time (s)              19.309576612431556
Epoch Time (s)               56.82140402914956
Total Train Time (s)         14893.410940507893
Epoch                        235
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:10:57.425729 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #235 | Epoch Duration: 56.695390701293945
2020-01-11 04:10:57.425922 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #235 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10730122
Z variance train             0.0027168316
KL Divergence                12.517071
KL Loss                      1.2517071
QF Loss                      174.61522
VF Loss                      128.74896
Policy Loss                  -1310.2489
Q Predictions Mean           1306.3921
Q Predictions Std            337.1802
Q Predictions Max            1608.6174
Q Predictions Min            -3.662996
V Predictions Mean           1307.8285
V Predictions Std            336.36383
V Predictions Max            1617.5405
V Predictions Min            -4.85632
Log Pis Mean                 -0.28099135
Log Pis Std                  2.020738
Log Pis Max                  8.69307
Log Pis Min                  -4.9671597
Policy mu Mean               0.13751976
Policy mu Std                0.87043875
Policy mu Max                2.8147633
Policy mu Min                -2.8458822
Policy log std Mean          -0.4663746
Policy log std Std           0.15851942
Policy log std Max           -0.043147475
Policy log std Min           -1.5005887
Z mean eval                  0.017228875
Z variance eval              0.002296408
total_rewards                [351.71567478 347.08858756 342.49710962 340.10831604 342.66031948
 322.49031032 307.80148011 345.77371449 322.56800475 343.76520881]
total_rewards_mean           336.6468725948777
total_rewards_std            13.353336716184515
total_rewards_max            351.7156747821279
total_rewards_min            307.80148010835137
Number of train steps total  237000
Number of env steps total    1187000
Number of rollouts total     0
Train Time (s)               32.2089112047106
(Previous) Eval Time (s)     4.651958827860653
Sample Time (s)              19.695352705195546
Epoch Time (s)               56.5562227377668
Total Train Time (s)         14949.37770064827
Epoch                        236
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:11:53.393812 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #236 | Epoch Duration: 55.96771287918091
2020-01-11 04:11:53.394082 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #236 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 6.959903
Z variance train             0.0039782007
KL Divergence                142.0991
KL Loss                      14.20991
QF Loss                      236.2736
VF Loss                      158.4589
Policy Loss                  -576.8496
Q Predictions Mean           575.2545
Q Predictions Std            107.83706
Q Predictions Max            684.82513
Q Predictions Min            9.125948
V Predictions Mean           588.27026
V Predictions Std            107.89925
V Predictions Max            694.56256
V Predictions Min            5.047268
Log Pis Mean                 -0.62645763
Log Pis Std                  1.4317657
Log Pis Max                  4.327635
Log Pis Min                  -8.186537
Policy mu Mean               0.25886372
Policy mu Std                0.63528967
Policy mu Max                2.0898702
Policy mu Min                -2.0550044
Policy log std Mean          -0.5860173
Policy log std Std           0.16377631
Policy log std Max           -0.2315561
Policy log std Min           -1.0688262
Z mean eval                  0.14614184
Z variance eval              0.0024108805
total_rewards                [342.03869469 289.92858261 339.34017944 350.50645454 333.34746061
 328.70453472 329.17381341 318.27709006 318.92417979 487.17207997]
total_rewards_mean           343.74130698253236
total_rewards_std            50.345701459867755
total_rewards_max            487.17207996736136
total_rewards_min            289.92858260536605
Number of train steps total  238000
Number of env steps total    1192000
Number of rollouts total     0
Train Time (s)               32.15353875234723
(Previous) Eval Time (s)     4.063133784104139
Sample Time (s)              18.23491837643087
Epoch Time (s)               54.45159091288224
Total Train Time (s)         15003.059180948418
Epoch                        237
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:12:47.080738 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #237 | Epoch Duration: 53.68646574020386
2020-01-11 04:12:47.081014 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #237 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 6.794774
Z variance train             0.0029148739
KL Divergence                140.89548
KL Loss                      14.089548
QF Loss                      163.77196
VF Loss                      47.08402
Policy Loss                  -587.63245
Q Predictions Mean           584.305
Q Predictions Std            173.4337
Q Predictions Max            734.19586
Q Predictions Min            -6.312853
V Predictions Mean           587.70526
V Predictions Std            174.3653
V Predictions Max            737.4041
V Predictions Min            -8.296076
Log Pis Mean                 -0.4661016
Log Pis Std                  1.3341975
Log Pis Max                  5.6855087
Log Pis Min                  -4.0688863
Policy mu Mean               0.2501453
Policy mu Std                0.64468336
Policy mu Max                2.2648332
Policy mu Min                -2.2680602
Policy log std Mean          -0.5747302
Policy log std Std           0.16087773
Policy log std Max           -0.20230593
Policy log std Min           -1.0584884
Z mean eval                  0.14978158
Z variance eval              0.0020662565
total_rewards                [302.85997571 331.12064622 308.87908293 311.95890803 311.0911651
 304.67729175 307.6757357  321.3603222  318.50920571 300.17581337]
total_rewards_mean           311.83081467276077
total_rewards_std            8.952869986129768
total_rewards_max            331.12064622278604
total_rewards_min            300.17581336822457
Number of train steps total  239000
Number of env steps total    1197000
Number of rollouts total     0
Train Time (s)               32.150337021332234
(Previous) Eval Time (s)     3.297676818910986
Sample Time (s)              17.468588575255126
Epoch Time (s)               52.916602415498346
Total Train Time (s)         15056.220156813972
Epoch                        238
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:13:40.243650 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #238 | Epoch Duration: 53.16242575645447
2020-01-11 04:13:40.243844 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #238 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 6.9953737
Z variance train             0.0009895776
KL Divergence                148.75186
KL Loss                      14.875186
QF Loss                      236.96481
VF Loss                      53.27319
Policy Loss                  -660.6001
Q Predictions Mean           657.6157
Q Predictions Std            137.73235
Q Predictions Max            792.9623
Q Predictions Min            10.039731
V Predictions Mean           659.1404
V Predictions Std            136.22554
V Predictions Max            798.66254
V Predictions Min            10.606519
Log Pis Mean                 -0.39204335
Log Pis Std                  1.5315872
Log Pis Max                  4.588462
Log Pis Min                  -5.2295403
Policy mu Mean               0.2782487
Policy mu Std                0.71158475
Policy mu Max                2.7295997
Policy mu Min                -1.9037505
Policy log std Mean          -0.60824466
Policy log std Std           0.15310605
Policy log std Max           -0.28121316
Policy log std Min           -1.1281596
Z mean eval                  0.15060112
Z variance eval              0.0022145626
total_rewards                [326.30692858 307.61217334 319.51543128 332.0412104  319.21933911
 312.65220364 331.44847219 330.99092814 322.61814372 313.36354527]
total_rewards_mean           321.57683756700953
total_rewards_std            8.191225506539393
total_rewards_max            332.0412104048132
total_rewards_min            307.61217333532625
Number of train steps total  240000
Number of env steps total    1202000
Number of rollouts total     0
Train Time (s)               32.64629861386493
(Previous) Eval Time (s)     3.5431835600174963
Sample Time (s)              17.777931961696595
Epoch Time (s)               53.96741413557902
Total Train Time (s)         15110.299225843046
Epoch                        239
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:14:34.331743 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #239 | Epoch Duration: 54.08775472640991
2020-01-11 04:14:34.331934 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #239 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.14659333
Z variance train             0.0020083103
KL Divergence                13.463027
KL Loss                      1.3463027
QF Loss                      174.14328
VF Loss                      141.13078
Policy Loss                  -1286.2278
Q Predictions Mean           1286.0204
Q Predictions Std            388.72232
Q Predictions Max            1613.4061
Q Predictions Min            -0.22607899
V Predictions Mean           1282.6792
V Predictions Std            385.05573
V Predictions Max            1597.1102
V Predictions Min            8.586046
Log Pis Mean                 0.109588616
Log Pis Std                  2.183642
Log Pis Max                  7.8945327
Log Pis Min                  -4.8189163
Policy mu Mean               0.07882642
Policy mu Std                0.9895008
Policy mu Max                2.5287907
Policy mu Min                -2.6519759
Policy log std Mean          -0.475405
Policy log std Std           0.16228214
Policy log std Max           7.6919794e-05
Policy log std Min           -1.2704722
Z mean eval                  6.150672
Z variance eval              0.0007455732
total_rewards                [329.44436711 332.09537015 395.58716758 268.44601648 397.84902814
 296.91566651 303.2421602  322.69488487 304.54838947 457.65508803]
total_rewards_mean           340.84781385389704
total_rewards_std            55.0722566334172
total_rewards_max            457.655088034963
total_rewards_min            268.44601648121215
Number of train steps total  241000
Number of env steps total    1207000
Number of rollouts total     0
Train Time (s)               32.38174808816984
(Previous) Eval Time (s)     3.663184161297977
Sample Time (s)              16.762239050120115
Epoch Time (s)               52.807171299587935
Total Train Time (s)         15163.467857115436
Epoch                        240
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:15:27.497111 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #240 | Epoch Duration: 53.16503715515137
2020-01-11 04:15:27.497292 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #240 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.14621887
Z variance train             0.0014312409
KL Divergence                14.120069
KL Loss                      1.4120069
QF Loss                      643.73
VF Loss                      134.42441
Policy Loss                  -1306.0599
Q Predictions Mean           1302.4688
Q Predictions Std            380.6219
Q Predictions Max            1587.5516
Q Predictions Min            4.776989
V Predictions Mean           1297.4314
V Predictions Std            377.53012
V Predictions Max            1578.714
V Predictions Min            1.3380611
Log Pis Mean                 -0.09305529
Log Pis Std                  2.22129
Log Pis Max                  7.8218985
Log Pis Min                  -7.0032783
Policy mu Mean               -0.043451417
Policy mu Std                0.92466325
Policy mu Max                2.2345145
Policy mu Min                -2.9731584
Policy log std Mean          -0.46343008
Policy log std Std           0.14826807
Policy log std Max           -0.08826724
Policy log std Min           -0.9627873
Z mean eval                  6.658826
Z variance eval              0.002770143
total_rewards                [443.02451349 484.5065376  315.14466933 298.91138898 292.64526401
 483.61410259 321.87578993 466.54811372 331.64471339 313.69829018]
total_rewards_mean           375.1613383234395
total_rewards_std            78.36519533252216
total_rewards_max            484.50653760113374
total_rewards_min            292.64526401343187
Number of train steps total  242000
Number of env steps total    1212000
Number of rollouts total     0
Train Time (s)               32.35479861171916
(Previous) Eval Time (s)     4.0207705199718475
Sample Time (s)              17.961740128230304
Epoch Time (s)               54.33730925992131
Total Train Time (s)         15217.886899957433
Epoch                        241
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:16:21.920390 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #241 | Epoch Duration: 54.422959327697754
2020-01-11 04:16:21.920580 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #241 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.15122767
Z variance train             0.0013247461
KL Divergence                14.481246
KL Loss                      1.4481246
QF Loss                      383.90503
VF Loss                      198.43958
Policy Loss                  -1300.29
Q Predictions Mean           1296.3257
Q Predictions Std            370.61618
Q Predictions Max            1614.0596
Q Predictions Min            -13.4043665
V Predictions Mean           1294.1387
V Predictions Std            364.53113
V Predictions Max            1592.2327
V Predictions Min            -26.473646
Log Pis Mean                 0.07915494
Log Pis Std                  2.2378175
Log Pis Max                  7.736392
Log Pis Min                  -6.931288
Policy mu Mean               0.07069949
Policy mu Std                0.98351794
Policy mu Max                2.802803
Policy mu Min                -2.9768572
Policy log std Mean          -0.47661862
Policy log std Std           0.14374492
Policy log std Max           -0.074783474
Policy log std Min           -0.985072
Z mean eval                  6.463118
Z variance eval              0.0013821695
total_rewards                [451.28360132 318.89533713 317.01923714 341.11273584 454.80129627
 306.6666404  332.14035559 308.11912308 328.21217636 323.50247218]
total_rewards_mean           348.1752975304783
total_rewards_std            53.3574563519838
total_rewards_max            454.80129626901225
total_rewards_min            306.66664039747945
Number of train steps total  243000
Number of env steps total    1217000
Number of rollouts total     0
Train Time (s)               32.30345951486379
(Previous) Eval Time (s)     4.106114401947707
Sample Time (s)              17.434475146699697
Epoch Time (s)               53.84404906351119
Total Train Time (s)         15271.52034701081
Epoch                        242
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:17:15.554288 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #242 | Epoch Duration: 53.63357949256897
2020-01-11 04:17:15.554429 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #242 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.17145963
Z variance train             0.0015765328
KL Divergence                14.218454
KL Loss                      1.4218454
QF Loss                      276.92633
VF Loss                      76.54059
Policy Loss                  -1310.345
Q Predictions Mean           1314.4172
Q Predictions Std            381.80627
Q Predictions Max            1625.019
Q Predictions Min            -7.4151506
V Predictions Mean           1315.271
V Predictions Std            379.32974
V Predictions Max            1618.3076
V Predictions Min            -19.950308
Log Pis Mean                 -0.04716655
Log Pis Std                  2.2131414
Log Pis Max                  7.850443
Log Pis Min                  -4.1911507
Policy mu Mean               -0.07030383
Policy mu Std                0.94487035
Policy mu Max                2.628577
Policy mu Min                -2.6820052
Policy log std Mean          -0.49199256
Policy log std Std           0.1541603
Policy log std Max           -0.051275074
Policy log std Min           -1.0266793
Z mean eval                  0.163438
Z variance eval              0.0013499263
total_rewards                [479.68249917 563.79363265 300.11290751 288.61520302 328.74685977
 335.30303003 568.8768226  422.01765881 299.10429484 474.36042833]
total_rewards_mean           406.06133367321524
total_rewards_std            104.48470912144786
total_rewards_max            568.8768226006429
total_rewards_min            288.6152030240299
Number of train steps total  244000
Number of env steps total    1222000
Number of rollouts total     0
Train Time (s)               32.84513292601332
(Previous) Eval Time (s)     3.8953370060771704
Sample Time (s)              18.229202622082084
Epoch Time (s)               54.969672554172575
Total Train Time (s)         15327.00212436961
Epoch                        243
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:18:11.041181 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #243 | Epoch Duration: 55.48654556274414
2020-01-11 04:18:11.041475 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #243 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 6.213032
Z variance train             0.0017881651
KL Divergence                117.12367
KL Loss                      11.712367
QF Loss                      281.24854
VF Loss                      59.667885
Policy Loss                  -735.7516
Q Predictions Mean           731.8461
Q Predictions Std            236.7452
Q Predictions Max            933.83887
Q Predictions Min            2.8558125
V Predictions Mean           733.8238
V Predictions Std            237.13554
V Predictions Max            933.75476
V Predictions Min            -4.446619
Log Pis Mean                 -0.34750462
Log Pis Std                  1.5318072
Log Pis Max                  4.6279936
Log Pis Min                  -4.331909
Policy mu Mean               0.3107293
Policy mu Std                0.7188216
Policy mu Max                2.2898645
Policy mu Min                -1.7559627
Policy log std Mean          -0.5754032
Policy log std Std           0.20644785
Policy log std Max           -0.026491135
Policy log std Min           -1.2833823
Z mean eval                  6.348043
Z variance eval              0.002378333
total_rewards                [549.04255073 301.06818498 311.19872606 269.87623938 305.22748333
 422.28199045 267.79168108 279.72147827 312.64455687 324.62471498]
total_rewards_mean           334.3477606127556
total_rewards_std            82.73667043517983
total_rewards_max            549.042550725891
total_rewards_min            267.79168107902836
Number of train steps total  245000
Number of env steps total    1227000
Number of rollouts total     0
Train Time (s)               32.68191224709153
(Previous) Eval Time (s)     4.411879966966808
Sample Time (s)              18.652155322022736
Epoch Time (s)               55.745947536081076
Total Train Time (s)         15382.125974213704
Epoch                        244
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:19:06.167101 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #244 | Epoch Duration: 55.12542200088501
2020-01-11 04:19:06.167466 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #244 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 6.554834
Z variance train             0.0018557484
KL Divergence                131.84923
KL Loss                      13.184923
QF Loss                      377.92456
VF Loss                      213.46207
Policy Loss                  -791.61176
Q Predictions Mean           788.6513
Q Predictions Std            269.2053
Q Predictions Max            997.8904
Q Predictions Min            -6.888071
V Predictions Mean           783.1441
V Predictions Std            266.6116
V Predictions Max            993.6609
V Predictions Min            -10.110335
Log Pis Mean                 -0.28934205
Log Pis Std                  1.7788013
Log Pis Max                  6.9019966
Log Pis Min                  -6.0336514
Policy mu Mean               0.30446598
Policy mu Std                0.7609706
Policy mu Max                2.2246802
Policy mu Min                -2.327815
Policy log std Mean          -0.5841763
Policy log std Std           0.20297414
Policy log std Max           0.13565654
Policy log std Min           -1.3297732
Z mean eval                  0.16873106
Z variance eval              0.0015367894
total_rewards                [313.73060847 504.03732986 499.58908292 526.11190692 470.53626598
 505.6584318  505.32274101 479.08440625 502.83964941 326.35278525]
total_rewards_mean           463.3263207860779
total_rewards_std            73.12478459589916
total_rewards_max            526.1119069168506
total_rewards_min            313.730608472503
Number of train steps total  246000
Number of env steps total    1232000
Number of rollouts total     0
Train Time (s)               32.012766419909894
(Previous) Eval Time (s)     3.7910015578381717
Sample Time (s)              18.423385959118605
Epoch Time (s)               54.22715393686667
Total Train Time (s)         15437.459894289263
Epoch                        245
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:20:01.504556 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #245 | Epoch Duration: 55.33678936958313
2020-01-11 04:20:01.504814 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #245 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.16605142
Z variance train             0.0016101577
KL Divergence                13.7379265
KL Loss                      1.3737926
QF Loss                      347.9757
VF Loss                      310.62762
Policy Loss                  -1286.4045
Q Predictions Mean           1286.6266
Q Predictions Std            396.8037
Q Predictions Max            1601.9629
Q Predictions Min            1.7788539
V Predictions Mean           1271.7683
V Predictions Std            391.8243
V Predictions Max            1551.8398
V Predictions Min            -2.5528142
Log Pis Mean                 0.2996462
Log Pis Std                  2.23517
Log Pis Max                  10.418074
Log Pis Min                  -4.1400137
Policy mu Mean               0.08093708
Policy mu Std                1.0333344
Policy mu Max                2.6161366
Policy mu Min                -3.2304592
Policy log std Mean          -0.49371335
Policy log std Std           0.15691435
Policy log std Max           0.14008659
Policy log std Min           -1.038673
Z mean eval                  5.8355403
Z variance eval              0.014851664
total_rewards                [312.5114959  314.51837689 272.94620584 432.91635506 310.10333724
 372.45172454 304.46120101 276.94074325 256.02752789 281.26672993]
total_rewards_mean           313.4143697542078
total_rewards_std            50.153771562764845
total_rewards_max            432.91635506347546
total_rewards_min            256.02752789042216
Number of train steps total  247000
Number of env steps total    1237000
Number of rollouts total     0
Train Time (s)               31.982610777020454
(Previous) Eval Time (s)     4.900302769150585
Sample Time (s)              18.043913369067013
Epoch Time (s)               54.92682691523805
Total Train Time (s)         15491.185996477026
Epoch                        246
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:20:55.232934 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #246 | Epoch Duration: 53.72795748710632
2020-01-11 04:20:55.233112 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #246 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 5.8723664
Z variance train             0.020077234
KL Divergence                103.81933
KL Loss                      10.381933
QF Loss                      225.45633
VF Loss                      54.07002
Policy Loss                  -810.2056
Q Predictions Mean           807.8564
Q Predictions Std            227.34624
Q Predictions Max            993.0101
Q Predictions Min            -4.6182847
V Predictions Mean           813.0836
V Predictions Std            227.37027
V Predictions Max            993.419
V Predictions Min            -5.039444
Log Pis Mean                 -0.38177136
Log Pis Std                  1.895658
Log Pis Max                  7.195249
Log Pis Min                  -5.9484677
Policy mu Mean               0.4267876
Policy mu Std                0.6946668
Policy mu Max                2.812343
Policy mu Min                -2.8920574
Policy log std Mean          -0.550183
Policy log std Std           0.19754358
Policy log std Max           0.053970844
Policy log std Min           -1.3613248
Z mean eval                  5.818933
Z variance eval              0.015655022
total_rewards                [456.35451528 422.08372776 299.11528924 284.41318174 258.51584123
 394.07637099 382.02428374 364.1495875  279.5130671  329.63079774]
total_rewards_mean           346.9876662315613
total_rewards_std            63.426055506760804
total_rewards_max            456.3545152820463
total_rewards_min            258.5158412260131
Number of train steps total  248000
Number of env steps total    1242000
Number of rollouts total     0
Train Time (s)               32.24696293333545
(Previous) Eval Time (s)     3.70112608326599
Sample Time (s)              18.607324295211583
Epoch Time (s)               54.55541331181303
Total Train Time (s)         15546.136882020626
Epoch                        247
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:21:50.186723 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #247 | Epoch Duration: 54.95347881317139
2020-01-11 04:21:50.186888 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #247 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.14950678
Z variance train             0.0015722208
KL Divergence                13.710944
KL Loss                      1.3710945
QF Loss                      159.01169
VF Loss                      74.72621
Policy Loss                  -1263.2947
Q Predictions Mean           1263.0471
Q Predictions Std            382.07043
Q Predictions Max            1566.2023
Q Predictions Min            -4.072573
V Predictions Mean           1261.8411
V Predictions Std            380.11023
V Predictions Max            1560.3068
V Predictions Min            5.9486127
Log Pis Mean                 -0.11347008
Log Pis Std                  2.219329
Log Pis Max                  12.435252
Log Pis Min                  -5.6670628
Policy mu Mean               0.14623834
Policy mu Std                0.94057405
Policy mu Max                4.0017796
Policy mu Min                -2.7617595
Policy log std Mean          -0.4885815
Policy log std Std           0.16966219
Policy log std Max           -0.08390397
Policy log std Min           -1.2911258
Z mean eval                  5.5607214
Z variance eval              0.0041005393
total_rewards                [303.7231702  317.33678959 295.22204175 306.27279226 257.08592081
 275.01845177 266.16304048 463.84393473 381.94313699 290.92441433]
total_rewards_mean           315.75336929024195
total_rewards_std            59.28526909101646
total_rewards_max            463.8439347255284
total_rewards_min            257.08592081096486
Number of train steps total  249000
Number of env steps total    1247000
Number of rollouts total     0
Train Time (s)               32.433558602351695
(Previous) Eval Time (s)     4.098711708094925
Sample Time (s)              18.01411275519058
Epoch Time (s)               54.5463830656372
Total Train Time (s)         15600.2138158069
Epoch                        248
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:22:44.267040 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #248 | Epoch Duration: 54.08002161979675
2020-01-11 04:22:44.267253 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #248 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 5.645705
Z variance train             0.006900292
KL Divergence                97.45238
KL Loss                      9.745238
QF Loss                      92.298775
VF Loss                      28.132738
Policy Loss                  -835.3207
Q Predictions Mean           832.9813
Q Predictions Std            252.47699
Q Predictions Max            1024.3296
Q Predictions Min            -3.4110022
V Predictions Mean           835.10205
V Predictions Std            251.95473
V Predictions Max            1043.7728
V Predictions Min            -0.95706964
Log Pis Mean                 -0.3453904
Log Pis Std                  1.6058314
Log Pis Max                  7.0299864
Log Pis Min                  -5.298071
Policy mu Mean               0.49011698
Policy mu Std                0.62242454
Policy mu Max                2.9877203
Policy mu Min                -1.9866786
Policy log std Mean          -0.51781553
Policy log std Std           0.19651254
Policy log std Max           0.09364712
Policy log std Min           -1.4621673
Z mean eval                  0.16627054
Z variance eval              0.002110436
total_rewards                [317.03863101 300.10106094 308.53855668 279.54644803 264.9647027
 296.70015534 245.78980438 267.32240144 384.47928756 351.31680673]
total_rewards_mean           301.5797854808899
total_rewards_std            39.71362379013385
total_rewards_max            384.47928756446316
total_rewards_min            245.7898043786626
Number of train steps total  250000
Number of env steps total    1252000
Number of rollouts total     0
Train Time (s)               32.107325504068285
(Previous) Eval Time (s)     3.632014560047537
Sample Time (s)              17.960964601952583
Epoch Time (s)               53.700304666068405
Total Train Time (s)         15653.867796155624
Epoch                        249
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:23:37.924077 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #249 | Epoch Duration: 53.656675577163696
2020-01-11 04:23:37.924273 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #249 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 5.4699044
Z variance train             0.0055257617
KL Divergence                91.75474
KL Loss                      9.175474
QF Loss                      458.60037
VF Loss                      524.4556
Policy Loss                  -860.1875
Q Predictions Mean           857.1289
Q Predictions Std            237.67851
Q Predictions Max            1044.7103
Q Predictions Min            9.133274
V Predictions Mean           840.4015
V Predictions Std            235.03699
V Predictions Max            1027.7577
V Predictions Min            -3.3186972
Log Pis Mean                 -0.82062864
Log Pis Std                  1.6183479
Log Pis Max                  7.452319
Log Pis Min                  -5.9593678
Policy mu Mean               0.365141
Policy mu Std                0.5907701
Policy mu Max                3.3398402
Policy mu Min                -2.078511
Policy log std Mean          -0.44429865
Policy log std Std           0.19128793
Policy log std Max           -0.01586324
Policy log std Min           -1.3993809
Z mean eval                  0.28421193
Z variance eval              0.0018206794
total_rewards                [323.09761939 283.17131453 273.21186013 283.32025852 308.17631413
 319.84021371 272.07205651 298.73767423 288.42241416 295.77512215]
total_rewards_mean           294.58248474697666
total_rewards_std            17.067419102564386
total_rewards_max            323.0976193926506
total_rewards_min            272.07205650930143
Number of train steps total  251000
Number of env steps total    1257000
Number of rollouts total     0
Train Time (s)               33.7377943219617
(Previous) Eval Time (s)     3.5880854595452547
Sample Time (s)              18.2911237902008
Epoch Time (s)               55.617003571707755
Total Train Time (s)         15708.891773271374
Epoch                        250
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:24:32.950974 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #250 | Epoch Duration: 55.02654242515564
2020-01-11 04:24:32.951170 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #250 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 5.481665
Z variance train             0.0035718363
KL Divergence                93.17255
KL Loss                      9.317255
QF Loss                      190.92575
VF Loss                      45.758762
Policy Loss                  -879.4404
Q Predictions Mean           884.85443
Q Predictions Std            220.61977
Q Predictions Max            1070.63
Q Predictions Min            3.454152
V Predictions Mean           878.761
V Predictions Std            219.9675
V Predictions Max            1057.4202
V Predictions Min            1.8223614
Log Pis Mean                 -0.45279074
Log Pis Std                  1.5192776
Log Pis Max                  3.7914977
Log Pis Min                  -4.810678
Policy mu Mean               0.45695737
Policy mu Std                0.58739614
Policy mu Max                2.1550803
Policy mu Min                -2.5142283
Policy log std Mean          -0.5073673
Policy log std Std           0.19571944
Policy log std Max           -0.023014784
Policy log std Min           -1.3999125
Z mean eval                  0.24346519
Z variance eval              0.002596173
total_rewards                [599.15692533 527.33874192 554.90128949 558.30899488 565.17512938
 572.38576472 589.91862869 307.50156689 573.04833749 332.65531751]
total_rewards_mean           518.0390696300822
total_rewards_std            100.85054195131225
total_rewards_max            599.1569253278572
total_rewards_min            307.5015668897714
Number of train steps total  252000
Number of env steps total    1262000
Number of rollouts total     0
Train Time (s)               34.32095552608371
(Previous) Eval Time (s)     2.9972806577570736
Sample Time (s)              17.46750956773758
Epoch Time (s)               54.78574575157836
Total Train Time (s)         15766.186296520289
Epoch                        251
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:25:30.248535 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #251 | Epoch Duration: 57.29706144332886
2020-01-11 04:25:30.248723 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #251 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.23296504
Z variance train             0.0025975567
KL Divergence                13.007726
KL Loss                      1.3007725
QF Loss                      1425.8397
VF Loss                      1167.3889
Policy Loss                  -1205.2684
Q Predictions Mean           1200.7822
Q Predictions Std            451.94315
Q Predictions Max            1591.4606
Q Predictions Min            -5.852958
V Predictions Mean           1236.1016
V Predictions Std            456.21198
V Predictions Max            1630.0118
V Predictions Min            4.4449797
Log Pis Mean                 -0.041100383
Log Pis Std                  2.1189947
Log Pis Max                  12.715748
Log Pis Min                  -4.6439877
Policy mu Mean               -0.15845083
Policy mu Std                0.9407526
Policy mu Max                3.3732166
Policy mu Min                -2.789214
Policy log std Mean          -0.4698961
Policy log std Std           0.18964855
Policy log std Max           -0.066081166
Policy log std Min           -1.3678093
Z mean eval                  0.2827688
Z variance eval              0.0035244033
total_rewards                [289.3481648  315.05109601 270.07626995 433.46315467 268.23683382
 395.29816541 361.77645036 305.75500648 462.94901953 519.26661345]
total_rewards_mean           362.12207744974336
total_rewards_std            83.08226947225909
total_rewards_max            519.2666134487248
total_rewards_min            268.2368338242181
Number of train steps total  253000
Number of env steps total    1267000
Number of rollouts total     0
Train Time (s)               34.35961339389905
(Previous) Eval Time (s)     5.508167188614607
Sample Time (s)              20.99991857074201
Epoch Time (s)               60.86769915325567
Total Train Time (s)         15825.772673024796
Epoch                        252
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:26:29.841811 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #252 | Epoch Duration: 59.59294366836548
2020-01-11 04:26:29.842007 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #252 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.28286478
Z variance train             0.0035239826
KL Divergence                12.238043
KL Loss                      1.2238044
QF Loss                      278.9969
VF Loss                      414.86826
Policy Loss                  -1300.4429
Q Predictions Mean           1299.8801
Q Predictions Std            428.98615
Q Predictions Max            1622.0522
Q Predictions Min            -8.619945
V Predictions Mean           1296.9233
V Predictions Std            423.73114
V Predictions Max            1615.7286
V Predictions Min            -14.213455
Log Pis Mean                 0.08273101
Log Pis Std                  2.120825
Log Pis Max                  8.040945
Log Pis Min                  -5.0179224
Policy mu Mean               -0.039894283
Policy mu Std                0.9821818
Policy mu Max                2.4573944
Policy mu Min                -2.8295488
Policy log std Mean          -0.4943893
Policy log std Std           0.17338613
Policy log std Max           -0.07564449
Policy log std Min           -1.340132
Z mean eval                  0.26094118
Z variance eval              0.0031046886
total_rewards                [721.54170146 470.26884788 582.99937622 603.5502203  461.47957494
 562.28079039 573.38662614 601.55358333 615.1175956  313.46787883]
total_rewards_mean           550.5646195090997
total_rewards_std            105.41164273431406
total_rewards_max            721.5417014648483
total_rewards_min            313.46787882517805
Number of train steps total  254000
Number of env steps total    1272000
Number of rollouts total     0
Train Time (s)               35.53980523115024
(Previous) Eval Time (s)     4.233007246162742
Sample Time (s)              18.867118183523417
Epoch Time (s)               58.6399306608364
Total Train Time (s)         15885.898922652006
Epoch                        253
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:27:29.969713 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #253 | Epoch Duration: 60.12751030921936
2020-01-11 04:27:29.970127 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #253 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.26145703
Z variance train             0.0031043119
KL Divergence                12.469076
KL Loss                      1.2469076
QF Loss                      381.00983
VF Loss                      107.41459
Policy Loss                  -1237.1973
Q Predictions Mean           1237.7217
Q Predictions Std            433.7044
Q Predictions Max            1614.5087
Q Predictions Min            -6.268881
V Predictions Mean           1233.6976
V Predictions Std            436.78378
V Predictions Max            1615.2412
V Predictions Min            -31.400644
Log Pis Mean                 0.13181174
Log Pis Std                  2.1446538
Log Pis Max                  8.882165
Log Pis Min                  -4.313237
Policy mu Mean               0.052582297
Policy mu Std                0.9518846
Policy mu Max                3.076905
Policy mu Min                -2.6226447
Policy log std Mean          -0.51892376
Policy log std Std           0.17567182
Policy log std Max           -0.09096816
Policy log std Min           -1.3392923
Z mean eval                  0.2440255
Z variance eval              0.003477731
total_rewards                [411.1147779  494.59023821 527.92757886 458.51049668 451.12017955
 473.93647729 461.90822471 544.09105214 583.75125063 559.16761269]
total_rewards_mean           496.61178886624276
total_rewards_std            52.24462048062945
total_rewards_max            583.7512506348904
total_rewards_min            411.11477790357384
Number of train steps total  255000
Number of env steps total    1277000
Number of rollouts total     0
Train Time (s)               35.32959913276136
(Previous) Eval Time (s)     5.720133105758578
Sample Time (s)              20.418521084357053
Epoch Time (s)               61.46825332287699
Total Train Time (s)         15946.020261796191
Epoch                        254
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:28:30.093716 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #254 | Epoch Duration: 60.12333917617798
2020-01-11 04:28:30.093993 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #254 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.23654473
Z variance train             0.003399557
KL Divergence                12.264105
KL Loss                      1.2264105
QF Loss                      223.85683
VF Loss                      66.607796
Policy Loss                  -1287.9785
Q Predictions Mean           1284.0474
Q Predictions Std            420.2963
Q Predictions Max            1607.4911
Q Predictions Min            8.5441675
V Predictions Mean           1285.7496
V Predictions Std            423.20837
V Predictions Max            1612.4039
V Predictions Min            -4.8695774
Log Pis Mean                 0.0066358447
Log Pis Std                  2.1974022
Log Pis Max                  6.6548176
Log Pis Min                  -5.2621737
Policy mu Mean               0.050038915
Policy mu Std                0.97558117
Policy mu Max                2.274855
Policy mu Min                -3.3153698
Policy log std Mean          -0.47658917
Policy log std Std           0.1703814
Policy log std Max           -0.08174449
Policy log std Min           -1.1337984
Z mean eval                  0.23773539
Z variance eval              0.0032279238
total_rewards                [520.27571194 655.61789496 419.4801739  428.45677699 610.49677501
 517.80623129 607.49957739 272.39837528 506.02360116 551.15182307]
total_rewards_mean           508.9206941004335
total_rewards_std            106.75774992769767
total_rewards_max            655.617894963905
total_rewards_min            272.3983752833754
Number of train steps total  256000
Number of env steps total    1282000
Number of rollouts total     0
Train Time (s)               33.87566292611882
(Previous) Eval Time (s)     4.374771979171783
Sample Time (s)              19.77190603967756
Epoch Time (s)               58.022340944968164
Total Train Time (s)         16004.992060346063
Epoch                        255
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:29:29.068537 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #255 | Epoch Duration: 58.97434687614441
2020-01-11 04:29:29.068741 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #255 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.22807972
Z variance train             0.0031881835
KL Divergence                12.2828865
KL Loss                      1.2282887
QF Loss                      216.24791
VF Loss                      51.65263
Policy Loss                  -1299.464
Q Predictions Mean           1297.5165
Q Predictions Std            404.0496
Q Predictions Max            1611.8295
Q Predictions Min            12.783472
V Predictions Mean           1295.1934
V Predictions Std            404.0678
V Predictions Max            1609.1367
V Predictions Min            -1.3753359
Log Pis Mean                 -0.058072157
Log Pis Std                  2.1435366
Log Pis Max                  7.1821117
Log Pis Min                  -4.414736
Policy mu Mean               -0.009712565
Policy mu Std                0.93702024
Policy mu Max                2.6117961
Policy mu Min                -2.8519857
Policy log std Mean          -0.4816443
Policy log std Std           0.16954613
Policy log std Max           -0.08922374
Policy log std Min           -1.0644113
Z mean eval                  4.8004036
Z variance eval              0.0041811476
total_rewards                [466.12398678 455.32126298 621.95408498 723.17760745 593.28375012
 578.53177358 447.7458254  606.32143346 593.1875738  542.47802144]
total_rewards_mean           562.8125319987387
total_rewards_std            82.31817846280596
total_rewards_max            723.1776074506133
total_rewards_min            447.74582539580416
Number of train steps total  257000
Number of env steps total    1287000
Number of rollouts total     0
Train Time (s)               34.52208007313311
(Previous) Eval Time (s)     5.326422362122685
Sample Time (s)              20.325926914345473
Epoch Time (s)               60.17442934960127
Total Train Time (s)         16065.734934995882
Epoch                        256
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:30:29.815247 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #256 | Epoch Duration: 60.74633431434631
2020-01-11 04:30:29.815457 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #256 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.21705778
Z variance train             0.002992338
KL Divergence                12.55629
KL Loss                      1.255629
QF Loss                      150.44124
VF Loss                      49.737675
Policy Loss                  -1299.7002
Q Predictions Mean           1297.6595
Q Predictions Std            393.40485
Q Predictions Max            1605.2216
Q Predictions Min            -10.205392
V Predictions Mean           1299.5356
V Predictions Std            392.00015
V Predictions Max            1603.9486
V Predictions Min            4.5802116
Log Pis Mean                 0.19014019
Log Pis Std                  2.363461
Log Pis Max                  7.1052027
Log Pis Min                  -4.548917
Policy mu Mean               0.04233429
Policy mu Std                0.97355986
Policy mu Max                2.6677673
Policy mu Min                -2.8219202
Policy log std Mean          -0.47404695
Policy log std Std           0.16388372
Policy log std Max           -0.0071641207
Policy log std Min           -1.2804956
Z mean eval                  0.20623894
Z variance eval              0.002766808
total_rewards                [623.17515433 576.94237774 678.84760759 678.67831936 610.48884163
 718.04966719 658.55298607 575.77336741 603.65767452 728.78560452]
total_rewards_mean           645.295160037676
total_rewards_std            52.55443063792423
total_rewards_max            728.7856045220374
total_rewards_min            575.7733674114843
Number of train steps total  258000
Number of env steps total    1292000
Number of rollouts total     0
Train Time (s)               34.52495922893286
(Previous) Eval Time (s)     5.897914313245565
Sample Time (s)              19.327750669326633
Epoch Time (s)               59.750624211505055
Total Train Time (s)         16125.469488067552
Epoch                        257
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:31:29.558769 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #257 | Epoch Duration: 59.743163108825684
2020-01-11 04:31:29.558933 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #257 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.17599559
Z variance train             0.002829033
KL Divergence                12.760332
KL Loss                      1.2760333
QF Loss                      161.37491
VF Loss                      31.007956
Policy Loss                  -1298.7721
Q Predictions Mean           1300.2102
Q Predictions Std            418.5997
Q Predictions Max            1622.3942
Q Predictions Min            -4.7098336
V Predictions Mean           1298.0457
V Predictions Std            415.31467
V Predictions Max            1613.0243
V Predictions Min            5.261627
Log Pis Mean                 -0.14480357
Log Pis Std                  2.2998512
Log Pis Max                  8.150684
Log Pis Min                  -4.382175
Policy mu Mean               -0.021350414
Policy mu Std                0.9371088
Policy mu Max                2.0974061
Policy mu Min                -2.8895862
Policy log std Mean          -0.4716606
Policy log std Std           0.16712329
Policy log std Max           -0.011304289
Policy log std Min           -1.1456146
Z mean eval                  0.20714298
Z variance eval              0.0028422517
total_rewards                [736.77701905 546.26608273 748.3096318  649.80802316 627.66928576
 629.92680819 669.2699685  675.32927933 698.55180676 533.06591201]
total_rewards_mean           651.4973817274102
total_rewards_std            67.73384120604383
total_rewards_max            748.3096317961614
total_rewards_min            533.06591200594
Number of train steps total  259000
Number of env steps total    1297000
Number of rollouts total     0
Train Time (s)               33.934900112915784
(Previous) Eval Time (s)     5.890065892133862
Sample Time (s)              21.148708258289844
Epoch Time (s)               60.97367426333949
Total Train Time (s)         16186.749639344867
Epoch                        258
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:32:30.839568 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #258 | Epoch Duration: 61.28045058250427
2020-01-11 04:32:30.839871 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #258 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.647415
Z variance train             0.006581108
KL Divergence                71.93319
KL Loss                      7.193319
QF Loss                      2791.1162
VF Loss                      211.77905
Policy Loss                  -955.0634
Q Predictions Mean           977.9403
Q Predictions Std            229.60748
Q Predictions Max            1174.6294
Q Predictions Min            2.3750656
V Predictions Mean           942.82715
V Predictions Std            243.11395
V Predictions Max            1144.5358
V Predictions Min            -17.543226
Log Pis Mean                 -0.011956569
Log Pis Std                  1.6635563
Log Pis Max                  5.757737
Log Pis Min                  -4.6373796
Policy mu Mean               0.4737269
Policy mu Std                0.7302757
Policy mu Max                1.9226098
Policy mu Min                -2.4447567
Policy log std Mean          -0.50800306
Policy log std Std           0.1828911
Policy log std Max           0.0068598986
Policy log std Min           -1.2899176
Z mean eval                  4.6773934
Z variance eval              0.0053910986
total_rewards                [810.25594852 768.2994793  671.88971928 653.80680972 870.66052085
 822.28967219 580.99379493 612.69762215 569.55734421 694.70307307]
total_rewards_mean           705.5153984225842
total_rewards_std            101.16733602198423
total_rewards_max            870.6605208516368
total_rewards_min            569.5573442129848
Number of train steps total  260000
Number of env steps total    1302000
Number of rollouts total     0
Train Time (s)               34.524840749334544
(Previous) Eval Time (s)     6.1964228972792625
Sample Time (s)              21.96209533372894
Epoch Time (s)               62.683358980342746
Total Train Time (s)         16248.835556183942
Epoch                        259
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:33:32.928934 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #259 | Epoch Duration: 62.08886408805847
2020-01-11 04:33:32.929228 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #259 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.2346529
Z variance train             0.0030376168
KL Divergence                12.694324
KL Loss                      1.2694324
QF Loss                      179.62744
VF Loss                      77.09988
Policy Loss                  -1300.8938
Q Predictions Mean           1300.127
Q Predictions Std            414.3779
Q Predictions Max            1599.1189
Q Predictions Min            9.367755
V Predictions Mean           1299.2449
V Predictions Std            412.03986
V Predictions Max            1602.6765
V Predictions Min            4.5624733
Log Pis Mean                 0.19266799
Log Pis Std                  2.4074755
Log Pis Max                  9.345376
Log Pis Min                  -5.8120565
Policy mu Mean               -0.104031004
Policy mu Std                1.0123619
Policy mu Max                2.9752822
Policy mu Min                -3.1375105
Policy log std Mean          -0.45132625
Policy log std Std           0.16841939
Policy log std Max           0.060873806
Policy log std Min           -1.050339
Z mean eval                  0.22292432
Z variance eval              0.0029459526
total_rewards                [539.14332912 600.21040401 548.99913619 603.01412485 494.42535042
 503.97762915 628.72744649 564.44625152 427.29324037 618.14842485]
total_rewards_mean           552.8385336969129
total_rewards_std            60.56759890893387
total_rewards_max            628.7274464901391
total_rewards_min            427.29324037080823
Number of train steps total  261000
Number of env steps total    1307000
Number of rollouts total     0
Train Time (s)               35.22222946723923
(Previous) Eval Time (s)     5.601586367934942
Sample Time (s)              22.8811829960905
Epoch Time (s)               63.704998831264675
Total Train Time (s)         16312.571039204486
Epoch                        260
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:34:36.667005 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #260 | Epoch Duration: 63.73759841918945
2020-01-11 04:34:36.667213 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #260 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.21875449
Z variance train             0.002940398
KL Divergence                12.8019905
KL Loss                      1.280199
QF Loss                      127.42122
VF Loss                      285.20898
Policy Loss                  -1209.6737
Q Predictions Mean           1210.4641
Q Predictions Std            483.36395
Q Predictions Max            1603.919
Q Predictions Min            0.2234292
V Predictions Mean           1221.5186
V Predictions Std            487.21332
V Predictions Max            1620.43
V Predictions Min            2.6848917
Log Pis Mean                 -0.22639659
Log Pis Std                  2.0007417
Log Pis Max                  7.6926584
Log Pis Min                  -4.4031267
Policy mu Mean               0.090384215
Policy mu Std                0.90325487
Policy mu Max                2.959879
Policy mu Min                -2.69438
Policy log std Mean          -0.45689586
Policy log std Std           0.17823412
Policy log std Max           -0.0834668
Policy log std Min           -1.080108
Z mean eval                  0.21071815
Z variance eval              0.002760306
total_rewards                [597.82272413 637.41038154 649.21752017 626.80743965 627.04591888
 674.12176466 636.20036367 641.72181599 581.74873352 592.06997246]
total_rewards_mean           626.4166634673754
total_rewards_std            26.906443932533243
total_rewards_max            674.1217646580594
total_rewards_min            581.7487335194176
Number of train steps total  262000
Number of env steps total    1312000
Number of rollouts total     0
Train Time (s)               35.166706073097885
(Previous) Eval Time (s)     5.63385179778561
Sample Time (s)              21.81073949439451
Epoch Time (s)               62.611297365278006
Total Train Time (s)         16375.621439914219
Epoch                        261
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:35:39.723740 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #261 | Epoch Duration: 63.05636405944824
2020-01-11 04:35:39.724044 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #261 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.3944306
Z variance train             0.027984586
KL Divergence                65.96234
KL Loss                      6.5962343
QF Loss                      1121.2345
VF Loss                      163.68423
Policy Loss                  -924.9114
Q Predictions Mean           927.6367
Q Predictions Std            250.61688
Q Predictions Max            1116.4268
Q Predictions Min            5.229498
V Predictions Mean           935.6144
V Predictions Std            252.27534
V Predictions Max            1130.2983
V Predictions Min            4.3202934
Log Pis Mean                 -0.1357895
Log Pis Std                  1.7081366
Log Pis Max                  7.770779
Log Pis Min                  -6.9152756
Policy mu Mean               0.4687232
Policy mu Std                0.7622354
Policy mu Max                2.3305728
Policy mu Min                -3.490028
Policy log std Mean          -0.5261322
Policy log std Std           0.19778624
Policy log std Max           -0.106235445
Policy log std Min           -1.3725321
Z mean eval                  0.21728325
Z variance eval              0.002464456
total_rewards                [616.06967724 636.5300789  686.11831596 676.34166502 760.18389305
 648.43884476 797.13804866 766.96153196 748.96666989 680.00925043]
total_rewards_mean           701.6757975876658
total_rewards_std            58.987058541907274
total_rewards_max            797.1380486571413
total_rewards_min            616.0696772399513
Number of train steps total  263000
Number of env steps total    1317000
Number of rollouts total     0
Train Time (s)               34.673155383672565
(Previous) Eval Time (s)     6.07853863062337
Sample Time (s)              23.706474729813635
Epoch Time (s)               64.45816874410957
Total Train Time (s)         16440.83403285453
Epoch                        262
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:36:44.937836 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #262 | Epoch Duration: 65.2135283946991
2020-01-11 04:36:44.938349 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #262 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07768758
Z variance train             0.0033362075
KL Divergence                12.76029
KL Loss                      1.276029
QF Loss                      337.28815
VF Loss                      81.499405
Policy Loss                  -1131.8658
Q Predictions Mean           1130.5663
Q Predictions Std            416.1038
Q Predictions Max            1493.2007
Q Predictions Min            -34.93329
V Predictions Mean           1129.728
V Predictions Std            411.63498
V Predictions Max            1479.3252
V Predictions Min            -15.243869
Log Pis Mean                 -0.2125564
Log Pis Std                  2.0195844
Log Pis Max                  7.8982563
Log Pis Min                  -5.49085
Policy mu Mean               -0.1819609
Policy mu Std                0.9005225
Policy mu Max                2.4165602
Policy mu Min                -2.674746
Policy log std Mean          -0.47158766
Policy log std Std           0.16647103
Policy log std Max           0.08791581
Policy log std Min           -0.9193357
Z mean eval                  0.20639741
Z variance eval              0.0030495434
total_rewards                [646.60800334 650.10081634 602.0068114  654.98020583 648.69716532
 640.87267859 675.27984303 598.99140351 605.21402855 584.13010767]
total_rewards_mean           630.6881063575465
total_rewards_std            28.776293637716286
total_rewards_max            675.2798430261399
total_rewards_min            584.1301076674354
Number of train steps total  264000
Number of env steps total    1322000
Number of rollouts total     0
Train Time (s)               34.998479827772826
(Previous) Eval Time (s)     6.83344607707113
Sample Time (s)              23.779034191276878
Epoch Time (s)               65.61096009612083
Total Train Time (s)         16505.456922682468
Epoch                        263
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:37:49.563157 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #263 | Epoch Duration: 64.62445092201233
2020-01-11 04:37:49.563367 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #263 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.19263265
Z variance train             0.0034208088
KL Divergence                12.616175
KL Loss                      1.2616175
QF Loss                      334.74057
VF Loss                      586.1128
Policy Loss                  -1270.9855
Q Predictions Mean           1269.4358
Q Predictions Std            422.72748
Q Predictions Max            1619.793
Q Predictions Min            1.1816483
V Predictions Mean           1270.8722
V Predictions Std            418.24207
V Predictions Max            1613.3857
V Predictions Min            3.0559347
Log Pis Mean                 -0.10959904
Log Pis Std                  2.0327268
Log Pis Max                  6.8770766
Log Pis Min                  -5.6167665
Policy mu Mean               0.15934789
Policy mu Std                0.9319069
Policy mu Max                2.985195
Policy mu Min                -2.810463
Policy log std Mean          -0.46932864
Policy log std Std           0.16749233
Policy log std Max           -0.10760635
Policy log std Min           -0.92540383
Z mean eval                  0.19780993
Z variance eval              0.0034093116
total_rewards                [861.14387369 740.81083443 833.23689696 810.37983413 879.19708358
 751.00096485 795.8751904  707.80320946 823.7946851  737.4067791 ]
total_rewards_mean           794.0649351704024
total_rewards_std            54.56789992044516
total_rewards_max            879.1970835847293
total_rewards_min            707.8032094611995
Number of train steps total  265000
Number of env steps total    1327000
Number of rollouts total     0
Train Time (s)               33.84992598230019
(Previous) Eval Time (s)     5.84657298726961
Sample Time (s)              23.21245241817087
Epoch Time (s)               62.90895138774067
Total Train Time (s)         16569.46389441332
Epoch                        264
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:38:53.573978 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #264 | Epoch Duration: 64.01045417785645
2020-01-11 04:38:53.574212 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #264 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.20625362
Z variance train             0.0033868984
KL Divergence                12.953254
KL Loss                      1.2953254
QF Loss                      142.34787
VF Loss                      192.41562
Policy Loss                  -1249.916
Q Predictions Mean           1247.8962
Q Predictions Std            417.6816
Q Predictions Max            1567.9944
Q Predictions Min            -1.6905824
V Predictions Mean           1239.0886
V Predictions Std            414.99463
V Predictions Max            1552.91
V Predictions Min            2.1878936
Log Pis Mean                 0.07366171
Log Pis Std                  2.1235955
Log Pis Max                  8.132034
Log Pis Min                  -6.318871
Policy mu Mean               -0.14264837
Policy mu Std                0.9555548
Policy mu Max                2.3180914
Policy mu Min                -2.8349733
Policy log std Mean          -0.5034774
Policy log std Std           0.15651673
Policy log std Max           -0.033837557
Policy log std Min           -1.0782552
Z mean eval                  0.16843864
Z variance eval              0.0032682992
total_rewards                [890.15148114 880.80761492 866.71468535 781.39993523 754.15405195
 781.13879508 587.99324364 868.39752733 651.94263544 841.79654359]
total_rewards_mean           790.4496513663405
total_rewards_std            97.10432379198183
total_rewards_max            890.1514811404728
total_rewards_min            587.9932436359154
Number of train steps total  266000
Number of env steps total    1332000
Number of rollouts total     0
Train Time (s)               32.393432955257595
(Previous) Eval Time (s)     6.947710703127086
Sample Time (s)              22.137758628930897
Epoch Time (s)               61.47890228731558
Total Train Time (s)         16630.968338032253
Epoch                        265
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:39:55.081619 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #265 | Epoch Duration: 61.50723433494568
2020-01-11 04:39:55.081815 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #265 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.17879154
Z variance train             0.0032954682
KL Divergence                12.7329235
KL Loss                      1.2732924
QF Loss                      1164.492
VF Loss                      1324.701
Policy Loss                  -1277.0088
Q Predictions Mean           1272.3683
Q Predictions Std            412.2256
Q Predictions Max            1592.6688
Q Predictions Min            14.127406
V Predictions Mean           1243.972
V Predictions Std            402.2034
V Predictions Max            1558.6943
V Predictions Min            2.2375143
Log Pis Mean                 0.13444686
Log Pis Std                  2.637354
Log Pis Max                  16.83017
Log Pis Min                  -4.5414543
Policy mu Mean               -0.061319884
Policy mu Std                1.0163935
Policy mu Max                3.9051654
Policy mu Min                -5.3065634
Policy log std Mean          -0.4910771
Policy log std Std           0.16538079
Policy log std Max           -0.08579561
Policy log std Min           -1.2685232
Z mean eval                  5.1484327
Z variance eval              0.010733792
total_rewards                [753.05536507 821.2511952  842.57562844 687.63997549 276.10694877
 517.9958783  832.74453885 785.02811032 872.19616718 644.44190656]
total_rewards_mean           703.303571417918
total_rewards_std            175.58134905569077
total_rewards_max            872.1961671755807
total_rewards_min            276.1069487726849
Number of train steps total  267000
Number of env steps total    1337000
Number of rollouts total     0
Train Time (s)               32.63533086888492
(Previous) Eval Time (s)     6.9756688619963825
Sample Time (s)              22.858861189801246
Epoch Time (s)               62.46986092068255
Total Train Time (s)         16693.287941630464
Epoch                        266
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:40:57.404996 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #266 | Epoch Duration: 62.32303762435913
2020-01-11 04:40:57.405174 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #266 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.8745475
Z variance train             0.0127998935
KL Divergence                78.980125
KL Loss                      7.8980126
QF Loss                      2037.0444
VF Loss                      540.67566
Policy Loss                  -1117.117
Q Predictions Mean           1109.6714
Q Predictions Std            324.49524
Q Predictions Max            1355.9053
Q Predictions Min            2.7405665
V Predictions Mean           1105.4884
V Predictions Std            328.86356
V Predictions Max            1345.3772
V Predictions Min            -0.74725795
Log Pis Mean                 0.23825535
Log Pis Std                  1.9843851
Log Pis Max                  6.399364
Log Pis Min                  -6.5510087
Policy mu Mean               0.6347913
Policy mu Std                0.80856144
Policy mu Max                3.069829
Policy mu Min                -2.9932368
Policy log std Mean          -0.5101599
Policy log std Std           0.15080214
Policy log std Max           0.032619238
Policy log std Min           -1.438436
Z mean eval                  5.091298
Z variance eval              0.012360243
total_rewards                [722.53807697 807.59692013 759.1243843  810.12919863 892.02696851
 805.88412054 778.24168336 929.87610344 818.576402   706.36369276]
total_rewards_mean           803.0357550635176
total_rewards_std            65.34292187398593
total_rewards_max            929.8761034368296
total_rewards_min            706.3636927606251
Number of train steps total  268000
Number of env steps total    1342000
Number of rollouts total     0
Train Time (s)               32.64564978238195
(Previous) Eval Time (s)     6.828556528314948
Sample Time (s)              21.02083275653422
Epoch Time (s)               60.49503906723112
Total Train Time (s)         16754.046917241532
Epoch                        267
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:41:58.166210 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #267 | Epoch Duration: 60.760902404785156
2020-01-11 04:41:58.166386 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #267 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.17691536
Z variance train             0.0033107973
KL Divergence                12.542704
KL Loss                      1.2542704
QF Loss                      175.15405
VF Loss                      102.829666
Policy Loss                  -1248.4745
Q Predictions Mean           1246.6492
Q Predictions Std            413.6164
Q Predictions Max            1563.7086
Q Predictions Min            4.048704
V Predictions Mean           1242.6816
V Predictions Std            412.0577
V Predictions Max            1559.8431
V Predictions Min            8.2686205
Log Pis Mean                 0.1176638
Log Pis Std                  2.2190838
Log Pis Max                  8.007393
Log Pis Min                  -4.276729
Policy mu Mean               0.03356066
Policy mu Std                0.9740124
Policy mu Max                3.1319544
Policy mu Min                -2.8650587
Policy log std Mean          -0.4688702
Policy log std Std           0.14987874
Policy log std Max           -0.056239814
Policy log std Min           -1.0996807
Z mean eval                  0.28579164
Z variance eval              0.006394514
total_rewards                [ 963.49598223  788.70584187  825.19021028  877.49523007  888.64295599
  819.902546    784.45435399  783.0966189  1003.13845841  929.26338333]
total_rewards_mean           866.3385581068053
total_rewards_std            74.99722702667793
total_rewards_max            1003.1384584144434
total_rewards_min            783.0966188969792
Number of train steps total  269000
Number of env steps total    1347000
Number of rollouts total     0
Train Time (s)               32.59776422707364
(Previous) Eval Time (s)     7.094106158707291
Sample Time (s)              23.781492904294282
Epoch Time (s)               63.47336329007521
Total Train Time (s)         16818.427044110373
Epoch                        268
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:43:02.549437 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #268 | Epoch Duration: 64.3829128742218
2020-01-11 04:43:02.549613 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #268 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.813794
Z variance train             0.013650003
KL Divergence                78.754845
KL Loss                      7.8754845
QF Loss                      172.07228
VF Loss                      94.769646
Policy Loss                  -1128.7616
Q Predictions Mean           1127.3931
Q Predictions Std            351.13687
Q Predictions Max            1392.8542
Q Predictions Min            0.68098056
V Predictions Mean           1135.8386
V Predictions Std            352.4365
V Predictions Max            1409.2222
V Predictions Min            3.3610535
Log Pis Mean                 0.00298357
Log Pis Std                  1.8369339
Log Pis Max                  6.924964
Log Pis Min                  -5.6260247
Policy mu Mean               0.50399464
Policy mu Std                0.8325463
Policy mu Max                2.3828483
Policy mu Min                -2.7196164
Policy log std Mean          -0.502212
Policy log std Std           0.17338447
Policy log std Max           -0.027900487
Policy log std Min           -1.3985623
Z mean eval                  0.19883105
Z variance eval              0.0039709387
total_rewards                [ 855.2596325   779.17375958  732.04606789  812.47874681  584.39790644
  750.22680264  588.48276764  756.36800115 1033.79849347  581.09854658]
total_rewards_mean           747.3330724705286
total_rewards_std            133.68143828711587
total_rewards_max            1033.7984934747747
total_rewards_min            581.0985465755186
Number of train steps total  270000
Number of env steps total    1352000
Number of rollouts total     0
Train Time (s)               32.47718432499096
(Previous) Eval Time (s)     8.003330861218274
Sample Time (s)              22.646805016323924
Epoch Time (s)               63.127320202533156
Total Train Time (s)         16880.563662671484
Epoch                        269
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:44:04.689510 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #269 | Epoch Duration: 62.139739751815796
2020-01-11 04:44:04.689743 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #269 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.9756737
Z variance train             0.007147978
KL Divergence                82.67175
KL Loss                      8.267176
QF Loss                      318.431
VF Loss                      153.21745
Policy Loss                  -1159.7887
Q Predictions Mean           1156.4218
Q Predictions Std            412.29684
Q Predictions Max            1465.7222
Q Predictions Min            -2.2337885
V Predictions Mean           1158.0203
V Predictions Std            409.04733
V Predictions Max            1470.6068
V Predictions Min            -1.0442313
Log Pis Mean                 0.38114786
Log Pis Std                  2.066932
Log Pis Max                  8.511885
Log Pis Min                  -6.7270937
Policy mu Mean               0.5428236
Policy mu Std                0.8761495
Policy mu Max                2.3570004
Policy mu Min                -3.044165
Policy log std Mean          -0.5299496
Policy log std Std           0.17851926
Policy log std Max           -0.028822243
Policy log std Min           -1.5756696
Z mean eval                  0.18842581
Z variance eval              0.0037539895
total_rewards                [815.46285674 597.15980609 690.35689926 505.98126324 771.01495418
 839.00499856 746.04812012 755.09763373 367.90549162 773.2023597 ]
total_rewards_mean           686.1234383244961
total_rewards_std            143.13821524960116
total_rewards_max            839.00499856399
total_rewards_min            367.9054916196596
Number of train steps total  271000
Number of env steps total    1357000
Number of rollouts total     0
Train Time (s)               32.859526487998664
(Previous) Eval Time (s)     7.015394723042846
Sample Time (s)              23.423041372094303
Epoch Time (s)               63.29796258313581
Total Train Time (s)         16943.51061526267
Epoch                        270
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:45:07.640123 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #270 | Epoch Duration: 62.95021343231201
2020-01-11 04:45:07.640317 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #270 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 5.021276
Z variance train             0.0058872597
KL Divergence                83.232666
KL Loss                      8.323267
QF Loss                      438.28558
VF Loss                      98.59271
Policy Loss                  -1203.6874
Q Predictions Mean           1198.1509
Q Predictions Std            394.69873
Q Predictions Max            1501.2184
Q Predictions Min            -7.0847874
V Predictions Mean           1202.9287
V Predictions Std            397.8901
V Predictions Max            1500.0719
V Predictions Min            0.36092573
Log Pis Mean                 0.11086027
Log Pis Std                  1.988032
Log Pis Max                  9.102588
Log Pis Min                  -4.243372
Policy mu Mean               0.386844
Policy mu Std                0.8565326
Policy mu Max                2.4743073
Policy mu Min                -3.412662
Policy log std Mean          -0.5391547
Policy log std Std           0.21165094
Policy log std Max           0.09422809
Policy log std Min           -1.5672551
Z mean eval                  0.1758261
Z variance eval              0.0038099743
total_rewards                [ 874.40143455  848.60729129  616.23901595  958.72454049 1115.28078327
  785.02047488  923.53627128  709.13863214  751.16831695  306.76823296]
total_rewards_mean           788.8884993767248
total_rewards_std            208.4299961702551
total_rewards_max            1115.280783273509
total_rewards_min            306.7682329585751
Number of train steps total  272000
Number of env steps total    1362000
Number of rollouts total     0
Train Time (s)               32.331419489812106
(Previous) Eval Time (s)     6.667302838061005
Sample Time (s)              22.93070700066164
Epoch Time (s)               61.92942932853475
Total Train Time (s)         17005.53490568977
Epoch                        271
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:46:09.668438 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #271 | Epoch Duration: 62.02796769142151
2020-01-11 04:46:09.668655 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #271 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.25257513
Z variance train             0.003937234
KL Divergence                12.365201
KL Loss                      1.2365202
QF Loss                      1058.9648
VF Loss                      282.73657
Policy Loss                  -1265.3822
Q Predictions Mean           1268.0021
Q Predictions Std            448.29996
Q Predictions Max            1608.8334
Q Predictions Min            -0.5311971
V Predictions Mean           1263.429
V Predictions Std            447.38083
V Predictions Max            1606.4424
V Predictions Min            2.1400275
Log Pis Mean                 0.10324025
Log Pis Std                  2.1686056
Log Pis Max                  9.690624
Log Pis Min                  -4.9025245
Policy mu Mean               0.15475833
Policy mu Std                0.9912257
Policy mu Max                2.678687
Policy mu Min                -3.287169
Policy log std Mean          -0.48873115
Policy log std Std           0.15584205
Policy log std Max           0.10387114
Policy log std Min           -0.96334696
Z mean eval                  4.0795875
Z variance eval              0.006274569
total_rewards                [719.50632173 566.83894754 619.50972239 731.17836319 759.66918603
 539.16700529 745.22854198 778.73961856 476.00289312 710.07269778]
total_rewards_mean           664.591329761282
total_rewards_std            100.48620499359274
total_rewards_max            778.739618555821
total_rewards_min            476.00289311751976
Number of train steps total  273000
Number of env steps total    1367000
Number of rollouts total     0
Train Time (s)               32.902236172929406
(Previous) Eval Time (s)     6.7654938087798655
Sample Time (s)              23.153204006608576
Epoch Time (s)               62.82093398831785
Total Train Time (s)         17067.349286816083
Epoch                        272
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:47:11.487360 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #272 | Epoch Duration: 61.81854844093323
2020-01-11 04:47:11.487528 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #272 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1285295
Z variance train             0.006199751
KL Divergence                60.795654
KL Loss                      6.0795655
QF Loss                      158.90842
VF Loss                      265.10602
Policy Loss                  -1098.2424
Q Predictions Mean           1093.8743
Q Predictions Std            297.3342
Q Predictions Max            1357.8246
Q Predictions Min            -2.0058913
V Predictions Mean           1086.1892
V Predictions Std            295.48633
V Predictions Max            1345.8453
V Predictions Min            2.1286693
Log Pis Mean                 0.0793331
Log Pis Std                  1.9918286
Log Pis Max                  8.9052925
Log Pis Min                  -4.5772114
Policy mu Mean               0.33254126
Policy mu Std                0.89891994
Policy mu Max                2.4988532
Policy mu Min                -2.9174454
Policy log std Mean          -0.49849746
Policy log std Std           0.17624189
Policy log std Max           -0.054138243
Policy log std Min           -1.3856229
Z mean eval                  4.721555
Z variance eval              0.0007739707
total_rewards                [852.30189341 673.89706626 931.85534451 933.92318098 894.43711145
 996.80268068 687.58775207 882.65349572 630.75547449 872.01285306]
total_rewards_mean           835.6226852609041
total_rewards_std            119.25446263241791
total_rewards_max            996.8026806769952
total_rewards_min            630.755474490594
Number of train steps total  274000
Number of env steps total    1372000
Number of rollouts total     0
Train Time (s)               32.21058908337727
(Previous) Eval Time (s)     5.762787397950888
Sample Time (s)              21.86532122734934
Epoch Time (s)               59.8386977086775
Total Train Time (s)         17129.53856535768
Epoch                        273
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:48:13.678734 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #273 | Epoch Duration: 62.19107532501221
2020-01-11 04:48:13.678902 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #273 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.98125
Z variance train             0.0036107483
KL Divergence                56.445545
KL Loss                      5.6445546
QF Loss                      84.473854
VF Loss                      50.334568
Policy Loss                  -1033.9373
Q Predictions Mean           1027.6285
Q Predictions Std            353.97778
Q Predictions Max            1327.043
Q Predictions Min            2.252081
V Predictions Mean           1035.3677
V Predictions Std            356.18045
V Predictions Max            1348.3873
V Predictions Min            1.9757959
Log Pis Mean                 0.19270265
Log Pis Std                  1.9492122
Log Pis Max                  8.899194
Log Pis Min                  -6.3998766
Policy mu Mean               0.4912827
Policy mu Std                0.844799
Policy mu Max                2.991579
Policy mu Min                -2.8717513
Policy log std Mean          -0.47858414
Policy log std Std           0.17210563
Policy log std Max           -0.013808429
Policy log std Min           -1.4193884
Z mean eval                  4.420892
Z variance eval              0.0022486243
total_rewards                [1066.43582781  859.04341378 1027.87427543  895.82641975  861.15369847
 1053.56056867  837.13212474 1021.40672645 1014.68335906  712.36907088]
total_rewards_mean           934.9485485029576
total_rewards_std            112.10399197494051
total_rewards_max            1066.4358278149928
total_rewards_min            712.369070877137
Number of train steps total  275000
Number of env steps total    1377000
Number of rollouts total     0
Train Time (s)               32.62471725419164
(Previous) Eval Time (s)     8.114808831829578
Sample Time (s)              22.761229456868023
Epoch Time (s)               63.50075554288924
Total Train Time (s)         17194.220573269762
Epoch                        274
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:49:18.363758 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #274 | Epoch Duration: 64.68469572067261
2020-01-11 04:49:18.363930 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #274 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.16222134
Z variance train             0.0050117197
KL Divergence                11.941218
KL Loss                      1.1941218
QF Loss                      232.29861
VF Loss                      147.43698
Policy Loss                  -1245.7253
Q Predictions Mean           1243.8394
Q Predictions Std            391.283
Q Predictions Max            1564.5212
Q Predictions Min            7.477794
V Predictions Mean           1236.5825
V Predictions Std            389.24576
V Predictions Max            1554.986
V Predictions Min            4.665797
Log Pis Mean                 0.21052928
Log Pis Std                  2.3604739
Log Pis Max                  8.354305
Log Pis Min                  -5.060907
Policy mu Mean               0.19768268
Policy mu Std                0.9938855
Policy mu Max                2.5336463
Policy mu Min                -2.7568567
Policy log std Mean          -0.5058505
Policy log std Std           0.15708958
Policy log std Max           0.0383275
Policy log std Min           -1.2185836
Z mean eval                  4.062819
Z variance eval              0.004870828
total_rewards                [758.19845365 719.64865748 679.10849363 642.96516308 737.87834084
 691.09311279 586.56875839 782.17126247 596.16893525 727.17330929]
total_rewards_mean           692.0974486878855
total_rewards_std            62.84122633467224
total_rewards_max            782.17126246823
total_rewards_min            586.5687583948021
Number of train steps total  276000
Number of env steps total    1382000
Number of rollouts total     0
Train Time (s)               32.86905964789912
(Previous) Eval Time (s)     9.298424378968775
Sample Time (s)              23.10243594739586
Epoch Time (s)               65.26991997426376
Total Train Time (s)         17257.12566466164
Epoch                        275
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:50:21.274864 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #275 | Epoch Duration: 62.91076898574829
2020-01-11 04:50:21.275144 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #275 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.896192
Z variance train             0.0066305893
KL Divergence                51.575813
KL Loss                      5.1575813
QF Loss                      112.59457
VF Loss                      49.20971
Policy Loss                  -1048.7339
Q Predictions Mean           1045.0403
Q Predictions Std            377.28348
Q Predictions Max            1373.1259
Q Predictions Min            -0.61698425
V Predictions Mean           1053.0421
V Predictions Std            375.90768
V Predictions Max            1378.3743
V Predictions Min            0.6144781
Log Pis Mean                 0.10974939
Log Pis Std                  1.9102561
Log Pis Max                  8.42829
Log Pis Min                  -5.556095
Policy mu Mean               0.4382074
Policy mu Std                0.8658639
Policy mu Max                2.496763
Policy mu Min                -2.7399383
Policy log std Mean          -0.48293626
Policy log std Std           0.14740491
Policy log std Max           -0.12256175
Policy log std Min           -1.0715308
Z mean eval                  3.861238
Z variance eval              0.0034352448
total_rewards                [722.22244478 497.99632901 731.49797343 654.31241233 634.46681359
 449.73836755 583.55991571 543.21532389 509.01189144 551.30939799]
total_rewards_mean           587.7330869702162
total_rewards_std            90.54875170870088
total_rewards_max            731.4979734254
total_rewards_min            449.7383675511325
Number of train steps total  277000
Number of env steps total    1387000
Number of rollouts total     0
Train Time (s)               32.75485492590815
(Previous) Eval Time (s)     6.938950835261494
Sample Time (s)              22.4387890486978
Epoch Time (s)               62.13259480986744
Total Train Time (s)         17318.36149216676
Epoch                        276
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:51:22.513186 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #276 | Epoch Duration: 61.237804889678955
2020-01-11 04:51:22.513369 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #276 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.750517
Z variance train             0.0040990873
KL Divergence                51.196083
KL Loss                      5.1196084
QF Loss                      229.27554
VF Loss                      77.01401
Policy Loss                  -1045.6725
Q Predictions Mean           1045.8335
Q Predictions Std            347.09174
Q Predictions Max            1377.9397
Q Predictions Min            2.2758934
V Predictions Mean           1045.5199
V Predictions Std            346.63544
V Predictions Max            1390.8079
V Predictions Min            1.3301749
Log Pis Mean                 -0.13848841
Log Pis Std                  1.9490545
Log Pis Max                  8.504364
Log Pis Min                  -5.5030475
Policy mu Mean               0.34686288
Policy mu Std                0.85812175
Policy mu Max                2.7082684
Policy mu Min                -2.9292798
Policy log std Mean          -0.46001175
Policy log std Std           0.15759729
Policy log std Max           -0.11244719
Policy log std Min           -1.2690799
Z mean eval                  3.4185662
Z variance eval              0.003748861
total_rewards                [ 610.28260479  974.36261879 1087.41617798  936.83853398  943.06044581
  816.08547388 1104.39887925 1050.51877289  997.77139703  992.36013206]
total_rewards_mean           951.3095036467766
total_rewards_std            138.21776675271175
total_rewards_max            1104.3988792520067
total_rewards_min            610.2826047891405
Number of train steps total  278000
Number of env steps total    1392000
Number of rollouts total     0
Train Time (s)               32.51231800625101
(Previous) Eval Time (s)     6.043854807969183
Sample Time (s)              23.63374242419377
Epoch Time (s)               62.18991523841396
Total Train Time (s)         17382.82232304616
Epoch                        277
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:52:26.977056 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #277 | Epoch Duration: 64.46355056762695
2020-01-11 04:52:26.977242 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #277 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.518277
Z variance train             0.0031719822
KL Divergence                46.593857
KL Loss                      4.6593857
QF Loss                      142.5845
VF Loss                      69.18761
Policy Loss                  -1010.94586
Q Predictions Mean           1010.6734
Q Predictions Std            324.24854
Q Predictions Max            1326.4701
Q Predictions Min            -12.509731
V Predictions Mean           1011.92554
V Predictions Std            323.96323
V Predictions Max            1332.4735
V Predictions Min            7.2264676
Log Pis Mean                 0.17554675
Log Pis Std                  1.912413
Log Pis Max                  6.8065615
Log Pis Min                  -6.714222
Policy mu Mean               0.38272694
Policy mu Std                0.92042196
Policy mu Max                3.4626312
Policy mu Min                -2.8044884
Policy log std Mean          -0.48353946
Policy log std Std           0.1670921
Policy log std Max           0.040228188
Policy log std Min           -1.2869077
Z mean eval                  3.0634978
Z variance eval              0.0050332816
total_rewards                [326.57473322 522.01795158 560.78918082 517.36160135 680.79053038
 701.92860989 555.17048228 688.86987039 531.69758688 641.35665522]
total_rewards_mean           572.6557202005991
total_rewards_std            107.2062296191504
total_rewards_max            701.9286098948941
total_rewards_min            326.57473321706084
Number of train steps total  279000
Number of env steps total    1397000
Number of rollouts total     0
Train Time (s)               32.69221623474732
(Previous) Eval Time (s)     8.317144321743399
Sample Time (s)              23.43553014891222
Epoch Time (s)               64.44489070540294
Total Train Time (s)         17445.050745709334
Epoch                        278
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:53:29.208648 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #278 | Epoch Duration: 62.231281042099
2020-01-11 04:53:29.208813 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #278 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2199154
Z variance train             0.0038061787
KL Divergence                40.78811
KL Loss                      4.078811
QF Loss                      269.94556
VF Loss                      72.563225
Policy Loss                  -972.3438
Q Predictions Mean           970.6738
Q Predictions Std            293.79797
Q Predictions Max            1272.0997
Q Predictions Min            0.011002749
V Predictions Mean           974.9608
V Predictions Std            291.83047
V Predictions Max            1281.2793
V Predictions Min            3.6832845
Log Pis Mean                 -0.11449843
Log Pis Std                  1.7721778
Log Pis Max                  5.788716
Log Pis Min                  -6.1524744
Policy mu Mean               0.32095942
Policy mu Std                0.888617
Policy mu Max                3.172911
Policy mu Min                -3.0464396
Policy log std Mean          -0.47640157
Policy log std Std           0.15311867
Policy log std Max           0.005856231
Policy log std Min           -1.2513667
Z mean eval                  3.17883
Z variance eval              0.0072500603
total_rewards                [541.6880011  967.24025075 750.61896786 519.7695916  853.65964538
 607.55095697 819.09187728 874.23128246 987.86491702 600.06614439]
total_rewards_mean           752.1781634812379
total_rewards_std            165.4842065992333
total_rewards_max            987.8649170192444
total_rewards_min            519.7695916024787
Number of train steps total  280000
Number of env steps total    1402000
Number of rollouts total     0
Train Time (s)               32.5144346090965
(Previous) Eval Time (s)     6.103172491770238
Sample Time (s)              21.787771612405777
Epoch Time (s)               60.40537871327251
Total Train Time (s)         17506.520458713174
Epoch                        279
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:54:30.681647 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #279 | Epoch Duration: 61.47269797325134
2020-01-11 04:54:30.681832 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #279 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1930447
Z variance train             0.007495639
KL Divergence                41.022453
KL Loss                      4.1022453
QF Loss                      232.41496
VF Loss                      112.258804
Policy Loss                  -977.12994
Q Predictions Mean           977.5083
Q Predictions Std            320.30585
Q Predictions Max            1333.1875
Q Predictions Min            7.7383714
V Predictions Mean           974.08417
V Predictions Std            317.8648
V Predictions Max            1320.5067
V Predictions Min            5.522905
Log Pis Mean                 -0.040350884
Log Pis Std                  1.9762573
Log Pis Max                  6.4503083
Log Pis Min                  -6.885211
Policy mu Mean               0.311415
Policy mu Std                0.93204623
Policy mu Max                2.3923082
Policy mu Min                -2.7816577
Policy log std Mean          -0.48530862
Policy log std Std           0.15565278
Policy log std Max           -0.10369735
Policy log std Min           -1.2099383
Z mean eval                  3.2350051
Z variance eval              0.0028060523
total_rewards                [ 518.00411234 1348.56428403  626.46078709  520.99547     522.64703165
 1035.29132295  902.29512664 1106.69143246  952.9478089  1138.8229952 ]
total_rewards_mean           867.2720371257561
total_rewards_std            286.03377920641566
total_rewards_max            1348.5642840338858
total_rewards_min            518.0041123444134
Number of train steps total  281000
Number of env steps total    1407000
Number of rollouts total     0
Train Time (s)               32.46467844303697
(Previous) Eval Time (s)     7.170147137250751
Sample Time (s)              22.331928212661296
Epoch Time (s)               61.96675379294902
Total Train Time (s)         17570.159696748015
Epoch                        280
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:55:34.324526 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #280 | Epoch Duration: 63.64255213737488
2020-01-11 04:55:34.324705 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #280 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2299361
Z variance train             0.0028214415
KL Divergence                42.390015
KL Loss                      4.2390018
QF Loss                      148.2922
VF Loss                      218.54529
Policy Loss                  -1039.3645
Q Predictions Mean           1037.177
Q Predictions Std            302.0904
Q Predictions Max            1316.5643
Q Predictions Min            -12.194763
V Predictions Mean           1045.6287
V Predictions Std            295.06052
V Predictions Max            1323.746
V Predictions Min            -4.3197184
Log Pis Mean                 0.06043987
Log Pis Std                  2.0073307
Log Pis Max                  8.401577
Log Pis Min                  -5.272653
Policy mu Mean               0.28970662
Policy mu Std                0.93066597
Policy mu Max                2.6314542
Policy mu Min                -3.4811878
Policy log std Mean          -0.4941635
Policy log std Std           0.16219102
Policy log std Max           -0.14236617
Policy log std Min           -1.2881969
Z mean eval                  3.1951938
Z variance eval              0.0020664888
total_rewards                [ 864.43202581 1196.41238628  294.10924188 1128.34076082  615.40323306
  964.66126799  776.94905494  947.46367113  951.47829945 1034.82936888]
total_rewards_mean           877.4079310208972
total_rewards_std            250.3326167442097
total_rewards_max            1196.4123862756003
total_rewards_min            294.1092418785359
Number of train steps total  282000
Number of env steps total    1412000
Number of rollouts total     0
Train Time (s)               33.050783338956535
(Previous) Eval Time (s)     8.845639233943075
Sample Time (s)              23.138509639073163
Epoch Time (s)               65.03493221197277
Total Train Time (s)         17635.64056396857
Epoch                        281
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:56:39.808206 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #281 | Epoch Duration: 65.4833574295044
2020-01-11 04:56:39.808390 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #281 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1981304
Z variance train             0.0019578305
KL Divergence                41.805832
KL Loss                      4.1805835
QF Loss                      200.05164
VF Loss                      79.82855
Policy Loss                  -1019.957
Q Predictions Mean           1017.34784
Q Predictions Std            357.72906
Q Predictions Max            1337.4193
Q Predictions Min            4.998329
V Predictions Mean           1016.912
V Predictions Std            357.9433
V Predictions Max            1346.3573
V Predictions Min            3.8598733
Log Pis Mean                 0.29940107
Log Pis Std                  2.0565789
Log Pis Max                  9.554629
Log Pis Min                  -4.1566067
Policy mu Mean               0.32709375
Policy mu Std                0.96086246
Policy mu Max                2.7183893
Policy mu Min                -3.4294128
Policy log std Mean          -0.44834104
Policy log std Std           0.1616789
Policy log std Max           -0.12232302
Policy log std Min           -1.4287957
Z mean eval                  3.0812612
Z variance eval              0.0025970112
total_rewards                [ 963.6170861   564.68404182  314.9961379   938.09814822 1024.7749246
  725.72659825  933.86113703  310.89372058  846.21781194  795.09097875]
total_rewards_mean           741.7960585175869
total_rewards_std            248.57820780154537
total_rewards_max            1024.774924596684
total_rewards_min            310.89372057639133
Number of train steps total  283000
Number of env steps total    1417000
Number of rollouts total     0
Train Time (s)               32.91303488286212
(Previous) Eval Time (s)     9.293719734996557
Sample Time (s)              22.522098049521446
Epoch Time (s)               64.72885266738012
Total Train Time (s)         17699.750133284833
Epoch                        282
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:57:43.921193 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #282 | Epoch Duration: 64.1126639842987
2020-01-11 04:57:43.921378 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #282 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.117718
Z variance train             0.0020446484
KL Divergence                40.947586
KL Loss                      4.0947585
QF Loss                      130.26682
VF Loss                      48.343567
Policy Loss                  -1017.3876
Q Predictions Mean           1015.9192
Q Predictions Std            343.76178
Q Predictions Max            1304.103
Q Predictions Min            -2.1293101
V Predictions Mean           1018.4636
V Predictions Std            342.29333
V Predictions Max            1315.7478
V Predictions Min            2.7501667
Log Pis Mean                 0.30803522
Log Pis Std                  2.1454058
Log Pis Max                  8.065975
Log Pis Min                  -5.6080427
Policy mu Mean               0.08392199
Policy mu Std                0.9890987
Policy mu Max                2.5402496
Policy mu Min                -3.0998275
Policy log std Mean          -0.473287
Policy log std Std           0.16006404
Policy log std Max           -0.11826876
Policy log std Min           -1.2679936
Z mean eval                  2.9558468
Z variance eval              0.005155415
total_rewards                [ 937.0484531   891.00274816  984.74728519  339.28894284  347.09020287
  323.87708483 1880.47021443 1087.23893485  359.13118248  379.54588387]
total_rewards_mean           752.9440932625146
total_rewards_std            480.02050116100395
total_rewards_max            1880.4702144342036
total_rewards_min            323.877084831833
Number of train steps total  284000
Number of env steps total    1422000
Number of rollouts total     0
Train Time (s)               32.51688719494268
(Previous) Eval Time (s)     8.677185907959938
Sample Time (s)              21.02155816135928
Epoch Time (s)               62.2156312642619
Total Train Time (s)         17762.676457128488
Epoch                        283
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:58:46.850854 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #283 | Epoch Duration: 62.929319858551025
2020-01-11 04:58:46.851049 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #283 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.0488248
Z variance train             0.003221043
KL Divergence                39.08876
KL Loss                      3.9088762
QF Loss                      165.57445
VF Loss                      81.65967
Policy Loss                  -1059.4481
Q Predictions Mean           1056.0981
Q Predictions Std            307.88937
Q Predictions Max            1306.8708
Q Predictions Min            4.7767525
V Predictions Mean           1058.9011
V Predictions Std            306.47638
V Predictions Max            1308.8193
V Predictions Min            -5.910803
Log Pis Mean                 -0.06618506
Log Pis Std                  1.6660029
Log Pis Max                  5.509231
Log Pis Min                  -5.283306
Policy mu Mean               0.30608952
Policy mu Std                0.8659823
Policy mu Max                2.3756015
Policy mu Min                -2.8273335
Policy log std Mean          -0.41902038
Policy log std Std           0.1565107
Policy log std Max           0.047075838
Policy log std Min           -1.334385
Z mean eval                  2.8800836
Z variance eval              0.0044417046
total_rewards                [ 415.74256723  343.12653674  813.99700582  354.32743276  738.62250302
  398.1354021  1007.40816741  779.27453544  910.85926867  352.03381362]
total_rewards_mean           611.3527232820311
total_rewards_std            249.1992507734989
total_rewards_max            1007.4081674115895
total_rewards_min            343.1265367386404
Number of train steps total  285000
Number of env steps total    1427000
Number of rollouts total     0
Train Time (s)               32.51055541075766
(Previous) Eval Time (s)     9.390579723287374
Sample Time (s)              19.95154942991212
Epoch Time (s)               61.852684563957155
Total Train Time (s)         17822.33329142118
Epoch                        284
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:59:46.511514 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #284 | Epoch Duration: 59.66030526161194
2020-01-11 04:59:46.511731 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #284 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.9789653
Z variance train             0.0033817687
KL Divergence                38.04664
KL Loss                      3.804664
QF Loss                      177.14743
VF Loss                      36.149586
Policy Loss                  -1056.377
Q Predictions Mean           1056.912
Q Predictions Std            301.09488
Q Predictions Max            1305.5074
Q Predictions Min            1.724926
V Predictions Mean           1057.9326
V Predictions Std            294.25424
V Predictions Max            1305.0894
V Predictions Min            -3.281066
Log Pis Mean                 0.1234802
Log Pis Std                  1.8624774
Log Pis Max                  11.211128
Log Pis Min                  -4.338257
Policy mu Mean               0.21796133
Policy mu Std                0.9406051
Policy mu Max                1.9509678
Policy mu Min                -3.2126582
Policy log std Mean          -0.45428053
Policy log std Std           0.16543706
Policy log std Max           -0.03902924
Policy log std Min           -1.639044
Z mean eval                  2.9243636
Z variance eval              0.0015398514
total_rewards                [1260.55267938 1253.5835365  1358.02267247  382.01380528  346.03332641
  537.06058161  732.90114483  389.70835655 1121.65047453  350.1839988 ]
total_rewards_mean           773.1710576366684
total_rewards_std            406.27681028798855
total_rewards_max            1358.0226724702688
total_rewards_min            346.03332641332884
Number of train steps total  286000
Number of env steps total    1432000
Number of rollouts total     0
Train Time (s)               32.728631182573736
(Previous) Eval Time (s)     7.197873599361628
Sample Time (s)              22.0398969091475
Epoch Time (s)               61.966401691082865
Total Train Time (s)         17885.834753729403
Epoch                        285
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:00:50.015999 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #285 | Epoch Duration: 63.50412321090698
2020-01-11 05:00:50.016175 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #285 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.9231918
Z variance train             0.0015390589
KL Divergence                37.965675
KL Loss                      3.7965677
QF Loss                      127.86671
VF Loss                      53.515827
Policy Loss                  -1018.7567
Q Predictions Mean           1019.4637
Q Predictions Std            332.5695
Q Predictions Max            1293.6237
Q Predictions Min            6.8888364
V Predictions Mean           1020.682
V Predictions Std            332.5381
V Predictions Max            1301.1953
V Predictions Min            6.2087436
Log Pis Mean                 -0.30487502
Log Pis Std                  1.7746329
Log Pis Max                  7.030822
Log Pis Min                  -4.9947596
Policy mu Mean               0.19324751
Policy mu Std                0.86845267
Policy mu Max                2.46042
Policy mu Min                -3.219438
Policy log std Mean          -0.42857575
Policy log std Std           0.15564105
Policy log std Max           0.0035963655
Policy log std Min           -1.0451224
Z mean eval                  2.7728393
Z variance eval              0.0065728626
total_rewards                [ 928.16708266 1167.85497223 1102.36778228 1114.5155612  1180.7642142
 1246.2429487   974.38293211 1549.00301529 1254.21213489 1222.37724711]
total_rewards_mean           1173.9887890675132
total_rewards_std            162.3744236485065
total_rewards_max            1549.0030152852955
total_rewards_min            928.1670826594857
Number of train steps total  287000
Number of env steps total    1437000
Number of rollouts total     0
Train Time (s)               32.59127787081525
(Previous) Eval Time (s)     8.735267660114914
Sample Time (s)              21.637046818621457
Epoch Time (s)               62.96359234955162
Total Train Time (s)         17951.991747142747
Epoch                        286
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:01:56.177654 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #286 | Epoch Duration: 66.16133141517639
2020-01-11 05:01:56.177882 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #286 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.6748302
Z variance train             0.007037456
KL Divergence                31.083092
KL Loss                      3.1083093
QF Loss                      318.67712
VF Loss                      70.69132
Policy Loss                  -984.1293
Q Predictions Mean           981.8354
Q Predictions Std            301.86624
Q Predictions Max            1226.813
Q Predictions Min            -1.5223453
V Predictions Mean           986.0426
V Predictions Std            296.39584
V Predictions Max            1224.4506
V Predictions Min            -3.78606
Log Pis Mean                 -0.15431508
Log Pis Std                  2.0339463
Log Pis Max                  10.8532715
Log Pis Min                  -5.4177446
Policy mu Mean               0.0018745326
Policy mu Std                0.9205156
Policy mu Max                2.807047
Policy mu Min                -3.727981
Policy log std Mean          -0.44924128
Policy log std Std           0.16136605
Policy log std Max           -0.11554672
Policy log std Min           -1.0595243
Z mean eval                  2.507356
Z variance eval              0.013313365
total_rewards                [ 958.77049789 1057.49669523 1158.91995246  992.5113601  1262.87717764
  976.17308602 1128.18618208 1215.04738986 1151.46271326 1846.77453836]
total_rewards_mean           1174.8219592909047
total_rewards_std            244.33736516587356
total_rewards_max            1846.7745383587983
total_rewards_min            958.7704978871599
Number of train steps total  288000
Number of env steps total    1442000
Number of rollouts total     0
Train Time (s)               32.869366283062845
(Previous) Eval Time (s)     11.932672528084368
Sample Time (s)              22.636696332134306
Epoch Time (s)               67.43873514328152
Total Train Time (s)         18019.48043584125
Epoch                        287
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:03:03.669222 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #287 | Epoch Duration: 67.49110984802246
2020-01-11 05:03:03.669528 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #287 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5267885
Z variance train             0.011193143
KL Divergence                27.916014
KL Loss                      2.7916014
QF Loss                      347.51132
VF Loss                      106.96687
Policy Loss                  -917.78094
Q Predictions Mean           920.69824
Q Predictions Std            334.4181
Q Predictions Max            1201.0238
Q Predictions Min            -8.297804
V Predictions Mean           914.29425
V Predictions Std            334.9682
V Predictions Max            1194.1538
V Predictions Min            -2.8305426
Log Pis Mean                 -0.3200507
Log Pis Std                  1.9216502
Log Pis Max                  8.910229
Log Pis Min                  -4.6172523
Policy mu Mean               0.037169088
Policy mu Std                0.8695447
Policy mu Max                1.8856856
Policy mu Min                -3.5325582
Policy log std Mean          -0.40344533
Policy log std Std           0.14968304
Policy log std Max           -0.07543704
Policy log std Min           -1.0369707
Z mean eval                  2.5843863
Z variance eval              0.015958045
total_rewards                [1332.70496286  957.37154011  936.67831739  913.04886325  846.820008
 1328.75871288  844.88529212 1268.0550009  1058.00183254  994.02980562]
total_rewards_mean           1048.0354335658953
total_rewards_std            182.17195117282938
total_rewards_max            1332.7049628565294
total_rewards_min            844.885292116184
Number of train steps total  289000
Number of env steps total    1447000
Number of rollouts total     0
Train Time (s)               32.425904023926705
(Previous) Eval Time (s)     11.984702843707055
Sample Time (s)              23.6449179276824
Epoch Time (s)               68.05552479531616
Total Train Time (s)         18085.978426929563
Epoch                        288
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:04:10.169105 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #288 | Epoch Duration: 66.49940013885498
2020-01-11 05:04:10.169274 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #288 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.6313996
Z variance train             0.015818935
KL Divergence                29.696926
KL Loss                      2.9696927
QF Loss                      259.67087
VF Loss                      120.71386
Policy Loss                  -959.2365
Q Predictions Mean           956.44226
Q Predictions Std            361.02902
Q Predictions Max            1263.4753
Q Predictions Min            0.27047306
V Predictions Mean           951.5657
V Predictions Std            359.33432
V Predictions Max            1252.5591
V Predictions Min            -0.65869576
Log Pis Mean                 -0.19435242
Log Pis Std                  1.9600413
Log Pis Max                  6.965539
Log Pis Min                  -5.373967
Policy mu Mean               -0.02766358
Policy mu Std                0.90244704
Policy mu Max                2.6204584
Policy mu Min                -2.9053924
Policy log std Mean          -0.43401513
Policy log std Std           0.15346704
Policy log std Max           -0.087090075
Policy log std Min           -1.089804
Z mean eval                  2.5942345
Z variance eval              0.013159273
total_rewards                [1084.69845187 1284.92610799 1757.0532594  1066.25091662 1953.92731479
 1198.74220048  993.04629247 1204.36875879 1302.26337411 1187.70459564]
total_rewards_mean           1303.298127215223
total_rewards_std            293.9157850252682
total_rewards_max            1953.9273147853585
total_rewards_min            993.0462924739244
Number of train steps total  290000
Number of env steps total    1452000
Number of rollouts total     0
Train Time (s)               32.338205753825605
(Previous) Eval Time (s)     10.428228789009154
Sample Time (s)              23.875937876291573
Epoch Time (s)               66.64237241912633
Total Train Time (s)         18154.632354329806
Epoch                        289
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:05:18.826892 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #289 | Epoch Duration: 68.6574776172638
2020-01-11 05:05:18.827104 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #289 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.610667
Z variance train             0.012565553
KL Divergence                29.014988
KL Loss                      2.9014988
QF Loss                      220.67719
VF Loss                      40.988255
Policy Loss                  -995.5723
Q Predictions Mean           992.83325
Q Predictions Std            339.13995
Q Predictions Max            1265.3057
Q Predictions Min            -1.0001707
V Predictions Mean           998.0226
V Predictions Std            339.29697
V Predictions Max            1264.3292
V Predictions Min            0.009510875
Log Pis Mean                 -0.4689691
Log Pis Std                  1.9716253
Log Pis Max                  11.719895
Log Pis Min                  -5.140933
Policy mu Mean               -0.012737371
Policy mu Std                0.8593742
Policy mu Max                2.462491
Policy mu Min                -3.6303883
Policy log std Mean          -0.3992219
Policy log std Std           0.13381374
Policy log std Max           -0.099788636
Policy log std Min           -1.0214427
Z mean eval                  2.5549893
Z variance eval              0.011832965
total_rewards                [1087.93254965  922.2122953  1023.66725909  916.95127101 1357.46150429
 1013.11676011  911.12187484 1038.1151845   870.43155326 1238.56623508]
total_rewards_mean           1037.957648713625
total_rewards_std            147.59307424454914
total_rewards_max            1357.461504290256
total_rewards_min            870.4315532617697
Number of train steps total  291000
Number of env steps total    1457000
Number of rollouts total     0
Train Time (s)               32.481805575080216
(Previous) Eval Time (s)     12.443002902902663
Sample Time (s)              23.740130546037108
Epoch Time (s)               68.66493902401999
Total Train Time (s)         18220.123590415344
Epoch                        290
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:06:24.322077 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #290 | Epoch Duration: 65.49460506439209
2020-01-11 05:06:24.322431 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #290 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5489962
Z variance train             0.011944316
KL Divergence                28.702572
KL Loss                      2.8702571
QF Loss                      804.7157
VF Loss                      58.159447
Policy Loss                  -995.3643
Q Predictions Mean           996.70105
Q Predictions Std            336.9461
Q Predictions Max            1276.466
Q Predictions Min            4.9037066
V Predictions Mean           997.6994
V Predictions Std            339.81516
V Predictions Max            1283.7031
V Predictions Min            2.2821975
Log Pis Mean                 -0.41138148
Log Pis Std                  1.9739196
Log Pis Max                  7.7628374
Log Pis Min                  -4.8262935
Policy mu Mean               -0.010749782
Policy mu Std                0.8809263
Policy mu Max                2.19321
Policy mu Min                -3.0258298
Policy log std Mean          -0.41792282
Policy log std Std           0.14757954
Policy log std Max           -0.13325053
Policy log std Min           -1.0000085
Z mean eval                  2.2646897
Z variance eval              0.013663283
total_rewards                [ 921.70142989 1202.26542168 1003.61138595  988.20477609  999.85475047
 1015.60755374  826.37844851  836.48721472 1006.97196263  999.16820321]
total_rewards_mean           980.0251146885719
total_rewards_std            100.18880523433127
total_rewards_max            1202.265421678668
total_rewards_min            826.3784485131315
Number of train steps total  292000
Number of env steps total    1462000
Number of rollouts total     0
Train Time (s)               33.10695054894313
(Previous) Eval Time (s)     9.272437285166234
Sample Time (s)              22.3191363918595
Epoch Time (s)               64.69852422596887
Total Train Time (s)         18284.65528974915
Epoch                        291
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:07:28.856627 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #291 | Epoch Duration: 64.5339424610138
2020-01-11 05:07:28.856889 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #291 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.267451
Z variance train             0.014100017
KL Divergence                24.177837
KL Loss                      2.4177837
QF Loss                      201.15332
VF Loss                      30.700163
Policy Loss                  -879.8337
Q Predictions Mean           878.6481
Q Predictions Std            320.92343
Q Predictions Max            1175.264
Q Predictions Min            2.9754167
V Predictions Mean           879.68945
V Predictions Std            321.4622
V Predictions Max            1166.8171
V Predictions Min            -6.293554
Log Pis Mean                 -0.5670205
Log Pis Std                  1.7651278
Log Pis Max                  7.5455403
Log Pis Min                  -4.7470193
Policy mu Mean               -0.01439732
Policy mu Std                0.8370791
Policy mu Max                2.630109
Policy mu Min                -2.38027
Policy log std Mean          -0.3935512
Policy log std Std           0.14008668
Policy log std Max           -0.12828924
Policy log std Min           -0.910447
Z mean eval                  2.2935047
Z variance eval              0.013949578
total_rewards                [ 936.5072651   919.02940577 1006.08968511 1168.09826415 1077.35560976
  844.66879673  915.59517849 1152.94930994  853.73088676  969.14848908]
total_rewards_mean           984.3172890887734
total_rewards_std            109.26939579095047
total_rewards_max            1168.0982641519415
total_rewards_min            844.6687967307993
Number of train steps total  293000
Number of env steps total    1467000
Number of rollouts total     0
Train Time (s)               32.6501916279085
(Previous) Eval Time (s)     9.107493318617344
Sample Time (s)              22.535429851617664
Epoch Time (s)               64.2931147981435
Total Train Time (s)         18349.61210943805
Epoch                        292
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:08:33.816007 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #292 | Epoch Duration: 64.95887064933777
2020-01-11 05:08:33.816207 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #292 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4082055
Z variance train             0.01205233
KL Divergence                26.82579
KL Loss                      2.682579
QF Loss                      151.02197
VF Loss                      62.720722
Policy Loss                  -1003.0908
Q Predictions Mean           1000.65186
Q Predictions Std            362.92673
Q Predictions Max            1304.2666
Q Predictions Min            0.08562261
V Predictions Mean           998.85986
V Predictions Std            361.55713
V Predictions Max            1305.3512
V Predictions Min            3.5964637
Log Pis Mean                 -0.41938296
Log Pis Std                  1.8095385
Log Pis Max                  5.756171
Log Pis Min                  -7.262374
Policy mu Mean               0.021694789
Policy mu Std                0.8445509
Policy mu Max                2.0719042
Policy mu Min                -2.8568342
Policy log std Mean          -0.4127023
Policy log std Std           0.15734755
Policy log std Max           -0.06530887
Policy log std Min           -1.1411774
Z mean eval                  2.404141
Z variance eval              0.012506561
total_rewards                [ 244.33689057 1152.80735686  245.52197242 1105.92265441  956.289167
  909.9097058   996.38555257  992.77328718 1182.4265514  1127.94878815]
total_rewards_mean           891.4321926358537
total_rewards_std            334.1715674334102
total_rewards_max            1182.426551401379
total_rewards_min            244.33689056742136
Number of train steps total  294000
Number of env steps total    1472000
Number of rollouts total     0
Train Time (s)               32.23664979962632
(Previous) Eval Time (s)     9.772936031222343
Sample Time (s)              22.33948668697849
Epoch Time (s)               64.34907251782715
Total Train Time (s)         18412.34035130171
Epoch                        293
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:09:36.547337 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #293 | Epoch Duration: 62.73100566864014
2020-01-11 05:09:36.547540 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #293 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4031997
Z variance train             0.012522982
KL Divergence                25.945044
KL Loss                      2.5945044
QF Loss                      240.52835
VF Loss                      84.32837
Policy Loss                  -1015.40784
Q Predictions Mean           1011.8403
Q Predictions Std            371.86792
Q Predictions Max            1347.3582
Q Predictions Min            -3.0313513
V Predictions Mean           1016.021
V Predictions Std            373.39856
V Predictions Max            1344.0828
V Predictions Min            -2.034576
Log Pis Mean                 -0.25240058
Log Pis Std                  2.1083455
Log Pis Max                  7.690113
Log Pis Min                  -6.115632
Policy mu Mean               0.021854976
Policy mu Std                0.8924963
Policy mu Max                2.694589
Policy mu Min                -2.9097466
Policy log std Mean          -0.4136562
Policy log std Std           0.14510259
Policy log std Max           -0.120566696
Policy log std Min           -1.0067581
Z mean eval                  2.3464575
Z variance eval              0.020353924
total_rewards                [1012.03494985  844.72447502  889.58138475  227.16661406  905.42178687
  928.14431679  260.04070357  925.54897891  209.94240492  913.82198523]
total_rewards_mean           711.6427599981515
total_rewards_std            316.39037743869204
total_rewards_max            1012.0349498536583
total_rewards_min            209.94240492423285
Number of train steps total  295000
Number of env steps total    1477000
Number of rollouts total     0
Train Time (s)               32.72031470015645
(Previous) Eval Time (s)     8.154519556090236
Sample Time (s)              23.95807882025838
Epoch Time (s)               64.83291307650506
Total Train Time (s)         18475.54540455155
Epoch                        294
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:10:39.754283 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #294 | Epoch Duration: 63.206626176834106
2020-01-11 05:10:39.754411 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #294 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3465862
Z variance train             0.020327192
KL Divergence                24.661663
KL Loss                      2.4661663
QF Loss                      109.593994
VF Loss                      135.8438
Policy Loss                  -1076.3639
Q Predictions Mean           1073.9333
Q Predictions Std            311.46365
Q Predictions Max            1367.3378
Q Predictions Min            3.7605102
V Predictions Mean           1077.2981
V Predictions Std            307.88336
V Predictions Max            1370.7523
V Predictions Min            0.7804406
Log Pis Mean                 -0.27821943
Log Pis Std                  2.055336
Log Pis Max                  8.715641
Log Pis Min                  -5.327854
Policy mu Mean               -0.05623595
Policy mu Std                0.9122193
Policy mu Max                2.3619761
Policy mu Min                -3.2583027
Policy log std Mean          -0.40863934
Policy log std Std           0.15089864
Policy log std Max           -0.019966379
Policy log std Min           -1.5995083
Z mean eval                  2.2978902
Z variance eval              0.018505564
total_rewards                [975.32445647 864.71391562 868.52764983 960.10119297 860.47246647
 981.44425404 813.0383947  795.62812079 743.5595324  857.1192419 ]
total_rewards_mean           871.9929225179139
total_rewards_std            75.26045544009611
total_rewards_max            981.4442540386062
total_rewards_min            743.5595323990792
Number of train steps total  296000
Number of env steps total    1482000
Number of rollouts total     0
Train Time (s)               32.2860362958163
(Previous) Eval Time (s)     6.527849034871906
Sample Time (s)              21.573840751312673
Epoch Time (s)               60.38772608200088
Total Train Time (s)         18537.781211432535
Epoch                        295
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:11:41.994238 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #295 | Epoch Duration: 62.239701986312866
2020-01-11 05:11:41.994438 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #295 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2964275
Z variance train             0.01850868
KL Divergence                24.153942
KL Loss                      2.4153943
QF Loss                      498.28073
VF Loss                      66.17276
Policy Loss                  -989.89734
Q Predictions Mean           986.5068
Q Predictions Std            373.00415
Q Predictions Max            1343.6702
Q Predictions Min            3.68849
V Predictions Mean           989.2384
V Predictions Std            372.8489
V Predictions Max            1354.7354
V Predictions Min            -3.9093318
Log Pis Mean                 -0.06221246
Log Pis Std                  1.9448756
Log Pis Max                  6.632607
Log Pis Min                  -4.505627
Policy mu Mean               0.119942844
Policy mu Std                0.938491
Policy mu Max                2.8608375
Policy mu Min                -2.6089509
Policy log std Mean          -0.41504225
Policy log std Std           0.15603274
Policy log std Max           0.10780758
Policy log std Min           -1.4614342
Z mean eval                  2.2399201
Z variance eval              0.02415345
total_rewards                [ 796.06651784  759.70106575  658.80033296  690.72145772  741.55918517
  726.44176581  681.44914756  682.80173504  712.56155954 1006.39442393]
total_rewards_mean           745.6497191309412
total_rewards_std            95.30955436572279
total_rewards_max            1006.3944239318989
total_rewards_min            658.8003329563251
Number of train steps total  297000
Number of env steps total    1487000
Number of rollouts total     0
Train Time (s)               32.08231252990663
(Previous) Eval Time (s)     8.379509577061981
Sample Time (s)              23.811975526157767
Epoch Time (s)               64.27379763312638
Total Train Time (s)         18600.649255814962
Epoch                        296
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:12:44.865787 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #296 | Epoch Duration: 62.87120342254639
2020-01-11 05:12:44.865983 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #296 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2389436
Z variance train             0.024306465
KL Divergence                22.785381
KL Loss                      2.2785382
QF Loss                      258.12567
VF Loss                      59.551617
Policy Loss                  -1019.6386
Q Predictions Mean           1015.1391
Q Predictions Std            326.98746
Q Predictions Max            1331.0547
Q Predictions Min            0.37745872
V Predictions Mean           1016.4069
V Predictions Std            326.36554
V Predictions Max            1342.2067
V Predictions Min            4.4526873
Log Pis Mean                 0.015162993
Log Pis Std                  2.092545
Log Pis Max                  8.182384
Log Pis Min                  -3.9565248
Policy mu Mean               0.1832313
Policy mu Std                0.9397362
Policy mu Max                2.6580122
Policy mu Min                -2.6803281
Policy log std Mean          -0.42748007
Policy log std Std           0.13646598
Policy log std Max           0.053819984
Policy log std Min           -1.1793581
Z mean eval                  2.1612742
Z variance eval              0.03949279
total_rewards                [1006.72670899  696.9075772   730.09644497  690.59667593  708.83438455
  675.11209091  654.11769488  695.04733784  713.61727873  701.3138255 ]
total_rewards_mean           727.2370019491423
total_rewards_std            95.22648707625453
total_rewards_max            1006.7267089876855
total_rewards_min            654.1176948819609
Number of train steps total  298000
Number of env steps total    1492000
Number of rollouts total     0
Train Time (s)               32.7558073583059
(Previous) Eval Time (s)     6.976593122817576
Sample Time (s)              23.268352398183197
Epoch Time (s)               63.000752879306674
Total Train Time (s)         18663.34899458615
Epoch                        297
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:13:47.569041 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #297 | Epoch Duration: 62.702913761138916
2020-01-11 05:13:47.569227 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #297 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1603534
Z variance train             0.039553586
KL Divergence                21.341
KL Loss                      2.1341
QF Loss                      252.16711
VF Loss                      71.37209
Policy Loss                  -1015.93066
Q Predictions Mean           1014.5918
Q Predictions Std            346.06458
Q Predictions Max            1358.2019
Q Predictions Min            1.5791057
V Predictions Mean           1017.24475
V Predictions Std            347.10858
V Predictions Max            1359.0793
V Predictions Min            1.6225164
Log Pis Mean                 -0.07672472
Log Pis Std                  2.0602283
Log Pis Max                  9.2367935
Log Pis Min                  -5.2078156
Policy mu Mean               0.10615656
Policy mu Std                0.9271644
Policy mu Max                2.634233
Policy mu Min                -2.9972563
Policy log std Mean          -0.41981778
Policy log std Std           0.1442334
Policy log std Max           -0.14925338
Policy log std Min           -0.943693
Z mean eval                  2.191613
Z variance eval              0.020174628
total_rewards                [799.49080966 755.96645329 880.70434461 860.43368444 813.72888964
 782.21918982 835.87946043 729.40718364 770.18051976 676.24015201]
total_rewards_mean           790.4250687301119
total_rewards_std            58.45413867042743
total_rewards_max            880.7043446079488
total_rewards_min            676.2401520057755
Number of train steps total  299000
Number of env steps total    1497000
Number of rollouts total     0
Train Time (s)               32.93324295524508
(Previous) Eval Time (s)     6.678428725339472
Sample Time (s)              23.642157705500722
Epoch Time (s)               63.25382938608527
Total Train Time (s)         18727.059000554495
Epoch                        298
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:14:51.282686 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #298 | Epoch Duration: 63.713310956954956
2020-01-11 05:14:51.282901 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #298 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.189106
Z variance train             0.020213952
KL Divergence                22.298847
KL Loss                      2.2298849
QF Loss                      210.58228
VF Loss                      46.028984
Policy Loss                  -987.109
Q Predictions Mean           985.63074
Q Predictions Std            387.71478
Q Predictions Max            1374.4026
Q Predictions Min            -1.4195633
V Predictions Mean           989.98376
V Predictions Std            388.62238
V Predictions Max            1380.8984
V Predictions Min            1.2174655
Log Pis Mean                 -0.18154398
Log Pis Std                  2.0668406
Log Pis Max                  8.6581745
Log Pis Min                  -4.697648
Policy mu Mean               0.15459812
Policy mu Std                0.9289997
Policy mu Max                2.5907092
Policy mu Min                -2.9164665
Policy log std Mean          -0.4182057
Policy log std Std           0.14895752
Policy log std Max           -0.1035483
Policy log std Min           -1.405204
Z mean eval                  2.173111
Z variance eval              0.015572032
total_rewards                [692.06986831 664.7588514  787.17041298 731.27929781 683.56983056
 629.62227139 667.00238153 696.46328827 733.17254182 585.74277811]
total_rewards_mean           687.0851522176395
total_rewards_std            53.56624363655592
total_rewards_max            787.1704129761637
total_rewards_min            585.7427781101538
Number of train steps total  300000
Number of env steps total    1502000
Number of rollouts total     0
Train Time (s)               32.706282613798976
(Previous) Eval Time (s)     7.137537057045847
Sample Time (s)              23.165383752435446
Epoch Time (s)               63.00920342328027
Total Train Time (s)         18787.489416672383
Epoch                        299
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:15:51.716400 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #299 | Epoch Duration: 60.43333840370178
2020-01-11 05:15:51.716586 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #299 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1697822
Z variance train             0.015579224
KL Divergence                22.612019
KL Loss                      2.2612019
QF Loss                      142.69263
VF Loss                      93.193344
Policy Loss                  -1037.7305
Q Predictions Mean           1037.3754
Q Predictions Std            348.46555
Q Predictions Max            1386.2379
Q Predictions Min            0.4146137
V Predictions Mean           1038.113
V Predictions Std            347.96286
V Predictions Max            1387.2264
V Predictions Min            1.3601838
Log Pis Mean                 0.16941488
Log Pis Std                  2.0056853
Log Pis Max                  7.35583
Log Pis Min                  -5.1005425
Policy mu Mean               0.28545037
Policy mu Std                0.9352441
Policy mu Max                2.846672
Policy mu Min                -2.589038
Policy log std Mean          -0.46186534
Policy log std Std           0.15066628
Policy log std Max           -0.13395019
Policy log std Min           -1.2306855
Z mean eval                  2.1390865
Z variance eval              0.012766844
total_rewards                [829.37678015 772.50721723 758.11940671 710.98212402 721.16533526
 829.41304225 799.25634293 800.97776579 655.44665567 780.49996898]
total_rewards_mean           765.7744638999368
total_rewards_std            52.85887104202836
total_rewards_max            829.4130422538177
total_rewards_min            655.446655670975
Number of train steps total  301000
Number of env steps total    1507000
Number of rollouts total     0
Train Time (s)               33.04763901280239
(Previous) Eval Time (s)     4.561336940154433
Sample Time (s)              22.870284335222095
Epoch Time (s)               60.47926028817892
Total Train Time (s)         18850.08259785315
Epoch                        300
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:16:54.312817 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #300 | Epoch Duration: 62.59609341621399
2020-01-11 05:16:54.312999 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #300 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1390965
Z variance train             0.012785727
KL Divergence                22.530758
KL Loss                      2.2530758
QF Loss                      150.92438
VF Loss                      42.779945
Policy Loss                  -978.2889
Q Predictions Mean           974.63446
Q Predictions Std            388.74927
Q Predictions Max            1357.4926
Q Predictions Min            -5.0904465
V Predictions Mean           977.33026
V Predictions Std            389.19672
V Predictions Max            1376.5409
V Predictions Min            3.1377692
Log Pis Mean                 -0.18227737
Log Pis Std                  1.938218
Log Pis Max                  6.677473
Log Pis Min                  -4.339033
Policy mu Mean               0.20230253
Policy mu Std                0.8984362
Policy mu Max                2.7576823
Policy mu Min                -2.6033165
Policy log std Mean          -0.43649164
Policy log std Std           0.14213441
Policy log std Max           -0.08141188
Policy log std Min           -1.0091399
Z mean eval                  2.1587977
Z variance eval              0.019764934
total_rewards                [1172.71912895  869.99671692  917.64851856  741.02674776  891.56651433
  672.97873044  849.78375155  791.80108563  807.49070121  677.19993948]
total_rewards_mean           839.2211834833967
total_rewards_std            137.0968761780372
total_rewards_max            1172.719128953902
total_rewards_min            672.9787304401435
Number of train steps total  302000
Number of env steps total    1512000
Number of rollouts total     0
Train Time (s)               32.237820284906775
(Previous) Eval Time (s)     6.677820383105427
Sample Time (s)              23.41437038127333
Epoch Time (s)               62.33001104928553
Total Train Time (s)         18913.641260891687
Epoch                        301
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:17:57.874602 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #301 | Epoch Duration: 63.561463832855225
2020-01-11 05:17:57.874783 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #301 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1611638
Z variance train             0.019711575
KL Divergence                22.1272
KL Loss                      2.21272
QF Loss                      226.27693
VF Loss                      65.901146
Policy Loss                  -1075.3629
Q Predictions Mean           1073.8286
Q Predictions Std            385.30484
Q Predictions Max            1427.7623
Q Predictions Min            -26.76051
V Predictions Mean           1074.6317
V Predictions Std            383.2308
V Predictions Max            1425.0564
V Predictions Min            -5.4957495
Log Pis Mean                 -0.2603246
Log Pis Std                  2.1004272
Log Pis Max                  8.14384
Log Pis Min                  -4.9570236
Policy mu Mean               0.09964857
Policy mu Std                0.91234094
Policy mu Max                2.1080418
Policy mu Min                -2.8442316
Policy log std Mean          -0.4607751
Policy log std Std           0.14624633
Policy log std Max           -0.124449655
Policy log std Min           -1.2619028
Z mean eval                  2.0962572
Z variance eval              0.013301912
total_rewards                [810.69587068 961.03389653 852.20309264 868.53100216 743.83887714
 817.11246378 965.40332614 925.86314321 826.0374194  883.89789773]
total_rewards_mean           865.4616989417976
total_rewards_std            67.06649092196288
total_rewards_max            965.4033261447745
total_rewards_min            743.8388771368147
Number of train steps total  303000
Number of env steps total    1517000
Number of rollouts total     0
Train Time (s)               32.64601009013131
(Previous) Eval Time (s)     7.908934727776796
Sample Time (s)              23.126164087560028
Epoch Time (s)               63.681108905468136
Total Train Time (s)         18977.397484149784
Epoch                        302
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:19:01.634126 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #302 | Epoch Duration: 63.75920653343201
2020-01-11 05:19:01.634308 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #302 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1008017
Z variance train             0.013335313
KL Divergence                21.830166
KL Loss                      2.1830165
QF Loss                      109.9144
VF Loss                      82.57806
Policy Loss                  -1040.968
Q Predictions Mean           1039.0409
Q Predictions Std            368.47427
Q Predictions Max            1387.455
Q Predictions Min            2.7135558
V Predictions Mean           1034.9592
V Predictions Std            365.77005
V Predictions Max            1380.6051
V Predictions Min            2.4781523
Log Pis Mean                 -0.24866699
Log Pis Std                  2.0290987
Log Pis Max                  7.5870514
Log Pis Min                  -4.815896
Policy mu Mean               0.23649687
Policy mu Std                0.8886512
Policy mu Max                2.3203664
Policy mu Min                -2.7626798
Policy log std Mean          -0.4507105
Policy log std Std           0.14307782
Policy log std Max           -0.1433205
Policy log std Min           -1.1376816
Z mean eval                  2.0841715
Z variance eval              0.020223016
total_rewards                [ 836.71967655  897.90691003 1149.76282331  841.0085601   728.6622633
 1349.72106479  764.69941734  931.69404745  812.16240964  819.29380617]
total_rewards_mean           913.1630978693953
total_rewards_std            182.5603777512368
total_rewards_max            1349.721064793013
total_rewards_min            728.662263299136
Number of train steps total  304000
Number of env steps total    1522000
Number of rollouts total     0
Train Time (s)               33.625358927063644
(Previous) Eval Time (s)     7.986724880989641
Sample Time (s)              23.377144975587726
Epoch Time (s)               64.98922878364101
Total Train Time (s)         19042.872320039198
Epoch                        303
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:20:07.113042 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #303 | Epoch Duration: 65.4785852432251
2020-01-11 05:20:07.113290 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #303 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.083091
Z variance train             0.020175604
KL Divergence                21.643286
KL Loss                      2.1643286
QF Loss                      152.5741
VF Loss                      127.18746
Policy Loss                  -1005.4741
Q Predictions Mean           1002.8428
Q Predictions Std            394.39328
Q Predictions Max            1366.1611
Q Predictions Min            -0.25372502
V Predictions Mean           1011.0273
V Predictions Std            392.74448
V Predictions Max            1378.8717
V Predictions Min            2.9528697
Log Pis Mean                 -0.20845932
Log Pis Std                  2.0193932
Log Pis Max                  6.1891074
Log Pis Min                  -5.357729
Policy mu Mean               0.1435047
Policy mu Std                0.88555527
Policy mu Max                2.1949055
Policy mu Min                -3.0007753
Policy log std Mean          -0.420005
Policy log std Std           0.1410396
Policy log std Max           -0.055506438
Policy log std Min           -1.3803846
Z mean eval                  2.0795884
Z variance eval              0.014654261
total_rewards                [1341.47139611  872.00661698  775.98954365  837.81111898  925.26195475
  855.28514313  929.3927608   891.55732948  898.78629764 1995.85417611]
total_rewards_mean           1032.3416337641206
total_rewards_std            352.73988139203647
total_rewards_max            1995.8541761122501
total_rewards_min            775.9895436511821
Number of train steps total  305000
Number of env steps total    1527000
Number of rollouts total     0
Train Time (s)               34.51858790870756
(Previous) Eval Time (s)     8.475743995048106
Sample Time (s)              24.0005812542513
Epoch Time (s)               66.99491315800697
Total Train Time (s)         19111.062483399175
Epoch                        304
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:21:15.307305 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #304 | Epoch Duration: 68.19384360313416
2020-01-11 05:21:15.307546 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #304 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0770066
Z variance train             0.0146648185
KL Divergence                22.201496
KL Loss                      2.2201498
QF Loss                      212.81485
VF Loss                      78.36639
Policy Loss                  -1072.6678
Q Predictions Mean           1072.4934
Q Predictions Std            335.31934
Q Predictions Max            1396.4369
Q Predictions Min            5.5881944
V Predictions Mean           1076.6588
V Predictions Std            335.8185
V Predictions Max            1402.6204
V Predictions Min            5.708309
Log Pis Mean                 -0.11450486
Log Pis Std                  2.063694
Log Pis Max                  6.5334406
Log Pis Min                  -5.9769087
Policy mu Mean               0.10544589
Policy mu Std                0.92533666
Policy mu Max                2.5425794
Policy mu Min                -2.9936032
Policy log std Mean          -0.45633757
Policy log std Std           0.13810453
Policy log std Max           -0.13334586
Policy log std Min           -1.1946692
Z mean eval                  2.0453792
Z variance eval              0.015771095
total_rewards                [ 872.98291956 2005.69952946 1299.091634    966.25455069  741.66052037
  820.41926699  686.51288069  843.57961537  932.72957289 1386.88125283]
total_rewards_mean           1055.5811742852807
total_rewards_std            382.5178721399524
total_rewards_max            2005.6995294583412
total_rewards_min            686.5128806923514
Number of train steps total  306000
Number of env steps total    1532000
Number of rollouts total     0
Train Time (s)               35.317736654076725
(Previous) Eval Time (s)     9.674283874221146
Sample Time (s)              23.539462660439312
Epoch Time (s)               68.53148318873718
Total Train Time (s)         19179.45526559651
Epoch                        305
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:22:23.703423 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #305 | Epoch Duration: 68.39572882652283
2020-01-11 05:22:23.703616 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #305 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.04487
Z variance train             0.015765516
KL Divergence                21.593775
KL Loss                      2.1593776
QF Loss                      130.74084
VF Loss                      28.963387
Policy Loss                  -1070.3953
Q Predictions Mean           1072.0085
Q Predictions Std            383.16556
Q Predictions Max            1428.5181
Q Predictions Min            0.99638534
V Predictions Mean           1071.1381
V Predictions Std            383.0212
V Predictions Max            1424.9022
V Predictions Min            2.0013933
Log Pis Mean                 -0.2177048
Log Pis Std                  1.8864424
Log Pis Max                  6.423112
Log Pis Min                  -5.828253
Policy mu Mean               0.2840099
Policy mu Std                0.85410976
Policy mu Max                2.4703565
Policy mu Min                -2.8933852
Policy log std Mean          -0.4535307
Policy log std Std           0.14209005
Policy log std Max           -0.10497016
Policy log std Min           -0.9882717
Z mean eval                  2.0122542
Z variance eval              0.017041873
total_rewards                [ 761.50304588 1721.18155668  741.05525631  749.96532192  734.28085791
 1019.8397557   788.48764734  751.4825363   753.95368593  744.71652299]
total_rewards_mean           876.6466186963484
total_rewards_std            292.84806885490394
total_rewards_max            1721.1815566757177
total_rewards_min            734.2808579073486
Number of train steps total  307000
Number of env steps total    1537000
Number of rollouts total     0
Train Time (s)               35.71868700813502
(Previous) Eval Time (s)     9.538163817953318
Sample Time (s)              25.01502265781164
Epoch Time (s)               70.27187348389998
Total Train Time (s)         19249.016013438348
Epoch                        306
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:23:33.267554 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #306 | Epoch Duration: 69.56380152702332
2020-01-11 05:23:33.267736 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #306 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0145988
Z variance train             0.017078202
KL Divergence                20.659323
KL Loss                      2.0659323
QF Loss                      119.911316
VF Loss                      73.02709
Policy Loss                  -1074.3917
Q Predictions Mean           1070.678
Q Predictions Std            393.56076
Q Predictions Max            1411.721
Q Predictions Min            -0.11012083
V Predictions Mean           1069.4271
V Predictions Std            393.82166
V Predictions Max            1425.2029
V Predictions Min            -0.020374775
Log Pis Mean                 -0.09143976
Log Pis Std                  1.9281309
Log Pis Max                  6.6809864
Log Pis Min                  -5.7324047
Policy mu Mean               0.105703466
Policy mu Std                0.9478968
Policy mu Max                2.6458879
Policy mu Min                -2.8552976
Policy log std Mean          -0.4637978
Policy log std Std           0.15349337
Policy log std Max           -0.049132064
Policy log std Min           -0.9636844
Z mean eval                  2.0022266
Z variance eval              0.018846044
total_rewards                [ 797.78868211  746.3054177   706.20876598  787.46278265  750.99144579
  821.75876767 1042.78069809  754.19924617  753.24078188  739.17037254]
total_rewards_mean           789.9906960595579
total_rewards_std            89.80102486553122
total_rewards_max            1042.7806980921002
total_rewards_min            706.2087659762323
Number of train steps total  308000
Number of env steps total    1542000
Number of rollouts total     0
Train Time (s)               34.636622737161815
(Previous) Eval Time (s)     8.829698737710714
Sample Time (s)              24.085935504175723
Epoch Time (s)               67.55225697904825
Total Train Time (s)         19315.362979666796
Epoch                        307
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:24:39.619174 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #307 | Epoch Duration: 66.35128331184387
2020-01-11 05:24:39.619442 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #307 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9977468
Z variance train             0.018811386
KL Divergence                20.101044
KL Loss                      2.0101044
QF Loss                      146.5818
VF Loss                      95.12597
Policy Loss                  -1096.1967
Q Predictions Mean           1097.3566
Q Predictions Std            416.72363
Q Predictions Max            1443.486
Q Predictions Min            0.08309218
V Predictions Mean           1102.3164
V Predictions Std            418.82047
V Predictions Max            1457.2263
V Predictions Min            0.6189802
Log Pis Mean                 -0.043536223
Log Pis Std                  1.9231826
Log Pis Max                  8.294214
Log Pis Min                  -4.287535
Policy mu Mean               0.10151148
Policy mu Std                0.9468396
Policy mu Max                2.7245078
Policy mu Min                -2.7245405
Policy log std Mean          -0.45063904
Policy log std Std           0.15546125
Policy log std Max           -0.113137946
Policy log std Min           -0.9054526
Z mean eval                  1.9686205
Z variance eval              0.022355082
total_rewards                [ 738.69582456 1037.64503956 1021.70726859  997.17235834  763.29268364
  780.93773545  802.42451118  839.97862422 1001.59463045 1321.39046157]
total_rewards_mean           930.4839137564534
total_rewards_std            171.40807308810744
total_rewards_max            1321.3904615674412
total_rewards_min            738.6958245557983
Number of train steps total  309000
Number of env steps total    1547000
Number of rollouts total     0
Train Time (s)               34.95273442706093
(Previous) Eval Time (s)     7.628328334074467
Sample Time (s)              24.100395478773862
Epoch Time (s)               66.68145823990926
Total Train Time (s)         19383.008654777892
Epoch                        308
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:25:47.267407 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #308 | Epoch Duration: 67.64779758453369
2020-01-11 05:25:47.267589 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #308 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9686339
Z variance train             0.02232663
KL Divergence                19.551392
KL Loss                      1.9551392
QF Loss                      101.34958
VF Loss                      102.8499
Policy Loss                  -1070.1428
Q Predictions Mean           1070.7715
Q Predictions Std            410.49234
Q Predictions Max            1425.7731
Q Predictions Min            6.842884
V Predictions Mean           1068.071
V Predictions Std            410.69736
V Predictions Max            1438.9128
V Predictions Min            0.88763565
Log Pis Mean                 -0.27134672
Log Pis Std                  1.9832183
Log Pis Max                  6.636053
Log Pis Min                  -4.4676304
Policy mu Mean               0.11312851
Policy mu Std                0.8930703
Policy mu Max                2.5623865
Policy mu Min                -3.0041792
Policy log std Mean          -0.42893848
Policy log std Std           0.17184757
Policy log std Max           -0.04913202
Policy log std Min           -1.2136352
Z mean eval                  1.9518852
Z variance eval              0.016959328
total_rewards                [ 826.36322324  976.97228447  779.66539191 1081.38047953 1305.23477529
  803.95667465  823.64506141  906.71385235 1271.39721446 1013.36083613]
total_rewards_mean           978.868979343905
total_rewards_std            180.72756034712032
total_rewards_max            1305.2347752942655
total_rewards_min            779.6653919123015
Number of train steps total  310000
Number of env steps total    1552000
Number of rollouts total     0
Train Time (s)               35.24090714100748
(Previous) Eval Time (s)     8.59431963134557
Sample Time (s)              24.82575329300016
Epoch Time (s)               68.66098006535321
Total Train Time (s)         19451.983322257176
Epoch                        309
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:26:56.245559 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #309 | Epoch Duration: 68.9778368473053
2020-01-11 05:26:56.245735 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #309 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9481428
Z variance train             0.01697075
KL Divergence                20.197634
KL Loss                      2.0197635
QF Loss                      166.20428
VF Loss                      82.060844
Policy Loss                  -1090.7666
Q Predictions Mean           1091.8672
Q Predictions Std            363.6638
Q Predictions Max            1401.558
Q Predictions Min            -5.413406
V Predictions Mean           1095.1396
V Predictions Std            363.1244
V Predictions Max            1407.7152
V Predictions Min            2.7619922
Log Pis Mean                 -0.07695139
Log Pis Std                  2.403163
Log Pis Max                  16.309048
Log Pis Min                  -4.624259
Policy mu Mean               0.1227979
Policy mu Std                0.980304
Policy mu Max                3.4317696
Policy mu Min                -3.7984803
Policy log std Mean          -0.45314303
Policy log std Std           0.1475215
Policy log std Max           0.09333062
Policy log std Min           -1.0519454
Z mean eval                  1.9327234
Z variance eval              0.012858527
total_rewards                [776.86373609 781.84116825 763.95751584 754.81226541 772.97968134
 750.78965821 765.40990563 996.32826415 773.38256365 757.83874575]
total_rewards_mean           789.4203504311545
total_rewards_std            69.61738907729242
total_rewards_max            996.3282641469667
total_rewards_min            750.7896582064697
Number of train steps total  311000
Number of env steps total    1557000
Number of rollouts total     0
Train Time (s)               34.398003227077425
(Previous) Eval Time (s)     8.910827514715493
Sample Time (s)              23.750524670816958
Epoch Time (s)               67.05935541260988
Total Train Time (s)         19517.85375353601
Epoch                        310
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:28:02.121691 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #310 | Epoch Duration: 65.87576651573181
2020-01-11 05:28:02.122076 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #310 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9356763
Z variance train             0.012829076
KL Divergence                21.414059
KL Loss                      2.1414058
QF Loss                      127.137024
VF Loss                      104.96304
Policy Loss                  -1123.811
Q Predictions Mean           1123.3167
Q Predictions Std            385.6993
Q Predictions Max            1467.424
Q Predictions Min            6.119239
V Predictions Mean           1123.9138
V Predictions Std            387.56628
V Predictions Max            1462.2954
V Predictions Min            -0.52357507
Log Pis Mean                 -0.03282083
Log Pis Std                  2.113306
Log Pis Max                  8.141229
Log Pis Min                  -4.125712
Policy mu Mean               -0.019716999
Policy mu Std                0.94816333
Policy mu Max                2.228557
Policy mu Min                -2.9034421
Policy log std Mean          -0.4434577
Policy log std Std           0.15655954
Policy log std Max           -0.023406446
Policy log std Min           -1.2035997
Z mean eval                  1.9060314
Z variance eval              0.0102012865
total_rewards                [ 756.30886252  730.29582728  779.93337252  726.58863781  740.3532558
  677.71603141  755.74342625  740.86351305  762.7110615  1006.51061503]
total_rewards_mean           767.7024603167534
total_rewards_std            83.74493695932571
total_rewards_max            1006.5106150331669
total_rewards_min            677.7160314108964
Number of train steps total  312000
Number of env steps total    1562000
Number of rollouts total     0
Train Time (s)               34.79464655695483
(Previous) Eval Time (s)     7.726809488143772
Sample Time (s)              23.609369191806763
Epoch Time (s)               66.13082523690537
Total Train Time (s)         19583.775098732207
Epoch                        311
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:29:08.045867 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #311 | Epoch Duration: 65.92358779907227
2020-01-11 05:29:08.046075 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #311 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9024614
Z variance train             0.010185463
KL Divergence                21.583513
KL Loss                      2.1583514
QF Loss                      105.45112
VF Loss                      85.81811
Policy Loss                  -1058.931
Q Predictions Mean           1060.2297
Q Predictions Std            384.79413
Q Predictions Max            1424.1339
Q Predictions Min            -1.5318382
V Predictions Mean           1063.1532
V Predictions Std            384.46017
V Predictions Max            1414.2449
V Predictions Min            -0.9232071
Log Pis Mean                 -0.04785938
Log Pis Std                  2.0070662
Log Pis Max                  6.937602
Log Pis Min                  -3.4495356
Policy mu Mean               0.031724945
Policy mu Std                0.9310849
Policy mu Max                2.716627
Policy mu Min                -2.714142
Policy log std Mean          -0.43829992
Policy log std Std           0.16494769
Policy log std Max           -0.092881516
Policy log std Min           -1.1845194
Z mean eval                  1.8867352
Z variance eval              0.009237812
total_rewards                [795.52361386 755.47923876 794.51814918 784.91420768 754.08098338
 759.92400801 820.88610942 882.8076036  894.20254217 707.44730695]
total_rewards_mean           794.9783763012146
total_rewards_std            55.18667496022075
total_rewards_max            894.2025421716962
total_rewards_min            707.4473069526554
Number of train steps total  313000
Number of env steps total    1567000
Number of rollouts total     0
Train Time (s)               35.61821725592017
(Previous) Eval Time (s)     7.519201144110411
Sample Time (s)              23.30388665944338
Epoch Time (s)               66.44130505947396
Total Train Time (s)         19650.54611261608
Epoch                        312
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:30:14.821347 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #312 | Epoch Duration: 66.77510070800781
2020-01-11 05:30:14.821639 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #312 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8915523
Z variance train             0.0092326
KL Divergence                21.619493
KL Loss                      2.1619494
QF Loss                      155.93124
VF Loss                      128.54205
Policy Loss                  -1148.3241
Q Predictions Mean           1144.4015
Q Predictions Std            383.29547
Q Predictions Max            1475.9146
Q Predictions Min            5.384886
V Predictions Mean           1140.5234
V Predictions Std            381.56238
V Predictions Max            1469.1439
V Predictions Min            2.3983712
Log Pis Mean                 -0.18602124
Log Pis Std                  1.9643731
Log Pis Max                  6.926322
Log Pis Min                  -4.7341413
Policy mu Mean               0.03961483
Policy mu Std                0.9053661
Policy mu Max                2.3007398
Policy mu Min                -2.8848627
Policy log std Mean          -0.43763545
Policy log std Std           0.16008067
Policy log std Max           0.0044737756
Policy log std Min           -1.2700738
Z mean eval                  1.8739411
Z variance eval              0.007121616
total_rewards                [ 821.80319328  765.73515871  972.69468602  756.16404673  988.63769103
  774.2850765  1591.49849067 1001.30248082  778.29238     786.24987512]
total_rewards_mean           923.666307886926
total_rewards_std            241.735230963335
total_rewards_max            1591.4984906722748
total_rewards_min            756.1640467304636
Number of train steps total  314000
Number of env steps total    1572000
Number of rollouts total     0
Train Time (s)               34.72214429313317
(Previous) Eval Time (s)     7.852574548218399
Sample Time (s)              22.59659207984805
Epoch Time (s)               65.17131092119962
Total Train Time (s)         19716.542133462615
Epoch                        313
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:31:20.820508 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #313 | Epoch Duration: 65.99869203567505
2020-01-11 05:31:20.820711 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #313 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8719075
Z variance train             0.0071243444
KL Divergence                21.656782
KL Loss                      2.1656783
QF Loss                      135.67609
VF Loss                      85.19528
Policy Loss                  -1136.8665
Q Predictions Mean           1135.4438
Q Predictions Std            333.78638
Q Predictions Max            1446.0536
Q Predictions Min            1.2917088
V Predictions Mean           1142.4647
V Predictions Std            332.92987
V Predictions Max            1455.1713
V Predictions Min            3.440158
Log Pis Mean                 -0.17547631
Log Pis Std                  1.9464749
Log Pis Max                  6.2442136
Log Pis Min                  -6.6508756
Policy mu Mean               0.16358854
Policy mu Std                0.92023057
Policy mu Max                2.289792
Policy mu Min                -2.8948994
Policy log std Mean          -0.43708977
Policy log std Std           0.1458114
Policy log std Max           -0.13221142
Policy log std Min           -1.0427556
Z mean eval                  1.8427699
Z variance eval              0.0074481345
total_rewards                [716.73468213 772.50123097 769.84052794 746.60686829 781.5375751
 748.25521457 749.66297239 771.56819807 771.30286336 748.92574704]
total_rewards_mean           757.6935879853132
total_rewards_std            18.286780417199836
total_rewards_max            781.5375750977386
total_rewards_min            716.7346821336135
Number of train steps total  315000
Number of env steps total    1577000
Number of rollouts total     0
Train Time (s)               34.894298809114844
(Previous) Eval Time (s)     8.679577950853854
Sample Time (s)              23.774072968401015
Epoch Time (s)               67.34794972836971
Total Train Time (s)         19782.342195982113
Epoch                        314
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:32:26.624605 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #314 | Epoch Duration: 65.80373120307922
2020-01-11 05:32:26.624845 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #314 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8409119
Z variance train             0.0074524013
KL Divergence                21.43037
KL Loss                      2.143037
QF Loss                      242.6705
VF Loss                      139.56793
Policy Loss                  -1108.0226
Q Predictions Mean           1106.4542
Q Predictions Std            392.53616
Q Predictions Max            1419.4983
Q Predictions Min            -2.6023338
V Predictions Mean           1107.988
V Predictions Std            393.22354
V Predictions Max            1435.1327
V Predictions Min            4.314736
Log Pis Mean                 -0.2247275
Log Pis Std                  2.0640488
Log Pis Max                  7.0544457
Log Pis Min                  -5.4912314
Policy mu Mean               0.09989443
Policy mu Std                0.90917087
Policy mu Max                2.0878823
Policy mu Min                -2.6166525
Policy log std Mean          -0.45724893
Policy log std Std           0.15983166
Policy log std Max           -0.12852485
Policy log std Min           -1.1364957
Z mean eval                  1.8225237
Z variance eval              0.011670564
total_rewards                [ 786.51545875  680.94975584 1005.14556115 1036.35956423  771.97080001
  985.50441247  983.26874062  759.02669522 1022.71703523  778.93540301]
total_rewards_mean           881.0393426527274
total_rewards_std            129.28338984315937
total_rewards_max            1036.359564230044
total_rewards_min            680.9497558359715
Number of train steps total  316000
Number of env steps total    1582000
Number of rollouts total     0
Train Time (s)               35.391778389923275
(Previous) Eval Time (s)     7.134963947348297
Sample Time (s)              23.77506431005895
Epoch Time (s)               66.30180664733052
Total Train Time (s)         19848.28073054459
Epoch                        315
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:33:32.566315 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #315 | Epoch Duration: 65.94130444526672
2020-01-11 05:33:32.566510 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #315 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8204848
Z variance train             0.011624394
KL Divergence                19.878643
KL Loss                      1.9878644
QF Loss                      203.5033
VF Loss                      67.161095
Policy Loss                  -1141.6112
Q Predictions Mean           1136.397
Q Predictions Std            366.02673
Q Predictions Max            1464.4376
Q Predictions Min            2.4876602
V Predictions Mean           1141.0189
V Predictions Std            366.48114
V Predictions Max            1476.9648
V Predictions Min            6.116787
Log Pis Mean                 -0.15067354
Log Pis Std                  2.223019
Log Pis Max                  7.762355
Log Pis Min                  -6.319518
Policy mu Mean               0.021789119
Policy mu Std                0.9531222
Policy mu Max                2.3650084
Policy mu Min                -2.8137636
Policy log std Mean          -0.47494578
Policy log std Std           0.16499552
Policy log std Max           -0.093006074
Policy log std Min           -1.238231
Z mean eval                  1.7936976
Z variance eval              0.017400203
total_rewards                [ 755.17140588  996.86070664  936.79051892  753.12859226 1290.7403359
  750.16490241  987.8864555  1274.12231128 1257.97893093  770.21972292]
total_rewards_mean           977.306388264152
total_rewards_std            214.7862260326768
total_rewards_max            1290.7403358994513
total_rewards_min            750.164902414685
Number of train steps total  317000
Number of env steps total    1587000
Number of rollouts total     0
Train Time (s)               32.422423257958144
(Previous) Eval Time (s)     6.774086380843073
Sample Time (s)              24.17436612676829
Epoch Time (s)               63.37087576556951
Total Train Time (s)         19913.621491022408
Epoch                        316
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:34:37.912991 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #316 | Epoch Duration: 65.34633564949036
2020-01-11 05:34:37.913200 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #316 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7952454
Z variance train             0.017363513
KL Divergence                18.62324
KL Loss                      1.862324
QF Loss                      128.80965
VF Loss                      68.17123
Policy Loss                  -1182.3044
Q Predictions Mean           1178.7142
Q Predictions Std            403.6288
Q Predictions Max            1511.7473
Q Predictions Min            -5.574181
V Predictions Mean           1177.5566
V Predictions Std            401.8797
V Predictions Max            1511.5968
V Predictions Min            2.7137268
Log Pis Mean                 0.109058075
Log Pis Std                  2.2943203
Log Pis Max                  8.23208
Log Pis Min                  -4.327264
Policy mu Mean               0.032712337
Policy mu Std                0.9903142
Policy mu Max                2.960691
Policy mu Min                -3.1357625
Policy log std Mean          -0.46209088
Policy log std Std           0.14686261
Policy log std Max           -0.10809681
Policy log std Min           -0.9353793
Z mean eval                  1.7908016
Z variance eval              0.018417774
total_rewards                [ 681.96629676  797.38477524  746.89501774  911.81040216  761.23180707
  774.80065169  798.13255513 1030.32948447 1002.2427975   970.46573249]
total_rewards_mean           847.5259520241382
total_rewards_std            114.81602340821533
total_rewards_max            1030.3294844655466
total_rewards_min            681.9662967550022
Number of train steps total  318000
Number of env steps total    1592000
Number of rollouts total     0
Train Time (s)               32.44637123728171
(Previous) Eval Time (s)     8.74912777915597
Sample Time (s)              22.822599363978952
Epoch Time (s)               64.01809838041663
Total Train Time (s)         19977.152136879973
Epoch                        317
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:35:41.447679 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #317 | Epoch Duration: 63.53429174423218
2020-01-11 05:35:41.447931 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #317 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.790934
Z variance train             0.018332608
KL Divergence                18.393076
KL Loss                      1.8393077
QF Loss                      245.94196
VF Loss                      64.97844
Policy Loss                  -1170.7916
Q Predictions Mean           1170.4655
Q Predictions Std            415.6631
Q Predictions Max            1530.0276
Q Predictions Min            -5.7833033
V Predictions Mean           1171.7056
V Predictions Std            415.3651
V Predictions Max            1529.1653
V Predictions Min            -1.2909505
Log Pis Mean                 0.1946326
Log Pis Std                  2.3489082
Log Pis Max                  9.56497
Log Pis Min                  -5.635646
Policy mu Mean               -0.0015229707
Policy mu Std                0.9912223
Policy mu Max                3.5281777
Policy mu Min                -3.3711703
Policy log std Mean          -0.4877437
Policy log std Std           0.17710428
Policy log std Max           0.1191155
Policy log std Min           -1.0819488
Z mean eval                  1.7664906
Z variance eval              0.012528365
total_rewards                [1230.26935499  765.23235929  757.62563122 1289.75490396 1269.50192328
 1571.11372084  765.28050535 1121.79287073 1587.56649034  784.05260358]
total_rewards_mean           1114.219036357686
total_rewards_std            313.20596246298214
total_rewards_max            1587.5664903378163
total_rewards_min            757.6256312214512
Number of train steps total  319000
Number of env steps total    1597000
Number of rollouts total     0
Train Time (s)               32.529102051630616
(Previous) Eval Time (s)     8.264976567123085
Sample Time (s)              22.81793325813487
Epoch Time (s)               63.61201187688857
Total Train Time (s)         20043.061713575386
Epoch                        318
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:36:47.360633 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #318 | Epoch Duration: 65.91253638267517
2020-01-11 05:36:47.360844 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #318 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.770896
Z variance train             0.012507321
KL Divergence                19.340471
KL Loss                      1.9340471
QF Loss                      219.31903
VF Loss                      85.59368
Policy Loss                  -1122.323
Q Predictions Mean           1117.3225
Q Predictions Std            374.2278
Q Predictions Max            1476.2969
Q Predictions Min            -1.8308595
V Predictions Mean           1116.1606
V Predictions Std            372.00568
V Predictions Max            1480.7179
V Predictions Min            3.0606315
Log Pis Mean                 -0.33025393
Log Pis Std                  2.319651
Log Pis Max                  14.657052
Log Pis Min                  -5.6342
Policy mu Mean               -0.05027902
Policy mu Std                0.8943251
Policy mu Max                2.240724
Policy mu Min                -3.7456145
Policy log std Mean          -0.460672
Policy log std Std           0.1749981
Policy log std Max           -0.09724404
Policy log std Min           -1.2415037
Z mean eval                  1.7462234
Z variance eval              0.017477002
total_rewards                [ 757.52932011  790.69867684  792.34086655  872.52729925  810.93624967
 1007.08600435  967.69465353  751.49009365 1287.4127435   721.38383344]
total_rewards_mean           875.9099740885765
total_rewards_std            163.3451896515059
total_rewards_max            1287.412743498035
total_rewards_min            721.3838334359214
Number of train steps total  320000
Number of env steps total    1602000
Number of rollouts total     0
Train Time (s)               32.30873655481264
(Previous) Eval Time (s)     10.565188122913241
Sample Time (s)              22.97243063384667
Epoch Time (s)               65.84635531157255
Total Train Time (s)         20105.566742889117
Epoch                        319
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:37:49.869089 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #319 | Epoch Duration: 62.508105754852295
2020-01-11 05:37:49.869261 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #319 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7466984
Z variance train             0.017496468
KL Divergence                18.490705
KL Loss                      1.8490705
QF Loss                      83.637764
VF Loss                      46.98076
Policy Loss                  -1145.5725
Q Predictions Mean           1143.5444
Q Predictions Std            384.1192
Q Predictions Max            1481.4408
Q Predictions Min            -0.21650833
V Predictions Mean           1146.8225
V Predictions Std            382.7851
V Predictions Max            1476.7856
V Predictions Min            4.2757654
Log Pis Mean                 -0.3782987
Log Pis Std                  2.0545533
Log Pis Max                  7.4277143
Log Pis Min                  -6.8099737
Policy mu Mean               0.104780056
Policy mu Std                0.8831088
Policy mu Max                2.3531103
Policy mu Min                -2.8916943
Policy log std Mean          -0.45870018
Policy log std Std           0.17760208
Policy log std Max           -0.014330924
Policy log std Min           -2.1010246
Z mean eval                  1.7414268
Z variance eval              0.01641508
total_rewards                [ 799.64303421  756.83712208 1308.6449905   715.13728381 1258.41283069
 1009.68439473  832.4854538  1524.88827666 2704.74043083  736.42888127]
total_rewards_mean           1164.6902698579404
total_rewards_std            578.8350561398366
total_rewards_max            2704.740430825182
total_rewards_min            715.1372838087799
Number of train steps total  321000
Number of env steps total    1607000
Number of rollouts total     0
Train Time (s)               32.95675844326615
(Previous) Eval Time (s)     7.2266281908378005
Sample Time (s)              22.969931818079203
Epoch Time (s)               63.15331845218316
Total Train Time (s)         20171.931641013827
Epoch                        320
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:38:56.237329 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #320 | Epoch Duration: 66.36793065071106
2020-01-11 05:38:56.237508 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #320 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7406721
Z variance train             0.01639303
KL Divergence                18.40895
KL Loss                      1.840895
QF Loss                      144.13257
VF Loss                      46.71664
Policy Loss                  -1101.9618
Q Predictions Mean           1100.7177
Q Predictions Std            429.60962
Q Predictions Max            1482.518
Q Predictions Min            2.307569
V Predictions Mean           1104.1387
V Predictions Std            429.29547
V Predictions Max            1486.2487
V Predictions Min            1.474926
Log Pis Mean                 -0.17000222
Log Pis Std                  2.198
Log Pis Max                  6.167099
Log Pis Min                  -5.1780486
Policy mu Mean               -0.08111185
Policy mu Std                0.9227624
Policy mu Max                2.6299706
Policy mu Min                -2.8366919
Policy log std Mean          -0.4272381
Policy log std Std           0.17346972
Policy log std Max           0.07489011
Policy log std Min           -1.7102774
Z mean eval                  1.7178558
Z variance eval              0.011614457
total_rewards                [ 981.52205439 1575.88931684 1634.81640226  761.36921726  699.72012194
  767.93511921  723.658712    987.8908171   970.27292042 2166.96503517]
total_rewards_mean           1127.003971659459
total_rewards_std            470.5157503222246
total_rewards_max            2166.9650351749747
total_rewards_min            699.7201219365786
Number of train steps total  322000
Number of env steps total    1612000
Number of rollouts total     0
Train Time (s)               32.73242940194905
(Previous) Eval Time (s)     10.440864059142768
Sample Time (s)              23.45354223297909
Epoch Time (s)               66.6268356940709
Total Train Time (s)         20238.767187785357
Epoch                        321
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:40:03.076925 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #321 | Epoch Duration: 66.83927750587463
2020-01-11 05:40:03.077111 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #321 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7198632
Z variance train             0.011650046
KL Divergence                18.936104
KL Loss                      1.8936104
QF Loss                      118.627686
VF Loss                      92.85716
Policy Loss                  -1067.0448
Q Predictions Mean           1063.7286
Q Predictions Std            415.1896
Q Predictions Max            1418.9132
Q Predictions Min            1.0747216
V Predictions Mean           1065.9161
V Predictions Std            416.38098
V Predictions Max            1440.477
V Predictions Min            2.4877696
Log Pis Mean                 -0.21618941
Log Pis Std                  2.2231827
Log Pis Max                  7.21733
Log Pis Min                  -5.309928
Policy mu Mean               0.048755866
Policy mu Std                0.95495605
Policy mu Max                2.4503777
Policy mu Min                -2.9912183
Policy log std Mean          -0.44493377
Policy log std Std           0.16212353
Policy log std Max           -0.026323408
Policy log std Min           -0.9901003
Z mean eval                  1.6965568
Z variance eval              0.011562471
total_rewards                [1276.18272162  951.18403598  921.86502671  759.53701906 1531.28242609
  737.40365503 1019.3582351   750.62420516  691.70048412 1015.86729572]
total_rewards_mean           965.5005104588781
total_rewards_std            252.9360616994685
total_rewards_max            1531.2824260880807
total_rewards_min            691.7004841171804
Number of train steps total  323000
Number of env steps total    1617000
Number of rollouts total     0
Train Time (s)               33.119361764751375
(Previous) Eval Time (s)     10.652980360668153
Sample Time (s)              22.37729296972975
Epoch Time (s)               66.14963509514928
Total Train Time (s)         20303.64736670023
Epoch                        322
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:41:07.961259 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #322 | Epoch Duration: 64.8840069770813
2020-01-11 05:41:07.961445 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #322 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6917156
Z variance train             0.011576789
KL Divergence                18.563112
KL Loss                      1.8563112
QF Loss                      180.33235
VF Loss                      111.08659
Policy Loss                  -1099.1124
Q Predictions Mean           1099.6024
Q Predictions Std            388.5142
Q Predictions Max            1436.159
Q Predictions Min            0.097927034
V Predictions Mean           1105.8262
V Predictions Std            388.66965
V Predictions Max            1447.0267
V Predictions Min            4.6331906
Log Pis Mean                 0.13769633
Log Pis Std                  2.1276295
Log Pis Max                  8.441939
Log Pis Min                  -4.3116584
Policy mu Mean               -0.08826667
Policy mu Std                0.9931445
Policy mu Max                2.639935
Policy mu Min                -2.8046746
Policy log std Mean          -0.45267937
Policy log std Std           0.15523565
Policy log std Max           -0.027883738
Policy log std Min           -1.0911956
Z mean eval                  1.6824051
Z variance eval              0.01242586
total_rewards                [ 913.33561928 1293.56497428  762.03186269  751.80795899  983.41876608
  892.73722496  768.53762991  966.62046205  983.94109208 2540.30108858]
total_rewards_mean           1085.6296678910064
total_rewards_std            507.72526300522003
total_rewards_max            2540.3010885829926
total_rewards_min            751.8079589888159
Number of train steps total  324000
Number of env steps total    1622000
Number of rollouts total     0
Train Time (s)               32.99334329366684
(Previous) Eval Time (s)     9.387055497150868
Sample Time (s)              23.518958622124046
Epoch Time (s)               65.89935741294175
Total Train Time (s)         20370.410231334157
Epoch                        323
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:42:14.728074 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #323 | Epoch Duration: 66.76647615432739
2020-01-11 05:42:14.728262 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #323 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6819
Z variance train             0.012464701
KL Divergence                18.239399
KL Loss                      1.8239399
QF Loss                      173.04901
VF Loss                      97.09714
Policy Loss                  -1169.4016
Q Predictions Mean           1170.4707
Q Predictions Std            341.55585
Q Predictions Max            1458.2651
Q Predictions Min            5.854508
V Predictions Mean           1168.2911
V Predictions Std            343.5191
V Predictions Max            1456.3934
V Predictions Min            1.8494468
Log Pis Mean                 -0.28729862
Log Pis Std                  2.1514988
Log Pis Max                  7.3345118
Log Pis Min                  -6.3285213
Policy mu Mean               -0.014896055
Policy mu Std                0.96487635
Policy mu Max                2.5238128
Policy mu Min                -2.8880575
Policy log std Mean          -0.45863095
Policy log std Std           0.14106975
Policy log std Max           -0.10882607
Policy log std Min           -0.8299511
Z mean eval                  1.6602758
Z variance eval              0.013539225
total_rewards                [ 925.96104717  986.97901316  763.07301741  805.94625003  884.33259727
 1024.69070692 1208.56047651 1981.29161448 1296.68643133 2295.94720941]
total_rewards_mean           1217.3468363682387
total_rewards_std            491.4231765991414
total_rewards_max            2295.947209411688
total_rewards_min            763.0730174091217
Number of train steps total  325000
Number of env steps total    1627000
Number of rollouts total     0
Train Time (s)               32.98292176378891
(Previous) Eval Time (s)     10.253841985017061
Sample Time (s)              21.4844630532898
Epoch Time (s)               64.72122680209577
Total Train Time (s)         20435.708500230685
Epoch                        324
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:43:20.028224 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #324 | Epoch Duration: 65.29983925819397
2020-01-11 05:43:20.028342 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #324 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6581684
Z variance train             0.013559476
KL Divergence                18.023743
KL Loss                      1.8023742
QF Loss                      104.99139
VF Loss                      56.125946
Policy Loss                  -1077.5494
Q Predictions Mean           1075.417
Q Predictions Std            428.15942
Q Predictions Max            1459.6437
Q Predictions Min            -0.22987682
V Predictions Mean           1081.1398
V Predictions Std            427.07242
V Predictions Max            1460.3037
V Predictions Min            7.1885443
Log Pis Mean                 -0.14134791
Log Pis Std                  2.0316217
Log Pis Max                  7.135158
Log Pis Min                  -3.4644132
Policy mu Mean               -0.056760643
Policy mu Std                0.9243665
Policy mu Max                2.1497648
Policy mu Min                -2.8789659
Policy log std Mean          -0.4319965
Policy log std Std           0.15981746
Policy log std Max           -0.13766265
Policy log std Min           -0.9091227
Z mean eval                  1.6147964
Z variance eval              0.022442434
total_rewards                [ 834.28334555  768.28153242  771.60596457 1216.5806478   766.88100058
  926.8692074  1556.03352608 1276.71729886  889.38984928  968.79182864]
total_rewards_mean           997.5434201186899
total_rewards_std            252.74750326951818
total_rewards_max            1556.033526081695
total_rewards_min            766.8810005779955
Number of train steps total  326000
Number of env steps total    1632000
Number of rollouts total     0
Train Time (s)               32.80500362999737
(Previous) Eval Time (s)     10.832093422301114
Sample Time (s)              21.789969440549612
Epoch Time (s)               65.4270664928481
Total Train Time (s)         20500.124550064094
Epoch                        325
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:44:24.451532 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #325 | Epoch Duration: 64.42308354377747
2020-01-11 05:44:24.451719 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #325 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6185362
Z variance train             0.022276348
KL Divergence                16.591898
KL Loss                      1.6591898
QF Loss                      228.6553
VF Loss                      110.69786
Policy Loss                  -1120.2476
Q Predictions Mean           1116.4829
Q Predictions Std            392.92682
Q Predictions Max            1449.4127
Q Predictions Min            -1.9386582
V Predictions Mean           1114.3215
V Predictions Std            390.3392
V Predictions Max            1441.8643
V Predictions Min            2.9077935
Log Pis Mean                 0.12816188
Log Pis Std                  2.0403278
Log Pis Max                  6.7750845
Log Pis Min                  -4.8834577
Policy mu Mean               -0.0148083465
Policy mu Std                0.9846598
Policy mu Max                2.3714266
Policy mu Min                -2.8223662
Policy log std Mean          -0.46494076
Policy log std Std           0.17308913
Policy log std Max           -0.102255166
Policy log std Min           -1.5369427
Z mean eval                  1.6401193
Z variance eval              0.023967404
total_rewards                [ 770.04084265  753.1961595   817.74743766  871.63171231  838.28619416
 1448.01472008 2056.98111015 3067.62478185  838.56184013 3082.28247943]
total_rewards_mean           1454.4367277908723
total_rewards_std            898.8588777771711
total_rewards_max            3082.2824794267485
total_rewards_min            753.196159496613
Number of train steps total  327000
Number of env steps total    1637000
Number of rollouts total     0
Train Time (s)               32.28310384135693
(Previous) Eval Time (s)     9.82781970500946
Sample Time (s)              22.98415785189718
Epoch Time (s)               65.09508139826357
Total Train Time (s)         20568.19461468747
Epoch                        326
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:45:32.521647 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #326 | Epoch Duration: 68.06978917121887
2020-01-11 05:45:32.521822 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #326 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6373934
Z variance train             0.024049275
KL Divergence                16.522259
KL Loss                      1.6522259
QF Loss                      298.34637
VF Loss                      64.343475
Policy Loss                  -1198.9337
Q Predictions Mean           1199.616
Q Predictions Std            356.97534
Q Predictions Max            1487.4452
Q Predictions Min            -0.44405955
V Predictions Mean           1201.9785
V Predictions Std            356.55734
V Predictions Max            1487.3209
V Predictions Min            0.4680605
Log Pis Mean                 -0.123851314
Log Pis Std                  1.997474
Log Pis Max                  9.449802
Log Pis Min                  -4.7237616
Policy mu Mean               -0.06418898
Policy mu Std                0.93156755
Policy mu Max                2.0274758
Policy mu Min                -3.0936937
Policy log std Mean          -0.45475706
Policy log std Std           0.16710527
Policy log std Max           -0.06457716
Policy log std Min           -1.1667954
Z mean eval                  1.6300209
Z variance eval              0.016188378
total_rewards                [ 775.15251221  762.40358583  859.31909714 1365.31285468  775.23761883
  799.99209704  848.32379071  916.31799453 1802.45920956 1046.26149069]
total_rewards_mean           995.0780251211545
total_rewards_std            320.40932210501245
total_rewards_max            1802.459209561453
total_rewards_min            762.4035858303962
Number of train steps total  328000
Number of env steps total    1642000
Number of rollouts total     0
Train Time (s)               32.34499703766778
(Previous) Eval Time (s)     12.802228223066777
Sample Time (s)              23.351810585241765
Epoch Time (s)               68.49903584597632
Total Train Time (s)         20632.22080638539
Epoch                        327
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:46:36.551757 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #327 | Epoch Duration: 64.02980351448059
2020-01-11 05:46:36.551937 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #327 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.630037
Z variance train             0.016204167
KL Divergence                17.090351
KL Loss                      1.7090352
QF Loss                      135.7606
VF Loss                      67.74404
Policy Loss                  -1124.8549
Q Predictions Mean           1121.8896
Q Predictions Std            395.0298
Q Predictions Max            1436.3984
Q Predictions Min            -3.1969268
V Predictions Mean           1125.6213
V Predictions Std            393.66312
V Predictions Max            1444.8788
V Predictions Min            -0.59254
Log Pis Mean                 -0.1309064
Log Pis Std                  2.3026366
Log Pis Max                  9.655909
Log Pis Min                  -4.751862
Policy mu Mean               -0.12654002
Policy mu Std                0.9398436
Policy mu Max                2.0585072
Policy mu Min                -3.3543246
Policy log std Mean          -0.43882695
Policy log std Std           0.17328225
Policy log std Max           0.008788854
Policy log std Min           -1.0799515
Z mean eval                  1.5972487
Z variance eval              0.017495777
total_rewards                [ 751.3780875  1476.37402858 1223.99477948 1508.11491219  682.80426217
  769.38525487 1180.41404823  737.45065146  753.68028276  776.87199594]
total_rewards_mean           986.0468303172413
total_rewards_std            309.9822223200585
total_rewards_max            1508.1149121885658
total_rewards_min            682.8042621703155
Number of train steps total  329000
Number of env steps total    1647000
Number of rollouts total     0
Train Time (s)               33.005033534020185
(Previous) Eval Time (s)     8.332697718404233
Sample Time (s)              23.569527476560324
Epoch Time (s)               64.90725872898474
Total Train Time (s)         20698.367665797472
Epoch                        328
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:47:42.703637 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #328 | Epoch Duration: 66.15155744552612
2020-01-11 05:47:42.703815 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #328 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5959071
Z variance train             0.017524863
KL Divergence                16.818819
KL Loss                      1.6818819
QF Loss                      624.2933
VF Loss                      72.091736
Policy Loss                  -1161.1832
Q Predictions Mean           1157.1381
Q Predictions Std            362.87747
Q Predictions Max            1452.2253
Q Predictions Min            -11.362404
V Predictions Mean           1166.0819
V Predictions Std            362.79138
V Predictions Max            1457.5426
V Predictions Min            -8.525162
Log Pis Mean                 -0.10789202
Log Pis Std                  2.1899168
Log Pis Max                  8.230607
Log Pis Min                  -4.3554487
Policy mu Mean               -0.017737558
Policy mu Std                0.9461919
Policy mu Max                2.1585848
Policy mu Min                -2.7526674
Policy log std Mean          -0.46372923
Policy log std Std           0.15413614
Policy log std Max           -0.09953106
Policy log std Min           -1.0165305
Z mean eval                  1.5963589
Z variance eval              0.01867785
total_rewards                [1524.54617442  942.60516293  959.2393409   747.31500964  746.71154905
  719.00960699  930.17884184 1282.33565061  762.7806961   904.29876283]
total_rewards_mean           951.9020795308425
total_rewards_std            247.7802800043188
total_rewards_max            1524.5461744191318
total_rewards_min            719.0096069882052
Number of train steps total  330000
Number of env steps total    1652000
Number of rollouts total     0
Train Time (s)               32.729007645044476
(Previous) Eval Time (s)     9.576669399160892
Sample Time (s)              22.55012006824836
Epoch Time (s)               64.85579711245373
Total Train Time (s)         20762.38136378443
Epoch                        329
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:48:46.720106 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #329 | Epoch Duration: 64.01616740226746
2020-01-11 05:48:46.720290 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #329 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5961246
Z variance train             0.01870282
KL Divergence                16.646187
KL Loss                      1.6646187
QF Loss                      464.8418
VF Loss                      159.11844
Policy Loss                  -1180.15
Q Predictions Mean           1177.1082
Q Predictions Std            393.00714
Q Predictions Max            1511.6749
Q Predictions Min            3.3717177
V Predictions Mean           1179.6838
V Predictions Std            392.53598
V Predictions Max            1512.6877
V Predictions Min            3.0857515
Log Pis Mean                 -0.089999765
Log Pis Std                  2.054341
Log Pis Max                  7.4885497
Log Pis Min                  -5.5152717
Policy mu Mean               -0.09373834
Policy mu Std                0.92172456
Policy mu Max                2.2840047
Policy mu Min                -2.8640683
Policy log std Mean          -0.4544588
Policy log std Std           0.18174762
Policy log std Max           -0.08843163
Policy log std Min           -2.161078
Z mean eval                  1.5850838
Z variance eval              0.019007955
total_rewards                [3167.65538765  776.99690892 3073.27831272 2589.3497227  3162.54701988
 1478.99011279 3233.27707727 3145.30998233 1440.28270194  843.13219007]
total_rewards_mean           2291.081941627065
total_rewards_std            980.735891780379
total_rewards_max            3233.277077272498
total_rewards_min            776.9969089208238
Number of train steps total  331000
Number of env steps total    1657000
Number of rollouts total     0
Train Time (s)               32.5356868528761
(Previous) Eval Time (s)     8.736659205053002
Sample Time (s)              22.990300667006522
Epoch Time (s)               64.26264672493562
Total Train Time (s)         20838.270131213125
Epoch                        330
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:50:02.612218 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #330 | Epoch Duration: 75.89179253578186
2020-01-11 05:50:02.612392 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #330 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.582352
Z variance train             0.019017521
KL Divergence                16.416088
KL Loss                      1.6416088
QF Loss                      72.123
VF Loss                      51.671936
Policy Loss                  -1193.4281
Q Predictions Mean           1193.5144
Q Predictions Std            400.60992
Q Predictions Max            1525.5182
Q Predictions Min            -5.926075
V Predictions Mean           1196.2993
V Predictions Std            399.67676
V Predictions Max            1523.4681
V Predictions Min            1.3207531
Log Pis Mean                 -0.42639863
Log Pis Std                  1.8462489
Log Pis Max                  7.317626
Log Pis Min                  -4.630019
Policy mu Mean               0.005352979
Policy mu Std                0.84280837
Policy mu Max                2.2611732
Policy mu Min                -2.8566253
Policy log std Mean          -0.42591083
Policy log std Std           0.15395518
Policy log std Max           -0.08994368
Policy log std Min           -0.9325196
Z mean eval                  1.5663406
Z variance eval              0.015968552
total_rewards                [ 699.94077539  793.68827568  840.85282644 1074.62432822  693.14211041
 1898.23274277  809.81272081 1053.7183596   799.55669496  864.44481421]
total_rewards_mean           952.8013648488962
total_rewards_std            337.6111642570368
total_rewards_max            1898.2327427667653
total_rewards_min            693.1421104129257
Number of train steps total  332000
Number of env steps total    1662000
Number of rollouts total     0
Train Time (s)               33.40109696611762
(Previous) Eval Time (s)     20.36545882327482
Sample Time (s)              23.104691048618406
Epoch Time (s)               76.87124683801085
Total Train Time (s)         20902.69518309692
Epoch                        331
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:51:07.040705 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #331 | Epoch Duration: 64.42819118499756
2020-01-11 05:51:07.040890 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #331 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5643065
Z variance train             0.015962292
KL Divergence                17.04205
KL Loss                      1.7042049
QF Loss                      134.34805
VF Loss                      75.27263
Policy Loss                  -1110.7954
Q Predictions Mean           1107.9421
Q Predictions Std            404.33588
Q Predictions Max            1457.476
Q Predictions Min            -5.036683
V Predictions Mean           1111.7867
V Predictions Std            404.85873
V Predictions Max            1455.0527
V Predictions Min            3.4111028
Log Pis Mean                 -0.21116424
Log Pis Std                  2.0134687
Log Pis Max                  7.142273
Log Pis Min                  -4.759484
Policy mu Mean               -0.033477265
Policy mu Std                0.8800453
Policy mu Max                2.0989761
Policy mu Min                -2.6845622
Policy log std Mean          -0.43942857
Policy log std Std           0.16681017
Policy log std Max           0.033542067
Policy log std Min           -0.95269084
Z mean eval                  1.5458429
Z variance eval              0.015089284
total_rewards                [1020.93808818 2059.10345808 2042.3999104   891.95833088 2030.95673299
 2076.2346042  1455.18063737  977.66775378  965.08368289 3153.5703685 ]
total_rewards_mean           1667.3093567267472
total_rewards_std            695.364413088237
total_rewards_max            3153.5703685046506
total_rewards_min            891.9583308818977
Number of train steps total  333000
Number of env steps total    1667000
Number of rollouts total     0
Train Time (s)               33.04014790710062
(Previous) Eval Time (s)     7.922019835095853
Sample Time (s)              23.440921985544264
Epoch Time (s)               64.40308972774073
Total Train Time (s)         20974.770957491826
Epoch                        332
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:52:19.120058 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #332 | Epoch Duration: 72.07903242111206
2020-01-11 05:52:19.120231 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #332 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5426311
Z variance train             0.015075264
KL Divergence                17.081694
KL Loss                      1.7081693
QF Loss                      127.42459
VF Loss                      54.469673
Policy Loss                  -1201.0795
Q Predictions Mean           1198.7585
Q Predictions Std            425.9526
Q Predictions Max            1531.8126
Q Predictions Min            -2.8164515
V Predictions Mean           1203.8203
V Predictions Std            425.4562
V Predictions Max            1535.9722
V Predictions Min            -4.0190754
Log Pis Mean                 -0.29744986
Log Pis Std                  2.1232083
Log Pis Max                  7.718331
Log Pis Min                  -4.5512996
Policy mu Mean               0.13661735
Policy mu Std                0.8968149
Policy mu Max                2.6460583
Policy mu Min                -2.8930721
Policy log std Mean          -0.4478997
Policy log std Std           0.15393539
Policy log std Max           -0.06387451
Policy log std Min           -1.064441
Z mean eval                  1.5343277
Z variance eval              0.022539314
total_rewards                [ 815.9048312   763.81459407  752.6433855  1068.22008144 2039.40368662
  872.09796773  824.88862448  782.51231572  855.84691702  806.93880399]
total_rewards_mean           958.2271207747372
total_rewards_std            370.24325706451395
total_rewards_max            2039.4036866176973
total_rewards_min            752.6433854965454
Number of train steps total  334000
Number of env steps total    1672000
Number of rollouts total     0
Train Time (s)               33.218703197781
(Previous) Eval Time (s)     15.597612579353154
Sample Time (s)              23.27729763649404
Epoch Time (s)               72.09361341362819
Total Train Time (s)         21040.169534566347
Epoch                        333
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:53:24.522666 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #333 | Epoch Duration: 65.4022786617279
2020-01-11 05:53:24.522937 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #333 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5336072
Z variance train             0.022536345
KL Divergence                16.070448
KL Loss                      1.6070448
QF Loss                      332.3954
VF Loss                      59.57066
Policy Loss                  -1170.9878
Q Predictions Mean           1170.4758
Q Predictions Std            413.90216
Q Predictions Max            1518.864
Q Predictions Min            -18.027231
V Predictions Mean           1173.1951
V Predictions Std            412.5333
V Predictions Max            1515.5599
V Predictions Min            -4.2976537
Log Pis Mean                 -0.21097615
Log Pis Std                  2.0567734
Log Pis Max                  7.0304446
Log Pis Min                  -5.117305
Policy mu Mean               0.08872626
Policy mu Std                0.900319
Policy mu Max                2.1697412
Policy mu Min                -2.9615993
Policy log std Mean          -0.44429764
Policy log std Std           0.157763
Policy log std Max           -0.12597814
Policy log std Min           -1.0947218
Z mean eval                  1.584115
Z variance eval              0.010611172
total_rewards                [1002.23848083 1009.76265382 2851.93068935  965.71156608  851.55132545
 1512.4070779   811.26820096 1603.41713278 1317.49589144  871.45441961]
total_rewards_mean           1279.7237438223817
total_rewards_std            587.3778276677047
total_rewards_max            2851.930689350998
total_rewards_min            811.2682009639445
Number of train steps total  335000
Number of env steps total    1677000
Number of rollouts total     0
Train Time (s)               32.69510099897161
(Previous) Eval Time (s)     8.905918071046472
Sample Time (s)              22.974857249762863
Epoch Time (s)               64.57587631978095
Total Train Time (s)         21107.43043546425
Epoch                        334
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:54:31.788911 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #334 | Epoch Duration: 67.26576519012451
2020-01-11 05:54:31.789242 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #334 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5826689
Z variance train             0.010628777
KL Divergence                18.246166
KL Loss                      1.8246167
QF Loss                      363.16852
VF Loss                      403.0155
Policy Loss                  -1176.8577
Q Predictions Mean           1177.169
Q Predictions Std            390.32043
Q Predictions Max            1484.458
Q Predictions Min            -0.12117964
V Predictions Mean           1176.9294
V Predictions Std            387.61765
V Predictions Max            1477.1141
V Predictions Min            -1.6766684
Log Pis Mean                 -0.11391621
Log Pis Std                  2.4035878
Log Pis Max                  9.080917
Log Pis Min                  -5.747783
Policy mu Mean               -0.09487299
Policy mu Std                0.9806764
Policy mu Max                2.4530056
Policy mu Min                -3.456738
Policy log std Mean          -0.44344965
Policy log std Std           0.16478199
Policy log std Max           -0.021653533
Policy log std Min           -1.016402
Z mean eval                  1.5440922
Z variance eval              0.012607297
total_rewards                [ 753.82391017  785.12505939 1517.09895851  870.14232669  759.22326149
  781.47652635 1859.76873111  767.73715502  909.96365213  748.73326507]
total_rewards_mean           975.309284593266
total_rewards_std            368.1097259995553
total_rewards_max            1859.768731108023
total_rewards_min            748.7332650654815
Number of train steps total  336000
Number of env steps total    1682000
Number of rollouts total     0
Train Time (s)               32.866021789610386
(Previous) Eval Time (s)     11.595486192032695
Sample Time (s)              24.207602922338992
Epoch Time (s)               68.66911090398207
Total Train Time (s)         21173.757326480933
Epoch                        335
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:55:38.119087 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #335 | Epoch Duration: 66.32961940765381
2020-01-11 05:55:38.119442 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #335 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5447174
Z variance train             0.012630859
KL Divergence                17.883945
KL Loss                      1.7883946
QF Loss                      312.18344
VF Loss                      84.5152
Policy Loss                  -1154.5399
Q Predictions Mean           1152.9304
Q Predictions Std            408.82254
Q Predictions Max            1509.2133
Q Predictions Min            -16.528612
V Predictions Mean           1156.7732
V Predictions Std            410.45102
V Predictions Max            1515.2539
V Predictions Min            -4.105711
Log Pis Mean                 -0.13259308
Log Pis Std                  2.0637064
Log Pis Max                  7.092746
Log Pis Min                  -3.9980276
Policy mu Mean               -0.020133635
Policy mu Std                0.89691633
Policy mu Max                2.251366
Policy mu Min                -2.9424946
Policy log std Mean          -0.4311769
Policy log std Std           0.16224097
Policy log std Max           0.059369624
Policy log std Min           -1.0152236
Z mean eval                  1.5154308
Z variance eval              0.0192624
total_rewards                [3158.07126027  815.53535054  846.24578194 1007.45866395  931.28487808
  935.02168766 1126.0463982  1518.59767398 1031.47387503 1565.54185673]
total_rewards_mean           1293.527742636767
total_rewards_std            668.4319556317231
total_rewards_max            3158.071260266737
total_rewards_min            815.5353505353206
Number of train steps total  337000
Number of env steps total    1687000
Number of rollouts total     0
Train Time (s)               32.94190987898037
(Previous) Eval Time (s)     9.255661817267537
Sample Time (s)              22.638983711134642
Epoch Time (s)               64.83655540738255
Total Train Time (s)         21241.208095556125
Epoch                        336
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:56:45.572400 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #336 | Epoch Duration: 67.45276856422424
2020-01-11 05:56:45.572559 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #336 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.517189
Z variance train             0.019235747
KL Divergence                17.148027
KL Loss                      1.7148027
QF Loss                      114.068375
VF Loss                      55.538624
Policy Loss                  -1117.29
Q Predictions Mean           1113.1932
Q Predictions Std            411.127
Q Predictions Max            1454.1296
Q Predictions Min            2.5802944
V Predictions Mean           1115.6267
V Predictions Std            411.8624
V Predictions Max            1455.135
V Predictions Min            4.8660655
Log Pis Mean                 -0.32304975
Log Pis Std                  2.0539746
Log Pis Max                  6.6489882
Log Pis Min                  -6.015284
Policy mu Mean               0.07595509
Policy mu Std                0.9082519
Policy mu Max                2.3992848
Policy mu Min                -3.2047405
Policy log std Mean          -0.4505829
Policy log std Std           0.16700968
Policy log std Max           0.0031303763
Policy log std Min           -1.0297017
Z mean eval                  1.5185492
Z variance eval              0.01272168
total_rewards                [ 941.98499494  936.53894752  933.26603072  900.61514945 1270.97939438
  886.65007689  976.76826733  988.79773927  934.95125404  858.42649678]
total_rewards_mean           962.8978351319874
total_rewards_std            109.16764550417795
total_rewards_max            1270.9793943772627
total_rewards_min            858.4264967777556
Number of train steps total  338000
Number of env steps total    1692000
Number of rollouts total     0
Train Time (s)               33.147381061222404
(Previous) Eval Time (s)     11.871555054094642
Sample Time (s)              23.496254635043442
Epoch Time (s)               68.51519075036049
Total Train Time (s)         21306.604046218563
Epoch                        337
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:57:50.972274 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #337 | Epoch Duration: 65.39957761764526
2020-01-11 05:57:50.972482 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #337 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5152525
Z variance train             0.01270886
KL Divergence                17.342709
KL Loss                      1.7342709
QF Loss                      583.8948
VF Loss                      583.4266
Policy Loss                  -1136.5718
Q Predictions Mean           1132.6093
Q Predictions Std            389.87265
Q Predictions Max            1462.9131
Q Predictions Min            -18.106625
V Predictions Mean           1139.9768
V Predictions Std            388.24612
V Predictions Max            1459.6823
V Predictions Min            -0.7579144
Log Pis Mean                 -0.21502495
Log Pis Std                  1.9084035
Log Pis Max                  8.059594
Log Pis Min                  -4.6752205
Policy mu Mean               0.009550647
Policy mu Std                0.8980236
Policy mu Max                2.5390947
Policy mu Min                -3.2674644
Policy log std Mean          -0.42954472
Policy log std Std           0.16884987
Policy log std Max           -0.03242919
Policy log std Min           -1.3606305
Z mean eval                  1.5011429
Z variance eval              0.0124468375
total_rewards                [ 976.01391974  844.40702599  824.98697958  810.41133153  795.97258143
 1191.99807176  862.15605975  840.31820921 1930.70416772  747.30496461]
total_rewards_mean           982.4273311313679
total_rewards_std            337.83496580546205
total_rewards_max            1930.7041677183886
total_rewards_min            747.3049646100038
Number of train steps total  339000
Number of env steps total    1697000
Number of rollouts total     0
Train Time (s)               33.00093340082094
(Previous) Eval Time (s)     8.755633830092847
Sample Time (s)              22.201666021253914
Epoch Time (s)               63.9582332521677
Total Train Time (s)         21371.074688401073
Epoch                        338
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:58:55.446808 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #338 | Epoch Duration: 64.4741702079773
2020-01-11 05:58:55.446992 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #338 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5027412
Z variance train             0.012519604
KL Divergence                17.103142
KL Loss                      1.7103142
QF Loss                      125.86845
VF Loss                      53.14121
Policy Loss                  -1146.1091
Q Predictions Mean           1145.9185
Q Predictions Std            385.2117
Q Predictions Max            1459.3198
Q Predictions Min            -2.827213
V Predictions Mean           1143.1663
V Predictions Std            383.40186
V Predictions Max            1453.9657
V Predictions Min            4.1721854
Log Pis Mean                 -0.24514602
Log Pis Std                  1.9244132
Log Pis Max                  7.4401336
Log Pis Min                  -4.888887
Policy mu Mean               0.012581308
Policy mu Std                0.8853242
Policy mu Max                2.7288635
Policy mu Min                -2.8143706
Policy log std Mean          -0.42849454
Policy log std Std           0.16838238
Policy log std Max           0.032257766
Policy log std Min           -1.3899307
Z mean eval                  1.5002086
Z variance eval              0.015495459
total_rewards                [ 797.04586402 1665.65493497  808.0344991   753.284362   3151.92477368
 2113.63439459 2868.48468427 1000.31923354 1403.67160287  759.46070022]
total_rewards_mean           1532.151504925831
total_rewards_std            856.3387660716683
total_rewards_max            3151.924773682925
total_rewards_min            753.2843619971186
Number of train steps total  340000
Number of env steps total    1702000
Number of rollouts total     0
Train Time (s)               32.92219720967114
(Previous) Eval Time (s)     9.27122011827305
Sample Time (s)              23.66398503538221
Epoch Time (s)               65.8574023633264
Total Train Time (s)         21441.632356669288
Epoch                        339
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:00:06.008375 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #339 | Epoch Duration: 70.56124997138977
2020-01-11 06:00:06.008542 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #339 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4968379
Z variance train             0.015574607
KL Divergence                16.463175
KL Loss                      1.6463175
QF Loss                      184.76993
VF Loss                      34.003586
Policy Loss                  -1219.0674
Q Predictions Mean           1220.3356
Q Predictions Std            361.68573
Q Predictions Max            1516.6622
Q Predictions Min            -3.86836
V Predictions Mean           1221.0724
V Predictions Std            361.4264
V Predictions Max            1508.2812
V Predictions Min            -5.065764
Log Pis Mean                 -0.10753478
Log Pis Std                  2.080863
Log Pis Max                  7.5131106
Log Pis Min                  -5.290297
Policy mu Mean               0.043960523
Policy mu Std                0.93543905
Policy mu Max                2.4366918
Policy mu Min                -2.884256
Policy log std Mean          -0.4000844
Policy log std Std           0.15332687
Policy log std Max           -0.05178106
Policy log std Min           -0.83639115
Z mean eval                  1.4863174
Z variance eval              0.012769972
total_rewards                [2066.14541808  819.14064073  985.96750342 1451.83178929 2364.3607994
  838.26918816 2168.2523746  1063.06908476 1972.26057778  730.48506504]
total_rewards_mean           1445.9782441262182
total_rewards_std            604.9063227217681
total_rewards_max            2364.360799402352
total_rewards_min            730.4850650408096
Number of train steps total  341000
Number of env steps total    1707000
Number of rollouts total     0
Train Time (s)               32.865561484359205
(Previous) Eval Time (s)     13.974385856185108
Sample Time (s)              22.45669951522723
Epoch Time (s)               69.29664685577154
Total Train Time (s)         21509.94132625498
Epoch                        340
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:01:14.321798 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #340 | Epoch Duration: 68.3131160736084
2020-01-11 06:01:14.322014 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #340 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4871273
Z variance train             0.012713909
KL Divergence                17.022402
KL Loss                      1.7022402
QF Loss                      115.58348
VF Loss                      43.44953
Policy Loss                  -1176.1079
Q Predictions Mean           1175.7273
Q Predictions Std            456.0505
Q Predictions Max            1574.8081
Q Predictions Min            1.9289991
V Predictions Mean           1178.509
V Predictions Std            457.65192
V Predictions Max            1574.8011
V Predictions Min            3.9673223
Log Pis Mean                 -0.3994678
Log Pis Std                  1.930398
Log Pis Max                  5.8722205
Log Pis Min                  -4.4438696
Policy mu Mean               0.06403878
Policy mu Std                0.87384665
Policy mu Max                2.3081973
Policy mu Min                -2.8706715
Policy log std Mean          -0.42691267
Policy log std Std           0.16201887
Policy log std Max           -0.069063395
Policy log std Min           -0.87844616
Z mean eval                  1.4713217
Z variance eval              0.012739782
total_rewards                [ 726.48717519 1185.43780971  930.49255397  674.89402248 1937.24836521
  839.588512   1446.42244187  741.88282831  798.04166929  868.55465932]
total_rewards_mean           1014.9050037348812
total_rewards_std            380.2168981429717
total_rewards_max            1937.248365207779
total_rewards_min            674.8940224813178
Number of train steps total  342000
Number of env steps total    1712000
Number of rollouts total     0
Train Time (s)               33.021322812885046
(Previous) Eval Time (s)     12.990470195189118
Sample Time (s)              23.796080419328064
Epoch Time (s)               69.80787342740223
Total Train Time (s)         21575.81859562872
Epoch                        341
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:02:20.202270 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #341 | Epoch Duration: 65.88010931015015
2020-01-11 06:02:20.202455 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #341 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4728541
Z variance train             0.012766527
KL Divergence                16.81306
KL Loss                      1.6813061
QF Loss                      117.39395
VF Loss                      88.0074
Policy Loss                  -1137.4474
Q Predictions Mean           1135.7972
Q Predictions Std            425.34467
Q Predictions Max            1467.3403
Q Predictions Min            1.6714544
V Predictions Mean           1130.3411
V Predictions Std            424.23383
V Predictions Max            1457.1619
V Predictions Min            0.39284682
Log Pis Mean                 -0.21051309
Log Pis Std                  1.9560198
Log Pis Max                  8.716227
Log Pis Min                  -4.738209
Policy mu Mean               0.041725278
Policy mu Std                0.86499673
Policy mu Max                2.3963401
Policy mu Min                -2.7890375
Policy log std Mean          -0.40369663
Policy log std Std           0.14739187
Policy log std Max           -0.053801373
Policy log std Min           -1.1102594
Z mean eval                  1.4602517
Z variance eval              0.016133677
total_rewards                [1630.46501953 1689.6890263   949.65070604  695.72481126  790.7494849
 1408.93985473  178.24763354 1652.42153801  806.62306734  850.88505643]
total_rewards_mean           1065.3396198075407
total_rewards_std            479.2870933936163
total_rewards_max            1689.6890262952359
total_rewards_min            178.24763353759107
Number of train steps total  343000
Number of env steps total    1717000
Number of rollouts total     0
Train Time (s)               32.49928934779018
(Previous) Eval Time (s)     9.062374830711633
Sample Time (s)              23.525271030608565
Epoch Time (s)               65.08693520911038
Total Train Time (s)         21642.014698375016
Epoch                        342
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:03:26.401802 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #342 | Epoch Duration: 66.19921684265137
2020-01-11 06:03:26.401975 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #342 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4611452
Z variance train             0.016133748
KL Divergence                16.148922
KL Loss                      1.6148922
QF Loss                      110.856125
VF Loss                      42.381523
Policy Loss                  -1095.4838
Q Predictions Mean           1093.3011
Q Predictions Std            427.59503
Q Predictions Max            1432.7792
Q Predictions Min            5.6671243
V Predictions Mean           1096.1497
V Predictions Std            427.48306
V Predictions Max            1436.3514
V Predictions Min            3.41836
Log Pis Mean                 -0.18663257
Log Pis Std                  2.2206862
Log Pis Max                  8.295807
Log Pis Min                  -4.827225
Policy mu Mean               0.13551252
Policy mu Std                0.9242849
Policy mu Max                2.084946
Policy mu Min                -2.9524524
Policy log std Mean          -0.40232107
Policy log std Std           0.16048865
Policy log std Max           -0.0752254
Policy log std Min           -1.1399877
Z mean eval                  1.4458637
Z variance eval              0.014524418
total_rewards                [1971.05531907  912.33514584  920.82165196  978.16883364  830.569243
 1817.85193932  866.25636204 1044.19476142  974.12337873  803.30932573]
total_rewards_mean           1111.8685960748055
total_rewards_std            398.6250715479857
total_rewards_max            1971.0553190700693
total_rewards_min            803.3093257268097
Number of train steps total  344000
Number of env steps total    1722000
Number of rollouts total     0
Train Time (s)               32.49241023370996
(Previous) Eval Time (s)     10.17426183493808
Sample Time (s)              22.774236257188022
Epoch Time (s)               65.44090832583606
Total Train Time (s)         21707.087586553767
Epoch                        343
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:04:31.478709 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #343 | Epoch Duration: 65.07659196853638
2020-01-11 06:04:31.478896 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #343 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4451759
Z variance train             0.014503749
KL Divergence                16.327284
KL Loss                      1.6327285
QF Loss                      310.6276
VF Loss                      81.465126
Policy Loss                  -1206.591
Q Predictions Mean           1207.6462
Q Predictions Std            386.35577
Q Predictions Max            1510.4973
Q Predictions Min            2.294546
V Predictions Mean           1207.85
V Predictions Std            386.31317
V Predictions Max            1505.2377
V Predictions Min            1.5022751
Log Pis Mean                 -0.32046223
Log Pis Std                  1.9232697
Log Pis Max                  6.089832
Log Pis Min                  -4.789469
Policy mu Mean               -0.053309698
Policy mu Std                0.89369285
Policy mu Max                2.2922242
Policy mu Min                -2.6569757
Policy log std Mean          -0.42028412
Policy log std Std           0.15042582
Policy log std Max           -0.07594189
Policy log std Min           -0.95833904
Z mean eval                  1.4162462
Z variance eval              0.015745092
total_rewards                [ 863.86000237  918.56223578 1067.07390913 1823.33066865 1351.61037369
 1270.28519126 1038.12299502  710.76924267 1079.48322439  821.00554294]
total_rewards_mean           1094.4103385899177
total_rewards_std            306.3582411408825
total_rewards_max            1823.3306686515948
total_rewards_min            710.7692426672671
Number of train steps total  345000
Number of env steps total    1727000
Number of rollouts total     0
Train Time (s)               33.03937710635364
(Previous) Eval Time (s)     9.809671472758055
Sample Time (s)              23.47580903675407
Epoch Time (s)               66.32485761586577
Total Train Time (s)         21774.8300850112
Epoch                        344
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:05:39.225401 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #344 | Epoch Duration: 67.74636483192444
2020-01-11 06:05:39.225575 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #344 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4122037
Z variance train             0.015736928
KL Divergence                16.341373
KL Loss                      1.6341374
QF Loss                      115.53612
VF Loss                      75.40083
Policy Loss                  -1122.6793
Q Predictions Mean           1123.5679
Q Predictions Std            444.237
Q Predictions Max            1473.9495
Q Predictions Min            -2.7950654
V Predictions Mean           1128.3672
V Predictions Std            443.76285
V Predictions Max            1478.8538
V Predictions Min            5.5414667
Log Pis Mean                 -0.3081239
Log Pis Std                  2.1204758
Log Pis Max                  6.489958
Log Pis Min                  -7.7230663
Policy mu Mean               -0.17391276
Policy mu Std                0.87321407
Policy mu Max                2.167072
Policy mu Min                -2.8711767
Policy log std Mean          -0.38934204
Policy log std Std           0.16488999
Policy log std Max           -0.0657357
Policy log std Min           -1.0900145
Z mean eval                  1.4298737
Z variance eval              0.015029987
total_rewards                [778.82861778 831.22385316 789.95861423 887.15001299 765.33788719
 674.30494387 812.55646215 650.04769826 816.92888455 759.70572956]
total_rewards_mean           776.6042703739115
total_rewards_std            67.2307898792881
total_rewards_max            887.1500129881586
total_rewards_min            650.0476982565907
Number of train steps total  346000
Number of env steps total    1732000
Number of rollouts total     0
Train Time (s)               32.775759282987565
(Previous) Eval Time (s)     11.230856106150895
Sample Time (s)              23.551350858528167
Epoch Time (s)               67.55796624766663
Total Train Time (s)         21838.374322231393
Epoch                        345
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:06:42.773601 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #345 | Epoch Duration: 63.54787850379944
2020-01-11 06:06:42.773796 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #345 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4355867
Z variance train             0.01506131
KL Divergence                16.826693
KL Loss                      1.6826693
QF Loss                      291.8238
VF Loss                      180.57576
Policy Loss                  -1186.8544
Q Predictions Mean           1180.8467
Q Predictions Std            454.4019
Q Predictions Max            1548.8297
Q Predictions Min            1.0695996
V Predictions Mean           1178.0745
V Predictions Std            447.43002
V Predictions Max            1538.3331
V Predictions Min            1.5754279
Log Pis Mean                 -0.60700214
Log Pis Std                  2.1960576
Log Pis Max                  11.604984
Log Pis Min                  -7.7055035
Policy mu Mean               -0.103729725
Policy mu Std                0.84719473
Policy mu Max                2.2916818
Policy mu Min                -2.9587572
Policy log std Mean          -0.38232636
Policy log std Std           0.16614631
Policy log std Max           0.09141764
Policy log std Min           -1.3644549
Z mean eval                  1.4276264
Z variance eval              0.017527133
total_rewards                [ 769.12624758  802.51157466  860.3169468   967.5415869   863.07735512
 3122.79793436  833.09472632 1132.01072269 2286.16505247 1136.06564123]
total_rewards_mean           1277.2707788129876
total_rewards_std            747.470126946978
total_rewards_max            3122.797934356013
total_rewards_min            769.1262475835217
Number of train steps total  347000
Number of env steps total    1737000
Number of rollouts total     0
Train Time (s)               33.016463454812765
(Previous) Eval Time (s)     7.220419245772064
Sample Time (s)              23.7471076361835
Epoch Time (s)               63.98399033676833
Total Train Time (s)         21906.377982856706
Epoch                        346
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:07:50.780997 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #346 | Epoch Duration: 68.00705695152283
2020-01-11 06:07:50.781181 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #346 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4268042
Z variance train             0.017530581
KL Divergence                16.180958
KL Loss                      1.6180958
QF Loss                      1698.221
VF Loss                      165.70963
Policy Loss                  -1186.26
Q Predictions Mean           1184.0474
Q Predictions Std            411.82135
Q Predictions Max            1522.3182
Q Predictions Min            -2.4355605
V Predictions Mean           1188.6545
V Predictions Std            410.64435
V Predictions Max            1522.201
V Predictions Min            0.517406
Log Pis Mean                 -0.36377847
Log Pis Std                  2.1412728
Log Pis Max                  9.711772
Log Pis Min                  -5.0484924
Policy mu Mean               -0.07053819
Policy mu Std                0.89297897
Policy mu Max                2.3326805
Policy mu Min                -2.9344857
Policy log std Mean          -0.40590253
Policy log std Std           0.16602865
Policy log std Max           -0.01987192
Policy log std Min           -1.0702031
Z mean eval                  1.4068792
Z variance eval              0.017373761
total_rewards                [1362.7931216  3049.93756399  781.05924424 2903.86164133 1906.52966511
  782.91312599 1985.72630109  798.89536291  962.20466218  786.45708277]
total_rewards_mean           1532.0377771207127
total_rewards_std            842.8461503571189
total_rewards_max            3049.937563988684
total_rewards_min            781.0592442387351
Number of train steps total  348000
Number of env steps total    1742000
Number of rollouts total     0
Train Time (s)               33.109361737035215
(Previous) Eval Time (s)     11.243157627992332
Sample Time (s)              22.11734822811559
Epoch Time (s)               66.46986759314314
Total Train Time (s)         21976.85018099891
Epoch                        347
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:09:01.257506 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #347 | Epoch Duration: 70.47616505622864
2020-01-11 06:09:01.257868 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #347 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.409136
Z variance train             0.017367046
KL Divergence                15.937949
KL Loss                      1.593795
QF Loss                      156.26498
VF Loss                      61.081024
Policy Loss                  -1174.9822
Q Predictions Mean           1171.4297
Q Predictions Std            369.3367
Q Predictions Max            1488.1101
Q Predictions Min            4.60246
V Predictions Mean           1172.1453
V Predictions Std            369.6123
V Predictions Max            1493.0112
V Predictions Min            6.0805745
Log Pis Mean                 -0.30929053
Log Pis Std                  1.9905344
Log Pis Max                  6.3324213
Log Pis Min                  -4.9931903
Policy mu Mean               0.0444781
Policy mu Std                0.872566
Policy mu Max                2.2694957
Policy mu Min                -2.7183523
Policy log std Mean          -0.42067456
Policy log std Std           0.16246516
Policy log std Max           -0.035320505
Policy log std Min           -1.287009
Z mean eval                  1.4077519
Z variance eval              0.013755958
total_rewards                [1273.1643126  2629.50879639  660.1466746   788.67897505 1305.48187359
 1603.63476968 1301.88474755  811.11306148 1253.7328131  1411.62981667]
total_rewards_mean           1303.897584070901
total_rewards_std            527.7180435184998
total_rewards_max            2629.508796392889
total_rewards_min            660.1466746011404
Number of train steps total  349000
Number of env steps total    1747000
Number of rollouts total     0
Train Time (s)               33.60612944327295
(Previous) Eval Time (s)     15.249139534309506
Sample Time (s)              22.30701728956774
Epoch Time (s)               71.1622862671502
Total Train Time (s)         22045.25525957253
Epoch                        348
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:10:09.665586 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #348 | Epoch Duration: 68.40746760368347
2020-01-11 06:10:09.665772 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #348 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4094765
Z variance train             0.013789895
KL Divergence                16.753887
KL Loss                      1.6753887
QF Loss                      134.70503
VF Loss                      134.70271
Policy Loss                  -1140.861
Q Predictions Mean           1139.6183
Q Predictions Std            419.206
Q Predictions Max            1467.4246
Q Predictions Min            1.2971529
V Predictions Mean           1135.4446
V Predictions Std            418.09964
V Predictions Max            1460.3027
V Predictions Min            1.8119714
Log Pis Mean                 -0.51132524
Log Pis Std                  1.7656056
Log Pis Max                  4.4965444
Log Pis Min                  -4.2476172
Policy mu Mean               0.009480814
Policy mu Std                0.86221075
Policy mu Max                2.584179
Policy mu Min                -2.8405955
Policy log std Mean          -0.38380137
Policy log std Std           0.1618613
Policy log std Max           0.007997498
Policy log std Min           -0.9377184
Z mean eval                  1.377716
Z variance eval              0.01747067
total_rewards                [2928.13546947 1020.16676531 3095.99855205 2050.60790339 1562.15357264
 1462.67841634 2289.14816578  870.96253997  814.10665054  732.90194017]
total_rewards_mean           1682.6859975650484
total_rewards_std            828.7965732156101
total_rewards_max            3095.998552045175
total_rewards_min            732.9019401725274
Number of train steps total  350000
Number of env steps total    1752000
Number of rollouts total     0
Train Time (s)               32.7000956046395
(Previous) Eval Time (s)     12.493986246176064
Sample Time (s)              23.79105949215591
Epoch Time (s)               68.98514134297147
Total Train Time (s)         22117.87758236006
Epoch                        349
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:11:22.291992 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #349 | Epoch Duration: 72.62607026100159
2020-01-11 06:11:22.292207 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #349 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3774213
Z variance train             0.0174087
KL Divergence                16.333172
KL Loss                      1.6333172
QF Loss                      966.963
VF Loss                      104.56747
Policy Loss                  -1059.4675
Q Predictions Mean           1056.3367
Q Predictions Std            428.2496
Q Predictions Max            1422.5409
Q Predictions Min            -3.9107318
V Predictions Mean           1061.7571
V Predictions Std            426.58688
V Predictions Max            1421.606
V Predictions Min            6.699667
Log Pis Mean                 -0.26162642
Log Pis Std                  2.0570643
Log Pis Max                  9.149731
Log Pis Min                  -5.0612645
Policy mu Mean               0.11344361
Policy mu Std                0.8959168
Policy mu Max                2.327716
Policy mu Min                -2.8453362
Policy log std Mean          -0.40552115
Policy log std Std           0.16680034
Policy log std Max           -0.0053721964
Policy log std Min           -1.5411086
Z mean eval                  1.3979698
Z variance eval              0.015003431
total_rewards                [ 839.22003826 2463.67299774  711.62318736 1582.03456247  926.82757533
  699.92819424  768.08568106 2167.94906857 1923.82041208 2403.81513046]
total_rewards_mean           1448.697684756788
total_rewards_std            701.0168172059279
total_rewards_max            2463.6729977364334
total_rewards_min            699.9281942389591
Number of train steps total  351000
Number of env steps total    1757000
Number of rollouts total     0
Train Time (s)               32.44737457903102
(Previous) Eval Time (s)     16.134576288051903
Sample Time (s)              22.633541465271264
Epoch Time (s)               71.21549233235419
Total Train Time (s)         22186.11601352645
Epoch                        350
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:12:30.534406 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #350 | Epoch Duration: 68.2420289516449
2020-01-11 06:12:30.534600 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #350 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4001787
Z variance train             0.014936505
KL Divergence                16.824806
KL Loss                      1.6824807
QF Loss                      188.39316
VF Loss                      100.303696
Policy Loss                  -1210.8469
Q Predictions Mean           1207.3649
Q Predictions Std            426.3105
Q Predictions Max            1540.4847
Q Predictions Min            -36.769344
V Predictions Mean           1209.9895
V Predictions Std            423.8328
V Predictions Max            1540.1224
V Predictions Min            -4.785091
Log Pis Mean                 -0.6387259
Log Pis Std                  1.9174501
Log Pis Max                  7.149114
Log Pis Min                  -4.9883695
Policy mu Mean               0.04532987
Policy mu Std                0.85855854
Policy mu Max                2.757329
Policy mu Min                -2.8366227
Policy log std Mean          -0.399317
Policy log std Std           0.16329406
Policy log std Max           0.10760042
Policy log std Min           -1.0105021
Z mean eval                  1.3735117
Z variance eval              0.011116468
total_rewards                [ 651.02683771  850.38837721 1901.90583577 2453.29684551 2498.33495577
 3026.06618035 1229.61724776 1381.43340636  928.48372832  799.96812365]
total_rewards_mean           1572.052153839502
total_rewards_std            799.4078906136232
total_rewards_max            3026.0661803469566
total_rewards_min            651.026837706576
Number of train steps total  352000
Number of env steps total    1762000
Number of rollouts total     0
Train Time (s)               32.53839502763003
(Previous) Eval Time (s)     13.160787435248494
Sample Time (s)              22.14373946748674
Epoch Time (s)               67.84292193036526
Total Train Time (s)         22255.69242018694
Epoch                        351
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:13:40.115427 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #351 | Epoch Duration: 69.58067870140076
2020-01-11 06:13:40.115617 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #351 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3777399
Z variance train             0.011092724
KL Divergence                17.739025
KL Loss                      1.7739025
QF Loss                      393.8756
VF Loss                      88.76771
Policy Loss                  -1166.4783
Q Predictions Mean           1160.6199
Q Predictions Std            375.3042
Q Predictions Max            1460.2709
Q Predictions Min            -0.00048571825
V Predictions Mean           1161.8257
V Predictions Std            374.10526
V Predictions Max            1456.5201
V Predictions Min            2.1271424
Log Pis Mean                 -0.3152327
Log Pis Std                  2.0752492
Log Pis Max                  7.0851316
Log Pis Min                  -7.8914375
Policy mu Mean               0.036338907
Policy mu Std                0.90620404
Policy mu Max                3.1936023
Policy mu Min                -2.9543836
Policy log std Mean          -0.41760126
Policy log std Std           0.16957945
Policy log std Max           -0.08475706
Policy log std Min           -1.1724659
Z mean eval                  1.3879149
Z variance eval              0.011940147
total_rewards                [ 982.91623684 1897.77114786 2527.77747186 2201.10520654  844.81238132
 1020.33066444  810.60503808 3005.48683838  766.25695024  793.87062186]
total_rewards_mean           1485.093255741239
total_rewards_std            800.5846313269953
total_rewards_max            3005.486838375102
total_rewards_min            766.2569502357379
Number of train steps total  353000
Number of env steps total    1767000
Number of rollouts total     0
Train Time (s)               33.0195273081772
(Previous) Eval Time (s)     14.898216285277158
Sample Time (s)              23.08788240235299
Epoch Time (s)               71.00562599580735
Total Train Time (s)         22326.23724842863
Epoch                        352
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:14:50.665058 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #352 | Epoch Duration: 70.54928779602051
2020-01-11 06:14:50.665309 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #352 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3872485
Z variance train             0.011940693
KL Divergence                17.12626
KL Loss                      1.7126261
QF Loss                      92.06914
VF Loss                      239.7478
Policy Loss                  -1226.8202
Q Predictions Mean           1227.1709
Q Predictions Std            360.6089
Q Predictions Max            1527.3909
Q Predictions Min            -11.276768
V Predictions Mean           1227.4491
V Predictions Std            358.4411
V Predictions Max            1537.051
V Predictions Min            -1.4232101
Log Pis Mean                 -0.25806838
Log Pis Std                  1.9409862
Log Pis Max                  5.277231
Log Pis Min                  -4.7421594
Policy mu Mean               -0.060442265
Policy mu Std                0.8982974
Policy mu Max                2.8767996
Policy mu Min                -2.8020654
Policy log std Mean          -0.40476382
Policy log std Std           0.1545768
Policy log std Max           -0.054648876
Policy log std Min           -0.9816627
Z mean eval                  1.3809812
Z variance eval              0.010759893
total_rewards                [ 853.23754538 1026.01395738 1339.79880286  991.50078879 1789.9034055
 1208.59323818 1022.16803838  845.9307152   852.11160459  761.05054085]
total_rewards_mean           1069.030863710738
total_rewards_std            293.38608055655584
total_rewards_max            1789.9034055043326
total_rewards_min            761.0505408469899
Number of train steps total  354000
Number of env steps total    1772000
Number of rollouts total     0
Train Time (s)               33.06505060987547
(Previous) Eval Time (s)     14.441547592170537
Sample Time (s)              22.552813629619777
Epoch Time (s)               70.05941183166578
Total Train Time (s)         22391.13336600922
Epoch                        353
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:15:55.563277 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #353 | Epoch Duration: 64.89766430854797
2020-01-11 06:15:55.563480 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #353 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3809017
Z variance train             0.010772752
KL Divergence                17.155521
KL Loss                      1.7155522
QF Loss                      149.51877
VF Loss                      88.463356
Policy Loss                  -1152.4663
Q Predictions Mean           1150.2019
Q Predictions Std            412.34628
Q Predictions Max            1487.102
Q Predictions Min            2.8766298
V Predictions Mean           1152.4209
V Predictions Std            412.23016
V Predictions Max            1467.8257
V Predictions Min            2.999277
Log Pis Mean                 -0.36492395
Log Pis Std                  2.0282123
Log Pis Max                  7.655431
Log Pis Min                  -4.6260276
Policy mu Mean               0.09687772
Policy mu Std                0.8856161
Policy mu Max                2.283509
Policy mu Min                -2.6346786
Policy log std Mean          -0.41017365
Policy log std Std           0.1651703
Policy log std Max           0.10048142
Policy log std Min           -0.9528809
Z mean eval                  1.3479027
Z variance eval              0.016766544
total_rewards                [1106.701829   1588.08686593  918.26299183 2247.5810092  1383.40759802
 1379.27697335 1672.95500612 1874.54473514 2917.47155214 1261.41695379]
total_rewards_mean           1634.9705514516863
total_rewards_std            560.5425998848458
total_rewards_max            2917.4715521422045
total_rewards_min            918.2629918306286
Number of train steps total  355000
Number of env steps total    1777000
Number of rollouts total     0
Train Time (s)               34.393181235995144
(Previous) Eval Time (s)     9.27944247610867
Sample Time (s)              23.410208912100643
Epoch Time (s)               67.08283262420446
Total Train Time (s)         22465.60461803805
Epoch                        354
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:17:10.038338 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #354 | Epoch Duration: 74.47468495368958
2020-01-11 06:17:10.038589 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #354 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3480031
Z variance train             0.016773593
KL Divergence                15.644676
KL Loss                      1.5644677
QF Loss                      434.50812
VF Loss                      121.17159
Policy Loss                  -1157.016
Q Predictions Mean           1156.6003
Q Predictions Std            453.3451
Q Predictions Max            1505.9441
Q Predictions Min            0.17989641
V Predictions Mean           1159.384
V Predictions Std            451.8837
V Predictions Max            1513.1692
V Predictions Min            4.959029
Log Pis Mean                 -0.16992694
Log Pis Std                  2.167166
Log Pis Max                  13.332423
Log Pis Min                  -4.0677047
Policy mu Mean               -0.10956609
Policy mu Std                0.91892093
Policy mu Max                1.9710428
Policy mu Min                -3.5331686
Policy log std Mean          -0.40486884
Policy log std Std           0.17135246
Policy log std Max           0.14256358
Policy log std Min           -1.343232
Z mean eval                  1.3520688
Z variance eval              0.017605942
total_rewards                [1237.86229924 2770.10077665 1584.08914263  887.79870401  817.19117119
 1091.16967527 2814.73163826 2866.64040599  810.29456455  809.99293443]
total_rewards_mean           1568.9871312220082
total_rewards_std            848.3831725263374
total_rewards_max            2866.6404059903534
total_rewards_min            809.9929344267805
Number of train steps total  356000
Number of env steps total    1782000
Number of rollouts total     0
Train Time (s)               35.029075247235596
(Previous) Eval Time (s)     16.67093777190894
Sample Time (s)              24.22453672485426
Epoch Time (s)               75.9245497439988
Total Train Time (s)         22540.105370652862
Epoch                        355
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:18:24.545301 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #355 | Epoch Duration: 74.50649404525757
2020-01-11 06:18:24.545703 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #355 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3507254
Z variance train             0.01762876
KL Divergence                15.157396
KL Loss                      1.5157397
QF Loss                      383.23987
VF Loss                      48.52217
Policy Loss                  -1130.926
Q Predictions Mean           1128.6799
Q Predictions Std            441.46384
Q Predictions Max            1507.044
Q Predictions Min            0.8469238
V Predictions Mean           1131.301
V Predictions Std            438.5912
V Predictions Max            1499.5293
V Predictions Min            1.0093384
Log Pis Mean                 -0.403218
Log Pis Std                  2.12873
Log Pis Max                  11.33509
Log Pis Min                  -6.310993
Policy mu Mean               0.025091866
Policy mu Std                0.9186582
Policy mu Max                2.6680422
Policy mu Min                -3.0987558
Policy log std Mean          -0.40044752
Policy log std Std           0.16667466
Policy log std Max           -0.053123623
Policy log std Min           -0.9983929
Z mean eval                  1.3286248
Z variance eval              0.020781647
total_rewards                [2025.03573199 2754.99603251 2762.0899071   786.12565236  837.49191101
  835.27531116 1018.3596203  1411.97004124  792.45590484  991.09500853]
total_rewards_mean           1421.489512103311
total_rewards_std            759.7125547256655
total_rewards_max            2762.0899071037456
total_rewards_min            786.1256523641816
Number of train steps total  357000
Number of env steps total    1787000
Number of rollouts total     0
Train Time (s)               35.905920998193324
(Previous) Eval Time (s)     15.25248290784657
Sample Time (s)              23.21044586552307
Epoch Time (s)               74.36884977156296
Total Train Time (s)         22613.466118576005
Epoch                        356
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:19:37.908409 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #356 | Epoch Duration: 73.36246156692505
2020-01-11 06:19:37.908616 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #356 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3291395
Z variance train             0.020872977
KL Divergence                14.85067
KL Loss                      1.485067
QF Loss                      176.97455
VF Loss                      45.87792
Policy Loss                  -1142.5398
Q Predictions Mean           1139.7123
Q Predictions Std            446.37595
Q Predictions Max            1501.9912
Q Predictions Min            -2.047804
V Predictions Mean           1142.9651
V Predictions Std            446.09143
V Predictions Max            1498.6436
V Predictions Min            4.051429
Log Pis Mean                 -0.6373395
Log Pis Std                  1.8904787
Log Pis Max                  5.3809705
Log Pis Min                  -4.742097
Policy mu Mean               -0.012677923
Policy mu Std                0.816369
Policy mu Max                2.0261183
Policy mu Min                -2.802599
Policy log std Mean          -0.379704
Policy log std Std           0.16398498
Policy log std Max           -0.09122458
Policy log std Min           -0.9078932
Z mean eval                  1.3660784
Z variance eval              0.021743143
total_rewards                [2837.80002584 2974.48673306 2990.52892444 1112.13911359 2850.68825964
 1103.54464286 2932.92481166 2850.17512556 2856.24822005 2137.60936094]
total_rewards_mean           2464.6145217650123
total_rewards_std            716.5792184368687
total_rewards_max            2990.528924440484
total_rewards_min            1103.5446428646662
Number of train steps total  358000
Number of env steps total    1792000
Number of rollouts total     0
Train Time (s)               34.6328856558539
(Previous) Eval Time (s)     14.245734992902726
Sample Time (s)              24.82456513494253
Epoch Time (s)               73.70318578369915
Total Train Time (s)         22698.54998669168
Epoch                        357
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:21:02.996440 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #357 | Epoch Duration: 85.08762240409851
2020-01-11 06:21:02.996696 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #357 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3692803
Z variance train             0.021802872
KL Divergence                14.872384
KL Loss                      1.4872384
QF Loss                      154.29922
VF Loss                      151.59813
Policy Loss                  -1239.0471
Q Predictions Mean           1235.6344
Q Predictions Std            395.8768
Q Predictions Max            1511.91
Q Predictions Min            -20.2793
V Predictions Mean           1229.5099
V Predictions Std            394.635
V Predictions Max            1506.9846
V Predictions Min            -6.2424846
Log Pis Mean                 -0.27436328
Log Pis Std                  2.1193666
Log Pis Max                  6.9000382
Log Pis Min                  -4.186369
Policy mu Mean               -0.04707479
Policy mu Std                0.9193314
Policy mu Max                2.527113
Policy mu Min                -2.7709403
Policy log std Mean          -0.3963262
Policy log std Std           0.15202017
Policy log std Max           -0.09182878
Policy log std Min           -0.954612
Z mean eval                  1.3278666
Z variance eval              0.020238923
total_rewards                [1884.99477537 1972.84449447 1424.05226072 1327.80050362  974.26570193
 2901.45333865  871.9541906  1605.24835846 1500.57315438 1063.9890566 ]
total_rewards_mean           1552.717583479522
total_rewards_std            567.0559780229212
total_rewards_max            2901.4533386505755
total_rewards_min            871.9541905961498
Number of train steps total  359000
Number of env steps total    1797000
Number of rollouts total     0
Train Time (s)               35.272150326985866
(Previous) Eval Time (s)     25.629762563854456
Sample Time (s)              23.51165440073237
Epoch Time (s)               84.41356729157269
Total Train Time (s)         22773.042794826906
Epoch                        358
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:22:17.493161 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #358 | Epoch Duration: 74.4962911605835
2020-01-11 06:22:17.493364 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #358 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3277206
Z variance train             0.020130819
KL Divergence                15.091
KL Loss                      1.5091
QF Loss                      307.4583
VF Loss                      56.60963
Policy Loss                  -1181.7606
Q Predictions Mean           1179.0071
Q Predictions Std            446.58594
Q Predictions Max            1568.6857
Q Predictions Min            3.8763924
V Predictions Mean           1183.7626
V Predictions Std            443.5602
V Predictions Max            1570.5039
V Predictions Min            1.3462621
Log Pis Mean                 -0.18159695
Log Pis Std                  2.179462
Log Pis Max                  7.796667
Log Pis Min                  -5.8849087
Policy mu Mean               -0.09965516
Policy mu Std                0.93931407
Policy mu Max                2.7009914
Policy mu Min                -3.684736
Policy log std Mean          -0.40079245
Policy log std Std           0.17393783
Policy log std Max           0.01956287
Policy log std Min           -1.1676186
Z mean eval                  1.3496187
Z variance eval              0.021656903
total_rewards                [2102.35261537 2247.24742812 2238.20726919 2383.25455723 2633.4142837
 2826.55038018 1787.94949373 1474.55574057 2947.01089614 2548.64928923]
total_rewards_mean           2318.9191953458762
total_rewards_std            431.4442638894203
total_rewards_max            2947.0108961372084
total_rewards_min            1474.5557405739996
Number of train steps total  360000
Number of env steps total    1802000
Number of rollouts total     0
Train Time (s)               34.90488436166197
(Previous) Eval Time (s)     15.712082272861153
Sample Time (s)              24.47318290406838
Epoch Time (s)               75.0901495385915
Total Train Time (s)         22855.54644455947
Epoch                        359
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:23:40.000734 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #359 | Epoch Duration: 82.50722670555115
2020-01-11 06:23:40.000923 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #359 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3484102
Z variance train             0.021690687
KL Divergence                15.156212
KL Loss                      1.5156212
QF Loss                      454.43
VF Loss                      110.42781
Policy Loss                  -1227.3816
Q Predictions Mean           1221.9344
Q Predictions Std            366.91113
Q Predictions Max            1499.0109
Q Predictions Min            -0.6052664
V Predictions Mean           1224.4658
V Predictions Std            366.74625
V Predictions Max            1489.5375
V Predictions Min            4.205428
Log Pis Mean                 -0.4552632
Log Pis Std                  1.936161
Log Pis Max                  6.0274696
Log Pis Min                  -4.9139104
Policy mu Mean               -0.10383437
Policy mu Std                0.86517817
Policy mu Max                2.56727
Policy mu Min                -2.6678667
Policy log std Mean          -0.39404523
Policy log std Std           0.17163353
Policy log std Max           0.0070236325
Policy log std Min           -1.1501696
Z mean eval                  1.3076853
Z variance eval              0.019338753
total_rewards                [ 815.80656778 1876.01833213  965.47659336 2868.11983932 1795.89966399
 2266.82575381 2296.60148611 3130.88595303 2094.40967686  788.36728555]
total_rewards_mean           1889.8411151942298
total_rewards_std            779.5448612074244
total_rewards_max            3130.8859530250643
total_rewards_min            788.3672855517987
Number of train steps total  361000
Number of env steps total    1807000
Number of rollouts total     0
Train Time (s)               34.7873713709414
(Previous) Eval Time (s)     23.128770464099944
Sample Time (s)              23.849695664830506
Epoch Time (s)               81.76583749987185
Total Train Time (s)         22933.653125583194
Epoch                        360
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:24:58.114076 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #360 | Epoch Duration: 78.11301374435425
2020-01-11 06:24:58.114271 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #360 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3098543
Z variance train             0.019377645
KL Divergence                15.363179
KL Loss                      1.536318
QF Loss                      139.47421
VF Loss                      87.51271
Policy Loss                  -1210.9812
Q Predictions Mean           1209.4635
Q Predictions Std            409.54422
Q Predictions Max            1520.8486
Q Predictions Min            7.5225563
V Predictions Mean           1209.9343
V Predictions Std            410.99414
V Predictions Max            1520.7014
V Predictions Min            4.8960204
Log Pis Mean                 -0.37831402
Log Pis Std                  1.9530278
Log Pis Max                  5.5086794
Log Pis Min                  -5.9783816
Policy mu Mean               0.043186378
Policy mu Std                0.87137145
Policy mu Max                2.378407
Policy mu Min                -3.0182383
Policy log std Mean          -0.40878877
Policy log std Std           0.16351534
Policy log std Max           -0.09378831
Policy log std Min           -1.1009606
Z mean eval                  1.3070767
Z variance eval              0.018554814
total_rewards                [2885.2289531  1203.85836828 2890.73839434 1969.58586037  822.42809387
 2189.50543755 2952.56589048 1127.75804765 2872.67176608 2919.41962186]
total_rewards_mean           2183.3760433579228
total_rewards_std            810.7532379163748
total_rewards_max            2952.5658904792213
total_rewards_min            822.4280938687963
Number of train steps total  362000
Number of env steps total    1812000
Number of rollouts total     0
Train Time (s)               35.65914657432586
(Previous) Eval Time (s)     19.475570197682828
Sample Time (s)              24.775745268911123
Epoch Time (s)               79.91046204091981
Total Train Time (s)         23016.866249842104
Epoch                        361
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:26:21.330185 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #361 | Epoch Duration: 83.21573686599731
2020-01-11 06:26:21.330528 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #361 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3094422
Z variance train             0.018644677
KL Divergence                14.910905
KL Loss                      1.4910905
QF Loss                      141.74506
VF Loss                      77.26355
Policy Loss                  -1132.113
Q Predictions Mean           1129.4424
Q Predictions Std            424.4736
Q Predictions Max            1450.1902
Q Predictions Min            1.1157862
V Predictions Mean           1127.1272
V Predictions Std            423.58783
V Predictions Max            1445.9384
V Predictions Min            0.49820113
Log Pis Mean                 -0.23298036
Log Pis Std                  2.03598
Log Pis Max                  8.178014
Log Pis Min                  -4.9573727
Policy mu Mean               -0.016040718
Policy mu Std                0.88193345
Policy mu Max                2.3112104
Policy mu Min                -2.6641095
Policy log std Mean          -0.37739134
Policy log std Std           0.15065786
Policy log std Max           -0.08639248
Policy log std Min           -0.9237689
Z mean eval                  1.306853
Z variance eval              0.032050967
total_rewards                [2930.36444284 1274.2816517  2930.48140137 2949.21955091 3006.10072782
 2899.47027199 2038.00565155 1574.43797215 2972.31663128 2906.33892869]
total_rewards_mean           2548.101723030668
total_rewards_std            626.544996207926
total_rewards_max            3006.100727817922
total_rewards_min            1274.2816517024216
Number of train steps total  363000
Number of env steps total    1817000
Number of rollouts total     0
Train Time (s)               34.863441521301866
(Previous) Eval Time (s)     22.780388216022402
Sample Time (s)              25.502702981699258
Epoch Time (s)               83.14653271902353
Total Train Time (s)         23103.41349985171
Epoch                        362
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:27:47.880176 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #362 | Epoch Duration: 86.5494396686554
2020-01-11 06:27:47.880373 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #362 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3094933
Z variance train             0.032099076
KL Divergence                14.055868
KL Loss                      1.4055868
QF Loss                      146.46954
VF Loss                      75.349464
Policy Loss                  -1086.1217
Q Predictions Mean           1086.1539
Q Predictions Std            376.85452
Q Predictions Max            1395.4415
Q Predictions Min            5.3616114
V Predictions Mean           1088.2848
V Predictions Std            376.60944
V Predictions Max            1396.5397
V Predictions Min            -1.4809322
Log Pis Mean                 -0.7187807
Log Pis Std                  1.7016928
Log Pis Max                  5.8338118
Log Pis Min                  -4.87833
Policy mu Mean               0.005645352
Policy mu Std                0.801383
Policy mu Max                2.224031
Policy mu Min                -2.539369
Policy log std Mean          -0.38609323
Policy log std Std           0.16203897
Policy log std Max           -0.073973745
Policy log std Min           -1.0689658
Z mean eval                  1.3129203
Z variance eval              0.02072228
total_rewards                [2949.05681046 2639.04789524 2579.45057726 3016.22271525 2959.49706258
 2495.82302345 2696.41121619 2906.77035214 1661.05308759 2331.03874047]
total_rewards_mean           2623.43714806485
total_rewards_std            385.8745442353132
total_rewards_max            3016.222715250866
total_rewards_min            1661.0530875885663
Number of train steps total  364000
Number of env steps total    1822000
Number of rollouts total     0
Train Time (s)               35.09339044895023
(Previous) Eval Time (s)     26.182911964133382
Sample Time (s)              24.337378789205104
Epoch Time (s)               85.61368120228872
Total Train Time (s)         23189.58795808535
Epoch                        363
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:29:14.059560 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #363 | Epoch Duration: 86.17900609970093
2020-01-11 06:29:14.059918 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #363 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3099425
Z variance train             0.020705897
KL Divergence                14.465215
KL Loss                      1.4465215
QF Loss                      103.167076
VF Loss                      55.994408
Policy Loss                  -1153.937
Q Predictions Mean           1153.7286
Q Predictions Std            418.8419
Q Predictions Max            1478.2643
Q Predictions Min            2.9445117
V Predictions Mean           1158.2196
V Predictions Std            420.12973
V Predictions Max            1482.3717
V Predictions Min            5.630689
Log Pis Mean                 -0.42827952
Log Pis Std                  1.9327173
Log Pis Max                  6.7836943
Log Pis Min                  -6.410944
Policy mu Mean               0.023332484
Policy mu Std                0.8658477
Policy mu Max                2.5842266
Policy mu Min                -2.6613936
Policy log std Mean          -0.41540697
Policy log std Std           0.17377065
Policy log std Max           -0.024911717
Policy log std Min           -1.1539309
Z mean eval                  1.285285
Z variance eval              0.024343425
total_rewards                [2798.97273044 1421.27075745 2994.41140578 2895.89853064 1406.10189078
 2640.14640338 2738.7853435  1684.25894991 1889.47006099 2700.8146506 ]
total_rewards_mean           2317.0130723473776
total_rewards_std            605.9007277788361
total_rewards_max            2994.4114057835573
total_rewards_min            1406.1018907798075
Number of train steps total  365000
Number of env steps total    1827000
Number of rollouts total     0
Train Time (s)               33.91590176708996
(Previous) Eval Time (s)     26.747851757798344
Sample Time (s)              24.925767535343766
Epoch Time (s)               85.58952106023207
Total Train Time (s)         23270.921820751857
Epoch                        364
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:30:35.396825 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #364 | Epoch Duration: 81.33665704727173
2020-01-11 06:30:35.397062 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #364 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2861588
Z variance train             0.024420876
KL Divergence                14.168227
KL Loss                      1.4168228
QF Loss                      1029.2363
VF Loss                      92.84311
Policy Loss                  -1247.539
Q Predictions Mean           1243.1252
Q Predictions Std            362.1143
Q Predictions Max            1508.1849
Q Predictions Min            -3.7565336
V Predictions Mean           1245.0485
V Predictions Std            357.80658
V Predictions Max            1515.8245
V Predictions Min            -8.648117
Log Pis Mean                 -0.22342494
Log Pis Std                  2.1910026
Log Pis Max                  7.476329
Log Pis Min                  -5.2448773
Policy mu Mean               0.02333721
Policy mu Std                0.93278474
Policy mu Max                2.4873228
Policy mu Min                -3.0510066
Policy log std Mean          -0.4150765
Policy log std Std           0.16315605
Policy log std Max           0.043902844
Policy log std Min           -1.2109582
Z mean eval                  1.2605982
Z variance eval              0.019872868
total_rewards                [ 976.62215668 2096.26109944 1015.02237708 1221.8129795   882.98954744
 3135.1442208  2068.86348658 2669.69370515 1275.37651941  934.33258661]
total_rewards_mean           1627.6118678687458
total_rewards_std            767.8422997393319
total_rewards_max            3135.1442208002663
total_rewards_min            882.9895474418968
Number of train steps total  366000
Number of env steps total    1832000
Number of rollouts total     0
Train Time (s)               32.910031952895224
(Previous) Eval Time (s)     22.494619882199913
Sample Time (s)              23.201858999673277
Epoch Time (s)               78.60651083476841
Total Train Time (s)         23341.930407424923
Epoch                        365
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:31:46.411776 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #365 | Epoch Duration: 71.01452493667603
2020-01-11 06:31:46.412055 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #365 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2630259
Z variance train             0.01976568
KL Divergence                14.178238
KL Loss                      1.4178238
QF Loss                      194.18631
VF Loss                      87.33501
Policy Loss                  -1161.8607
Q Predictions Mean           1157.4827
Q Predictions Std            415.78625
Q Predictions Max            1500.2769
Q Predictions Min            -5.529807
V Predictions Mean           1160.6008
V Predictions Std            415.15436
V Predictions Max            1507.4922
V Predictions Min            0.6062472
Log Pis Mean                 -0.52859795
Log Pis Std                  2.1083574
Log Pis Max                  11.964316
Log Pis Min                  -4.626698
Policy mu Mean               0.124232285
Policy mu Std                0.8662427
Policy mu Max                2.18207
Policy mu Min                -3.5752985
Policy log std Mean          -0.3945968
Policy log std Std           0.15400693
Policy log std Max           -0.0024683475
Policy log std Min           -0.991989
Z mean eval                  1.2691485
Z variance eval              0.022046244
total_rewards                [1397.26482204 1254.49680309 3123.55688478 2271.40751703 1424.49158914
 1692.21332079 1927.15143506 2008.33973211 1728.63073197 3180.41148913]
total_rewards_mean           2000.7964325121575
total_rewards_std            644.4712624054225
total_rewards_max            3180.4114891308327
total_rewards_min            1254.4968030913997
Number of train steps total  367000
Number of env steps total    1837000
Number of rollouts total     0
Train Time (s)               33.079624156001955
(Previous) Eval Time (s)     14.902323015965521
Sample Time (s)              23.42312674690038
Epoch Time (s)               71.40507391886786
Total Train Time (s)         23417.203149566427
Epoch                        366
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:33:01.688999 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #366 | Epoch Duration: 75.27661633491516
2020-01-11 06:33:01.689284 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #366 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2706051
Z variance train             0.02209354
KL Divergence                13.837836
KL Loss                      1.3837837
QF Loss                      159.5125
VF Loss                      57.583466
Policy Loss                  -1183.8683
Q Predictions Mean           1181.6138
Q Predictions Std            368.67352
Q Predictions Max            1468.9625
Q Predictions Min            4.661851
V Predictions Mean           1183.986
V Predictions Std            367.54172
V Predictions Max            1484.511
V Predictions Min            3.0383642
Log Pis Mean                 -0.46702278
Log Pis Std                  1.9254057
Log Pis Max                  5.268526
Log Pis Min                  -5.52385
Policy mu Mean               -0.018021667
Policy mu Std                0.84912837
Policy mu Max                2.6349392
Policy mu Min                -3.0050502
Policy log std Mean          -0.3933293
Policy log std Std           0.16321258
Policy log std Max           -0.057595134
Policy log std Min           -1.1392419
Z mean eval                  1.2561197
Z variance eval              0.0144667905
total_rewards                [1289.23519896 1301.11225718 2445.70627436 1030.91476298 2922.9493077
 2185.10635101 1763.92688027 2106.04225106 3066.82986284 1244.19630415]
total_rewards_mean           1935.6019450503131
total_rewards_std            689.3751017987267
total_rewards_max            3066.829862837661
total_rewards_min            1030.9147629751126
Number of train steps total  368000
Number of env steps total    1842000
Number of rollouts total     0
Train Time (s)               33.03433510893956
(Previous) Eval Time (s)     18.773550142068416
Sample Time (s)              22.982151557691395
Epoch Time (s)               74.79003680869937
Total Train Time (s)         23492.807066450827
Epoch                        367
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:34:17.300724 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #367 | Epoch Duration: 75.61119771003723
2020-01-11 06:34:17.301025 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #367 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.252442
Z variance train             0.01448815
KL Divergence                14.8521595
KL Loss                      1.485216
QF Loss                      92.656784
VF Loss                      71.29322
Policy Loss                  -1270.2228
Q Predictions Mean           1271.4852
Q Predictions Std            314.57568
Q Predictions Max            1501.305
Q Predictions Min            -0.13455778
V Predictions Mean           1270.3862
V Predictions Std            312.82495
V Predictions Max            1500.7812
V Predictions Min            4.8285193
Log Pis Mean                 -0.5109006
Log Pis Std                  2.1598852
Log Pis Max                  11.194794
Log Pis Min                  -5.5168033
Policy mu Mean               0.073124334
Policy mu Std                0.8326256
Policy mu Max                2.2141538
Policy mu Min                -3.5736299
Policy log std Mean          -0.39055693
Policy log std Std           0.16232659
Policy log std Max           -0.05134523
Policy log std Min           -1.1642122
Z mean eval                  1.2615999
Z variance eval              0.013347271
total_rewards                [1143.52893367  814.98396981 1727.03194863  808.43229037 2928.3644842
  870.20491131 1864.69372604 1852.65079845 3060.94049624 1005.58641217]
total_rewards_mean           1607.6417970905425
total_rewards_std            799.0914529746696
total_rewards_max            3060.940496236226
total_rewards_min            808.4322903719276
Number of train steps total  369000
Number of env steps total    1847000
Number of rollouts total     0
Train Time (s)               32.76726493379101
(Previous) Eval Time (s)     19.59436800284311
Sample Time (s)              23.427661593537778
Epoch Time (s)               75.7892945301719
Total Train Time (s)         23564.719324274454
Epoch                        368
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:35:29.221517 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #368 | Epoch Duration: 71.9202651977539
2020-01-11 06:35:29.221782 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #368 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2628132
Z variance train             0.013394711
KL Divergence                15.356342
KL Loss                      1.5356343
QF Loss                      132.51349
VF Loss                      228.82733
Policy Loss                  -1154.114
Q Predictions Mean           1152.1965
Q Predictions Std            436.19455
Q Predictions Max            1518.8649
Q Predictions Min            -7.69135
V Predictions Mean           1155.2073
V Predictions Std            434.14227
V Predictions Max            1534.1907
V Predictions Min            -5.2976265
Log Pis Mean                 -0.19816294
Log Pis Std                  1.9757687
Log Pis Max                  6.7661896
Log Pis Min                  -4.6543365
Policy mu Mean               -0.057391673
Policy mu Std                0.8960991
Policy mu Max                2.5009818
Policy mu Min                -2.7188673
Policy log std Mean          -0.4062027
Policy log std Std           0.18793684
Policy log std Max           0.07337153
Policy log std Min           -1.5017639
Z mean eval                  1.2587645
Z variance eval              0.011572225
total_rewards                [ 972.72761927 1751.95305019 3133.00992432 1553.5370845   778.34498927
 3002.91231736 2624.35058267 1337.90882496 2590.05040145 3017.58478895]
total_rewards_mean           2076.237958293247
total_rewards_std            851.5764750636745
total_rewards_max            3133.0099243161067
total_rewards_min            778.344989272755
Number of train steps total  370000
Number of env steps total    1852000
Number of rollouts total     0
Train Time (s)               33.09053873317316
(Previous) Eval Time (s)     15.725003141909838
Sample Time (s)              22.659103060141206
Epoch Time (s)               71.4746449352242
Total Train Time (s)         23640.850671063177
Epoch                        369
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:36:45.352261 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #369 | Epoch Duration: 76.13032388687134
2020-01-11 06:36:45.352428 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #369 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2586737
Z variance train             0.011551788
KL Divergence                15.796406
KL Loss                      1.5796406
QF Loss                      267.79517
VF Loss                      60.370815
Policy Loss                  -1124.0817
Q Predictions Mean           1127.0566
Q Predictions Std            383.3097
Q Predictions Max            1447.3322
Q Predictions Min            8.70988
V Predictions Mean           1125.5393
V Predictions Std            383.98334
V Predictions Max            1452.732
V Predictions Min            2.0983093
Log Pis Mean                 -0.54841936
Log Pis Std                  1.8733021
Log Pis Max                  5.8981466
Log Pis Min                  -5.5082173
Policy mu Mean               0.020905653
Policy mu Std                0.8287642
Policy mu Max                2.7327926
Policy mu Min                -2.6219792
Policy log std Mean          -0.3984172
Policy log std Std           0.18181388
Policy log std Max           -0.08802678
Policy log std Min           -1.1355741
Z mean eval                  1.2346594
Z variance eval              0.013923412
total_rewards                [2921.3233321  1160.59672941  935.424443   2866.90888788 2894.09591903
 2970.44697875 1910.47613621 1790.54115703 2210.87405368 1760.80370499]
total_rewards_mean           2142.1491342104027
total_rewards_std            716.307756482884
total_rewards_max            2970.4469787537496
total_rewards_min            935.4244430023494
Number of train steps total  371000
Number of env steps total    1857000
Number of rollouts total     0
Train Time (s)               32.96066749794409
(Previous) Eval Time (s)     20.38035613996908
Sample Time (s)              23.97468065842986
Epoch Time (s)               77.31570429634303
Total Train Time (s)         23719.70303899655
Epoch                        370
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:38:04.208671 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #370 | Epoch Duration: 78.85610246658325
2020-01-11 06:38:04.208858 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #370 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2343476
Z variance train             0.013949958
KL Divergence                15.455565
KL Loss                      1.5455565
QF Loss                      85.79424
VF Loss                      50.87129
Policy Loss                  -1164.6356
Q Predictions Mean           1162.5178
Q Predictions Std            375.5102
Q Predictions Max            1460.7474
Q Predictions Min            -0.032771647
V Predictions Mean           1165.2283
V Predictions Std            373.63837
V Predictions Max            1466.5348
V Predictions Min            5.721894
Log Pis Mean                 -0.39627677
Log Pis Std                  2.137612
Log Pis Max                  6.993444
Log Pis Min                  -5.648664
Policy mu Mean               -0.14296369
Policy mu Std                0.88481563
Policy mu Max                1.9931469
Policy mu Min                -3.0254815
Policy log std Mean          -0.391534
Policy log std Std           0.18028349
Policy log std Max           -0.014410883
Policy log std Min           -1.2948049
Z mean eval                  1.2622806
Z variance eval              0.009422321
total_rewards                [2954.8764172  2801.93817756 2973.72954597 1285.04288801 3043.34837649
 2310.66779438 1808.10393596 2995.51110154 2999.77024182 1724.0643738 ]
total_rewards_mean           2489.7052852732204
total_rewards_std            624.8785338997938
total_rewards_max            3043.3483764895304
total_rewards_min            1285.0428880147872
Number of train steps total  372000
Number of env steps total    1862000
Number of rollouts total     0
Train Time (s)               32.915891837794334
(Previous) Eval Time (s)     21.920448207762092
Sample Time (s)              22.968044369015843
Epoch Time (s)               77.80438441457227
Total Train Time (s)         23800.114678115584
Epoch                        371
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:39:24.624672 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #371 | Epoch Duration: 80.41566324234009
2020-01-11 06:39:24.624864 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #371 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2597353
Z variance train             0.009424937
KL Divergence                16.422705
KL Loss                      1.6422704
QF Loss                      284.02136
VF Loss                      42.33726
Policy Loss                  -1164.8994
Q Predictions Mean           1164.1838
Q Predictions Std            376.77383
Q Predictions Max            1464.5594
Q Predictions Min            -16.582071
V Predictions Mean           1166.6052
V Predictions Std            375.20554
V Predictions Max            1470.2084
V Predictions Min            3.3530617
Log Pis Mean                 -0.39416677
Log Pis Std                  1.93979
Log Pis Max                  5.632192
Log Pis Min                  -5.9282455
Policy mu Mean               0.020405779
Policy mu Std                0.8636769
Policy mu Max                2.5592737
Policy mu Min                -2.80366
Policy log std Mean          -0.4051609
Policy log std Std           0.17675744
Policy log std Max           0.036874503
Policy log std Min           -1.1297143
Z mean eval                  1.2177067
Z variance eval              0.011987755
total_rewards                [1387.07082806 1721.90572147 2975.22548477 2367.2128483  1983.32129887
 1215.83891508 1547.89107031 1301.13235064 2290.04980608 2249.25120609]
total_rewards_mean           1903.8899529680534
total_rewards_std            538.5923805442328
total_rewards_max            2975.2254847664335
total_rewards_min            1215.8389150807036
Number of train steps total  373000
Number of env steps total    1867000
Number of rollouts total     0
Train Time (s)               32.8065400137566
(Previous) Eval Time (s)     24.531419727951288
Sample Time (s)              22.06881119357422
Epoch Time (s)               79.40677093528211
Total Train Time (s)         23873.736510873772
Epoch                        372
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:40:38.250119 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #372 | Epoch Duration: 73.62511038780212
2020-01-11 06:40:38.250357 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #372 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2171679
Z variance train             0.012019503
KL Divergence                15.580651
KL Loss                      1.5580652
QF Loss                      213.34814
VF Loss                      134.10425
Policy Loss                  -1209.206
Q Predictions Mean           1209.9443
Q Predictions Std            407.83124
Q Predictions Max            1507.9589
Q Predictions Min            3.3124564
V Predictions Mean           1213.922
V Predictions Std            409.85522
V Predictions Max            1510.1978
V Predictions Min            5.306715
Log Pis Mean                 -0.46303254
Log Pis Std                  1.871872
Log Pis Max                  6.5008264
Log Pis Min                  -5.9478188
Policy mu Mean               -0.008505133
Policy mu Std                0.83893037
Policy mu Max                2.6580157
Policy mu Min                -2.6709352
Policy log std Mean          -0.39791933
Policy log std Std           0.17044419
Policy log std Max           0.006122023
Policy log std Min           -1.3245572
Z mean eval                  1.2204044
Z variance eval              0.01356619
total_rewards                [1384.70874992 2732.25056361 1383.36995779  813.58566597  844.64443166
 2821.22739758 1456.61299673 1389.5043307  2868.89902436 2462.20946372]
total_rewards_mean           1815.701258205546
total_rewards_std            775.163463874889
total_rewards_max            2868.8990243616267
total_rewards_min            813.5856659746383
Number of train steps total  374000
Number of env steps total    1872000
Number of rollouts total     0
Train Time (s)               32.99870905606076
(Previous) Eval Time (s)     18.749471307732165
Sample Time (s)              23.228878178168088
Epoch Time (s)               74.97705854196101
Total Train Time (s)         23946.83022059733
Epoch                        373
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:41:51.347481 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #373 | Epoch Duration: 73.09695935249329
2020-01-11 06:41:51.347749 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #373 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2209308
Z variance train             0.013566347
KL Divergence                15.114486
KL Loss                      1.5114486
QF Loss                      67.33978
VF Loss                      41.616867
Policy Loss                  -1173.4473
Q Predictions Mean           1170.6682
Q Predictions Std            441.56165
Q Predictions Max            1494.0964
Q Predictions Min            -2.9474826
V Predictions Mean           1172.5222
V Predictions Std            441.00153
V Predictions Max            1495.6768
V Predictions Min            -3.5119545
Log Pis Mean                 -0.6536504
Log Pis Std                  1.7595949
Log Pis Max                  5.6048822
Log Pis Min                  -4.873255
Policy mu Mean               -0.020670163
Policy mu Std                0.83686936
Policy mu Max                2.0866935
Policy mu Min                -2.844453
Policy log std Mean          -0.38393643
Policy log std Std           0.16363819
Policy log std Max           -0.054922134
Policy log std Min           -1.0072476
Z mean eval                  1.2188021
Z variance eval              0.01228894
total_rewards                [ 795.7373771  1492.53118542 2040.76423553 1246.59165008 2067.31574475
  833.70949839  786.5367665  1221.27801048 3156.11290463 2208.67099395]
total_rewards_mean           1584.9248366827294
total_rewards_std            733.3479083561875
total_rewards_max            3156.1129046252686
total_rewards_min            786.5367664987159
Number of train steps total  375000
Number of env steps total    1877000
Number of rollouts total     0
Train Time (s)               33.31541301589459
(Previous) Eval Time (s)     16.869051716756076
Sample Time (s)              23.819365406408906
Epoch Time (s)               74.00383013905957
Total Train Time (s)         24019.20646173926
Epoch                        374
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:43:03.727810 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #374 | Epoch Duration: 72.3799135684967
2020-01-11 06:43:03.728323 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #374 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2179472
Z variance train             0.012261172
KL Divergence                15.421425
KL Loss                      1.5421425
QF Loss                      1521.8491
VF Loss                      174.6994
Policy Loss                  -1176.4121
Q Predictions Mean           1176.5051
Q Predictions Std            429.2319
Q Predictions Max            1514.8909
Q Predictions Min            4.099381
V Predictions Mean           1179.1542
V Predictions Std            426.8168
V Predictions Max            1512.0734
V Predictions Min            -16.04995
Log Pis Mean                 -0.5858019
Log Pis Std                  1.9476129
Log Pis Max                  8.757332
Log Pis Min                  -5.0098176
Policy mu Mean               0.10179929
Policy mu Std                0.8400552
Policy mu Max                3.4247627
Policy mu Min                -2.775874
Policy log std Mean          -0.38046908
Policy log std Std           0.16998072
Policy log std Max           -0.04944189
Policy log std Min           -1.2336107
Z mean eval                  1.2135087
Z variance eval              0.015928488
total_rewards                [1895.23143792 2737.69912055  887.09996609 1285.79064916 2944.46900211
 2707.9181697  3045.07942883 2638.51613426 3158.00943517 2775.97019277]
total_rewards_mean           2407.5783536567023
total_rewards_std            740.1888996670634
total_rewards_max            3158.0094351711427
total_rewards_min            887.0999660897426
Number of train steps total  376000
Number of env steps total    1882000
Number of rollouts total     0
Train Time (s)               32.772381572052836
(Previous) Eval Time (s)     15.24476463533938
Sample Time (s)              22.39275318617001
Epoch Time (s)               70.40989939356223
Total Train Time (s)         24092.93071424635
Epoch                        375
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:44:17.454165 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #375 | Epoch Duration: 73.72552442550659
2020-01-11 06:44:17.454288 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #375 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2136595
Z variance train             0.016012723
KL Divergence                14.157986
KL Loss                      1.4157985
QF Loss                      123.62535
VF Loss                      39.338615
Policy Loss                  -1248.0762
Q Predictions Mean           1248.6963
Q Predictions Std            434.8555
Q Predictions Max            1558.063
Q Predictions Min            -3.5473354
V Predictions Mean           1248.8201
V Predictions Std            434.9442
V Predictions Max            1561.8964
V Predictions Min            5.546673
Log Pis Mean                 -0.46440887
Log Pis Std                  2.017529
Log Pis Max                  7.508536
Log Pis Min                  -4.0491815
Policy mu Mean               -0.020786786
Policy mu Std                0.86443
Policy mu Max                2.1517546
Policy mu Min                -2.8820941
Policy log std Mean          -0.40755257
Policy log std Std           0.18223678
Policy log std Max           -0.06712891
Policy log std Min           -1.2053307
Z mean eval                  1.2067598
Z variance eval              0.01957842
total_rewards                [3013.67463721 2984.85878075  823.95892948 2859.55801692 2772.9039139
 2331.21171751 1627.52903619 2912.71439347 3088.66889781  815.70338122]
total_rewards_mean           2323.0781704450046
total_rewards_std            856.86772171369
total_rewards_max            3088.6688978070647
total_rewards_min            815.7033812164932
Number of train steps total  377000
Number of env steps total    1887000
Number of rollouts total     0
Train Time (s)               32.887973472010344
(Previous) Eval Time (s)     18.560071940999478
Sample Time (s)              22.47457612771541
Epoch Time (s)               73.92262154072523
Total Train Time (s)         24171.00972561119
Epoch                        376
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:45:35.538910 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #376 | Epoch Duration: 78.08448266983032
2020-01-11 06:45:35.539280 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #376 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.206205
Z variance train             0.019654235
KL Divergence                13.737144
KL Loss                      1.3737144
QF Loss                      368.4651
VF Loss                      231.23466
Policy Loss                  -1229.2098
Q Predictions Mean           1224.2688
Q Predictions Std            402.20697
Q Predictions Max            1553.1588
Q Predictions Min            -5.213516
V Predictions Mean           1228.2598
V Predictions Std            399.8142
V Predictions Max            1558.289
V Predictions Min            1.2703269
Log Pis Mean                 -0.4792714
Log Pis Std                  1.9392025
Log Pis Max                  8.856272
Log Pis Min                  -4.864285
Policy mu Mean               0.03948243
Policy mu Std                0.8310673
Policy mu Max                2.51682
Policy mu Min                -2.8628051
Policy log std Mean          -0.39730415
Policy log std Std           0.1786838
Policy log std Max           -0.029470205
Policy log std Min           -1.7552395
Z mean eval                  1.2146873
Z variance eval              0.020478375
total_rewards                [1306.45912238 3055.53442078 3114.16744881  822.22875424 3018.35842365
 1194.234109   1592.30455431  920.80266236 3040.28857394 1469.14395484]
total_rewards_mean           1953.352202430191
total_rewards_std            926.4507208390299
total_rewards_max            3114.1674488091135
total_rewards_min            822.228754235313
Number of train steps total  378000
Number of env steps total    1892000
Number of rollouts total     0
Train Time (s)               33.1567621328868
(Previous) Eval Time (s)     22.721595144830644
Sample Time (s)              23.517342244740576
Epoch Time (s)               79.39569952245802
Total Train Time (s)         24246.215238235425
Epoch                        377
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:46:50.747866 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #377 | Epoch Duration: 75.20832538604736
2020-01-11 06:46:50.748071 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #377 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2143948
Z variance train             0.02040999
KL Divergence                14.060302
KL Loss                      1.4060302
QF Loss                      208.38434
VF Loss                      117.398056
Policy Loss                  -1210.2144
Q Predictions Mean           1208.4891
Q Predictions Std            399.04718
Q Predictions Max            1507.0269
Q Predictions Min            0.3072613
V Predictions Mean           1204.9612
V Predictions Std            399.53653
V Predictions Max            1508.0093
V Predictions Min            -3.3257122
Log Pis Mean                 -0.31272975
Log Pis Std                  2.0427496
Log Pis Max                  7.291115
Log Pis Min                  -4.7423887
Policy mu Mean               0.053167313
Policy mu Std                0.8776428
Policy mu Max                2.445887
Policy mu Min                -2.931637
Policy log std Mean          -0.41086963
Policy log std Std           0.19157885
Policy log std Max           -0.0696463
Policy log std Min           -1.5983065
Z mean eval                  1.2137492
Z variance eval              0.017652115
total_rewards                [2997.07809307 1362.09314918 3066.91822932 2998.64420351 2972.11293351
 1987.14635512 2599.04526367 1979.53199166  943.53836692 2633.77211151]
total_rewards_mean           2353.988069747179
total_rewards_std            714.5516288214423
total_rewards_max            3066.9182293201907
total_rewards_min            943.5383669219217
Number of train steps total  379000
Number of env steps total    1897000
Number of rollouts total     0
Train Time (s)               33.076872766949236
(Previous) Eval Time (s)     18.533911906182766
Sample Time (s)              21.700813364703208
Epoch Time (s)               73.31159803783521
Total Train Time (s)         24324.599597923923
Epoch                        378
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:48:09.136125 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #378 | Epoch Duration: 78.38791084289551
2020-01-11 06:48:09.136311 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #378 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2138046
Z variance train             0.017635256
KL Divergence                14.372492
KL Loss                      1.4372492
QF Loss                      166.09456
VF Loss                      55.438187
Policy Loss                  -1253.3195
Q Predictions Mean           1250.284
Q Predictions Std            402.93027
Q Predictions Max            1546.7737
Q Predictions Min            -4.020822
V Predictions Mean           1252.8269
V Predictions Std            403.0893
V Predictions Max            1550.212
V Predictions Min            -1.6052824
Log Pis Mean                 -0.47847226
Log Pis Std                  1.9866902
Log Pis Max                  8.069878
Log Pis Min                  -4.2295637
Policy mu Mean               -0.07861363
Policy mu Std                0.80650455
Policy mu Max                1.6808773
Policy mu Min                -3.4497352
Policy log std Mean          -0.40751132
Policy log std Std           0.18116833
Policy log std Max           -0.015536338
Policy log std Min           -1.3982205
Z mean eval                  1.2168503
Z variance eval              0.017501388
total_rewards                [3012.95261018 2891.65655752 3027.55107954 2983.49276621 3021.26530591
 2643.53051304 3068.43574643 2928.50908093 2930.03942524 2077.67405987]
total_rewards_mean           2858.510714486508
total_rewards_std            283.8383653363598
total_rewards_max            3068.4357464279756
total_rewards_min            2077.674059865046
Number of train steps total  380000
Number of env steps total    1902000
Number of rollouts total     0
Train Time (s)               33.25225745514035
(Previous) Eval Time (s)     23.6099163251929
Sample Time (s)              22.353210240602493
Epoch Time (s)               79.21538402093574
Total Train Time (s)         24406.424957387615
Epoch                        379
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:49:30.965135 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #379 | Epoch Duration: 81.82869911193848
2020-01-11 06:49:30.965292 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #379 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2182068
Z variance train             0.017468156
KL Divergence                14.399395
KL Loss                      1.4399395
QF Loss                      3662.1074
VF Loss                      61.86804
Policy Loss                  -1241.1177
Q Predictions Mean           1244.6942
Q Predictions Std            453.10388
Q Predictions Max            1587.5663
Q Predictions Min            -5.471004
V Predictions Mean           1243.7292
V Predictions Std            452.7167
V Predictions Max            1584.895
V Predictions Min            -1.4760921
Log Pis Mean                 -0.51601154
Log Pis Std                  2.2927926
Log Pis Max                  10.212676
Log Pis Min                  -5.270804
Policy mu Mean               -0.033791304
Policy mu Std                0.87798715
Policy mu Max                2.8533819
Policy mu Min                -3.1858118
Policy log std Mean          -0.4001343
Policy log std Std           0.19206381
Policy log std Max           -0.039680213
Policy log std Min           -2.1645608
Z mean eval                  1.1912762
Z variance eval              0.01733556
total_rewards                [3114.41312137 3051.27168854 2056.14304278 2077.76828783 2203.70750086
 1003.12315145 3034.93061083 1748.11481387 2953.25978576 3068.47706573]
total_rewards_mean           2431.120906903159
total_rewards_std            686.8603587929659
total_rewards_max            3114.4131213710025
total_rewards_min            1003.1231514532956
Number of train steps total  381000
Number of env steps total    1907000
Number of rollouts total     0
Train Time (s)               33.27038618084043
(Previous) Eval Time (s)     26.22296018199995
Sample Time (s)              23.47276590531692
Epoch Time (s)               82.9661122681573
Total Train Time (s)         24486.63603178179
Epoch                        380
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:50:51.180039 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #380 | Epoch Duration: 80.21461653709412
2020-01-11 06:50:51.180226 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #380 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.19098
Z variance train             0.0173382
KL Divergence                13.788567
KL Loss                      1.3788567
QF Loss                      116.87955
VF Loss                      43.82958
Policy Loss                  -1238.7623
Q Predictions Mean           1238.0637
Q Predictions Std            400.11118
Q Predictions Max            1563.0342
Q Predictions Min            4.6876125
V Predictions Mean           1241.8511
V Predictions Std            399.93176
V Predictions Max            1559.391
V Predictions Min            3.1610045
Log Pis Mean                 -0.5830863
Log Pis Std                  1.9619583
Log Pis Max                  6.490725
Log Pis Min                  -6.9874
Policy mu Mean               0.019764563
Policy mu Std                0.8588815
Policy mu Max                2.7580414
Policy mu Min                -2.674275
Policy log std Mean          -0.39090323
Policy log std Std           0.17108244
Policy log std Max           -0.057002753
Policy log std Min           -1.0564466
Z mean eval                  1.1814321
Z variance eval              0.015511045
total_rewards                [ 936.24400454 2511.13239404 3063.54469818  905.31878411 3108.1597068
  812.62666913 2967.91690292 3015.96056702 1385.76186348 3082.71312119]
total_rewards_mean           2178.937871140183
total_rewards_std            977.6793120824658
total_rewards_max            3108.1597067988205
total_rewards_min            812.6266691313009
Number of train steps total  382000
Number of env steps total    1912000
Number of rollouts total     0
Train Time (s)               33.097369600087404
(Previous) Eval Time (s)     23.47118333214894
Sample Time (s)              22.54822332179174
Epoch Time (s)               79.11677625402808
Total Train Time (s)         24562.160635245964
Epoch                        381
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:52:06.709192 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #381 | Epoch Duration: 75.52883911132812
2020-01-11 06:52:06.709336 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #381 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1846823
Z variance train             0.015410575
KL Divergence                14.329882
KL Loss                      1.4329882
QF Loss                      4108.921
VF Loss                      142.71762
Policy Loss                  -1170.0
Q Predictions Mean           1169.0088
Q Predictions Std            427.55716
Q Predictions Max            1496.3816
Q Predictions Min            -0.64801484
V Predictions Mean           1169.0995
V Predictions Std            425.00253
V Predictions Max            1496.351
V Predictions Min            0.6294905
Log Pis Mean                 -0.31082866
Log Pis Std                  1.9132134
Log Pis Max                  5.4756293
Log Pis Min                  -4.8143272
Policy mu Mean               0.056658607
Policy mu Std                0.88289577
Policy mu Max                2.253659
Policy mu Min                -2.6542177
Policy log std Mean          -0.40945062
Policy log std Std           0.17874752
Policy log std Max           -0.077020116
Policy log std Min           -1.8435595
Z mean eval                  1.1869026
Z variance eval              0.014792301
total_rewards                [2436.19454349 3023.12277887  724.76583546  767.7445824  1083.7795707
 1465.48759869 2072.23731658  921.17762336 1541.135299   3105.15366556]
total_rewards_mean           1714.0798814086866
total_rewards_std            853.8371693516075
total_rewards_max            3105.153665555417
total_rewards_min            724.7658354601856
Number of train steps total  383000
Number of env steps total    1917000
Number of rollouts total     0
Train Time (s)               32.442316397093236
(Previous) Eval Time (s)     19.882916938047856
Sample Time (s)              22.872482294682413
Epoch Time (s)               75.1977156298235
Total Train Time (s)         24633.261390547268
Epoch                        382
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:53:17.819778 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #382 | Epoch Duration: 71.11032819747925
2020-01-11 06:53:17.819973 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #382 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1875408
Z variance train             0.014797874
KL Divergence                14.531906
KL Loss                      1.4531907
QF Loss                      1373.5366
VF Loss                      88.66173
Policy Loss                  -1156.9459
Q Predictions Mean           1151.9077
Q Predictions Std            471.8073
Q Predictions Max            1533.1627
Q Predictions Min            0.48259658
V Predictions Mean           1157.1685
V Predictions Std            465.0949
V Predictions Max            1530.4362
V Predictions Min            -0.013537347
Log Pis Mean                 -0.6308528
Log Pis Std                  2.0226076
Log Pis Max                  10.668035
Log Pis Min                  -5.7640185
Policy mu Mean               0.051159512
Policy mu Std                0.8250945
Policy mu Max                3.0440059
Policy mu Min                -3.9985619
Policy log std Mean          -0.38521692
Policy log std Std           0.17363603
Policy log std Max           -0.033848077
Policy log std Min           -1.1201587
Z mean eval                  1.1930375
Z variance eval              0.012821943
total_rewards                [2683.28683472 1043.11277883 3001.0030201  3109.22940565 2141.89739565
 1417.75224153 1210.86456465 2156.91598479 2715.15041207 2968.78604984]
total_rewards_mean           2244.7998687825007
total_rewards_std            739.7386310434728
total_rewards_max            3109.229405651107
total_rewards_min            1043.112778834285
Number of train steps total  384000
Number of env steps total    1922000
Number of rollouts total     0
Train Time (s)               33.2744532530196
(Previous) Eval Time (s)     15.795203039888293
Sample Time (s)              23.76987505191937
Epoch Time (s)               72.83953134482726
Total Train Time (s)         24712.11915896181
Epoch                        383
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:54:36.677766 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #383 | Epoch Duration: 78.85764908790588
2020-01-11 06:54:36.677999 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #383 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1915653
Z variance train             0.012805397
KL Divergence                15.15877
KL Loss                      1.515877
QF Loss                      139.20418
VF Loss                      94.35822
Policy Loss                  -1189.3835
Q Predictions Mean           1188.3733
Q Predictions Std            424.58972
Q Predictions Max            1514.7266
Q Predictions Min            2.171126
V Predictions Mean           1192.9855
V Predictions Std            423.31372
V Predictions Max            1520.2418
V Predictions Min            2.3760724
Log Pis Mean                 -0.36566743
Log Pis Std                  2.0117285
Log Pis Max                  8.572489
Log Pis Min                  -4.411445
Policy mu Mean               0.07753544
Policy mu Std                0.8705263
Policy mu Max                2.7809896
Policy mu Min                -2.749817
Policy log std Mean          -0.39717022
Policy log std Std           0.16169494
Policy log std Max           -0.03609979
Policy log std Min           -1.0861026
Z mean eval                  1.1859305
Z variance eval              0.012880904
total_rewards                [ 815.53386679 3022.53061203 3024.18301727 1339.02884586 3008.41994591
 3006.06738196 2978.56018087 2989.18688935 2797.06883849 1267.23635066]
total_rewards_mean           2424.781592917339
total_rewards_std            852.4894702564528
total_rewards_max            3024.183017265694
total_rewards_min            815.5338667932373
Number of train steps total  385000
Number of env steps total    1927000
Number of rollouts total     0
Train Time (s)               32.76573948794976
(Previous) Eval Time (s)     21.812980874907225
Sample Time (s)              24.269204150419682
Epoch Time (s)               78.84792451327667
Total Train Time (s)         24792.688797091134
Epoch                        384
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:55:57.251910 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #384 | Epoch Duration: 80.57372951507568
2020-01-11 06:55:57.252192 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #384 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1860799
Z variance train             0.012856195
KL Divergence                15.549713
KL Loss                      1.5549713
QF Loss                      52.482086
VF Loss                      32.359715
Policy Loss                  -1225.3336
Q Predictions Mean           1224.7224
Q Predictions Std            394.55203
Q Predictions Max            1526.8695
Q Predictions Min            -2.2453098
V Predictions Mean           1225.3253
V Predictions Std            393.7237
V Predictions Max            1530.3982
V Predictions Min            0.7802709
Log Pis Mean                 -0.5096347
Log Pis Std                  1.912936
Log Pis Max                  6.9980965
Log Pis Min                  -5.463514
Policy mu Mean               -0.031642314
Policy mu Std                0.8269671
Policy mu Max                2.3744047
Policy mu Min                -2.7356606
Policy log std Mean          -0.40382084
Policy log std Std           0.16494556
Policy log std Max           -0.06419285
Policy log std Min           -1.2709376
Z mean eval                  1.1456492
Z variance eval              0.01207013
total_rewards                [1879.84316897  971.90471339 1355.60112734 2990.95762332 3036.93103614
 2716.02218253 3036.91811154 3083.16400973 1350.67376032 2026.92600535]
total_rewards_mean           2244.8941738625067
total_rewards_std            782.7924178029107
total_rewards_max            3083.1640097323016
total_rewards_min            971.9047133862932
Number of train steps total  386000
Number of env steps total    1932000
Number of rollouts total     0
Train Time (s)               33.4500022046268
(Previous) Eval Time (s)     23.538430126849562
Sample Time (s)              22.67128828726709
Epoch Time (s)               79.65972061874345
Total Train Time (s)         24870.79994939128
Epoch                        385
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:57:15.367398 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #385 | Epoch Duration: 78.11496901512146
2020-01-11 06:57:15.367640 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #385 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1465786
Z variance train             0.012110912
KL Divergence                15.020466
KL Loss                      1.5020466
QF Loss                      198.2305
VF Loss                      65.49219
Policy Loss                  -1203.58
Q Predictions Mean           1199.1321
Q Predictions Std            430.0942
Q Predictions Max            1512.9375
Q Predictions Min            -1.1218612
V Predictions Mean           1200.983
V Predictions Std            428.27673
V Predictions Max            1516.2104
V Predictions Min            0.4253592
Log Pis Mean                 -0.5072703
Log Pis Std                  1.8790247
Log Pis Max                  6.424032
Log Pis Min                  -5.8623686
Policy mu Mean               0.01380679
Policy mu Std                0.85921323
Policy mu Max                2.8249207
Policy mu Min                -2.709538
Policy log std Mean          -0.41768137
Policy log std Std           0.17893074
Policy log std Max           -0.11292922
Policy log std Min           -1.3289919
Z mean eval                  1.1609858
Z variance eval              0.011264746
total_rewards                [2908.67071539 2961.99637377 2873.34710603 1352.15464798 3049.94902817
 2971.17256328 2959.84955399 3152.3071949  2620.44216196 3075.59343487]
total_rewards_mean           2792.548278035102
total_rewards_std            498.87597560454145
total_rewards_max            3152.3071948955676
total_rewards_min            1352.1546479825784
Number of train steps total  387000
Number of env steps total    1937000
Number of rollouts total     0
Train Time (s)               32.42267069220543
(Previous) Eval Time (s)     21.99333182675764
Sample Time (s)              23.734825919382274
Epoch Time (s)               78.15082843834534
Total Train Time (s)         24953.298890680075
Epoch                        386
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:58:37.871156 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #386 | Epoch Duration: 82.50327229499817
2020-01-11 06:58:37.871502 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #386 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.155762
Z variance train             0.0112041235
KL Divergence                15.415248
KL Loss                      1.5415248
QF Loss                      158.38763
VF Loss                      161.99611
Policy Loss                  -1164.627
Q Predictions Mean           1162.5448
Q Predictions Std            415.15216
Q Predictions Max            1507.4697
Q Predictions Min            -0.15621066
V Predictions Mean           1159.686
V Predictions Std            414.9375
V Predictions Max            1498.4912
V Predictions Min            1.1126711
Log Pis Mean                 -0.44733077
Log Pis Std                  1.9137189
Log Pis Max                  6.8134904
Log Pis Min                  -4.714991
Policy mu Mean               0.009222633
Policy mu Std                0.8233524
Policy mu Max                2.5086136
Policy mu Min                -3.2802947
Policy log std Mean          -0.3900257
Policy log std Std           0.17834182
Policy log std Max           -0.022778451
Policy log std Min           -1.1520823
Z mean eval                  1.1672719
Z variance eval              0.011184329
total_rewards                [3031.12498912 3137.16371142 3067.22554743 2296.23469904 1641.92681136
  790.93435592  852.05276287 1042.81036892 3067.43806199 1567.56128151]
total_rewards_mean           2049.4472589580437
total_rewards_std            933.2263043990537
total_rewards_max            3137.1637114239143
total_rewards_min            790.9343559157546
Number of train steps total  388000
Number of env steps total    1942000
Number of rollouts total     0
Train Time (s)               33.09390604868531
(Previous) Eval Time (s)     26.345408173277974
Sample Time (s)              22.97203672071919
Epoch Time (s)               82.41135094268247
Total Train Time (s)         25029.158895293716
Epoch                        387
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:59:53.736328 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #387 | Epoch Duration: 75.86463570594788
2020-01-11 06:59:53.736546 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #387 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1640463
Z variance train             0.011239728
KL Divergence                15.381283
KL Loss                      1.5381283
QF Loss                      143.95438
VF Loss                      61.399574
Policy Loss                  -1179.3057
Q Predictions Mean           1177.3977
Q Predictions Std            407.98132
Q Predictions Max            1485.0492
Q Predictions Min            -10.717055
V Predictions Mean           1175.2361
V Predictions Std            405.88202
V Predictions Max            1477.0352
V Predictions Min            -0.98182416
Log Pis Mean                 -0.43595448
Log Pis Std                  2.0557618
Log Pis Max                  5.3749914
Log Pis Min                  -5.1784635
Policy mu Mean               -0.1072086
Policy mu Std                0.85711163
Policy mu Max                2.4845438
Policy mu Min                -2.7980995
Policy log std Mean          -0.39825788
Policy log std Std           0.18441713
Policy log std Max           0.042299956
Policy log std Min           -1.1989772
Z mean eval                  1.1626949
Z variance eval              0.011723586
total_rewards                [ 801.78767519 3002.23938488 3111.90087667 1871.62774607 3143.91177734
 3211.02641851 3246.01195232 1673.75730729 3113.61215739 3143.98820629]
total_rewards_mean           2631.9863501949903
total_rewards_std            817.4272053520353
total_rewards_max            3246.0119523239355
total_rewards_min            801.7876751895334
Number of train steps total  389000
Number of env steps total    1947000
Number of rollouts total     0
Train Time (s)               32.995542308781296
(Previous) Eval Time (s)     19.798373667988926
Sample Time (s)              23.138798616360873
Epoch Time (s)               75.9327145931311
Total Train Time (s)         25110.096985866316
Epoch                        388
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:01:14.678512 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #388 | Epoch Duration: 80.94173526763916
2020-01-11 07:01:14.678801 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #388 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1643206
Z variance train             0.0117513165
KL Divergence                15.632856
KL Loss                      1.5632857
QF Loss                      84.482925
VF Loss                      52.929337
Policy Loss                  -1283.3624
Q Predictions Mean           1280.6743
Q Predictions Std            411.03152
Q Predictions Max            1601.1656
Q Predictions Min            -2.6238704
V Predictions Mean           1283.2118
V Predictions Std            411.71478
V Predictions Max            1598.8625
V Predictions Min            -0.19885117
Log Pis Mean                 -0.38602006
Log Pis Std                  1.8296356
Log Pis Max                  6.0758953
Log Pis Min                  -5.2542925
Policy mu Mean               -0.029921234
Policy mu Std                0.84081197
Policy mu Max                1.9120197
Policy mu Min                -2.8491695
Policy log std Mean          -0.3962953
Policy log std Std           0.17861502
Policy log std Max           -0.015244037
Policy log std Min           -1.1586925
Z mean eval                  1.1409823
Z variance eval              0.0138085615
total_rewards                [2991.21252525 1110.06343431 2996.39364221 1326.41171008 2870.43722074
 1473.08984394 2899.06307667 2734.83076958  829.40715571 2896.90984665]
total_rewards_mean           2212.781922513623
total_rewards_std            855.9538652239751
total_rewards_max            2996.3936422125093
total_rewards_min            829.407155707945
Number of train steps total  390000
Number of env steps total    1952000
Number of rollouts total     0
Train Time (s)               33.249724846333265
(Previous) Eval Time (s)     24.80705154594034
Sample Time (s)              23.306649496313184
Epoch Time (s)               81.36342588858679
Total Train Time (s)         25188.661695916206
Epoch                        389
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:02:33.245759 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #389 | Epoch Duration: 78.56679773330688
2020-01-11 07:02:33.245918 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #389 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1377586
Z variance train             0.013831872
KL Divergence                14.127018
KL Loss                      1.4127018
QF Loss                      101.306335
VF Loss                      85.77263
Policy Loss                  -1249.3527
Q Predictions Mean           1249.1711
Q Predictions Std            415.84686
Q Predictions Max            1552.9169
Q Predictions Min            -7.1655774
V Predictions Mean           1255.3483
V Predictions Std            416.59848
V Predictions Max            1567.2778
V Predictions Min            -3.5407338
Log Pis Mean                 -0.599628
Log Pis Std                  1.7717476
Log Pis Max                  6.175006
Log Pis Min                  -4.8851924
Policy mu Mean               -0.0370069
Policy mu Std                0.83532006
Policy mu Max                2.3555803
Policy mu Min                -2.9687972
Policy log std Mean          -0.41001925
Policy log std Std           0.17976806
Policy log std Max           0.007078588
Policy log std Min           -1.2255135
Z mean eval                  1.1848675
Z variance eval              0.011123478
total_rewards                [2036.14408645 2269.50736414  868.86166886 1218.83523202 3029.38324088
 1058.86490714  813.85923014 2813.46565167 1528.45969225 1001.46124918]
total_rewards_mean           1663.8842322731477
total_rewards_std            778.9317140013949
total_rewards_max            3029.3832408778453
total_rewards_min            813.8592301378651
Number of train steps total  391000
Number of env steps total    1957000
Number of rollouts total     0
Train Time (s)               32.83028550306335
(Previous) Eval Time (s)     22.010092118754983
Sample Time (s)              21.938800031784922
Epoch Time (s)               76.77917765360326
Total Train Time (s)         25259.957749076653
Epoch                        390
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:03:44.546061 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #390 | Epoch Duration: 71.3000123500824
2020-01-11 07:03:44.546249 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #390 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1863862
Z variance train             0.01111127
KL Divergence                14.729675
KL Loss                      1.4729675
QF Loss                      245.39246
VF Loss                      62.177303
Policy Loss                  -1102.8126
Q Predictions Mean           1101.6533
Q Predictions Std            435.9748
Q Predictions Max            1470.2557
Q Predictions Min            -4.827721
V Predictions Mean           1104.1069
V Predictions Std            436.48874
V Predictions Max            1474.7452
V Predictions Min            -1.943164
Log Pis Mean                 -0.56761336
Log Pis Std                  1.940308
Log Pis Max                  9.481724
Log Pis Min                  -5.126793
Policy mu Mean               0.032319885
Policy mu Std                0.8312473
Policy mu Max                2.2284014
Policy mu Min                -2.6998427
Policy log std Mean          -0.38531235
Policy log std Std           0.16067572
Policy log std Max           -0.048297197
Policy log std Min           -1.0869644
Z mean eval                  1.1382354
Z variance eval              0.012485279
total_rewards                [2358.11644823 3087.8027488  3185.97923648 1039.7879217  1408.14736594
 3144.27939089 2427.12557755 3101.1754858  3077.83130926 2609.11795826]
total_rewards_mean           2543.936344292193
total_rewards_std            725.8706717950098
total_rewards_max            3185.979236476323
total_rewards_min            1039.7879217046352
Number of train steps total  392000
Number of env steps total    1962000
Number of rollouts total     0
Train Time (s)               32.716653887182474
(Previous) Eval Time (s)     16.530614187940955
Sample Time (s)              23.727371456101537
Epoch Time (s)               72.97463953122497
Total Train Time (s)         25340.697482404765
Epoch                        391
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:05:05.289879 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #391 | Epoch Duration: 80.74348139762878
2020-01-11 07:05:05.290068 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #391 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1371342
Z variance train             0.012514794
KL Divergence                15.092732
KL Loss                      1.5092733
QF Loss                      130.90436
VF Loss                      67.03933
Policy Loss                  -1131.0613
Q Predictions Mean           1128.8162
Q Predictions Std            460.6918
Q Predictions Max            1485.5936
Q Predictions Min            -20.593117
V Predictions Mean           1131.0911
V Predictions Std            459.32715
V Predictions Max            1490.9922
V Predictions Min            0.03942883
Log Pis Mean                 -0.50965846
Log Pis Std                  1.9304539
Log Pis Max                  7.8625097
Log Pis Min                  -5.288884
Policy mu Mean               -0.0037556987
Policy mu Std                0.86148906
Policy mu Max                2.4919105
Policy mu Min                -2.8827987
Policy log std Mean          -0.38669124
Policy log std Std           0.171357
Policy log std Max           -0.11929822
Policy log std Min           -1.3376577
Z mean eval                  1.1320492
Z variance eval              0.016624775
total_rewards                [2982.19593438 3009.08076424 2571.05441635 2976.67972801 2987.8944844
 2049.76132682 3011.29696738 2998.5267036  1979.96363125  787.65377488]
total_rewards_mean           2535.4107731310896
total_rewards_std            697.4730089101676
total_rewards_max            3011.2969673841317
total_rewards_min            787.6537748816693
Number of train steps total  393000
Number of env steps total    1967000
Number of rollouts total     0
Train Time (s)               33.128856756258756
(Previous) Eval Time (s)     24.299153037834913
Sample Time (s)              23.434039054904133
Epoch Time (s)               80.8620488489978
Total Train Time (s)         25422.18355925847
Epoch                        392
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:06:26.778638 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #392 | Epoch Duration: 81.48844242095947
2020-01-11 07:06:26.778779 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #392 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1321462
Z variance train             0.016630558
KL Divergence                13.997307
KL Loss                      1.3997307
QF Loss                      177.11331
VF Loss                      112.353096
Policy Loss                  -1153.865
Q Predictions Mean           1150.7136
Q Predictions Std            428.1302
Q Predictions Max            1485.6451
Q Predictions Min            -3.7423313
V Predictions Mean           1152.7173
V Predictions Std            426.73505
V Predictions Max            1484.2141
V Predictions Min            4.1079135
Log Pis Mean                 -0.43176657
Log Pis Std                  1.9469558
Log Pis Max                  5.532961
Log Pis Min                  -4.871928
Policy mu Mean               0.0060931644
Policy mu Std                0.8744256
Policy mu Max                2.561392
Policy mu Min                -2.8707974
Policy log std Mean          -0.39954233
Policy log std Std           0.16150883
Policy log std Max           -0.12371068
Policy log std Min           -1.3180215
Z mean eval                  1.1128536
Z variance eval              0.018152084
total_rewards                [2947.24226459 1767.93837112 3011.28655981 2477.14548631 3024.92765865
 2985.18562491 3078.61539875 1556.88725953 3062.8786101  2976.08288054]
total_rewards_mean           2688.819011430579
total_rewards_std            540.3747545158197
total_rewards_max            3078.6153987501557
total_rewards_min            1556.8872595269452
Number of train steps total  394000
Number of env steps total    1972000
Number of rollouts total     0
Train Time (s)               32.75345228007063
(Previous) Eval Time (s)     24.925217276904732
Sample Time (s)              23.4023971054703
Epoch Time (s)               81.08106666244566
Total Train Time (s)         25504.60252844682
Epoch                        393
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:07:49.202041 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #393 | Epoch Duration: 82.42313528060913
2020-01-11 07:07:49.202242 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #393 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1118437
Z variance train             0.01811533
KL Divergence                13.404955
KL Loss                      1.3404955
QF Loss                      116.06598
VF Loss                      63.16607
Policy Loss                  -1305.0741
Q Predictions Mean           1302.7263
Q Predictions Std            362.18085
Q Predictions Max            1583.649
Q Predictions Min            -1.0518334
V Predictions Mean           1306.6582
V Predictions Std            363.4506
V Predictions Max            1590.244
V Predictions Min            6.43077
Log Pis Mean                 -0.67808384
Log Pis Std                  1.9342334
Log Pis Max                  7.380981
Log Pis Min                  -4.576191
Policy mu Mean               -0.018743357
Policy mu Std                0.83220255
Policy mu Max                2.1678927
Policy mu Min                -3.0087402
Policy log std Mean          -0.38798976
Policy log std Std           0.15777625
Policy log std Max           -0.08042048
Policy log std Min           -1.2973845
Z mean eval                  1.1688216
Z variance eval              0.012481957
total_rewards                [ 999.32653022  975.62028269  799.89745664 2925.87011554 2910.87079183
 2984.63421026 3035.68328887 1437.20921987  827.48334649 1991.15817093]
total_rewards_mean           1888.7753413330124
total_rewards_std            937.4385570269723
total_rewards_max            3035.6832888694494
total_rewards_min            799.8974566414785
Number of train steps total  395000
Number of env steps total    1977000
Number of rollouts total     0
Train Time (s)               32.74342788010836
(Previous) Eval Time (s)     26.266928112134337
Sample Time (s)              23.356401006225497
Epoch Time (s)               82.36675699846819
Total Train Time (s)         25579.214126240462
Epoch                        394
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:09:03.817102 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #394 | Epoch Duration: 74.61473441123962
2020-01-11 07:09:03.817225 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #394 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.163718
Z variance train             0.0124777425
KL Divergence                14.32979
KL Loss                      1.432979
QF Loss                      228.26245
VF Loss                      113.0775
Policy Loss                  -1161.1444
Q Predictions Mean           1162.2095
Q Predictions Std            467.64267
Q Predictions Max            1536.231
Q Predictions Min            -3.823698
V Predictions Mean           1168.2595
V Predictions Std            467.21036
V Predictions Max            1546.8923
V Predictions Min            5.0824404
Log Pis Mean                 -0.34882492
Log Pis Std                  2.0462012
Log Pis Max                  6.768385
Log Pis Min                  -10.863186
Policy mu Mean               -0.01651013
Policy mu Std                0.889598
Policy mu Max                2.5585802
Policy mu Min                -2.7087977
Policy log std Mean          -0.39923143
Policy log std Std           0.1854462
Policy log std Max           -0.07753512
Policy log std Min           -1.2966324
Z mean eval                  1.1360903
Z variance eval              0.01643012
total_rewards                [2968.89778283 2915.82706499 2977.41375554 2895.44310716 2891.89205252
 2845.43884947  851.95285042 2933.09372009 3024.08514217 2919.07593507]
total_rewards_mean           2722.31202602805
total_rewards_std            625.274090884902
total_rewards_max            3024.0851421725765
total_rewards_min            851.9528504201949
Number of train steps total  396000
Number of env steps total    1982000
Number of rollouts total     0
Train Time (s)               32.67322147497907
(Previous) Eval Time (s)     18.514609267935157
Sample Time (s)              23.227053571958095
Epoch Time (s)               74.41488431487232
Total Train Time (s)         25662.870921285823
Epoch                        395
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:10:27.479419 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #395 | Epoch Duration: 83.66207981109619
2020-01-11 07:10:27.479638 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #395 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1371663
Z variance train             0.016396958
KL Divergence                13.651093
KL Loss                      1.3651093
QF Loss                      105.685425
VF Loss                      30.235085
Policy Loss                  -1184.6455
Q Predictions Mean           1183.6781
Q Predictions Std            427.55737
Q Predictions Max            1564.9604
Q Predictions Min            3.9907613
V Predictions Mean           1182.8656
V Predictions Std            426.40826
V Predictions Max            1556.647
V Predictions Min            5.598044
Log Pis Mean                 -0.48797584
Log Pis Std                  2.0846298
Log Pis Max                  7.3260183
Log Pis Min                  -6.3249836
Policy mu Mean               0.013295256
Policy mu Std                0.8811798
Policy mu Max                2.6549351
Policy mu Min                -2.9443603
Policy log std Mean          -0.41153654
Policy log std Std           0.16719218
Policy log std Max           -0.109103024
Policy log std Min           -1.1388031
Z mean eval                  1.1240776
Z variance eval              0.018136283
total_rewards                [2960.87912273 3107.09470451 2827.14424861 3011.75847322 3021.84328807
  959.52258209 2956.65067675 3003.11648884 3036.62904378 2984.07538514]
total_rewards_mean           2786.871401373889
total_rewards_std            612.8856724151658
total_rewards_max            3107.094704508635
total_rewards_min            959.5225820854611
Number of train steps total  397000
Number of env steps total    1987000
Number of rollouts total     0
Train Time (s)               33.56311881914735
(Previous) Eval Time (s)     27.761418730951846
Sample Time (s)              22.490310985594988
Epoch Time (s)               83.81484853569418
Total Train Time (s)         25746.976671104785
Epoch                        396
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:11:51.590986 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #396 | Epoch Duration: 84.11108255386353
2020-01-11 07:11:51.591403 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #396 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1226175
Z variance train             0.018140469
KL Divergence                13.23244
KL Loss                      1.323244
QF Loss                      132.66078
VF Loss                      38.59841
Policy Loss                  -1167.647
Q Predictions Mean           1168.9756
Q Predictions Std            443.7548
Q Predictions Max            1503.8115
Q Predictions Min            3.8883069
V Predictions Mean           1170.6117
V Predictions Std            444.12616
V Predictions Max            1502.2411
V Predictions Min            2.4972048
Log Pis Mean                 -0.6465833
Log Pis Std                  1.932558
Log Pis Max                  6.508391
Log Pis Min                  -5.57807
Policy mu Mean               0.07252335
Policy mu Std                0.7716396
Policy mu Max                2.0329075
Policy mu Min                -2.7686923
Policy log std Mean          -0.38344884
Policy log std Std           0.16568422
Policy log std Max           -0.03690228
Policy log std Min           -1.1737188
Z mean eval                  1.1428715
Z variance eval              0.014763966
total_rewards                [2384.50378207 1341.09482529 2911.67799553 1840.60239286 2898.00864524
 2879.04647809 2979.87897625 2905.71232488 2884.08893496 2935.97405954]
total_rewards_mean           2596.0588414689832
total_rewards_std            538.7933438334532
total_rewards_max            2979.8789762525785
total_rewards_min            1341.0948252858282
Number of train steps total  398000
Number of env steps total    1992000
Number of rollouts total     0
Train Time (s)               34.823618384078145
(Previous) Eval Time (s)     28.057269207201898
Sample Time (s)              24.344871199689806
Epoch Time (s)               87.22575879096985
Total Train Time (s)         25831.89690910466
Epoch                        397
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:13:16.514199 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #397 | Epoch Duration: 84.92259955406189
2020-01-11 07:13:16.514393 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #397 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1424993
Z variance train             0.014700191
KL Divergence                13.984459
KL Loss                      1.398446
QF Loss                      237.51137
VF Loss                      128.3318
Policy Loss                  -1253.1493
Q Predictions Mean           1251.2092
Q Predictions Std            407.4616
Q Predictions Max            1554.8542
Q Predictions Min            -3.8671098
V Predictions Mean           1257.3601
V Predictions Std            407.1247
V Predictions Max            1568.0594
V Predictions Min            5.328376
Log Pis Mean                 -0.44587964
Log Pis Std                  2.0753565
Log Pis Max                  7.3854365
Log Pis Min                  -4.619046
Policy mu Mean               0.044270594
Policy mu Std                0.84705967
Policy mu Max                2.4961512
Policy mu Min                -2.8110714
Policy log std Mean          -0.38530123
Policy log std Std           0.1761761
Policy log std Max           0.051360935
Policy log std Min           -1.3036491
Z mean eval                  1.1027443
Z variance eval              0.017856643
total_rewards                [ 805.44666155 3110.21061317  828.6769702  1661.39131487 3149.65522847
 3176.00691839 3105.11579384 2175.38649556 3102.35409931 2859.0730725 ]
total_rewards_mean           2397.331716785193
total_rewards_std            920.7271960462009
total_rewards_max            3176.0069183924184
total_rewards_min            805.4466615460636
Number of train steps total  399000
Number of env steps total    1997000
Number of rollouts total     0
Train Time (s)               36.38080421509221
(Previous) Eval Time (s)     25.75375834899023
Sample Time (s)              23.062436556443572
Epoch Time (s)               85.19699912052602
Total Train Time (s)         25915.014802183025
Epoch                        398
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:14:39.637403 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #398 | Epoch Duration: 83.12276315689087
2020-01-11 07:14:39.637747 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #398 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1024135
Z variance train             0.017855499
KL Divergence                13.632873
KL Loss                      1.3632873
QF Loss                      1019.4509
VF Loss                      102.71651
Policy Loss                  -1119.1506
Q Predictions Mean           1117.0494
Q Predictions Std            405.44568
Q Predictions Max            1436.609
Q Predictions Min            2.5346732
V Predictions Mean           1119.32
V Predictions Std            402.96872
V Predictions Max            1437.6025
V Predictions Min            1.8587372
Log Pis Mean                 -0.46743667
Log Pis Std                  2.0443938
Log Pis Max                  7.501133
Log Pis Min                  -4.2467217
Policy mu Mean               0.001374313
Policy mu Std                0.84579533
Policy mu Max                2.2323966
Policy mu Min                -2.814113
Policy log std Mean          -0.4139054
Policy log std Std           0.19074698
Policy log std Max           -0.027914152
Policy log std Min           -1.4615741
Z mean eval                  1.1247652
Z variance eval              0.017327057
total_rewards                [2476.46425769  969.30480032  788.93012176  849.734617   1593.69721541
 3133.09689845  843.26917596 1078.89792267 2828.61353206 3101.64846411]
total_rewards_mean           1766.3657005427672
total_rewards_std            952.3117724864505
total_rewards_max            3133.096898453331
total_rewards_min            788.9301217610476
Number of train steps total  400000
Number of env steps total    2002000
Number of rollouts total     0
Train Time (s)               35.70619674725458
(Previous) Eval Time (s)     23.6791758290492
Sample Time (s)              25.04054706543684
Epoch Time (s)               84.42591964174062
Total Train Time (s)         25992.120336655993
Epoch                        399
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:15:56.747521 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #399 | Epoch Duration: 77.10957789421082
2020-01-11 07:15:56.747823 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #399 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1228453
Z variance train             0.017285137
KL Divergence                13.396379
KL Loss                      1.339638
QF Loss                      265.58698
VF Loss                      104.54515
Policy Loss                  -1175.1847
Q Predictions Mean           1174.0902
Q Predictions Std            390.1942
Q Predictions Max            1504.2208
Q Predictions Min            3.8209128
V Predictions Mean           1171.0392
V Predictions Std            389.03156
V Predictions Max            1492.2317
V Predictions Min            4.682136
Log Pis Mean                 -0.56232816
Log Pis Std                  1.9067099
Log Pis Max                  6.275936
Log Pis Min                  -5.1255255
Policy mu Mean               0.016640529
Policy mu Std                0.8222556
Policy mu Max                2.4807029
Policy mu Min                -2.683546
Policy log std Mean          -0.40432063
Policy log std Std           0.18473318
Policy log std Max           -0.09511244
Policy log std Min           -1.8237578
Z mean eval                  1.1238538
Z variance eval              0.016577478
total_rewards                [ 984.75427286  833.13318022 3102.83119913 1908.81326639  593.8201747
 3221.91102403 3183.61670256  852.81597805  796.14024454 2804.67666658]
total_rewards_mean           1828.2512709062662
total_rewards_std            1077.313708044645
total_rewards_max            3221.911024033563
total_rewards_min            593.8201746979536
Number of train steps total  401000
Number of env steps total    2007000
Number of rollouts total     0
Train Time (s)               35.428918602876365
(Previous) Eval Time (s)     16.362424107734114
Sample Time (s)              23.991099931299686
Epoch Time (s)               75.78244264191017
Total Train Time (s)         26069.265573016834
Epoch                        400
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:17:13.897738 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #400 | Epoch Duration: 77.14971208572388
2020-01-11 07:17:13.897957 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #400 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1189411
Z variance train             0.01660309
KL Divergence                13.469934
KL Loss                      1.3469934
QF Loss                      77.25327
VF Loss                      78.37749
Policy Loss                  -1226.764
Q Predictions Mean           1228.8044
Q Predictions Std            442.68082
Q Predictions Max            1574.3828
Q Predictions Min            1.710479
V Predictions Mean           1232.0173
V Predictions Std            443.13126
V Predictions Max            1574.6656
V Predictions Min            4.5986657
Log Pis Mean                 -0.5731181
Log Pis Std                  1.8261038
Log Pis Max                  5.705723
Log Pis Min                  -5.672455
Policy mu Mean               0.021796077
Policy mu Std                0.8026781
Policy mu Max                2.129655
Policy mu Min                -2.7303512
Policy log std Mean          -0.391665
Policy log std Std           0.16764285
Policy log std Max           -0.104482636
Policy log std Min           -1.105861
Z mean eval                  1.1142544
Z variance eval              0.021248728
total_rewards                [3105.731907   3093.34789828 3064.93813664  880.76732699 1527.85893119
 2423.07183263 2092.24793548 3198.68721253 3168.80524279 3097.66833664]
total_rewards_mean           2565.312476015053
total_rewards_std            776.3565472734787
total_rewards_max            3198.6872125251607
total_rewards_min            880.7673269911745
Number of train steps total  402000
Number of env steps total    2012000
Number of rollouts total     0
Train Time (s)               35.62200064677745
(Previous) Eval Time (s)     17.729320395272225
Sample Time (s)              24.54176747146994
Epoch Time (s)               77.89308851351961
Total Train Time (s)         26154.972735530697
Epoch                        401
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:18:39.609858 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #401 | Epoch Duration: 85.71172332763672
2020-01-11 07:18:39.610074 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #401 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1144284
Z variance train             0.021259673
KL Divergence                13.091686
KL Loss                      1.3091687
QF Loss                      131.42526
VF Loss                      80.44821
Policy Loss                  -1241.2754
Q Predictions Mean           1242.3193
Q Predictions Std            388.2188
Q Predictions Max            1538.8241
Q Predictions Min            5.0015206
V Predictions Mean           1238.8811
V Predictions Std            386.3878
V Predictions Max            1536.517
V Predictions Min            4.149639
Log Pis Mean                 -0.24911201
Log Pis Std                  2.0198457
Log Pis Max                  10.202218
Log Pis Min                  -3.6821713
Policy mu Mean               -0.04520676
Policy mu Std                0.8679772
Policy mu Max                2.2874713
Policy mu Min                -3.4371011
Policy log std Mean          -0.40424833
Policy log std Std           0.1733904
Policy log std Max           -0.037650257
Policy log std Min           -1.638297
Z mean eval                  1.0898994
Z variance eval              0.024550509
total_rewards                [3148.12874549 2071.80497848 3078.46012109 1655.99099668 3214.49891732
 1543.48552053  822.14041454 3231.00176997  805.43267065 3190.05887245]
total_rewards_mean           2276.1003007194513
total_rewards_std            962.9030643239578
total_rewards_max            3231.0017699694135
total_rewards_min            805.4326706472959
Number of train steps total  403000
Number of env steps total    2017000
Number of rollouts total     0
Train Time (s)               34.82593549974263
(Previous) Eval Time (s)     25.54749573627487
Sample Time (s)              23.772625538054854
Epoch Time (s)               84.14605677407235
Total Train Time (s)         26235.067591009196
Epoch                        402
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:19:59.708564 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #402 | Epoch Duration: 80.0983338356018
2020-01-11 07:19:59.708756 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #402 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0896775
Z variance train             0.024620451
KL Divergence                12.570274
KL Loss                      1.2570275
QF Loss                      97.75021
VF Loss                      78.84642
Policy Loss                  -1203.9973
Q Predictions Mean           1203.124
Q Predictions Std            416.9203
Q Predictions Max            1533.2965
Q Predictions Min            6.547588
V Predictions Mean           1202.5802
V Predictions Std            416.5122
V Predictions Max            1534.3549
V Predictions Min            4.145273
Log Pis Mean                 -0.44560266
Log Pis Std                  2.025602
Log Pis Max                  7.0375695
Log Pis Min                  -5.070996
Policy mu Mean               0.019453442
Policy mu Std                0.85685873
Policy mu Max                2.9161344
Policy mu Min                -2.6501493
Policy log std Mean          -0.40407023
Policy log std Std           0.1790485
Policy log std Max           -0.10079626
Policy log std Min           -1.4927617
Z mean eval                  1.0814276
Z variance eval              0.01882136
total_rewards                [3027.55348237 3034.33391147 3091.7464187  3049.15336818 1515.3125201
 2346.89680956 2426.75451216 3133.0566126  1547.6298681  3045.05519588]
total_rewards_mean           2621.7492699108816
total_rewards_std            605.8547214661055
total_rewards_max            3133.056612595068
total_rewards_min            1515.312520097312
Number of train steps total  404000
Number of env steps total    2022000
Number of rollouts total     0
Train Time (s)               35.53460245812312
(Previous) Eval Time (s)     21.499440923333168
Sample Time (s)              24.306499235797673
Epoch Time (s)               81.34054261725396
Total Train Time (s)         26320.50473385537
Epoch                        403
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:21:25.150281 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #403 | Epoch Duration: 85.44136190414429
2020-01-11 07:21:25.150549 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #403 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0823559
Z variance train             0.01882433
KL Divergence                13.335609
KL Loss                      1.333561
QF Loss                      214.38744
VF Loss                      50.393066
Policy Loss                  -1119.6578
Q Predictions Mean           1120.5464
Q Predictions Std            401.41855
Q Predictions Max            1458.722
Q Predictions Min            2.068466
V Predictions Mean           1117.105
V Predictions Std            401.15857
V Predictions Max            1461.4214
V Predictions Min            2.2974482
Log Pis Mean                 -0.18152596
Log Pis Std                  2.2145314
Log Pis Max                  8.298313
Log Pis Min                  -4.17829
Policy mu Mean               0.006045031
Policy mu Std                0.9189914
Policy mu Max                2.309453
Policy mu Min                -2.8152685
Policy log std Mean          -0.4005673
Policy log std Std           0.18479039
Policy log std Max           -0.08287339
Policy log std Min           -1.1888027
Z mean eval                  1.1186898
Z variance eval              0.020240497
total_rewards                [2786.21325708 2736.92786598 2941.06709374 2853.61503687 2142.76980011
 2891.95688416 2835.79598707 2909.89873    2781.51826182 2384.49976974]
total_rewards_mean           2726.426268657611
total_rewards_std            244.859230943343
total_rewards_max            2941.0670937429672
total_rewards_min            2142.7698001061513
Number of train steps total  405000
Number of env steps total    2027000
Number of rollouts total     0
Train Time (s)               36.24966267403215
(Previous) Eval Time (s)     25.599871366284788
Sample Time (s)              24.075493860058486
Epoch Time (s)               85.92502790037543
Total Train Time (s)         26410.237323296256
Epoch                        404
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:22:54.886754 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #404 | Epoch Duration: 89.73605442047119
2020-01-11 07:22:54.886974 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #404 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1188971
Z variance train             0.020243224
KL Divergence                12.791611
KL Loss                      1.2791611
QF Loss                      125.14148
VF Loss                      64.70022
Policy Loss                  -1152.7173
Q Predictions Mean           1150.6755
Q Predictions Std            411.57242
Q Predictions Max            1500.0968
Q Predictions Min            -0.14594948
V Predictions Mean           1149.7513
V Predictions Std            408.5684
V Predictions Max            1493.1064
V Predictions Min            5.6043944
Log Pis Mean                 -0.46215674
Log Pis Std                  2.0582397
Log Pis Max                  8.882776
Log Pis Min                  -5.1361995
Policy mu Mean               -0.16955908
Policy mu Std                0.8503572
Policy mu Max                2.68087
Policy mu Min                -2.7698212
Policy log std Mean          -0.3895701
Policy log std Std           0.1763858
Policy log std Max           -0.085800305
Policy log std Min           -1.2706041
Z mean eval                  1.0814673
Z variance eval              0.017324904
total_rewards                [1522.42622859 3008.35834146 2779.93911713 2925.30020457   75.06675458
 3045.46660446 3041.50951465  132.44193916 2948.63539448 1832.55927055]
total_rewards_mean           2131.170336962739
total_rewards_std            1132.966075554306
total_rewards_max            3045.466604464392
total_rewards_min            75.0667545849151
Number of train steps total  406000
Number of env steps total    2032000
Number of rollouts total     0
Train Time (s)               35.14747421396896
(Previous) Eval Time (s)     29.410516659729183
Sample Time (s)              24.44281268492341
Epoch Time (s)               89.00080355862156
Total Train Time (s)         26491.49518192606
Epoch                        405
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:24:16.150338 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #405 | Epoch Duration: 81.26317811012268
2020-01-11 07:24:16.150640 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #405 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0824115
Z variance train             0.017378304
KL Divergence                12.918152
KL Loss                      1.2918152
QF Loss                      123.639694
VF Loss                      57.798695
Policy Loss                  -1244.1411
Q Predictions Mean           1242.138
Q Predictions Std            393.4963
Q Predictions Max            1554.317
Q Predictions Min            -0.7214889
V Predictions Mean           1242.4829
V Predictions Std            395.45706
V Predictions Max            1563.0366
V Predictions Min            0.2329889
Log Pis Mean                 -0.37182504
Log Pis Std                  2.0001965
Log Pis Max                  7.019276
Log Pis Min                  -4.436661
Policy mu Mean               -0.23224586
Policy mu Std                0.85162807
Policy mu Max                2.0776064
Policy mu Min                -2.8502998
Policy log std Mean          -0.37822542
Policy log std Std           0.17129673
Policy log std Max           -0.05215168
Policy log std Min           -1.1184095
Z mean eval                  1.08163
Z variance eval              0.012158251
total_rewards                [3078.11574078 2990.08569676 1256.02411153 1491.9152259  3073.30932718
 2979.8442564  2705.96865258 1866.31647334  750.54334678 1961.42877829]
total_rewards_mean           2215.3551609520823
total_rewards_std            817.40170136929
total_rewards_max            3078.115740781537
total_rewards_min            750.5433467763169
Number of train steps total  407000
Number of env steps total    2037000
Number of rollouts total     0
Train Time (s)               35.838924480136484
(Previous) Eval Time (s)     21.672521982807666
Sample Time (s)              23.964217303320765
Epoch Time (s)               81.47566376626492
Total Train Time (s)         26573.124514145777
Epoch                        406
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:25:37.800829 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #406 | Epoch Duration: 81.64995288848877
2020-01-11 07:25:37.801514 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #406 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0816598
Z variance train             0.012157933
KL Divergence                14.005394
KL Loss                      1.4005394
QF Loss                      159.3197
VF Loss                      87.09715
Policy Loss                  -1237.0295
Q Predictions Mean           1236.0837
Q Predictions Std            384.69165
Q Predictions Max            1573.639
Q Predictions Min            -0.5543359
V Predictions Mean           1234.2521
V Predictions Std            383.85413
V Predictions Max            1577.3693
V Predictions Min            2.266615
Log Pis Mean                 -0.40423477
Log Pis Std                  1.9704152
Log Pis Max                  7.6954446
Log Pis Min                  -4.309946
Policy mu Mean               -0.11713632
Policy mu Std                0.8675303
Policy mu Max                2.3300207
Policy mu Min                -2.870671
Policy log std Mean          -0.40557826
Policy log std Std           0.17400172
Policy log std Max           -0.0042999685
Policy log std Min           -1.5445886
Z mean eval                  1.0888164
Z variance eval              0.014240694
total_rewards                [2973.08927768 1960.30828933 2982.35384275 1972.90984185 3058.07697781
 2979.18259392 3079.31490222 1825.13527538 3034.75285816 3080.67963873]
total_rewards_mean           2694.5803497828597
total_rewards_std            510.1194205821548
total_rewards_max            3080.679638730359
total_rewards_min            1825.1352753777364
Number of train steps total  408000
Number of env steps total    2042000
Number of rollouts total     0
Train Time (s)               33.6491517778486
(Previous) Eval Time (s)     21.846364833880216
Sample Time (s)              23.633770620450377
Epoch Time (s)               79.1292872321792
Total Train Time (s)         26657.134748775978
Epoch                        407
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:27:01.807468 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #407 | Epoch Duration: 84.0054395198822
2020-01-11 07:27:01.807646 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #407 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0889195
Z variance train             0.014219321
KL Divergence                13.582415
KL Loss                      1.3582414
QF Loss                      228.93262
VF Loss                      95.28101
Policy Loss                  -1258.509
Q Predictions Mean           1260.7766
Q Predictions Std            421.6657
Q Predictions Max            1569.7224
Q Predictions Min            3.4077282
V Predictions Mean           1258.1802
V Predictions Std            422.36548
V Predictions Max            1575.7711
V Predictions Min            3.7311716
Log Pis Mean                 -0.5153247
Log Pis Std                  1.8849206
Log Pis Max                  7.2918415
Log Pis Min                  -4.2654886
Policy mu Mean               0.020833327
Policy mu Std                0.8772376
Policy mu Max                2.230667
Policy mu Min                -2.873709
Policy log std Mean          -0.39123395
Policy log std Std           0.15957259
Policy log std Max           -0.0023218095
Policy log std Min           -1.0217727
Z mean eval                  1.090592
Z variance eval              0.008103559
total_rewards                [2200.23207227 2540.09700514 2987.8933146  2893.52604997 2973.14603928
 3012.17847356  974.1217923  1786.99196105 1486.72208654 1859.50675335]
total_rewards_mean           2271.441554805891
total_rewards_std            687.1552990820152
total_rewards_max            3012.178473556445
total_rewards_min            974.1217923014113
Number of train steps total  409000
Number of env steps total    2047000
Number of rollouts total     0
Train Time (s)               33.22852616989985
(Previous) Eval Time (s)     26.722163863945752
Sample Time (s)              23.165973770897835
Epoch Time (s)               83.11666380474344
Total Train Time (s)         26735.383168352302
Epoch                        408
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:28:20.062131 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #408 | Epoch Duration: 78.25435280799866
2020-01-11 07:28:20.062315 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #408 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.089422
Z variance train             0.008104166
KL Divergence                15.116363
KL Loss                      1.5116363
QF Loss                      152.97726
VF Loss                      144.34752
Policy Loss                  -1213.0828
Q Predictions Mean           1213.1924
Q Predictions Std            467.30743
Q Predictions Max            1565.1733
Q Predictions Min            -4.1360855
V Predictions Mean           1213.5537
V Predictions Std            465.36948
V Predictions Max            1566.179
V Predictions Min            -6.68382
Log Pis Mean                 -0.4716974
Log Pis Std                  2.0478044
Log Pis Max                  9.395391
Log Pis Min                  -6.9450293
Policy mu Mean               -0.078320496
Policy mu Std                0.87503034
Policy mu Max                2.5370932
Policy mu Min                -3.8031428
Policy log std Mean          -0.39171728
Policy log std Std           0.18962273
Policy log std Max           -0.1145827
Policy log std Min           -1.4859697
Z mean eval                  1.07724
Z variance eval              0.008547382
total_rewards                [3115.48084333 3187.43014425 3210.27614384 1785.43388514 3235.24438408
 1861.0810852  1031.76097053 1460.1715448  2679.1804329  3140.28921659]
total_rewards_mean           2470.634865066786
total_rewards_std            805.3382736194643
total_rewards_max            3235.2443840840137
total_rewards_min            1031.7609705337443
Number of train steps total  410000
Number of env steps total    2052000
Number of rollouts total     0
Train Time (s)               33.255675595253706
(Previous) Eval Time (s)     21.85952855506912
Sample Time (s)              24.313405429944396
Epoch Time (s)               79.42860958026722
Total Train Time (s)         26816.065157074016
Epoch                        409
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:29:40.748324 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #409 | Epoch Duration: 80.68587446212769
2020-01-11 07:29:40.748493 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #409 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0793698
Z variance train             0.008549904
KL Divergence                15.109741
KL Loss                      1.5109742
QF Loss                      619.19714
VF Loss                      581.7615
Policy Loss                  -1273.6273
Q Predictions Mean           1271.3931
Q Predictions Std            396.1568
Q Predictions Max            1573.1835
Q Predictions Min            -2.272234
V Predictions Mean           1262.7057
V Predictions Std            393.72223
V Predictions Max            1567.0874
V Predictions Min            0.39719552
Log Pis Mean                 -0.33203757
Log Pis Std                  2.0712516
Log Pis Max                  7.04541
Log Pis Min                  -4.849588
Policy mu Mean               0.038729023
Policy mu Std                0.8973731
Policy mu Max                2.623483
Policy mu Min                -3.1783304
Policy log std Mean          -0.40946993
Policy log std Std           0.18808728
Policy log std Max           -0.03804475
Policy log std Min           -1.8051505
Z mean eval                  1.0784338
Z variance eval              0.01155835
total_rewards                [2847.17908263 2785.62074034 1949.75001132 2878.85448284 2916.44679407
 2906.68686538 2762.31394096 2880.10496583 2781.52215068 1601.55042668]
total_rewards_mean           2631.0029460730307
total_rewards_std            437.6502550770445
total_rewards_max            2916.4467940675772
total_rewards_min            1601.5504266808803
Number of train steps total  411000
Number of env steps total    2057000
Number of rollouts total     0
Train Time (s)               34.29696946917102
(Previous) Eval Time (s)     23.116466014180332
Sample Time (s)              22.434253150131553
Epoch Time (s)               79.8476886334829
Total Train Time (s)         26901.024411148857
Epoch                        410
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:31:05.710097 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #410 | Epoch Duration: 84.96147871017456
2020-01-11 07:31:05.710240 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #410 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0795645
Z variance train             0.011596296
KL Divergence                14.297369
KL Loss                      1.429737
QF Loss                      81.734665
VF Loss                      165.98955
Policy Loss                  -1293.7709
Q Predictions Mean           1291.452
Q Predictions Std            351.64505
Q Predictions Max            1586.3877
Q Predictions Min            0.9720232
V Predictions Mean           1283.2844
V Predictions Std            350.56058
V Predictions Max            1573.7518
V Predictions Min            2.1955807
Log Pis Mean                 -0.5188634
Log Pis Std                  1.8260655
Log Pis Max                  6.1821985
Log Pis Min                  -4.961009
Policy mu Mean               0.029619271
Policy mu Std                0.8211021
Policy mu Max                2.7006643
Policy mu Min                -2.8791034
Policy log std Mean          -0.41849682
Policy log std Std           0.15718602
Policy log std Max           -0.053480536
Policy log std Min           -1.0578502
Z mean eval                  1.0775278
Z variance eval              0.018281711
total_rewards                [2911.78504791 2317.40684032 2449.72469571  967.05727787 3065.29105613
 3081.99473867 2995.35710946 2971.21338508 2328.36208641  960.40513579]
total_rewards_mean           2404.859737335741
total_rewards_std            773.9726080949665
total_rewards_max            3081.9947386744793
total_rewards_min            960.4051357933743
Number of train steps total  412000
Number of env steps total    2062000
Number of rollouts total     0
Train Time (s)               32.95895586209372
(Previous) Eval Time (s)     28.229979482013732
Sample Time (s)              23.713548979721963
Epoch Time (s)               84.90248432382941
Total Train Time (s)         26981.157701618504
Epoch                        411
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:32:25.850081 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #411 | Epoch Duration: 80.13968992233276
2020-01-11 07:32:25.850299 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #411 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0785656
Z variance train             0.018303413
KL Divergence                13.274491
KL Loss                      1.3274492
QF Loss                      126.19229
VF Loss                      51.923042
Policy Loss                  -1328.3788
Q Predictions Mean           1327.6891
Q Predictions Std            401.07617
Q Predictions Max            1655.6515
Q Predictions Min            -1.7405009
V Predictions Mean           1327.8181
V Predictions Std            401.0553
V Predictions Max            1661.5469
V Predictions Min            2.5268774
Log Pis Mean                 -0.52767754
Log Pis Std                  1.9107804
Log Pis Max                  7.307398
Log Pis Min                  -5.282143
Policy mu Mean               0.069127925
Policy mu Std                0.82488716
Policy mu Max                2.380341
Policy mu Min                -2.8140423
Policy log std Mean          -0.41697025
Policy log std Std           0.16417934
Policy log std Max           -0.0712682
Policy log std Min           -1.1725384
Z mean eval                  1.0657549
Z variance eval              0.014893839
total_rewards                [3082.44830189 1601.49632115 2411.43596249 1431.73639743 1697.00249088
 2938.10337284 2970.94312425 2510.17722822 2928.69077889 2959.39860009]
total_rewards_mean           2453.1432578138106
total_rewards_std            610.4984423072585
total_rewards_max            3082.448301889534
total_rewards_min            1431.7363974262148
Number of train steps total  413000
Number of env steps total    2067000
Number of rollouts total     0
Train Time (s)               32.823699882254004
(Previous) Eval Time (s)     23.466852874029428
Sample Time (s)              23.620948165655136
Epoch Time (s)               79.91150092193857
Total Train Time (s)         27062.723946031183
Epoch                        412
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:33:47.423675 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #412 | Epoch Duration: 81.57322239875793
2020-01-11 07:33:47.423940 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #412 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0630318
Z variance train             0.014866238
KL Divergence                13.8638525
KL Loss                      1.3863853
QF Loss                      231.03763
VF Loss                      66.29703
Policy Loss                  -1161.3982
Q Predictions Mean           1159.2104
Q Predictions Std            405.46298
Q Predictions Max            1512.1968
Q Predictions Min            -8.919178
V Predictions Mean           1164.3867
V Predictions Std            407.14148
V Predictions Max            1514.4222
V Predictions Min            -3.5552528
Log Pis Mean                 -0.34521276
Log Pis Std                  2.0685449
Log Pis Max                  9.588148
Log Pis Min                  -4.2260222
Policy mu Mean               -0.03397653
Policy mu Std                0.876653
Policy mu Max                2.6173356
Policy mu Min                -3.475725
Policy log std Mean          -0.43550992
Policy log std Std           0.18420762
Policy log std Max           -0.066602275
Policy log std Min           -1.1686229
Z mean eval                  1.0556533
Z variance eval              0.012247838
total_rewards                [2884.96536912 2981.21561092 2904.47770693 2274.25356415 1096.68204935
 2910.81114334 2890.13616811 2903.12306466 2977.10609319 2945.50147067]
total_rewards_mean           2676.8272240441015
total_rewards_std            562.1863643162037
total_rewards_max            2981.215610919874
total_rewards_min            1096.6820493545179
Number of train steps total  414000
Number of env steps total    2072000
Number of rollouts total     0
Train Time (s)               32.9162467638962
(Previous) Eval Time (s)     25.12822941876948
Sample Time (s)              23.016133116558194
Epoch Time (s)               81.06060929922387
Total Train Time (s)         27145.36467990419
Epoch                        413
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:35:10.068604 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #413 | Epoch Duration: 82.64443612098694
2020-01-11 07:35:10.068864 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #413 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0524565
Z variance train             0.012258793
KL Divergence                14.190842
KL Loss                      1.4190842
QF Loss                      170.57965
VF Loss                      232.47366
Policy Loss                  -1250.4954
Q Predictions Mean           1254.3516
Q Predictions Std            403.3559
Q Predictions Max            1562.5325
Q Predictions Min            5.9097095
V Predictions Mean           1260.6897
V Predictions Std            406.20578
V Predictions Max            1562.762
V Predictions Min            3.1753116
Log Pis Mean                 -0.44726127
Log Pis Std                  2.0696824
Log Pis Max                  6.0506597
Log Pis Min                  -8.368693
Policy mu Mean               -0.12180152
Policy mu Std                0.8807665
Policy mu Max                2.043541
Policy mu Min                -2.767695
Policy log std Mean          -0.38584003
Policy log std Std           0.16047738
Policy log std Max           0.014477685
Policy log std Min           -1.0559942
Z mean eval                  1.0719601
Z variance eval              0.01734507
total_rewards                [3014.55714245  858.30901113 2962.72222932 2483.46885424 1489.73236095
 2995.22902962 2454.21844384 3161.61462983 1411.10476032  876.92236285]
total_rewards_mean           2170.787882454657
total_rewards_std            872.7137867291548
total_rewards_max            3161.6146298282347
total_rewards_min            858.3090111303952
Number of train steps total  415000
Number of env steps total    2077000
Number of rollouts total     0
Train Time (s)               33.64543708693236
(Previous) Eval Time (s)     26.71172507898882
Sample Time (s)              23.845617258921266
Epoch Time (s)               84.20277942484245
Total Train Time (s)         27223.61300239805
Epoch                        414
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:36:28.321403 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #414 | Epoch Duration: 78.25238680839539
2020-01-11 07:36:28.321597 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #414 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0781819
Z variance train             0.017368037
KL Divergence                14.700466
KL Loss                      1.4700466
QF Loss                      224.49721
VF Loss                      173.22101
Policy Loss                  -1176.5679
Q Predictions Mean           1175.2285
Q Predictions Std            426.5963
Q Predictions Max            1522.3453
Q Predictions Min            5.823868
V Predictions Mean           1166.7754
V Predictions Std            425.6167
V Predictions Max            1529.4642
V Predictions Min            6.359294
Log Pis Mean                 -0.17118828
Log Pis Std                  2.044231
Log Pis Max                  5.2915597
Log Pis Min                  -5.852798
Policy mu Mean               -0.013664335
Policy mu Std                0.88590485
Policy mu Max                2.9838057
Policy mu Min                -2.7010221
Policy log std Mean          -0.41797018
Policy log std Std           0.193307
Policy log std Max           -0.018584102
Policy log std Min           -1.2633501
Z mean eval                  1.0466582
Z variance eval              0.011599449
total_rewards                [2707.50761794 3060.99895047 1024.33518624 2414.16636602 2973.0943339
 1879.00675133  913.8096413  3067.37802179 3138.52760665 3040.46962514]
total_rewards_mean           2421.929410077511
total_rewards_std            814.1852723163738
total_rewards_max            3138.527606649223
total_rewards_min            913.8096412989365
Number of train steps total  416000
Number of env steps total    2082000
Number of rollouts total     0
Train Time (s)               33.00351982191205
(Previous) Eval Time (s)     20.761024159844965
Sample Time (s)              21.62043973337859
Epoch Time (s)               75.3849837151356
Total Train Time (s)         27301.57500432711
Epoch                        415
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:37:46.286772 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #415 | Epoch Duration: 77.96504998207092
2020-01-11 07:37:46.286902 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #415 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0449903
Z variance train             0.011593945
KL Divergence                13.918712
KL Loss                      1.3918712
QF Loss                      341.828
VF Loss                      116.49615
Policy Loss                  -1261.2052
Q Predictions Mean           1260.1345
Q Predictions Std            338.26483
Q Predictions Max            1546.69
Q Predictions Min            3.4282541
V Predictions Mean           1264.9275
V Predictions Std            336.88446
V Predictions Max            1550.7146
V Predictions Min            5.887926
Log Pis Mean                 -0.39705837
Log Pis Std                  2.0809639
Log Pis Max                  8.6964035
Log Pis Min                  -5.731353
Policy mu Mean               -0.025315957
Policy mu Std                0.8667111
Policy mu Max                2.5603776
Policy mu Min                -3.7079587
Policy log std Mean          -0.40875685
Policy log std Std           0.1728353
Policy log std Max           -0.04424344
Policy log std Min           -1.2752794
Z mean eval                  1.063027
Z variance eval              0.012708964
total_rewards                [1091.03484692 3018.39345822  830.35943369 1560.15756625 3175.61566804
 1470.85774047 1541.54979363 3082.68054213 1224.96952093  817.9422945 ]
total_rewards_mean           1781.356086479063
total_rewards_std            893.8222327364995
total_rewards_max            3175.61566803531
total_rewards_min            817.942294502911
Number of train steps total  417000
Number of env steps total    2087000
Number of rollouts total     0
Train Time (s)               32.988776018843055
(Previous) Eval Time (s)     23.34080448327586
Sample Time (s)              23.04708032729104
Epoch Time (s)               79.37666082940996
Total Train Time (s)         27374.31464442052
Epoch                        416
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:38:59.030874 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #416 | Epoch Duration: 72.74385595321655
2020-01-11 07:38:59.031059 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #416 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0628399
Z variance train             0.012670383
KL Divergence                13.641874
KL Loss                      1.3641875
QF Loss                      127.68895
VF Loss                      30.142004
Policy Loss                  -1227.037
Q Predictions Mean           1225.2476
Q Predictions Std            434.4431
Q Predictions Max            1551.7284
Q Predictions Min            -0.41623503
V Predictions Mean           1226.1355
V Predictions Std            434.98132
V Predictions Max            1546.5161
V Predictions Min            -0.04419017
Log Pis Mean                 -0.3955041
Log Pis Std                  1.9953929
Log Pis Max                  7.6774197
Log Pis Min                  -4.302561
Policy mu Mean               0.016612263
Policy mu Std                0.8951856
Policy mu Max                2.5977113
Policy mu Min                -2.660421
Policy log std Mean          -0.39241084
Policy log std Std           0.16176045
Policy log std Max           0.11007416
Policy log std Min           -1.1900047
Z mean eval                  1.0414441
Z variance eval              0.009714458
total_rewards                [2394.12136543 3059.81734952 2309.14854158  890.12946703 2551.0571413
 2945.85131816 3132.77367319 3033.82767433 3121.46786265 3139.32029235]
total_rewards_mean           2657.7514685540627
total_rewards_std            662.2367689389497
total_rewards_max            3139.3202923503723
total_rewards_min            890.1294670288075
Number of train steps total  418000
Number of env steps total    2092000
Number of rollouts total     0
Train Time (s)               32.90753849130124
(Previous) Eval Time (s)     16.707634733989835
Sample Time (s)              23.705583185423166
Epoch Time (s)               73.32075641071424
Total Train Time (s)         27455.342651006766
Epoch                        417
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:40:20.063123 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #417 | Epoch Duration: 81.03191018104553
2020-01-11 07:40:20.063352 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #417 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0421536
Z variance train             0.009719332
KL Divergence                14.486601
KL Loss                      1.4486601
QF Loss                      196.13297
VF Loss                      169.61609
Policy Loss                  -1243.0171
Q Predictions Mean           1239.1606
Q Predictions Std            443.52652
Q Predictions Max            1564.5427
Q Predictions Min            -2.6846874
V Predictions Mean           1240.5826
V Predictions Std            439.90442
V Predictions Max            1571.2675
V Predictions Min            3.2426157
Log Pis Mean                 -0.29283863
Log Pis Std                  2.1294286
Log Pis Max                  6.7275457
Log Pis Min                  -4.6259394
Policy mu Mean               -0.0020604108
Policy mu Std                0.91190875
Policy mu Max                2.8117757
Policy mu Min                -3.6765265
Policy log std Mean          -0.410396
Policy log std Std           0.17468533
Policy log std Max           0.038891047
Policy log std Min           -1.1175821
Z mean eval                  1.0655667
Z variance eval              0.009027256
total_rewards                [1608.82655363 2979.63214151 2942.59209114 1044.54933182 2208.1539918
  911.36881456 1556.28979037 2971.57660658 1522.57596254 3062.40030715]
total_rewards_mean           2080.7965591101824
total_rewards_std            810.844911606247
total_rewards_max            3062.400307150085
total_rewards_min            911.3688145622293
Number of train steps total  419000
Number of env steps total    2097000
Number of rollouts total     0
Train Time (s)               33.655080537777394
(Previous) Eval Time (s)     24.41848113760352
Sample Time (s)              23.474501193501055
Epoch Time (s)               81.54806286888197
Total Train Time (s)         27532.85146175744
Epoch                        418
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:41:37.576196 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #418 | Epoch Duration: 77.51270580291748
2020-01-11 07:41:37.576378 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #418 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0664179
Z variance train             0.009022263
KL Divergence                14.613289
KL Loss                      1.4613289
QF Loss                      165.22092
VF Loss                      93.29785
Policy Loss                  -1241.4626
Q Predictions Mean           1241.7273
Q Predictions Std            426.94324
Q Predictions Max            1588.9172
Q Predictions Min            0.79893607
V Predictions Mean           1235.523
V Predictions Std            426.0036
V Predictions Max            1591.8237
V Predictions Min            1.051698
Log Pis Mean                 -0.38412878
Log Pis Std                  1.9275894
Log Pis Max                  6.748355
Log Pis Min                  -4.9580765
Policy mu Mean               -0.058644604
Policy mu Std                0.83246744
Policy mu Max                2.36356
Policy mu Min                -2.7564027
Policy log std Mean          -0.39699996
Policy log std Std           0.17325187
Policy log std Max           0.16104239
Policy log std Min           -1.2070572
Z mean eval                  1.0524094
Z variance eval              0.010474824
total_rewards                [2270.03244414 3022.18986466 3001.15465129 1739.28606499 2972.54534695
 3013.49859299 1026.76517905 2865.59058042 2909.26554811  934.98112981]
total_rewards_mean           2375.5309402394546
total_rewards_std            800.5200254553627
total_rewards_max            3022.1898646552563
total_rewards_min            934.9811298141666
Number of train steps total  420000
Number of env steps total    2102000
Number of rollouts total     0
Train Time (s)               33.187317855190486
(Previous) Eval Time (s)     20.38279165001586
Sample Time (s)              23.402281287126243
Epoch Time (s)               76.97239079233259
Total Train Time (s)         27612.94599464722
Epoch                        419
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:42:57.683449 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #419 | Epoch Duration: 80.10693025588989
2020-01-11 07:42:57.683647 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #419 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.054231
Z variance train             0.010473376
KL Divergence                14.269262
KL Loss                      1.4269263
QF Loss                      87.16214
VF Loss                      29.667475
Policy Loss                  -1314.5889
Q Predictions Mean           1312.4489
Q Predictions Std            404.7722
Q Predictions Max            1628.1086
Q Predictions Min            1.6483192
V Predictions Mean           1313.7808
V Predictions Std            403.80707
V Predictions Max            1630.3374
V Predictions Min            4.66984
Log Pis Mean                 -0.5077146
Log Pis Std                  1.9060314
Log Pis Max                  7.6262665
Log Pis Min                  -4.2432704
Policy mu Mean               -0.019828098
Policy mu Std                0.8254708
Policy mu Max                2.3619478
Policy mu Min                -2.9193664
Policy log std Mean          -0.3803568
Policy log std Std           0.16157593
Policy log std Max           0.053754747
Policy log std Min           -1.0916597
Z mean eval                  1.0542655
Z variance eval              0.010362705
total_rewards                [1698.13948017  972.95989274 2487.48823467 2277.92937812 1434.88401935
 2865.15444649 2663.77232842 1423.30938966 2885.72983869  994.49592862]
total_rewards_mean           1970.3862936926369
total_rewards_std            713.3456941841288
total_rewards_max            2885.729838692506
total_rewards_min            972.9598927359935
Number of train steps total  421000
Number of env steps total    2107000
Number of rollouts total     0
Train Time (s)               33.92771780397743
(Previous) Eval Time (s)     23.517035722732544
Sample Time (s)              23.49315678142011
Epoch Time (s)               80.93791030813009
Total Train Time (s)         27688.956881590653
Epoch                        420
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:44:13.690107 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #420 | Epoch Duration: 76.00632357597351
2020-01-11 07:44:13.690298 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #420 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.055331
Z variance train             0.010359446
KL Divergence                13.9570265
KL Loss                      1.3957027
QF Loss                      172.89145
VF Loss                      65.235756
Policy Loss                  -1278.9391
Q Predictions Mean           1277.1753
Q Predictions Std            394.1562
Q Predictions Max            1570.952
Q Predictions Min            2.29717
V Predictions Mean           1276.8545
V Predictions Std            392.11884
V Predictions Max            1576.4618
V Predictions Min            -2.3370926
Log Pis Mean                 -0.4310161
Log Pis Std                  2.1092603
Log Pis Max                  8.129559
Log Pis Min                  -7.9084196
Policy mu Mean               0.029457157
Policy mu Std                0.8535874
Policy mu Max                2.1246748
Policy mu Min                -2.7565262
Policy log std Mean          -0.4220066
Policy log std Std           0.1800651
Policy log std Max           0.021067113
Policy log std Min           -1.1697713
Z mean eval                  1.0587541
Z variance eval              0.011192018
total_rewards                [3122.87123879 3050.67827872 2556.50829398 3113.23621774 3079.92397514
 1030.41954999 3133.58651968 2937.26606731 2512.7611161  2878.14684376]
total_rewards_mean           2741.539810121335
total_rewards_std            609.8214560933516
total_rewards_max            3133.5865196757095
total_rewards_min            1030.4195499919595
Number of train steps total  422000
Number of env steps total    2112000
Number of rollouts total     0
Train Time (s)               32.794207458384335
(Previous) Eval Time (s)     18.585109042935073
Sample Time (s)              23.31549445539713
Epoch Time (s)               74.69481095671654
Total Train Time (s)         27772.36299381638
Epoch                        421
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:45:37.099589 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #421 | Epoch Duration: 83.40915656089783
2020-01-11 07:45:37.099747 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #421 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0582473
Z variance train             0.011229539
KL Divergence                13.839845
KL Loss                      1.3839844
QF Loss                      309.1016
VF Loss                      40.511368
Policy Loss                  -1225.3472
Q Predictions Mean           1219.9253
Q Predictions Std            419.69968
Q Predictions Max            1540.1552
Q Predictions Min            2.724485
V Predictions Mean           1227.0465
V Predictions Std            415.30667
V Predictions Max            1541.2914
V Predictions Min            4.5324225
Log Pis Mean                 -0.46751237
Log Pis Std                  2.053285
Log Pis Max                  11.781247
Log Pis Min                  -7.268454
Policy mu Mean               0.051320925
Policy mu Std                0.84660316
Policy mu Max                3.0957828
Policy mu Min                -3.9865046
Policy log std Mean          -0.40229073
Policy log std Std           0.16697109
Policy log std Max           0.10603824
Policy log std Min           -1.1634555
Z mean eval                  1.0660305
Z variance eval              0.009127271
total_rewards                [3082.01217881 3027.91469653 3080.48547422 3072.73785779 3152.6500084
 3038.66249722 1466.10809493 2970.29684919 2477.13883614 3078.88499243]
total_rewards_mean           2844.6891485659994
total_rewards_std            493.5756715637765
total_rewards_max            3152.650008402896
total_rewards_min            1466.1080949322868
Number of train steps total  423000
Number of env steps total    2117000
Number of rollouts total     0
Train Time (s)               32.87428359221667
(Previous) Eval Time (s)     27.29915933078155
Sample Time (s)              22.90430259006098
Epoch Time (s)               83.0777455130592
Total Train Time (s)         27855.071813335177
Epoch                        422
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:46:59.811300 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #422 | Epoch Duration: 82.7114429473877
2020-01-11 07:46:59.811439 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #422 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0681791
Z variance train             0.009116466
KL Divergence                14.312281
KL Loss                      1.431228
QF Loss                      172.7793
VF Loss                      93.44111
Policy Loss                  -1306.7607
Q Predictions Mean           1303.6484
Q Predictions Std            393.35278
Q Predictions Max            1589.8026
Q Predictions Min            -0.9534544
V Predictions Mean           1301.6077
V Predictions Std            393.26456
V Predictions Max            1588.859
V Predictions Min            4.658011
Log Pis Mean                 -0.8195386
Log Pis Std                  1.5702788
Log Pis Max                  5.8007903
Log Pis Min                  -5.4253454
Policy mu Mean               -0.0371641
Policy mu Std                0.75580585
Policy mu Max                2.7527514
Policy mu Min                -2.6460307
Policy log std Mean          -0.38654938
Policy log std Std           0.14948922
Policy log std Max           -0.0830003
Policy log std Min           -1.1610564
Z mean eval                  1.0391352
Z variance eval              0.0125827845
total_rewards                [2903.37956086 2928.28395189 2946.64044474 2973.98813268 2688.24038748
 2924.94916726 2908.72552191 2958.41317336 2943.61937665 2840.33453672]
total_rewards_mean           2901.6574253552308
total_rewards_std            79.27733166871413
total_rewards_max            2973.9881326796435
total_rewards_min            2688.240387481104
Number of train steps total  424000
Number of env steps total    2122000
Number of rollouts total     0
Train Time (s)               32.98697636928409
(Previous) Eval Time (s)     26.9325430681929
Sample Time (s)              24.10039698285982
Epoch Time (s)               84.01991642033681
Total Train Time (s)         27941.072452377994
Epoch                        423
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:48:25.818278 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #423 | Epoch Duration: 86.0066168308258
2020-01-11 07:48:25.818621 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #423 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0365757
Z variance train             0.012537341
KL Divergence                13.333165
KL Loss                      1.3333166
QF Loss                      806.51575
VF Loss                      61.970108
Policy Loss                  -1252.4749
Q Predictions Mean           1251.3745
Q Predictions Std            367.23795
Q Predictions Max            1546.1711
Q Predictions Min            2.522289
V Predictions Mean           1256.0266
V Predictions Std            366.64304
V Predictions Max            1540.735
V Predictions Min            1.7365024
Log Pis Mean                 -0.46385053
Log Pis Std                  2.054857
Log Pis Max                  10.976774
Log Pis Min                  -5.4627395
Policy mu Mean               0.0056520044
Policy mu Std                0.8434366
Policy mu Max                3.1646392
Policy mu Min                -2.7185807
Policy log std Mean          -0.421209
Policy log std Std           0.16872467
Policy log std Max           -0.08100748
Policy log std Min           -1.1753283
Z mean eval                  1.0570227
Z variance eval              0.012142228
total_rewards                [3094.83622999  984.49873041 3081.13875306 1594.95221088 2929.83785228
 3005.69906302 3113.62521568 2933.75234652 3082.44082624 1311.5704762 ]
total_rewards_mean           2513.235170427955
total_rewards_std            810.0881104137688
total_rewards_max            3113.625215682706
total_rewards_min            984.4987304069997
Number of train steps total  425000
Number of env steps total    2127000
Number of rollouts total     0
Train Time (s)               32.85179383913055
(Previous) Eval Time (s)     28.918851302936673
Sample Time (s)              23.901281708385795
Epoch Time (s)               85.67192685045302
Total Train Time (s)         28022.333737145644
Epoch                        424
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:49:47.084105 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #424 | Epoch Duration: 81.26527714729309
2020-01-11 07:49:47.084369 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #424 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0551794
Z variance train             0.012176502
KL Divergence                14.046986
KL Loss                      1.4046986
QF Loss                      162.73795
VF Loss                      117.64231
Policy Loss                  -1295.9219
Q Predictions Mean           1292.9888
Q Predictions Std            395.74902
Q Predictions Max            1576.591
Q Predictions Min            -28.56688
V Predictions Mean           1298.3302
V Predictions Std            395.41583
V Predictions Max            1579.6125
V Predictions Min            4.8331885
Log Pis Mean                 -0.45309722
Log Pis Std                  1.9259063
Log Pis Max                  7.2748814
Log Pis Min                  -5.4164257
Policy mu Mean               -0.0038631558
Policy mu Std                0.84641
Policy mu Max                1.6757772
Policy mu Min                -2.9178243
Policy log std Mean          -0.42625487
Policy log std Std           0.1701791
Policy log std Max           0.07187042
Policy log std Min           -1.1879299
Z mean eval                  1.0553836
Z variance eval              0.008742126
total_rewards                [ 894.12490773  940.56326227 2399.3437104  1535.51418953 1623.25162312
 2974.83810734 2928.16968808 3126.09788026 1530.68137097 1663.0969626 ]
total_rewards_mean           1961.5681702286486
total_rewards_std            791.2917316444871
total_rewards_max            3126.0978802567724
total_rewards_min            894.124907729012
Number of train steps total  426000
Number of env steps total    2132000
Number of rollouts total     0
Train Time (s)               33.263694087043405
(Previous) Eval Time (s)     24.511882500257343
Sample Time (s)              23.26748379971832
Epoch Time (s)               81.04306038701907
Total Train Time (s)         28097.341202819254
Epoch                        425
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:51:02.096451 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #425 | Epoch Duration: 75.01179647445679
2020-01-11 07:51:02.096870 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #425 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0527077
Z variance train             0.008749223
KL Divergence                14.624594
KL Loss                      1.4624594
QF Loss                      114.7825
VF Loss                      58.023563
Policy Loss                  -1313.8037
Q Predictions Mean           1313.9994
Q Predictions Std            383.21466
Q Predictions Max            1617.2692
Q Predictions Min            0.6402598
V Predictions Mean           1317.2911
V Predictions Std            383.99893
V Predictions Max            1614.2445
V Predictions Min            -3.2978575
Log Pis Mean                 -0.46881106
Log Pis Std                  1.9291459
Log Pis Max                  5.711061
Log Pis Min                  -4.1247997
Policy mu Mean               0.054769
Policy mu Std                0.84355885
Policy mu Max                2.1387138
Policy mu Min                -2.9297097
Policy log std Mean          -0.4165034
Policy log std Std           0.1762883
Policy log std Max           -0.036593407
Policy log std Min           -1.2634101
Z mean eval                  1.0423443
Z variance eval              0.011420147
total_rewards                [3074.54520729 1710.41966372  858.33046606  834.79348991 3113.29885261
 2264.56625858  973.29988149 3057.32029741 1661.33212154 3088.18487133]
total_rewards_mean           2063.6091109938825
total_rewards_std            929.4874797810877
total_rewards_max            3113.2988526086096
total_rewards_min            834.7934899111796
Number of train steps total  427000
Number of env steps total    2137000
Number of rollouts total     0
Train Time (s)               33.350986961741
(Previous) Eval Time (s)     18.480242318008095
Sample Time (s)              22.020819348748773
Epoch Time (s)               73.85204862849787
Total Train Time (s)         28172.22581027262
Epoch                        426
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:52:16.984150 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #426 | Epoch Duration: 74.88707160949707
2020-01-11 07:52:16.984329 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #426 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0418136
Z variance train             0.011449523
KL Divergence                13.563544
KL Loss                      1.3563545
QF Loss                      138.35226
VF Loss                      99.9507
Policy Loss                  -1228.9226
Q Predictions Mean           1228.2174
Q Predictions Std            400.5745
Q Predictions Max            1539.9663
Q Predictions Min            -0.6812114
V Predictions Mean           1228.0339
V Predictions Std            398.55188
V Predictions Max            1535.7548
V Predictions Min            5.9606495
Log Pis Mean                 -0.57202363
Log Pis Std                  1.8656198
Log Pis Max                  5.5594616
Log Pis Min                  -5.7324886
Policy mu Mean               -0.016761309
Policy mu Std                0.81614405
Policy mu Max                2.1774952
Policy mu Min                -2.9103057
Policy log std Mean          -0.41989532
Policy log std Std           0.17891617
Policy log std Max           0.062705666
Policy log std Min           -1.3961781
Z mean eval                  1.0435617
Z variance eval              0.013366732
total_rewards                [3107.70350855 2150.08266179 1713.16940443  958.90144414 3133.25370776
 1509.64058882 2302.97133861 2538.24492578  849.55778638 2450.34235875]
total_rewards_mean           2071.386772500549
total_rewards_std            761.3980710711099
total_rewards_max            3133.253707760842
total_rewards_min            849.5577863806702
Number of train steps total  428000
Number of env steps total    2142000
Number of rollouts total     0
Train Time (s)               33.30205583292991
(Previous) Eval Time (s)     19.514964333735406
Sample Time (s)              22.713738836813718
Epoch Time (s)               75.53075900347903
Total Train Time (s)         28247.747529151384
Epoch                        427
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:53:32.510901 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #427 | Epoch Duration: 75.52641415596008
2020-01-11 07:53:32.511160 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #427 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0440266
Z variance train             0.013355563
KL Divergence                13.934266
KL Loss                      1.3934267
QF Loss                      126.999435
VF Loss                      90.547195
Policy Loss                  -1321.5531
Q Predictions Mean           1320.3984
Q Predictions Std            322.25488
Q Predictions Max            1562.7932
Q Predictions Min            0.36793387
V Predictions Mean           1315.1843
V Predictions Std            322.24295
V Predictions Max            1555.3148
V Predictions Min            1.3652129
Log Pis Mean                 -0.49157354
Log Pis Std                  1.967165
Log Pis Max                  7.418954
Log Pis Min                  -5.961
Policy mu Mean               0.03193519
Policy mu Std                0.8432855
Policy mu Max                2.9683783
Policy mu Min                -2.632947
Policy log std Mean          -0.407204
Policy log std Std           0.1728044
Policy log std Max           -0.06515869
Policy log std Min           -1.190562
Z mean eval                  1.0410327
Z variance eval              0.010624825
total_rewards                [3218.56137433 1287.33832084  943.24199253  964.50511883 3090.10378475
 3289.09197145 3171.42606074 3219.79953738 3202.50704937 2995.12863162]
total_rewards_mean           2538.1703841824446
total_rewards_std            971.1864136144347
total_rewards_max            3289.09197144566
total_rewards_min            943.2419925268996
Number of train steps total  429000
Number of env steps total    2147000
Number of rollouts total     0
Train Time (s)               33.16518386406824
(Previous) Eval Time (s)     19.510288106743246
Sample Time (s)              23.37242423836142
Epoch Time (s)               76.0478962091729
Total Train Time (s)         28327.969086124096
Epoch                        428
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:54:52.736964 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #428 | Epoch Duration: 80.22561454772949
2020-01-11 07:54:52.737153 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #428 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0404403
Z variance train             0.010624093
KL Divergence                13.8563595
KL Loss                      1.385636
QF Loss                      104.31761
VF Loss                      44.64256
Policy Loss                  -1400.1178
Q Predictions Mean           1399.9016
Q Predictions Std            350.6993
Q Predictions Max            1659.583
Q Predictions Min            5.9114203
V Predictions Mean           1397.9241
V Predictions Std            349.67618
V Predictions Max            1659.568
V Predictions Min            3.009037
Log Pis Mean                 -0.69053704
Log Pis Std                  1.7391201
Log Pis Max                  6.717148
Log Pis Min                  -5.3435054
Policy mu Mean               0.05272012
Policy mu Std                0.7692897
Policy mu Max                2.5733395
Policy mu Min                -2.650767
Policy log std Mean          -0.39582703
Policy log std Std           0.16911095
Policy log std Max           -0.040831476
Policy log std Min           -1.1669883
Z mean eval                  1.044125
Z variance eval              0.009419956
total_rewards                [1104.23280432 2445.5619721  1398.57519974  892.5537774  3056.1280053
 3247.71028855 2591.5435956  1247.27745321 2820.19485771 1052.46905018]
total_rewards_mean           1985.6247004110999
total_rewards_std            880.127471728509
total_rewards_max            3247.7102885484355
total_rewards_min            892.5537774043339
Number of train steps total  430000
Number of env steps total    2152000
Number of rollouts total     0
Train Time (s)               33.55683508096263
(Previous) Eval Time (s)     23.68768321396783
Sample Time (s)              23.391854436602443
Epoch Time (s)               80.6363727315329
Total Train Time (s)         28403.434440207202
Epoch                        429
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:56:08.206359 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #429 | Epoch Duration: 75.46905946731567
2020-01-11 07:56:08.206570 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #429 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0440743
Z variance train             0.009414509
KL Divergence                14.603485
KL Loss                      1.4603485
QF Loss                      79.24698
VF Loss                      49.969578
Policy Loss                  -1387.2507
Q Predictions Mean           1386.3281
Q Predictions Std            305.51044
Q Predictions Max            1613.6283
Q Predictions Min            12.695158
V Predictions Mean           1382.9457
V Predictions Std            303.11264
V Predictions Max            1602.8914
V Predictions Min            14.9799385
Log Pis Mean                 -0.597147
Log Pis Std                  1.7494326
Log Pis Max                  5.4808965
Log Pis Min                  -4.601125
Policy mu Mean               0.07388898
Policy mu Std                0.8056471
Policy mu Max                2.579442
Policy mu Min                -2.7882934
Policy log std Mean          -0.38190627
Policy log std Std           0.15205665
Policy log std Max           -0.0771708
Policy log std Min           -1.0136052
Z mean eval                  1.0490372
Z variance eval              0.00899154
total_rewards                [ 847.2751647   897.38060356 3177.37982544 1627.99660306  837.36802838
  968.88774904 1963.81714771 2403.75313529 1390.46286558 2501.48164923]
total_rewards_mean           1661.5802771998265
total_rewards_std            782.6956946056198
total_rewards_max            3177.379825444085
total_rewards_min            837.3680283813501
Number of train steps total  431000
Number of env steps total    2157000
Number of rollouts total     0
Train Time (s)               33.40124863293022
(Previous) Eval Time (s)     18.520005657803267
Sample Time (s)              22.97997470293194
Epoch Time (s)               74.90122899366543
Total Train Time (s)         28473.64336321922
Epoch                        430
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:57:18.420410 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #430 | Epoch Duration: 70.21367835998535
2020-01-11 07:57:18.420625 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #430 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.049523
Z variance train             0.009024026
KL Divergence                14.953922
KL Loss                      1.4953922
QF Loss                      101.43097
VF Loss                      45.056
Policy Loss                  -1331.6681
Q Predictions Mean           1330.9407
Q Predictions Std            391.9701
Q Predictions Max            1640.6365
Q Predictions Min            -3.6162364
V Predictions Mean           1328.7323
V Predictions Std            392.2348
V Predictions Max            1636.3092
V Predictions Min            -1.765902
Log Pis Mean                 -0.47736335
Log Pis Std                  1.7861758
Log Pis Max                  6.5417023
Log Pis Min                  -4.275028
Policy mu Mean               0.043856498
Policy mu Std                0.8324065
Policy mu Max                2.5421371
Policy mu Min                -2.7461247
Policy log std Mean          -0.40865874
Policy log std Std           0.14951086
Policy log std Max           -0.057412058
Policy log std Min           -0.98771816
Z mean eval                  1.0640265
Z variance eval              0.012043557
total_rewards                [ 933.3005966  3111.24288944 3182.57960405 3220.07672238 2498.61496432
 2909.42571352 1671.81763175 2782.95806491 3219.55355407 3187.54494512]
total_rewards_mean           2671.711468616668
total_rewards_std            737.6855706499578
total_rewards_max            3220.07672237751
total_rewards_min            933.3005966043955
Number of train steps total  432000
Number of env steps total    2162000
Number of rollouts total     0
Train Time (s)               33.31959367822856
(Previous) Eval Time (s)     13.832109237089753
Sample Time (s)              22.409796459134668
Epoch Time (s)               69.56149937445298
Total Train Time (s)         28553.40880423924
Epoch                        431
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:58:38.190107 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #431 | Epoch Duration: 79.7693133354187
2020-01-11 07:58:38.190334 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #431 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0609226
Z variance train             0.012064801
KL Divergence                15.009446
KL Loss                      1.5009446
QF Loss                      174.94467
VF Loss                      74.20582
Policy Loss                  -1316.487
Q Predictions Mean           1316.7903
Q Predictions Std            403.12524
Q Predictions Max            1595.5061
Q Predictions Min            -2.0332751
V Predictions Mean           1319.9932
V Predictions Std            400.3641
V Predictions Max            1601.0815
V Predictions Min            4.3467617
Log Pis Mean                 -0.7247469
Log Pis Std                  1.6600667
Log Pis Max                  7.657606
Log Pis Min                  -4.577573
Policy mu Mean               0.0023065582
Policy mu Std                0.7737388
Policy mu Max                2.6746523
Policy mu Min                -2.6408222
Policy log std Mean          -0.38780424
Policy log std Std           0.14670151
Policy log std Max           -0.06480101
Policy log std Min           -1.0391406
Z mean eval                  1.0809214
Z variance eval              0.01770511
total_rewards                [3129.31002072  867.87865322 1265.69704973 1245.08909777 1644.17885461
 3179.64562507  855.23234708 3131.97849588  924.5624267  3131.31321591]
total_rewards_mean           1937.4885786709383
total_rewards_std            1008.6392184989827
total_rewards_max            3179.6456250704587
total_rewards_min            855.2323470837399
Number of train steps total  433000
Number of env steps total    2167000
Number of rollouts total     0
Train Time (s)               32.86813480965793
(Previous) Eval Time (s)     24.039591622073203
Sample Time (s)              22.597780093550682
Epoch Time (s)               79.50550652528182
Total Train Time (s)         28626.483992409892
Epoch                        432
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:59:51.275636 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #432 | Epoch Duration: 73.08513569831848
2020-01-11 07:59:51.276077 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #432 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0803493
Z variance train             0.017668517
KL Divergence                14.348564
KL Loss                      1.4348564
QF Loss                      59.643692
VF Loss                      37.502426
Policy Loss                  -1322.673
Q Predictions Mean           1321.7085
Q Predictions Std            386.14136
Q Predictions Max            1602.5256
Q Predictions Min            1.1716392
V Predictions Mean           1324.1274
V Predictions Std            385.3575
V Predictions Max            1606.3632
V Predictions Min            2.8444967
Log Pis Mean                 -0.66183674
Log Pis Std                  1.9637772
Log Pis Max                  6.7821183
Log Pis Min                  -4.9336305
Policy mu Mean               -0.0077266567
Policy mu Std                0.81897753
Policy mu Max                3.1469936
Policy mu Min                -2.9325886
Policy log std Mean          -0.39443263
Policy log std Std           0.15876491
Policy log std Max           0.029754966
Policy log std Min           -1.1336479
Z mean eval                  1.06922
Z variance eval              0.013614638
total_rewards                [1506.52699572 2332.69040656 3092.83620453 1050.85790226 1585.86718411
 1015.54407992 2977.74352591  848.18082173 2540.87875326 2072.10757904]
total_rewards_mean           1902.3233453036187
total_rewards_std            779.4248850147876
total_rewards_max            3092.8362045250888
total_rewards_min            848.1808217324879
Number of train steps total  434000
Number of env steps total    2172000
Number of rollouts total     0
Train Time (s)               33.340230260044336
(Previous) Eval Time (s)     17.618873017840087
Sample Time (s)              23.49815666442737
Epoch Time (s)               74.4572599423118
Total Train Time (s)         28701.49036486866
Epoch                        433
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:01:06.300163 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #433 | Epoch Duration: 75.0237250328064
2020-01-11 08:01:06.300408 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #433 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0689695
Z variance train             0.013661939
KL Divergence                15.458571
KL Loss                      1.5458572
QF Loss                      180.68416
VF Loss                      152.8669
Policy Loss                  -1351.4746
Q Predictions Mean           1351.8203
Q Predictions Std            395.57812
Q Predictions Max            1623.1903
Q Predictions Min            -1.4088895
V Predictions Mean           1345.1514
V Predictions Std            390.7546
V Predictions Max            1615.6143
V Predictions Min            1.4642942
Log Pis Mean                 -0.7970271
Log Pis Std                  1.7460631
Log Pis Max                  6.5464616
Log Pis Min                  -5.8177557
Policy mu Mean               0.02646631
Policy mu Std                0.7614672
Policy mu Max                2.2349756
Policy mu Min                -2.8266878
Policy log std Mean          -0.38438508
Policy log std Std           0.15113297
Policy log std Max           -0.076456785
Policy log std Min           -1.1691017
Z mean eval                  1.0666304
Z variance eval              0.01267087
total_rewards                [ 935.0683425  2420.0402229  1168.96756721 2261.39354404 1300.62424242
 1273.26147913 1426.45915788 1025.40647489 3286.43337294 2484.96387088]
total_rewards_mean           1758.2618274787837
total_rewards_std            753.0762920524668
total_rewards_max            3286.4333729353752
total_rewards_min            935.0683425039889
Number of train steps total  435000
Number of env steps total    2177000
Number of rollouts total     0
Train Time (s)               33.555647226050496
(Previous) Eval Time (s)     18.185028430074453
Sample Time (s)              22.26265487074852
Epoch Time (s)               74.00333052687347
Total Train Time (s)         28772.555730439257
Epoch                        434
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:02:17.351249 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #434 | Epoch Duration: 71.05063891410828
2020-01-11 08:02:17.351429 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #434 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0702856
Z variance train             0.012657173
KL Divergence                15.57036
KL Loss                      1.557036
QF Loss                      169.35477
VF Loss                      106.29888
Policy Loss                  -1363.2117
Q Predictions Mean           1362.0066
Q Predictions Std            381.46194
Q Predictions Max            1661.6838
Q Predictions Min            -3.7007723
V Predictions Mean           1356.5691
V Predictions Std            378.58014
V Predictions Max            1651.0625
V Predictions Min            4.7314095
Log Pis Mean                 -0.76486915
Log Pis Std                  1.8200188
Log Pis Max                  5.552407
Log Pis Min                  -4.0822678
Policy mu Mean               0.002861794
Policy mu Std                0.78121096
Policy mu Max                2.6131437
Policy mu Min                -2.8034682
Policy log std Mean          -0.38787177
Policy log std Std           0.16940436
Policy log std Max           -0.10716293
Policy log std Min           -1.2987134
Z mean eval                  1.055096
Z variance eval              0.010341478
total_rewards                [1521.85615288 1425.39070137 3166.22330376 3088.11543832 3079.60262174
 3147.29752562 3099.42886176 2692.76699692 1852.92247527 2475.67455816]
total_rewards_mean           2554.927863580987
total_rewards_std            666.4699167247599
total_rewards_max            3166.2233037632523
total_rewards_min            1425.3907013736796
Number of train steps total  436000
Number of env steps total    2182000
Number of rollouts total     0
Train Time (s)               33.5770917981863
(Previous) Eval Time (s)     15.232029550243169
Sample Time (s)              22.487240409478545
Epoch Time (s)               71.29636175790802
Total Train Time (s)         28853.541880534962
Epoch                        435
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:03:38.343115 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #435 | Epoch Duration: 80.99156498908997
2020-01-11 08:03:38.343304 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #435 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0521252
Z variance train             0.010296587
KL Divergence                15.119347
KL Loss                      1.5119346
QF Loss                      72.14963
VF Loss                      30.11464
Policy Loss                  -1363.9254
Q Predictions Mean           1364.7598
Q Predictions Std            328.92303
Q Predictions Max            1593.1353
Q Predictions Min            -1.1876984
V Predictions Mean           1365.7043
V Predictions Std            328.29257
V Predictions Max            1591.903
V Predictions Min            5.3670793
Log Pis Mean                 -0.52306414
Log Pis Std                  1.7518688
Log Pis Max                  7.639308
Log Pis Min                  -4.5762825
Policy mu Mean               -0.023491526
Policy mu Std                0.79393435
Policy mu Max                2.4405785
Policy mu Min                -2.7154284
Policy log std Mean          -0.3891559
Policy log std Std           0.16153897
Policy log std Max           -0.042935967
Policy log std Min           -1.3471568
Z mean eval                  1.0362033
Z variance eval              0.017474476
total_rewards                [3245.37782679 3238.23530366 3185.87759578 3222.65772517 3215.83429895
 1562.45905423  912.78148109 1009.67040512 3291.31304145 3215.82542873]
total_rewards_mean           2610.003216094457
total_rewards_std            961.3825319586206
total_rewards_max            3291.313041452071
total_rewards_min            912.7814810876664
Number of train steps total  437000
Number of env steps total    2187000
Number of rollouts total     0
Train Time (s)               33.26303449086845
(Previous) Eval Time (s)     24.92691066628322
Sample Time (s)              23.688213566783816
Epoch Time (s)               81.87815872393548
Total Train Time (s)         28935.010206087958
Epoch                        436
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:04:59.816000 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #436 | Epoch Duration: 81.47252130508423
2020-01-11 08:04:59.816252 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #436 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0377175
Z variance train             0.017500173
KL Divergence                12.709735
KL Loss                      1.2709736
QF Loss                      213.44748
VF Loss                      77.38911
Policy Loss                  -1314.8528
Q Predictions Mean           1313.4346
Q Predictions Std            340.5233
Q Predictions Max            1583.3734
Q Predictions Min            10.36954
V Predictions Mean           1311.2473
V Predictions Std            339.53107
V Predictions Max            1576.4475
V Predictions Min            3.3706694
Log Pis Mean                 -0.65465117
Log Pis Std                  1.6222367
Log Pis Max                  5.145171
Log Pis Min                  -4.805562
Policy mu Mean               0.013255513
Policy mu Std                0.76765037
Policy mu Max                1.8740809
Policy mu Min                -2.5803206
Policy log std Mean          -0.4107243
Policy log std Std           0.17410496
Policy log std Max           -0.065438405
Policy log std Min           -1.3244032
Z mean eval                  1.0537375
Z variance eval              0.0122171715
total_rewards                [1662.86940546 1536.62895697 3142.01753203 3151.33226186 3168.3580336
 3176.43703801 1824.11279501 3153.09030934 2184.06227503 2906.83425756]
total_rewards_mean           2590.5742864873246
total_rewards_std            666.0484490318805
total_rewards_max            3176.437038011721
total_rewards_min            1536.62895697431
Number of train steps total  438000
Number of env steps total    2192000
Number of rollouts total     0
Train Time (s)               33.38231573672965
(Previous) Eval Time (s)     24.520952473860234
Sample Time (s)              22.460432754829526
Epoch Time (s)               80.36370096541941
Total Train Time (s)         29015.817637751345
Epoch                        437
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:06:20.627124 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #437 | Epoch Duration: 80.81070709228516
2020-01-11 08:06:20.627400 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #437 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0561879
Z variance train             0.012221487
KL Divergence                13.528006
KL Loss                      1.3528006
QF Loss                      74.84961
VF Loss                      90.07936
Policy Loss                  -1385.9424
Q Predictions Mean           1387.3066
Q Predictions Std            340.5712
Q Predictions Max            1625.8003
Q Predictions Min            3.7978783
V Predictions Mean           1393.0144
V Predictions Std            340.9475
V Predictions Max            1626.0211
V Predictions Min            5.0240583
Log Pis Mean                 -0.71925807
Log Pis Std                  1.7636211
Log Pis Max                  5.877299
Log Pis Min                  -4.83674
Policy mu Mean               0.0334845
Policy mu Std                0.7895506
Policy mu Max                2.1468763
Policy mu Min                -2.6278684
Policy log std Mean          -0.40560937
Policy log std Std           0.15586229
Policy log std Max           -0.06585339
Policy log std Min           -1.0892943
Z mean eval                  1.0846093
Z variance eval              0.01680641
total_rewards                [3175.39193226 3130.75378365 3098.72251162 1248.49415947 3167.89692618
  262.50987072  248.41545059 1836.79894192 2539.48937822 3193.33590346]
total_rewards_mean           2190.180885809388
total_rewards_std            1151.6532625989275
total_rewards_max            3193.3359034613122
total_rewards_min            248.4154505927605
Number of train steps total  439000
Number of env steps total    2197000
Number of rollouts total     0
Train Time (s)               33.49769293284044
(Previous) Eval Time (s)     24.967637876048684
Sample Time (s)              22.636818469967693
Epoch Time (s)               81.10214927885681
Total Train Time (s)         29092.888640917838
Epoch                        438
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:07:37.702945 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #438 | Epoch Duration: 77.07540917396545
2020-01-11 08:07:37.703131 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #438 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0853676
Z variance train             0.016797509
KL Divergence                13.437697
KL Loss                      1.3437698
QF Loss                      89.910545
VF Loss                      32.01306
Policy Loss                  -1419.6718
Q Predictions Mean           1419.7373
Q Predictions Std            322.63705
Q Predictions Max            1656.7845
Q Predictions Min            4.275228
V Predictions Mean           1418.3398
V Predictions Std            320.79208
V Predictions Max            1652.8429
V Predictions Min            3.889669
Log Pis Mean                 -0.59454393
Log Pis Std                  1.7807089
Log Pis Max                  6.082367
Log Pis Min                  -4.729945
Policy mu Mean               -0.0005947811
Policy mu Std                0.8195278
Policy mu Max                2.4060168
Policy mu Min                -2.743879
Policy log std Mean          -0.39223608
Policy log std Std           0.14744811
Policy log std Max           -0.1035738
Policy log std Min           -1.080835
Z mean eval                  1.0295271
Z variance eval              0.01618689
total_rewards                [3080.97760734 3215.891818   3056.32290082 2425.32097439 2874.91294752
 3116.05614849 3110.82075063 3070.10324076 2787.41288582 3147.31450751]
total_rewards_mean           2988.513378128848
total_rewards_std            223.26706552171555
total_rewards_max            3215.891818004521
total_rewards_min            2425.3209743863713
Number of train steps total  440000
Number of env steps total    2202000
Number of rollouts total     0
Train Time (s)               35.37691903114319
(Previous) Eval Time (s)     20.940583295188844
Sample Time (s)              22.47290934761986
Epoch Time (s)               78.7904116739519
Total Train Time (s)         29179.720994281117
Epoch                        439
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:09:04.538682 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #439 | Epoch Duration: 86.83539080619812
2020-01-11 08:09:04.538827 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #439 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0338898
Z variance train             0.015798816
KL Divergence                13.096419
KL Loss                      1.309642
QF Loss                      182.29245
VF Loss                      91.14768
Policy Loss                  -1413.3903
Q Predictions Mean           1406.814
Q Predictions Std            314.87827
Q Predictions Max            1635.29
Q Predictions Min            -6.9975386
V Predictions Mean           1413.9922
V Predictions Std            314.07678
V Predictions Max            1635.2188
V Predictions Min            2.5800347
Log Pis Mean                 -0.6879133
Log Pis Std                  1.774505
Log Pis Max                  6.918976
Log Pis Min                  -4.0483437
Policy mu Mean               0.104588725
Policy mu Std                0.7854226
Policy mu Max                2.43805
Policy mu Min                -2.9380107
Policy log std Mean          -0.36902764
Policy log std Std           0.14025307
Policy log std Max           -0.09280641
Policy log std Min           -0.9988758
Z mean eval                  1.028729
Z variance eval              0.028604697
total_rewards                [3106.7505949  3099.57486101 3150.5755576  3154.81238899 3102.28256301
 3185.71514173 3133.187237   3160.98879863 3135.13244067 3166.73779845]
total_rewards_mean           3139.5757381988515
total_rewards_std            27.94134884325801
total_rewards_max            3185.715141734
total_rewards_min            3099.5748610098785
Number of train steps total  441000
Number of env steps total    2207000
Number of rollouts total     0
Train Time (s)               35.92293333867565
(Previous) Eval Time (s)     28.985153893008828
Sample Time (s)              24.531074893195182
Epoch Time (s)               89.43916212487966
Total Train Time (s)         29271.042140200734
Epoch                        440
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:10:35.864852 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #440 | Epoch Duration: 91.32589101791382
2020-01-11 08:10:35.865122 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #440 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0284164
Z variance train             0.02862975
KL Divergence                12.208845
KL Loss                      1.2208846
QF Loss                      160.10828
VF Loss                      44.334126
Policy Loss                  -1422.7755
Q Predictions Mean           1421.325
Q Predictions Std            348.62842
Q Predictions Max            1681.4828
Q Predictions Min            4.8499026
V Predictions Mean           1423.3094
V Predictions Std            346.18372
V Predictions Max            1682.6165
V Predictions Min            6.0160174
Log Pis Mean                 -0.4867906
Log Pis Std                  1.952325
Log Pis Max                  7.197135
Log Pis Min                  -4.2227917
Policy mu Mean               -0.010633388
Policy mu Std                0.84927833
Policy mu Max                2.5814936
Policy mu Min                -2.7729492
Policy log std Mean          -0.3940721
Policy log std Std           0.17559645
Policy log std Max           -0.07097116
Policy log std Min           -1.4639069
Z mean eval                  1.0511299
Z variance eval              0.01443845
total_rewards                [3240.8936193  1272.37366662 2907.19965263 2131.86420412 3228.91002681
 1850.49334787 3243.8353989  3244.75783257 3300.65519712  540.92985332]
total_rewards_mean           2496.191279925358
total_rewards_std            943.25547227764
total_rewards_max            3300.6551971191075
total_rewards_min            540.9298533166169
Number of train steps total  442000
Number of env steps total    2212000
Number of rollouts total     0
Train Time (s)               35.174538732971996
(Previous) Eval Time (s)     30.871472583152354
Sample Time (s)              25.543601005338132
Epoch Time (s)               91.58961232146248
Total Train Time (s)         29355.240121221635
Epoch                        441
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:12:00.068315 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #441 | Epoch Duration: 84.20303773880005
2020-01-11 08:12:00.068553 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #441 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0520127
Z variance train             0.014436321
KL Divergence                13.27939
KL Loss                      1.327939
QF Loss                      154.03244
VF Loss                      31.743061
Policy Loss                  -1459.343
Q Predictions Mean           1457.593
Q Predictions Std            328.60965
Q Predictions Max            1670.1069
Q Predictions Min            -9.381327
V Predictions Mean           1457.263
V Predictions Std            328.318
V Predictions Max            1670.2472
V Predictions Min            2.3697424
Log Pis Mean                 -0.5071006
Log Pis Std                  1.795124
Log Pis Max                  6.3781023
Log Pis Min                  -4.489067
Policy mu Mean               -0.024798073
Policy mu Std                0.78812426
Policy mu Max                2.0638638
Policy mu Min                -2.8219004
Policy log std Mean          -0.3905162
Policy log std Std           0.1535521
Policy log std Max           -0.08044667
Policy log std Min           -1.1773268
Z mean eval                  1.0719849
Z variance eval              0.011324603
total_rewards                [1665.58470581 2757.80293117 1264.45237946 2006.24612061 3215.7367633
 3240.54541282 1267.46794031 1281.6962602  3197.19888363 1933.47424173]
total_rewards_mean           2183.020563903766
total_rewards_std            799.9653769343851
total_rewards_max            3240.5454128170786
total_rewards_min            1264.452379460933
Number of train steps total  443000
Number of env steps total    2217000
Number of rollouts total     0
Train Time (s)               35.44337919540703
(Previous) Eval Time (s)     23.484454358927906
Sample Time (s)              23.701739489566535
Epoch Time (s)               82.62957304390147
Total Train Time (s)         29435.140429697465
Epoch                        442
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:13:19.972938 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #442 | Epoch Duration: 79.90423560142517
2020-01-11 08:13:19.973120 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #442 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0719669
Z variance train             0.011314721
KL Divergence                13.889677
KL Loss                      1.3889678
QF Loss                      207.00577
VF Loss                      90.85549
Policy Loss                  -1433.4939
Q Predictions Mean           1434.3467
Q Predictions Std            316.8125
Q Predictions Max            1668.2155
Q Predictions Min            23.46359
V Predictions Mean           1438.0625
V Predictions Std            317.53616
V Predictions Max            1676.5901
V Predictions Min            25.124678
Log Pis Mean                 -0.4254901
Log Pis Std                  1.8808513
Log Pis Max                  5.8980303
Log Pis Min                  -5.801648
Policy mu Mean               -0.07581643
Policy mu Std                0.85525215
Policy mu Max                2.0602643
Policy mu Min                -2.7211916
Policy log std Mean          -0.4045746
Policy log std Std           0.14735271
Policy log std Max           -0.006244123
Policy log std Min           -1.2596146
Z mean eval                  1.0247093
Z variance eval              0.01101264
total_rewards                [3190.9437153  3122.10054009 3149.2445657  3175.22281195 1320.3520481
 3118.49001108 3177.4887882  3187.77371262 3100.25264391 3174.09165191]
total_rewards_mean           2971.5960488866585
total_rewards_std            551.2398781075088
total_rewards_max            3190.9437153022773
total_rewards_min            1320.3520480962482
Number of train steps total  444000
Number of env steps total    2222000
Number of rollouts total     0
Train Time (s)               35.589056792669
(Previous) Eval Time (s)     20.758768701925874
Sample Time (s)              23.457292444072664
Epoch Time (s)               79.80511793866754
Total Train Time (s)         29523.055326925125
Epoch                        443
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:14:47.892351 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #443 | Epoch Duration: 87.91910004615784
2020-01-11 08:14:47.892543 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #443 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0250546
Z variance train             0.011043287
KL Divergence                13.683428
KL Loss                      1.3683428
QF Loss                      84.34367
VF Loss                      72.681175
Policy Loss                  -1370.354
Q Predictions Mean           1370.4812
Q Predictions Std            333.17508
Q Predictions Max            1594.8315
Q Predictions Min            7.662837
V Predictions Mean           1371.8079
V Predictions Std            333.25876
V Predictions Max            1589.4873
V Predictions Min            5.1261754
Log Pis Mean                 -0.42050475
Log Pis Std                  1.9358997
Log Pis Max                  7.938266
Log Pis Min                  -4.8827777
Policy mu Mean               -0.047617164
Policy mu Std                0.8600398
Policy mu Max                3.3922303
Policy mu Min                -2.7068486
Policy log std Mean          -0.4149541
Policy log std Std           0.15848881
Policy log std Max           -0.05239615
Policy log std Min           -1.0691123
Z mean eval                  1.0425928
Z variance eval              0.009633384
total_rewards                [1018.41842877 1175.60468536 2395.69175311 3136.1228252  3136.46007607
 3156.60905844 1296.95967455 1322.24794312 3159.75670196  997.55864132]
total_rewards_mean           2079.542978789911
total_rewards_std            946.5743527153206
total_rewards_max            3159.756701957325
total_rewards_min            997.55864131816
Number of train steps total  445000
Number of env steps total    2227000
Number of rollouts total     0
Train Time (s)               35.132893305271864
(Previous) Eval Time (s)     28.87238884717226
Sample Time (s)              24.016335084103048
Epoch Time (s)               88.02161723654717
Total Train Time (s)         29602.444126349874
Epoch                        444
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:16:07.285816 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #444 | Epoch Duration: 79.3931348323822
2020-01-11 08:16:07.286000 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #444 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0423291
Z variance train             0.009626275
KL Divergence                14.508681
KL Loss                      1.4508681
QF Loss                      140.3212
VF Loss                      29.473082
Policy Loss                  -1421.4508
Q Predictions Mean           1420.9572
Q Predictions Std            317.42526
Q Predictions Max            1632.4133
Q Predictions Min            4.347717
V Predictions Mean           1419.0406
V Predictions Std            316.51447
V Predictions Max            1627.816
V Predictions Min            2.2123196
Log Pis Mean                 -0.72655916
Log Pis Std                  1.6111106
Log Pis Max                  5.3988276
Log Pis Min                  -5.3621216
Policy mu Mean               -0.03737588
Policy mu Std                0.7781189
Policy mu Max                2.031158
Policy mu Min                -2.821335
Policy log std Mean          -0.3814505
Policy log std Std           0.15556729
Policy log std Max           -0.03647977
Policy log std Min           -1.1426818
Z mean eval                  1.0691814
Z variance eval              0.016491672
total_rewards                [1354.21906135 2845.68686907 3239.63678654 3088.74252129 3235.93779099
 3129.12411455 3171.35347487 1186.12209656 3148.09736863 3154.6889502 ]
total_rewards_mean           2755.3609034039246
total_rewards_std            750.7956999838233
total_rewards_max            3239.6367865367943
total_rewards_min            1186.1220965576365
Number of train steps total  446000
Number of env steps total    2232000
Number of rollouts total     0
Train Time (s)               36.18305180687457
(Previous) Eval Time (s)     20.24355548620224
Sample Time (s)              23.751956227235496
Epoch Time (s)               80.17856352031231
Total Train Time (s)         29689.74490476679
Epoch                        445
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:17:34.592235 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #445 | Epoch Duration: 87.30607461929321
2020-01-11 08:17:34.592483 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #445 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0669773
Z variance train             0.016470384
KL Divergence                14.414482
KL Loss                      1.4414482
QF Loss                      139.8233
VF Loss                      180.46483
Policy Loss                  -1460.0837
Q Predictions Mean           1464.5565
Q Predictions Std            260.99597
Q Predictions Max            1682.7719
Q Predictions Min            7.8866754
V Predictions Mean           1467.1716
V Predictions Std            261.52484
V Predictions Max            1683.1776
V Predictions Min            5.7332234
Log Pis Mean                 -0.46689725
Log Pis Std                  1.8775761
Log Pis Max                  4.9183664
Log Pis Min                  -5.204694
Policy mu Mean               -0.009651761
Policy mu Std                0.87756044
Policy mu Max                2.0924118
Policy mu Min                -2.6862712
Policy log std Mean          -0.41644016
Policy log std Std           0.16038585
Policy log std Max           -0.093372576
Policy log std Min           -1.0547934
Z mean eval                  1.0113695
Z variance eval              0.027572852
total_rewards                [2907.56459527 3109.87253569 3175.11213586 3058.30862568 3093.17759415
 3099.34143328 1570.00330819 1540.23422476 3117.33989233 3149.02907074]
total_rewards_mean           2781.9983415946535
total_rewards_std            617.2332589269313
total_rewards_max            3175.1121358559267
total_rewards_min            1540.2342247625352
Number of train steps total  447000
Number of env steps total    2237000
Number of rollouts total     0
Train Time (s)               35.39515143400058
(Previous) Eval Time (s)     27.370678312610835
Sample Time (s)              25.366202150005847
Epoch Time (s)               88.13203189661726
Total Train Time (s)         29777.866587566212
Epoch                        446
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:19:02.721157 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #446 | Epoch Duration: 88.12837839126587
2020-01-11 08:19:02.721652 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #446 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0102861
Z variance train             0.027507782
KL Divergence                13.531494
KL Loss                      1.3531494
QF Loss                      136.46002
VF Loss                      39.522556
Policy Loss                  -1446.3838
Q Predictions Mean           1444.4233
Q Predictions Std            274.88293
Q Predictions Max            1653.4362
Q Predictions Min            5.4329
V Predictions Mean           1449.1603
V Predictions Std            274.88528
V Predictions Max            1662.7213
V Predictions Min            13.762198
Log Pis Mean                 -0.6817046
Log Pis Std                  1.6132715
Log Pis Max                  6.105335
Log Pis Min                  -4.670588
Policy mu Mean               0.025162235
Policy mu Std                0.7706975
Policy mu Max                2.140467
Policy mu Min                -2.6862154
Policy log std Mean          -0.37898913
Policy log std Std           0.14666013
Policy log std Max           -0.06997213
Policy log std Min           -0.9897584
Z mean eval                  1.0133358
Z variance eval              0.0238263
total_rewards                [3120.44296888 1086.61059425 3116.86886203 3089.13757246 3107.84427322
 3145.77110046 3080.78238209 1205.76361082 3065.15403507 2232.69734556]
total_rewards_mean           2625.1072744849857
total_rewards_std            783.7991984163496
total_rewards_max            3145.7711004590124
total_rewards_min            1086.6105942531944
Number of train steps total  448000
Number of env steps total    2242000
Number of rollouts total     0
Train Time (s)               35.18963471474126
(Previous) Eval Time (s)     27.366625481750816
Sample Time (s)              23.459576067514718
Epoch Time (s)               86.0158362640068
Total Train Time (s)         29860.55969138397
Epoch                        447
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:20:25.417684 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #447 | Epoch Duration: 82.6957471370697
2020-01-11 08:20:25.417992 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #447 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0125444
Z variance train             0.02383651
KL Divergence                12.666479
KL Loss                      1.2666479
QF Loss                      192.8548
VF Loss                      261.8964
Policy Loss                  -1353.5763
Q Predictions Mean           1351.6721
Q Predictions Std            336.5757
Q Predictions Max            1570.9432
Q Predictions Min            -7.806036
V Predictions Mean           1358.7981
V Predictions Std            334.9736
V Predictions Max            1578.0327
V Predictions Min            4.379007
Log Pis Mean                 -0.6170158
Log Pis Std                  1.8715869
Log Pis Max                  5.942801
Log Pis Min                  -4.811013
Policy mu Mean               0.006992905
Policy mu Std                0.81446254
Policy mu Max                1.995537
Policy mu Min                -2.917346
Policy log std Mean          -0.40929258
Policy log std Std           0.15891601
Policy log std Max           -0.08289924
Policy log std Min           -1.0760587
Z mean eval                  1.0043442
Z variance eval              0.02245279
total_rewards                [1279.25141548 2876.0464824  3197.31124313 2993.93071778 3169.00445423
 3219.0526738  3188.96513916 3214.70831175 3243.13865116 3176.37719673]
total_rewards_mean           2955.7786285621273
total_rewards_std            569.5904505176801
total_rewards_max            3243.1386511574215
total_rewards_min            1279.251415478575
Number of train steps total  449000
Number of env steps total    2247000
Number of rollouts total     0
Train Time (s)               35.2847806699574
(Previous) Eval Time (s)     24.046215232927352
Sample Time (s)              24.28200046811253
Epoch Time (s)               83.61299637099728
Total Train Time (s)         29947.68215335207
Epoch                        448
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:21:52.545023 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #448 | Epoch Duration: 87.12676644325256
2020-01-11 08:21:52.545306 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #448 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0045059
Z variance train             0.022465074
KL Divergence                11.860392
KL Loss                      1.1860392
QF Loss                      94.40271
VF Loss                      49.045673
Policy Loss                  -1288.8711
Q Predictions Mean           1287.3677
Q Predictions Std            272.34708
Q Predictions Max            1517.0828
Q Predictions Min            8.272027
V Predictions Mean           1290.6578
V Predictions Std            273.2477
V Predictions Max            1512.9884
V Predictions Min            13.493846
Log Pis Mean                 -0.6274694
Log Pis Std                  1.6844693
Log Pis Max                  5.18699
Log Pis Min                  -4.0309086
Policy mu Mean               -0.009642194
Policy mu Std                0.8285162
Policy mu Max                2.2581336
Policy mu Min                -2.6199844
Policy log std Mean          -0.40228245
Policy log std Std           0.15078232
Policy log std Max           -0.03063023
Policy log std Min           -1.0430483
Z mean eval                  1.008631
Z variance eval              0.01966574
total_rewards                [3278.98465766 2953.24477982 3279.93049354 1996.96133486 1346.88009779
 3258.04179654 1046.80421136 1285.86884732 1084.85661538 3219.24127953]
total_rewards_mean           2275.081411379141
total_rewards_std            958.0108471760296
total_rewards_max            3279.9304935402242
total_rewards_min            1046.8042113555903
Number of train steps total  450000
Number of env steps total    2252000
Number of rollouts total     0
Train Time (s)               33.23810817301273
(Previous) Eval Time (s)     27.559650528244674
Sample Time (s)              24.019827058073133
Epoch Time (s)               84.81758575933054
Total Train Time (s)         30024.20099601196
Epoch                        449
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:23:09.067759 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #449 | Epoch Duration: 76.52230286598206
2020-01-11 08:23:09.067925 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #449 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0093887
Z variance train             0.019631995
KL Divergence                12.214765
KL Loss                      1.2214764
QF Loss                      100.239
VF Loss                      30.366602
Policy Loss                  -1476.5737
Q Predictions Mean           1476.3564
Q Predictions Std            254.83118
Q Predictions Max            1678.6821
Q Predictions Min            3.4678397
V Predictions Mean           1473.6055
V Predictions Std            253.44617
V Predictions Max            1669.287
V Predictions Min            5.569145
Log Pis Mean                 -0.7405
Log Pis Std                  1.6087284
Log Pis Max                  4.7792077
Log Pis Min                  -4.4398527
Policy mu Mean               0.04509483
Policy mu Std                0.7773392
Policy mu Max                2.3349485
Policy mu Min                -2.6436043
Policy log std Mean          -0.39423373
Policy log std Std           0.14510374
Policy log std Max           -0.040539414
Policy log std Min           -1.0157444
Z mean eval                  0.9927921
Z variance eval              0.020106196
total_rewards                [ 765.1097114  2147.4101406  3064.81162131 3202.41092232 2743.31298013
 3183.55868948 2209.94736636 3159.65282617 3159.14300696 3161.64436045]
total_rewards_mean           2679.7001625175567
total_rewards_std            744.4195418361711
total_rewards_max            3202.4109223164132
total_rewards_min            765.1097113986431
Number of train steps total  451000
Number of env steps total    2257000
Number of rollouts total     0
Train Time (s)               33.55613607773557
(Previous) Eval Time (s)     19.264017588924617
Sample Time (s)              22.788893068674952
Epoch Time (s)               75.60904673533514
Total Train Time (s)         30104.99643840408
Epoch                        450
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:24:29.867092 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #450 | Epoch Duration: 80.79905223846436
2020-01-11 08:24:29.867291 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #450 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99353695
Z variance train             0.020158669
KL Divergence                12.026512
KL Loss                      1.2026513
QF Loss                      230.55319
VF Loss                      92.84144
Policy Loss                  -1368.8085
Q Predictions Mean           1367.8375
Q Predictions Std            260.34198
Q Predictions Max            1577.1016
Q Predictions Min            20.740839
V Predictions Mean           1363.2849
V Predictions Std            258.22287
V Predictions Max            1565.8888
V Predictions Min            16.530485
Log Pis Mean                 -0.5015001
Log Pis Std                  1.8184811
Log Pis Max                  6.7013226
Log Pis Min                  -5.4280167
Policy mu Mean               -0.06974461
Policy mu Std                0.8212233
Policy mu Max                1.924339
Policy mu Min                -2.742686
Policy log std Mean          -0.39932704
Policy log std Std           0.1574021
Policy log std Max           -0.05956766
Policy log std Min           -1.1387355
Z mean eval                  1.0030844
Z variance eval              0.016215805
total_rewards                [1235.59944944 3336.1544902  1798.60326463 3258.63209368 3250.86253393
 3312.42568925 3214.90798505 3322.23117656 3251.44980392 3234.8256173 ]
total_rewards_mean           2921.569210396031
total_rewards_std            714.4067610252389
total_rewards_max            3336.154490203767
total_rewards_min            1235.5994494445074
Number of train steps total  452000
Number of env steps total    2262000
Number of rollouts total     0
Train Time (s)               33.53725341614336
(Previous) Eval Time (s)     24.453712347429246
Sample Time (s)              23.69090596586466
Epoch Time (s)               81.68187172943726
Total Train Time (s)         30188.99187021097
Epoch                        451
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:25:53.868414 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #451 | Epoch Duration: 84.00097513198853
2020-01-11 08:25:53.868630 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #451 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0044861
Z variance train             0.016264405
KL Divergence                12.9948
KL Loss                      1.29948
QF Loss                      85.42585
VF Loss                      57.095985
Policy Loss                  -1375.9962
Q Predictions Mean           1376.9834
Q Predictions Std            228.28688
Q Predictions Max            1583.8279
Q Predictions Min            12.062069
V Predictions Mean           1370.7686
V Predictions Std            225.44598
V Predictions Max            1574.8612
V Predictions Min            18.055199
Log Pis Mean                 -0.54028404
Log Pis Std                  1.8347746
Log Pis Max                  5.610224
Log Pis Min                  -4.282825
Policy mu Mean               0.10104779
Policy mu Std                0.8252862
Policy mu Max                2.5341516
Policy mu Min                -2.7656357
Policy log std Mean          -0.40847287
Policy log std Std           0.15249562
Policy log std Max           -0.112326674
Policy log std Min           -1.1262965
Z mean eval                  1.0028079
Z variance eval              0.015998954
total_rewards                [2467.05788698 2761.60057725 3121.84778055 3149.37134562 1374.23068252
 2316.68951072 2195.50608709 1966.53919488 2860.91859269 3136.968844  ]
total_rewards_mean           2535.0730502296074
total_rewards_std            554.9634642953007
total_rewards_max            3149.3713456218547
total_rewards_min            1374.2306825197209
Number of train steps total  453000
Number of env steps total    2267000
Number of rollouts total     0
Train Time (s)               32.974846662953496
(Previous) Eval Time (s)     26.77246316941455
Sample Time (s)              23.744419708848
Epoch Time (s)               83.49172954121605
Total Train Time (s)         30269.189411411528
Epoch                        452
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:27:14.069499 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #452 | Epoch Duration: 80.20071840286255
2020-01-11 08:27:14.069671 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #452 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0013502
Z variance train             0.01599444
KL Divergence                12.934865
KL Loss                      1.2934865
QF Loss                      181.42374
VF Loss                      53.48559
Policy Loss                  -1394.2157
Q Predictions Mean           1393.6276
Q Predictions Std            243.46834
Q Predictions Max            1582.4401
Q Predictions Min            11.117734
V Predictions Mean           1397.1481
V Predictions Std            241.34543
V Predictions Max            1588.6742
V Predictions Min            23.918194
Log Pis Mean                 -0.40027755
Log Pis Std                  1.8460919
Log Pis Max                  7.20561
Log Pis Min                  -5.2640867
Policy mu Mean               0.09849417
Policy mu Std                0.8196433
Policy mu Max                2.5816836
Policy mu Min                -2.6555989
Policy log std Mean          -0.4015529
Policy log std Std           0.15859275
Policy log std Max           -0.093948275
Policy log std Min           -1.1053469
Z mean eval                  0.9933971
Z variance eval              0.015107912
total_rewards                [3159.68318002  166.13110551 1307.00496348  784.06559544 1171.42696248
 1598.45398705 2906.60016009 1289.41072249 3212.34551984 1854.50693468]
total_rewards_mean           1744.9629131058543
total_rewards_std            983.9625491991703
total_rewards_max            3212.345519839207
total_rewards_min            166.13110550737352
Number of train steps total  454000
Number of env steps total    2272000
Number of rollouts total     0
Train Time (s)               33.27932595089078
(Previous) Eval Time (s)     23.48115499317646
Sample Time (s)              22.58130910806358
Epoch Time (s)               79.34179005213082
Total Train Time (s)         30342.37592401309
Epoch                        453
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:28:27.260805 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #453 | Epoch Duration: 73.19100141525269
2020-01-11 08:28:27.260967 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #453 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9936659
Z variance train             0.0151369795
KL Divergence                12.78792
KL Loss                      1.278792
QF Loss                      83.10467
VF Loss                      32.17729
Policy Loss                  -1422.5299
Q Predictions Mean           1421.7064
Q Predictions Std            197.38228
Q Predictions Max            1578.0518
Q Predictions Min            10.307169
V Predictions Mean           1423.3953
V Predictions Std            197.48877
V Predictions Max            1580.0205
V Predictions Min            12.301
Log Pis Mean                 -0.4303573
Log Pis Std                  1.7674917
Log Pis Max                  6.7945886
Log Pis Min                  -4.7289653
Policy mu Mean               0.02272585
Policy mu Std                0.83760726
Policy mu Max                1.8727459
Policy mu Min                -2.7707758
Policy log std Mean          -0.41037297
Policy log std Std           0.15754381
Policy log std Max           -0.075871795
Policy log std Min           -1.150604
Z mean eval                  0.9817627
Z variance eval              0.01779924
total_rewards                [3049.38525395 2934.57550851 3128.16000565 1048.74538823 1630.87195332
 2697.49260828 3091.57690968 3084.25851959 3074.55389459 3044.33098484]
total_rewards_mean           2678.3951026651184
total_rewards_std            691.7567052553129
total_rewards_max            3128.1600056532684
total_rewards_min            1048.7453882334817
Number of train steps total  455000
Number of env steps total    2277000
Number of rollouts total     0
Train Time (s)               33.00450460892171
(Previous) Eval Time (s)     17.330085618887097
Sample Time (s)              23.379230634775013
Epoch Time (s)               73.71382086258382
Total Train Time (s)         30424.511682900134
Epoch                        454
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:29:49.400776 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #454 | Epoch Duration: 82.13968324661255
2020-01-11 08:29:49.400953 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #454 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9826759
Z variance train             0.017825762
KL Divergence                12.640722
KL Loss                      1.2640723
QF Loss                      110.29744
VF Loss                      180.31947
Policy Loss                  -1462.657
Q Predictions Mean           1460.2922
Q Predictions Std            199.20888
Q Predictions Max            1638.8717
Q Predictions Min            40.864933
V Predictions Mean           1458.792
V Predictions Std            200.81776
V Predictions Max            1630.6698
V Predictions Min            21.933693
Log Pis Mean                 -0.44054553
Log Pis Std                  1.9873326
Log Pis Max                  6.802993
Log Pis Min                  -8.132811
Policy mu Mean               -0.04397871
Policy mu Std                0.8870023
Policy mu Max                2.4132223
Policy mu Min                -2.8469632
Policy log std Mean          -0.39352033
Policy log std Std           0.15213828
Policy log std Max           -0.020672515
Policy log std Min           -1.0450468
Z mean eval                  0.97652876
Z variance eval              0.021056604
total_rewards                [1252.79934137 3119.52023597 3177.63624351 1120.12911853 3249.70526428
 1734.44206677 3134.45394384 3165.33704248 2496.73333273 3148.94524227]
total_rewards_mean           2559.970183175767
total_rewards_std            817.3779922989115
total_rewards_max            3249.705264281706
total_rewards_min            1120.1291185292068
Number of train steps total  456000
Number of env steps total    2282000
Number of rollouts total     0
Train Time (s)               33.21718855202198
(Previous) Eval Time (s)     25.755594263784587
Sample Time (s)              24.10677511198446
Epoch Time (s)               83.07955792779103
Total Train Time (s)         30505.240420949645
Epoch                        455
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:31:10.134598 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #455 | Epoch Duration: 80.73347187042236
2020-01-11 08:31:10.134832 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #455 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9787852
Z variance train             0.02108668
KL Divergence                11.913782
KL Loss                      1.1913782
QF Loss                      141.90662
VF Loss                      68.88385
Policy Loss                  -1429.9132
Q Predictions Mean           1428.0964
Q Predictions Std            207.71454
Q Predictions Max            1619.769
Q Predictions Min            48.576664
V Predictions Mean           1424.936
V Predictions Std            206.83955
V Predictions Max            1610.7054
V Predictions Min            20.265184
Log Pis Mean                 -0.47000948
Log Pis Std                  2.0400357
Log Pis Max                  10.43145
Log Pis Min                  -3.7482932
Policy mu Mean               -0.04707669
Policy mu Std                0.83531904
Policy mu Max                3.0407577
Policy mu Min                -2.8055582
Policy log std Mean          -0.40005806
Policy log std Std           0.16150175
Policy log std Max           -0.11494717
Policy log std Min           -1.0843515
Z mean eval                  0.99279135
Z variance eval              0.013890959
total_rewards                [3286.73892878 3214.29662534 1392.69306394 3259.43407835 3335.83071981
 3311.60251578 3266.7791069  3252.002545   3216.52144857 1483.3383884 ]
total_rewards_mean           2901.923742087148
total_rewards_std            733.1025247217624
total_rewards_max            3335.8307198108964
total_rewards_min            1392.6930639408313
Number of train steps total  457000
Number of env steps total    2287000
Number of rollouts total     0
Train Time (s)               33.85720175597817
(Previous) Eval Time (s)     23.40909078111872
Sample Time (s)              22.52047119382769
Epoch Time (s)               79.78676373092458
Total Train Time (s)         30589.230480974074
Epoch                        456
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:32:34.130576 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #456 | Epoch Duration: 83.99548602104187
2020-01-11 08:32:34.130927 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #456 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98974526
Z variance train             0.013905883
KL Divergence                13.099727
KL Loss                      1.3099726
QF Loss                      109.535164
VF Loss                      31.8909
Policy Loss                  -1392.0228
Q Predictions Mean           1389.8866
Q Predictions Std            206.26471
Q Predictions Max            1566.1903
Q Predictions Min            -7.208816
V Predictions Mean           1391.0978
V Predictions Std            205.06136
V Predictions Max            1563.3545
V Predictions Min            3.5836596
Log Pis Mean                 -0.5055023
Log Pis Std                  1.8056264
Log Pis Max                  6.938448
Log Pis Min                  -4.7854767
Policy mu Mean               0.0060676853
Policy mu Std                0.80845404
Policy mu Max                2.2636533
Policy mu Min                -2.9127414
Policy log std Mean          -0.38321352
Policy log std Std           0.15172733
Policy log std Max           -0.0652356
Policy log std Min           -1.0391183
Z mean eval                  1.0037801
Z variance eval              0.0141722085
total_rewards                [3286.73896672 1363.55711341 3264.01700702 3216.55140751 1218.44905989
 2108.23422567 3194.44478378 3225.54655159 3216.64492155 1324.50767515]
total_rewards_mean           2541.869171228228
total_rewards_std            876.9255959041512
total_rewards_max            3286.738966717776
total_rewards_min            1218.4490598908806
Number of train steps total  458000
Number of env steps total    2292000
Number of rollouts total     0
Train Time (s)               33.24799809418619
(Previous) Eval Time (s)     27.617454521358013
Sample Time (s)              24.107087895274162
Epoch Time (s)               84.97254051081836
Total Train Time (s)         30670.368199815042
Epoch                        457
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:33:55.272498 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #457 | Epoch Duration: 81.14136624336243
2020-01-11 08:33:55.272716 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #457 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9977419
Z variance train             0.014168091
KL Divergence                13.116124
KL Loss                      1.3116125
QF Loss                      61.849384
VF Loss                      51.39077
Policy Loss                  -1379.9226
Q Predictions Mean           1382.3496
Q Predictions Std            260.2344
Q Predictions Max            1581.3207
Q Predictions Min            5.331466
V Predictions Mean           1384.5693
V Predictions Std            258.57114
V Predictions Max            1576.5382
V Predictions Min            2.6888702
Log Pis Mean                 -0.86655223
Log Pis Std                  1.6152978
Log Pis Max                  6.048401
Log Pis Min                  -5.6559596
Policy mu Mean               0.058595106
Policy mu Std                0.75406957
Policy mu Max                2.3056
Policy mu Min                -2.7693262
Policy log std Mean          -0.36851367
Policy log std Std           0.14126782
Policy log std Max           -0.048436552
Policy log std Min           -0.9059896
Z mean eval                  0.9829439
Z variance eval              0.012538863
total_rewards                [ 156.44376961 3133.32715877 2597.37647088  167.64571541 3144.97136975
  262.48110427 3153.58770682  170.69797257 3127.29398684 1114.16467059]
total_rewards_mean           1702.7989925510597
total_rewards_std            1362.9660423643131
total_rewards_max            3153.5877068160617
total_rewards_min            156.44376961261167
Number of train steps total  459000
Number of env steps total    2297000
Number of rollouts total     0
Train Time (s)               32.848567731212825
(Previous) Eval Time (s)     23.78588433098048
Sample Time (s)              24.53421053290367
Epoch Time (s)               81.16866259509698
Total Train Time (s)         30744.159594559576
Epoch                        458
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:35:09.068572 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #458 | Epoch Duration: 73.79569149017334
2020-01-11 08:35:09.068758 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #458 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98275965
Z variance train             0.012521143
KL Divergence                13.389
KL Loss                      1.3389
QF Loss                      70.79628
VF Loss                      43.07847
Policy Loss                  -1373.8271
Q Predictions Mean           1373.2515
Q Predictions Std            220.03485
Q Predictions Max            1562.3481
Q Predictions Min            -2.786074
V Predictions Mean           1377.0172
V Predictions Std            219.15443
V Predictions Max            1567.2385
V Predictions Min            -0.44044268
Log Pis Mean                 -0.5164236
Log Pis Std                  1.8767631
Log Pis Max                  7.8771505
Log Pis Min                  -4.6710863
Policy mu Mean               0.036189977
Policy mu Std                0.8224758
Policy mu Max                2.7220774
Policy mu Min                -2.8897934
Policy log std Mean          -0.36888584
Policy log std Std           0.15786393
Policy log std Max           -0.0314402
Policy log std Min           -1.1389841
Z mean eval                  0.9799452
Z variance eval              0.014974763
total_rewards                [2634.3986339  3116.3076013  3237.27028232 3011.477451   3248.29587775
 3206.04296222 3241.93389836 3223.14996434 3169.08171211 3190.58794534]
total_rewards_mean           3127.854632866177
total_rewards_std            178.18460021788795
total_rewards_max            3248.2958777545205
total_rewards_min            2634.3986339012845
Number of train steps total  460000
Number of env steps total    2302000
Number of rollouts total     0
Train Time (s)               33.21506361523643
(Previous) Eval Time (s)     16.41258138185367
Sample Time (s)              23.324838375207037
Epoch Time (s)               72.95248337229714
Total Train Time (s)         30829.978999510873
Epoch                        459
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:36:34.893669 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #459 | Epoch Duration: 85.82471060752869
2020-01-11 08:36:34.893970 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #459 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9827547
Z variance train             0.014914306
KL Divergence                12.8198185
KL Loss                      1.2819818
QF Loss                      188.55693
VF Loss                      78.32319
Policy Loss                  -1418.9714
Q Predictions Mean           1413.7356
Q Predictions Std            241.2017
Q Predictions Max            1597.0421
Q Predictions Min            0.8964466
V Predictions Mean           1412.7017
V Predictions Std            239.06833
V Predictions Max            1586.3169
V Predictions Min            2.4595265
Log Pis Mean                 -0.65529525
Log Pis Std                  1.6521587
Log Pis Max                  4.483102
Log Pis Min                  -3.9347486
Policy mu Mean               -0.056220394
Policy mu Std                0.7870055
Policy mu Max                1.881985
Policy mu Min                -2.8289254
Policy log std Mean          -0.37710175
Policy log std Std           0.14149483
Policy log std Max           -0.028019413
Policy log std Min           -0.8149761
Z mean eval                  0.95189655
Z variance eval              0.014487381
total_rewards                [3148.19596432  718.62298644 3131.11953364 1550.40734722 3215.64483144
 1273.50268969 3021.71247673 1259.66108974 3146.93319882 3196.98893263]
total_rewards_mean           2366.278905067106
total_rewards_std            971.908980604705
total_rewards_max            3215.6448314363
total_rewards_min            718.6229864430255
Number of train steps total  461000
Number of env steps total    2307000
Number of rollouts total     0
Train Time (s)               33.58690929878503
(Previous) Eval Time (s)     29.284480136819184
Sample Time (s)              23.108735247515142
Epoch Time (s)               85.98012468311936
Total Train Time (s)         30909.49844130315
Epoch                        460
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:37:54.417846 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #460 | Epoch Duration: 79.52370882034302
2020-01-11 08:37:54.418046 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #460 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9479186
Z variance train             0.014410233
KL Divergence                13.299567
KL Loss                      1.3299568
QF Loss                      245.0428
VF Loss                      58.997612
Policy Loss                  -1422.347
Q Predictions Mean           1426.105
Q Predictions Std            198.07384
Q Predictions Max            1591.7894
Q Predictions Min            16.423779
V Predictions Mean           1423.7126
V Predictions Std            198.98033
V Predictions Max            1584.5221
V Predictions Min            18.866144
Log Pis Mean                 -0.79780614
Log Pis Std                  1.6688259
Log Pis Max                  5.5049744
Log Pis Min                  -4.6215196
Policy mu Mean               -0.015839493
Policy mu Std                0.782489
Policy mu Max                2.3259373
Policy mu Min                -2.6338205
Policy log std Mean          -0.37082553
Policy log std Std           0.15426198
Policy log std Max           -0.030965358
Policy log std Min           -1.0511837
Z mean eval                  0.9782944
Z variance eval              0.01853257
total_rewards                [ 680.747017    707.42575489  701.19152579  761.97908975  985.88085311
 1540.85916025  795.50792157  727.55691329 1325.11299255  714.3281288 ]
total_rewards_mean           894.0589356998865
total_rewards_std            285.8854011794007
total_rewards_max            1540.8591602532417
total_rewards_min            680.7470170032321
Number of train steps total  462000
Number of env steps total    2312000
Number of rollouts total     0
Train Time (s)               32.64542364189401
(Previous) Eval Time (s)     22.82775945821777
Sample Time (s)              23.407455030828714
Epoch Time (s)               78.8806381309405
Total Train Time (s)         30974.67272722721
Epoch                        461
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:38:59.596764 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #461 | Epoch Duration: 65.17856693267822
2020-01-11 08:38:59.596941 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #461 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97943497
Z variance train             0.018512106
KL Divergence                12.668897
KL Loss                      1.2668897
QF Loss                      161.892
VF Loss                      160.96478
Policy Loss                  -1340.8604
Q Predictions Mean           1340.5493
Q Predictions Std            242.25404
Q Predictions Max            1560.8403
Q Predictions Min            11.006289
V Predictions Mean           1335.8834
V Predictions Std            241.44463
V Predictions Max            1547.4021
V Predictions Min            10.632616
Log Pis Mean                 -0.45810398
Log Pis Std                  1.981222
Log Pis Max                  8.98159
Log Pis Min                  -4.9335656
Policy mu Mean               -0.025518509
Policy mu Std                0.8636102
Policy mu Max                2.2047286
Policy mu Min                -3.0060005
Policy log std Mean          -0.39649728
Policy log std Std           0.16889392
Policy log std Max           -0.017373592
Policy log std Min           -1.1781921
Z mean eval                  0.95936745
Z variance eval              0.012336185
total_rewards                [3200.06392101 3145.86721798 1234.45777257 1109.00265728 3067.49342688
 3172.29984286 2006.44048394 3156.93710469 3184.30160529 3124.25479047]
total_rewards_mean           2640.111882297929
total_rewards_std            809.602201830871
total_rewards_max            3200.0639210127547
total_rewards_min            1109.0026572837899
Number of train steps total  463000
Number of env steps total    2317000
Number of rollouts total     0
Train Time (s)               32.808167894836515
(Previous) Eval Time (s)     9.125376409385353
Sample Time (s)              23.03857024712488
Epoch Time (s)               64.97211455134675
Total Train Time (s)         31055.07885845285
Epoch                        462
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:40:20.006932 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #462 | Epoch Duration: 80.40985989570618
2020-01-11 08:40:20.007114 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #462 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95994914
Z variance train             0.012388713
KL Divergence                13.37752
KL Loss                      1.337752
QF Loss                      90.494934
VF Loss                      88.40311
Policy Loss                  -1389.4106
Q Predictions Mean           1388.7808
Q Predictions Std            209.43167
Q Predictions Max            1567.908
Q Predictions Min            -3.6602871
V Predictions Mean           1392.9111
V Predictions Std            211.03662
V Predictions Max            1569.9202
V Predictions Min            7.4987144
Log Pis Mean                 -0.7639941
Log Pis Std                  1.8066878
Log Pis Max                  7.4455857
Log Pis Min                  -5.390932
Policy mu Mean               0.04472351
Policy mu Std                0.7593594
Policy mu Max                2.639053
Policy mu Min                -2.9370809
Policy log std Mean          -0.38496447
Policy log std Std           0.1491837
Policy log std Max           -0.10232164
Policy log std Min           -1.094767
Z mean eval                  0.96359694
Z variance eval              0.013508404
total_rewards                [3225.71476738 2421.55701508 1216.1310732  3181.76062342 3188.8070188
  976.05782518 3250.13335958 3151.96325288 2143.29896225 1589.90549722]
total_rewards_mean           2434.5329395002
total_rewards_std            856.9242364496223
total_rewards_max            3250.1333595847977
total_rewards_min            976.0578251847594
Number of train steps total  464000
Number of env steps total    2322000
Number of rollouts total     0
Train Time (s)               33.37402247497812
(Previous) Eval Time (s)     24.56277366168797
Sample Time (s)              23.245260717347264
Epoch Time (s)               81.18205685401335
Total Train Time (s)         31134.65892878361
Epoch                        463
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:41:39.589902 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #463 | Epoch Duration: 79.58262991905212
2020-01-11 08:41:39.590045 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #463 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96274245
Z variance train             0.013527334
KL Divergence                13.239925
KL Loss                      1.3239926
QF Loss                      138.36642
VF Loss                      238.25171
Policy Loss                  -1481.5684
Q Predictions Mean           1484.1179
Q Predictions Std            157.4795
Q Predictions Max            1659.6957
Q Predictions Min            327.65167
V Predictions Mean           1494.6052
V Predictions Std            157.03146
V Predictions Max            1658.9641
V Predictions Min            335.08533
Log Pis Mean                 -0.5799408
Log Pis Std                  1.6890764
Log Pis Max                  8.087502
Log Pis Min                  -4.268874
Policy mu Mean               0.016209763
Policy mu Std                0.78117067
Policy mu Max                2.027102
Policy mu Min                -2.828053
Policy log std Mean          -0.3631854
Policy log std Std           0.15104374
Policy log std Max           0.017473504
Policy log std Min           -0.89400214
Z mean eval                  0.92362976
Z variance eval              0.013766773
total_rewards                [1094.81063558 3266.43830389 3263.98957673 3278.29344061 3297.78954357
 3340.34587559 3242.97599145 1226.52612813 3238.40699057 3302.04293417]
total_rewards_mean           2855.1619420290585
total_rewards_std            848.2288400304524
total_rewards_max            3340.3458755888187
total_rewards_min            1094.8106355788104
Number of train steps total  465000
Number of env steps total    2327000
Number of rollouts total     0
Train Time (s)               33.43381212512031
(Previous) Eval Time (s)     22.963074143975973
Sample Time (s)              22.235402000602335
Epoch Time (s)               78.63228826969862
Total Train Time (s)         31215.761041274294
Epoch                        464
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:43:00.697121 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #464 | Epoch Duration: 81.10692572593689
2020-01-11 08:43:00.697457 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #464 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9253645
Z variance train             0.0137337
KL Divergence                13.2087555
KL Loss                      1.3208755
QF Loss                      133.27922
VF Loss                      63.957504
Policy Loss                  -1358.006
Q Predictions Mean           1356.1611
Q Predictions Std            188.40674
Q Predictions Max            1516.2692
Q Predictions Min            6.5281253
V Predictions Mean           1352.3065
V Predictions Std            188.76215
V Predictions Max            1514.4406
V Predictions Min            8.469824
Log Pis Mean                 -0.5932025
Log Pis Std                  1.7381696
Log Pis Max                  5.1081223
Log Pis Min                  -4.0081167
Policy mu Mean               -0.09227126
Policy mu Std                0.779161
Policy mu Max                1.9719634
Policy mu Min                -2.7281682
Policy log std Mean          -0.38125446
Policy log std Std           0.15679337
Policy log std Max           -0.0051164627
Policy log std Min           -0.95244575
Z mean eval                  0.95923203
Z variance eval              0.012524714
total_rewards                [  27.37488867 3189.55740459 1416.2945393  3190.35060288 3262.76163982
 3233.88236986 1211.26314725 2955.92416556 3230.85884559 1216.36978419]
total_rewards_mean           2293.463738769936
total_rewards_std            1139.5066002140002
total_rewards_max            3262.7616398154414
total_rewards_min            27.37488866503026
Number of train steps total  466000
Number of env steps total    2332000
Number of rollouts total     0
Train Time (s)               32.84589056717232
(Previous) Eval Time (s)     25.437350531108677
Sample Time (s)              24.01494421530515
Epoch Time (s)               82.29818531358615
Total Train Time (s)         31293.37542416202
Epoch                        465
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:44:18.317129 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #465 | Epoch Duration: 77.61945152282715
2020-01-11 08:44:18.317442 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #465 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9598039
Z variance train             0.012511136
KL Divergence                13.257729
KL Loss                      1.3257729
QF Loss                      1318.9802
VF Loss                      91.37011
Policy Loss                  -1431.1599
Q Predictions Mean           1426.3148
Q Predictions Std            187.20836
Q Predictions Max            1610.6161
Q Predictions Min            21.766273
V Predictions Mean           1429.8899
V Predictions Std            184.88318
V Predictions Max            1614.249
V Predictions Min            18.52064
Log Pis Mean                 -0.68796164
Log Pis Std                  1.9389505
Log Pis Max                  10.163458
Log Pis Min                  -6.302731
Policy mu Mean               -0.038450632
Policy mu Std                0.77390355
Policy mu Max                2.1098678
Policy mu Min                -2.7051547
Policy log std Mean          -0.39956117
Policy log std Std           0.16331603
Policy log std Max           -0.013176426
Policy log std Min           -1.5063479
Z mean eval                  0.9388688
Z variance eval              0.013851047
total_rewards                [3285.83444615 3310.37999771 3250.83490635 3328.2456649  3273.32926201
 3265.38125555 3277.24995005 3307.42214774 3287.67601514 3325.71270995]
total_rewards_mean           3291.206635554388
total_rewards_std            24.587927003267165
total_rewards_max            3328.245664898017
total_rewards_min            3250.8349063483656
Number of train steps total  467000
Number of env steps total    2337000
Number of rollouts total     0
Train Time (s)               33.22490174230188
(Previous) Eval Time (s)     20.7583095501177
Sample Time (s)              23.88228819426149
Epoch Time (s)               77.86549948668107
Total Train Time (s)         31379.794564402197
Epoch                        466
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:45:44.746552 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #466 | Epoch Duration: 86.42889070510864
2020-01-11 08:45:44.746811 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #466 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9398039
Z variance train             0.013881167
KL Divergence                12.960262
KL Loss                      1.2960262
QF Loss                      108.79689
VF Loss                      50.020813
Policy Loss                  -1416.1307
Q Predictions Mean           1414.1174
Q Predictions Std            186.19797
Q Predictions Max            1574.8182
Q Predictions Min            4.6286287
V Predictions Mean           1413.1484
V Predictions Std            184.63298
V Predictions Max            1570.4723
V Predictions Min            1.6979115
Log Pis Mean                 -0.5422641
Log Pis Std                  1.7608736
Log Pis Max                  8.282249
Log Pis Min                  -4.1029654
Policy mu Mean               0.0073470604
Policy mu Std                0.8055179
Policy mu Max                2.217687
Policy mu Min                -2.7226732
Policy log std Mean          -0.39051902
Policy log std Std           0.17936175
Policy log std Max           0.020599172
Policy log std Min           -1.1780658
Z mean eval                  0.93346155
Z variance eval              0.019225249
total_rewards                [3241.9728879  3311.34803484 3295.93298426 3302.02330367 3348.19810466
 3319.10582962 3240.52468503 3297.16293618 3475.47605437 3351.57459315]
total_rewards_mean           3318.33194136735
total_rewards_std            63.119880876761435
total_rewards_max            3475.476054366287
total_rewards_min            3240.5246850339963
Number of train steps total  468000
Number of env steps total    2342000
Number of rollouts total     0
Train Time (s)               33.66216396307573
(Previous) Eval Time (s)     29.321349726989865
Sample Time (s)              22.499026236589998
Epoch Time (s)               85.48253992665559
Total Train Time (s)         31466.0150442156
Epoch                        467
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:47:10.971036 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #467 | Epoch Duration: 86.22405338287354
2020-01-11 08:47:10.971331 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #467 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93215764
Z variance train             0.0191336
KL Divergence                12.074933
KL Loss                      1.2074933
QF Loss                      85.89898
VF Loss                      62.688248
Policy Loss                  -1376.4138
Q Predictions Mean           1376.7222
Q Predictions Std            175.52069
Q Predictions Max            1544.6552
Q Predictions Min            0.7241041
V Predictions Mean           1377.7145
V Predictions Std            174.16557
V Predictions Max            1540.662
V Predictions Min            6.57118
Log Pis Mean                 -0.45480797
Log Pis Std                  1.884239
Log Pis Max                  5.9036584
Log Pis Min                  -6.3924046
Policy mu Mean               0.059777856
Policy mu Std                0.84925985
Policy mu Max                2.5528154
Policy mu Min                -2.6707659
Policy log std Mean          -0.4122099
Policy log std Std           0.16228628
Policy log std Max           0.024931878
Policy log std Min           -1.0739906
Z mean eval                  0.90626717
Z variance eval              0.01660626
total_rewards                [3225.68174675 3160.49384736 1937.74340916 3152.58712951 3286.7635704
 1378.59865466 3223.10045045 3245.24401677 3232.43570033 3225.78150106]
total_rewards_mean           2906.84300264533
total_rewards_std            637.7834984471273
total_rewards_max            3286.7635703975056
total_rewards_min            1378.5986546609815
Number of train steps total  469000
Number of env steps total    2347000
Number of rollouts total     0
Train Time (s)               32.93118119472638
(Previous) Eval Time (s)     30.062532026786357
Sample Time (s)              23.468584034126252
Epoch Time (s)               86.46229725563899
Total Train Time (s)         31548.661959506106
Epoch                        468
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:48:33.623339 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #468 | Epoch Duration: 82.65184760093689
2020-01-11 08:48:33.623572 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #468 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9015333
Z variance train             0.016707713
KL Divergence                12.326628
KL Loss                      1.2326628
QF Loss                      104.99583
VF Loss                      69.086395
Policy Loss                  -1374.852
Q Predictions Mean           1376.007
Q Predictions Std            225.25821
Q Predictions Max            1547.2041
Q Predictions Min            -6.627902
V Predictions Mean           1377.4746
V Predictions Std            225.49013
V Predictions Max            1547.666
V Predictions Min            6.060463
Log Pis Mean                 -0.35062677
Log Pis Std                  1.9600903
Log Pis Max                  7.066057
Log Pis Min                  -4.949498
Policy mu Mean               -0.02033072
Policy mu Std                0.86989695
Policy mu Max                3.3887413
Policy mu Min                -2.817033
Policy log std Mean          -0.40130106
Policy log std Std           0.15559022
Policy log std Max           -0.046113864
Policy log std Min           -1.0439845
Z mean eval                  0.93975466
Z variance eval              0.011998633
total_rewards                [1208.64183343 1150.66890569 2921.72516094 3105.88545543 3210.40603432
 2858.07999228 2763.31352353 1072.48769454 1861.16865408 1112.50779213]
total_rewards_mean           2126.48850463594
total_rewards_std            878.1460450883432
total_rewards_max            3210.406034321693
total_rewards_min            1072.487694540825
Number of train steps total  470000
Number of env steps total    2352000
Number of rollouts total     0
Train Time (s)               32.91983507713303
(Previous) Eval Time (s)     26.251765547785908
Sample Time (s)              22.278933177236468
Epoch Time (s)               81.4505338021554
Total Train Time (s)         31623.405389543623
Epoch                        469
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:49:48.370944 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #469 | Epoch Duration: 74.74719667434692
2020-01-11 08:49:48.371144 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #469 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9374712
Z variance train             0.011946257
KL Divergence                13.131401
KL Loss                      1.3131402
QF Loss                      117.65233
VF Loss                      58.12697
Policy Loss                  -1511.1152
Q Predictions Mean           1510.8892
Q Predictions Std            129.28407
Q Predictions Max            1656.4594
Q Predictions Min            423.42853
V Predictions Mean           1515.961
V Predictions Std            126.89946
V Predictions Max            1657.7173
V Predictions Min            509.4437
Log Pis Mean                 -0.8498554
Log Pis Std                  1.6578153
Log Pis Max                  7.385412
Log Pis Min                  -5.102912
Policy mu Mean               0.0020005424
Policy mu Std                0.7533103
Policy mu Max                2.6440687
Policy mu Min                -2.747797
Policy log std Mean          -0.36885324
Policy log std Std           0.14907962
Policy log std Max           0.0026323646
Policy log std Min           -0.92213285
Z mean eval                  0.9358309
Z variance eval              0.010365447
total_rewards                [3164.22216087 1389.73579223 3259.71610722 1226.49305222 3219.99969838
 3250.65698802 1743.06127729 3176.39677106 3171.08666486 3170.8579759 ]
total_rewards_mean           2677.22264880572
total_rewards_std            810.6509460856618
total_rewards_max            3259.716107219186
total_rewards_min            1226.4930522219404
Number of train steps total  471000
Number of env steps total    2357000
Number of rollouts total     0
Train Time (s)               33.159111557062715
(Previous) Eval Time (s)     19.548147932160646
Sample Time (s)              23.39403626602143
Epoch Time (s)               76.10129575524479
Total Train Time (s)         31704.500109313056
Epoch                        470
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:51:09.470291 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #470 | Epoch Duration: 81.09897041320801
2020-01-11 08:51:09.470471 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #470 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93522054
Z variance train             0.010352189
KL Divergence                13.413708
KL Loss                      1.3413708
QF Loss                      77.631714
VF Loss                      82.72067
Policy Loss                  -1501.0391
Q Predictions Mean           1499.2141
Q Predictions Std            155.40697
Q Predictions Max            1651.056
Q Predictions Min            10.159387
V Predictions Mean           1504.5647
V Predictions Std            156.81287
V Predictions Max            1650.6539
V Predictions Min            -0.24144274
Log Pis Mean                 -0.6357439
Log Pis Std                  1.6974088
Log Pis Max                  5.863169
Log Pis Min                  -5.9233603
Policy mu Mean               0.061376378
Policy mu Std                0.79044956
Policy mu Max                1.8891398
Policy mu Min                -2.733122
Policy log std Mean          -0.38116845
Policy log std Std           0.13982369
Policy log std Max           -0.03952314
Policy log std Min           -1.0005441
Z mean eval                  0.89692557
Z variance eval              0.010930839
total_rewards                [3160.86218859 3248.44973654 3222.63652881 1275.56351702 3278.10431709
 1263.91747999 3236.47953108 3216.94454871 3284.76262266 3277.71013974]
total_rewards_mean           2846.543061022362
total_rewards_std            789.1695957249359
total_rewards_max            3284.762622661939
total_rewards_min            1263.9174799886123
Number of train steps total  472000
Number of env steps total    2362000
Number of rollouts total     0
Train Time (s)               33.787393344100565
(Previous) Eval Time (s)     24.545497206039727
Sample Time (s)              22.846804607193917
Epoch Time (s)               81.17969515733421
Total Train Time (s)         31787.66213407507
Epoch                        471
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:52:32.637613 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #471 | Epoch Duration: 83.1670036315918
2020-01-11 08:52:32.637809 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #471 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89544785
Z variance train             0.010949049
KL Divergence                12.950639
KL Loss                      1.2950639
QF Loss                      170.7219
VF Loss                      59.59966
Policy Loss                  -1335.2456
Q Predictions Mean           1334.3052
Q Predictions Std            136.32945
Q Predictions Max            1510.3815
Q Predictions Min            411.1639
V Predictions Mean           1335.6995
V Predictions Std            133.6528
V Predictions Max            1506.452
V Predictions Min            456.89862
Log Pis Mean                 -0.2733189
Log Pis Std                  1.9057704
Log Pis Max                  6.8478093
Log Pis Min                  -5.034096
Policy mu Mean               -0.19531925
Policy mu Std                0.86423063
Policy mu Max                3.0885718
Policy mu Min                -2.8173885
Policy log std Mean          -0.4194342
Policy log std Std           0.1556312
Policy log std Max           -0.058027968
Policy log std Min           -1.0306286
Z mean eval                  0.90932214
Z variance eval              0.012063265
total_rewards                [3217.58031689 1598.31047875 3159.02456034 3161.12752598 3141.00065178
 3179.42900254 3194.18470328 3189.35372085 1227.61254671 3206.92564816]
total_rewards_mean           2827.4549155291134
total_rewards_std            712.4199272028573
total_rewards_max            3217.580316893173
total_rewards_min            1227.6125467090465
Number of train steps total  473000
Number of env steps total    2367000
Number of rollouts total     0
Train Time (s)               33.231703266035765
(Previous) Eval Time (s)     26.53247303934768
Sample Time (s)              23.463673131540418
Epoch Time (s)               83.22784943692386
Total Train Time (s)         31870.92957907915
Epoch                        472
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:53:55.911011 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #472 | Epoch Duration: 83.27304720878601
2020-01-11 08:53:55.911230 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #472 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90825194
Z variance train             0.012066288
KL Divergence                12.972991
KL Loss                      1.2972991
QF Loss                      3160.2532
VF Loss                      426.32562
Policy Loss                  -1430.1096
Q Predictions Mean           1430.6537
Q Predictions Std            168.29724
Q Predictions Max            1592.1013
Q Predictions Min            242.30261
V Predictions Mean           1438.8572
V Predictions Std            164.10307
V Predictions Max            1589.3533
V Predictions Min            285.19003
Log Pis Mean                 -0.6024023
Log Pis Std                  1.922552
Log Pis Max                  10.437118
Log Pis Min                  -4.606531
Policy mu Mean               -0.061134856
Policy mu Std                0.81767327
Policy mu Max                3.331848
Policy mu Min                -2.833265
Policy log std Mean          -0.39029106
Policy log std Std           0.14779507
Policy log std Max           -0.05618976
Policy log std Min           -1.0314561
Z mean eval                  0.8996604
Z variance eval              0.0071405075
total_rewards                [3202.96944858 3206.45160149 3143.28522818 3184.50331042 3168.98420551
 3159.5123912  3180.91560073 3220.76130986 3190.14589026 3156.23304011]
total_rewards_mean           3181.3762026335744
total_rewards_std            23.34056072182114
total_rewards_max            3220.7613098623237
total_rewards_min            3143.2852281769474
Number of train steps total  474000
Number of env steps total    2372000
Number of rollouts total     0
Train Time (s)               33.65586093487218
(Previous) Eval Time (s)     26.577274406328797
Sample Time (s)              23.907646343577653
Epoch Time (s)               84.14078168477863
Total Train Time (s)         31958.22391790012
Epoch                        473
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:55:23.208484 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #473 | Epoch Duration: 87.29711055755615
2020-01-11 08:55:23.208659 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #473 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90198594
Z variance train             0.0071307076
KL Divergence                14.553553
KL Loss                      1.4553553
QF Loss                      87.6977
VF Loss                      80.8707
Policy Loss                  -1404.8116
Q Predictions Mean           1403.6462
Q Predictions Std            122.3296
Q Predictions Max            1547.7533
Q Predictions Min            379.98865
V Predictions Mean           1399.2383
V Predictions Std            120.37965
V Predictions Max            1533.4269
V Predictions Min            389.9966
Log Pis Mean                 -0.5947969
Log Pis Std                  1.7877305
Log Pis Max                  5.383047
Log Pis Min                  -5.512602
Policy mu Mean               -0.0012970393
Policy mu Std                0.81163895
Policy mu Max                2.8319383
Policy mu Min                -2.7774189
Policy log std Mean          -0.38239363
Policy log std Std           0.13931099
Policy log std Max           -0.06519526
Policy log std Min           -0.8527886
Z mean eval                  0.9127806
Z variance eval              0.008634296
total_rewards                [3185.88735485 3175.17792215 3177.47529766 3167.833159   3172.73586234
 3146.42443714 3019.48758024 3204.20260832 3158.42191785 3161.29877872]
total_rewards_mean           3156.894491827191
total_rewards_std            48.186214847694394
total_rewards_max            3204.2026083187106
total_rewards_min            3019.4875802446777
Number of train steps total  475000
Number of env steps total    2377000
Number of rollouts total     0
Train Time (s)               33.355407604947686
(Previous) Eval Time (s)     29.733264330308884
Sample Time (s)              22.058618251234293
Epoch Time (s)               85.14729018649086
Total Train Time (s)         32042.468528181314
Epoch                        474
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:56:47.458291 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #474 | Epoch Duration: 84.24948573112488
2020-01-11 08:56:47.458521 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #474 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9124163
Z variance train             0.008655995
KL Divergence                14.111624
KL Loss                      1.4111624
QF Loss                      72.33974
VF Loss                      53.75807
Policy Loss                  -1460.0305
Q Predictions Mean           1458.2949
Q Predictions Std            152.19496
Q Predictions Max            1597.4276
Q Predictions Min            451.13586
V Predictions Mean           1462.5433
V Predictions Std            149.39009
V Predictions Max            1598.8898
V Predictions Min            440.60004
Log Pis Mean                 -0.74329424
Log Pis Std                  1.6523623
Log Pis Max                  5.3278084
Log Pis Min                  -5.0725274
Policy mu Mean               0.05886078
Policy mu Std                0.78708243
Policy mu Max                3.7223346
Policy mu Min                -2.64966
Policy log std Mean          -0.39850745
Policy log std Std           0.152867
Policy log std Max           -0.09405778
Policy log std Min           -1.095197
Z mean eval                  0.9232222
Z variance eval              0.012887508
total_rewards                [3194.84450336 1715.41550547 2310.22374854 3156.83968475 2303.30165485
 3191.91686326 1183.43323981 3154.8376152  3209.20647461 1510.5766608 ]
total_rewards_mean           2493.059595063847
total_rewards_std            756.7618718292177
total_rewards_max            3209.2064746111905
total_rewards_min            1183.4332398055117
Number of train steps total  476000
Number of env steps total    2382000
Number of rollouts total     0
Train Time (s)               33.30371182691306
(Previous) Eval Time (s)     28.8351542619057
Sample Time (s)              23.6138155721128
Epoch Time (s)               85.75268166093156
Total Train Time (s)         32123.526068123057
Epoch                        475
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:58:08.521112 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #475 | Epoch Duration: 81.06242275238037
2020-01-11 08:58:08.521330 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #475 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9211338
Z variance train             0.012905719
KL Divergence                12.671057
KL Loss                      1.2671057
QF Loss                      118.75329
VF Loss                      52.17835
Policy Loss                  -1380.6926
Q Predictions Mean           1381.5232
Q Predictions Std            177.48355
Q Predictions Max            1536.5089
Q Predictions Min            6.933389
V Predictions Mean           1380.8909
V Predictions Std            179.89041
V Predictions Max            1538.4651
V Predictions Min            6.4504128
Log Pis Mean                 -0.8402416
Log Pis Std                  1.7325934
Log Pis Max                  5.3797355
Log Pis Min                  -4.942882
Policy mu Mean               -0.014253237
Policy mu Std                0.7620243
Policy mu Max                1.8051037
Policy mu Min                -3.2953508
Policy log std Mean          -0.38819656
Policy log std Std           0.14934821
Policy log std Max           -0.102595896
Policy log std Min           -1.2559496
Z mean eval                  0.89758444
Z variance eval              0.01611882
total_rewards                [3193.21753425 1243.13724522 1506.47208826 1996.98848139 3222.64346012
 3178.96588609 3218.95134893 1174.87254312 1111.89885693 1038.85939879]
total_rewards_mean           2088.600684310126
total_rewards_std            944.7590998675765
total_rewards_max            3222.643460123243
total_rewards_min            1038.859398791163
Number of train steps total  477000
Number of env steps total    2387000
Number of rollouts total     0
Train Time (s)               33.41629005828872
(Previous) Eval Time (s)     24.144541586283594
Sample Time (s)              23.230573794338852
Epoch Time (s)               80.79140543891117
Total Train Time (s)         32198.85991456313
Epoch                        476
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:59:23.859491 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #476 | Epoch Duration: 75.33800864219666
2020-01-11 08:59:23.859667 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #476 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8992268
Z variance train             0.016075358
KL Divergence                12.218831
KL Loss                      1.2218832
QF Loss                      79.803955
VF Loss                      39.715473
Policy Loss                  -1392.228
Q Predictions Mean           1389.1921
Q Predictions Std            197.66475
Q Predictions Max            1551.4952
Q Predictions Min            -4.8443203
V Predictions Mean           1391.7789
V Predictions Std            198.6739
V Predictions Max            1558.7709
V Predictions Min            3.675652
Log Pis Mean                 -0.6740841
Log Pis Std                  1.8582464
Log Pis Max                  6.166747
Log Pis Min                  -4.3851233
Policy mu Mean               -0.038779125
Policy mu Std                0.8474498
Policy mu Max                1.8822862
Policy mu Min                -2.9119835
Policy log std Mean          -0.39071882
Policy log std Std           0.15931301
Policy log std Max           0.0612092
Policy log std Min           -1.0596391
Z mean eval                  0.87858325
Z variance eval              0.020958282
total_rewards                [3197.3204464  3247.41080337 3197.94158771 3173.55658472 3164.99307345
 3167.88034541 3278.98165282 3181.91209471 3139.62863157 3149.63062151]
total_rewards_mean           3189.92558416774
total_rewards_std            41.16761390444412
total_rewards_max            3278.981652820511
total_rewards_min            3139.6286315663065
Number of train steps total  478000
Number of env steps total    2392000
Number of rollouts total     0
Train Time (s)               33.61959351086989
(Previous) Eval Time (s)     18.690829084720463
Sample Time (s)              23.87409936171025
Epoch Time (s)               76.1845219573006
Total Train Time (s)         32285.745895095635
Epoch                        477
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:00:50.749994 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #477 | Epoch Duration: 86.89019417762756
2020-01-11 09:00:50.750166 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #477 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.88159627
Z variance train             0.021042699
KL Divergence                12.743141
KL Loss                      1.2743142
QF Loss                      79.38492
VF Loss                      55.90866
Policy Loss                  -1425.9205
Q Predictions Mean           1424.7888
Q Predictions Std            152.67741
Q Predictions Max            1570.5552
Q Predictions Min            0.51343304
V Predictions Mean           1425.8627
V Predictions Std            150.59973
V Predictions Max            1578.944
V Predictions Min            4.145683
Log Pis Mean                 -0.6150577
Log Pis Std                  1.7679127
Log Pis Max                  6.9548774
Log Pis Min                  -4.8895793
Policy mu Mean               -0.05221198
Policy mu Std                0.79597735
Policy mu Max                3.1061788
Policy mu Min                -2.7159042
Policy log std Mean          -0.39074335
Policy log std Std           0.14880246
Policy log std Max           -0.041273013
Policy log std Min           -0.9761665
Z mean eval                  0.9050482
Z variance eval              0.015533512
total_rewards                [1224.60540068 1508.54620591 2246.69259183 3183.43161962 3119.18883463
 2825.00713014 3202.79984796 3217.9116171  3215.41348525 3170.11980604]
total_rewards_mean           2691.3716539140396
total_rewards_std            723.4535579729169
total_rewards_max            3217.9116170956713
total_rewards_min            1224.6054006765787
Number of train steps total  479000
Number of env steps total    2397000
Number of rollouts total     0
Train Time (s)               33.25127606326714
(Previous) Eval Time (s)     29.396179114002734
Sample Time (s)              24.49478452047333
Epoch Time (s)               87.14223969774321
Total Train Time (s)         32367.77334340755
Epoch                        478
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:02:12.782527 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #478 | Epoch Duration: 82.03222870826721
2020-01-11 09:02:12.782722 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #478 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9062273
Z variance train             0.015555163
KL Divergence                12.948111
KL Loss                      1.2948111
QF Loss                      53.46834
VF Loss                      104.69111
Policy Loss                  -1481.0519
Q Predictions Mean           1481.9177
Q Predictions Std            157.68849
Q Predictions Max            1645.7311
Q Predictions Min            12.261931
V Predictions Mean           1474.979
V Predictions Std            157.5695
V Predictions Max            1626.1154
V Predictions Min            5.58562
Log Pis Mean                 -0.8613926
Log Pis Std                  1.4801517
Log Pis Max                  5.143091
Log Pis Min                  -5.3571973
Policy mu Mean               0.09972372
Policy mu Std                0.6994503
Policy mu Max                2.1340873
Policy mu Min                -2.661584
Policy log std Mean          -0.3668878
Policy log std Std           0.13301855
Policy log std Max           -0.053634584
Policy log std Min           -0.9237759
Z mean eval                  0.8621132
Z variance eval              0.012748529
total_rewards                [3098.30288276 1349.1114433  3152.94045647 3322.25961897 1359.45424143
 3106.75413172 3105.08960262 3089.35284172 3103.93074106 3070.67374951]
total_rewards_mean           2775.786970956439
total_rewards_std            713.9492046376248
total_rewards_max            3322.2596189726146
total_rewards_min            1349.1114432963543
Number of train steps total  480000
Number of env steps total    2402000
Number of rollouts total     0
Train Time (s)               35.60405554110184
(Previous) Eval Time (s)     24.285779307596385
Sample Time (s)              23.12375072715804
Epoch Time (s)               83.01358557585627
Total Train Time (s)         32453.77011747798
Epoch                        479
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:03:38.786184 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #479 | Epoch Duration: 86.00327849388123
2020-01-11 09:03:38.786553 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #479 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.86139095
Z variance train             0.012694955
KL Divergence                13.299292
KL Loss                      1.3299292
QF Loss                      147.77478
VF Loss                      29.849659
Policy Loss                  -1381.7079
Q Predictions Mean           1382.5308
Q Predictions Std            136.59497
Q Predictions Max            1529.0138
Q Predictions Min            238.5356
V Predictions Mean           1383.7721
V Predictions Std            136.18192
V Predictions Max            1526.2207
V Predictions Min            240.57999
Log Pis Mean                 -0.42517123
Log Pis Std                  1.8915106
Log Pis Max                  5.794701
Log Pis Min                  -5.9349947
Policy mu Mean               0.026803369
Policy mu Std                0.831461
Policy mu Max                2.616793
Policy mu Min                -2.6712415
Policy log std Mean          -0.39465484
Policy log std Std           0.1543874
Policy log std Max           -0.045549482
Policy log std Min           -0.96350634
Z mean eval                  0.9127041
Z variance eval              0.015103986
total_rewards                [3220.92912479 1192.30472293 3177.57962149 3207.73180392 3190.36648968
 1266.95465717 1401.86464306 2698.45081107 2712.06746335 3138.36962916]
total_rewards_mean           2520.661896663575
total_rewards_std            829.476590218388
total_rewards_max            3220.9291247940932
total_rewards_min            1192.3047229324081
Number of train steps total  481000
Number of env steps total    2407000
Number of rollouts total     0
Train Time (s)               35.47100878180936
(Previous) Eval Time (s)     27.27509280713275
Sample Time (s)              24.641924949828535
Epoch Time (s)               87.38802653877065
Total Train Time (s)         32538.085651688743
Epoch                        480
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:05:03.106507 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #480 | Epoch Duration: 84.3197340965271
2020-01-11 09:05:03.106746 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #480 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91249675
Z variance train             0.015109
KL Divergence                13.381115
KL Loss                      1.3381115
QF Loss                      58.654438
VF Loss                      27.518919
Policy Loss                  -1479.1777
Q Predictions Mean           1477.737
Q Predictions Std            134.67078
Q Predictions Max            1646.0078
Q Predictions Min            597.4064
V Predictions Mean           1481.3293
V Predictions Std            133.31288
V Predictions Max            1650.5387
V Predictions Min            642.1633
Log Pis Mean                 -0.6881331
Log Pis Std                  1.7479304
Log Pis Max                  6.2886267
Log Pis Min                  -4.6591754
Policy mu Mean               -0.03706857
Policy mu Std                0.7668601
Policy mu Max                2.937821
Policy mu Min                -2.7617607
Policy log std Mean          -0.37527665
Policy log std Std           0.14209579
Policy log std Max           -0.072374195
Policy log std Min           -1.0287149
Z mean eval                  0.88290054
Z variance eval              0.0149388015
total_rewards                [3297.94009915 3233.6983889  1186.13052507 3211.32961774 3277.93847817
 1433.73943935 3241.3461403  3195.08894178 3235.65368368 3219.38576449]
total_rewards_mean           2853.2251078615377
total_rewards_std            774.1530596648042
total_rewards_max            3297.940099145133
total_rewards_min            1186.1305250707283
Number of train steps total  482000
Number of env steps total    2412000
Number of rollouts total     0
Train Time (s)               36.41435968130827
(Previous) Eval Time (s)     24.206418767105788
Sample Time (s)              24.39156984211877
Epoch Time (s)               85.01234829053283
Total Train Time (s)         32626.22270407714
Epoch                        481
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:06:31.248117 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #481 | Epoch Duration: 88.14121770858765
2020-01-11 09:06:31.248381 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #481 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8814634
Z variance train             0.014970134
KL Divergence                12.022265
KL Loss                      1.2022265
QF Loss                      199.0803
VF Loss                      56.60644
Policy Loss                  -1420.2069
Q Predictions Mean           1418.6075
Q Predictions Std            134.81401
Q Predictions Max            1569.8068
Q Predictions Min            451.3844
V Predictions Mean           1423.3619
V Predictions Std            134.83662
V Predictions Max            1575.5409
V Predictions Min            441.01294
Log Pis Mean                 -0.6363476
Log Pis Std                  1.8585826
Log Pis Max                  6.8260183
Log Pis Min                  -5.411596
Policy mu Mean               0.012959587
Policy mu Std                0.8124844
Policy mu Max                1.7146119
Policy mu Min                -2.9770074
Policy log std Mean          -0.4036804
Policy log std Std           0.14545268
Policy log std Max           -0.07919696
Policy log std Min           -0.9643152
Z mean eval                  0.8331375
Z variance eval              0.024694871
total_rewards                [3185.99214732 3168.24581908 3154.13245534 3153.7455353  3186.96480364
 3141.93522896 1868.89764909 3130.37561972 3097.61539907 3176.25095204]
total_rewards_mean           3026.4155609569107
total_rewards_std            386.70419715997224
total_rewards_max            3186.9648036397502
total_rewards_min            1868.8976490914815
Number of train steps total  483000
Number of env steps total    2417000
Number of rollouts total     0
Train Time (s)               35.1092351176776
(Previous) Eval Time (s)     27.334934765007347
Sample Time (s)              24.15473169228062
Epoch Time (s)               86.59890157496557
Total Train Time (s)         32715.222052981146
Epoch                        482
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:08:00.251999 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #482 | Epoch Duration: 89.00347471237183
2020-01-11 09:08:00.252193 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #482 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.83405364
Z variance train             0.024836522
KL Divergence                11.292623
KL Loss                      1.1292623
QF Loss                      84.322945
VF Loss                      102.69514
Policy Loss                  -1424.371
Q Predictions Mean           1423.3293
Q Predictions Std            118.79059
Q Predictions Max            1564.1382
Q Predictions Min            724.586
V Predictions Mean           1428.1365
V Predictions Std            118.86284
V Predictions Max            1573.934
V Predictions Min            765.016
Log Pis Mean                 -0.534764
Log Pis Std                  1.609826
Log Pis Max                  4.5309124
Log Pis Min                  -3.9895177
Policy mu Mean               0.0005481082
Policy mu Std                0.8265589
Policy mu Max                2.441512
Policy mu Min                -2.8516762
Policy log std Mean          -0.3842049
Policy log std Std           0.14449456
Policy log std Max           -0.068989575
Policy log std Min           -1.0435878
Z mean eval                  0.8539381
Z variance eval              0.028070608
total_rewards                [1049.2136559  3128.54286812 3158.9368443  1164.04430033 3142.11700123
 1258.8302713  3109.34325857 3116.67672003 3141.6845485  2193.2922041 ]
total_rewards_mean           2446.2681672380136
total_rewards_std            888.8299109152111
total_rewards_max            3158.936844296464
total_rewards_min            1049.2136559000621
Number of train steps total  484000
Number of env steps total    2422000
Number of rollouts total     0
Train Time (s)               36.248803530819714
(Previous) Eval Time (s)     29.73914160905406
Sample Time (s)              24.924502927344292
Epoch Time (s)               90.91244806721807
Total Train Time (s)         32800.72399552073
Epoch                        483
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:09:25.759283 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #483 | Epoch Duration: 85.50695180892944
2020-01-11 09:09:25.759476 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #483 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8524748
Z variance train             0.028082728
KL Divergence                10.852905
KL Loss                      1.0852906
QF Loss                      144.26048
VF Loss                      163.17543
Policy Loss                  -1483.8405
Q Predictions Mean           1483.5281
Q Predictions Std            187.85405
Q Predictions Max            1646.9366
Q Predictions Min            12.759567
V Predictions Mean           1488.2823
V Predictions Std            187.70636
V Predictions Max            1649.2743
V Predictions Min            16.633677
Log Pis Mean                 -0.76663303
Log Pis Std                  1.5575609
Log Pis Max                  5.82847
Log Pis Min                  -6.6158824
Policy mu Mean               0.15851156
Policy mu Std                0.7421018
Policy mu Max                1.9563363
Policy mu Min                -2.788352
Policy log std Mean          -0.38891506
Policy log std Std           0.13943751
Policy log std Max           -0.062109277
Policy log std Min           -1.279521
Z mean eval                  0.9186171
Z variance eval              0.027860666
total_rewards                [3181.3092191  3238.84912713 1103.04381105 3190.51263078 3236.20364785
 3266.63160418 1098.41960647 3239.64867241 3174.6573976  2487.8897828 ]
total_rewards_mean           2721.7165499368175
total_rewards_std            839.2454428768325
total_rewards_max            3266.631604178523
total_rewards_min            1098.419606470576
Number of train steps total  485000
Number of env steps total    2427000
Number of rollouts total     0
Train Time (s)               34.66418053396046
(Previous) Eval Time (s)     24.333207183983177
Sample Time (s)              24.36231322027743
Epoch Time (s)               83.35970093822107
Total Train Time (s)         32885.4169505965
Epoch                        484
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:10:50.457519 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #484 | Epoch Duration: 84.69790315628052
2020-01-11 09:10:50.457706 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #484 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91938746
Z variance train             0.027828401
KL Divergence                10.856152
KL Loss                      1.0856152
QF Loss                      40.517357
VF Loss                      23.701092
Policy Loss                  -1530.144
Q Predictions Mean           1529.9622
Q Predictions Std            129.03415
Q Predictions Max            1671.6887
Q Predictions Min            918.62646
V Predictions Mean           1527.3042
V Predictions Std            129.88742
V Predictions Max            1666.0089
V Predictions Min            906.2847
Log Pis Mean                 -0.8726492
Log Pis Std                  1.3122197
Log Pis Max                  4.9445767
Log Pis Min                  -5.1428328
Policy mu Mean               0.10603476
Policy mu Std                0.65695715
Policy mu Max                1.929989
Policy mu Min                -2.6559336
Policy log std Mean          -0.36540684
Policy log std Std           0.12212061
Policy log std Max           -0.05548221
Policy log std Min           -0.9463939
Z mean eval                  0.8449251
Z variance eval              0.024444284
total_rewards                [3112.26914964 3107.19020646 1328.51186213 1035.2076005  3156.94331333
 3136.11049132 1083.4950734  3131.03030097 1990.88928209  960.42616982]
total_rewards_mean           2204.20734496631
total_rewards_std            962.1330243315261
total_rewards_max            3156.9433133346693
total_rewards_min            960.4261698173736
Number of train steps total  486000
Number of env steps total    2432000
Number of rollouts total     0
Train Time (s)               35.56504255300388
(Previous) Eval Time (s)     25.671032798010856
Sample Time (s)              23.830848598387092
Epoch Time (s)               85.06692394940183
Total Train Time (s)         32966.814608922694
Epoch                        485
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:12:11.859661 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #485 | Epoch Duration: 81.4017915725708
2020-01-11 09:12:11.859952 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #485 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8455469
Z variance train             0.024445469
KL Divergence                11.082682
KL Loss                      1.1082681
QF Loss                      51.96792
VF Loss                      16.764936
Policy Loss                  -1512.4143
Q Predictions Mean           1511.794
Q Predictions Std            97.0029
Q Predictions Max            1629.8418
Q Predictions Min            1142.153
V Predictions Mean           1510.4541
V Predictions Std            96.868965
V Predictions Max            1629.9852
V Predictions Min            1131.5156
Log Pis Mean                 -0.9631905
Log Pis Std                  1.4690888
Log Pis Max                  5.2115507
Log Pis Min                  -6.0130863
Policy mu Mean               0.10293347
Policy mu Std                0.67367
Policy mu Max                1.8953767
Policy mu Min                -2.623786
Policy log std Mean          -0.359921
Policy log std Std           0.13894476
Policy log std Max           -0.05127217
Policy log std Min           -0.8752642
Z mean eval                  0.8668852
Z variance eval              0.013448216
total_rewards                [3266.81233505 3225.1616182  3273.45611413 3363.10905078 2457.88039218
 3295.63144628 3249.00549602 3346.45873814 3286.08961272 3203.6093032 ]
total_rewards_mean           3196.7214106707142
total_rewards_std            250.629787086105
total_rewards_max            3363.109050784877
total_rewards_min            2457.8803921823746
Number of train steps total  487000
Number of env steps total    2437000
Number of rollouts total     0
Train Time (s)               36.90036032581702
(Previous) Eval Time (s)     22.00556904776022
Sample Time (s)              25.128205843735486
Epoch Time (s)               84.03413521731272
Total Train Time (s)         33057.90063756332
Epoch                        486
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:13:42.950735 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #486 | Epoch Duration: 91.09061312675476
2020-01-11 09:13:42.950955 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #486 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8678837
Z variance train             0.013450019
KL Divergence                12.631026
KL Loss                      1.2631027
QF Loss                      82.62341
VF Loss                      73.51305
Policy Loss                  -1466.4202
Q Predictions Mean           1465.7423
Q Predictions Std            104.70809
Q Predictions Max            1591.3359
Q Predictions Min            773.02057
V Predictions Mean           1469.2435
V Predictions Std            104.252975
V Predictions Max            1601.4794
V Predictions Min            764.9548
Log Pis Mean                 -0.7515938
Log Pis Std                  1.7254919
Log Pis Max                  5.3624883
Log Pis Min                  -6.8917084
Policy mu Mean               -0.046756644
Policy mu Std                0.7454434
Policy mu Max                1.6949077
Policy mu Min                -2.4629402
Policy log std Mean          -0.379601
Policy log std Std           0.14549212
Policy log std Max           -0.07618111
Policy log std Min           -0.9651102
Z mean eval                  0.84550846
Z variance eval              0.011134905
total_rewards                [3274.78154485 3262.28001284 3237.13118765 3287.40182436 3254.88161838
 3229.41684796 3255.51797078 1607.95626837 1815.87264811 3224.44554191]
total_rewards_mean           2944.968546522114
total_rewards_std            618.5505155649696
total_rewards_max            3287.401824357839
total_rewards_min            1607.9562683743588
Number of train steps total  488000
Number of env steps total    2442000
Number of rollouts total     0
Train Time (s)               35.28866782784462
(Previous) Eval Time (s)     29.061611732002348
Sample Time (s)              23.597430442925543
Epoch Time (s)               87.94771000277251
Total Train Time (s)         33141.85044148285
Epoch                        487
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:15:06.906528 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #487 | Epoch Duration: 83.95541572570801
2020-01-11 09:15:06.906799 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #487 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8435303
Z variance train             0.011151133
KL Divergence                13.043236
KL Loss                      1.3043236
QF Loss                      39.911205
VF Loss                      32.27377
Policy Loss                  -1447.1859
Q Predictions Mean           1449.7882
Q Predictions Std            112.304565
Q Predictions Max            1587.2611
Q Predictions Min            1037.397
V Predictions Mean           1451.0326
V Predictions Std            111.96714
V Predictions Max            1588.1025
V Predictions Min            1047.2408
Log Pis Mean                 -0.66407657
Log Pis Std                  1.7679915
Log Pis Max                  5.2081456
Log Pis Min                  -4.886651
Policy mu Mean               0.049413193
Policy mu Std                0.7766803
Policy mu Max                1.8954265
Policy mu Min                -2.9606075
Policy log std Mean          -0.38040757
Policy log std Std           0.13864791
Policy log std Max           -0.06556293
Policy log std Min           -0.9389857
Z mean eval                  0.83605975
Z variance eval              0.01242987
total_rewards                [1460.82263087 3326.31713675 3321.87415789 3115.39938987 3026.2783124
 1467.67211388 3189.21615447 1626.42461202 1161.60414448 3215.98424576]
total_rewards_mean           2491.1592898417857
total_rewards_std            877.5455015427938
total_rewards_max            3326.3171367518116
total_rewards_min            1161.6041444805778
Number of train steps total  489000
Number of env steps total    2447000
Number of rollouts total     0
Train Time (s)               36.018146719783545
(Previous) Eval Time (s)     25.06890406506136
Sample Time (s)              24.962275438476354
Epoch Time (s)               86.04932622332126
Total Train Time (s)         33226.4310586364
Epoch                        488
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:16:31.492262 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #488 | Epoch Duration: 84.5853054523468
2020-01-11 09:16:31.492448 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #488 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8363854
Z variance train             0.01244464
KL Divergence                12.960517
KL Loss                      1.2960517
QF Loss                      37.015793
VF Loss                      19.587162
Policy Loss                  -1435.8376
Q Predictions Mean           1434.4407
Q Predictions Std            123.508736
Q Predictions Max            1574.4744
Q Predictions Min            883.0047
V Predictions Mean           1434.1339
V Predictions Std            122.53755
V Predictions Max            1573.4203
V Predictions Min            883.03143
Log Pis Mean                 -0.8007068
Log Pis Std                  1.6728872
Log Pis Max                  8.216572
Log Pis Min                  -4.7168584
Policy mu Mean               0.06508403
Policy mu Std                0.76640326
Policy mu Max                2.2135005
Policy mu Min                -2.7325056
Policy log std Mean          -0.37874302
Policy log std Std           0.14689219
Policy log std Max           -0.005049765
Policy log std Min           -1.0377929
Z mean eval                  0.87369597
Z variance eval              0.009503498
total_rewards                [1017.63012374 3262.10951251 3256.71964339 3247.19074846 1364.01082935
 3233.48971129 3188.18353734 3242.70273878 1261.88569012 3267.14244423]
total_rewards_mean           2634.1064979202374
total_rewards_std            932.9748941040574
total_rewards_max            3267.142444230959
total_rewards_min            1017.6301237350789
Number of train steps total  490000
Number of env steps total    2452000
Number of rollouts total     0
Train Time (s)               33.15743237780407
(Previous) Eval Time (s)     23.60450525721535
Sample Time (s)              21.480227237567306
Epoch Time (s)               78.24216487258673
Total Train Time (s)         33305.82408580836
Epoch                        489
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:17:50.889737 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #489 | Epoch Duration: 79.3971495628357
2020-01-11 09:17:50.889928 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #489 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.87334967
Z variance train             0.009533814
KL Divergence                13.442496
KL Loss                      1.3442496
QF Loss                      82.06675
VF Loss                      20.2276
Policy Loss                  -1476.2129
Q Predictions Mean           1475.439
Q Predictions Std            128.42488
Q Predictions Max            1613.0643
Q Predictions Min            449.58255
V Predictions Mean           1477.5481
V Predictions Std            128.41199
V Predictions Max            1617.2198
V Predictions Min            429.04218
Log Pis Mean                 -0.73266935
Log Pis Std                  1.7030312
Log Pis Max                  6.8508854
Log Pis Min                  -5.603237
Policy mu Mean               0.0685801
Policy mu Std                0.7554529
Policy mu Max                1.7778968
Policy mu Min                -2.824382
Policy log std Mean          -0.37712368
Policy log std Std           0.14954492
Policy log std Max           -0.07949287
Policy log std Min           -0.9943105
Z mean eval                  0.83456564
Z variance eval              0.011471378
total_rewards                [3296.64712954 3254.67121979 3304.45850408 3277.67894146 1572.1848608
  958.45798106 3230.78746569 3253.07079969 3253.72764711 3310.26009653]
total_rewards_mean           2871.1944645741182
total_rewards_std            814.9383708327365
total_rewards_max            3310.2600965259976
total_rewards_min            958.457981056222
Number of train steps total  491000
Number of env steps total    2457000
Number of rollouts total     0
Train Time (s)               33.19567116815597
(Previous) Eval Time (s)     24.759176631923765
Sample Time (s)              22.931588228791952
Epoch Time (s)               80.88643602887169
Total Train Time (s)         33388.04610384861
Epoch                        490
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:19:13.117294 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #490 | Epoch Duration: 82.22721719741821
2020-01-11 09:19:13.117507 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #490 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8385952
Z variance train             0.011475755
KL Divergence                12.543808
KL Loss                      1.2543808
QF Loss                      138.6033
VF Loss                      36.99041
Policy Loss                  -1397.4933
Q Predictions Mean           1397.2051
Q Predictions Std            117.10517
Q Predictions Max            1529.8196
Q Predictions Min            665.6498
V Predictions Mean           1395.1573
V Predictions Std            116.34389
V Predictions Max            1530.5902
V Predictions Min            659.71313
Log Pis Mean                 -0.58582664
Log Pis Std                  1.6982598
Log Pis Max                  6.212344
Log Pis Min                  -4.664024
Policy mu Mean               0.04831465
Policy mu Std                0.82230526
Policy mu Max                2.003464
Policy mu Min                -2.9005837
Policy log std Mean          -0.3984097
Policy log std Std           0.14517105
Policy log std Max           -0.09467363
Policy log std Min           -1.1188588
Z mean eval                  0.8010217
Z variance eval              0.008446204
total_rewards                [1296.4043535  3264.6093433  3234.64442499 1373.05575177 3225.83543445
 3247.32781028 3251.66507367 3258.1620267  3211.97103672 3257.49900639]
total_rewards_mean           2862.117426178098
total_rewards_std            764.0378833519458
total_rewards_max            3264.6093433046467
total_rewards_min            1296.404353495261
Number of train steps total  492000
Number of env steps total    2462000
Number of rollouts total     0
Train Time (s)               33.62419065274298
(Previous) Eval Time (s)     26.099616983905435
Sample Time (s)              23.747964423149824
Epoch Time (s)               83.47177205979824
Total Train Time (s)         33471.92141920002
Epoch                        491
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:20:36.996012 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #491 | Epoch Duration: 83.87831497192383
2020-01-11 09:20:36.996252 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #491 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8010026
Z variance train             0.008452984
KL Divergence                13.400856
KL Loss                      1.3400856
QF Loss                      76.62106
VF Loss                      58.145527
Policy Loss                  -1482.7076
Q Predictions Mean           1481.3817
Q Predictions Std            125.15834
Q Predictions Max            1617.272
Q Predictions Min            814.8434
V Predictions Mean           1484.2798
V Predictions Std            123.93668
V Predictions Max            1623.272
V Predictions Min            814.6846
Log Pis Mean                 -0.6280357
Log Pis Std                  1.7862341
Log Pis Max                  7.458334
Log Pis Min                  -8.137881
Policy mu Mean               0.010764745
Policy mu Std                0.80317444
Policy mu Max                2.4150896
Policy mu Min                -2.6685038
Policy log std Mean          -0.37924448
Policy log std Std           0.15438579
Policy log std Max           -0.0023221672
Policy log std Min           -1.0070024
Z mean eval                  0.8219601
Z variance eval              0.00799312
total_rewards                [1044.406081   1446.24442369 3217.69262002 3207.40297723 3234.75743093
 1802.42437826 3227.68176037 1526.89540737 3207.68953271  772.02511128]
total_rewards_mean           2268.7219722873515
total_rewards_std            984.8561363636891
total_rewards_max            3234.757430932863
total_rewards_min            772.0251112753388
Number of train steps total  493000
Number of env steps total    2467000
Number of rollouts total     0
Train Time (s)               33.323436863254756
(Previous) Eval Time (s)     26.505785257089883
Sample Time (s)              22.86550196260214
Epoch Time (s)               82.69472408294678
Total Train Time (s)         33549.60624301573
Epoch                        492
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:21:54.685878 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #492 | Epoch Duration: 77.68948864936829
2020-01-11 09:21:54.686071 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #492 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8221591
Z variance train             0.007982637
KL Divergence                13.683886
KL Loss                      1.3683885
QF Loss                      80.0811
VF Loss                      48.62411
Policy Loss                  -1508.4553
Q Predictions Mean           1507.4054
Q Predictions Std            127.679886
Q Predictions Max            1688.845
Q Predictions Min            716.6566
V Predictions Mean           1508.2828
V Predictions Std            124.51618
V Predictions Max            1693.7928
V Predictions Min            711.591
Log Pis Mean                 -0.7274195
Log Pis Std                  1.8864534
Log Pis Max                  11.730263
Log Pis Min                  -4.702346
Policy mu Mean               0.06334794
Policy mu Std                0.76087743
Policy mu Max                2.8964872
Policy mu Min                -2.8320267
Policy log std Mean          -0.36506882
Policy log std Std           0.14082913
Policy log std Max           -0.008710623
Policy log std Min           -1.020159
Z mean eval                  0.82767934
Z variance eval              0.009516662
total_rewards                [3197.83360613 3205.42349611 3282.57579588 3160.44728499 3227.76786125
 3233.28383777 1399.44980029 1488.71176005 3267.98025614 3265.04168447]
total_rewards_mean           2872.8515383072095
total_rewards_std            715.4980917369771
total_rewards_max            3282.575795875435
total_rewards_min            1399.4498002949254
Number of train steps total  494000
Number of env steps total    2472000
Number of rollouts total     0
Train Time (s)               33.35019771102816
(Previous) Eval Time (s)     21.500231896992773
Sample Time (s)              22.27339019952342
Epoch Time (s)               77.12381980754435
Total Train Time (s)         33632.01698394958
Epoch                        493
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:23:17.102145 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #493 | Epoch Duration: 82.41585373878479
2020-01-11 09:23:17.102444 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #493 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8274706
Z variance train             0.0095099555
KL Divergence                13.075823
KL Loss                      1.3075823
QF Loss                      50.143944
VF Loss                      80.83301
Policy Loss                  -1518.9509
Q Predictions Mean           1519.061
Q Predictions Std            106.00481
Q Predictions Max            1655.1044
Q Predictions Min            989.37885
V Predictions Mean           1519.9734
V Predictions Std            104.99901
V Predictions Max            1653.1785
V Predictions Min            1003.5921
Log Pis Mean                 -0.954554
Log Pis Std                  1.5106738
Log Pis Max                  3.501108
Log Pis Min                  -6.9831514
Policy mu Mean               0.033462886
Policy mu Std                0.7193834
Policy mu Max                1.4442729
Policy mu Min                -2.7242272
Policy log std Mean          -0.37491632
Policy log std Std           0.14068553
Policy log std Max           -0.051781654
Policy log std Min           -0.9528372
Z mean eval                  0.8047155
Z variance eval              0.019116605
total_rewards                [3099.36159547 3118.47733114 3107.99321619 1009.04288796 1235.76405137
 3177.32676718 1125.5412137  1033.96895777 1351.86203919 1158.75137672]
total_rewards_mean           1941.8089436685918
total_rewards_std            971.1437350010575
total_rewards_max            3177.3267671772956
total_rewards_min            1009.0428879586776
Number of train steps total  495000
Number of env steps total    2477000
Number of rollouts total     0
Train Time (s)               33.536452749278396
(Previous) Eval Time (s)     26.79196489835158
Sample Time (s)              22.347161277662963
Epoch Time (s)               82.67557892529294
Total Train Time (s)         33704.154445888475
Epoch                        494
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:24:29.243625 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #494 | Epoch Duration: 72.14102053642273
2020-01-11 09:24:29.243811 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #494 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8058082
Z variance train             0.018927267
KL Divergence                11.561644
KL Loss                      1.1561644
QF Loss                      73.285034
VF Loss                      66.98702
Policy Loss                  -1427.6705
Q Predictions Mean           1427.6849
Q Predictions Std            113.30833
Q Predictions Max            1588.654
Q Predictions Min            967.10986
V Predictions Mean           1430.1843
V Predictions Std            113.35167
V Predictions Max            1581.245
V Predictions Min            964.5555
Log Pis Mean                 -0.7052358
Log Pis Std                  1.7299562
Log Pis Max                  8.253024
Log Pis Min                  -6.06621
Policy mu Mean               0.023318877
Policy mu Std                0.77475005
Policy mu Max                1.9536238
Policy mu Min                -2.7460232
Policy log std Mean          -0.39582643
Policy log std Std           0.16043907
Policy log std Max           0.05039853
Policy log std Min           -1.0162638
Z mean eval                  0.81905496
Z variance eval              0.009024406
total_rewards                [1191.51010312 1112.47612296 1251.44019965  933.20752456 3243.96608132
 2711.09044927 3198.41419484 3271.66989218 1087.90224452 1219.35641391]
total_rewards_mean           1922.103322632992
total_rewards_std            981.1642289769568
total_rewards_max            3271.6698921768843
total_rewards_min            933.2075245613014
Number of train steps total  496000
Number of env steps total    2482000
Number of rollouts total     0
Train Time (s)               33.22412983700633
(Previous) Eval Time (s)     16.2570665567182
Sample Time (s)              23.79366422770545
Epoch Time (s)               73.27486062142998
Total Train Time (s)         33777.38429816952
Epoch                        495
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:25:42.479745 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #495 | Epoch Duration: 73.2357885837555
2020-01-11 09:25:42.479948 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #495 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8161375
Z variance train             0.009039355
KL Divergence                13.390261
KL Loss                      1.3390261
QF Loss                      2103.5063
VF Loss                      225.21606
Policy Loss                  -1542.5432
Q Predictions Mean           1540.9912
Q Predictions Std            123.361084
Q Predictions Max            1674.1177
Q Predictions Min            680.6762
V Predictions Mean           1551.414
V Predictions Std            114.75697
V Predictions Max            1685.0818
V Predictions Min            930.8497
Log Pis Mean                 -0.6798486
Log Pis Std                  1.7899827
Log Pis Max                  6.9219565
Log Pis Min                  -6.4173994
Policy mu Mean               -0.024525532
Policy mu Std                0.78840756
Policy mu Max                1.7595034
Policy mu Min                -3.6701286
Policy log std Mean          -0.3998039
Policy log std Std           0.16798134
Policy log std Max           -0.0706667
Policy log std Min           -1.6374838
Z mean eval                  0.814196
Z variance eval              0.014740892
total_rewards                [1145.28968992 1356.14297029 1621.43754023 3180.21296035 1106.95650233
 3201.23514641 3194.56137132 2378.66275645 3144.48599197 2435.89058443]
total_rewards_mean           2276.4875513695983
total_rewards_std            850.1496222463411
total_rewards_max            3201.235146413109
total_rewards_min            1106.9565023314753
Number of train steps total  497000
Number of env steps total    2487000
Number of rollouts total     0
Train Time (s)               33.27034474397078
(Previous) Eval Time (s)     16.217656020075083
Sample Time (s)              22.565303437411785
Epoch Time (s)               72.05330420145765
Total Train Time (s)         33854.464255324565
Epoch                        496
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:26:59.563732 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #496 | Epoch Duration: 77.08363699913025
2020-01-11 09:26:59.563911 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #496 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8142325
Z variance train             0.014771268
KL Divergence                12.44195
KL Loss                      1.244195
QF Loss                      41.275475
VF Loss                      31.218716
Policy Loss                  -1481.0262
Q Predictions Mean           1480.9932
Q Predictions Std            109.63967
Q Predictions Max            1631.0144
Q Predictions Min            882.9271
V Predictions Mean           1480.1548
V Predictions Std            109.10189
V Predictions Max            1627.8915
V Predictions Min            887.1763
Log Pis Mean                 -1.0944299
Log Pis Std                  1.6621459
Log Pis Max                  8.348611
Log Pis Min                  -9.061763
Policy mu Mean               0.071666814
Policy mu Std                0.702084
Policy mu Max                1.8048484
Policy mu Min                -2.6585233
Policy log std Mean          -0.35345212
Policy log std Std           0.13989097
Policy log std Max           -0.075666815
Policy log std Min           -1.186497
Z mean eval                  0.78411376
Z variance eval              0.012987619
total_rewards                [1060.30668364 3217.41663934 3187.722833   1047.62784453 1405.08326612
 1270.54241309 1050.00815457 1140.66167184 3253.2490761  1175.1426952 ]
total_rewards_mean           1780.7761277427744
total_rewards_std            947.6411753108795
total_rewards_max            3253.2490760968694
total_rewards_min            1047.6278445342145
Number of train steps total  498000
Number of env steps total    2492000
Number of rollouts total     0
Train Time (s)               33.27962249936536
(Previous) Eval Time (s)     21.247449465095997
Sample Time (s)              22.87566323718056
Epoch Time (s)               77.40273520164192
Total Train Time (s)         33926.73574802093
Epoch                        497
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:28:11.840504 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #497 | Epoch Duration: 72.27645468711853
2020-01-11 09:28:11.840694 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #497 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.78560406
Z variance train             0.012995357
KL Divergence                12.460946
KL Loss                      1.2460946
QF Loss                      67.62253
VF Loss                      32.16524
Policy Loss                  -1429.2708
Q Predictions Mean           1427.688
Q Predictions Std            108.21719
Q Predictions Max            1545.0591
Q Predictions Min            410.47717
V Predictions Mean           1426.8228
V Predictions Std            108.40809
V Predictions Max            1538.4757
V Predictions Min            382.35428
Log Pis Mean                 -0.32936245
Log Pis Std                  1.9322145
Log Pis Max                  7.6374836
Log Pis Min                  -3.9688156
Policy mu Mean               -0.066107094
Policy mu Std                0.8767148
Policy mu Max                2.3197813
Policy mu Min                -2.8292568
Policy log std Mean          -0.3911915
Policy log std Std           0.16521908
Policy log std Max           -0.087164536
Policy log std Min           -1.0422866
Z mean eval                  0.80119
Z variance eval              0.01629167
total_rewards                [3205.16385281 1581.10581582 3203.2961906  3179.12498323 3179.04026044
 3214.30118872 3206.24320741 3214.14911316 1242.56948357 3175.69753174]
total_rewards_mean           2840.0691627487863
total_rewards_std            718.2476903163177
total_rewards_max            3214.3011887220496
total_rewards_min            1242.5694835684487
Number of train steps total  499000
Number of env steps total    2497000
Number of rollouts total     0
Train Time (s)               33.158788511995226
(Previous) Eval Time (s)     16.120834997389466
Sample Time (s)              23.389641186688095
Epoch Time (s)               72.66926469607279
Total Train Time (s)         34009.16632748069
Epoch                        498
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:29:34.275713 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #498 | Epoch Duration: 82.4348795413971
2020-01-11 09:29:34.275900 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #498 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8026959
Z variance train             0.016297799
KL Divergence                11.927187
KL Loss                      1.1927187
QF Loss                      71.21517
VF Loss                      27.026293
Policy Loss                  -1486.6471
Q Predictions Mean           1485.79
Q Predictions Std            88.31924
Q Predictions Max            1599.032
Q Predictions Min            1197.7852
V Predictions Mean           1483.6238
V Predictions Std            88.544815
V Predictions Max            1598.1324
V Predictions Min            1196.9294
Log Pis Mean                 -0.9791903
Log Pis Std                  1.4421293
Log Pis Max                  4.8212557
Log Pis Min                  -4.616624
Policy mu Mean               0.00080474373
Policy mu Std                0.69210964
Policy mu Max                1.5701632
Policy mu Min                -2.4854305
Policy log std Mean          -0.35994753
Policy log std Std           0.14689495
Policy log std Max           0.0005494654
Policy log std Min           -1.1492468
Z mean eval                  0.82739353
Z variance eval              0.014985936
total_rewards                [3266.43181121 1168.76658722 3258.23739884 3243.95481078 3263.71606292
 3177.04593552 3231.88638916 3206.18629176 3248.00799312 3217.41503123]
total_rewards_mean           3028.164831176572
total_rewards_std            620.3726637107188
total_rewards_max            3266.4318112085157
total_rewards_min            1168.7665872186242
Number of train steps total  500000
Number of env steps total    2502000
Number of rollouts total     0
Train Time (s)               33.443756722379476
(Previous) Eval Time (s)     25.88613132480532
Sample Time (s)              22.862415284849703
Epoch Time (s)               82.1923033320345
Total Train Time (s)         34093.03070799541
Epoch                        499
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:30:58.144837 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #499 | Epoch Duration: 83.86879706382751
2020-01-11 09:30:58.145033 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #499 | Started Training: True
2020-01-11 09:30:58.824703 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Variant:
2020-01-11 09:30:58.825256 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] {
  "env_name": "HalfCheetah-v2",
  "n_train_tasks": 1,
  "n_eval_tasks": 1,
  "latent_size": 5,
  "net_size": 300,
  "path_to_weights": null,
  "env_params": {
    "n_tasks": 2,
    "randomize_tasks": true
  },
  "algo_params": {
    "meta_batch": 1,
    "num_iterations": 500,
    "num_initial_steps": 2000,
    "num_tasks_sample": 5,
    "num_steps_prior": 400,
    "num_steps_posterior": 0,
    "num_extra_rl_steps_posterior": 600,
    "num_train_steps_per_itr": 1000,
    "num_evals": 2,
    "num_steps_per_eval": 600,
    "batch_size": 256,
    "embedding_batch_size": 20,
    "embedding_mini_batch_size": 20,
    "max_path_length": 200,
    "discount": 0.99,
    "soft_target_tau": 0.005,
    "policy_lr": 0.0003,
    "qf_lr": 0.0003,
    "vf_lr": 0.0003,
    "context_lr": 0.0003,
    "reward_scale": 5.0,
    "sparse_rewards": false,
    "kl_lambda": 0.1,
    "use_information_bottleneck": true,
    "use_next_obs_in_context": false,
    "update_post_train": 1,
    "num_exp_traj_eval": 2,
    "recurrent": true,
    "dump_eval_paths": false
  },
  "util_params": {
    "base_log_dir": "./test/train1000/H-20_seed567",
    "use_gpu": true,
    "gpu_id": 0,
    "debug": false,
    "docker": false,
    "num_iterations": 3000
  }
}
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0015201619
Z variance train             0.69264114
KL Divergence                0.14971898
KL Loss                      0.014971899
QF Loss                      32.371784
VF Loss                      16.538906
Policy Loss                  -4.035804
Q Predictions Mean           0.0036291555
Q Predictions Std            0.002453938
Q Predictions Max            0.013234481
Q Predictions Min            -0.0022524772
V Predictions Mean           0.0029185028
V Predictions Std            0.0014939969
V Predictions Max            0.0071519334
V Predictions Min            -0.000653669
Log Pis Mean                 -4.064831
Log Pis Std                  0.5246426
Log Pis Max                  -2.2257078
Log Pis Min                  -5.3402777
Policy mu Mean               -0.0006778512
Policy mu Std                0.0014411181
Policy mu Max                0.0035296434
Policy mu Min                -0.0050696675
Policy log std Mean          0.000738925
Policy log std Std           0.0011386123
Policy log std Max           0.0049709105
Policy log std Min           -0.0033788155
Z mean eval                  0.07993744
Z variance eval              0.32485247
total_rewards                [-200.82907101 -202.76848645 -168.74245878 -232.31895182 -220.13140052
 -212.3383889  -226.08169056 -120.83841821 -218.3369065  -135.31654978]
total_rewards_mean           -193.77023225472038
total_rewards_std            36.96797392052177
total_rewards_max            -120.8384182108695
total_rewards_min            -232.3189518241989
Number of train steps total  1000
Number of env steps total    7000
Number of rollouts total     0
Train Time (s)               31.282528204843402
(Previous) Eval Time (s)     0
Sample Time (s)              30.15089809242636
Epoch Time (s)               61.43342629726976
Total Train Time (s)         88.84280491713434
Epoch                        0
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:32:27.762176 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #0 | Epoch Duration: 88.84666299819946
2020-01-11 09:32:27.762379 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #0 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07835974
Z variance train             0.33578882
KL Divergence                1.1684575
KL Loss                      0.11684575
QF Loss                      14.789925
VF Loss                      3.5173538
Policy Loss                  -14.803765
Q Predictions Mean           10.779072
Q Predictions Std            6.6848345
Q Predictions Max            28.215405
Q Predictions Min            -6.1339226
V Predictions Mean           15.420614
V Predictions Std            6.321533
V Predictions Max            30.021038
V Predictions Min            -1.2740269
Log Pis Mean                 -3.2535362
Log Pis Std                  1.3246145
Log Pis Max                  0.6511984
Log Pis Min                  -6.5906816
Policy mu Mean               0.09648109
Policy mu Std                0.4450997
Policy mu Max                1.1736729
Policy mu Min                -1.3065996
Policy log std Mean          -0.18879552
Policy log std Std           0.077634394
Policy log std Max           -0.08752225
Policy log std Min           -0.43323752
Z mean eval                  0.22500324
Z variance eval              0.13169323
total_rewards                [-200.14584303 -242.15254698 -284.64994695 -242.56218723 -235.53361072
 -198.37059878 -235.11872719 -236.8546247  -214.17362031 -264.53065285]
total_rewards_mean           -235.4092358749761
total_rewards_std            25.372917462329237
total_rewards_max            -198.37059878300934
total_rewards_min            -284.64994694706746
Number of train steps total  2000
Number of env steps total    12000
Number of rollouts total     0
Train Time (s)               30.879661465995014
(Previous) Eval Time (s)     27.412906241137534
Sample Time (s)              22.467444519046694
Epoch Time (s)               80.76001222617924
Total Train Time (s)         169.52885462203994
Epoch                        1
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:33:48.451266 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #1 | Epoch Duration: 80.68870210647583
2020-01-11 09:33:48.451571 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #1 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.22587089
Z variance train             0.13049558
KL Divergence                3.1642394
KL Loss                      0.31642395
QF Loss                      34.187645
VF Loss                      5.099211
Policy Loss                  -28.973028
Q Predictions Mean           25.473892
Q Predictions Std            10.219346
Q Predictions Max            62.92463
Q Predictions Min            -3.5590649
V Predictions Mean           29.424427
V Predictions Std            9.8846
V Predictions Max            68.13687
V Predictions Min            5.0687485
Log Pis Mean                 -3.5062134
Log Pis Std                  1.0859234
Log Pis Max                  0.0016558766
Log Pis Min                  -7.534276
Policy mu Mean               0.020472305
Policy mu Std                0.37830496
Policy mu Max                1.3228645
Policy mu Min                -1.2648107
Policy log std Mean          -0.18281329
Policy log std Std           0.06932604
Policy log std Max           -0.05493781
Policy log std Min           -0.4418341
Z mean eval                  0.4366208
Z variance eval              0.08436639
total_rewards                [-264.47025993 -277.17459009 -254.08721252 -247.84073219 -242.9712891
 -263.57358716 -292.24720484 -241.42823686 -245.26586305 -245.56727435]
total_rewards_mean           -257.46262500927
total_rewards_std            15.957175147557543
total_rewards_max            -241.4282368622492
total_rewards_min            -292.2472048401007
Number of train steps total  3000
Number of env steps total    17000
Number of rollouts total     0
Train Time (s)               31.203827689867467
(Previous) Eval Time (s)     27.341280607972294
Sample Time (s)              23.04788814811036
Epoch Time (s)               81.59299644595012
Total Train Time (s)         251.59368136012927
Epoch                        2
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:35:10.515292 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #2 | Epoch Duration: 82.0635118484497
2020-01-11 09:35:10.515471 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #2 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.43565378
Z variance train             0.084201396
KL Divergence                4.8077207
KL Loss                      0.48077208
QF Loss                      36.738667
VF Loss                      7.615075
Policy Loss                  -43.12816
Q Predictions Mean           39.194317
Q Predictions Std            13.250546
Q Predictions Max            85.675735
Q Predictions Min            -3.2411332
V Predictions Mean           43.626335
V Predictions Std            12.417139
V Predictions Max            79.00407
V Predictions Min            -0.5445509
Log Pis Mean                 -3.1287332
Log Pis Std                  1.5452608
Log Pis Max                  1.7656198
Log Pis Min                  -8.724302
Policy mu Mean               0.066637784
Policy mu Std                0.47198477
Policy mu Max                1.8134552
Policy mu Min                -1.3583819
Policy log std Mean          -0.20153923
Policy log std Std           0.09314299
Policy log std Max           7.034652e-05
Policy log std Min           -0.6536395
Z mean eval                  0.65564376
Z variance eval              0.0458109
total_rewards                [-161.97096196 -181.25996467 -160.20721111 -212.30009532 -203.11699627
 -179.74121454 -151.54230731 -171.16730712 -136.22365779 -218.70594424]
total_rewards_mean           -177.62356603179987
total_rewards_std            25.57742651214993
total_rewards_max            -136.22365778745254
total_rewards_min            -218.70594423686362
Number of train steps total  4000
Number of env steps total    22000
Number of rollouts total     0
Train Time (s)               30.50432626903057
(Previous) Eval Time (s)     27.811487597879022
Sample Time (s)              21.65523344743997
Epoch Time (s)               79.97104731434956
Total Train Time (s)         331.9024976002984
Epoch                        3
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:36:30.825816 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #3 | Epoch Duration: 80.31020545959473
2020-01-11 09:36:30.826020 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #3 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6630057
Z variance train             0.044580724
KL Divergence                7.3903823
KL Loss                      0.7390382
QF Loss                      33.999825
VF Loss                      8.407857
Policy Loss                  -59.162487
Q Predictions Mean           55.42431
Q Predictions Std            15.97362
Q Predictions Max            110.08674
Q Predictions Min            -9.916785
V Predictions Mean           58.90364
V Predictions Std            15.103675
V Predictions Max            107.87996
V Predictions Min            0.15744306
Log Pis Mean                 -2.9543755
Log Pis Std                  1.7350848
Log Pis Max                  3.798399
Log Pis Min                  -7.824932
Policy mu Mean               0.018923905
Policy mu Std                0.51861316
Policy mu Max                1.8961312
Policy mu Min                -1.7239045
Policy log std Mean          -0.2119714
Policy log std Std           0.10100964
Policy log std Max           -0.06413683
Policy log std Min           -0.5824467
Z mean eval                  0.8020009
Z variance eval              0.050723605
total_rewards                [-153.02118313 -166.25615525 -224.9905118  -157.353563   -151.70931495
 -151.67136606 -145.34570543 -173.69564171 -183.47780554 -108.58247541]
total_rewards_mean           -161.61037222773217
total_rewards_std            28.333849668781042
total_rewards_max            -108.58247540695703
total_rewards_min            -224.99051180276723
Number of train steps total  5000
Number of env steps total    27000
Number of rollouts total     0
Train Time (s)               30.629740813281387
(Previous) Eval Time (s)     28.150364140048623
Sample Time (s)              22.358004365116358
Epoch Time (s)               81.13810931844637
Total Train Time (s)         412.80799443414435
Epoch                        4
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:37:51.731560 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #4 | Epoch Duration: 80.9054012298584
2020-01-11 09:37:51.731743 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #4 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8057186
Z variance train             0.04912064
KL Divergence                8.044588
KL Loss                      0.8044588
QF Loss                      41.17598
VF Loss                      11.064675
Policy Loss                  -73.76578
Q Predictions Mean           69.34883
Q Predictions Std            17.089077
Q Predictions Max            119.19427
Q Predictions Min            9.302284
V Predictions Mean           71.62541
V Predictions Std            16.807451
V Predictions Max            118.83016
V Predictions Min            8.948689
Log Pis Mean                 -3.061572
Log Pis Std                  1.7076039
Log Pis Max                  3.2548497
Log Pis Min                  -7.445352
Policy mu Mean               -0.008753528
Policy mu Std                0.49865893
Policy mu Max                1.8039142
Policy mu Min                -1.9925624
Policy log std Mean          -0.20137449
Policy log std Std           0.103393145
Policy log std Max           -0.056216855
Policy log std Min           -0.6666055
Z mean eval                  0.901347
Z variance eval              0.051752865
total_rewards                [-158.12344484 -112.1703421  -189.88269211 -158.47393257 -193.03128145
 -177.54146635 -158.08879611 -139.09107738 -150.04927092 -189.59665954]
total_rewards_mean           -162.60489633579056
total_rewards_std            24.358223582763216
total_rewards_max            -112.17034209850152
total_rewards_min            -193.03128145128008
Number of train steps total  6000
Number of env steps total    32000
Number of rollouts total     0
Train Time (s)               30.80589438881725
(Previous) Eval Time (s)     27.917344293091446
Sample Time (s)              23.297137051355094
Epoch Time (s)               82.02037573326379
Total Train Time (s)         495.4503342662938
Epoch                        5
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:39:14.374535 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #5 | Epoch Duration: 82.64265465736389
2020-01-11 09:39:14.374689 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #5 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9027621
Z variance train             0.051680595
KL Divergence                8.843341
KL Loss                      0.8843341
QF Loss                      33.450153
VF Loss                      6.4520445
Policy Loss                  -85.952385
Q Predictions Mean           81.73154
Q Predictions Std            19.306187
Q Predictions Max            164.27942
Q Predictions Min            19.26034
V Predictions Mean           85.901886
V Predictions Std            19.529678
V Predictions Max            167.90323
V Predictions Min            39.925488
Log Pis Mean                 -3.1801076
Log Pis Std                  1.6333816
Log Pis Max                  3.4466276
Log Pis Min                  -6.481405
Policy mu Mean               -0.012619029
Policy mu Std                0.46316916
Policy mu Max                1.8580676
Policy mu Min                -1.928293
Policy log std Mean          -0.20114447
Policy log std Std           0.09241416
Policy log std Max           0.0064579993
Policy log std Min           -0.696
Z mean eval                  0.9766189
Z variance eval              0.04702075
total_rewards                [-149.07605836 -145.53239557 -146.88562668 -148.95878947  -90.98746393
 -163.70930106 -128.32661636 -171.68806721 -118.97231745  -97.44061771]
total_rewards_mean           -136.15772537889487
total_rewards_std            25.399308748104495
total_rewards_max            -90.98746392741118
total_rewards_min            -171.6880672061502
Number of train steps total  7000
Number of env steps total    37000
Number of rollouts total     0
Train Time (s)               31.502125311177224
(Previous) Eval Time (s)     28.539308989886194
Sample Time (s)              22.301208697259426
Epoch Time (s)               82.34264299832284
Total Train Time (s)         576.8459163047373
Epoch                        6
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:40:35.772669 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #6 | Epoch Duration: 81.39785718917847
2020-01-11 09:40:35.772861 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #6 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97602445
Z variance train             0.04694254
KL Divergence                9.758129
KL Loss                      0.9758129
QF Loss                      57.943726
VF Loss                      18.13096
Policy Loss                  -98.24181
Q Predictions Mean           96.45314
Q Predictions Std            24.753475
Q Predictions Max            164.3506
Q Predictions Min            41.61074
V Predictions Mean           100.26493
V Predictions Std            24.65675
V Predictions Max            177.36543
V Predictions Min            53.839314
Log Pis Mean                 -3.0864115
Log Pis Std                  1.4867457
Log Pis Max                  2.2095249
Log Pis Min                  -7.0574064
Policy mu Mean               0.048770864
Policy mu Std                0.4794033
Policy mu Max                1.809677
Policy mu Min                -1.9506223
Policy log std Mean          -0.20490937
Policy log std Std           0.083888486
Policy log std Max           0.12673739
Policy log std Min           -0.6467075
Z mean eval                  1.0186815
Z variance eval              0.050217815
total_rewards                [ -44.41206089  -79.48092391  -70.81271431 -146.84353258 -114.38220065
  -84.89470599 -117.734346   -131.61554423 -144.30347488  -83.26479511]
total_rewards_mean           -101.77442985578094
total_rewards_std            32.431021986847945
total_rewards_max            -44.41206089256293
total_rewards_min            -146.8435325752307
Number of train steps total  8000
Number of env steps total    42000
Number of rollouts total     0
Train Time (s)               31.23419266194105
(Previous) Eval Time (s)     27.594204633962363
Sample Time (s)              23.25204490032047
Epoch Time (s)               82.08044219622388
Total Train Time (s)         658.0619021113962
Epoch                        7
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:41:56.989240 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #7 | Epoch Duration: 81.21623992919922
2020-01-11 09:41:56.989439 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #7 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0185368
Z variance train             0.050598264
KL Divergence                10.043104
KL Loss                      1.0043105
QF Loss                      41.45702
VF Loss                      12.81398
Policy Loss                  -111.64321
Q Predictions Mean           106.722916
Q Predictions Std            27.16031
Q Predictions Max            193.7343
Q Predictions Min            70.06034
V Predictions Mean           109.72436
V Predictions Std            25.983679
V Predictions Max            195.03882
V Predictions Min            75.16518
Log Pis Mean                 -3.1263309
Log Pis Std                  1.5191318
Log Pis Max                  2.7373748
Log Pis Min                  -7.1388397
Policy mu Mean               -0.030586729
Policy mu Std                0.4794564
Policy mu Max                1.5562617
Policy mu Min                -2.002719
Policy log std Mean          -0.21957035
Policy log std Std           0.09361458
Policy log std Max           0.09777486
Policy log std Min           -0.72312665
Z mean eval                  1.0942835
Z variance eval              0.04344431
total_rewards                [-56.27239054   1.69540573   5.72586809 -61.7749005  -29.92085982
 -32.97786786   5.04803372 -28.97104048 -51.09173236   4.40024093]
total_rewards_mean           -24.413924308035945
total_rewards_std            25.564256140392047
total_rewards_max            5.725868093499321
total_rewards_min            -61.77490049563736
Number of train steps total  9000
Number of env steps total    47000
Number of rollouts total     0
Train Time (s)               31.158348460216075
(Previous) Eval Time (s)     26.729710310697556
Sample Time (s)              22.90138601604849
Epoch Time (s)               80.78944478696212
Total Train Time (s)         740.0623128400184
Epoch                        8
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:43:18.990441 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #8 | Epoch Duration: 82.00086569786072
2020-01-11 09:43:18.990619 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #8 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.09183
Z variance train             0.043615095
KL Divergence                11.392872
KL Loss                      1.1392872
QF Loss                      32.58496
VF Loss                      17.83353
Policy Loss                  -122.612335
Q Predictions Mean           119.35448
Q Predictions Std            30.67128
Q Predictions Max            216.82132
Q Predictions Min            75.554535
V Predictions Mean           125.10418
V Predictions Std            31.594719
V Predictions Max            229.34958
V Predictions Min            84.95755
Log Pis Mean                 -3.2488508
Log Pis Std                  1.474577
Log Pis Max                  2.0143466
Log Pis Min                  -7.5491924
Policy mu Mean               -0.005070189
Policy mu Std                0.47742093
Policy mu Max                1.8484424
Policy mu Min                -1.8989244
Policy log std Mean          -0.21700753
Policy log std Std           0.08917145
Policy log std Max           0.03202007
Policy log std Min           -0.7190094
Z mean eval                  1.1381837
Z variance eval              0.04430213
total_rewards                [ 20.56950252  14.02535825  73.89255714  91.3083509   92.53113151
  82.08657403   4.39718752 149.59806207  73.19182402  66.12986567]
total_rewards_mean           66.77304136287702
total_rewards_std            41.545256201266014
total_rewards_max            149.59806206599572
total_rewards_min            4.397187516308273
Number of train steps total  10000
Number of env steps total    52000
Number of rollouts total     0
Train Time (s)               30.566280148923397
(Previous) Eval Time (s)     27.9408347918652
Sample Time (s)              23.24390358151868
Epoch Time (s)               81.75101852230728
Total Train Time (s)         821.5306851188652
Epoch                        9
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:44:40.460055 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #9 | Epoch Duration: 81.46929216384888
2020-01-11 09:44:40.460260 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #9 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.133028
Z variance train             0.044331484
KL Divergence                12.234659
KL Loss                      1.2234659
QF Loss                      35.513264
VF Loss                      19.547712
Policy Loss                  -128.97498
Q Predictions Mean           126.09135
Q Predictions Std            32.016544
Q Predictions Max            244.68954
Q Predictions Min            86.734436
V Predictions Mean           132.01956
V Predictions Std            32.9003
V Predictions Max            256.5565
V Predictions Min            95.96737
Log Pis Mean                 -3.0672739
Log Pis Std                  1.683093
Log Pis Max                  5.0131574
Log Pis Min                  -7.2425747
Policy mu Mean               -0.011444359
Policy mu Std                0.50485533
Policy mu Max                1.7981929
Policy mu Min                -2.1223986
Policy log std Mean          -0.22838606
Policy log std Std           0.09285361
Policy log std Max           0.020523667
Policy log std Min           -0.7683546
Z mean eval                  1.1322503
Z variance eval              0.039528586
total_rewards                [ 33.5665265  122.36252509 193.16586231 135.33365709 153.98854041
 171.82841966  57.1803142  101.56130533 131.69781382  78.15365863]
total_rewards_mean           117.88386230365184
total_rewards_std            47.99538561943817
total_rewards_max            193.16586230634329
total_rewards_min            33.56652649890937
Number of train steps total  11000
Number of env steps total    57000
Number of rollouts total     0
Train Time (s)               31.3660002136603
(Previous) Eval Time (s)     27.65877843508497
Sample Time (s)              22.83519466686994
Epoch Time (s)               81.8599733156152
Total Train Time (s)         903.9868268193677
Epoch                        10
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:46:02.917538 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #10 | Epoch Duration: 82.45713329315186
2020-01-11 09:46:02.917726 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #10 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1347691
Z variance train             0.03951291
KL Divergence                12.276606
KL Loss                      1.2276605
QF Loss                      33.68023
VF Loss                      10.375688
Policy Loss                  -147.69983
Q Predictions Mean           142.5132
Q Predictions Std            39.87548
Q Predictions Max            279.19415
Q Predictions Min            98.349144
V Predictions Mean           146.49722
V Predictions Std            39.639725
V Predictions Max            283.80582
V Predictions Min            103.64554
Log Pis Mean                 -3.0778902
Log Pis Std                  1.5110328
Log Pis Max                  2.0815492
Log Pis Min                  -8.04791
Policy mu Mean               -0.020445859
Policy mu Std                0.47572753
Policy mu Max                1.6900885
Policy mu Min                -1.4956285
Policy log std Mean          -0.23273455
Policy log std Std           0.09489862
Policy log std Max           0.07173778
Policy log std Min           -0.7228459
Z mean eval                  1.1641713
Z variance eval              0.03627351
total_rewards                [109.88897122 105.43027799 230.13187946 255.41306564 141.23434957
 183.73054183 190.73140345 158.55002862 174.90547836 193.85448763]
total_rewards_mean           174.38704837737822
total_rewards_std            45.46574668063686
total_rewards_max            255.4130656408421
total_rewards_min            105.43027798734101
Number of train steps total  12000
Number of env steps total    62000
Number of rollouts total     0
Train Time (s)               30.954024689737707
(Previous) Eval Time (s)     28.25562819512561
Sample Time (s)              23.060216513928026
Epoch Time (s)               82.26986939879134
Total Train Time (s)         985.7231395915151
Epoch                        11
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:47:24.655263 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #11 | Epoch Duration: 81.73738884925842
2020-01-11 09:47:24.655468 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #11 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1616275
Z variance train             0.036166646
KL Divergence                12.779986
KL Loss                      1.2779987
QF Loss                      43.357536
VF Loss                      8.479563
Policy Loss                  -156.5703
Q Predictions Mean           152.84154
Q Predictions Std            42.583286
Q Predictions Max            314.51566
Q Predictions Min            106.26481
V Predictions Mean           156.96124
V Predictions Std            42.01075
V Predictions Max            309.15826
V Predictions Min            110.86297
Log Pis Mean                 -2.970049
Log Pis Std                  1.5612094
Log Pis Max                  2.2961462
Log Pis Min                  -6.757117
Policy mu Mean               -0.058495235
Policy mu Std                0.48692524
Policy mu Max                1.6990263
Policy mu Min                -1.5769061
Policy log std Mean          -0.24607833
Policy log std Std           0.1010238
Policy log std Max           0.036857665
Policy log std Min           -0.7095067
Z mean eval                  1.1796161
Z variance eval              0.035937134
total_rewards                [313.04626655 270.02617913 217.76333964 390.89539388 198.41489171
 172.97877122 310.36162047 346.27241507 279.10284536 197.11646193]
total_rewards_mean           269.5978184967797
total_rewards_std            68.24565142332685
total_rewards_max            390.89539387911736
total_rewards_min            172.9787712181966
Number of train steps total  13000
Number of env steps total    67000
Number of rollouts total     0
Train Time (s)               30.73579427599907
(Previous) Eval Time (s)     27.722824529279023
Sample Time (s)              23.074334785807878
Epoch Time (s)               81.53295359108597
Total Train Time (s)         1066.883723301813
Epoch                        12
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:48:45.816829 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #12 | Epoch Duration: 81.16121053695679
2020-01-11 09:48:45.817057 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #12 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1805618
Z variance train             0.035982534
KL Divergence                12.948805
KL Loss                      1.2948805
QF Loss                      33.65877
VF Loss                      10.2216835
Policy Loss                  -159.26308
Q Predictions Mean           155.32071
Q Predictions Std            41.23714
Q Predictions Max            319.36438
Q Predictions Min            111.01356
V Predictions Mean           158.66278
V Predictions Std            40.30182
V Predictions Max            317.04443
V Predictions Min            118.16551
Log Pis Mean                 -3.0218148
Log Pis Std                  1.5203948
Log Pis Max                  4.1830196
Log Pis Min                  -6.6819253
Policy mu Mean               0.045301702
Policy mu Std                0.48875883
Policy mu Max                1.8024282
Policy mu Min                -1.9853652
Policy log std Mean          -0.23462623
Policy log std Std           0.10225036
Policy log std Max           0.14872093
Policy log std Min           -0.71061534
Z mean eval                  1.1844629
Z variance eval              0.04272435
total_rewards                [513.91443674 445.07862697 418.89370057 276.35928426 397.46738212
 397.16801522 306.34192605 372.31540449 397.6663129  276.4861728 ]
total_rewards_mean           380.1691262136316
total_rewards_std            71.78701972184412
total_rewards_max            513.9144367449906
total_rewards_min            276.3592842630214
Number of train steps total  14000
Number of env steps total    72000
Number of rollouts total     0
Train Time (s)               30.616104275919497
(Previous) Eval Time (s)     27.35073783993721
Sample Time (s)              22.226598078384995
Epoch Time (s)               80.1934401942417
Total Train Time (s)         1148.1272029485554
Epoch                        13
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:50:07.061324 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #13 | Epoch Duration: 81.24409055709839
2020-01-11 09:50:07.061515 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #13 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1838614
Z variance train             0.042702354
KL Divergence                13.127537
KL Loss                      1.3127537
QF Loss                      35.101772
VF Loss                      12.881174
Policy Loss                  -173.2161
Q Predictions Mean           169.15393
Q Predictions Std            48.646175
Q Predictions Max            355.24738
Q Predictions Min            115.96021
V Predictions Mean           172.30122
V Predictions Std            48.912655
V Predictions Max            347.97458
V Predictions Min            121.21125
Log Pis Mean                 -2.7489102
Log Pis Std                  1.5877421
Log Pis Max                  2.3705928
Log Pis Min                  -7.446942
Policy mu Mean               0.021554159
Policy mu Std                0.5356501
Policy mu Max                1.9423994
Policy mu Min                -1.6323805
Policy log std Mean          -0.25923833
Policy log std Std           0.12519392
Policy log std Max           0.11545859
Policy log std Min           -0.91879785
Z mean eval                  1.1798432
Z variance eval              0.033920567
total_rewards                [1080.10432338 1318.944368    350.92123176  419.75815047  840.20825756
  479.94070331 1275.34411813  405.07643646  664.64394018  794.60671968]
total_rewards_mean           762.9548248935638
total_rewards_std            344.18243748662786
total_rewards_max            1318.9443680042398
total_rewards_min            350.9212317618292
Number of train steps total  15000
Number of env steps total    77000
Number of rollouts total     0
Train Time (s)               31.174784757662565
(Previous) Eval Time (s)     28.401082387194037
Sample Time (s)              22.178720062598586
Epoch Time (s)               81.75458720745519
Total Train Time (s)         1229.0617710277438
Epoch                        14
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:51:27.997070 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #14 | Epoch Duration: 80.93541383743286
2020-01-11 09:51:27.997258 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #14 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1786008
Z variance train             0.033883102
KL Divergence                13.491608
KL Loss                      1.3491608
QF Loss                      41.049576
VF Loss                      13.280671
Policy Loss                  -203.02661
Q Predictions Mean           199.25887
Q Predictions Std            65.033745
Q Predictions Max            376.96426
Q Predictions Min            127.3021
V Predictions Mean           201.32588
V Predictions Std            64.84946
V Predictions Max            374.60956
V Predictions Min            131.13881
Log Pis Mean                 -2.715607
Log Pis Std                  1.6946076
Log Pis Max                  4.4224405
Log Pis Min                  -6.8258114
Policy mu Mean               0.016896686
Policy mu Std                0.5880427
Policy mu Max                2.0395164
Policy mu Min                -2.0384872
Policy log std Mean          -0.27519205
Policy log std Std           0.1221252
Policy log std Max           0.049510993
Policy log std Min           -0.8148135
Z mean eval                  1.2357035
Z variance eval              0.03492287
total_rewards                [1821.02729056  701.50676868 1519.87409679 1234.50205444 1801.67373143
 1536.34244705 1137.5319286  1494.85745685 1822.82791939  624.70914657]
total_rewards_mean           1369.4852840358367
total_rewards_std            416.5672209385302
total_rewards_max            1822.8279193909525
total_rewards_min            624.7091465665416
Number of train steps total  16000
Number of env steps total    82000
Number of rollouts total     0
Train Time (s)               31.072036435827613
(Previous) Eval Time (s)     27.581547719892114
Sample Time (s)              22.41868360200897
Epoch Time (s)               81.0722677577287
Total Train Time (s)         1308.8397087650374
Epoch                        15
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:52:47.776933 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #15 | Epoch Duration: 79.77953886985779
2020-01-11 09:52:47.777110 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #15 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2368205
Z variance train             0.03492842
KL Divergence                13.544209
KL Loss                      1.3544209
QF Loss                      43.87442
VF Loss                      15.074235
Policy Loss                  -205.66624
Q Predictions Mean           201.05676
Q Predictions Std            72.37625
Q Predictions Max            408.06833
Q Predictions Min            134.45547
V Predictions Mean           206.97675
V Predictions Std            73.79414
V Predictions Max            415.86432
V Predictions Min            139.20882
Log Pis Mean                 -2.408657
Log Pis Std                  2.077685
Log Pis Max                  5.4321384
Log Pis Min                  -7.7204423
Policy mu Mean               0.024089614
Policy mu Std                0.6172652
Policy mu Max                2.3932045
Policy mu Min                -1.7264677
Policy log std Mean          -0.27551207
Policy log std Std           0.13703531
Policy log std Max           0.10670206
Policy log std Min           -1.0834877
Z mean eval                  1.2656448
Z variance eval              0.031946324
total_rewards                [2055.93768758 1955.13873017 2029.61739805 2191.98630611  926.14471931
 2130.19329615 2123.3880868  2106.1428148  2109.62418764 1248.24340049]
total_rewards_mean           1887.6416627096278
total_rewards_std            411.14417831085075
total_rewards_max            2191.9863061120595
total_rewards_min            926.1447193084119
Number of train steps total  17000
Number of env steps total    87000
Number of rollouts total     0
Train Time (s)               31.14617990097031
(Previous) Eval Time (s)     26.28848956199363
Sample Time (s)              22.552295421250165
Epoch Time (s)               79.9869648842141
Total Train Time (s)         1389.9355632211082
Epoch                        16
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:54:08.873401 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #16 | Epoch Duration: 81.09614562988281
2020-01-11 09:54:08.873613 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #16 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2692006
Z variance train             0.03188368
KL Divergence                14.859533
KL Loss                      1.4859533
QF Loss                      44.182533
VF Loss                      20.94289
Policy Loss                  -235.49886
Q Predictions Mean           230.97327
Q Predictions Std            90.757835
Q Predictions Max            457.3693
Q Predictions Min            143.67831
V Predictions Mean           233.48508
V Predictions Std            88.46681
V Predictions Max            452.8161
V Predictions Min            146.75853
Log Pis Mean                 -1.9479457
Log Pis Std                  2.3873606
Log Pis Max                  5.521472
Log Pis Min                  -7.4464626
Policy mu Mean               0.0320873
Policy mu Std                0.6907971
Policy mu Max                2.0358553
Policy mu Min                -2.0057642
Policy log std Mean          -0.311577
Policy log std Std           0.16038263
Policy log std Max           -0.038918905
Policy log std Min           -1.0441618
Z mean eval                  1.3201697
Z variance eval              0.026469907
total_rewards                [2140.91034703 2172.5857636  2253.58421676 2185.12443549 2240.48129377
 2181.18646232 2167.10508605 2042.93949895  612.3757868  2342.97468337]
total_rewards_mean           2033.926757413198
total_rewards_std            479.6110530678901
total_rewards_max            2342.9746833714867
total_rewards_min            612.375786797576
Number of train steps total  18000
Number of env steps total    92000
Number of rollouts total     0
Train Time (s)               31.007586885243654
(Previous) Eval Time (s)     27.39729680912569
Sample Time (s)              23.08671848429367
Epoch Time (s)               81.49160217866302
Total Train Time (s)         1472.7163184694946
Epoch                        17
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:55:31.654614 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #17 | Epoch Duration: 82.78083848953247
2020-01-11 09:55:31.654773 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #17 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3170698
Z variance train             0.02650646
KL Divergence                15.612611
KL Loss                      1.561261
QF Loss                      76.17983
VF Loss                      17.641594
Policy Loss                  -283.33002
Q Predictions Mean           279.27545
Q Predictions Std            116.150154
Q Predictions Max            510.45593
Q Predictions Min            151.87903
V Predictions Mean           284.24774
V Predictions Std            115.18494
V Predictions Max            515.0004
V Predictions Min            161.26428
Log Pis Mean                 -1.9163857
Log Pis Std                  2.3108473
Log Pis Max                  6.192054
Log Pis Min                  -6.736388
Policy mu Mean               -0.0199283
Policy mu Std                0.69060296
Policy mu Max                1.940068
Policy mu Min                -2.324714
Policy log std Mean          -0.33289167
Policy log std Std           0.16259013
Policy log std Max           -0.0580066
Policy log std Min           -1.0386759
Z mean eval                  1.3549879
Z variance eval              0.028707916
total_rewards                [ 881.28183339 2614.60223307 1025.92089835 2494.0007342  2393.80208523
 2610.69360139 2480.51524847  997.25732629 2631.61443176 2614.12455688]
total_rewards_mean           2074.381294901762
total_rewards_std            728.5127030549461
total_rewards_max            2631.614431759717
total_rewards_min            881.2818333911125
Number of train steps total  19000
Number of env steps total    97000
Number of rollouts total     0
Train Time (s)               30.919151170179248
(Previous) Eval Time (s)     28.686214711982757
Sample Time (s)              22.387102692387998
Epoch Time (s)               81.99246857455
Total Train Time (s)         1554.1737942122854
Epoch                        18
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:56:53.113642 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #18 | Epoch Duration: 81.45872473716736
2020-01-11 09:56:53.113833 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #18 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3551931
Z variance train             0.028780153
KL Divergence                15.7446995
KL Loss                      1.5744699
QF Loss                      69.863594
VF Loss                      28.553965
Policy Loss                  -289.918
Q Predictions Mean           285.71964
Q Predictions Std            120.274284
Q Predictions Max            557.13794
Q Predictions Min            160.3371
V Predictions Mean           291.44238
V Predictions Std            119.49723
V Predictions Max            564.1017
V Predictions Min            167.31177
Log Pis Mean                 -1.5050884
Log Pis Std                  2.4119902
Log Pis Max                  7.00255
Log Pis Min                  -6.3680797
Policy mu Mean               0.061992038
Policy mu Std                0.7387179
Policy mu Max                2.1461446
Policy mu Min                -2.1810036
Policy log std Mean          -0.33011582
Policy log std Std           0.16480318
Policy log std Max           -0.024815135
Policy log std Min           -1.0989262
Z mean eval                  1.3994142
Z variance eval              0.022932207
total_rewards                [2775.66955567 2773.10287566 1968.3092764  2920.4988994  2059.98008743
 2727.31423354 1220.15871892 2717.63646318 2735.11275622 2708.96805601]
total_rewards_mean           2460.675092242788
total_rewards_std            512.2717078391642
total_rewards_max            2920.498899395399
total_rewards_min            1220.1587189215456
Number of train steps total  20000
Number of env steps total    102000
Number of rollouts total     0
Train Time (s)               31.250473340041935
(Previous) Eval Time (s)     28.152134232223034
Sample Time (s)              22.786119532305747
Epoch Time (s)               82.18872710457072
Total Train Time (s)         1636.1405198709108
Epoch                        19
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:58:15.084879 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #19 | Epoch Duration: 81.97090816497803
2020-01-11 09:58:15.085152 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #19 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3987851
Z variance train             0.02287886
KL Divergence                16.299252
KL Loss                      1.6299251
QF Loss                      75.50303
VF Loss                      30.106155
Policy Loss                  -308.59656
Q Predictions Mean           306.16443
Q Predictions Std            141.7257
Q Predictions Max            606.37006
Q Predictions Min            158.54907
V Predictions Mean           311.66693
V Predictions Std            140.27504
V Predictions Max            613.7364
V Predictions Min            166.7363
Log Pis Mean                 -1.4629819
Log Pis Std                  2.686466
Log Pis Max                  8.187489
Log Pis Min                  -9.898722
Policy mu Mean               0.068701655
Policy mu Std                0.76305723
Policy mu Max                2.1524034
Policy mu Min                -2.0959938
Policy log std Mean          -0.34218946
Policy log std Std           0.17343818
Policy log std Max           -0.039045908
Policy log std Min           -1.1252127
Z mean eval                  1.4300785
Z variance eval              0.030331725
total_rewards                [2790.06859174 2803.74423108 1176.69020632  725.52845988 2805.31894118
 2841.38621487 2700.32560025 2948.85036194 2755.94171939 2811.86998389]
total_rewards_mean           2435.972431053963
total_rewards_std            751.6271252667807
total_rewards_max            2948.8503619394724
total_rewards_min            725.5284598794142
Number of train steps total  21000
Number of env steps total    107000
Number of rollouts total     0
Train Time (s)               32.64294188283384
(Previous) Eval Time (s)     27.93399286363274
Sample Time (s)              22.26885146368295
Epoch Time (s)               82.84578621014953
Total Train Time (s)         1719.5642258808948
Epoch                        20
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:59:38.506868 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #20 | Epoch Duration: 83.42148447036743
2020-01-11 09:59:38.507107 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #20 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4298657
Z variance train             0.03043807
KL Divergence                15.579622
KL Loss                      1.5579623
QF Loss                      89.93002
VF Loss                      48.363453
Policy Loss                  -362.60373
Q Predictions Mean           358.3661
Q Predictions Std            156.83704
Q Predictions Max            669.961
Q Predictions Min            172.89629
V Predictions Mean           359.66238
V Predictions Std            153.92207
V Predictions Max            644.98694
V Predictions Min            179.02591
Log Pis Mean                 -1.269341
Log Pis Std                  2.7269034
Log Pis Max                  7.0305924
Log Pis Min                  -8.673935
Policy mu Mean               0.07143982
Policy mu Std                0.80241597
Policy mu Max                2.2005517
Policy mu Min                -2.4863932
Policy log std Mean          -0.37559056
Policy log std Std           0.17814064
Policy log std Max           -0.05009433
Policy log std Min           -1.0794735
Z mean eval                  1.4743454
Z variance eval              0.032330833
total_rewards                [2946.161615   3103.62101661 3009.21172601 2941.98683816 2945.60401413
 2873.05083868 3030.74439769 2931.79228848 2940.40434882 3090.60319312]
total_rewards_mean           2981.3180276704197
total_rewards_std            70.73133089782851
total_rewards_max            3103.6210166058113
total_rewards_min            2873.050838680747
Number of train steps total  22000
Number of env steps total    112000
Number of rollouts total     0
Train Time (s)               33.13077902700752
(Previous) Eval Time (s)     28.509332423098385
Sample Time (s)              23.53684837091714
Epoch Time (s)               85.17695982102305
Total Train Time (s)         1805.2259539235383
Epoch                        21
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:01:04.170224 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #21 | Epoch Duration: 85.66290950775146
2020-01-11 10:01:04.170464 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #21 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4731365
Z variance train             0.03265255
KL Divergence                15.984253
KL Loss                      1.5984253
QF Loss                      72.32254
VF Loss                      48.85364
Policy Loss                  -371.4996
Q Predictions Mean           369.98425
Q Predictions Std            175.52034
Q Predictions Max            727.9038
Q Predictions Min            183.38359
V Predictions Mean           376.2398
V Predictions Std            176.53116
V Predictions Max            723.2956
V Predictions Min            189.74956
Log Pis Mean                 -1.2138946
Log Pis Std                  2.9987116
Log Pis Max                  8.656765
Log Pis Min                  -7.5642166
Policy mu Mean               0.085791595
Policy mu Std                0.7878126
Policy mu Max                2.7732449
Policy mu Min                -2.2590654
Policy log std Mean          -0.3838047
Policy log std Std           0.19350566
Policy log std Max           -0.07561052
Policy log std Min           -1.1758821
Z mean eval                  1.5196606
Z variance eval              0.026429653
total_rewards                [2927.40869478 3057.57765496 3147.15026365 3189.55025218 2806.54301728
 2104.50023151 1850.04292095 3017.68996436 3250.69188759 2932.6555651 ]
total_rewards_mean           2828.381045234907
total_rewards_std            447.3340898288127
total_rewards_max            3250.691887589831
total_rewards_min            1850.0429209526621
Number of train steps total  23000
Number of env steps total    117000
Number of rollouts total     0
Train Time (s)               33.67555905133486
(Previous) Eval Time (s)     28.994902901817113
Sample Time (s)              23.040207132697105
Epoch Time (s)               85.71066908584908
Total Train Time (s)         1890.3942754934542
Epoch                        22
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:02:29.340285 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #22 | Epoch Duration: 85.16963386535645
2020-01-11 10:02:29.340606 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #22 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5178933
Z variance train             0.02650084
KL Divergence                16.8987
KL Loss                      1.6898701
QF Loss                      139.18611
VF Loss                      30.888386
Policy Loss                  -445.29916
Q Predictions Mean           437.4017
Q Predictions Std            193.56242
Q Predictions Max            752.95544
Q Predictions Min            190.37123
V Predictions Mean           447.3595
V Predictions Std            194.86687
V Predictions Max            760.57416
V Predictions Min            196.65929
Log Pis Mean                 -0.8625451
Log Pis Std                  2.8413756
Log Pis Max                  6.8236313
Log Pis Min                  -7.6027412
Policy mu Mean               0.055795997
Policy mu Std                0.8558265
Policy mu Max                2.5082383
Policy mu Min                -2.2316067
Policy log std Mean          -0.4000986
Policy log std Std           0.18913463
Policy log std Max           -0.018077075
Policy log std Min           -1.1232285
Z mean eval                  1.5382296
Z variance eval              0.043498676
total_rewards                [3119.71499602 3259.79939536 3195.88615725 3197.57831615 3296.82222448
 3126.2025427  1761.09795542 3170.0976506  3334.47897664 3022.89900382]
total_rewards_mean           3048.457721844851
total_rewards_std            437.72103300965426
total_rewards_max            3334.478976639122
total_rewards_min            1761.0979554156593
Number of train steps total  24000
Number of env steps total    122000
Number of rollouts total     0
Train Time (s)               32.47954228706658
(Previous) Eval Time (s)     28.45322960615158
Sample Time (s)              23.275572823826224
Epoch Time (s)               84.20834471704438
Total Train Time (s)         1974.9011042262428
Epoch                        23
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:03:53.847943 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #23 | Epoch Duration: 84.50712561607361
2020-01-11 10:03:53.848132 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #23 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.538862
Z variance train             0.043508217
KL Divergence                15.297827
KL Loss                      1.5297827
QF Loss                      107.296814
VF Loss                      42.32123
Policy Loss                  -470.53595
Q Predictions Mean           466.27853
Q Predictions Std            209.80774
Q Predictions Max            836.1322
Q Predictions Min            201.60175
V Predictions Mean           470.83176
V Predictions Std            208.58983
V Predictions Max            842.0093
V Predictions Min            204.3878
Log Pis Mean                 -0.60493946
Log Pis Std                  2.928569
Log Pis Max                  7.4657974
Log Pis Min                  -7.850007
Policy mu Mean               0.12478397
Policy mu Std                0.85901165
Policy mu Max                2.36241
Policy mu Min                -2.08647
Policy log std Mean          -0.41054782
Policy log std Std           0.19582534
Policy log std Max           -0.027548462
Policy log std Min           -1.2293991
Z mean eval                  1.6017148
Z variance eval              0.038147435
total_rewards                [3225.26231821 3175.84733054 3231.04830286 3230.20429382 3254.14164909
 3220.41640235 3272.39114732 3230.96672965 3331.72168981 3121.12072564]
total_rewards_mean           3229.3120589298273
total_rewards_std            52.56041509458865
total_rewards_max            3331.7216898097417
total_rewards_min            3121.120725642358
Number of train steps total  25000
Number of env steps total    127000
Number of rollouts total     0
Train Time (s)               33.56406134273857
(Previous) Eval Time (s)     28.75166823901236
Sample Time (s)              22.968437008094043
Epoch Time (s)               85.28416658984497
Total Train Time (s)         2061.003243458923
Epoch                        24
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:05:19.952128 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #24 | Epoch Duration: 86.10382771492004
2020-01-11 10:05:19.952451 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #24 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6009958
Z variance train             0.03813895
KL Divergence                15.8843775
KL Loss                      1.5884378
QF Loss                      101.90107
VF Loss                      34.421326
Policy Loss                  -479.44955
Q Predictions Mean           476.30164
Q Predictions Std            230.4271
Q Predictions Max            878.4982
Q Predictions Min            204.78773
V Predictions Mean           481.58096
V Predictions Std            229.94565
V Predictions Max            870.4342
V Predictions Min            207.95317
Log Pis Mean                 -0.5105235
Log Pis Std                  3.0908217
Log Pis Max                  8.409803
Log Pis Min                  -7.072196
Policy mu Mean               0.06995011
Policy mu Std                0.873976
Policy mu Max                2.299274
Policy mu Min                -2.5432096
Policy log std Mean          -0.41862914
Policy log std Std           0.21255104
Policy log std Max           -0.041984946
Policy log std Min           -1.3219897
Z mean eval                  1.6756713
Z variance eval              0.026377996
total_rewards                [3256.80054167 3378.74960159 2228.34692517 3410.2457355  3551.80671901
 3316.79798904 3515.9079766  3587.12709579 3442.19820997 3461.87945687]
total_rewards_mean           3314.9860251222076
total_rewards_std            374.91180664099716
total_rewards_max            3587.127095788458
total_rewards_min            2228.3469251742454
Number of train steps total  26000
Number of env steps total    132000
Number of rollouts total     0
Train Time (s)               32.52485264604911
(Previous) Eval Time (s)     29.570984139107168
Sample Time (s)              22.677499408833683
Epoch Time (s)               84.77333619398996
Total Train Time (s)         2143.6060259547085
Epoch                        25
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:06:42.555460 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #25 | Epoch Duration: 82.60279369354248
2020-01-11 10:06:42.555639 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #25 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6768005
Z variance train             0.02645328
KL Divergence                17.421984
KL Loss                      1.7421983
QF Loss                      108.68051
VF Loss                      45.463932
Policy Loss                  -525.11115
Q Predictions Mean           518.7407
Q Predictions Std            244.03227
Q Predictions Max            901.0218
Q Predictions Min            211.43459
V Predictions Mean           522.2763
V Predictions Std            243.26256
V Predictions Max            888.92633
V Predictions Min            219.65639
Log Pis Mean                 -0.49691117
Log Pis Std                  3.1934493
Log Pis Max                  7.10886
Log Pis Min                  -8.308132
Policy mu Mean               0.11413791
Policy mu Std                0.9046226
Policy mu Max                2.4826894
Policy mu Min                -2.8455997
Policy log std Mean          -0.42471138
Policy log std Std           0.21628374
Policy log std Max           0.059777007
Policy log std Min           -1.4481275
Z mean eval                  1.7323917
Z variance eval              0.021093944
total_rewards                [ 587.88087872 3643.90123568 3693.46157817 3456.28085848 3391.99685875
 3496.84858481 3429.96975902 3524.44296196 3443.19442827 3301.43947399]
total_rewards_mean           3196.941661784772
total_rewards_std            876.4627763093397
total_rewards_max            3693.461578167049
total_rewards_min            587.8808787182994
Number of train steps total  27000
Number of env steps total    137000
Number of rollouts total     0
Train Time (s)               32.815090311691165
(Previous) Eval Time (s)     27.40008606389165
Sample Time (s)              23.01055916491896
Epoch Time (s)               83.22573554050177
Total Train Time (s)         2229.0768666104414
Epoch                        26
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:08:08.027976 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #26 | Epoch Duration: 85.4721908569336
2020-01-11 10:08:08.028185 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #26 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7304657
Z variance train             0.021068295
KL Divergence                18.692509
KL Loss                      1.8692509
QF Loss                      128.73743
VF Loss                      38.20308
Policy Loss                  -552.62445
Q Predictions Mean           547.7346
Q Predictions Std            259.22888
Q Predictions Max            972.52313
Q Predictions Min            219.99603
V Predictions Mean           553.68915
V Predictions Std            258.22043
V Predictions Max            965.98114
V Predictions Min            224.93562
Log Pis Mean                 -0.41006547
Log Pis Std                  3.11503
Log Pis Max                  9.351208
Log Pis Min                  -6.5640807
Policy mu Mean               0.091566205
Policy mu Std                0.8975853
Policy mu Max                2.4113617
Policy mu Min                -2.46001
Policy log std Mean          -0.43226162
Policy log std Std           0.20771381
Policy log std Max           -0.022678092
Policy log std Min           -1.3974218
Z mean eval                  1.7464516
Z variance eval              0.022124996
total_rewards                [3624.6538856  3410.59195999 3483.08327611 3484.49044225 3530.76160805
 3599.57289556 3565.16843471 3539.12845504 3573.15175312 3535.60510094]
total_rewards_mean           3534.620781138131
total_rewards_std            59.43990831909798
total_rewards_max            3624.653885598101
total_rewards_min            3410.5919599897793
Number of train steps total  28000
Number of env steps total    142000
Number of rollouts total     0
Train Time (s)               33.833372300025076
(Previous) Eval Time (s)     29.646165372803807
Sample Time (s)              23.93695364613086
Epoch Time (s)               87.41649131895974
Total Train Time (s)         2316.230979983695
Epoch                        27
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:09:35.183630 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #27 | Epoch Duration: 87.1552906036377
2020-01-11 10:09:35.183891 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #27 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7488823
Z variance train             0.022139642
KL Divergence                18.781567
KL Loss                      1.8781567
QF Loss                      147.2796
VF Loss                      36.620266
Policy Loss                  -591.0202
Q Predictions Mean           587.872
Q Predictions Std            272.9128
Q Predictions Max            980.7149
Q Predictions Min            229.08015
V Predictions Mean           587.86035
V Predictions Std            271.4249
V Predictions Max            979.1401
V Predictions Min            227.57732
Log Pis Mean                 -0.030872919
Log Pis Std                  3.5383313
Log Pis Max                  10.63592
Log Pis Min                  -9.051558
Policy mu Mean               0.071513735
Policy mu Std                0.96545476
Policy mu Max                2.4331594
Policy mu Min                -2.5206296
Policy log std Mean          -0.44340536
Policy log std Std           0.21780662
Policy log std Max           0.025141433
Policy log std Min           -1.4918679
Z mean eval                  1.8110771
Z variance eval              0.015109161
total_rewards                [3518.24394529 3538.41329594 3494.12662046 3418.02692999 3445.42847491
 3422.99634584 3492.53637054 3548.58153737 3461.06727053 3545.03311157]
total_rewards_mean           3488.445390241738
total_rewards_std            47.004933546974804
total_rewards_max            3548.5815373743685
total_rewards_min            3418.026929987102
Number of train steps total  29000
Number of env steps total    147000
Number of rollouts total     0
Train Time (s)               32.71275597810745
(Previous) Eval Time (s)     29.38447932386771
Sample Time (s)              23.38550410233438
Epoch Time (s)               85.48273940430954
Total Train Time (s)         2401.1964098997414
Epoch                        28
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:11:00.152027 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #28 | Epoch Duration: 84.96794080734253
2020-01-11 10:11:00.152350 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #28 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8121979
Z variance train             0.015128637
KL Divergence                20.748886
KL Loss                      2.0748887
QF Loss                      146.43983
VF Loss                      109.70557
Policy Loss                  -642.3956
Q Predictions Mean           632.53784
Q Predictions Std            290.73505
Q Predictions Max            1076.512
Q Predictions Min            222.21414
V Predictions Mean           633.91174
V Predictions Std            286.59183
V Predictions Max            1065.6129
V Predictions Min            223.87663
Log Pis Mean                 -0.10686302
Log Pis Std                  3.2410183
Log Pis Max                  8.875432
Log Pis Min                  -7.308128
Policy mu Mean               0.04848659
Policy mu Std                0.9127369
Policy mu Max                2.3790493
Policy mu Min                -2.5961432
Policy log std Mean          -0.44376835
Policy log std Std           0.21413638
Policy log std Max           0.07748029
Policy log std Min           -1.3711109
Z mean eval                  1.8401861
Z variance eval              0.01794907
total_rewards                [3623.96936929 3594.50135236 3765.01054227 3725.2656945  3686.68142535
 3463.59744698 3617.79519233 1679.96880924 3572.86589905 3651.41115023]
total_rewards_mean           3438.106688159192
total_rewards_std            591.4190924377835
total_rewards_max            3765.0105422683528
total_rewards_min            1679.9688092438644
Number of train steps total  30000
Number of env steps total    152000
Number of rollouts total     0
Train Time (s)               33.78640498733148
(Previous) Eval Time (s)     28.86929231416434
Sample Time (s)              23.54719650838524
Epoch Time (s)               86.20289380988106
Total Train Time (s)         2487.9705864698626
Epoch                        29
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:12:26.926712 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #29 | Epoch Duration: 86.77418065071106
2020-01-11 10:12:26.926928 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #29 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8398006
Z variance train             0.017942
KL Divergence                20.81009
KL Loss                      2.081009
QF Loss                      120.728745
VF Loss                      41.64657
Policy Loss                  -647.42896
Q Predictions Mean           641.0531
Q Predictions Std            296.68732
Q Predictions Max            1067.5123
Q Predictions Min            231.43747
V Predictions Mean           645.25574
V Predictions Std            293.94064
V Predictions Max            1062.1227
V Predictions Min            241.50479
Log Pis Mean                 -0.12664983
Log Pis Std                  3.4233148
Log Pis Max                  10.379229
Log Pis Min                  -7.02652
Policy mu Mean               0.089868404
Policy mu Std                0.9293665
Policy mu Max                2.4633155
Policy mu Min                -2.6430335
Policy log std Mean          -0.44893527
Policy log std Std           0.21689178
Policy log std Max           -0.015713274
Policy log std Min           -1.3272274
Z mean eval                  1.8777685
Z variance eval              0.017170548
total_rewards                [3708.2668536  3517.87909508 3636.16037642 3679.19766056 3828.54193038
 3721.84528943 3723.65480674 3688.70256514 3800.28549023 3772.54141498]
total_rewards_mean           3707.707548255699
total_rewards_std            83.76001410774504
total_rewards_max            3828.5419303791045
total_rewards_min            3517.879095076308
Number of train steps total  31000
Number of env steps total    157000
Number of rollouts total     0
Train Time (s)               31.22840493079275
(Previous) Eval Time (s)     29.440172566100955
Sample Time (s)              23.16971821244806
Epoch Time (s)               83.83829570934176
Total Train Time (s)         2570.2249971553683
Epoch                        30
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:13:49.182478 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #30 | Epoch Duration: 82.25540161132812
2020-01-11 10:13:49.182674 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #30 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8793666
Z variance train             0.017193278
KL Divergence                21.576355
KL Loss                      2.1576355
QF Loss                      137.11826
VF Loss                      33.997726
Policy Loss                  -691.6441
Q Predictions Mean           690.1566
Q Predictions Std            331.315
Q Predictions Max            1120.1852
Q Predictions Min            248.82622
V Predictions Mean           690.1187
V Predictions Std            327.3913
V Predictions Max            1117.6963
V Predictions Min            256.10886
Log Pis Mean                 -0.73449486
Log Pis Std                  3.063672
Log Pis Max                  9.348474
Log Pis Min                  -6.1808577
Policy mu Mean               0.097212255
Policy mu Std                0.8502805
Policy mu Max                2.4793155
Policy mu Min                -2.2739499
Policy log std Mean          -0.43777624
Policy log std Std           0.22781686
Policy log std Max           -0.0017333776
Policy log std Min           -1.5364562
Z mean eval                  1.9071783
Z variance eval              0.01624388
total_rewards                [3665.29945252 3886.91349322 3704.72907322 3729.9791925  3744.35345209
 3893.19202414 3760.491664   3852.91473361 3751.27407058 3839.98437297]
total_rewards_mean           3782.9131528848898
total_rewards_std            75.41431422906484
total_rewards_max            3893.1920241365174
total_rewards_min            3665.2994525151857
Number of train steps total  32000
Number of env steps total    162000
Number of rollouts total     0
Train Time (s)               31.35969841014594
(Previous) Eval Time (s)     27.856947750784457
Sample Time (s)              22.845608113799244
Epoch Time (s)               82.06225427472964
Total Train Time (s)         2651.475520135835
Epoch                        31
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:15:10.434070 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #31 | Epoch Duration: 81.25126266479492
2020-01-11 10:15:10.434244 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #31 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.90476
Z variance train             0.016243717
KL Divergence                22.027493
KL Loss                      2.2027493
QF Loss                      328.57697
VF Loss                      65.946884
Policy Loss                  -727.00183
Q Predictions Mean           718.5487
Q Predictions Std            310.13074
Q Predictions Max            1116.3743
Q Predictions Min            236.84848
V Predictions Mean           730.88116
V Predictions Std            310.68066
V Predictions Max            1129.0526
V Predictions Min            245.04022
Log Pis Mean                 0.14851418
Log Pis Std                  3.4882627
Log Pis Max                  11.905404
Log Pis Min                  -9.163441
Policy mu Mean               0.071284175
Policy mu Std                0.9448283
Policy mu Max                2.659757
Policy mu Min                -2.6055253
Policy log std Mean          -0.48339257
Policy log std Std           0.24482764
Policy log std Max           -0.04086697
Policy log std Min           -1.7101657
Z mean eval                  1.9403751
Z variance eval              0.01496958
total_rewards                [3974.91709047 4007.68219731 3787.87073162 3766.40245606 3983.84932462
 3737.69876501 3808.59270405 3926.29901713 3962.1137315  4049.40519187]
total_rewards_mean           3900.483120964965
total_rewards_std            107.80831496267845
total_rewards_max            4049.4051918726245
total_rewards_min            3737.6987650090723
Number of train steps total  33000
Number of env steps total    167000
Number of rollouts total     0
Train Time (s)               31.354226001072675
(Previous) Eval Time (s)     27.045585389714688
Sample Time (s)              22.745321285910904
Epoch Time (s)               81.14513267669827
Total Train Time (s)         2733.8255157768726
Epoch                        32
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:16:32.785548 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #32 | Epoch Duration: 82.3511643409729
2020-01-11 10:16:32.785739 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #32 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9409113
Z variance train             0.014993122
KL Divergence                22.889397
KL Loss                      2.2889397
QF Loss                      108.40101
VF Loss                      40.850517
Policy Loss                  -763.2809
Q Predictions Mean           758.7499
Q Predictions Std            335.92856
Q Predictions Max            1197.0276
Q Predictions Min            263.5823
V Predictions Mean           764.1343
V Predictions Std            336.28552
V Predictions Max            1200.9287
V Predictions Min            265.62228
Log Pis Mean                 0.21919185
Log Pis Std                  3.4577909
Log Pis Max                  15.36074
Log Pis Min                  -8.152205
Policy mu Mean               0.1522629
Policy mu Std                0.94765407
Policy mu Max                2.9142678
Policy mu Min                -2.411192
Policy log std Mean          -0.47828832
Policy log std Std           0.24390684
Policy log std Max           -0.050852835
Policy log std Min           -1.6868677
Z mean eval                  1.9485435
Z variance eval              0.021703295
total_rewards                [3752.04013712 3967.17709752 3834.03479214 3832.98832179 3798.80596356
 3847.5608693  3967.71351442 3958.24899573 3898.44745856 3614.9299917 ]
total_rewards_mean           3847.1947141840456
total_rewards_std            104.68923345356362
total_rewards_max            3967.713514417897
total_rewards_min            3614.929991703674
Number of train steps total  34000
Number of env steps total    172000
Number of rollouts total     0
Train Time (s)               31.177020700648427
(Previous) Eval Time (s)     28.251252529211342
Sample Time (s)              22.593506139703095
Epoch Time (s)               82.02177936956286
Total Train Time (s)         2815.370868950151
Epoch                        33
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:17:54.332244 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #33 | Epoch Duration: 81.54636526107788
2020-01-11 10:17:54.332440 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #33 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9478829
Z variance train             0.0216609
KL Divergence                21.522484
KL Loss                      2.1522484
QF Loss                      123.83351
VF Loss                      82.66338
Policy Loss                  -760.066
Q Predictions Mean           757.7439
Q Predictions Std            359.1161
Q Predictions Max            1251.12
Q Predictions Min            253.76935
V Predictions Mean           766.40735
V Predictions Std            356.84497
V Predictions Max            1260.9072
V Predictions Min            269.12213
Log Pis Mean                 0.007882997
Log Pis Std                  3.486558
Log Pis Max                  11.322649
Log Pis Min                  -9.627664
Policy mu Mean               0.07583495
Policy mu Std                0.9324827
Policy mu Max                2.4416218
Policy mu Min                -2.3711135
Policy log std Mean          -0.48182616
Policy log std Std           0.24553402
Policy log std Max           -0.044685513
Policy log std Min           -1.7263768
Z mean eval                  1.9752792
Z variance eval              0.018091237
total_rewards                [4111.87340473 4057.3067137  3997.31360685 3869.5127553  3945.82298633
 4054.71457358 4099.42160353 4160.31674355 4010.48175588 4027.59346127]
total_rewards_mean           4033.4357604706347
total_rewards_std            80.02535115338911
total_rewards_max            4160.316743554317
total_rewards_min            3869.512755298018
Number of train steps total  35000
Number of env steps total    177000
Number of rollouts total     0
Train Time (s)               31.32300064060837
(Previous) Eval Time (s)     27.77557635633275
Sample Time (s)              20.873764706775546
Epoch Time (s)               79.97234170371667
Total Train Time (s)         2895.498157621827
Epoch                        34
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:19:14.469270 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #34 | Epoch Duration: 80.13666796684265
2020-01-11 10:19:14.469806 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #34 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9738508
Z variance train             0.018072994
KL Divergence                22.510391
KL Loss                      2.2510393
QF Loss                      180.54262
VF Loss                      78.8511
Policy Loss                  -833.8063
Q Predictions Mean           832.9532
Q Predictions Std            368.88608
Q Predictions Max            1279.563
Q Predictions Min            264.76996
V Predictions Mean           833.90735
V Predictions Std            368.4531
V Predictions Max            1279.9772
V Predictions Min            265.98312
Log Pis Mean                 0.47465172
Log Pis Std                  3.5525868
Log Pis Max                  10.971694
Log Pis Min                  -6.4417667
Policy mu Mean               0.021831928
Policy mu Std                0.9690475
Policy mu Max                2.7301314
Policy mu Min                -2.6212683
Policy log std Mean          -0.4811581
Policy log std Std           0.23689565
Policy log std Max           -0.038725376
Policy log std Min           -1.6664307
Z mean eval                  1.9792624
Z variance eval              0.019367019
total_rewards                [4036.96242894 4002.57641686 4105.59422135 4112.86660275 4058.9972871
 4213.21863698 4148.80280842 3971.43099708 3976.5590829  3973.71164173]
total_rewards_mean           4060.0720124106447
total_rewards_std            78.94129911683392
total_rewards_max            4213.21863698148
total_rewards_min            3971.4309970781296
Number of train steps total  36000
Number of env steps total    182000
Number of rollouts total     0
Train Time (s)               30.748200244270265
(Previous) Eval Time (s)     27.93953431583941
Sample Time (s)              22.10673202201724
Epoch Time (s)               80.79446658212692
Total Train Time (s)         2976.2918414375745
Epoch                        35
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:20:35.256454 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #35 | Epoch Duration: 80.7862377166748
2020-01-11 10:20:35.256639 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #35 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9802281
Z variance train             0.019334689
KL Divergence                22.69873
KL Loss                      2.2698731
QF Loss                      176.94846
VF Loss                      64.42146
Policy Loss                  -848.0074
Q Predictions Mean           841.088
Q Predictions Std            382.28098
Q Predictions Max            1296.5256
Q Predictions Min            272.61603
V Predictions Mean           846.66406
V Predictions Std            380.4301
V Predictions Max            1298.0669
V Predictions Min            276.2732
Log Pis Mean                 -0.007447321
Log Pis Std                  3.3079772
Log Pis Max                  10.378077
Log Pis Min                  -6.1354537
Policy mu Mean               0.017157031
Policy mu Std                0.933511
Policy mu Max                2.4217062
Policy mu Min                -2.4967015
Policy log std Mean          -0.48188722
Policy log std Std           0.24573044
Policy log std Max           0.0011275262
Policy log std Min           -1.5996387
Z mean eval                  2.0062916
Z variance eval              0.017677048
total_rewards                [4024.29235209 3956.70523291 4106.39947703 4175.88926679 4216.64980534
 4118.75040051 4196.24436349 4205.66408173 3981.37906082 4080.08309547]
total_rewards_mean           4106.205713618532
total_rewards_std            89.74090711987198
total_rewards_max            4216.649805341771
total_rewards_min            3956.705232911302
Number of train steps total  37000
Number of env steps total    187000
Number of rollouts total     0
Train Time (s)               31.259476360864937
(Previous) Eval Time (s)     27.931023311801255
Sample Time (s)              22.651144224684685
Epoch Time (s)               81.84164389735088
Total Train Time (s)         3057.277790784836
Epoch                        36
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:21:56.243144 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #36 | Epoch Duration: 80.98637223243713
2020-01-11 10:21:56.243361 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #36 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0046673
Z variance train             0.017643198
KL Divergence                23.185955
KL Loss                      2.3185956
QF Loss                      183.84326
VF Loss                      65.10809
Policy Loss                  -851.7425
Q Predictions Mean           845.90216
Q Predictions Std            389.0508
Q Predictions Max            1335.7449
Q Predictions Min            263.22018
V Predictions Mean           855.404
V Predictions Std            389.66666
V Predictions Max            1344.719
V Predictions Min            270.31503
Log Pis Mean                 -0.095661126
Log Pis Std                  3.4616923
Log Pis Max                  12.76536
Log Pis Min                  -6.856677
Policy mu Mean               0.07142859
Policy mu Std                0.9423389
Policy mu Max                2.501352
Policy mu Min                -2.30604
Policy log std Mean          -0.46090773
Policy log std Std           0.23270959
Policy log std Max           0.035345957
Policy log std Min           -1.3933423
Z mean eval                  2.013846
Z variance eval              0.017405102
total_rewards                [4177.7819984  4129.83696847 4146.91397364 4298.5115515  4215.03507575
 4103.30409745 4161.38258734 4302.24543809 4072.95941915 4078.14239225]
total_rewards_mean           4168.61135020351
total_rewards_std            77.84397227473646
total_rewards_max            4302.245438089036
total_rewards_min            4072.959419147781
Number of train steps total  38000
Number of env steps total    192000
Number of rollouts total     0
Train Time (s)               31.85145627707243
(Previous) Eval Time (s)     27.075440646149218
Sample Time (s)              21.500817864201963
Epoch Time (s)               80.42771478742361
Total Train Time (s)         3138.736484156456
Epoch                        37
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:23:17.703430 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #37 | Epoch Duration: 81.45994806289673
2020-01-11 10:23:17.703615 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #37 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0126405
Z variance train             0.017392967
KL Divergence                23.351387
KL Loss                      2.3351388
QF Loss                      231.42125
VF Loss                      52.57604
Policy Loss                  -905.81976
Q Predictions Mean           900.40784
Q Predictions Std            407.25793
Q Predictions Max            1402.3134
Q Predictions Min            272.41724
V Predictions Mean           908.5509
V Predictions Std            405.0556
V Predictions Max            1423.9669
V Predictions Min            280.26617
Log Pis Mean                 0.46162832
Log Pis Std                  3.6594849
Log Pis Max                  11.790085
Log Pis Min                  -6.7382255
Policy mu Mean               0.04119908
Policy mu Std                0.9802458
Policy mu Max                2.478971
Policy mu Min                -2.3752806
Policy log std Mean          -0.4901866
Policy log std Std           0.252759
Policy log std Max           -0.035702378
Policy log std Min           -1.8814162
Z mean eval                  2.023473
Z variance eval              0.019995693
total_rewards                [4188.65671144 4415.9649545  4407.7754186  4441.66458094 4320.01388196
 4424.10194262 4465.0843004  4415.07479688 4471.89169425 4389.57801331]
total_rewards_mean           4393.980629489235
total_rewards_std            79.41905533543586
total_rewards_max            4471.891694251296
total_rewards_min            4188.656711437787
Number of train steps total  39000
Number of env steps total    197000
Number of rollouts total     0
Train Time (s)               31.029344724025577
(Previous) Eval Time (s)     28.107383267953992
Sample Time (s)              22.79334571538493
Epoch Time (s)               81.9300737073645
Total Train Time (s)         3221.105213801842
Epoch                        38
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:24:40.074137 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #38 | Epoch Duration: 82.37037253379822
2020-01-11 10:24:40.074358 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #38 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0236516
Z variance train             0.01996401
KL Divergence                23.072716
KL Loss                      2.3072717
QF Loss                      167.72864
VF Loss                      102.06381
Policy Loss                  -937.0148
Q Predictions Mean           936.602
Q Predictions Std            407.29858
Q Predictions Max            1395.5293
Q Predictions Min            266.954
V Predictions Mean           938.0705
V Predictions Std            403.44547
V Predictions Max            1382.4348
V Predictions Min            275.17932
Log Pis Mean                 0.7910099
Log Pis Std                  3.6843047
Log Pis Max                  10.510146
Log Pis Min                  -7.5885653
Policy mu Mean               0.0563129
Policy mu Std                1.0156212
Policy mu Max                2.6234434
Policy mu Min                -2.5435517
Policy log std Mean          -0.4961364
Policy log std Std           0.26275483
Policy log std Max           -0.013640389
Policy log std Min           -1.6974229
Z mean eval                  2.0429032
Z variance eval              0.013954902
total_rewards                [4351.4290198  4361.12377422 4466.7724219  4398.65726286 4399.84422075
 4343.84568833 4393.32183941 4385.74107443 4284.24060191 4262.07009303]
total_rewards_mean           4364.704599664143
total_rewards_std            56.30217644457159
total_rewards_max            4466.772421895949
total_rewards_min            4262.070093033316
Number of train steps total  40000
Number of env steps total    202000
Number of rollouts total     0
Train Time (s)               31.81956434296444
(Previous) Eval Time (s)     28.547343663405627
Sample Time (s)              21.99971121083945
Epoch Time (s)               82.36661921720952
Total Train Time (s)         3303.930345137138
Epoch                        39
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:26:02.900526 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #39 | Epoch Duration: 82.82601261138916
2020-01-11 10:26:02.900719 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #39 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0420988
Z variance train             0.013915581
KL Divergence                24.488659
KL Loss                      2.448866
QF Loss                      373.81067
VF Loss                      75.65582
Policy Loss                  -946.5494
Q Predictions Mean           939.4425
Q Predictions Std            425.78574
Q Predictions Max            1462.3452
Q Predictions Min            269.34604
V Predictions Mean           943.54083
V Predictions Std            422.20294
V Predictions Max            1470.1844
V Predictions Min            280.62677
Log Pis Mean                 0.3869719
Log Pis Std                  3.5401373
Log Pis Max                  10.419273
Log Pis Min                  -6.801856
Policy mu Mean               0.00092670694
Policy mu Std                0.9758509
Policy mu Max                2.5289237
Policy mu Min                -2.2757843
Policy log std Mean          -0.48688698
Policy log std Std           0.25407597
Policy log std Max           -0.045001
Policy log std Min           -1.5372269
Z mean eval                  2.035019
Z variance eval              0.015154158
total_rewards                [4304.1627912  4550.19694116 4425.91323538 4535.25125089 4462.165037
 4498.31488309 4295.70876727 4462.22241687 4480.61985208 4693.62930493]
total_rewards_mean           4470.818447985714
total_rewards_std            110.25066454161379
total_rewards_max            4693.6293049274755
total_rewards_min            4295.708767268059
Number of train steps total  41000
Number of env steps total    207000
Number of rollouts total     0
Train Time (s)               31.738999634981155
(Previous) Eval Time (s)     29.00643179891631
Sample Time (s)              22.23379666497931
Epoch Time (s)               82.97922809887677
Total Train Time (s)         3386.074085570406
Epoch                        40
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:27:25.045377 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #40 | Epoch Duration: 82.14451503753662
2020-01-11 10:27:25.045565 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #40 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0355237
Z variance train             0.01523519
KL Divergence                23.670883
KL Loss                      2.3670883
QF Loss                      223.66342
VF Loss                      65.56641
Policy Loss                  -984.54926
Q Predictions Mean           985.2811
Q Predictions Std            418.87955
Q Predictions Max            1511.8523
Q Predictions Min            261.6789
V Predictions Mean           988.3817
V Predictions Std            417.05368
V Predictions Max            1503.659
V Predictions Min            269.33276
Log Pis Mean                 0.4930182
Log Pis Std                  3.640217
Log Pis Max                  9.048473
Log Pis Min                  -8.764563
Policy mu Mean               0.05126953
Policy mu Std                1.0047516
Policy mu Max                2.7711482
Policy mu Min                -2.428476
Policy log std Mean          -0.50416213
Policy log std Std           0.26825914
Policy log std Max           -0.043543786
Policy log std Min           -1.8605369
Z mean eval                  1.9935888
Z variance eval              0.07588675
total_rewards                [4175.86776715 4380.40621634 4405.07400553 4419.47539358 4222.00287182
 4378.48111776 4373.57546051 4323.2441621  4434.78141015 4283.95297706]
total_rewards_mean           4339.686138199341
total_rewards_std            82.49788136243853
total_rewards_max            4434.781410153428
total_rewards_min            4175.867767150898
Number of train steps total  42000
Number of env steps total    212000
Number of rollouts total     0
Train Time (s)               31.121267006266862
(Previous) Eval Time (s)     28.171402517240494
Sample Time (s)              23.047017930075526
Epoch Time (s)               82.33968745358288
Total Train Time (s)         3469.083707562182
Epoch                        41
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:28:48.056874 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #41 | Epoch Duration: 83.01115822792053
2020-01-11 10:28:48.057090 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #41 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.993887
Z variance train             0.07526262
KL Divergence                21.435652
KL Loss                      2.1435652
QF Loss                      184.67133
VF Loss                      74.748024
Policy Loss                  -964.0892
Q Predictions Mean           964.234
Q Predictions Std            432.24625
Q Predictions Max            1548.9978
Q Predictions Min            265.36325
V Predictions Mean           966.8187
V Predictions Std            432.0748
V Predictions Max            1554.5219
V Predictions Min            269.3691
Log Pis Mean                 0.17747094
Log Pis Std                  3.4141943
Log Pis Max                  10.897291
Log Pis Min                  -9.020287
Policy mu Mean               -0.010112348
Policy mu Std                0.9801398
Policy mu Max                2.3578756
Policy mu Min                -2.3249097
Policy log std Mean          -0.4769791
Policy log std Std           0.2529658
Policy log std Max           -0.055658385
Policy log std Min           -1.5748355
Z mean eval                  2.0230165
Z variance eval              0.044674855
total_rewards                [4648.63261138 4629.41398654 4589.25944983 4656.92718448 4579.48914545
 4597.71774049 4458.23036563 4550.23315279 4641.18291924 4662.85291203]
total_rewards_mean           4601.393946786975
total_rewards_std            59.34200867090498
total_rewards_max            4662.852912029577
total_rewards_min            4458.230365626417
Number of train steps total  43000
Number of env steps total    217000
Number of rollouts total     0
Train Time (s)               31.421416639350355
(Previous) Eval Time (s)     28.84252368938178
Sample Time (s)              22.59837858332321
Epoch Time (s)               82.86231891205534
Total Train Time (s)         3550.5812860717997
Epoch                        42
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:30:09.557807 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #42 | Epoch Duration: 81.50052809715271
2020-01-11 10:30:09.558100 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #42 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0205379
Z variance train             0.044591166
KL Divergence                22.185968
KL Loss                      2.218597
QF Loss                      256.0641
VF Loss                      73.85019
Policy Loss                  -1057.3815
Q Predictions Mean           1051.379
Q Predictions Std            460.973
Q Predictions Max            1598.9381
Q Predictions Min            279.13824
V Predictions Mean           1057.5535
V Predictions Std            459.51157
V Predictions Max            1601.4326
V Predictions Min            286.20358
Log Pis Mean                 0.37084842
Log Pis Std                  3.6416245
Log Pis Max                  10.496767
Log Pis Min                  -7.481943
Policy mu Mean               0.06352362
Policy mu Std                1.0138581
Policy mu Max                3.1743298
Policy mu Min                -2.5674188
Policy log std Mean          -0.49380842
Policy log std Std           0.26857635
Policy log std Max           0.00443615
Policy log std Min           -1.6397294
Z mean eval                  2.0388005
Z variance eval              0.029388988
total_rewards                [4579.40108003 4635.32868659 4589.82300123 4473.87223172 4596.62214183
 4528.63401111 4431.42446427 4535.27879355 4568.64873041 4429.1730798 ]
total_rewards_mean           4536.820622056781
total_rewards_std            67.560104896262
total_rewards_max            4635.3286865919445
total_rewards_min            4429.173079804523
Number of train steps total  44000
Number of env steps total    222000
Number of rollouts total     0
Train Time (s)               31.60208289604634
(Previous) Eval Time (s)     27.480404898058623
Sample Time (s)              22.25041037797928
Epoch Time (s)               81.33289817208424
Total Train Time (s)         3631.9321217220277
Epoch                        43
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:31:30.909015 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #43 | Epoch Duration: 81.35068655014038
2020-01-11 10:31:30.909247 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #43 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0401275
Z variance train             0.029361105
KL Divergence                22.984314
KL Loss                      2.2984314
QF Loss                      259.0703
VF Loss                      72.77893
Policy Loss                  -1103.6119
Q Predictions Mean           1096.6392
Q Predictions Std            444.48672
Q Predictions Max            1631.3965
Q Predictions Min            266.16794
V Predictions Mean           1099.6592
V Predictions Std            440.5605
V Predictions Max            1614.9246
V Predictions Min            271.0834
Log Pis Mean                 1.2116547
Log Pis Std                  3.8815448
Log Pis Max                  13.026007
Log Pis Min                  -5.7804437
Policy mu Mean               0.0572494
Policy mu Std                1.074131
Policy mu Max                2.4792116
Policy mu Min                -2.8657053
Policy log std Mean          -0.5115985
Policy log std Std           0.28123385
Policy log std Max           -0.027022704
Policy log std Min           -1.8635153
Z mean eval                  2.0653927
Z variance eval              0.021079166
total_rewards                [4760.21583577 4725.79256396 4849.97742806 4667.96369635 4807.28050003
 4624.01954468 5019.55272899 4571.47103889 4731.49151269 4720.36689579]
total_rewards_mean           4747.813174519113
total_rewards_std            119.27785287972603
total_rewards_max            5019.552728986684
total_rewards_min            4571.471038889534
Number of train steps total  45000
Number of env steps total    227000
Number of rollouts total     0
Train Time (s)               31.140321366954595
(Previous) Eval Time (s)     27.49784696381539
Sample Time (s)              21.060775371734053
Epoch Time (s)               79.69894370250404
Total Train Time (s)         3712.3602463994175
Epoch                        44
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:32:51.338330 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #44 | Epoch Duration: 80.42892003059387
2020-01-11 10:32:51.338515 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #44 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0657783
Z variance train             0.021055453
KL Divergence                23.984676
KL Loss                      2.3984678
QF Loss                      201.30704
VF Loss                      77.72123
Policy Loss                  -1113.5012
Q Predictions Mean           1108.2661
Q Predictions Std            435.5848
Q Predictions Max            1625.7754
Q Predictions Min            267.67224
V Predictions Mean           1108.9104
V Predictions Std            430.73566
V Predictions Max            1617.376
V Predictions Min            269.94724
Log Pis Mean                 1.0020742
Log Pis Std                  3.6742427
Log Pis Max                  10.624571
Log Pis Min                  -6.990963
Policy mu Mean               0.08176132
Policy mu Std                1.0386329
Policy mu Max                2.6924875
Policy mu Min                -2.533888
Policy log std Mean          -0.5091723
Policy log std Std           0.26561403
Policy log std Max           0.032076538
Policy log std Min           -1.6706741
Z mean eval                  2.0710201
Z variance eval              0.017879738
total_rewards                [4587.26497838 4655.26861478 4628.47715599 4686.38639619 4897.09225552
 4829.34076359 4715.25055015 4716.67935509 4651.18232008 4708.05454579]
total_rewards_mean           4707.499693556814
total_rewards_std            88.30724057200281
total_rewards_max            4897.092255523622
total_rewards_min            4587.264978376738
Number of train steps total  46000
Number of env steps total    232000
Number of rollouts total     0
Train Time (s)               31.355830643791705
(Previous) Eval Time (s)     28.22748169116676
Sample Time (s)              22.204573074821383
Epoch Time (s)               81.78788540977985
Total Train Time (s)         3793.924988921266
Epoch                        45
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:34:12.905971 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #45 | Epoch Duration: 81.56729412078857
2020-01-11 10:34:12.906260 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #45 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0703704
Z variance train             0.017906923
KL Divergence                24.410831
KL Loss                      2.4410832
QF Loss                      204.93094
VF Loss                      112.79609
Policy Loss                  -1124.469
Q Predictions Mean           1119.8071
Q Predictions Std            476.6844
Q Predictions Max            1672.9882
Q Predictions Min            279.53442
V Predictions Mean           1122.8269
V Predictions Std            474.74945
V Predictions Max            1673.1393
V Predictions Min            278.446
Log Pis Mean                 1.172645
Log Pis Std                  3.875973
Log Pis Max                  13.403608
Log Pis Min                  -7.0309086
Policy mu Mean               0.085123055
Policy mu Std                1.0561439
Policy mu Max                3.0788853
Policy mu Min                -2.8191946
Policy log std Mean          -0.5110636
Policy log std Std           0.27512676
Policy log std Max           -0.042955175
Policy log std Min           -1.7486303
Z mean eval                  2.072871
Z variance eval              0.015657576
total_rewards                [4949.59896733 4762.52721436 4905.89596348 4750.77963264 5009.43601909
 4931.87414516 4819.3113862  4821.42626426 4761.67849827 5010.34658505]
total_rewards_mean           4872.287467584832
total_rewards_std            96.41906173944491
total_rewards_max            5010.346585053749
total_rewards_min            4750.779632639114
Number of train steps total  47000
Number of env steps total    237000
Number of rollouts total     0
Train Time (s)               31.542483313009143
(Previous) Eval Time (s)     28.006522127892822
Sample Time (s)              21.531737339217216
Epoch Time (s)               81.08074278011918
Total Train Time (s)         3874.5143678183667
Epoch                        46
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:35:33.496007 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #46 | Epoch Duration: 80.58957552909851
2020-01-11 10:35:33.496191 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #46 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0763588
Z variance train             0.015775451
KL Divergence                25.042408
KL Loss                      2.5042408
QF Loss                      207.28114
VF Loss                      203.66766
Policy Loss                  -1191.5206
Q Predictions Mean           1188.9609
Q Predictions Std            474.15118
Q Predictions Max            1684.2894
Q Predictions Min            260.7245
V Predictions Mean           1180.4968
V Predictions Std            466.57254
V Predictions Max            1661.7896
V Predictions Min            269.21957
Log Pis Mean                 0.60410345
Log Pis Std                  3.5007372
Log Pis Max                  11.96684
Log Pis Min                  -6.654749
Policy mu Mean               0.023665795
Policy mu Std                1.0116143
Policy mu Max                2.7916465
Policy mu Min                -2.7262201
Policy log std Mean          -0.4992796
Policy log std Std           0.27105367
Policy log std Max           -0.03634625
Policy log std Min           -1.837738
Z mean eval                  2.0676816
Z variance eval              0.015228677
total_rewards                [4891.72504992 4327.12215365 4879.68161515 4979.28072382 4838.77355613
 4799.34870944 4753.52267441 4961.5201512  4823.02113221 4976.08188804]
total_rewards_mean           4823.0077653978615
total_rewards_std            180.69632677247742
total_rewards_max            4979.2807238191035
total_rewards_min            4327.122153648742
Number of train steps total  48000
Number of env steps total    242000
Number of rollouts total     0
Train Time (s)               31.24342101207003
(Previous) Eval Time (s)     27.51504789479077
Sample Time (s)              22.646737348288298
Epoch Time (s)               81.4052062551491
Total Train Time (s)         3956.264512630645
Epoch                        47
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:36:55.247734 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #47 | Epoch Duration: 81.75140523910522
2020-01-11 10:36:55.247916 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #47 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0650043
Z variance train             0.015227435
KL Divergence                25.131706
KL Loss                      2.5131707
QF Loss                      201.988
VF Loss                      112.093956
Policy Loss                  -1188.6703
Q Predictions Mean           1186.6465
Q Predictions Std            462.72107
Q Predictions Max            1783.1506
Q Predictions Min            259.26382
V Predictions Mean           1193.3657
V Predictions Std            460.66037
V Predictions Max            1764.6825
V Predictions Min            266.56958
Log Pis Mean                 1.1793385
Log Pis Std                  3.8176885
Log Pis Max                  10.959795
Log Pis Min                  -7.4058495
Policy mu Mean               0.06381178
Policy mu Std                1.0671451
Policy mu Max                2.6909554
Policy mu Min                -2.6402152
Policy log std Mean          -0.5204261
Policy log std Std           0.28479588
Policy log std Max           0.017204255
Policy log std Min           -1.9199024
Z mean eval                  2.075172
Z variance eval              0.013680605
total_rewards                [4893.11479347 5010.34609667 4911.61093698 4892.73422185 4996.41282983
 4944.84327372 4867.14475194 4871.53465599 4943.90295016 4992.48467265]
total_rewards_mean           4932.412918325712
total_rewards_std            50.57892798465066
total_rewards_max            5010.346096667866
total_rewards_min            4867.144751935819
Number of train steps total  49000
Number of env steps total    247000
Number of rollouts total     0
Train Time (s)               31.284674047026783
(Previous) Eval Time (s)     27.860915489960462
Sample Time (s)              20.739544483833015
Epoch Time (s)               79.88513402082026
Total Train Time (s)         4035.782058820594
Epoch                        48
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:38:14.765088 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #48 | Epoch Duration: 79.51705527305603
2020-01-11 10:38:14.765226 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #48 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0760856
Z variance train             0.013659455
KL Divergence                25.725376
KL Loss                      2.5725377
QF Loss                      191.82202
VF Loss                      81.9395
Policy Loss                  -1248.7411
Q Predictions Mean           1242.9453
Q Predictions Std            467.1571
Q Predictions Max            1797.5553
Q Predictions Min            270.30853
V Predictions Mean           1247.0927
V Predictions Std            464.44995
V Predictions Max            1778.2529
V Predictions Min            265.51788
Log Pis Mean                 1.6347833
Log Pis Std                  4.0486765
Log Pis Max                  12.66481
Log Pis Min                  -5.379085
Policy mu Mean               0.03397544
Policy mu Std                1.1157937
Policy mu Max                2.914334
Policy mu Min                -3.1011784
Policy log std Mean          -0.54698527
Policy log std Std           0.2870548
Policy log std Max           -0.010382742
Policy log std Min           -1.8966838
Z mean eval                  2.0662074
Z variance eval              0.011545819
total_rewards                [4926.83051345 4959.10013017 4927.21492366 5036.41011351 4955.34977719
 4923.58395926 5082.70110378 5229.82621307 4932.22884861 4929.96911654]
total_rewards_mean           4990.321469924843
total_rewards_std            94.71170225018832
total_rewards_max            5229.826213071207
total_rewards_min            4923.58395926469
Number of train steps total  50000
Number of env steps total    252000
Number of rollouts total     0
Train Time (s)               31.00441701244563
(Previous) Eval Time (s)     27.49252914870158
Sample Time (s)              22.51261919364333
Epoch Time (s)               81.00956535479054
Total Train Time (s)         4117.120109434705
Epoch                        49
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:39:36.105547 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #49 | Epoch Duration: 81.34021234512329
2020-01-11 10:39:36.105752 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #49 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0660713
Z variance train             0.0115471985
KL Divergence                25.974792
KL Loss                      2.5974793
QF Loss                      263.41345
VF Loss                      90.20712
Policy Loss                  -1277.8147
Q Predictions Mean           1275.1204
Q Predictions Std            478.67084
Q Predictions Max            1813.9114
Q Predictions Min            270.10657
V Predictions Mean           1279.8071
V Predictions Std            476.76434
V Predictions Max            1802.772
V Predictions Min            277.02762
Log Pis Mean                 1.6285872
Log Pis Std                  4.1001515
Log Pis Max                  13.679377
Log Pis Min                  -7.8622875
Policy mu Mean               0.013217506
Policy mu Std                1.1221533
Policy mu Max                2.6683939
Policy mu Min                -2.8402045
Policy log std Mean          -0.56321406
Policy log std Std           0.2884459
Policy log std Max           -0.01610884
Policy log std Min           -1.9041153
Z mean eval                  2.0404449
Z variance eval              0.01606578
total_rewards                [4950.46837622 5037.05865745 4981.8518377  5285.61645753 5130.00151828
 5098.23970586 5071.83729075 5190.41966077 4898.55697402 5088.68436996]
total_rewards_mean           5073.2734848534155
total_rewards_std            108.70606686614127
total_rewards_max            5285.616457526616
total_rewards_min            4898.556974019945
Number of train steps total  51000
Number of env steps total    257000
Number of rollouts total     0
Train Time (s)               31.644688901957124
(Previous) Eval Time (s)     27.82284165127203
Sample Time (s)              22.867839088197798
Epoch Time (s)               82.33536964142695
Total Train Time (s)         4199.293257548939
Epoch                        50
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:40:58.280987 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #50 | Epoch Duration: 82.17509627342224
2020-01-11 10:40:58.281171 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #50 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0396523
Z variance train             0.016042575
KL Divergence                24.845804
KL Loss                      2.4845805
QF Loss                      238.59036
VF Loss                      111.83638
Policy Loss                  -1287.2949
Q Predictions Mean           1282.7407
Q Predictions Std            476.90744
Q Predictions Max            1771.8518
Q Predictions Min            258.39487
V Predictions Mean           1280.8806
V Predictions Std            474.05124
V Predictions Max            1771.6102
V Predictions Min            265.36697
Log Pis Mean                 1.2912883
Log Pis Std                  3.913008
Log Pis Max                  12.745909
Log Pis Min                  -6.6440773
Policy mu Mean               0.016449139
Policy mu Std                1.0871814
Policy mu Max                3.0007837
Policy mu Min                -2.4288247
Policy log std Mean          -0.5526409
Policy log std Std           0.3004458
Policy log std Max           -0.012514636
Policy log std Min           -1.922509
Z mean eval                  2.0406127
Z variance eval              0.014806658
total_rewards                [5105.21705717 5073.49016231 5160.87880212 5016.41411928 5192.99461186
 5134.2607817  5166.64871372 4972.07921864 5127.32431611 5050.74482161]
total_rewards_mean           5100.00526045127
total_rewards_std            67.24811082696866
total_rewards_max            5192.994611859931
total_rewards_min            4972.079218638237
Number of train steps total  52000
Number of env steps total    262000
Number of rollouts total     0
Train Time (s)               31.322198836132884
(Previous) Eval Time (s)     27.662229637615383
Sample Time (s)              22.475300974678248
Epoch Time (s)               81.45972944842651
Total Train Time (s)         4280.918583967723
Epoch                        51
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:42:19.908441 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #51 | Epoch Duration: 81.62712335586548
2020-01-11 10:42:19.908674 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #51 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0411544
Z variance train             0.014802593
KL Divergence                25.315384
KL Loss                      2.5315385
QF Loss                      261.18912
VF Loss                      120.93497
Policy Loss                  -1292.7474
Q Predictions Mean           1285.0791
Q Predictions Std            515.24615
Q Predictions Max            1907.0498
Q Predictions Min            270.95032
V Predictions Mean           1286.9615
V Predictions Std            511.87936
V Predictions Max            1894.976
V Predictions Min            275.60632
Log Pis Mean                 1.3329716
Log Pis Std                  4.1445737
Log Pis Max                  12.797676
Log Pis Min                  -7.859056
Policy mu Mean               0.001841087
Policy mu Std                1.0941694
Policy mu Max                2.7276564
Policy mu Min                -2.9146543
Policy log std Mean          -0.5373023
Policy log std Std           0.29684287
Policy log std Max           0.07881293
Policy log std Min           -1.9939736
Z mean eval                  2.0344698
Z variance eval              0.01780422
total_rewards                [5030.01659313 5325.06958331 5228.13118635 5436.11467827 5147.10392081
 5068.54602961 5129.93423741 5172.88467733 5021.26101477 5119.96132754]
total_rewards_mean           5167.9023248518515
total_rewards_std            124.4395692633454
total_rewards_max            5436.114678266391
total_rewards_min            5021.2610147694
Number of train steps total  53000
Number of env steps total    267000
Number of rollouts total     0
Train Time (s)               31.747415489982814
(Previous) Eval Time (s)     27.829238282050937
Sample Time (s)              20.581413054373115
Epoch Time (s)               80.15806682640687
Total Train Time (s)         4361.340093057137
Epoch                        52
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:43:40.329691 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #52 | Epoch Duration: 80.42085266113281
2020-01-11 10:43:40.329856 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #52 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0347552
Z variance train             0.0178316
KL Divergence                24.965954
KL Loss                      2.4965954
QF Loss                      382.361
VF Loss                      121.0157
Policy Loss                  -1307.4385
Q Predictions Mean           1308.0325
Q Predictions Std            545.37
Q Predictions Max            1899.9353
Q Predictions Min            272.74936
V Predictions Mean           1312.2448
V Predictions Std            543.90265
V Predictions Max            1886.9008
V Predictions Min            273.7721
Log Pis Mean                 1.3385425
Log Pis Std                  4.156401
Log Pis Max                  13.804295
Log Pis Min                  -6.5577583
Policy mu Mean               0.002426366
Policy mu Std                1.0902941
Policy mu Max                2.8783932
Policy mu Min                -3.0471666
Policy log std Mean          -0.5329924
Policy log std Std           0.29352486
Policy log std Max           0.0009998083
Policy log std Min           -2.1698294
Z mean eval                  2.0071363
Z variance eval              0.034767695
total_rewards                [5032.86453133 5094.1245739  5240.2989436  4875.87593843 5048.13654648
 5065.41262274 4935.31949792 5007.58738189 5284.33086265 5121.31623473]
total_rewards_mean           5070.526713366178
total_rewards_std            118.2152473661397
total_rewards_max            5284.330862645135
total_rewards_min            4875.875938431835
Number of train steps total  54000
Number of env steps total    272000
Number of rollouts total     0
Train Time (s)               31.317281652241945
(Previous) Eval Time (s)     28.091733722016215
Sample Time (s)              22.19188640639186
Epoch Time (s)               81.60090178065002
Total Train Time (s)         4441.725893240422
Epoch                        53
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:45:00.717209 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #53 | Epoch Duration: 80.38721990585327
2020-01-11 10:45:00.717393 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #53 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0069218
Z variance train             0.034664042
KL Divergence                24.00577
KL Loss                      2.400577
QF Loss                      218.45148
VF Loss                      186.49527
Policy Loss                  -1346.9608
Q Predictions Mean           1347.7358
Q Predictions Std            534.7764
Q Predictions Max            1897.229
Q Predictions Min            261.7562
V Predictions Mean           1357.352
V Predictions Std            534.7135
V Predictions Max            1904.5417
V Predictions Min            270.70688
Log Pis Mean                 1.3796117
Log Pis Std                  3.965239
Log Pis Max                  12.558211
Log Pis Min                  -6.4389715
Policy mu Mean               -0.0325509
Policy mu Std                1.0983862
Policy mu Max                3.0105762
Policy mu Min                -2.7394373
Policy log std Mean          -0.54474133
Policy log std Std           0.30255046
Policy log std Max           0.028759003
Policy log std Min           -1.9557035
Z mean eval                  2.0049224
Z variance eval              0.034230836
total_rewards                [4898.40120382 5078.73231125 5041.34588493 5068.91629349 5101.52681303
 5076.74681937 5182.76349376 5184.48020603 4973.80141735 5008.7331068 ]
total_rewards_mean           5061.544754982662
total_rewards_std            83.36564236950754
total_rewards_max            5184.480206034946
total_rewards_min            4898.401203816653
Number of train steps total  55000
Number of env steps total    277000
Number of rollouts total     0
Train Time (s)               31.543838298879564
(Previous) Eval Time (s)     26.877722769975662
Sample Time (s)              22.609442011918873
Epoch Time (s)               81.0310030807741
Total Train Time (s)         4525.156349443831
Epoch                        54
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:46:24.149257 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #54 | Epoch Duration: 83.4317262172699
2020-01-11 10:46:24.149448 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #54 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.004387
Z variance train             0.03435813
KL Divergence                24.224218
KL Loss                      2.422422
QF Loss                      213.10257
VF Loss                      97.846504
Policy Loss                  -1366.5072
Q Predictions Mean           1362.8536
Q Predictions Std            539.83307
Q Predictions Max            1921.3357
Q Predictions Min            266.73407
V Predictions Mean           1365.8851
V Predictions Std            535.81793
V Predictions Max            1914.1335
V Predictions Min            267.93124
Log Pis Mean                 1.3634953
Log Pis Std                  4.1130123
Log Pis Max                  12.610235
Log Pis Min                  -7.104994
Policy mu Mean               -0.023150042
Policy mu Std                1.0894113
Policy mu Max                2.496416
Policy mu Min                -2.6550415
Policy log std Mean          -0.5402175
Policy log std Std           0.30552065
Policy log std Max           -0.044600368
Policy log std Min           -2.1116223
Z mean eval                  2.0121858
Z variance eval              0.015406938
total_rewards                [5010.12849576 5040.45951704 5177.45293303 5167.65215622 5298.10046962
 5192.57958523 5092.32201194 5197.93823459 5128.99911329 4979.30819666]
total_rewards_mean           5128.494071338489
total_rewards_std            93.24789079232444
total_rewards_max            5298.10046962108
total_rewards_min            4979.308196663509
Number of train steps total  56000
Number of env steps total    282000
Number of rollouts total     0
Train Time (s)               31.58744387002662
(Previous) Eval Time (s)     29.27814471302554
Sample Time (s)              21.90343284374103
Epoch Time (s)               82.76902142679319
Total Train Time (s)         4607.381397745572
Epoch                        55
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:47:46.375872 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #55 | Epoch Duration: 82.22626805305481
2020-01-11 10:47:46.376067 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #55 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.011755
Z variance train             0.015390444
KL Divergence                26.027256
KL Loss                      2.6027257
QF Loss                      450.10468
VF Loss                      151.62494
Policy Loss                  -1349.5355
Q Predictions Mean           1343.7957
Q Predictions Std            563.96387
Q Predictions Max            1926.0446
Q Predictions Min            259.61063
V Predictions Mean           1341.894
V Predictions Std            560.05615
V Predictions Max            1923.7134
V Predictions Min            254.48138
Log Pis Mean                 1.5490551
Log Pis Std                  4.3614893
Log Pis Max                  13.278366
Log Pis Min                  -7.9514875
Policy mu Mean               0.017815627
Policy mu Std                1.1225011
Policy mu Max                3.0243137
Policy mu Min                -2.854451
Policy log std Mean          -0.5405118
Policy log std Std           0.30331966
Policy log std Max           0.020679712
Policy log std Min           -2.1498404
Z mean eval                  2.01327
Z variance eval              0.013254347
total_rewards                [5400.50010304 5321.66965982 5050.14090435 5382.70592167 5288.79231793
 5426.97674235 5217.26021693 5104.44317521 5435.60377268 5247.11013115]
total_rewards_mean           5287.520294513384
total_rewards_std            126.80891986993436
total_rewards_max            5435.603772678169
total_rewards_min            5050.1409043499825
Number of train steps total  57000
Number of env steps total    287000
Number of rollouts total     0
Train Time (s)               31.54009644081816
(Previous) Eval Time (s)     28.73512487532571
Sample Time (s)              21.59174938686192
Epoch Time (s)               81.86697070300579
Total Train Time (s)         4688.4212221177295
Epoch                        56
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:49:07.416750 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #56 | Epoch Duration: 81.04054355621338
2020-01-11 10:49:07.416928 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #56 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.013412
Z variance train             0.013257189
KL Divergence                26.304714
KL Loss                      2.6304715
QF Loss                      186.75409
VF Loss                      104.31715
Policy Loss                  -1452.2537
Q Predictions Mean           1448.1792
Q Predictions Std            521.4464
Q Predictions Max            1997.1183
Q Predictions Min            265.12915
V Predictions Mean           1448.9573
V Predictions Std            519.81
V Predictions Max            1996.0529
V Predictions Min            261.02188
Log Pis Mean                 1.8268006
Log Pis Std                  4.193028
Log Pis Max                  13.182152
Log Pis Min                  -7.1729927
Policy mu Mean               0.013410619
Policy mu Std                1.123053
Policy mu Max                3.6184366
Policy mu Min                -2.6133795
Policy log std Mean          -0.56616914
Policy log std Std           0.319007
Policy log std Max           -0.02939248
Policy log std Min           -2.0276005
Z mean eval                  2.0241408
Z variance eval              0.012960577
total_rewards                [5282.15457277 5507.87620614 5364.9493047  5364.59054877 5404.48443469
 5598.961664   5303.06108524 5457.21272559 5372.8705233  5350.54944757]
total_rewards_mean           5400.671051274322
total_rewards_std            91.35664543505837
total_rewards_max            5598.9616639961805
total_rewards_min            5282.154572767092
Number of train steps total  58000
Number of env steps total    292000
Number of rollouts total     0
Train Time (s)               31.612659459002316
(Previous) Eval Time (s)     27.908404592890292
Sample Time (s)              22.80804098211229
Epoch Time (s)               82.3291050340049
Total Train Time (s)         4769.271528150886
Epoch                        57
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:50:28.269435 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #57 | Epoch Duration: 80.85235333442688
2020-01-11 10:50:28.269641 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #57 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0236485
Z variance train             0.012966692
KL Divergence                26.627434
KL Loss                      2.6627433
QF Loss                      334.8048
VF Loss                      109.00946
Policy Loss                  -1461.8983
Q Predictions Mean           1456.3042
Q Predictions Std            527.4136
Q Predictions Max            2030.7473
Q Predictions Min            265.9786
V Predictions Mean           1459.749
V Predictions Std            524.68195
V Predictions Max            2026.1891
V Predictions Min            267.5097
Log Pis Mean                 2.099419
Log Pis Std                  4.135749
Log Pis Max                  12.546692
Log Pis Min                  -6.661998
Policy mu Mean               -0.04303831
Policy mu Std                1.1685997
Policy mu Max                2.973418
Policy mu Min                -2.7680788
Policy log std Mean          -0.5594494
Policy log std Std           0.30243412
Policy log std Max           -0.06474964
Policy log std Min           -2.040035
Z mean eval                  2.0247533
Z variance eval              0.01942766
total_rewards                [5394.61946297 5216.07761413 5432.47950546 5124.38710234 5359.46815593
 5577.67401839 5227.12468826 5489.88888804 5503.94964236 5374.42398628]
total_rewards_mean           5370.009306415826
total_rewards_std            135.83659236021455
total_rewards_max            5577.674018386609
total_rewards_min            5124.3871023395
Number of train steps total  59000
Number of env steps total    297000
Number of rollouts total     0
Train Time (s)               31.638057584874332
(Previous) Eval Time (s)     26.43130757380277
Sample Time (s)              22.740424748510122
Epoch Time (s)               80.80978990718722
Total Train Time (s)         4851.194862604607
Epoch                        58
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:51:50.193889 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #58 | Epoch Duration: 81.92411684989929
2020-01-11 10:51:50.194081 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #58 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.023825
Z variance train             0.019533407
KL Divergence                26.00922
KL Loss                      2.600922
QF Loss                      174.98682
VF Loss                      77.321365
Policy Loss                  -1447.1724
Q Predictions Mean           1444.693
Q Predictions Std            606.5482
Q Predictions Max            2055.7827
Q Predictions Min            256.9505
V Predictions Mean           1447.4823
V Predictions Std            607.18384
V Predictions Max            2050.2485
V Predictions Min            258.51175
Log Pis Mean                 1.0951242
Log Pis Std                  4.045174
Log Pis Max                  12.963133
Log Pis Min                  -8.69061
Policy mu Mean               0.021376481
Policy mu Std                1.0692366
Policy mu Max                2.9663901
Policy mu Min                -2.6079614
Policy log std Mean          -0.52501667
Policy log std Std           0.31286258
Policy log std Max           -0.02417034
Policy log std Min           -2.0927596
Z mean eval                  2.0134416
Z variance eval              0.029431995
total_rewards                [5373.31673397 5378.48335603 5300.36514387 5302.94410958 5742.83841852
 5207.93072695 5423.79489722 5153.70838257 5517.58346097 5394.00218468]
total_rewards_mean           5379.496741436111
total_rewards_std            156.79109217584238
total_rewards_max            5742.838418524939
total_rewards_min            5153.708382573983
Number of train steps total  60000
Number of env steps total    302000
Number of rollouts total     0
Train Time (s)               30.51310090208426
(Previous) Eval Time (s)     27.545318874996156
Sample Time (s)              21.9799940045923
Epoch Time (s)               80.03841378167272
Total Train Time (s)         4932.688118043356
Epoch                        59
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:53:11.688861 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #59 | Epoch Duration: 81.49463558197021
2020-01-11 10:53:11.689054 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #59 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0132232
Z variance train             0.029720504
KL Divergence                25.07177
KL Loss                      2.507177
QF Loss                      444.69482
VF Loss                      198.72275
Policy Loss                  -1347.4083
Q Predictions Mean           1350.2262
Q Predictions Std            623.8859
Q Predictions Max            2013.3926
Q Predictions Min            257.5933
V Predictions Mean           1355.5858
V Predictions Std            626.3804
V Predictions Max            2027.051
V Predictions Min            253.84709
Log Pis Mean                 1.2123965
Log Pis Std                  4.3447614
Log Pis Max                  13.460878
Log Pis Min                  -7.5068817
Policy mu Mean               0.03332339
Policy mu Std                1.0693278
Policy mu Max                2.6895792
Policy mu Min                -2.6253655
Policy log std Mean          -0.53502965
Policy log std Std           0.32185394
Policy log std Max           0.011178106
Policy log std Min           -2.119517
Z mean eval                  2.0093799
Z variance eval              0.025849689
total_rewards                [5118.98416714 5219.7689264  5338.98221686 5216.29489641 5514.20308594
 5239.07578609 5499.96736649 5309.64430765 5289.34136087 5324.0732402 ]
total_rewards_mean           5307.033535405951
total_rewards_std            117.3043127906101
total_rewards_max            5514.20308594005
total_rewards_min            5118.9841671448385
Number of train steps total  61000
Number of env steps total    307000
Number of rollouts total     0
Train Time (s)               31.930295537225902
(Previous) Eval Time (s)     29.001213295850903
Sample Time (s)              21.979140787851065
Epoch Time (s)               82.91064962092787
Total Train Time (s)         5014.703381260391
Epoch                        60
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:54:33.707058 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #60 | Epoch Duration: 82.01784086227417
2020-01-11 10:54:33.707377 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #60 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.008575
Z variance train             0.025867725
KL Divergence                25.040833
KL Loss                      2.5040834
QF Loss                      307.7169
VF Loss                      127.49503
Policy Loss                  -1450.769
Q Predictions Mean           1444.117
Q Predictions Std            579.5972
Q Predictions Max            2079.2097
Q Predictions Min            224.80968
V Predictions Mean           1450.2307
V Predictions Std            573.2246
V Predictions Max            2063.3933
V Predictions Min            237.03133
Log Pis Mean                 1.7236204
Log Pis Std                  4.2640586
Log Pis Max                  14.762294
Log Pis Min                  -8.528137
Policy mu Mean               -0.018282406
Policy mu Std                1.1329323
Policy mu Max                3.0073707
Policy mu Min                -2.907153
Policy log std Mean          -0.56341445
Policy log std Std           0.32291925
Policy log std Max           0.047390193
Policy log std Min           -2.1326532
Z mean eval                  2.0379953
Z variance eval              0.019211907
total_rewards                [5577.68449783 5781.47382883 5728.99980782 5576.31033472 5771.88471686
 5651.40523014 5570.29478038 5644.96415316 5705.92108074 5538.90817031]
total_rewards_mean           5654.784660078785
total_rewards_std            84.06057861095499
total_rewards_max            5781.473828827806
total_rewards_min            5538.908170309849
Number of train steps total  62000
Number of env steps total    312000
Number of rollouts total     0
Train Time (s)               33.22074736887589
(Previous) Eval Time (s)     28.10809353319928
Sample Time (s)              22.074639656580985
Epoch Time (s)               83.40348055865616
Total Train Time (s)         5098.71564652957
Epoch                        61
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:55:57.719681 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #61 | Epoch Duration: 84.01211190223694
2020-01-11 10:55:57.719931 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #61 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0390244
Z variance train             0.01917678
KL Divergence                26.420734
KL Loss                      2.6420734
QF Loss                      476.9852
VF Loss                      180.68924
Policy Loss                  -1485.6599
Q Predictions Mean           1479.4028
Q Predictions Std            608.9895
Q Predictions Max            2141.0403
Q Predictions Min            249.69115
V Predictions Mean           1487.6469
V Predictions Std            605.97345
V Predictions Max            2151.4517
V Predictions Min            261.11465
Log Pis Mean                 2.1727595
Log Pis Std                  4.3968334
Log Pis Max                  13.666006
Log Pis Min                  -7.9204087
Policy mu Mean               0.022429146
Policy mu Std                1.1645663
Policy mu Max                3.3534355
Policy mu Min                -2.8084035
Policy log std Mean          -0.5783078
Policy log std Std           0.3388798
Policy log std Max           0.06948975
Policy log std Min           -2.064958
Z mean eval                  2.0267282
Z variance eval              0.020318303
total_rewards                [5353.29010415 5305.78798421 5438.62155004 4996.54825495 5369.83099347
 5192.37344707 5130.50448859 5198.22218029 5233.13471645 5536.8442075 ]
total_rewards_mean           5275.515792672284
total_rewards_std            149.76344943847496
total_rewards_max            5536.84420750107
total_rewards_min            4996.548254946272
Number of train steps total  63000
Number of env steps total    317000
Number of rollouts total     0
Train Time (s)               33.86086726281792
(Previous) Eval Time (s)     28.716258583124727
Sample Time (s)              23.406370665878057
Epoch Time (s)               85.9834965118207
Total Train Time (s)         5185.839077274781
Epoch                        62
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:57:24.845883 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #62 | Epoch Duration: 87.12571811676025
2020-01-11 10:57:24.846238 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #62 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0254183
Z variance train             0.020229498
KL Divergence                25.799393
KL Loss                      2.5799394
QF Loss                      385.3214
VF Loss                      140.55156
Policy Loss                  -1602.4569
Q Predictions Mean           1606.8513
Q Predictions Std            552.4492
Q Predictions Max            2180.0444
Q Predictions Min            256.64227
V Predictions Mean           1609.4652
V Predictions Std            552.4448
V Predictions Max            2183.3796
V Predictions Min            224.21202
Log Pis Mean                 1.8200808
Log Pis Std                  4.1533217
Log Pis Max                  12.251984
Log Pis Min                  -7.4068375
Policy mu Mean               -0.088115536
Policy mu Std                1.1367687
Policy mu Max                2.885927
Policy mu Min                -2.9193997
Policy log std Mean          -0.5747276
Policy log std Std           0.3268146
Policy log std Max           -0.031159759
Policy log std Min           -2.0426183
Z mean eval                  2.0525863
Z variance eval              0.013073881
total_rewards                [5278.78957789 5364.42702941 5415.35154788 5298.08208453 5364.57554704
 5356.46542279 5229.76175621 5360.63285913 5382.26187734 5319.5053651 ]
total_rewards_mean           5336.985306732579
total_rewards_std            52.294195144086466
total_rewards_max            5415.351547879533
total_rewards_min            5229.761756207668
Number of train steps total  64000
Number of env steps total    322000
Number of rollouts total     0
Train Time (s)               33.36486695101485
(Previous) Eval Time (s)     29.858100766316056
Sample Time (s)              23.793877604883164
Epoch Time (s)               87.01684532221407
Total Train Time (s)         5271.678896309808
Epoch                        63
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:58:50.686426 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #63 | Epoch Duration: 85.83999538421631
2020-01-11 10:58:50.686647 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #63 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0540826
Z variance train             0.013032375
KL Divergence                27.190304
KL Loss                      2.7190304
QF Loss                      356.1452
VF Loss                      64.165886
Policy Loss                  -1592.29
Q Predictions Mean           1592.383
Q Predictions Std            559.15265
Q Predictions Max            2164.615
Q Predictions Min            245.32793
V Predictions Mean           1593.7474
V Predictions Std            555.9762
V Predictions Max            2161.7026
V Predictions Min            251.05127
Log Pis Mean                 2.0926342
Log Pis Std                  4.5518923
Log Pis Max                  14.601321
Log Pis Min                  -7.2139826
Policy mu Mean               -0.08946123
Policy mu Std                1.1585116
Policy mu Max                2.9546804
Policy mu Min                -2.8058636
Policy log std Mean          -0.564356
Policy log std Std           0.32068107
Policy log std Max           0.022530377
Policy log std Min           -2.2817595
Z mean eval                  2.054189
Z variance eval              0.01288003
total_rewards                [5720.60426659 5901.51581184 5706.79318643 5756.56278306 5790.21840744
 5496.68122363 5884.25790511 5667.71427195 5766.43540726 5769.77753422]
total_rewards_mean           5746.056079751717
total_rewards_std            108.08368356459093
total_rewards_max            5901.515811840177
total_rewards_min            5496.681223627512
Number of train steps total  65000
Number of env steps total    327000
Number of rollouts total     0
Train Time (s)               33.91810190118849
(Previous) Eval Time (s)     28.680819565895945
Sample Time (s)              23.8484271094203
Epoch Time (s)               86.44734857650474
Total Train Time (s)         5358.433065568563
Epoch                        64
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:00:17.443121 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #64 | Epoch Duration: 86.75624799728394
2020-01-11 11:00:17.443430 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #64 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0540252
Z variance train             0.012903348
KL Divergence                27.017483
KL Loss                      2.7017484
QF Loss                      205.95905
VF Loss                      76.24681
Policy Loss                  -1620.2056
Q Predictions Mean           1619.3275
Q Predictions Std            557.336
Q Predictions Max            2169.5056
Q Predictions Min            229.25378
V Predictions Mean           1620.4087
V Predictions Std            554.80383
V Predictions Max            2151.1865
V Predictions Min            244.8899
Log Pis Mean                 2.3243842
Log Pis Std                  4.2773857
Log Pis Max                  15.218156
Log Pis Min                  -5.5830703
Policy mu Mean               -0.028565481
Policy mu Std                1.1718726
Policy mu Max                2.8725832
Policy mu Min                -2.827321
Policy log std Mean          -0.59094524
Policy log std Std           0.3253409
Policy log std Max           -0.07583135
Policy log std Min           -2.092714
Z mean eval                  2.034642
Z variance eval              0.04763553
total_rewards                [5683.54255834 5704.70885809 5664.77282275 5638.66904341 5639.81553245
 5714.95162652 5735.74772724 5736.1183425  5673.72508981 5888.98080475]
total_rewards_mean           5708.103240585529
total_rewards_std            68.8992796125034
total_rewards_max            5888.980804748531
total_rewards_min            5638.669043407141
Number of train steps total  66000
Number of env steps total    332000
Number of rollouts total     0
Train Time (s)               33.49394419416785
(Previous) Eval Time (s)     28.98928249720484
Sample Time (s)              23.83618614729494
Epoch Time (s)               86.31941283866763
Total Train Time (s)         5444.335825035814
Epoch                        65
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:01:43.347218 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #65 | Epoch Duration: 85.90357613563538
2020-01-11 11:01:43.347468 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #65 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0345607
Z variance train             0.047717333
KL Divergence                25.569908
KL Loss                      2.5569909
QF Loss                      338.8183
VF Loss                      158.34091
Policy Loss                  -1508.8704
Q Predictions Mean           1510.5662
Q Predictions Std            598.4036
Q Predictions Max            2117.0679
Q Predictions Min            220.29977
V Predictions Mean           1502.4551
V Predictions Std            596.81024
V Predictions Max            2108.321
V Predictions Min            225.04968
Log Pis Mean                 1.8126863
Log Pis Std                  4.2458467
Log Pis Max                  13.202741
Log Pis Min                  -7.6153655
Policy mu Mean               -0.08486283
Policy mu Std                1.1093374
Policy mu Max                3.7663553
Policy mu Min                -2.8438592
Policy log std Mean          -0.5862491
Policy log std Std           0.33123106
Policy log std Max           -0.021607608
Policy log std Min           -2.3054254
Z mean eval                  2.0732608
Z variance eval              0.023040187
total_rewards                [5841.81391376 5952.22600992 5865.86436821 5915.20162249 5971.71165608
 5910.1876292  5900.82545751 5939.18818815 6048.85643433 5984.51138499]
total_rewards_mean           5933.038666464469
total_rewards_std            57.16391319870196
total_rewards_max            6048.856434325807
total_rewards_min            5841.813913758132
Number of train steps total  67000
Number of env steps total    337000
Number of rollouts total     0
Train Time (s)               33.77890321193263
(Previous) Eval Time (s)     28.573060653172433
Sample Time (s)              21.608794504776597
Epoch Time (s)               83.96075836988166
Total Train Time (s)         5528.717976918444
Epoch                        66
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:03:07.730720 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #66 | Epoch Duration: 84.3830943107605
2020-01-11 11:03:07.730940 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #66 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0731924
Z variance train             0.02302443
KL Divergence                26.461395
KL Loss                      2.6461396
QF Loss                      235.99539
VF Loss                      88.856834
Policy Loss                  -1562.9843
Q Predictions Mean           1561.955
Q Predictions Std            662.89453
Q Predictions Max            2196.7732
Q Predictions Min            244.54477
V Predictions Mean           1566.9236
V Predictions Std            659.78375
V Predictions Max            2199.2686
V Predictions Min            241.54808
Log Pis Mean                 1.7291133
Log Pis Std                  4.470781
Log Pis Max                  13.013176
Log Pis Min                  -5.985433
Policy mu Mean               0.004097845
Policy mu Std                1.1294845
Policy mu Max                2.9447913
Policy mu Min                -3.0819604
Policy log std Mean          -0.5454212
Policy log std Std           0.3474875
Policy log std Max           0.102757156
Policy log std Min           -2.1069102
Z mean eval                  2.0955136
Z variance eval              0.013792193
total_rewards                [5737.36634618 5898.60183577 5924.15912513 5917.62546856 5953.25917131
 5797.75080442 5830.95244718 5801.05118653 5870.72133674 5845.14717923]
total_rewards_mean           5857.663490106059
total_rewards_std            64.13900655414236
total_rewards_max            5953.259171309892
total_rewards_min            5737.36634618312
Number of train steps total  68000
Number of env steps total    342000
Number of rollouts total     0
Train Time (s)               34.33328831382096
(Previous) Eval Time (s)     28.99503556918353
Sample Time (s)              23.671087882947177
Epoch Time (s)               86.99941176595166
Total Train Time (s)         5616.43619381031
Epoch                        67
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:04:35.450833 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #67 | Epoch Duration: 87.71974611282349
2020-01-11 11:04:35.451031 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #67 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0970707
Z variance train             0.013803745
KL Divergence                27.715683
KL Loss                      2.7715683
QF Loss                      229.73602
VF Loss                      99.41829
Policy Loss                  -1641.2261
Q Predictions Mean           1635.1548
Q Predictions Std            579.3409
Q Predictions Max            2255.6995
Q Predictions Min            238.49467
V Predictions Mean           1638.0681
V Predictions Std            576.6452
V Predictions Max            2236.8767
V Predictions Min            243.66182
Log Pis Mean                 1.670243
Log Pis Std                  3.8188024
Log Pis Max                  13.659279
Log Pis Min                  -7.170472
Policy mu Mean               0.018325772
Policy mu Std                1.1132969
Policy mu Max                2.9587586
Policy mu Min                -2.685468
Policy log std Mean          -0.5651023
Policy log std Std           0.3221919
Policy log std Max           0.038921
Policy log std Min           -2.0961962
Z mean eval                  2.0838563
Z variance eval              0.011064863
total_rewards                [5870.04387009 5905.54532701 5968.61152172 6008.9666343  5742.9911026
 5897.89156686 5842.88642814 5860.00601628 5697.25852503 6062.20540799]
total_rewards_mean           5885.640640002779
total_rewards_std            106.0093838829731
total_rewards_max            6062.205407991227
total_rewards_min            5697.258525027953
Number of train steps total  69000
Number of env steps total    347000
Number of rollouts total     0
Train Time (s)               33.22641342692077
(Previous) Eval Time (s)     29.715038198046386
Sample Time (s)              23.874159247614443
Epoch Time (s)               86.8156108725816
Total Train Time (s)         5702.6540380558
Epoch                        68
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:06:01.670529 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #68 | Epoch Duration: 86.21934723854065
2020-01-11 11:06:01.670760 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #68 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0819497
Z variance train             0.011045547
KL Divergence                28.423595
KL Loss                      2.8423595
QF Loss                      408.3325
VF Loss                      177.35391
Policy Loss                  -1598.2646
Q Predictions Mean           1595.3691
Q Predictions Std            633.54065
Q Predictions Max            2222.441
Q Predictions Min            232.79854
V Predictions Mean           1602.5865
V Predictions Std            632.82104
V Predictions Max            2236.5322
V Predictions Min            243.75876
Log Pis Mean                 2.5809503
Log Pis Std                  4.4662027
Log Pis Max                  14.429176
Log Pis Min                  -5.635748
Policy mu Mean               -0.05606849
Policy mu Std                1.208436
Policy mu Max                3.41036
Policy mu Min                -2.7092867
Policy log std Mean          -0.5744757
Policy log std Std           0.33312744
Policy log std Max           -0.010628611
Policy log std Min           -2.4634151
Z mean eval                  2.0926025
Z variance eval              0.01164424
total_rewards                [5761.49429066 5821.17837162 5915.55649189 5969.69744422 6191.73372815
 5980.96007262 5979.84565105 5818.1583395  5914.21921282 5884.38081431]
total_rewards_mean           5923.722441683605
total_rewards_std            114.0401281353854
total_rewards_max            6191.73372814644
total_rewards_min            5761.494290660418
Number of train steps total  70000
Number of env steps total    352000
Number of rollouts total     0
Train Time (s)               33.92594486521557
(Previous) Eval Time (s)     29.118336235173047
Sample Time (s)              22.5183638012968
Epoch Time (s)               85.56264490168542
Total Train Time (s)         5788.1949321520515
Epoch                        69
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:07:27.212624 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #69 | Epoch Duration: 85.54172015190125
2020-01-11 11:07:27.212800 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #69 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0943716
Z variance train             0.011673568
KL Divergence                28.996618
KL Loss                      2.8996618
QF Loss                      438.46933
VF Loss                      129.57812
Policy Loss                  -1642.9235
Q Predictions Mean           1639.4998
Q Predictions Std            642.5633
Q Predictions Max            2271.9395
Q Predictions Min            237.29791
V Predictions Mean           1638.6522
V Predictions Std            636.9745
V Predictions Max            2242.5752
V Predictions Min            236.21213
Log Pis Mean                 1.8174763
Log Pis Std                  4.153148
Log Pis Max                  12.245399
Log Pis Min                  -6.0209136
Policy mu Mean               0.08255458
Policy mu Std                1.1195666
Policy mu Max                2.8909614
Policy mu Min                -2.450357
Policy log std Mean          -0.58163494
Policy log std Std           0.34637278
Policy log std Max           -0.033139795
Policy log std Min           -2.1706736
Z mean eval                  2.1016607
Z variance eval              0.011923835
total_rewards                [6001.79139899 5943.09200256 6029.5300707  6014.79996738 6067.66000125
 6042.17067271 5945.21526318 6059.05205181 5931.04291715 5883.47355335]
total_rewards_mean           5991.7827899082395
total_rewards_std            59.02187190983176
total_rewards_max            6067.660001248
total_rewards_min            5883.4735533488765
Number of train steps total  71000
Number of env steps total    357000
Number of rollouts total     0
Train Time (s)               33.033643026370555
(Previous) Eval Time (s)     29.09702240396291
Sample Time (s)              23.398571940604597
Epoch Time (s)               85.52923737093806
Total Train Time (s)         5873.224006571807
Epoch                        70
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:08:52.243736 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #70 | Epoch Duration: 85.03079771995544
2020-01-11 11:08:52.243924 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #70 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.102152
Z variance train             0.011881178
KL Divergence                29.307533
KL Loss                      2.9307535
QF Loss                      242.74435
VF Loss                      130.07253
Policy Loss                  -1661.451
Q Predictions Mean           1659.6771
Q Predictions Std            637.1956
Q Predictions Max            2308.9946
Q Predictions Min            235.28268
V Predictions Mean           1655.4197
V Predictions Std            630.4683
V Predictions Max            2287.785
V Predictions Min            241.30844
Log Pis Mean                 2.4097986
Log Pis Std                  4.3220277
Log Pis Max                  13.908327
Log Pis Min                  -6.2991114
Policy mu Mean               -0.03422207
Policy mu Std                1.1656649
Policy mu Max                2.739013
Policy mu Min                -2.6938107
Policy log std Mean          -0.58906394
Policy log std Std           0.33664277
Policy log std Max           -0.047555357
Policy log std Min           -2.148845
Z mean eval                  2.099486
Z variance eval              0.014072609
total_rewards                [5896.48071562 6000.87138147 6149.75725187 5967.3044107  5692.00421338
 5910.02184673 5939.60866919 5882.39266124 6028.63633127 5727.33605352]
total_rewards_mean           5919.441353498444
total_rewards_std            128.42041158520055
total_rewards_max            6149.757251866341
total_rewards_min            5692.0042133815305
Number of train steps total  72000
Number of env steps total    362000
Number of rollouts total     0
Train Time (s)               31.56630276190117
(Previous) Eval Time (s)     28.598134248983115
Sample Time (s)              22.832471795380116
Epoch Time (s)               82.9969088062644
Total Train Time (s)         5956.226402248722
Epoch                        71
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:10:15.247720 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #71 | Epoch Duration: 83.00365734100342
2020-01-11 11:10:15.247894 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #71 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0972707
Z variance train             0.014099918
KL Divergence                29.420046
KL Loss                      2.9420047
QF Loss                      461.50885
VF Loss                      271.8603
Policy Loss                  -1784.0004
Q Predictions Mean           1783.7297
Q Predictions Std            552.6394
Q Predictions Max            2333.5005
Q Predictions Min            230.09521
V Predictions Mean           1796.0752
V Predictions Std            544.9087
V Predictions Max            2347.072
V Predictions Min            245.54745
Log Pis Mean                 1.9477649
Log Pis Std                  4.199779
Log Pis Max                  14.339385
Log Pis Min                  -6.7605777
Policy mu Mean               -0.037640553
Policy mu Std                1.1457485
Policy mu Max                3.0470953
Policy mu Min                -2.753489
Policy log std Mean          -0.61021596
Policy log std Std           0.3413965
Policy log std Max           0.025689691
Policy log std Min           -2.3181841
Z mean eval                  2.0871596
Z variance eval              0.013581817
total_rewards                [5974.04276412 6191.01186975 6114.12244729 6189.82039446 6127.6343554
 6250.41691344 5948.62286841 5896.37577379 6106.6098375  6091.92340038]
total_rewards_mean           6089.058062453961
total_rewards_std            109.1301795278632
total_rewards_max            6250.416913438549
total_rewards_min            5896.37577379083
Number of train steps total  73000
Number of env steps total    367000
Number of rollouts total     0
Train Time (s)               31.23246879922226
(Previous) Eval Time (s)     28.604533900041133
Sample Time (s)              23.01376499934122
Epoch Time (s)               82.85076769860461
Total Train Time (s)         6037.607088102493
Epoch                        72
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:11:36.629887 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #72 | Epoch Duration: 81.38185834884644
2020-01-11 11:11:36.630064 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #72 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.088297
Z variance train             0.013584899
KL Divergence                28.712194
KL Loss                      2.8712194
QF Loss                      287.73566
VF Loss                      144.98694
Policy Loss                  -1673.5808
Q Predictions Mean           1670.3284
Q Predictions Std            628.2927
Q Predictions Max            2254.8298
Q Predictions Min            178.31087
V Predictions Mean           1671.5623
V Predictions Std            624.9462
V Predictions Max            2256.1465
V Predictions Min            219.47527
Log Pis Mean                 2.0107691
Log Pis Std                  4.381879
Log Pis Max                  15.139852
Log Pis Min                  -6.461306
Policy mu Mean               -0.033444766
Policy mu Std                1.132883
Policy mu Max                3.4174132
Policy mu Min                -3.2109635
Policy log std Mean          -0.59144944
Policy log std Std           0.34043708
Policy log std Max           0.39829198
Policy log std Min           -2.10734
Z mean eval                  2.0855472
Z variance eval              0.015771419
total_rewards                [6056.13538551 6167.55110991 6033.90178203 6301.03925415 6251.3457514
 6335.30321597 6088.39541447 5996.39485228 6234.37438629 6131.39362046]
total_rewards_mean           6159.583477249113
total_rewards_std            111.33506788975154
total_rewards_max            6335.303215971844
total_rewards_min            5996.394852284366
Number of train steps total  74000
Number of env steps total    372000
Number of rollouts total     0
Train Time (s)               32.028457100037485
(Previous) Eval Time (s)     27.13530923705548
Sample Time (s)              22.40794648276642
Epoch Time (s)               81.57171281985939
Total Train Time (s)         6120.496538940817
Epoch                        73
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:12:59.521316 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #73 | Epoch Duration: 82.89111423492432
2020-01-11 11:12:59.521507 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #73 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0829456
Z variance train             0.015787052
KL Divergence                28.38974
KL Loss                      2.838974
QF Loss                      317.6906
VF Loss                      375.7648
Policy Loss                  -1620.8213
Q Predictions Mean           1623.8385
Q Predictions Std            696.7949
Q Predictions Max            2369.4626
Q Predictions Min            216.99594
V Predictions Mean           1638.0404
V Predictions Std            696.613
V Predictions Max            2362.8857
V Predictions Min            220.73717
Log Pis Mean                 1.7844996
Log Pis Std                  4.4231963
Log Pis Max                  14.945031
Log Pis Min                  -6.8453064
Policy mu Mean               -0.053721216
Policy mu Std                1.1366625
Policy mu Max                2.8887918
Policy mu Min                -2.7730458
Policy log std Mean          -0.57496405
Policy log std Std           0.34069622
Policy log std Max           -0.0013042092
Policy log std Min           -2.1682572
Z mean eval                  2.097365
Z variance eval              0.022150425
total_rewards                [6038.06150055 6193.7584051  6220.37264466 6192.43709363 6006.72631192
 6345.80159439 6213.56403154 6114.60211506 6161.20930186 6430.97391217]
total_rewards_mean           6191.7506910888505
total_rewards_std            121.2427473444249
total_rewards_max            6430.973912168036
total_rewards_min            6006.726311922985
Number of train steps total  75000
Number of env steps total    377000
Number of rollouts total     0
Train Time (s)               31.83042331971228
(Previous) Eval Time (s)     28.45436543179676
Sample Time (s)              22.582369415089488
Epoch Time (s)               82.86715816659853
Total Train Time (s)         6203.157266685739
Epoch                        74
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:14:22.183696 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #74 | Epoch Duration: 82.66202521324158
2020-01-11 11:14:22.183910 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #74 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0953338
Z variance train             0.022086024
KL Divergence                28.051376
KL Loss                      2.8051376
QF Loss                      421.44403
VF Loss                      229.32138
Policy Loss                  -1776.8141
Q Predictions Mean           1769.3373
Q Predictions Std            620.0654
Q Predictions Max            2452.779
Q Predictions Min            211.99585
V Predictions Mean           1776.9658
V Predictions Std            614.4709
V Predictions Max            2475.5444
V Predictions Min            229.39946
Log Pis Mean                 2.5029273
Log Pis Std                  4.3813357
Log Pis Max                  14.084156
Log Pis Min                  -6.784932
Policy mu Mean               -0.074602894
Policy mu Std                1.1695241
Policy mu Max                2.9728124
Policy mu Min                -2.7080154
Policy log std Mean          -0.61930066
Policy log std Std           0.34025046
Policy log std Max           -0.07641886
Policy log std Min           -2.2160373
Z mean eval                  2.0955396
Z variance eval              0.0211276
total_rewards                [6165.01297531 6312.28054688 6341.73892246 6417.61135302 6256.36372655
 6222.39087414 6334.98757824 6399.51301628 6470.16498208 6322.76446655]
total_rewards_mean           6324.282844149853
total_rewards_std            87.5093854142323
total_rewards_max            6470.164982077686
total_rewards_min            6165.012975305183
Number of train steps total  76000
Number of env steps total    382000
Number of rollouts total     0
Train Time (s)               31.772151921875775
(Previous) Eval Time (s)     28.248885050415993
Sample Time (s)              21.256525094620883
Epoch Time (s)               81.27756206691265
Total Train Time (s)         6284.550940855872
Epoch                        75
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:15:43.579727 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #75 | Epoch Duration: 81.39562821388245
2020-01-11 11:15:43.580017 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #75 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0933452
Z variance train             0.021007104
KL Divergence                27.855131
KL Loss                      2.7855132
QF Loss                      301.0777
VF Loss                      175.91002
Policy Loss                  -1779.442
Q Predictions Mean           1781.8313
Q Predictions Std            647.4751
Q Predictions Max            2431.0156
Q Predictions Min            219.37886
V Predictions Mean           1787.7917
V Predictions Std            647.04486
V Predictions Max            2419.649
V Predictions Min            227.01611
Log Pis Mean                 2.3321924
Log Pis Std                  4.285305
Log Pis Max                  14.23316
Log Pis Min                  -5.962763
Policy mu Mean               -0.030345224
Policy mu Std                1.1766378
Policy mu Max                3.1160839
Policy mu Min                -2.8929005
Policy log std Mean          -0.5947221
Policy log std Std           0.3514268
Policy log std Max           -0.03581506
Policy log std Min           -2.228064
Z mean eval                  2.1001167
Z variance eval              0.018153023
total_rewards                [6396.82240901 6307.51128099 6299.97775389 6509.21459477 6399.50105621
 6093.45598631 6262.57056864 6332.32633919 6439.37777647 6477.85041857]
total_rewards_mean           6351.860818403792
total_rewards_std            115.05219720189389
total_rewards_max            6509.214594767351
total_rewards_min            6093.455986306117
Number of train steps total  77000
Number of env steps total    387000
Number of rollouts total     0
Train Time (s)               32.28954933490604
(Previous) Eval Time (s)     28.36658034613356
Sample Time (s)              21.985120948404074
Epoch Time (s)               82.64125062944368
Total Train Time (s)         6367.242208614945
Epoch                        76
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:17:06.272411 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #76 | Epoch Duration: 82.69216871261597
2020-01-11 11:17:06.272635 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #76 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1020591
Z variance train             0.018251449
KL Divergence                28.486172
KL Loss                      2.8486173
QF Loss                      380.73248
VF Loss                      159.18684
Policy Loss                  -1789.928
Q Predictions Mean           1786.756
Q Predictions Std            624.2061
Q Predictions Max            2396.669
Q Predictions Min            219.85318
V Predictions Mean           1789.7229
V Predictions Std            623.6722
V Predictions Max            2400.4697
V Predictions Min            206.69519
Log Pis Mean                 2.0871572
Log Pis Std                  4.254151
Log Pis Max                  15.729063
Log Pis Min                  -6.958583
Policy mu Mean               -0.02815026
Policy mu Std                1.1589617
Policy mu Max                2.9010863
Policy mu Min                -2.958884
Policy log std Mean          -0.59529036
Policy log std Std           0.3398196
Policy log std Max           -0.06713654
Policy log std Min           -2.2132566
Z mean eval                  2.1066844
Z variance eval              0.016813211
total_rewards                [6496.52623913 6591.85177837 6569.42270709 6098.36901669 6464.48388517
 6701.31683893 6480.2497233  6434.90569056 6448.79880998 6390.03749129]
total_rewards_mean           6467.5962180509505
total_rewards_std            150.068732970856
total_rewards_max            6701.316838927655
total_rewards_min            6098.369016687215
Number of train steps total  78000
Number of env steps total    392000
Number of rollouts total     0
Train Time (s)               31.142293139360845
(Previous) Eval Time (s)     28.417192582972348
Sample Time (s)              22.83404496172443
Epoch Time (s)               82.39353068405762
Total Train Time (s)         6447.94673908269
Epoch                        77
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:18:26.978911 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #77 | Epoch Duration: 80.70609283447266
2020-01-11 11:18:26.979288 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #77 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1067314
Z variance train             0.016856857
KL Divergence                28.803871
KL Loss                      2.880387
QF Loss                      389.25513
VF Loss                      176.45143
Policy Loss                  -1875.2975
Q Predictions Mean           1872.6464
Q Predictions Std            547.9376
Q Predictions Max            2413.548
Q Predictions Min            161.21803
V Predictions Mean           1871.4536
V Predictions Std            545.42053
V Predictions Max            2427.1062
V Predictions Min            214.08049
Log Pis Mean                 2.3561518
Log Pis Std                  4.365781
Log Pis Max                  15.383451
Log Pis Min                  -8.819117
Policy mu Mean               -0.046467345
Policy mu Std                1.1826154
Policy mu Max                3.1466222
Policy mu Min                -3.6537957
Policy log std Mean          -0.6178339
Policy log std Std           0.35264978
Policy log std Max           0.06282872
Policy log std Min           -2.2314305
Z mean eval                  2.0777872
Z variance eval              0.024229335
total_rewards                [6462.08451885 6486.22193854 6263.60969888 6443.50471603 6422.35798863
 6451.67359546 6474.77611572 6229.02328472 6347.49653079 6426.39904059]
total_rewards_mean           6400.71474282173
total_rewards_std            85.57256835475307
total_rewards_max            6486.22193853989
total_rewards_min            6229.023284715592
Number of train steps total  79000
Number of env steps total    397000
Number of rollouts total     0
Train Time (s)               31.590394223108888
(Previous) Eval Time (s)     26.72938992269337
Sample Time (s)              22.737240285612643
Epoch Time (s)               81.0570244314149
Total Train Time (s)         6530.1892535244115
Epoch                        78
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:19:49.222828 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #78 | Epoch Duration: 82.2432861328125
2020-01-11 11:19:49.223032 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #78 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0770366
Z variance train             0.02424673
KL Divergence                27.59309
KL Loss                      2.759309
QF Loss                      336.47437
VF Loss                      157.20813
Policy Loss                  -1779.4272
Q Predictions Mean           1773.571
Q Predictions Std            651.49774
Q Predictions Max            2512.0935
Q Predictions Min            222.51367
V Predictions Mean           1779.9452
V Predictions Std            647.31744
V Predictions Max            2514.0007
V Predictions Min            217.52129
Log Pis Mean                 2.40904
Log Pis Std                  4.404644
Log Pis Max                  13.6718025
Log Pis Min                  -6.7849283
Policy mu Mean               -0.07350745
Policy mu Std                1.1917588
Policy mu Max                3.254386
Policy mu Min                -2.7481205
Policy log std Mean          -0.6126142
Policy log std Std           0.34092745
Policy log std Max           0.01766634
Policy log std Min           -2.27721
Z mean eval                  2.0973535
Z variance eval              0.02116807
total_rewards                [6485.55220137 6711.74806887 6354.84641704 6560.31175036 6576.22259422
 6551.25041772 6563.85525369 6672.28597527 6444.87322902 6563.53562426]
total_rewards_mean           6548.448153181422
total_rewards_std            97.75121189992925
total_rewards_max            6711.748068870518
total_rewards_min            6354.846417039762
Number of train steps total  80000
Number of env steps total    402000
Number of rollouts total     0
Train Time (s)               32.33784643094987
(Previous) Eval Time (s)     27.915332227014005
Sample Time (s)              22.642516432795674
Epoch Time (s)               82.89569509075955
Total Train Time (s)         6612.682141779456
Epoch                        79
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:21:11.717466 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #79 | Epoch Duration: 82.49427723884583
2020-01-11 11:21:11.717661 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #79 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0967438
Z variance train             0.021209795
KL Divergence                28.727974
KL Loss                      2.8727975
QF Loss                      518.7213
VF Loss                      130.17665
Policy Loss                  -1846.8888
Q Predictions Mean           1840.259
Q Predictions Std            608.31757
Q Predictions Max            2457.4092
Q Predictions Min            218.85968
V Predictions Mean           1845.5198
V Predictions Std            608.83026
V Predictions Max            2455.9893
V Predictions Min            214.42593
Log Pis Mean                 2.209661
Log Pis Std                  4.5332227
Log Pis Max                  15.467663
Log Pis Min                  -6.444452
Policy mu Mean               -0.08669285
Policy mu Std                1.1741309
Policy mu Max                2.7243667
Policy mu Min                -3.0644083
Policy log std Mean          -0.6135056
Policy log std Std           0.34137842
Policy log std Max           -0.03082177
Policy log std Min           -2.2224193
Z mean eval                  2.1182961
Z variance eval              0.017575603
total_rewards                [6584.50745257 6430.3114182  6506.28525856 6594.6324448  6535.42465627
 6454.55311118 6625.09571204 6532.69686149 6679.12758733 6481.70395329]
total_rewards_mean           6542.433845572608
total_rewards_std            74.46226246962519
total_rewards_max            6679.127587328068
total_rewards_min            6430.311418204361
Number of train steps total  81000
Number of env steps total    407000
Number of rollouts total     0
Train Time (s)               31.64458189206198
(Previous) Eval Time (s)     27.51359796896577
Sample Time (s)              22.06374857062474
Epoch Time (s)               81.22192843165249
Total Train Time (s)         6694.514301301446
Epoch                        80
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:22:33.552764 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #80 | Epoch Duration: 81.8349404335022
2020-01-11 11:22:33.553001 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #80 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1188369
Z variance train             0.017597403
KL Divergence                29.537905
KL Loss                      2.9537904
QF Loss                      401.2291
VF Loss                      179.031
Policy Loss                  -1853.7913
Q Predictions Mean           1852.9116
Q Predictions Std            668.46277
Q Predictions Max            2551.4937
Q Predictions Min            214.47496
V Predictions Mean           1852.5505
V Predictions Std            663.68567
V Predictions Max            2545.7922
V Predictions Min            219.05602
Log Pis Mean                 2.6887329
Log Pis Std                  4.493025
Log Pis Max                  15.113478
Log Pis Min                  -7.182695
Policy mu Mean               -0.052093964
Policy mu Std                1.2008934
Policy mu Max                2.7003493
Policy mu Min                -2.8021836
Policy log std Mean          -0.6244492
Policy log std Std           0.33620277
Policy log std Max           -0.007921994
Policy log std Min           -2.1131406
Z mean eval                  2.1144593
Z variance eval              0.018258236
total_rewards                [6523.77573713 6560.98857927 6468.41986991 6551.11268241 6559.73390812
 6739.11281117 6625.51859199 6325.59097589 6571.0135313  6502.80981734]
total_rewards_mean           6542.807650452154
total_rewards_std            100.76560504299825
total_rewards_max            6739.112811168114
total_rewards_min            6325.590975889167
Number of train steps total  82000
Number of env steps total    412000
Number of rollouts total     0
Train Time (s)               31.75899184588343
(Previous) Eval Time (s)     28.12618798390031
Sample Time (s)              22.837701288051903
Epoch Time (s)               82.72288111783564
Total Train Time (s)         6777.165078229271
Epoch                        81
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:23:56.205335 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #81 | Epoch Duration: 82.65216112136841
2020-01-11 11:23:56.205542 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #81 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.113205
Z variance train             0.0182937
KL Divergence                29.402794
KL Loss                      2.9402795
QF Loss                      677.991
VF Loss                      150.39099
Policy Loss                  -1852.6014
Q Predictions Mean           1848.2668
Q Predictions Std            645.3081
Q Predictions Max            2485.9106
Q Predictions Min            194.89334
V Predictions Mean           1854.8942
V Predictions Std            637.1705
V Predictions Max            2516.4905
V Predictions Min            211.51683
Log Pis Mean                 2.3673987
Log Pis Std                  4.5556006
Log Pis Max                  15.93849
Log Pis Min                  -7.33017
Policy mu Mean               -0.09343714
Policy mu Std                1.2288659
Policy mu Max                3.5613308
Policy mu Min                -3.1131883
Policy log std Mean          -0.62361574
Policy log std Std           0.3313539
Policy log std Max           -0.00787735
Policy log std Min           -2.2958403
Z mean eval                  2.1065998
Z variance eval              0.020310437
total_rewards                [6379.90688631 6643.80982193 6462.67493711 6873.78047488 6897.02683891
 6781.95437331 6875.60188093 7167.73572092 6912.18550762 6491.93771956]
total_rewards_mean           6748.661416147399
total_rewards_std            234.93017350029933
total_rewards_max            7167.73572091989
total_rewards_min            6379.9068863074035
Number of train steps total  83000
Number of env steps total    417000
Number of rollouts total     0
Train Time (s)               31.787185475230217
(Previous) Eval Time (s)     28.055093235801905
Sample Time (s)              23.236125783994794
Epoch Time (s)               83.07840449502692
Total Train Time (s)         6859.8750419127755
Epoch                        82
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:25:18.915651 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #82 | Epoch Duration: 82.70996618270874
2020-01-11 11:25:18.915823 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #82 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1092575
Z variance train             0.02032469
KL Divergence                28.854057
KL Loss                      2.8854058
QF Loss                      532.5845
VF Loss                      407.4976
Policy Loss                  -1846.4158
Q Predictions Mean           1835.4927
Q Predictions Std            725.7744
Q Predictions Max            2618.6304
Q Predictions Min            207.80984
V Predictions Mean           1829.6224
V Predictions Std            720.9508
V Predictions Max            2602.0237
V Predictions Min            214.03217
Log Pis Mean                 2.4140263
Log Pis Std                  4.3602095
Log Pis Max                  14.18362
Log Pis Min                  -6.7119536
Policy mu Mean               -0.04896359
Policy mu Std                1.1768855
Policy mu Max                3.402853
Policy mu Min                -2.7629507
Policy log std Mean          -0.6067989
Policy log std Std           0.33346012
Policy log std Max           -0.0036138296
Policy log std Min           -2.0050826
Z mean eval                  2.0886703
Z variance eval              0.031356927
total_rewards                [6798.20100136 6671.60454175 6792.0939159  6777.29104147 6715.5205953
 6910.66600738 6829.47753105 6521.86882741 6857.65240796 6633.00851318]
total_rewards_mean           6750.738438275839
total_rewards_std            110.28117892348645
total_rewards_max            6910.666007380107
total_rewards_min            6521.868827412861
Number of train steps total  84000
Number of env steps total    422000
Number of rollouts total     0
Train Time (s)               31.3283561039716
(Previous) Eval Time (s)     27.68636200018227
Sample Time (s)              22.175486393272877
Epoch Time (s)               81.19020449742675
Total Train Time (s)         6939.923338152468
Epoch                        83
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:26:38.966105 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #83 | Epoch Duration: 80.05014610290527
2020-01-11 11:26:38.966293 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #83 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0884247
Z variance train             0.03130274
KL Divergence                28.087553
KL Loss                      2.8087554
QF Loss                      249.94194
VF Loss                      114.77025
Policy Loss                  -1871.5049
Q Predictions Mean           1869.6436
Q Predictions Std            728.095
Q Predictions Max            2617.8857
Q Predictions Min            205.44496
V Predictions Mean           1869.1597
V Predictions Std            726.2737
V Predictions Max            2616.3254
V Predictions Min            210.04489
Log Pis Mean                 2.4130554
Log Pis Std                  4.5925326
Log Pis Max                  15.929441
Log Pis Min                  -6.2246084
Policy mu Mean               -0.080102876
Policy mu Std                1.1873438
Policy mu Max                2.8691845
Policy mu Min                -3.1432986
Policy log std Mean          -0.6100736
Policy log std Std           0.36573324
Policy log std Max           0.012500346
Policy log std Min           -2.3621314
Z mean eval                  2.099985
Z variance eval              0.028327515
total_rewards                [6630.99073372 6538.98417365 6588.57398212 6710.33546421 6432.11691934
 6603.29084294 6576.92622231 6442.99878831 6614.86910876 6377.62436887]
total_rewards_mean           6551.671060422637
total_rewards_std            98.32614657645769
total_rewards_max            6710.335464206322
total_rewards_min            6377.624368867579
Number of train steps total  85000
Number of env steps total    427000
Number of rollouts total     0
Train Time (s)               31.678121712990105
(Previous) Eval Time (s)     26.545996421016753
Sample Time (s)              22.391425173729658
Epoch Time (s)               80.61554330773652
Total Train Time (s)         7021.8484479291365
Epoch                        84
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:28:00.892404 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #84 | Epoch Duration: 81.92596220970154
2020-01-11 11:28:00.892582 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #84 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1018925
Z variance train             0.028330058
KL Divergence                28.093094
KL Loss                      2.8093095
QF Loss                      1451.8175
VF Loss                      120.89322
Policy Loss                  -1945.1616
Q Predictions Mean           1954.598
Q Predictions Std            637.1124
Q Predictions Max            2620.242
Q Predictions Min            212.45891
V Predictions Mean           1950.2878
V Predictions Std            634.9307
V Predictions Max            2606.7793
V Predictions Min            208.37622
Log Pis Mean                 2.3047783
Log Pis Std                  4.57508
Log Pis Max                  17.197739
Log Pis Min                  -6.2794724
Policy mu Mean               -0.16298713
Policy mu Std                1.1618208
Policy mu Max                2.8657908
Policy mu Min                -3.015986
Policy log std Mean          -0.6190343
Policy log std Std           0.3543062
Policy log std Max           -0.021057993
Policy log std Min           -2.3900938
Z mean eval                  2.1140022
Z variance eval              0.02110885
total_rewards                [6760.27941642 6742.98074972 6707.65063711 6679.25113666 6696.190642
 6855.21397432 6731.10085851 6855.74330612 6789.23215351 6830.71572654]
total_rewards_mean           6764.835860090473
total_rewards_std            61.89605896203413
total_rewards_max            6855.743306124078
total_rewards_min            6679.251136658741
Number of train steps total  86000
Number of env steps total    432000
Number of rollouts total     0
Train Time (s)               31.777977966703475
(Previous) Eval Time (s)     27.85612461809069
Sample Time (s)              22.522625032346696
Epoch Time (s)               82.15672761714086
Total Train Time (s)         7103.869797238149
Epoch                        85
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:29:22.914260 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #85 | Epoch Duration: 82.02155041694641
2020-01-11 11:29:22.914406 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #85 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.112228
Z variance train             0.021010736
KL Divergence                28.432049
KL Loss                      2.843205
QF Loss                      362.76715
VF Loss                      262.61792
Policy Loss                  -1937.0385
Q Predictions Mean           1936.4425
Q Predictions Std            690.8804
Q Predictions Max            2690.564
Q Predictions Min            191.97372
V Predictions Mean           1944.2379
V Predictions Std            684.3185
V Predictions Max            2680.6792
V Predictions Min            210.49422
Log Pis Mean                 2.432567
Log Pis Std                  4.0059767
Log Pis Max                  13.010123
Log Pis Min                  -6.674517
Policy mu Mean               -0.081043266
Policy mu Std                1.1618865
Policy mu Max                3.1702826
Policy mu Min                -2.7782154
Policy log std Mean          -0.6273359
Policy log std Std           0.348233
Policy log std Max           0.05909407
Policy log std Min           -2.234322
Z mean eval                  2.1126835
Z variance eval              0.018164866
total_rewards                [6839.03810333 6555.95161584 6741.67534627 6702.73312704 6481.94097652
 6802.65686198 2412.43893181 6631.2685094  6659.46165728 6629.65464334]
total_rewards_mean           6245.681977281837
total_rewards_std            1281.809701347207
total_rewards_max            6839.038103334925
total_rewards_min            2412.438931811393
Number of train steps total  87000
Number of env steps total    437000
Number of rollouts total     0
Train Time (s)               31.26047171698883
(Previous) Eval Time (s)     27.720649952068925
Sample Time (s)              21.086291301529855
Epoch Time (s)               80.06741297058761
Total Train Time (s)         7183.523848954588
Epoch                        86
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:30:42.573019 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #86 | Epoch Duration: 79.65839886665344
2020-01-11 11:30:42.573401 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #86 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1122093
Z variance train             0.018192524
KL Divergence                27.948612
KL Loss                      2.7948613
QF Loss                      475.8467
VF Loss                      118.64786
Policy Loss                  -1915.0682
Q Predictions Mean           1908.3127
Q Predictions Std            684.91095
Q Predictions Max            2626.552
Q Predictions Min            194.20831
V Predictions Mean           1911.2839
V Predictions Std            677.7635
V Predictions Max            2614.6887
V Predictions Min            201.56479
Log Pis Mean                 2.7419057
Log Pis Std                  4.2740397
Log Pis Max                  13.172458
Log Pis Min                  -6.4256954
Policy mu Mean               -0.06695369
Policy mu Std                1.2126532
Policy mu Max                2.609532
Policy mu Min                -2.8924427
Policy log std Mean          -0.5986962
Policy log std Std           0.3265152
Policy log std Max           0.03910461
Policy log std Min           -2.280141
Z mean eval                  2.1120822
Z variance eval              0.017669603
total_rewards                [6767.18419889 6949.36941714 6603.08756659 6880.87454639 6818.82063983
 6861.73579043 6695.86394742 7048.37480728 6714.21383405 6784.25004562]
total_rewards_mean           6812.377479363035
total_rewards_std            123.07659902729091
total_rewards_max            7048.374807279032
total_rewards_min            6603.087566592673
Number of train steps total  88000
Number of env steps total    442000
Number of rollouts total     0
Train Time (s)               31.77444492187351
(Previous) Eval Time (s)     27.311299308668822
Sample Time (s)              23.21236277744174
Epoch Time (s)               82.29810700798407
Total Train Time (s)         7266.471374774817
Epoch                        87
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:32:05.521085 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #87 | Epoch Duration: 82.94746780395508
2020-01-11 11:32:05.521285 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #87 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1124923
Z variance train             0.017688561
KL Divergence                28.207996
KL Loss                      2.8207996
QF Loss                      466.57025
VF Loss                      214.30792
Policy Loss                  -1963.8219
Q Predictions Mean           1958.6404
Q Predictions Std            730.1865
Q Predictions Max            2711.2788
Q Predictions Min            196.43704
V Predictions Mean           1954.2266
V Predictions Std            726.26306
V Predictions Max            2697.0273
V Predictions Min            204.41394
Log Pis Mean                 2.8433022
Log Pis Std                  4.665374
Log Pis Max                  15.240866
Log Pis Min                  -6.678838
Policy mu Mean               -0.08147884
Policy mu Std                1.2410358
Policy mu Max                3.1264265
Policy mu Min                -2.8271646
Policy log std Mean          -0.60500544
Policy log std Std           0.3651821
Policy log std Max           0.04102108
Policy log std Min           -2.2579112
Z mean eval                  2.1097808
Z variance eval              0.018948661
total_rewards                [6801.84851859 6812.16330308 6831.3982109  6889.64659081 6770.77880587
 6861.66577564 6805.52559288 6784.80240836 6722.74975077 6558.204185  ]
total_rewards_mean           6783.878314191641
total_rewards_std            87.13523771701067
total_rewards_max            6889.6465908081445
total_rewards_min            6558.204184998341
Number of train steps total  89000
Number of env steps total    447000
Number of rollouts total     0
Train Time (s)               32.00230955518782
(Previous) Eval Time (s)     27.96031287126243
Sample Time (s)              22.048906228970736
Epoch Time (s)               82.01152865542099
Total Train Time (s)         7349.015656871721
Epoch                        88
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:33:28.067536 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #88 | Epoch Duration: 82.54603695869446
2020-01-11 11:33:28.067830 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #88 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.110106
Z variance train             0.018981364
KL Divergence                27.951036
KL Loss                      2.7951038
QF Loss                      506.87244
VF Loss                      153.84172
Policy Loss                  -2052.2905
Q Predictions Mean           2055.8228
Q Predictions Std            601.44
Q Predictions Max            2659.5276
Q Predictions Min            192.12689
V Predictions Mean           2056.56
V Predictions Std            596.3299
V Predictions Max            2655.185
V Predictions Min            201.69096
Log Pis Mean                 2.9147983
Log Pis Std                  3.9191172
Log Pis Max                  13.768966
Log Pis Min                  -6.5295362
Policy mu Mean               -0.007997685
Policy mu Std                1.2457504
Policy mu Max                3.5480807
Policy mu Min                -2.9732943
Policy log std Mean          -0.6226627
Policy log std Std           0.3603897
Policy log std Max           0.04567063
Policy log std Min           -2.1778457
Z mean eval                  2.1118426
Z variance eval              0.017422507
total_rewards                [6714.87013567 6884.98832926 7042.79497826 6684.55038662 6934.30109752
 6817.73004192 6931.20631787 6745.69504787 6900.6793934  6812.53539134]
total_rewards_mean           6846.93511197147
total_rewards_std            106.54943378546048
total_rewards_max            7042.7949782627975
total_rewards_min            6684.550386618351
Number of train steps total  90000
Number of env steps total    452000
Number of rollouts total     0
Train Time (s)               31.466287653893232
(Previous) Eval Time (s)     28.494518701918423
Sample Time (s)              22.495821324177086
Epoch Time (s)               82.45662767998874
Total Train Time (s)         7431.434999479912
Epoch                        89
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:34:50.488458 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #89 | Epoch Duration: 82.42046403884888
2020-01-11 11:34:50.488647 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #89 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.112128
Z variance train             0.0174337
KL Divergence                28.180244
KL Loss                      2.8180244
QF Loss                      835.49347
VF Loss                      210.00035
Policy Loss                  -2045.658
Q Predictions Mean           2043.8903
Q Predictions Std            622.3102
Q Predictions Max            2718.1814
Q Predictions Min            197.03322
V Predictions Mean           2049.2231
V Predictions Std            617.7603
V Predictions Max            2730.426
V Predictions Min            199.60341
Log Pis Mean                 3.227231
Log Pis Std                  4.425824
Log Pis Max                  16.957983
Log Pis Min                  -6.6081724
Policy mu Mean               -0.055796485
Policy mu Std                1.2466598
Policy mu Max                4.330242
Policy mu Min                -2.9449768
Policy log std Mean          -0.6300986
Policy log std Std           0.3576951
Policy log std Max           0.03934647
Policy log std Min           -2.2321386
Z mean eval                  2.1186893
Z variance eval              0.017611785
total_rewards                [6813.48761313 6888.99163258 6868.36802793 7026.66711728 6733.32457812
 6878.95312789 6578.33334946 7078.17181731 6755.71313242 6867.10103369]
total_rewards_mean           6848.911142980379
total_rewards_std            135.6058052438946
total_rewards_max            7078.1718173113
total_rewards_min            6578.333349457154
Number of train steps total  91000
Number of env steps total    457000
Number of rollouts total     0
Train Time (s)               32.455909995827824
(Previous) Eval Time (s)     28.45807777205482
Sample Time (s)              23.124376366380602
Epoch Time (s)               84.03836413426325
Total Train Time (s)         7513.782491726801
Epoch                        90
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:36:12.837426 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #90 | Epoch Duration: 82.34864473342896
2020-01-11 11:36:12.837620 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #90 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1175394
Z variance train             0.01759595
KL Divergence                27.9471
KL Loss                      2.79471
QF Loss                      287.48227
VF Loss                      91.46337
Policy Loss                  -2007.4587
Q Predictions Mean           2006.3157
Q Predictions Std            735.9497
Q Predictions Max            2759.633
Q Predictions Min            193.59557
V Predictions Mean           2004.6622
V Predictions Std            732.506
V Predictions Max            2738.8313
V Predictions Min            199.29922
Log Pis Mean                 2.6386476
Log Pis Std                  4.3377843
Log Pis Max                  13.914677
Log Pis Min                  -6.6948643
Policy mu Mean               -0.107962035
Policy mu Std                1.1910582
Policy mu Max                2.5565758
Policy mu Min                -2.6055024
Policy log std Mean          -0.6202526
Policy log std Std           0.35530874
Policy log std Max           0.056209266
Policy log std Min           -2.2930908
Z mean eval                  2.1202505
Z variance eval              0.013820967
total_rewards                [6779.09597663 7175.07871727 7330.15553361 7034.34727864 7026.51673566
 7067.17853818 7008.28033393 7209.93594539 6747.74496621 7007.16710751]
total_rewards_mean           7038.550113303012
total_rewards_std            169.6508686120331
total_rewards_max            7330.155533606854
total_rewards_min            6747.744966214429
Number of train steps total  92000
Number of env steps total    462000
Number of rollouts total     0
Train Time (s)               32.23511420702562
(Previous) Eval Time (s)     26.76800780603662
Sample Time (s)              22.1454661404714
Epoch Time (s)               81.14858815353364
Total Train Time (s)         7596.685723581351
Epoch                        91
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:37:35.742533 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #91 | Epoch Duration: 82.90476846694946
2020-01-11 11:37:35.742737 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #91 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1204176
Z variance train             0.013808973
KL Divergence                28.360386
KL Loss                      2.8360386
QF Loss                      288.9018
VF Loss                      175.24768
Policy Loss                  -2019.5417
Q Predictions Mean           2013.7673
Q Predictions Std            714.5852
Q Predictions Max            2774.7124
Q Predictions Min            197.85751
V Predictions Mean           2011.8303
V Predictions Std            711.487
V Predictions Max            2777.704
V Predictions Min            192.47272
Log Pis Mean                 2.6169648
Log Pis Std                  4.2280393
Log Pis Max                  14.41494
Log Pis Min                  -6.1153097
Policy mu Mean               -0.06642738
Policy mu Std                1.1828641
Policy mu Max                3.0285776
Policy mu Min                -3.0315902
Policy log std Mean          -0.62903917
Policy log std Std           0.35726207
Policy log std Max           0.021601051
Policy log std Min           -2.2929173
Z mean eval                  2.1172786
Z variance eval              0.011871544
total_rewards                [6983.63347062 6778.27900534 6912.16333077 6863.20215314 6803.55488877
 6912.60340925 6486.79388735 7045.45568998 6738.74531046 6868.63059816]
total_rewards_mean           6839.306174385197
total_rewards_std            146.56720314263478
total_rewards_max            7045.455689981259
total_rewards_min            6486.793887354033
Number of train steps total  93000
Number of env steps total    467000
Number of rollouts total     0
Train Time (s)               31.687888253014535
(Previous) Eval Time (s)     28.52386320894584
Sample Time (s)              23.23496784735471
Epoch Time (s)               83.44671930931509
Total Train Time (s)         7679.566983580124
Epoch                        92
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:38:58.625772 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #92 | Epoch Duration: 82.88286972045898
2020-01-11 11:38:58.626028 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #92 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1174304
Z variance train             0.011867834
KL Divergence                28.786076
KL Loss                      2.8786075
QF Loss                      445.09286
VF Loss                      276.53772
Policy Loss                  -2063.1572
Q Predictions Mean           2056.5977
Q Predictions Std            654.83716
Q Predictions Max            2736.2563
Q Predictions Min            178.22464
V Predictions Mean           2055.3574
V Predictions Std            651.06537
V Predictions Max            2759.9446
V Predictions Min            183.11778
Log Pis Mean                 2.8057919
Log Pis Std                  4.4714513
Log Pis Max                  16.774456
Log Pis Min                  -7.1423755
Policy mu Mean               -0.13472456
Policy mu Std                1.2428132
Policy mu Max                2.738569
Policy mu Min                -2.9618506
Policy log std Mean          -0.6322445
Policy log std Std           0.3479886
Policy log std Max           0.0012553483
Policy log std Min           -2.2436156
Z mean eval                  2.1072001
Z variance eval              0.008850307
total_rewards                [6715.22586402 6805.25555951 7102.4767276  6865.50750782 4256.57998419
 6900.19411248 7139.03480449 6662.16356179 7095.34320911 6910.89199455]
total_rewards_mean           6645.267332557145
total_rewards_std            810.9295937733664
total_rewards_max            7139.034804488825
total_rewards_min            4256.579984193225
Number of train steps total  94000
Number of env steps total    472000
Number of rollouts total     0
Train Time (s)               32.32762238429859
(Previous) Eval Time (s)     27.95968560082838
Sample Time (s)              22.991132081951946
Epoch Time (s)               83.27844006707892
Total Train Time (s)         7761.746618331876
Epoch                        93
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:40:20.807412 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #93 | Epoch Duration: 82.18122458457947
2020-01-11 11:40:20.807636 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #93 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1078668
Z variance train             0.008865264
KL Divergence                29.469751
KL Loss                      2.9469752
QF Loss                      327.32654
VF Loss                      123.76684
Policy Loss                  -2007.035
Q Predictions Mean           2007.781
Q Predictions Std            749.353
Q Predictions Max            2741.1887
Q Predictions Min            186.55022
V Predictions Mean           2003.5571
V Predictions Std            746.2945
V Predictions Max            2705.4775
V Predictions Min            188.93533
Log Pis Mean                 2.8261132
Log Pis Std                  4.3259068
Log Pis Max                  15.593731
Log Pis Min                  -4.9157553
Policy mu Mean               -0.043644857
Policy mu Std                1.2247381
Policy mu Max                2.8771842
Policy mu Min                -3.3189218
Policy log std Mean          -0.6332294
Policy log std Std           0.36702898
Policy log std Max           -0.033600748
Policy log std Min           -2.2837336
Z mean eval                  2.1191444
Z variance eval              0.008026131
total_rewards                [6835.60011343 6733.46879938 7050.80796047 6929.79503593 6789.21743635
 6838.60736755 6934.29373986 6970.26275832 6822.22251711 6962.67082431]
total_rewards_mean           6886.69465527071
total_rewards_std            92.66723578910506
total_rewards_max            7050.807960468956
total_rewards_min            6733.468799378648
Number of train steps total  95000
Number of env steps total    477000
Number of rollouts total     0
Train Time (s)               31.791734471917152
(Previous) Eval Time (s)     26.862084524706006
Sample Time (s)              21.60929848300293
Epoch Time (s)               80.26311747962609
Total Train Time (s)         7843.161450934596
Epoch                        94
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:41:42.224575 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #94 | Epoch Duration: 81.41675305366516
2020-01-11 11:41:42.224886 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #94 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1192627
Z variance train             0.008038575
KL Divergence                29.807312
KL Loss                      2.9807312
QF Loss                      320.82248
VF Loss                      251.53008
Policy Loss                  -2085.5803
Q Predictions Mean           2078.0361
Q Predictions Std            716.219
Q Predictions Max            2795.3025
Q Predictions Min            188.09776
V Predictions Mean           2075.9353
V Predictions Std            711.064
V Predictions Max            2792.8374
V Predictions Min            194.62733
Log Pis Mean                 2.8077197
Log Pis Std                  4.5463023
Log Pis Max                  16.072325
Log Pis Min                  -5.6628838
Policy mu Mean               -0.05699371
Policy mu Std                1.2296203
Policy mu Max                2.7341442
Policy mu Min                -2.5883276
Policy log std Mean          -0.64061135
Policy log std Std           0.37037396
Policy log std Max           -0.038245022
Policy log std Min           -2.4186273
Z mean eval                  2.1186175
Z variance eval              0.0071749003
total_rewards                [6851.31883071 7091.39425214 7224.73847447 7278.1994485  6995.87540857
 7378.25215714 7171.23371735 6852.40175692 7170.36554699 6838.76571899]
total_rewards_mean           7085.254531176998
total_rewards_std            183.0018607944202
total_rewards_max            7378.252157136382
total_rewards_min            6838.76571898508
Number of train steps total  96000
Number of env steps total    482000
Number of rollouts total     0
Train Time (s)               31.90249383635819
(Previous) Eval Time (s)     28.01534418016672
Sample Time (s)              22.91089844563976
Epoch Time (s)               82.82873646216467
Total Train Time (s)         7925.049193513114
Epoch                        95
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:43:04.113324 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #95 | Epoch Duration: 81.8882155418396
2020-01-11 11:43:04.113497 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #95 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1162438
Z variance train             0.0071644313
KL Divergence                30.30085
KL Loss                      3.030085
QF Loss                      464.3106
VF Loss                      220.29218
Policy Loss                  -2092.5344
Q Predictions Mean           2091.3926
Q Predictions Std            669.70264
Q Predictions Max            2793.803
Q Predictions Min            181.58452
V Predictions Mean           2097.6978
V Predictions Std            669.6082
V Predictions Max            2777.4092
V Predictions Min            181.1402
Log Pis Mean                 2.2486963
Log Pis Std                  4.134164
Log Pis Max                  13.612854
Log Pis Min                  -5.9579945
Policy mu Mean               0.0090423245
Policy mu Std                1.1739162
Policy mu Max                2.730339
Policy mu Min                -2.6667879
Policy log std Mean          -0.6431652
Policy log std Std           0.3598806
Policy log std Max           -0.054006934
Policy log std Min           -2.2048943
Z mean eval                  2.134063
Z variance eval              0.005682435
total_rewards                [7055.40523255 7177.82566413 5143.05560085 7145.24726666 6993.00954606
 3477.99877738 7009.16716847 6717.94774776 6931.86664131 6934.35264699]
total_rewards_mean           6458.587629214582
total_rewards_std            1143.0611594456557
total_rewards_max            7177.825664131643
total_rewards_min            3477.99877737707
Number of train steps total  97000
Number of env steps total    487000
Number of rollouts total     0
Train Time (s)               31.849084697198123
(Previous) Eval Time (s)     27.07452030479908
Sample Time (s)              22.555999418720603
Epoch Time (s)               81.4796044207178
Total Train Time (s)         8006.473046441097
Epoch                        96
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:44:25.539054 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #96 | Epoch Duration: 81.42540836334229
2020-01-11 11:44:25.539260 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #96 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1371675
Z variance train             0.00568719
KL Divergence                31.357662
KL Loss                      3.1357663
QF Loss                      280.57385
VF Loss                      356.23404
Policy Loss                  -2116.6597
Q Predictions Mean           2110.7603
Q Predictions Std            686.72235
Q Predictions Max            2871.4963
Q Predictions Min            197.71082
V Predictions Mean           2101.2236
V Predictions Std            682.7245
V Predictions Max            2860.786
V Predictions Min            195.21568
Log Pis Mean                 3.4897428
Log Pis Std                  4.1962047
Log Pis Max                  14.266742
Log Pis Min                  -5.5196714
Policy mu Mean               -0.09966087
Policy mu Std                1.268674
Policy mu Max                2.8053565
Policy mu Min                -3.0533977
Policy log std Mean          -0.65864867
Policy log std Std           0.3691005
Policy log std Max           0.033157796
Policy log std Min           -2.35281
Z mean eval                  2.1503696
Z variance eval              0.0053493693
total_rewards                [7078.17292316 7240.5019635  7238.84420118 7232.5832005  7460.92613744
 6996.14090442 7006.86617906 7327.31194015 7107.67501884 7109.62599625]
total_rewards_mean           7179.864846450076
total_rewards_std            139.58505800344452
total_rewards_max            7460.926137436067
total_rewards_min            6996.140904420887
Number of train steps total  98000
Number of env steps total    492000
Number of rollouts total     0
Train Time (s)               31.98550223885104
(Previous) Eval Time (s)     27.020043678116053
Sample Time (s)              22.074924333952367
Epoch Time (s)               81.08047025091946
Total Train Time (s)         8088.1016197912395
Epoch                        97
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:45:47.169939 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #97 | Epoch Duration: 81.63052868843079
2020-01-11 11:45:47.170121 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #97 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.148963
Z variance train             0.0053339778
KL Divergence                31.565243
KL Loss                      3.1565244
QF Loss                      380.07614
VF Loss                      212.30496
Policy Loss                  -2134.048
Q Predictions Mean           2134.5652
Q Predictions Std            677.5153
Q Predictions Max            2860.344
Q Predictions Min            187.1003
V Predictions Mean           2143.7783
V Predictions Std            674.9054
V Predictions Max            2829.2566
V Predictions Min            184.64319
Log Pis Mean                 3.5662358
Log Pis Std                  4.3476176
Log Pis Max                  13.570621
Log Pis Min                  -7.1309032
Policy mu Mean               -0.1348129
Policy mu Std                1.2938145
Policy mu Max                3.1469343
Policy mu Min                -3.1639054
Policy log std Mean          -0.65423644
Policy log std Std           0.35299584
Policy log std Max           -0.06714463
Policy log std Min           -2.2436695
Z mean eval                  2.1320581
Z variance eval              0.004439346
total_rewards                [6892.44296666 7117.78435908 7267.55180856 6926.61496555 7159.47947329
 7104.77421176 7233.85590234 7052.7586227  6946.87606007 7134.1111035 ]
total_rewards_mean           7083.62494735283
total_rewards_std            121.31406359957607
total_rewards_max            7267.551808563098
total_rewards_min            6892.442966662097
Number of train steps total  99000
Number of env steps total    497000
Number of rollouts total     0
Train Time (s)               31.792365617584437
(Previous) Eval Time (s)     27.569824036676437
Sample Time (s)              23.15028202859685
Epoch Time (s)               82.51247168285772
Total Train Time (s)         8170.449477254413
Epoch                        98
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:47:09.520762 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #98 | Epoch Duration: 82.35050177574158
2020-01-11 11:47:09.520954 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #98 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1291676
Z variance train             0.004429465
KL Divergence                32.194828
KL Loss                      3.219483
QF Loss                      450.18982
VF Loss                      631.0471
Policy Loss                  -2177.9539
Q Predictions Mean           2184.2803
Q Predictions Std            685.8927
Q Predictions Max            2875.6655
Q Predictions Min            175.13774
V Predictions Mean           2199.931
V Predictions Std            685.0158
V Predictions Max            2887.877
V Predictions Min            186.33867
Log Pis Mean                 3.176488
Log Pis Std                  4.6382437
Log Pis Max                  17.059273
Log Pis Min                  -9.317337
Policy mu Mean               -0.13251558
Policy mu Std                1.2626597
Policy mu Max                3.1459513
Policy mu Min                -2.9884877
Policy log std Mean          -0.64590496
Policy log std Std           0.3594624
Policy log std Max           -0.0053099394
Policy log std Min           -2.370951
Z mean eval                  2.131353
Z variance eval              0.0036839545
total_rewards                [6899.71682717 7320.73298889 7199.8930073  7163.88799184 6998.40959845
 7250.86717397 7302.9521925  7171.56097303 7046.77989204 7050.13059071]
total_rewards_mean           7140.493123590006
total_rewards_std            130.84768877513184
total_rewards_max            7320.732988893716
total_rewards_min            6899.716827168728
Number of train steps total  100000
Number of env steps total    502000
Number of rollouts total     0
Train Time (s)               31.881872869096696
(Previous) Eval Time (s)     27.407501507084817
Sample Time (s)              23.42759629059583
Epoch Time (s)               82.71697066677734
Total Train Time (s)         8253.326687164139
Epoch                        99
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:48:32.399009 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #99 | Epoch Duration: 82.87791419029236
2020-01-11 11:48:32.399222 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #99 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.131139
Z variance train             0.0036748268
KL Divergence                32.50668
KL Loss                      3.250668
QF Loss                      574.34094
VF Loss                      239.89857
Policy Loss                  -2051.0068
Q Predictions Mean           2049.7236
Q Predictions Std            790.1528
Q Predictions Max            2877.0508
Q Predictions Min            177.79305
V Predictions Mean           2058.7808
V Predictions Std            785.891
V Predictions Max            2881.9502
V Predictions Min            181.6676
Log Pis Mean                 3.212482
Log Pis Std                  4.598144
Log Pis Max                  15.460869
Log Pis Min                  -9.032459
Policy mu Mean               -0.047839742
Policy mu Std                1.2521594
Policy mu Max                3.6966214
Policy mu Min                -5.0537553
Policy log std Mean          -0.6386722
Policy log std Std           0.35279524
Policy log std Max           0.016781896
Policy log std Min           -2.2599518
Z mean eval                  2.140799
Z variance eval              0.0036377453
total_rewards                [7227.34234386 7124.43252943 7157.90265136 7008.05203563 7132.55745653
 7211.51122127 7382.11657567 7156.16241376 7208.88108197 7139.78598931]
total_rewards_mean           7174.874429879261
total_rewards_std            90.6835696865784
total_rewards_max            7382.116575672344
total_rewards_min            7008.052035634384
Number of train steps total  101000
Number of env steps total    507000
Number of rollouts total     0
Train Time (s)               32.35200693504885
(Previous) Eval Time (s)     27.5681062489748
Sample Time (s)              22.080661674495786
Epoch Time (s)               82.00077485851943
Total Train Time (s)         8335.207479867619
Epoch                        100
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:49:54.281880 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #100 | Epoch Duration: 81.88250160217285
2020-01-11 11:49:54.282112 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #100 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.137263
Z variance train             0.0036380868
KL Divergence                32.16594
KL Loss                      3.216594
QF Loss                      489.71283
VF Loss                      490.662
Policy Loss                  -2134.3386
Q Predictions Mean           2138.532
Q Predictions Std            714.7278
Q Predictions Max            2896.4895
Q Predictions Min            166.85074
V Predictions Mean           2152.772
V Predictions Std            714.1172
V Predictions Max            2901.6553
V Predictions Min            176.99907
Log Pis Mean                 3.1143703
Log Pis Std                  4.2532215
Log Pis Max                  13.659947
Log Pis Min                  -7.444617
Policy mu Mean               -0.073867775
Policy mu Std                1.2631724
Policy mu Max                2.997128
Policy mu Min                -2.9464452
Policy log std Mean          -0.6527584
Policy log std Std           0.36855367
Policy log std Max           0.0048601627
Policy log std Min           -2.3027902
Z mean eval                  2.1204114
Z variance eval              0.0051975
total_rewards                [7096.07603631 7304.90372859 7211.44010684 7172.73403248 7417.0705852
 7473.29884131 7046.34190952 7204.8240059  7351.21975079 7043.59483481]
total_rewards_mean           7232.150383176342
total_rewards_std            143.21968590248912
total_rewards_max            7473.298841310296
total_rewards_min            7043.594834810469
Number of train steps total  102000
Number of env steps total    512000
Number of rollouts total     0
Train Time (s)               33.35786796268076
(Previous) Eval Time (s)     27.449537944048643
Sample Time (s)              22.00178477121517
Epoch Time (s)               82.80919067794457
Total Train Time (s)         8419.313698085956
Epoch                        101
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:51:18.390385 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #101 | Epoch Duration: 84.10811448097229
2020-01-11 11:51:18.390611 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #101 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1169312
Z variance train             0.0052031027
KL Divergence                31.4827
KL Loss                      3.1482701
QF Loss                      346.35223
VF Loss                      169.10416
Policy Loss                  -2219.5642
Q Predictions Mean           2219.6973
Q Predictions Std            636.3301
Q Predictions Max            2940.0
Q Predictions Min            171.89912
V Predictions Mean           2226.9697
V Predictions Std            631.1763
V Predictions Max            2926.5706
V Predictions Min            182.79803
Log Pis Mean                 3.003573
Log Pis Std                  4.415983
Log Pis Max                  15.49664
Log Pis Min                  -5.2680445
Policy mu Mean               -0.07170412
Policy mu Std                1.235413
Policy mu Max                2.7958124
Policy mu Min                -2.86961
Policy log std Mean          -0.6550223
Policy log std Std           0.36406028
Policy log std Max           0.0028227568
Policy log std Min           -2.1966865
Z mean eval                  2.1211767
Z variance eval              0.010084364
total_rewards                [7037.67945928 7430.45699401 7147.78068049 7077.46946984 7320.24929776
 7245.54356773 6999.79319027 7265.97780183 7075.99664207 7047.62483679]
total_rewards_mean           7164.857194007325
total_rewards_std            135.7990332650425
total_rewards_max            7430.456994005418
total_rewards_min            6999.79319026626
Number of train steps total  103000
Number of env steps total    517000
Number of rollouts total     0
Train Time (s)               34.44724034098908
(Previous) Eval Time (s)     28.74812363088131
Sample Time (s)              23.831363868899643
Epoch Time (s)               87.02672784077004
Total Train Time (s)         8507.310651890468
Epoch                        102
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:52:46.389833 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #102 | Epoch Duration: 87.99907684326172
2020-01-11 11:52:46.390024 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #102 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1185086
Z variance train             0.010065323
KL Divergence                30.537508
KL Loss                      3.0537508
QF Loss                      363.68954
VF Loss                      117.62398
Policy Loss                  -2229.6921
Q Predictions Mean           2229.7937
Q Predictions Std            675.51654
Q Predictions Max            2885.7068
Q Predictions Min            178.32274
V Predictions Mean           2228.5193
V Predictions Std            674.758
V Predictions Max            2880.8413
V Predictions Min            173.64786
Log Pis Mean                 3.4511132
Log Pis Std                  4.364775
Log Pis Max                  14.622446
Log Pis Min                  -7.099739
Policy mu Mean               -0.09909111
Policy mu Std                1.2671685
Policy mu Max                2.7829292
Policy mu Min                -2.7473803
Policy log std Mean          -0.6473047
Policy log std Std           0.34630036
Policy log std Max           -0.07612109
Policy log std Min           -2.4121976
Z mean eval                  2.106296
Z variance eval              0.009802744
total_rewards                [7113.18753162 7426.62367965 7141.4547043  7345.4977043  7170.6601782
 7537.61384165 7426.6493299  7343.14136494 7083.99668239 7193.90916856]
total_rewards_mean           7278.273418551548
total_rewards_std            149.13809646831518
total_rewards_max            7537.613841654994
total_rewards_min            7083.996682387271
Number of train steps total  104000
Number of env steps total    522000
Number of rollouts total     0
Train Time (s)               34.00727264303714
(Previous) Eval Time (s)     29.720013650134206
Sample Time (s)              24.55756931938231
Epoch Time (s)               88.28485561255366
Total Train Time (s)         8594.27070953697
Epoch                        103
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:54:13.351756 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #103 | Epoch Duration: 86.96158695220947
2020-01-11 11:54:13.351952 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #103 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1070285
Z variance train             0.009765396
KL Divergence                29.947784
KL Loss                      2.9947784
QF Loss                      338.114
VF Loss                      286.04062
Policy Loss                  -2113.373
Q Predictions Mean           2116.8232
Q Predictions Std            822.12726
Q Predictions Max            2933.0005
Q Predictions Min            185.27792
V Predictions Mean           2100.2634
V Predictions Std            818.3948
V Predictions Max            2890.8237
V Predictions Min            172.71957
Log Pis Mean                 2.7631838
Log Pis Std                  4.3388033
Log Pis Max                  14.716442
Log Pis Min                  -5.554622
Policy mu Mean               0.0071986
Policy mu Std                1.1983473
Policy mu Max                3.0830958
Policy mu Min                -2.8514168
Policy log std Mean          -0.6178236
Policy log std Std           0.36823186
Policy log std Max           -0.033277005
Policy log std Min           -2.2644005
Z mean eval                  2.1128974
Z variance eval              0.011359483
total_rewards                [7059.20889698 7427.5308194  7397.09379276 7350.16945831 7342.9628902
 7149.64614178 7305.72909953 7141.38206092 7490.09662668 7046.60521533]
total_rewards_mean           7271.042500187781
total_rewards_std            150.92828977607954
total_rewards_max            7490.0966266828955
total_rewards_min            7046.605215329578
Number of train steps total  105000
Number of env steps total    527000
Number of rollouts total     0
Train Time (s)               34.184664546046406
(Previous) Eval Time (s)     28.39627891406417
Sample Time (s)              23.08108240040019
Epoch Time (s)               85.66202586051077
Total Train Time (s)         8680.394489575643
Epoch                        104
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:55:39.476173 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #104 | Epoch Duration: 86.12408566474915
2020-01-11 11:55:39.476320 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #104 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1126962
Z variance train             0.011354087
KL Divergence                29.984858
KL Loss                      2.9984858
QF Loss                      401.4806
VF Loss                      167.92606
Policy Loss                  -2196.6252
Q Predictions Mean           2197.8784
Q Predictions Std            753.9764
Q Predictions Max            2891.858
Q Predictions Min            169.8377
V Predictions Mean           2199.7842
V Predictions Std            751.18396
V Predictions Max            2887.9424
V Predictions Min            164.96953
Log Pis Mean                 3.0556073
Log Pis Std                  4.4909596
Log Pis Max                  15.20136
Log Pis Min                  -5.9642563
Policy mu Mean               -0.077390276
Policy mu Std                1.260786
Policy mu Max                3.2304842
Policy mu Min                -3.1529126
Policy log std Mean          -0.64260054
Policy log std Std           0.3673946
Policy log std Max           0.016211003
Policy log std Min           -2.4225721
Z mean eval                  2.1097214
Z variance eval              0.0081944475
total_rewards                [7495.04495877 7485.4193152  7699.20669265 7660.93403681 7601.81081139
 7453.04068446 7411.19260523 7635.50219021 7639.55123677 7627.52508351]
total_rewards_mean           7570.922761499535
total_rewards_std            94.90798099970795
total_rewards_max            7699.206692649361
total_rewards_min            7411.192605227635
Number of train steps total  106000
Number of env steps total    532000
Number of rollouts total     0
Train Time (s)               34.14707150636241
(Previous) Eval Time (s)     28.857904695905745
Sample Time (s)              23.630060674156994
Epoch Time (s)               86.63503687642515
Total Train Time (s)         8766.770439348184
Epoch                        105
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:57:05.856328 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #105 | Epoch Duration: 86.37984776496887
2020-01-11 11:57:05.856644 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #105 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1101084
Z variance train             0.008187551
KL Divergence                30.295332
KL Loss                      3.0295331
QF Loss                      388.31555
VF Loss                      164.54356
Policy Loss                  -2255.5042
Q Predictions Mean           2246.1108
Q Predictions Std            695.3236
Q Predictions Max            2916.2031
Q Predictions Min            172.19154
V Predictions Mean           2247.1262
V Predictions Std            694.957
V Predictions Max            2906.462
V Predictions Min            163.66127
Log Pis Mean                 3.3098376
Log Pis Std                  4.6179943
Log Pis Max                  16.971157
Log Pis Min                  -6.105455
Policy mu Mean               -0.14203691
Policy mu Std                1.245393
Policy mu Max                3.0177863
Policy mu Min                -2.7432668
Policy log std Mean          -0.63918823
Policy log std Std           0.3502886
Policy log std Max           0.008238822
Policy log std Min           -2.283938
Z mean eval                  2.095262
Z variance eval              0.04059807
total_rewards                [7266.99168518 7534.22600104 7335.08284463 7265.61446801 7158.20934963
 7239.09743025 7397.50628294 7381.47335685 7208.09847981 7203.70352608]
total_rewards_mean           7299.00034244197
total_rewards_std            107.71840185543418
total_rewards_max            7534.226001044297
total_rewards_min            7158.209349632185
Number of train steps total  107000
Number of env steps total    537000
Number of rollouts total     0
Train Time (s)               33.779819475952536
(Previous) Eval Time (s)     28.602082048077136
Sample Time (s)              23.058954121544957
Epoch Time (s)               85.44085564557463
Total Train Time (s)         8852.270060225856
Epoch                        106
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:58:31.357175 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #106 | Epoch Duration: 85.50035738945007
2020-01-11 11:58:31.357383 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #106 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.096887
Z variance train             0.041200936
KL Divergence                29.510897
KL Loss                      2.9510896
QF Loss                      435.24957
VF Loss                      130.59377
Policy Loss                  -2267.9514
Q Predictions Mean           2270.836
Q Predictions Std            673.9038
Q Predictions Max            2933.276
Q Predictions Min            166.89392
V Predictions Mean           2270.0464
V Predictions Std            668.8757
V Predictions Max            2933.5588
V Predictions Min            173.94849
Log Pis Mean                 2.9219365
Log Pis Std                  4.3837347
Log Pis Max                  14.883076
Log Pis Min                  -8.072243
Policy mu Mean               -0.06263662
Policy mu Std                1.2403475
Policy mu Max                2.7912946
Policy mu Min                -2.7753944
Policy log std Mean          -0.66427964
Policy log std Std           0.3657315
Policy log std Max           -0.023473322
Policy log std Min           -2.4917445
Z mean eval                  2.110065
Z variance eval              0.03850005
total_rewards                [7042.28089531 7199.36306973 7487.29894194 7083.1903505  7061.10726149
 7106.20028341 7036.08925792 7064.27313291 7184.57379157 6957.45550965]
total_rewards_mean           7122.183249442574
total_rewards_std            138.9065593898401
total_rewards_max            7487.29894193724
total_rewards_min            6957.455509649512
Number of train steps total  108000
Number of env steps total    542000
Number of rollouts total     0
Train Time (s)               34.783489307854325
(Previous) Eval Time (s)     28.66121829301119
Sample Time (s)              23.639052606653422
Epoch Time (s)               87.08376020751894
Total Train Time (s)         8940.213014943525
Epoch                        107
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:59:59.302917 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #107 | Epoch Duration: 87.94535422325134
2020-01-11 11:59:59.303284 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #107 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1122518
Z variance train             0.03854538
KL Divergence                29.685438
KL Loss                      2.9685438
QF Loss                      419.8003
VF Loss                      327.24115
Policy Loss                  -2178.456
Q Predictions Mean           2167.748
Q Predictions Std            699.14777
Q Predictions Max            2931.8936
Q Predictions Min            149.54788
V Predictions Mean           2165.563
V Predictions Std            691.4845
V Predictions Max            2930.138
V Predictions Min            158.81248
Log Pis Mean                 3.1352925
Log Pis Std                  4.456382
Log Pis Max                  13.170013
Log Pis Min                  -6.8989496
Policy mu Mean               -0.12077254
Policy mu Std                1.2631902
Policy mu Max                2.842502
Policy mu Min                -2.6692502
Policy log std Mean          -0.64496577
Policy log std Std           0.34558335
Policy log std Max           -0.045044303
Policy log std Min           -2.1963277
Z mean eval                  2.149693
Z variance eval              0.009720111
total_rewards                [7269.0269355  7511.68337783 7780.37946299 7560.96827885 7305.55452067
 7276.84506873 7554.11541697 7557.26837466 7306.04288581 7138.77855381]
total_rewards_mean           7426.066287582199
total_rewards_std            185.22108465979085
total_rewards_max            7780.3794629942095
total_rewards_min            7138.77855380896
Number of train steps total  109000
Number of env steps total    547000
Number of rollouts total     0
Train Time (s)               34.006360894069076
(Previous) Eval Time (s)     29.522449960932136
Sample Time (s)              24.776930660475045
Epoch Time (s)               88.30574151547626
Total Train Time (s)         9026.360802510288
Epoch                        108
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:01:25.452563 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #108 | Epoch Duration: 86.1490683555603
2020-01-11 12:01:25.452815 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #108 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1500878
Z variance train             0.009722221
KL Divergence                31.468628
KL Loss                      3.1468627
QF Loss                      542.267
VF Loss                      113.64594
Policy Loss                  -2191.5027
Q Predictions Mean           2190.2854
Q Predictions Std            824.22015
Q Predictions Max            2988.3794
Q Predictions Min            154.43639
V Predictions Mean           2191.1694
V Predictions Std            820.74585
V Predictions Max            2977.3582
V Predictions Min            160.19589
Log Pis Mean                 3.163113
Log Pis Std                  4.3687115
Log Pis Max                  12.804199
Log Pis Min                  -6.0463285
Policy mu Mean               -0.059833843
Policy mu Std                1.2605726
Policy mu Max                2.8894713
Policy mu Min                -2.8688948
Policy log std Mean          -0.62063426
Policy log std Std           0.34014478
Policy log std Max           0.01679194
Policy log std Min           -2.195249
Z mean eval                  2.1309724
Z variance eval              0.010476066
total_rewards                [7110.2740164  7188.31157362 6942.48972325 6696.87810133 7015.37067782
 7332.66010995 7481.70183404 7248.71863941 7324.07205204 7324.38506716]
total_rewards_mean           7166.486179501716
total_rewards_std            219.24425577304612
total_rewards_max            7481.701834044574
total_rewards_min            6696.878101333877
Number of train steps total  110000
Number of env steps total    552000
Number of rollouts total     0
Train Time (s)               34.381796058733016
(Previous) Eval Time (s)     27.365319018252194
Sample Time (s)              23.458883432671428
Epoch Time (s)               85.20599850965664
Total Train Time (s)         9113.569654759485
Epoch                        109
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:02:52.664361 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #109 | Epoch Duration: 87.21135258674622
2020-01-11 12:02:52.664716 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #109 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1322606
Z variance train             0.0104754735
KL Divergence                30.337208
KL Loss                      3.0337207
QF Loss                      436.74054
VF Loss                      321.33188
Policy Loss                  -2320.1653
Q Predictions Mean           2311.6775
Q Predictions Std            680.76337
Q Predictions Max            2949.6042
Q Predictions Min            168.14175
V Predictions Mean           2317.2646
V Predictions Std            676.6763
V Predictions Max            2954.089
V Predictions Min            162.77443
Log Pis Mean                 3.1494603
Log Pis Std                  4.399215
Log Pis Max                  15.787262
Log Pis Min                  -8.497261
Policy mu Mean               -0.08499023
Policy mu Std                1.2471751
Policy mu Max                3.7374082
Policy mu Min                -3.1960382
Policy log std Mean          -0.64397174
Policy log std Std           0.3569181
Policy log std Max           0.04184243
Policy log std Min           -2.2648249
Z mean eval                  2.1494312
Z variance eval              0.009230427
total_rewards                [7410.94248404 7901.22444622 7581.64811442 7649.40208446 7391.39969899
 7486.57584616 7548.10861527 7515.72745003 7557.45377383 7329.71765727]
total_rewards_mean           7537.22001706827
total_rewards_std            151.9471734932087
total_rewards_max            7901.224446224628
total_rewards_min            7329.717657268471
Number of train steps total  111000
Number of env steps total    557000
Number of rollouts total     0
Train Time (s)               33.58071416430175
(Previous) Eval Time (s)     29.370236618909985
Sample Time (s)              23.790479606948793
Epoch Time (s)               86.74143039016053
Total Train Time (s)         9199.382819779217
Epoch                        110
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:04:18.479294 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #110 | Epoch Duration: 85.81439399719238
2020-01-11 12:04:18.479504 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #110 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1509123
Z variance train             0.009226255
KL Divergence                30.31403
KL Loss                      3.031403
QF Loss                      475.03714
VF Loss                      116.80836
Policy Loss                  -2306.9548
Q Predictions Mean           2305.411
Q Predictions Std            779.14246
Q Predictions Max            3042.805
Q Predictions Min            159.17107
V Predictions Mean           2307.392
V Predictions Std            778.1978
V Predictions Max            3060.7253
V Predictions Min            167.01123
Log Pis Mean                 4.106906
Log Pis Std                  4.8126283
Log Pis Max                  15.842436
Log Pis Min                  -5.982725
Policy mu Mean               -0.093729
Policy mu Std                1.3142086
Policy mu Max                2.9010594
Policy mu Min                -2.9167616
Policy log std Mean          -0.64378065
Policy log std Std           0.3620565
Policy log std Max           -0.025357336
Policy log std Min           -2.3988056
Z mean eval                  2.1385007
Z variance eval              0.018369805
total_rewards                [7338.56976998 7593.3225492  7557.56389928 7307.87774659 7256.93559413
 7641.40468065 7175.28000583 7472.94346339 7408.10199588 7366.28167047]
total_rewards_mean           7411.8281375407805
total_rewards_std            144.50853314756424
total_rewards_max            7641.404680651087
total_rewards_min            7175.280005828779
Number of train steps total  112000
Number of env steps total    562000
Number of rollouts total     0
Train Time (s)               31.93513130908832
(Previous) Eval Time (s)     28.4428558209911
Sample Time (s)              21.790069838054478
Epoch Time (s)               82.1680569681339
Total Train Time (s)         9282.141971101053
Epoch                        111
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:05:41.255237 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #111 | Epoch Duration: 82.77557325363159
2020-01-11 12:05:41.255420 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #111 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1355731
Z variance train             0.01845999
KL Divergence                28.22334
KL Loss                      2.822334
QF Loss                      698.6847
VF Loss                      235.12639
Policy Loss                  -2323.7397
Q Predictions Mean           2320.0369
Q Predictions Std            701.5083
Q Predictions Max            3060.404
Q Predictions Min            156.99994
V Predictions Mean           2332.276
V Predictions Std            700.72266
V Predictions Max            3081.8171
V Predictions Min            163.65865
Log Pis Mean                 3.5314102
Log Pis Std                  4.146191
Log Pis Max                  12.478049
Log Pis Min                  -5.905792
Policy mu Mean               -0.087601684
Policy mu Std                1.2884964
Policy mu Max                3.0241313
Policy mu Min                -2.5319161
Policy log std Mean          -0.6545729
Policy log std Std           0.36815608
Policy log std Max           -0.10518041
Policy log std Min           -2.4717531
Z mean eval                  2.1263278
Z variance eval              0.07237793
total_rewards                [7508.97389381 7683.48736609 7668.00839604 7656.18637422 7702.22575994
 7610.4003947  7411.93828888 7421.20731451 7485.01578733 7839.43160801]
total_rewards_mean           7598.687518353663
total_rewards_std            130.94345598847494
total_rewards_max            7839.431608013015
total_rewards_min            7411.938288878392
Number of train steps total  113000
Number of env steps total    567000
Number of rollouts total     0
Train Time (s)               32.07003004895523
(Previous) Eval Time (s)     29.05005435924977
Sample Time (s)              22.26452341163531
Epoch Time (s)               83.38460781984031
Total Train Time (s)         9364.94206942711
Epoch                        112
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:07:04.041928 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #112 | Epoch Duration: 82.78637194633484
2020-01-11 12:07:04.042115 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #112 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1255012
Z variance train             0.07253233
KL Divergence                27.594051
KL Loss                      2.7594051
QF Loss                      722.95123
VF Loss                      323.3188
Policy Loss                  -2295.397
Q Predictions Mean           2288.9878
Q Predictions Std            766.8266
Q Predictions Max            3029.2751
Q Predictions Min            144.04811
V Predictions Mean           2285.996
V Predictions Std            762.952
V Predictions Max            3003.464
V Predictions Min            150.39314
Log Pis Mean                 3.8741899
Log Pis Std                  4.423392
Log Pis Max                  16.436085
Log Pis Min                  -6.2528644
Policy mu Mean               -0.19308896
Policy mu Std                1.3314401
Policy mu Max                3.2212152
Policy mu Min                -3.2202108
Policy log std Mean          -0.64146364
Policy log std Std           0.35202777
Policy log std Max           0.007009983
Policy log std Min           -2.2213311
Z mean eval                  2.1594284
Z variance eval              0.03528331
total_rewards                [7526.59799172 7420.83608399 7026.77649788 7600.56338907  784.91780135
 7516.07841832 7561.65901374 7433.14114581 7321.06056313 7565.60694412]
total_rewards_mean           6775.723784914667
total_rewards_std            2003.308525494748
total_rewards_max            7600.563389073999
total_rewards_min            784.9178013546275
Number of train steps total  114000
Number of env steps total    572000
Number of rollouts total     0
Train Time (s)               31.73837530054152
(Previous) Eval Time (s)     28.45150250289589
Sample Time (s)              22.683589450083673
Epoch Time (s)               82.87346725352108
Total Train Time (s)         9446.612814343069
Epoch                        113
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:08:25.713277 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #113 | Epoch Duration: 81.67098832130432
2020-01-11 12:08:25.713423 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #113 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1590898
Z variance train             0.035337083
KL Divergence                28.689764
KL Loss                      2.8689764
QF Loss                      352.23053
VF Loss                      223.04655
Policy Loss                  -2406.429
Q Predictions Mean           2409.4817
Q Predictions Std            708.21387
Q Predictions Max            3114.1982
Q Predictions Min            165.5045
V Predictions Mean           2405.2268
V Predictions Std            705.40735
V Predictions Max            3107.8748
V Predictions Min            170.6744
Log Pis Mean                 3.5988455
Log Pis Std                  4.2451525
Log Pis Max                  14.981598
Log Pis Min                  -7.4913607
Policy mu Mean               -0.009034869
Policy mu Std                1.2759578
Policy mu Max                3.0347803
Policy mu Min                -2.726309
Policy log std Mean          -0.65901405
Policy log std Std           0.36898822
Policy log std Max           0.0045678318
Policy log std Min           -2.2644408
Z mean eval                  2.144406
Z variance eval              0.026352052
total_rewards                [7456.91857808 7611.25785799 7394.77075579 7704.47061088 7683.77381022
 7902.03192819 7458.48265036 7898.24934662 7520.51377    7858.62842472]
total_rewards_mean           7648.909773285304
total_rewards_std            181.6971153914399
total_rewards_max            7902.031928187303
total_rewards_min            7394.770755794435
Number of train steps total  115000
Number of env steps total    577000
Number of rollouts total     0
Train Time (s)               32.58432270120829
(Previous) Eval Time (s)     27.248720303643495
Sample Time (s)              21.70526448637247
Epoch Time (s)               81.53830749122426
Total Train Time (s)         9529.647103800438
Epoch                        114
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:09:48.750664 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #114 | Epoch Duration: 83.03710699081421
2020-01-11 12:09:48.750881 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #114 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1429608
Z variance train             0.026342865
KL Divergence                28.007057
KL Loss                      2.8007057
QF Loss                      529.9026
VF Loss                      222.46034
Policy Loss                  -2315.4573
Q Predictions Mean           2317.126
Q Predictions Std            748.0376
Q Predictions Max            3078.0469
Q Predictions Min            155.15051
V Predictions Mean           2319.1604
V Predictions Std            746.3554
V Predictions Max            3033.578
V Predictions Min            156.50874
Log Pis Mean                 3.3010983
Log Pis Std                  4.543342
Log Pis Max                  14.195842
Log Pis Min                  -7.350049
Policy mu Mean               -0.1349045
Policy mu Std                1.2720443
Policy mu Max                3.7773933
Policy mu Min                -2.8201857
Policy log std Mean          -0.6450735
Policy log std Std           0.351397
Policy log std Max           -0.018994838
Policy log std Min           -2.329298
Z mean eval                  2.1672196
Z variance eval              0.030491525
total_rewards                [7389.10326874 7377.48118158 7722.08784378 7679.9598871  7735.5752469
 7947.98033704 7663.10609671 7268.07788803 7576.92504352 7545.03130575]
total_rewards_mean           7590.532809915579
total_rewards_std            192.76266376691282
total_rewards_max            7947.9803370390355
total_rewards_min            7268.0778880336775
Number of train steps total  116000
Number of env steps total    582000
Number of rollouts total     0
Train Time (s)               32.1136109828949
(Previous) Eval Time (s)     28.747202422935516
Sample Time (s)              22.124507736880332
Epoch Time (s)               82.98532114271075
Total Train Time (s)         9610.944065124262
Epoch                        115
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:11:10.064147 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #115 | Epoch Duration: 81.31309604644775
2020-01-11 12:11:10.064427 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #115 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.166699
Z variance train             0.030564994
KL Divergence                28.413616
KL Loss                      2.8413618
QF Loss                      518.5525
VF Loss                      147.1306
Policy Loss                  -2352.0217
Q Predictions Mean           2343.3271
Q Predictions Std            747.1976
Q Predictions Max            3112.5164
Q Predictions Min            154.86742
V Predictions Mean           2345.8267
V Predictions Std            743.34296
V Predictions Max            3097.377
V Predictions Min            163.76198
Log Pis Mean                 3.3147008
Log Pis Std                  4.5653906
Log Pis Max                  15.8278055
Log Pis Min                  -5.8372893
Policy mu Mean               -0.027875898
Policy mu Std                1.2779633
Policy mu Max                2.9703162
Policy mu Min                -3.1395283
Policy log std Mean          -0.6682063
Policy log std Std           0.3874564
Policy log std Max           0.0154545605
Policy log std Min           -2.7174525
Z mean eval                  2.1401494
Z variance eval              0.023749918
total_rewards                [7373.57146268 7549.53692103 7584.10930499 7647.21837991 7725.99937749
 7490.91287627 7396.47495376 7390.76454638 7576.31709766 7516.29413311]
total_rewards_mean           7525.119905326277
total_rewards_std            109.89700808892283
total_rewards_max            7725.999377489779
total_rewards_min            7373.571462675387
Number of train steps total  117000
Number of env steps total    587000
Number of rollouts total     0
Train Time (s)               32.49827014096081
(Previous) Eval Time (s)     27.074641888961196
Sample Time (s)              22.076462081633508
Epoch Time (s)               81.64937411155552
Total Train Time (s)         9693.638220705092
Epoch                        116
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:12:32.746686 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #116 | Epoch Duration: 82.68205499649048
2020-01-11 12:12:32.746883 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #116 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.140013
Z variance train             0.023713032
KL Divergence                27.795218
KL Loss                      2.7795217
QF Loss                      324.84848
VF Loss                      220.01105
Policy Loss                  -2375.778
Q Predictions Mean           2371.7883
Q Predictions Std            732.4757
Q Predictions Max            3190.255
Q Predictions Min            163.22998
V Predictions Mean           2365.7659
V Predictions Std            731.0529
V Predictions Max            3177.6418
V Predictions Min            146.25775
Log Pis Mean                 3.4242613
Log Pis Std                  4.330859
Log Pis Max                  18.024483
Log Pis Min                  -7.091023
Policy mu Mean               -0.10029149
Policy mu Std                1.2815934
Policy mu Max                3.6735494
Policy mu Min                -2.852701
Policy log std Mean          -0.636404
Policy log std Std           0.3551131
Policy log std Max           0.04967022
Policy log std Min           -2.3966842
Z mean eval                  2.1236436
Z variance eval              0.030370152
total_rewards                [7094.14086389 6956.61885004 7232.70830602 7179.98434034 7210.74068818
 7293.94971708 7298.88162312 7130.27050971 7512.41329858 7263.54324892]
total_rewards_mean           7217.325144588137
total_rewards_std            139.33086411803507
total_rewards_max            7512.41329857616
total_rewards_min            6956.6188500378
Number of train steps total  118000
Number of env steps total    592000
Number of rollouts total     0
Train Time (s)               31.97789427312091
(Previous) Eval Time (s)     28.10699481703341
Sample Time (s)              23.36145328031853
Epoch Time (s)               83.44634237047285
Total Train Time (s)         9776.16332501173
Epoch                        117
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:13:55.273240 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #117 | Epoch Duration: 82.5262131690979
2020-01-11 12:13:55.273449 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #117 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1248085
Z variance train             0.030241128
KL Divergence                27.023613
KL Loss                      2.7023613
QF Loss                      478.9682
VF Loss                      213.45969
Policy Loss                  -2341.7983
Q Predictions Mean           2330.7517
Q Predictions Std            724.29865
Q Predictions Max            3012.2678
Q Predictions Min            152.05907
V Predictions Mean           2335.854
V Predictions Std            723.7485
V Predictions Max            3030.556
V Predictions Min            151.6353
Log Pis Mean                 3.6820002
Log Pis Std                  4.81591
Log Pis Max                  19.693758
Log Pis Min                  -6.324106
Policy mu Mean               -0.0818796
Policy mu Std                1.3036859
Policy mu Max                3.67282
Policy mu Min                -4.4581013
Policy log std Mean          -0.65584546
Policy log std Std           0.35120735
Policy log std Max           0.06569767
Policy log std Min           -2.2111728
Z mean eval                  2.1442418
Z variance eval              0.032032073
total_rewards                [7015.57949991 7584.73680885 7266.17355138 7632.92153587 7353.85207272
 7432.9831967  7528.10498244 7450.22539977 7698.85659955 7299.04190254]
total_rewards_mean           7426.2475549724595
total_rewards_std            192.05161611917384
total_rewards_max            7698.856599548134
total_rewards_min            7015.579499905669
Number of train steps total  119000
Number of env steps total    597000
Number of rollouts total     0
Train Time (s)               31.902583480346948
(Previous) Eval Time (s)     27.186499509960413
Sample Time (s)              22.523742003832012
Epoch Time (s)               81.61282499413937
Total Train Time (s)         9859.202987961471
Epoch                        118
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:15:18.317425 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #118 | Epoch Duration: 83.04383039474487
2020-01-11 12:15:18.317602 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #118 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.142915
Z variance train             0.032176126
KL Divergence                27.232662
KL Loss                      2.7232664
QF Loss                      599.9242
VF Loss                      248.53967
Policy Loss                  -2428.552
Q Predictions Mean           2426.7617
Q Predictions Std            677.93195
Q Predictions Max            3093.9102
Q Predictions Min            137.43947
V Predictions Mean           2431.7217
V Predictions Std            671.9735
V Predictions Max            3100.5488
V Predictions Min            153.88716
Log Pis Mean                 3.638464
Log Pis Std                  4.3956985
Log Pis Max                  14.92223
Log Pis Min                  -8.168527
Policy mu Mean               -0.06799839
Policy mu Std                1.3026059
Policy mu Max                2.9740832
Policy mu Min                -2.7027028
Policy log std Mean          -0.6702903
Policy log std Std           0.36021549
Policy log std Max           -0.020496786
Policy log std Min           -2.1766102
Z mean eval                  2.163973
Z variance eval              0.028902596
total_rewards                [7641.68410075 7894.56245001 7947.85026302 7728.4557448  7771.97416162
 7430.9892206  7772.72463099 8008.85295461 7655.7975318  7771.29311321]
total_rewards_mean           7762.418417142384
total_rewards_std            158.0496284247883
total_rewards_max            8008.852954614325
total_rewards_min            7430.989220600062
Number of train steps total  120000
Number of env steps total    602000
Number of rollouts total     0
Train Time (s)               32.05728844227269
(Previous) Eval Time (s)     28.6171563831158
Sample Time (s)              22.346906901337206
Epoch Time (s)               83.0213517267257
Total Train Time (s)         9942.722405671142
Epoch                        119
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:16:41.837914 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #119 | Epoch Duration: 83.52016758918762
2020-01-11 12:16:41.838188 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #119 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1602707
Z variance train             0.028858488
KL Divergence                27.296791
KL Loss                      2.729679
QF Loss                      401.2388
VF Loss                      510.7658
Policy Loss                  -2362.0732
Q Predictions Mean           2366.3262
Q Predictions Std            804.5355
Q Predictions Max            3156.0527
Q Predictions Min            112.66487
V Predictions Mean           2380.247
V Predictions Std            807.25476
V Predictions Max            3166.221
V Predictions Min            161.13603
Log Pis Mean                 3.705635
Log Pis Std                  4.6241894
Log Pis Max                  15.8421
Log Pis Min                  -5.207158
Policy mu Mean               -0.08613255
Policy mu Std                1.3001207
Policy mu Max                3.238702
Policy mu Min                -3.1809554
Policy log std Mean          -0.6720298
Policy log std Std           0.37692523
Policy log std Max           0.07308251
Policy log std Min           -2.2911768
Z mean eval                  2.161359
Z variance eval              0.03745121
total_rewards                [1670.06486198 7887.85652497 7838.66724746 7660.85296517 7786.61000705
 7739.99749694 7577.82909044 7823.07193376 7573.41005468 7856.44628089]
total_rewards_mean           7141.480646333126
total_rewards_std            1826.9210227176288
total_rewards_max            7887.856524966769
total_rewards_min            1670.0648619832155
Number of train steps total  121000
Number of env steps total    607000
Number of rollouts total     0
Train Time (s)               32.233737925067544
(Previous) Eval Time (s)     29.11563022620976
Sample Time (s)              22.272349659353495
Epoch Time (s)               83.6217178106308
Total Train Time (s)         10025.5637827022
Epoch                        120
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:18:04.678007 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #120 | Epoch Duration: 82.83962345123291
2020-01-11 12:18:04.678137 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #120 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1615384
Z variance train             0.037366137
KL Divergence                27.223349
KL Loss                      2.7223349
QF Loss                      493.4255
VF Loss                      116.13165
Policy Loss                  -2399.9343
Q Predictions Mean           2400.5347
Q Predictions Std            717.86743
Q Predictions Max            3130.753
Q Predictions Min            142.47969
V Predictions Mean           2403.6807
V Predictions Std            714.3444
V Predictions Max            3133.4565
V Predictions Min            147.08215
Log Pis Mean                 3.5403497
Log Pis Std                  4.5292826
Log Pis Max                  13.945557
Log Pis Min                  -7.399075
Policy mu Mean               -0.10427099
Policy mu Std                1.2915564
Policy mu Max                3.1460598
Policy mu Min                -2.8937132
Policy log std Mean          -0.6493683
Policy log std Std           0.360737
Policy log std Max           0.023186922
Policy log std Min           -2.4276505
Z mean eval                  2.166556
Z variance eval              0.028832573
total_rewards                [7768.19847141 7747.50659594 7668.43532834 7374.96079382 7875.80072032
 7588.43056421 7576.55682443 7521.63314238 7827.77809117 7818.90093491]
total_rewards_mean           7676.820146693162
total_rewards_std            151.34494536750242
total_rewards_max            7875.800720319751
total_rewards_min            7374.960793822822
Number of train steps total  122000
Number of env steps total    612000
Number of rollouts total     0
Train Time (s)               31.633822922129184
(Previous) Eval Time (s)     28.333247672766447
Sample Time (s)              22.70806915126741
Epoch Time (s)               82.67513974616304
Total Train Time (s)         10108.172321683262
Epoch                        121
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:19:27.288362 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #121 | Epoch Duration: 82.61009097099304
2020-01-11 12:19:27.288658 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #121 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1669364
Z variance train             0.028765962
KL Divergence                27.72247
KL Loss                      2.772247
QF Loss                      483.68976
VF Loss                      260.29395
Policy Loss                  -2445.991
Q Predictions Mean           2449.4014
Q Predictions Std            650.5726
Q Predictions Max            3113.2083
Q Predictions Min            163.05203
V Predictions Mean           2438.819
V Predictions Std            648.2336
V Predictions Max            3088.8696
V Predictions Min            141.6081
Log Pis Mean                 3.9256926
Log Pis Std                  4.2858915
Log Pis Max                  14.054834
Log Pis Min                  -5.445697
Policy mu Mean               -0.08777684
Policy mu Std                1.3004625
Policy mu Max                3.1136425
Policy mu Min                -2.83485
Policy log std Mean          -0.6886563
Policy log std Std           0.37058768
Policy log std Max           0.026530385
Policy log std Min           -2.567794
Z mean eval                  2.1651862
Z variance eval              0.022629252
total_rewards                [7641.04870339 7881.64989157 7788.48949085 7700.76540655 7869.69252472
 7797.97736464 7750.3407883  7908.42127357 7963.95271762 7801.34298356]
total_rewards_mean           7810.368114476305
total_rewards_std            93.16752868474026
total_rewards_max            7963.952717622465
total_rewards_min            7641.048703387032
Number of train steps total  123000
Number of env steps total    617000
Number of rollouts total     0
Train Time (s)               31.718963470775634
(Previous) Eval Time (s)     28.267850168980658
Sample Time (s)              21.725071489810944
Epoch Time (s)               81.71188512956724
Total Train Time (s)         10189.474520849064
Epoch                        122
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:20:48.591644 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #122 | Epoch Duration: 81.30278396606445
2020-01-11 12:20:48.591789 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #122 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1675887
Z variance train             0.022673242
KL Divergence                27.969124
KL Loss                      2.7969124
QF Loss                      343.4251
VF Loss                      232.29019
Policy Loss                  -2507.861
Q Predictions Mean           2502.7715
Q Predictions Std            729.1567
Q Predictions Max            3235.6135
Q Predictions Min            144.80428
V Predictions Mean           2495.6082
V Predictions Std            721.66144
V Predictions Max            3201.9722
V Predictions Min            151.91975
Log Pis Mean                 3.9773197
Log Pis Std                  4.1661787
Log Pis Max                  14.810989
Log Pis Min                  -5.9714284
Policy mu Mean               -0.060611084
Policy mu Std                1.3432254
Policy mu Max                2.8210905
Policy mu Min                -3.023932
Policy log std Mean          -0.6700917
Policy log std Std           0.38071197
Policy log std Max           0.018575013
Policy log std Min           -2.4792962
Z mean eval                  2.158179
Z variance eval              0.022369374
total_rewards                [7569.42945748 7521.61936796 7662.41411332 7605.22178639 7673.95936073
 7539.21259328 7713.16769686 7389.85814552 7572.85418923 7618.50869766]
total_rewards_mean           7586.62454084272
total_rewards_std            87.42020960175738
total_rewards_max            7713.167696860186
total_rewards_min            7389.858145524164
Number of train steps total  124000
Number of env steps total    622000
Number of rollouts total     0
Train Time (s)               31.900997004006058
(Previous) Eval Time (s)     27.858421981334686
Sample Time (s)              23.19695779355243
Epoch Time (s)               82.95637677889317
Total Train Time (s)         10272.593683172483
Epoch                        123
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:22:11.714766 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #123 | Epoch Duration: 83.12278199195862
2020-01-11 12:22:11.715079 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #123 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1583824
Z variance train             0.022367457
KL Divergence                28.011662
KL Loss                      2.8011663
QF Loss                      379.68927
VF Loss                      152.9073
Policy Loss                  -2477.808
Q Predictions Mean           2475.121
Q Predictions Std            757.524
Q Predictions Max            3194.2378
Q Predictions Min            146.45087
V Predictions Mean           2482.6062
V Predictions Std            755.21204
V Predictions Max            3197.0005
V Predictions Min            149.76118
Log Pis Mean                 3.753213
Log Pis Std                  4.49923
Log Pis Max                  14.227472
Log Pis Min                  -8.425393
Policy mu Mean               -0.08532071
Policy mu Std                1.3291787
Policy mu Max                2.9437695
Policy mu Min                -3.0960083
Policy log std Mean          -0.66863745
Policy log std Std           0.38493922
Policy log std Max           -0.019096792
Policy log std Min           -2.5060906
Z mean eval                  2.1611867
Z variance eval              0.022162767
total_rewards                [7506.01897348 7785.45865677 7848.43541352 7670.12277356 7976.60466923
 7832.07810446 7630.69376134 7733.10958317 7787.92228522 7860.19480731]
total_rewards_mean           7763.0639028051755
total_rewards_std            127.01734346316492
total_rewards_max            7976.604669227559
total_rewards_min            7506.018973476086
Number of train steps total  125000
Number of env steps total    627000
Number of rollouts total     0
Train Time (s)               32.02152909198776
(Previous) Eval Time (s)     28.024450284894556
Sample Time (s)              22.444499496836215
Epoch Time (s)               82.49047887371853
Total Train Time (s)         10354.931254369672
Epoch                        124
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:23:34.053872 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #124 | Epoch Duration: 82.33848881721497
2020-01-11 12:23:34.054080 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #124 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1608572
Z variance train             0.022153946
KL Divergence                28.166801
KL Loss                      2.8166802
QF Loss                      363.5307
VF Loss                      164.76459
Policy Loss                  -2548.734
Q Predictions Mean           2549.0957
Q Predictions Std            724.4027
Q Predictions Max            3276.55
Q Predictions Min            147.92834
V Predictions Mean           2548.504
V Predictions Std            720.96655
V Predictions Max            3263.4514
V Predictions Min            155.44008
Log Pis Mean                 3.6401284
Log Pis Std                  4.2937927
Log Pis Max                  16.123154
Log Pis Min                  -5.25014
Policy mu Mean               -0.10102471
Policy mu Std                1.3115661
Policy mu Max                3.5708656
Policy mu Min                -2.7394338
Policy log std Mean          -0.6572583
Policy log std Std           0.36736044
Policy log std Max           0.07411778
Policy log std Min           -2.595261
Z mean eval                  2.1855383
Z variance eval              0.017542686
total_rewards                [7900.35309413 7638.18243217 7950.30773248 7682.0755332  7651.15239274
 7767.43930253 7836.05726565 7736.93384004 7946.70313695 7638.91278255]
total_rewards_mean           7774.811751244479
total_rewards_std            119.3205608777489
total_rewards_max            7950.307732476468
total_rewards_min            7638.182432166923
Number of train steps total  126000
Number of env steps total    632000
Number of rollouts total     0
Train Time (s)               32.161142848897725
(Previous) Eval Time (s)     27.872199334204197
Sample Time (s)              22.375892338808626
Epoch Time (s)               82.40923452191055
Total Train Time (s)         10437.237067535985
Epoch                        125
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:24:56.362875 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #125 | Epoch Duration: 82.30854797363281
2020-01-11 12:24:56.363318 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #125 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1862042
Z variance train             0.017526515
KL Divergence                28.95858
KL Loss                      2.895858
QF Loss                      472.78363
VF Loss                      195.39989
Policy Loss                  -2495.0303
Q Predictions Mean           2497.3833
Q Predictions Std            757.35474
Q Predictions Max            3268.611
Q Predictions Min            140.42471
V Predictions Mean           2502.8516
V Predictions Std            757.9763
V Predictions Max            3247.23
V Predictions Min            141.71968
Log Pis Mean                 3.786283
Log Pis Std                  4.1812944
Log Pis Max                  15.40319
Log Pis Min                  -6.0013056
Policy mu Mean               -0.13535248
Policy mu Std                1.2990096
Policy mu Max                2.8774095
Policy mu Min                -3.786364
Policy log std Mean          -0.6798355
Policy log std Std           0.38679394
Policy log std Max           0.04966098
Policy log std Min           -2.416494
Z mean eval                  2.158931
Z variance eval              0.019582726
total_rewards                [7183.76126148 7534.87593825 7377.10301487 7974.69601064 7523.60203838
 7750.1305903  7701.22382803 7604.6092168  7563.93823029 7590.9114624 ]
total_rewards_mean           7580.485159144186
total_rewards_std            200.94628903415756
total_rewards_max            7974.696010637538
total_rewards_min            7183.761261483706
Number of train steps total  127000
Number of env steps total    637000
Number of rollouts total     0
Train Time (s)               31.755634099710733
(Previous) Eval Time (s)     27.77115014800802
Sample Time (s)              20.634361669886857
Epoch Time (s)               80.16114591760561
Total Train Time (s)         10517.300397719722
Epoch                        126
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:26:16.426055 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #126 | Epoch Duration: 80.0624623298645
2020-01-11 12:26:16.426191 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #126 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1568856
Z variance train             0.019552493
KL Divergence                28.229713
KL Loss                      2.8229713
QF Loss                      616.3839
VF Loss                      487.9043
Policy Loss                  -2451.4524
Q Predictions Mean           2450.3145
Q Predictions Std            766.3673
Q Predictions Max            3219.5278
Q Predictions Min            139.47939
V Predictions Mean           2462.5503
V Predictions Std            760.4519
V Predictions Max            3219.7705
V Predictions Min            152.21211
Log Pis Mean                 3.4882557
Log Pis Std                  4.645358
Log Pis Max                  16.348852
Log Pis Min                  -6.896637
Policy mu Mean               -0.15351354
Policy mu Std                1.2808789
Policy mu Max                3.5147452
Policy mu Min                -3.3616762
Policy log std Mean          -0.6643668
Policy log std Std           0.3720756
Policy log std Max           -0.021333754
Policy log std Min           -2.6209126
Z mean eval                  2.1848404
Z variance eval              0.0146914525
total_rewards                [7665.51673957 7996.26428224 7917.98592376 7785.54545286 7956.04141808
 7726.39150836 7549.55906913 7840.61620286 7929.07260121 7789.35055474]
total_rewards_mean           7815.63437528122
total_rewards_std            133.8660928336053
total_rewards_max            7996.264282237264
total_rewards_min            7549.559069130345
Number of train steps total  128000
Number of env steps total    642000
Number of rollouts total     0
Train Time (s)               32.06702484516427
(Previous) Eval Time (s)     27.67221516976133
Sample Time (s)              23.030520821455866
Epoch Time (s)               82.76976083638147
Total Train Time (s)         10599.788477720227
Epoch                        127
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:27:38.918540 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #127 | Epoch Duration: 82.4921522140503
2020-01-11 12:27:38.918878 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #127 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.186056
Z variance train             0.014709538
KL Divergence                29.431313
KL Loss                      2.9431312
QF Loss                      347.77133
VF Loss                      105.075
Policy Loss                  -2509.9248
Q Predictions Mean           2510.8784
Q Predictions Std            730.0727
Q Predictions Max            3281.5493
Q Predictions Min            135.64326
V Predictions Mean           2508.6826
V Predictions Std            725.0124
V Predictions Max            3267.8672
V Predictions Min            140.59537
Log Pis Mean                 3.5548878
Log Pis Std                  4.439563
Log Pis Max                  16.564537
Log Pis Min                  -6.9519835
Policy mu Mean               -0.11658005
Policy mu Std                1.2975591
Policy mu Max                3.1982803
Policy mu Min                -2.8408027
Policy log std Mean          -0.678245
Policy log std Std           0.38412327
Policy log std Max           0.012543142
Policy log std Min           -2.3966534
Z mean eval                  2.1987805
Z variance eval              0.010929668
total_rewards                [7971.61194829 8250.10267551 7994.21648406 7941.97234983 8022.69116697
 8020.94085041 7942.53201428 8024.63327984 7943.2123199  8082.61037518]
total_rewards_mean           8019.452346427235
total_rewards_std            88.25306795480223
total_rewards_max            8250.102675513604
total_rewards_min            7941.972349832387
Number of train steps total  129000
Number of env steps total    647000
Number of rollouts total     0
Train Time (s)               31.83170649362728
(Previous) Eval Time (s)     27.394187772180885
Sample Time (s)              22.11462298920378
Epoch Time (s)               81.34051725501195
Total Train Time (s)         10680.922513339669
Epoch                        128
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:29:00.055331 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #128 | Epoch Duration: 81.13625645637512
2020-01-11 12:29:00.055576 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #128 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1981645
Z variance train             0.0109062465
KL Divergence                30.459705
KL Loss                      3.0459707
QF Loss                      508.8352
VF Loss                      167.3658
Policy Loss                  -2480.093
Q Predictions Mean           2471.5469
Q Predictions Std            789.5917
Q Predictions Max            3215.9558
Q Predictions Min            111.80424
V Predictions Mean           2480.1736
V Predictions Std            778.1357
V Predictions Max            3210.1396
V Predictions Min            144.80128
Log Pis Mean                 3.9257646
Log Pis Std                  4.7665505
Log Pis Max                  17.98684
Log Pis Min                  -5.703204
Policy mu Mean               -0.17822695
Policy mu Std                1.3045448
Policy mu Max                3.0189474
Policy mu Min                -2.8363128
Policy log std Mean          -0.6788616
Policy log std Std           0.3771828
Policy log std Max           -0.03958553
Policy log std Min           -2.5687318
Z mean eval                  2.1800232
Z variance eval              0.012905789
total_rewards                [7435.02148792 7985.90044128 7693.62373194 7300.79498894 7911.70031642
 7621.12642823 8008.40533427 7757.86631593 3686.14073356 8016.91313735]
total_rewards_mean           7341.749291583762
total_rewards_std            1240.5209729568464
total_rewards_max            8016.913137353257
total_rewards_min            3686.1407335605672
Number of train steps total  130000
Number of env steps total    652000
Number of rollouts total     0
Train Time (s)               31.91690224967897
(Previous) Eval Time (s)     27.189595696050674
Sample Time (s)              22.414226626977324
Epoch Time (s)               81.52072457270697
Total Train Time (s)         10763.46572679421
Epoch                        129
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:30:22.601328 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #129 | Epoch Duration: 82.54552626609802
2020-01-11 12:30:22.601599 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #129 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1816583
Z variance train             0.012899275
KL Divergence                30.08772
KL Loss                      3.0087721
QF Loss                      563.63745
VF Loss                      255.33463
Policy Loss                  -2592.8206
Q Predictions Mean           2598.5361
Q Predictions Std            718.49274
Q Predictions Max            3345.5615
Q Predictions Min            149.24925
V Predictions Mean           2602.4749
V Predictions Std            718.4068
V Predictions Max            3330.0022
V Predictions Min            149.19011
Log Pis Mean                 4.0616083
Log Pis Std                  4.535389
Log Pis Max                  14.117641
Log Pis Min                  -6.478543
Policy mu Mean               -0.11300554
Policy mu Std                1.3381039
Policy mu Max                2.8607955
Policy mu Min                -3.3548527
Policy log std Mean          -0.66918564
Policy log std Std           0.35371384
Policy log std Max           -0.107973665
Policy log std Min           -2.4231956
Z mean eval                  2.1868505
Z variance eval              0.010797994
total_rewards                [7787.50632432 7787.63517445 8000.95543005 8014.95406301 8078.08116443
 7897.90390285 7824.36309574 7802.32746202 7925.1775027  7889.43005443]
total_rewards_mean           7900.833417399372
total_rewards_std            98.18551919732603
total_rewards_max            8078.081164428279
total_rewards_min            7787.506324324556
Number of train steps total  131000
Number of env steps total    657000
Number of rollouts total     0
Train Time (s)               32.30447591515258
(Previous) Eval Time (s)     28.214088364038616
Sample Time (s)              21.972522630356252
Epoch Time (s)               82.49108690954745
Total Train Time (s)         10846.639206974767
Epoch                        130
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:31:45.777665 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #130 | Epoch Duration: 83.17590975761414
2020-01-11 12:31:45.777851 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #130 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1872587
Z variance train             0.010801589
KL Divergence                30.666052
KL Loss                      3.0666053
QF Loss                      368.12326
VF Loss                      166.74309
Policy Loss                  -2549.8804
Q Predictions Mean           2546.2996
Q Predictions Std            749.80695
Q Predictions Max            3337.5823
Q Predictions Min            145.52222
V Predictions Mean           2546.1174
V Predictions Std            750.222
V Predictions Max            3331.3303
V Predictions Min            139.57898
Log Pis Mean                 3.378889
Log Pis Std                  4.169176
Log Pis Max                  14.205139
Log Pis Min                  -5.038956
Policy mu Mean               -0.10830248
Policy mu Std                1.2843491
Policy mu Max                2.6152368
Policy mu Min                -2.7718062
Policy log std Mean          -0.6588785
Policy log std Std           0.37039933
Policy log std Max           -0.00889504
Policy log std Min           -2.4257443
Z mean eval                  2.1947482
Z variance eval              0.009609329
total_rewards                [7664.53587769 7756.44508608 7518.92684882 7783.85920457 7476.20986128
 7745.09483413 7918.33713711 7631.31959376 7860.38310331 7439.93364179]
total_rewards_mean           7679.504518854861
total_rewards_std            154.2478138918197
total_rewards_max            7918.337137107134
total_rewards_min            7439.933641793547
Number of train steps total  132000
Number of env steps total    662000
Number of rollouts total     0
Train Time (s)               31.84923062985763
(Previous) Eval Time (s)     28.898611365351826
Sample Time (s)              22.945441315881908
Epoch Time (s)               83.69328331109136
Total Train Time (s)         10929.035116858315
Epoch                        131
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:33:08.174147 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #131 | Epoch Duration: 82.39614343643188
2020-01-11 12:33:08.174333 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #131 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1953063
Z variance train             0.0096020745
KL Divergence                31.206398
KL Loss                      3.1206398
QF Loss                      764.90674
VF Loss                      264.12103
Policy Loss                  -2453.4915
Q Predictions Mean           2450.1814
Q Predictions Std            850.0971
Q Predictions Max            3249.1733
Q Predictions Min            129.88243
V Predictions Mean           2451.913
V Predictions Std            843.2255
V Predictions Max            3234.3718
V Predictions Min            135.44153
Log Pis Mean                 3.5663114
Log Pis Std                  4.3955283
Log Pis Max                  13.736706
Log Pis Min                  -6.5514946
Policy mu Mean               -0.117340714
Policy mu Std                1.3064028
Policy mu Max                4.5757027
Policy mu Min                -2.8674254
Policy log std Mean          -0.6696584
Policy log std Std           0.36769778
Policy log std Max           0.024642467
Policy log std Min           -2.4179523
Z mean eval                  2.1784477
Z variance eval              0.009002568
total_rewards                [7740.67960258 8174.96788707 7613.4121651  7793.82885911 8179.02302141
 7895.67492717 7764.59842428 7971.63741703 8064.91000879 7996.04592701]
total_rewards_mean           7919.477823953368
total_rewards_std            181.20694247679668
total_rewards_max            8179.023021407733
total_rewards_min            7613.412165099122
Number of train steps total  133000
Number of env steps total    667000
Number of rollouts total     0
Train Time (s)               32.590766195673496
(Previous) Eval Time (s)     27.60115135787055
Sample Time (s)              23.093001856468618
Epoch Time (s)               83.28491941001266
Total Train Time (s)         11012.056824208237
Epoch                        132
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:34:31.198488 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #132 | Epoch Duration: 83.0240089893341
2020-01-11 12:34:31.198701 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #132 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1782072
Z variance train             0.009007083
KL Divergence                30.950039
KL Loss                      3.0950038
QF Loss                      304.92255
VF Loss                      260.78442
Policy Loss                  -2475.579
Q Predictions Mean           2473.23
Q Predictions Std            842.1723
Q Predictions Max            3345.2468
Q Predictions Min            127.501785
V Predictions Mean           2479.293
V Predictions Std            841.7808
V Predictions Max            3348.9192
V Predictions Min            129.70471
Log Pis Mean                 3.9319239
Log Pis Std                  4.7513337
Log Pis Max                  14.667539
Log Pis Min                  -9.062307
Policy mu Mean               -0.07101205
Policy mu Std                1.321804
Policy mu Max                3.1458182
Policy mu Min                -3.2162943
Policy log std Mean          -0.6699941
Policy log std Std           0.3905936
Policy log std Max           -0.057042032
Policy log std Min           -2.4933712
Z mean eval                  2.1946511
Z variance eval              0.008420995
total_rewards                [7814.75901599 8259.06453777 8131.9097698  7892.20625793 7729.84299654
 7881.58627853 8047.34195834 7690.24782842 7976.16346751 7825.01462485]
total_rewards_mean           7924.813673568475
total_rewards_std            170.382171845127
total_rewards_max            8259.064537772898
total_rewards_min            7690.247828419931
Number of train steps total  134000
Number of env steps total    672000
Number of rollouts total     0
Train Time (s)               31.581646645907313
(Previous) Eval Time (s)     27.339926719665527
Sample Time (s)              22.493171635549515
Epoch Time (s)               81.41474500112236
Total Train Time (s)         11094.26396752568
Epoch                        133
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:35:53.407650 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #133 | Epoch Duration: 82.20880246162415
2020-01-11 12:35:53.407844 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #133 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.194228
Z variance train             0.008444454
KL Divergence                31.737072
KL Loss                      3.1737072
QF Loss                      575.3832
VF Loss                      245.72696
Policy Loss                  -2461.962
Q Predictions Mean           2456.9783
Q Predictions Std            851.7289
Q Predictions Max            3322.598
Q Predictions Min            124.58693
V Predictions Mean           2460.1719
V Predictions Std            845.2321
V Predictions Max            3314.071
V Predictions Min            133.74403
Log Pis Mean                 3.8720582
Log Pis Std                  4.597559
Log Pis Max                  19.540956
Log Pis Min                  -5.172459
Policy mu Mean               -0.14549999
Policy mu Std                1.3062592
Policy mu Max                3.9423015
Policy mu Min                -3.1065602
Policy log std Mean          -0.693693
Policy log std Std           0.4019579
Policy log std Max           0.046117842
Policy log std Min           -2.5365105
Z mean eval                  2.170587
Z variance eval              0.008513495
total_rewards                [7900.81288572 7826.53268408 8180.6190086  7720.02396701 8056.56363928
 7861.60039003 7886.94731271 7989.39418172 7719.36049426 7625.51845332]
total_rewards_mean           7876.737301672389
total_rewards_std            159.13645794017913
total_rewards_max            8180.619008599673
total_rewards_min            7625.518453322919
Number of train steps total  135000
Number of env steps total    677000
Number of rollouts total     0
Train Time (s)               32.62761056935415
(Previous) Eval Time (s)     28.133608389180154
Sample Time (s)              22.803111080545932
Epoch Time (s)               83.56433003908023
Total Train Time (s)         11178.46212478634
Epoch                        134
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:37:17.608549 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #134 | Epoch Duration: 84.20055484771729
2020-01-11 12:37:17.608779 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #134 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1691406
Z variance train             0.008511709
KL Divergence                31.255707
KL Loss                      3.1255708
QF Loss                      356.83652
VF Loss                      227.43079
Policy Loss                  -2597.9646
Q Predictions Mean           2596.4102
Q Predictions Std            745.4515
Q Predictions Max            3326.816
Q Predictions Min            86.734665
V Predictions Mean           2604.976
V Predictions Std            745.75995
V Predictions Max            3340.791
V Predictions Min            132.43741
Log Pis Mean                 4.0929856
Log Pis Std                  4.4637647
Log Pis Max                  14.87507
Log Pis Min                  -5.2626367
Policy mu Mean               -0.121877335
Policy mu Std                1.3337426
Policy mu Max                2.689363
Policy mu Min                -2.609521
Policy log std Mean          -0.6783728
Policy log std Std           0.37448117
Policy log std Max           -0.09960866
Policy log std Min           -2.5533023
Z mean eval                  2.1662872
Z variance eval              0.009902049
total_rewards                [7734.26545797 7779.41310245 7428.82489516 7563.46061131 7589.20453299
 7675.10086838 7552.14661881 7495.63497881 7714.55281585 7716.43740051]
total_rewards_mean           7624.904128223044
total_rewards_std            109.66716194364625
total_rewards_max            7779.413102449878
total_rewards_min            7428.824895161483
Number of train steps total  136000
Number of env steps total    682000
Number of rollouts total     0
Train Time (s)               32.46828634524718
(Previous) Eval Time (s)     28.769483662676066
Sample Time (s)              20.518734690267593
Epoch Time (s)               81.75650469819084
Total Train Time (s)         11260.075653527398
Epoch                        135
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:38:39.224876 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #135 | Epoch Duration: 81.61592054367065
2020-01-11 12:38:39.225214 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #135 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1645577
Z variance train             0.00991799
KL Divergence                31.33941
KL Loss                      3.1339412
QF Loss                      464.33734
VF Loss                      231.79546
Policy Loss                  -2599.4653
Q Predictions Mean           2591.939
Q Predictions Std            685.3346
Q Predictions Max            3265.1226
Q Predictions Min            129.29195
V Predictions Mean           2595.9097
V Predictions Std            679.0578
V Predictions Max            3233.5815
V Predictions Min            126.45525
Log Pis Mean                 4.0028033
Log Pis Std                  4.3124266
Log Pis Max                  15.100565
Log Pis Min                  -5.8274956
Policy mu Mean               -0.047028277
Policy mu Std                1.3377188
Policy mu Max                2.8694193
Policy mu Min                -2.84863
Policy log std Mean          -0.68946195
Policy log std Std           0.36810452
Policy log std Max           -0.1146452
Policy log std Min           -2.463295
Z mean eval                  2.1688435
Z variance eval              0.010434966
total_rewards                [7631.89988614 7783.75768456 7906.87818033 7699.05729174 7691.17588854
 8078.31481877 7744.44184311 7587.49605666 7751.56027143 7897.64156454]
total_rewards_mean           7777.222348581898
total_rewards_std            139.4174901420211
total_rewards_max            8078.314818770149
total_rewards_min            7587.496056660684
Number of train steps total  137000
Number of env steps total    687000
Number of rollouts total     0
Train Time (s)               32.053010005969554
(Previous) Eval Time (s)     28.628570897039026
Sample Time (s)              22.618344428483397
Epoch Time (s)               83.29992533149198
Total Train Time (s)         11342.216952871531
Epoch                        136
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:40:01.367864 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #136 | Epoch Duration: 82.14245319366455
2020-01-11 12:40:01.368073 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #136 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1700578
Z variance train             0.010450147
KL Divergence                31.384525
KL Loss                      3.1384525
QF Loss                      545.8311
VF Loss                      363.88025
Policy Loss                  -2518.2847
Q Predictions Mean           2514.3198
Q Predictions Std            824.2324
Q Predictions Max            3342.3564
Q Predictions Min            149.10762
V Predictions Mean           2510.5654
V Predictions Std            821.0022
V Predictions Max            3308.6917
V Predictions Min            125.96727
Log Pis Mean                 3.7103674
Log Pis Std                  4.316576
Log Pis Max                  12.878366
Log Pis Min                  -4.743309
Policy mu Mean               -0.15159865
Policy mu Std                1.3097025
Policy mu Max                3.0037315
Policy mu Min                -3.2773986
Policy log std Mean          -0.67722726
Policy log std Std           0.3609604
Policy log std Max           -0.0942049
Policy log std Min           -2.5852575
Z mean eval                  2.1694674
Z variance eval              0.01302254
total_rewards                [7530.97688146 7930.48783672 8120.51402197 8051.80425762 7982.69071741
 7964.84816224 7704.37279383 8211.41470652 7909.246295   7928.45900895]
total_rewards_mean           7933.481468172604
total_rewards_std            185.67606762757083
total_rewards_max            8211.414706517406
total_rewards_min            7530.976881458233
Number of train steps total  138000
Number of env steps total    692000
Number of rollouts total     0
Train Time (s)               31.881814050022513
(Previous) Eval Time (s)     27.4707824960351
Sample Time (s)              22.23274060478434
Epoch Time (s)               81.58533715084195
Total Train Time (s)         11424.664784220047
Epoch                        137
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:41:23.817584 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #137 | Epoch Duration: 82.44936895370483
2020-01-11 12:41:23.817782 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #137 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1717608
Z variance train             0.013005422
KL Divergence                31.558426
KL Loss                      3.1558425
QF Loss                      497.1909
VF Loss                      141.47517
Policy Loss                  -2610.3813
Q Predictions Mean           2617.7014
Q Predictions Std            720.5717
Q Predictions Max            3351.514
Q Predictions Min            133.32135
V Predictions Mean           2609.4756
V Predictions Std            715.0963
V Predictions Max            3328.3123
V Predictions Min            129.00397
Log Pis Mean                 3.9014273
Log Pis Std                  4.8802414
Log Pis Max                  15.700635
Log Pis Min                  -9.054565
Policy mu Mean               -0.09679934
Policy mu Std                1.337877
Policy mu Max                3.1095595
Policy mu Min                -2.867675
Policy log std Mean          -0.6752781
Policy log std Std           0.35143888
Policy log std Max           -0.115986645
Policy log std Min           -2.5342627
Z mean eval                  2.1736605
Z variance eval              0.018814351
total_rewards                [7583.62525472 8087.00515764 7531.96793574 8145.37703754 8018.93940978
 7729.49165194 7726.7120938  7630.51892102 7775.76307073 7831.83781866]
total_rewards_mean           7806.123835156967
total_rewards_std            202.12456157828697
total_rewards_max            8145.377037540081
total_rewards_min            7531.967935738024
Number of train steps total  139000
Number of env steps total    697000
Number of rollouts total     0
Train Time (s)               32.1892668409273
(Previous) Eval Time (s)     28.33451888570562
Sample Time (s)              21.83393588894978
Epoch Time (s)               82.3577216155827
Total Train Time (s)         11506.432054608129
Epoch                        138
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:42:45.587930 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #138 | Epoch Duration: 81.77000689506531
2020-01-11 12:42:45.588108 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #138 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1734264
Z variance train             0.018801466
KL Divergence                30.747011
KL Loss                      3.074701
QF Loss                      357.63638
VF Loss                      175.34703
Policy Loss                  -2591.5713
Q Predictions Mean           2591.9336
Q Predictions Std            773.8418
Q Predictions Max            3330.319
Q Predictions Min            121.60279
V Predictions Mean           2597.9827
V Predictions Std            770.2079
V Predictions Max            3325.821
V Predictions Min            127.1102
Log Pis Mean                 3.804027
Log Pis Std                  4.5094495
Log Pis Max                  15.664596
Log Pis Min                  -5.623625
Policy mu Mean               -0.14805211
Policy mu Std                1.3263484
Policy mu Max                2.905786
Policy mu Min                -2.7753088
Policy log std Mean          -0.6772725
Policy log std Std           0.3831285
Policy log std Max           0.06172514
Policy log std Min           -2.6847196
Z mean eval                  2.1771522
Z variance eval              0.017222885
total_rewards                [7948.15398444 7988.2427815  8208.21735297 8153.77991273 8126.46806001
 8208.79029926 8108.12746054 7977.36512071 8288.16614913 8161.4410863 ]
total_rewards_mean           8116.875220759303
total_rewards_std            106.82939458890603
total_rewards_max            8288.166149132394
total_rewards_min            7948.1539844448625
Number of train steps total  140000
Number of env steps total    702000
Number of rollouts total     0
Train Time (s)               33.040467496961355
(Previous) Eval Time (s)     27.746446553617716
Sample Time (s)              22.628484062850475
Epoch Time (s)               83.41539811342955
Total Train Time (s)         11590.021434172057
Epoch                        139
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:44:09.178769 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #139 | Epoch Duration: 83.59053564071655
2020-01-11 12:44:09.178953 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #139 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.179197
Z variance train             0.01725789
KL Divergence                30.884186
KL Loss                      3.0884187
QF Loss                      318.04926
VF Loss                      220.39583
Policy Loss                  -2655.1084
Q Predictions Mean           2649.4658
Q Predictions Std            703.5291
Q Predictions Max            3429.0725
Q Predictions Min            122.69882
V Predictions Mean           2647.2856
V Predictions Std            701.20966
V Predictions Max            3400.4062
V Predictions Min            125.45416
Log Pis Mean                 3.889709
Log Pis Std                  4.0291147
Log Pis Max                  13.977915
Log Pis Min                  -5.899637
Policy mu Mean               -0.14719062
Policy mu Std                1.3344375
Policy mu Max                3.190541
Policy mu Min                -2.9124854
Policy log std Mean          -0.6896093
Policy log std Std           0.35330197
Policy log std Max           -0.12744164
Policy log std Min           -2.495167
Z mean eval                  2.1696541
Z variance eval              0.01736121
total_rewards                [7242.57301035 7647.56048482 7436.55393542 7432.65070625 7832.84630897
 7723.54543414 7689.47545919 7963.73261145 7704.43797415 7655.2221715 ]
total_rewards_mean           7632.859809625103
total_rewards_std            199.4200869767306
total_rewards_max            7963.732611446228
total_rewards_min            7242.573010354453
Number of train steps total  141000
Number of env steps total    707000
Number of rollouts total     0
Train Time (s)               31.62743871100247
(Previous) Eval Time (s)     27.921318877954036
Sample Time (s)              20.935219258069992
Epoch Time (s)               80.4839768470265
Total Train Time (s)         11670.938934384845
Epoch                        140
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:45:30.099178 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #140 | Epoch Duration: 80.92007946968079
2020-01-11 12:45:30.099440 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #140 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1721935
Z variance train             0.017292937
KL Divergence                30.738293
KL Loss                      3.0738294
QF Loss                      344.6336
VF Loss                      266.31494
Policy Loss                  -2577.519
Q Predictions Mean           2575.3867
Q Predictions Std            696.39294
Q Predictions Max            3326.9248
Q Predictions Min            131.18968
V Predictions Mean           2573.9587
V Predictions Std            691.5307
V Predictions Max            3290.102
V Predictions Min            128.30995
Log Pis Mean                 4.476345
Log Pis Std                  4.6452665
Log Pis Max                  15.229158
Log Pis Min                  -6.2366066
Policy mu Mean               -0.12382728
Policy mu Std                1.366121
Policy mu Max                3.094192
Policy mu Min                -2.8068967
Policy log std Mean          -0.69165134
Policy log std Std           0.35674566
Policy log std Max           0.048240602
Policy log std Min           -2.4141808
Z mean eval                  2.186639
Z variance eval              0.016912075
total_rewards                [7909.08287681 7728.80028692 7993.70263423 8189.40397069 7854.07741244
 8184.13862291 7954.08298718 7900.05607335 7934.25290456 8067.4427184 ]
total_rewards_mean           7971.504048750644
total_rewards_std            136.30015832211308
total_rewards_max            8189.403970690679
total_rewards_min            7728.800286924179
Number of train steps total  142000
Number of env steps total    712000
Number of rollouts total     0
Train Time (s)               33.996261787135154
(Previous) Eval Time (s)     28.357096292078495
Sample Time (s)              22.524886657949537
Epoch Time (s)               84.87824473716319
Total Train Time (s)         11756.10625736788
Epoch                        141
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:46:55.268509 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #141 | Epoch Duration: 85.16890907287598
2020-01-11 12:46:55.268730 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #141 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1857333
Z variance train             0.016904306
KL Divergence                30.963089
KL Loss                      3.096309
QF Loss                      930.1045
VF Loss                      295.70374
Policy Loss                  -2606.9036
Q Predictions Mean           2606.8584
Q Predictions Std            717.6201
Q Predictions Max            3346.1487
Q Predictions Min            117.75682
V Predictions Mean           2619.331
V Predictions Std            715.3399
V Predictions Max            3372.2458
V Predictions Min            120.90672
Log Pis Mean                 3.4072404
Log Pis Std                  4.3985085
Log Pis Max                  13.635675
Log Pis Min                  -6.324918
Policy mu Mean               -0.11801449
Policy mu Std                1.286422
Policy mu Max                3.292681
Policy mu Min                -2.820134
Policy log std Mean          -0.6730531
Policy log std Std           0.359619
Policy log std Max           -0.011057854
Policy log std Min           -2.5227983
Z mean eval                  2.1801398
Z variance eval              0.016105149
total_rewards                [8033.81073301 7964.38257423 8201.90262438 8112.31099287 8310.37864266
 8165.95527967 7848.13128244 8158.99906105 8020.12560538 7962.91015347]
total_rewards_mean           8077.890694915724
total_rewards_std            130.04697388189726
total_rewards_max            8310.378642661153
total_rewards_min            7848.1312824400875
Number of train steps total  143000
Number of env steps total    717000
Number of rollouts total     0
Train Time (s)               35.16356502985582
(Previous) Eval Time (s)     28.647387025877833
Sample Time (s)              23.160227664746344
Epoch Time (s)               86.97117972048
Total Train Time (s)         11842.536763054319
Epoch                        142
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:48:21.701083 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #142 | Epoch Duration: 86.43218851089478
2020-01-11 12:48:21.701297 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #142 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1836553
Z variance train             0.0160135
KL Divergence                31.08053
KL Loss                      3.108053
QF Loss                      317.73132
VF Loss                      292.46588
Policy Loss                  -2680.1714
Q Predictions Mean           2679.3403
Q Predictions Std            755.68567
Q Predictions Max            3416.0098
Q Predictions Min            131.14708
V Predictions Mean           2666.5222
V Predictions Std            751.3525
V Predictions Max            3361.236
V Predictions Min            132.65543
Log Pis Mean                 4.181818
Log Pis Std                  4.624046
Log Pis Max                  15.526642
Log Pis Min                  -6.7618465
Policy mu Mean               -0.15324421
Policy mu Std                1.3386686
Policy mu Max                2.8726826
Policy mu Min                -2.7971344
Policy log std Mean          -0.67837715
Policy log std Std           0.36563018
Policy log std Max           -0.036978126
Policy log std Min           -2.5403833
Z mean eval                  2.1807866
Z variance eval              0.017010735
total_rewards                [5127.01521167 3293.08600206 3299.60015781 7883.69967112 7736.4225393
 7796.21186622 8084.58621526 7653.32259114 8299.13702327 7886.71832898]
total_rewards_mean           6705.979960682655
total_rewards_std            1900.3195844377187
total_rewards_max            8299.137023269337
total_rewards_min            3293.086002055934
Number of train steps total  144000
Number of env steps total    722000
Number of rollouts total     0
Train Time (s)               34.73040391411632
(Previous) Eval Time (s)     28.108037685975432
Sample Time (s)              23.37034860998392
Epoch Time (s)               86.20879021007568
Total Train Time (s)         11929.39017646201
Epoch                        143
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:49:48.556513 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #143 | Epoch Duration: 86.85507416725159
2020-01-11 12:49:48.556696 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #143 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.17959
Z variance train             0.017060356
KL Divergence                30.284977
KL Loss                      3.0284977
QF Loss                      642.35925
VF Loss                      162.909
Policy Loss                  -2703.3018
Q Predictions Mean           2697.425
Q Predictions Std            748.1061
Q Predictions Max            3415.1638
Q Predictions Min            128.95009
V Predictions Mean           2704.9482
V Predictions Std            746.3405
V Predictions Max            3412.483
V Predictions Min            129.41751
Log Pis Mean                 4.3424025
Log Pis Std                  4.4791617
Log Pis Max                  17.391302
Log Pis Min                  -5.875
Policy mu Mean               -0.13399671
Policy mu Std                1.3571267
Policy mu Max                3.2493262
Policy mu Min                -3.1954772
Policy log std Mean          -0.6900994
Policy log std Std           0.37775344
Policy log std Max           -0.02314198
Policy log std Min           -2.587591
Z mean eval                  2.1846442
Z variance eval              0.015598996
total_rewards                [7685.51772389 8275.19315731 7988.67088554 8050.90535399 8056.87854443
 8076.49097113 7848.18197943 7804.51505356 8121.40137335 8161.21998545]
total_rewards_mean           8006.8975028084005
total_rewards_std            169.69196049372056
total_rewards_max            8275.193157313277
total_rewards_min            7685.517723889621
Number of train steps total  145000
Number of env steps total    727000
Number of rollouts total     0
Train Time (s)               34.528948449064046
(Previous) Eval Time (s)     28.753930575214326
Sample Time (s)              23.264798528980464
Epoch Time (s)               86.54767755325884
Total Train Time (s)         12015.596650345717
Epoch                        144
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:51:14.769681 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #144 | Epoch Duration: 86.21283221244812
2020-01-11 12:51:14.769919 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #144 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1853175
Z variance train             0.015634859
KL Divergence                30.286522
KL Loss                      3.0286522
QF Loss                      449.727
VF Loss                      299.0274
Policy Loss                  -2595.171
Q Predictions Mean           2599.7405
Q Predictions Std            808.89655
Q Predictions Max            3334.3555
Q Predictions Min            121.14121
V Predictions Mean           2593.8706
V Predictions Std            801.99554
V Predictions Max            3319.1917
V Predictions Min            125.518456
Log Pis Mean                 3.90182
Log Pis Std                  4.8812914
Log Pis Max                  22.247377
Log Pis Min                  -8.107687
Policy mu Mean               -0.10241414
Policy mu Std                1.3309243
Policy mu Max                3.750727
Policy mu Min                -3.9114876
Policy log std Mean          -0.67686707
Policy log std Std           0.37682548
Policy log std Max           0.036878407
Policy log std Min           -2.6026204
Z mean eval                  2.1740806
Z variance eval              0.016438363
total_rewards                [7712.14947511 8181.83242656 8130.48160333 8066.40997955 8216.40211491
 7977.84527479 8219.38489484 8177.84966531 8333.89454116 7864.0805901 ]
total_rewards_mean           8088.0330565667855
total_rewards_std            178.0165983998801
total_rewards_max            8333.894541157872
total_rewards_min            7712.149475109668
Number of train steps total  146000
Number of env steps total    732000
Number of rollouts total     0
Train Time (s)               34.99804446985945
(Previous) Eval Time (s)     28.418695447966456
Sample Time (s)              23.615481947548687
Epoch Time (s)               87.0322218653746
Total Train Time (s)         12101.873331838753
Epoch                        145
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:52:41.044777 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #145 | Epoch Duration: 86.27470970153809
2020-01-11 12:52:41.044982 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #145 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1735835
Z variance train             0.016437728
KL Divergence                29.721806
KL Loss                      2.9721806
QF Loss                      1034.8977
VF Loss                      182.78183
Policy Loss                  -2619.8757
Q Predictions Mean           2619.969
Q Predictions Std            763.30774
Q Predictions Max            3350.7356
Q Predictions Min            118.724556
V Predictions Mean           2620.9067
V Predictions Std            759.81506
V Predictions Max            3337.7368
V Predictions Min            119.12189
Log Pis Mean                 3.963673
Log Pis Std                  4.4745493
Log Pis Max                  16.105885
Log Pis Min                  -5.3274183
Policy mu Mean               -0.10852497
Policy mu Std                1.3160682
Policy mu Max                3.2577121
Policy mu Min                -3.0110087
Policy log std Mean          -0.6866922
Policy log std Std           0.35968587
Policy log std Max           -0.067824304
Policy log std Min           -2.4720795
Z mean eval                  2.1812978
Z variance eval              0.022588765
total_rewards                [7980.81079794 8193.6396807  8076.71733921 7982.66283382 8068.2812653
 8113.7116349  8252.75263329 8170.15344308 7871.15815388 8128.67557722]
total_rewards_mean           8083.856335933054
total_rewards_std            108.31353033417643
total_rewards_max            8252.752633288334
total_rewards_min            7871.158153882301
Number of train steps total  147000
Number of env steps total    737000
Number of rollouts total     0
Train Time (s)               33.70450932113454
(Previous) Eval Time (s)     27.660793066956103
Sample Time (s)              22.86515737976879
Epoch Time (s)               84.23045976785943
Total Train Time (s)         12187.383306235075
Epoch                        146
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:54:06.556877 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #146 | Epoch Duration: 85.51174211502075
2020-01-11 12:54:06.557076 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #146 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1807172
Z variance train             0.022455912
KL Divergence                29.49115
KL Loss                      2.949115
QF Loss                      291.25793
VF Loss                      208.53003
Policy Loss                  -2717.308
Q Predictions Mean           2725.7637
Q Predictions Std            721.9104
Q Predictions Max            3425.8545
Q Predictions Min            123.27343
V Predictions Mean           2727.772
V Predictions Std            719.3412
V Predictions Max            3418.2422
V Predictions Min            126.74532
Log Pis Mean                 4.4831676
Log Pis Std                  4.7297
Log Pis Max                  14.873716
Log Pis Min                  -5.2306604
Policy mu Mean               -0.14083825
Policy mu Std                1.3717936
Policy mu Max                3.0902903
Policy mu Min                -2.7745898
Policy log std Mean          -0.6773295
Policy log std Std           0.37763205
Policy log std Max           -0.033352077
Policy log std Min           -2.6110125
Z mean eval                  2.1739573
Z variance eval              0.017666081
total_rewards                [8394.79184065 8358.00932333 8061.50860468 8057.27440619 8317.16755266
 8288.77152348 3193.82498633 8372.93169551 8029.84168581 8226.63076156]
total_rewards_mean           7730.075238019733
total_rewards_std            1517.7988587692978
total_rewards_max            8394.791840650349
total_rewards_min            3193.8249863346878
Number of train steps total  148000
Number of env steps total    742000
Number of rollouts total     0
Train Time (s)               34.97083742078394
(Previous) Eval Time (s)     28.941618971992284
Sample Time (s)              23.519856427330524
Epoch Time (s)               87.43231282010674
Total Train Time (s)         12275.292817876674
Epoch                        147
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:55:34.468686 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #147 | Epoch Duration: 87.91145873069763
2020-01-11 12:55:34.468893 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #147 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1750267
Z variance train             0.017659504
KL Divergence                29.713604
KL Loss                      2.9713604
QF Loss                      413.0855
VF Loss                      145.6702
Policy Loss                  -2620.3179
Q Predictions Mean           2622.8274
Q Predictions Std            799.8625
Q Predictions Max            3436.7678
Q Predictions Min            121.347305
V Predictions Mean           2616.065
V Predictions Std            799.17957
V Predictions Max            3416.8428
V Predictions Min            109.27268
Log Pis Mean                 4.2571335
Log Pis Std                  4.6509295
Log Pis Max                  15.542897
Log Pis Min                  -6.7210274
Policy mu Mean               -0.09779634
Policy mu Std                1.3570921
Policy mu Max                3.2355702
Policy mu Min                -3.032516
Policy log std Mean          -0.6882505
Policy log std Std           0.38621438
Policy log std Max           -0.06733291
Policy log std Min           -2.6815994
Z mean eval                  2.1841197
Z variance eval              0.015552203
total_rewards                [8222.6328539  8018.87966435 8021.27024279 8278.94598326 8257.77411458
 8558.47921906 7901.6260407  8191.04965231 8543.33674246 8318.70878135]
total_rewards_mean           8231.270329476069
total_rewards_std            203.62698790077326
total_rewards_max            8558.479219061168
total_rewards_min            7901.626040698002
Number of train steps total  149000
Number of env steps total    747000
Number of rollouts total     0
Train Time (s)               34.14721919596195
(Previous) Eval Time (s)     29.420342409051955
Sample Time (s)              24.362708696629852
Epoch Time (s)               87.93027030164376
Total Train Time (s)         12362.16829444142
Epoch                        148
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:57:01.346354 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #148 | Epoch Duration: 86.87731623649597
2020-01-11 12:57:01.346544 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #148 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1828792
Z variance train             0.015567553
KL Divergence                29.988707
KL Loss                      2.9988706
QF Loss                      573.16455
VF Loss                      253.85223
Policy Loss                  -2721.856
Q Predictions Mean           2729.6812
Q Predictions Std            855.5803
Q Predictions Max            3466.3062
Q Predictions Min            120.05811
V Predictions Mean           2732.308
V Predictions Std            852.2054
V Predictions Max            3463.9976
V Predictions Min            125.69478
Log Pis Mean                 3.9435625
Log Pis Std                  4.4639707
Log Pis Max                  14.112034
Log Pis Min                  -6.8253584
Policy mu Mean               -0.07139673
Policy mu Std                1.3211466
Policy mu Max                2.85628
Policy mu Min                -3.0030997
Policy log std Mean          -0.68580467
Policy log std Std           0.3820334
Policy log std Max           0.3560654
Policy log std Min           -2.5760899
Z mean eval                  2.1996827
Z variance eval              0.015123211
total_rewards                [8032.85102045 8067.88808157 8138.11705652 8040.87570091 4945.60939462
 8251.79756987 8294.31315824 8261.84623656 8105.66090459 7986.16986662]
total_rewards_mean           7812.512898996198
total_rewards_std            960.9455846948803
total_rewards_max            8294.313158236917
total_rewards_min            4945.609394621281
Number of train steps total  150000
Number of env steps total    752000
Number of rollouts total     0
Train Time (s)               34.255717772990465
(Previous) Eval Time (s)     28.366993669886142
Sample Time (s)              23.12407329166308
Epoch Time (s)               85.74678473453969
Total Train Time (s)         12447.836281966884
Epoch                        149
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:58:27.016953 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #149 | Epoch Duration: 85.6702573299408
2020-01-11 12:58:27.017206 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #149 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2008262
Z variance train             0.015152323
KL Divergence                30.459185
KL Loss                      3.0459185
QF Loss                      648.2738
VF Loss                      226.78369
Policy Loss                  -2753.8606
Q Predictions Mean           2746.866
Q Predictions Std            732.07446
Q Predictions Max            3473.1675
Q Predictions Min            108.01375
V Predictions Mean           2748.4917
V Predictions Std            729.0113
V Predictions Max            3466.8237
V Predictions Min            108.59829
Log Pis Mean                 4.319524
Log Pis Std                  4.410352
Log Pis Max                  18.854507
Log Pis Min                  -4.972476
Policy mu Mean               -0.15832445
Policy mu Std                1.3493961
Policy mu Max                3.336906
Policy mu Min                -3.5219538
Policy log std Mean          -0.6980637
Policy log std Std           0.37110224
Policy log std Max           -0.0024894178
Policy log std Min           -2.4434958
Z mean eval                  2.1964366
Z variance eval              0.012359759
total_rewards                [8107.79827767 8174.99926671 8104.74283201 8307.2220705  7963.7253753
 8076.08363864 8158.69306914 3722.51059333 7800.00738274 7893.78239253]
total_rewards_mean           7630.956489857871
total_rewards_std            1310.1966821664262
total_rewards_max            8307.222070501075
total_rewards_min            3722.510593332787
Number of train steps total  151000
Number of env steps total    757000
Number of rollouts total     0
Train Time (s)               34.64345977129415
(Previous) Eval Time (s)     28.290116680320352
Sample Time (s)              23.027602296322584
Epoch Time (s)               85.96117874793708
Total Train Time (s)         12533.656794335693
Epoch                        150
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:59:52.838898 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #150 | Epoch Duration: 85.82153677940369
2020-01-11 12:59:52.839060 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #150 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.194336
Z variance train             0.012364132
KL Divergence                31.15099
KL Loss                      3.115099
QF Loss                      483.41174
VF Loss                      232.22438
Policy Loss                  -2661.7856
Q Predictions Mean           2672.4243
Q Predictions Std            829.24634
Q Predictions Max            3479.3608
Q Predictions Min            124.254745
V Predictions Mean           2669.0884
V Predictions Std            830.9873
V Predictions Max            3468.9172
V Predictions Min            117.09113
Log Pis Mean                 3.9629035
Log Pis Std                  4.8691263
Log Pis Max                  18.926704
Log Pis Min                  -7.02364
Policy mu Mean               -0.068377644
Policy mu Std                1.3277528
Policy mu Max                2.835916
Policy mu Min                -3.0173485
Policy log std Mean          -0.6776502
Policy log std Std           0.38649938
Policy log std Max           -0.01805988
Policy log std Min           -2.725581
Z mean eval                  2.1913269
Z variance eval              0.012306685
total_rewards                [8055.88837829 8134.17530672 8328.58114563 8032.46381218 7961.75675681
 8237.8845128  8118.17592875 8205.17021746 7993.80224986 8162.36254457]
total_rewards_mean           8123.026085307305
total_rewards_std            109.2262691869434
total_rewards_max            8328.58114563489
total_rewards_min            7961.756756807744
Number of train steps total  152000
Number of env steps total    762000
Number of rollouts total     0
Train Time (s)               32.203697175718844
(Previous) Eval Time (s)     28.150103885680437
Sample Time (s)              21.049227268900722
Epoch Time (s)               81.4030283303
Total Train Time (s)         12614.784143243916
Epoch                        151
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:01:13.968694 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #151 | Epoch Duration: 81.12951445579529
2020-01-11 13:01:13.968868 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #151 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.190844
Z variance train             0.012286754
KL Divergence                31.179657
KL Loss                      3.1179657
QF Loss                      503.67444
VF Loss                      238.56946
Policy Loss                  -2651.4604
Q Predictions Mean           2646.427
Q Predictions Std            856.5455
Q Predictions Max            3398.7092
Q Predictions Min            103.810715
V Predictions Mean           2654.853
V Predictions Std            856.7348
V Predictions Max            3401.4172
V Predictions Min            110.66564
Log Pis Mean                 3.8171098
Log Pis Std                  4.448261
Log Pis Max                  16.70994
Log Pis Min                  -5.0599794
Policy mu Mean               -0.101178326
Policy mu Std                1.3052834
Policy mu Max                2.9918728
Policy mu Min                -2.8971944
Policy log std Mean          -0.67693776
Policy log std Std           0.35865656
Policy log std Max           -0.06218344
Policy log std Min           -2.5735424
Z mean eval                  2.1782012
Z variance eval              0.015002829
total_rewards                [7106.10241674 8395.75549472 8335.61862581 8294.1673385  8258.29546361
 8330.44749481 8350.11028251 8251.23925161 8372.49300861 8382.056169  ]
total_rewards_mean           8207.628554592182
total_rewards_std            370.14616595589683
total_rewards_max            8395.755494715408
total_rewards_min            7106.102416741076
Number of train steps total  153000
Number of env steps total    767000
Number of rollouts total     0
Train Time (s)               32.59887999901548
(Previous) Eval Time (s)     27.876289496663958
Sample Time (s)              21.899822616018355
Epoch Time (s)               82.3749921116978
Total Train Time (s)         12697.619671269786
Epoch                        152
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:02:36.807329 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #152 | Epoch Duration: 82.83830714225769
2020-01-11 13:02:36.807637 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #152 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.177626
Z variance train             0.014954132
KL Divergence                30.536848
KL Loss                      3.053685
QF Loss                      455.80273
VF Loss                      738.08167
Policy Loss                  -2645.9907
Q Predictions Mean           2653.5332
Q Predictions Std            812.8927
Q Predictions Max            3439.4792
Q Predictions Min            96.710434
V Predictions Mean           2664.6445
V Predictions Std            808.546
V Predictions Max            3432.751
V Predictions Min            101.68033
Log Pis Mean                 4.3382387
Log Pis Std                  4.6633787
Log Pis Max                  15.353985
Log Pis Min                  -4.4617596
Policy mu Mean               -0.17368758
Policy mu Std                1.3622711
Policy mu Max                4.3207726
Policy mu Min                -3.463114
Policy log std Mean          -0.6966862
Policy log std Std           0.37037534
Policy log std Max           0.000228405
Policy log std Min           -2.5500858
Z mean eval                  2.1709118
Z variance eval              0.011536563
total_rewards                [8163.43378296 8168.49902448 8336.31668977 8362.42540092 8231.52786885
 8321.64787705 8292.29924114 8307.82509966 8056.59220911 8242.03378643]
total_rewards_mean           8248.260098036659
total_rewards_std            90.7047562483921
total_rewards_max            8362.425400918017
total_rewards_min            8056.592209113478
Number of train steps total  154000
Number of env steps total    772000
Number of rollouts total     0
Train Time (s)               32.66214693989605
(Previous) Eval Time (s)     28.339242266025394
Sample Time (s)              21.866661607753485
Epoch Time (s)               82.86805081367493
Total Train Time (s)         12779.527209723834
Epoch                        153
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:03:58.717091 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #153 | Epoch Duration: 81.90924620628357
2020-01-11 13:03:58.717281 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #153 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1705556
Z variance train             0.011510333
KL Divergence                31.016249
KL Loss                      3.101625
QF Loss                      1170.7958
VF Loss                      287.6662
Policy Loss                  -2654.2622
Q Predictions Mean           2649.7964
Q Predictions Std            778.9335
Q Predictions Max            3390.7097
Q Predictions Min            93.25692
V Predictions Mean           2658.3733
V Predictions Std            773.1238
V Predictions Max            3398.9512
V Predictions Min            107.267426
Log Pis Mean                 3.7786884
Log Pis Std                  4.5174794
Log Pis Max                  17.774292
Log Pis Min                  -9.257866
Policy mu Mean               -0.1434378
Policy mu Std                1.3272784
Policy mu Max                4.925196
Policy mu Min                -3.50671
Policy log std Mean          -0.671478
Policy log std Std           0.3794885
Policy log std Max           0.096235275
Policy log std Min           -2.6341438
Z mean eval                  2.161058
Z variance eval              0.014749801
total_rewards                [8215.01055933 8330.75159695 7745.54277876 8080.68800786 8082.39573593
 8410.17716879 8398.83377979 7816.26723659 8031.50441315 7846.26812753]
total_rewards_mean           8095.743940467682
total_rewards_std            229.71779778780964
total_rewards_max            8410.177168792185
total_rewards_min            7745.542778761427
Number of train steps total  155000
Number of env steps total    777000
Number of rollouts total     0
Train Time (s)               32.28870747704059
(Previous) Eval Time (s)     27.380124324001372
Sample Time (s)              22.83941999077797
Epoch Time (s)               82.50825179181993
Total Train Time (s)         12861.902644032147
Epoch                        154
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:05:21.094753 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #154 | Epoch Duration: 82.3773398399353
2020-01-11 13:05:21.094929 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #154 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1608405
Z variance train             0.01472949
KL Divergence                30.228409
KL Loss                      3.022841
QF Loss                      767.4296
VF Loss                      260.09085
Policy Loss                  -2772.9883
Q Predictions Mean           2761.1082
Q Predictions Std            766.8192
Q Predictions Max            3497.7207
Q Predictions Min            121.39891
V Predictions Mean           2763.059
V Predictions Std            766.21356
V Predictions Max            3495.3843
V Predictions Min            116.19682
Log Pis Mean                 4.207266
Log Pis Std                  4.755133
Log Pis Max                  17.509733
Log Pis Min                  -7.431881
Policy mu Mean               -0.1649101
Policy mu Std                1.3376147
Policy mu Max                2.8905327
Policy mu Min                -2.811872
Policy log std Mean          -0.7073922
Policy log std Std           0.3705382
Policy log std Max           -0.0059678555
Policy log std Min           -2.6800046
Z mean eval                  2.1682675
Z variance eval              0.016317654
total_rewards                [8338.93478303 8203.07022355 8495.69068551 8431.92074674 8250.21987105
 8231.88062433 8207.3651958  8436.64316631 8536.3160995  8416.22993162]
total_rewards_mean           8354.827132744622
total_rewards_std            118.43759967844558
total_rewards_max            8536.316099497728
total_rewards_min            8203.07022354993
Number of train steps total  156000
Number of env steps total    782000
Number of rollouts total     0
Train Time (s)               32.21453553903848
(Previous) Eval Time (s)     27.248861314263195
Sample Time (s)              22.44150106003508
Epoch Time (s)               81.90489791333675
Total Train Time (s)         12944.035590780899
Epoch                        155
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:06:43.228786 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #155 | Epoch Duration: 82.13373041152954
2020-01-11 13:06:43.228930 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #155 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1670048
Z variance train             0.016318586
KL Divergence                30.233809
KL Loss                      3.023381
QF Loss                      308.20233
VF Loss                      278.70557
Policy Loss                  -2789.9438
Q Predictions Mean           2789.7783
Q Predictions Std            584.7291
Q Predictions Max            3480.3813
Q Predictions Min            110.83753
V Predictions Mean           2777.259
V Predictions Std            579.1333
V Predictions Max            3456.7659
V Predictions Min            109.43785
Log Pis Mean                 4.4722176
Log Pis Std                  4.191602
Log Pis Max                  16.762405
Log Pis Min                  -5.4968224
Policy mu Mean               -0.08120951
Policy mu Std                1.3496226
Policy mu Max                3.0048628
Policy mu Min                -3.1860738
Policy log std Mean          -0.7209366
Policy log std Std           0.39630088
Policy log std Max           -0.025103152
Policy log std Min           -2.6640217
Z mean eval                  2.1600013
Z variance eval              0.018863175
total_rewards                [8175.03825279 8228.27016256 8110.70689738 8580.78345492 8145.94168623
 7906.9830663  8498.81926087 8025.16689448 5754.96525512 8309.44694516]
total_rewards_mean           7973.612187581084
total_rewards_std            764.2441691084034
total_rewards_max            8580.783454918585
total_rewards_min            5754.965255118916
Number of train steps total  157000
Number of env steps total    787000
Number of rollouts total     0
Train Time (s)               32.166706276126206
(Previous) Eval Time (s)     27.477429253980517
Sample Time (s)              21.959417109843343
Epoch Time (s)               81.60355263995007
Total Train Time (s)         13025.608002073597
Epoch                        156
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:08:04.804701 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #156 | Epoch Duration: 81.57559752464294
2020-01-11 13:08:04.804971 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #156 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1603985
Z variance train             0.018761765
KL Divergence                29.376331
KL Loss                      2.9376333
QF Loss                      748.91034
VF Loss                      405.7658
Policy Loss                  -2666.9695
Q Predictions Mean           2673.156
Q Predictions Std            849.9787
Q Predictions Max            3464.2207
Q Predictions Min            104.91224
V Predictions Mean           2666.674
V Predictions Std            838.42084
V Predictions Max            3455.7625
V Predictions Min            104.79795
Log Pis Mean                 3.990968
Log Pis Std                  4.812022
Log Pis Max                  16.991848
Log Pis Min                  -7.0292025
Policy mu Mean               -0.051224858
Policy mu Std                1.3403344
Policy mu Max                3.0802205
Policy mu Min                -3.431369
Policy log std Mean          -0.71091604
Policy log std Std           0.3801864
Policy log std Max           -0.08791202
Policy log std Min           -2.4887362
Z mean eval                  2.183313
Z variance eval              0.01875658
total_rewards                [8138.68112638 8196.13400562 8213.06151692 8237.17980699 8454.8290708
 8534.52496643 8380.31321311 8294.39988887 8179.81607736 8314.77694257]
total_rewards_mean           8294.371661504787
total_rewards_std            121.70370828532121
total_rewards_max            8534.524966427543
total_rewards_min            8138.681126384749
Number of train steps total  158000
Number of env steps total    792000
Number of rollouts total     0
Train Time (s)               32.091468083206564
(Previous) Eval Time (s)     27.449103095103055
Sample Time (s)              22.977306901477277
Epoch Time (s)               82.5178780797869
Total Train Time (s)         13108.380205229856
Epoch                        157
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:09:27.578169 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #157 | Epoch Duration: 82.7729697227478
2020-01-11 13:09:27.578561 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #157 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1843288
Z variance train             0.018695083
KL Divergence                30.225536
KL Loss                      3.0225537
QF Loss                      367.27243
VF Loss                      351.9325
Policy Loss                  -2822.964
Q Predictions Mean           2816.8745
Q Predictions Std            642.86456
Q Predictions Max            3483.8079
Q Predictions Min            102.616066
V Predictions Mean           2812.8052
V Predictions Std            635.41565
V Predictions Max            3483.7883
V Predictions Min            111.241615
Log Pis Mean                 4.645456
Log Pis Std                  4.122541
Log Pis Max                  16.314152
Log Pis Min                  -5.810479
Policy mu Mean               -0.18458688
Policy mu Std                1.3911924
Policy mu Max                2.7579005
Policy mu Min                -2.8049376
Policy log std Mean          -0.6953148
Policy log std Std           0.3670618
Policy log std Max           0.06722808
Policy log std Min           -2.5413923
Z mean eval                  2.1707952
Z variance eval              0.019570205
total_rewards                [8394.50978013 8120.94966761 8669.24955646 8390.04871691 8453.33751742
 8504.02741007 8410.53904979 8550.78493647 8614.40231324 8380.45046641]
total_rewards_mean           8448.829941449583
total_rewards_std            144.74607007570927
total_rewards_max            8669.24955646147
total_rewards_min            8120.949667608857
Number of train steps total  159000
Number of env steps total    797000
Number of rollouts total     0
Train Time (s)               32.64221241977066
(Previous) Eval Time (s)     27.70375945419073
Sample Time (s)              21.9531758450903
Epoch Time (s)               82.29914771905169
Total Train Time (s)         13191.177050733007
Epoch                        158
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:10:50.377829 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #158 | Epoch Duration: 82.79907631874084
2020-01-11 13:10:50.378028 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #158 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1709785
Z variance train             0.019532867
KL Divergence                30.5111
KL Loss                      3.05111
QF Loss                      367.93744
VF Loss                      123.40687
Policy Loss                  -2731.0935
Q Predictions Mean           2728.9363
Q Predictions Std            767.4172
Q Predictions Max            3515.9114
Q Predictions Min            111.92651
V Predictions Mean           2728.6538
V Predictions Std            757.54144
V Predictions Max            3508.8982
V Predictions Min            115.1222
Log Pis Mean                 3.9842062
Log Pis Std                  4.6791973
Log Pis Max                  23.34141
Log Pis Min                  -6.2911525
Policy mu Mean               -0.09305751
Policy mu Std                1.3617815
Policy mu Max                3.7388265
Policy mu Min                -4.3848176
Policy log std Mean          -0.6909594
Policy log std Std           0.37988663
Policy log std Max           -0.07103239
Policy log std Min           -2.6738527
Z mean eval                  2.179823
Z variance eval              0.021304952
total_rewards                [8040.88230212 8000.54138174 7739.20669464 7983.2984479  7891.42486316
 7870.22842351 7491.67943965 7717.56880705 8082.19005766 7622.84153616]
total_rewards_mean           7843.986195359427
total_rewards_std            185.02723554931686
total_rewards_max            8082.190057659273
total_rewards_min            7491.67943965178
Number of train steps total  160000
Number of env steps total    802000
Number of rollouts total     0
Train Time (s)               32.54895751923323
(Previous) Eval Time (s)     28.203358255326748
Sample Time (s)              21.93366146320477
Epoch Time (s)               82.68597723776475
Total Train Time (s)         13273.291741450317
Epoch                        159
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:12:12.496401 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #159 | Epoch Duration: 82.11813831329346
2020-01-11 13:12:12.496714 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #159 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.178524
Z variance train             0.02129187
KL Divergence                29.961823
KL Loss                      2.9961822
QF Loss                      361.32373
VF Loss                      339.13947
Policy Loss                  -2718.0022
Q Predictions Mean           2723.6282
Q Predictions Std            785.4607
Q Predictions Max            3500.926
Q Predictions Min            94.73536
V Predictions Mean           2733.1675
V Predictions Std            781.8608
V Predictions Max            3499.9858
V Predictions Min            114.96151
Log Pis Mean                 4.367237
Log Pis Std                  4.5824003
Log Pis Max                  14.5554085
Log Pis Min                  -5.6210938
Policy mu Mean               -0.10741816
Policy mu Std                1.3480103
Policy mu Max                2.8335993
Policy mu Min                -2.894303
Policy log std Mean          -0.70940137
Policy log std Std           0.41077542
Policy log std Max           -0.006300628
Policy log std Min           -2.6367137
Z mean eval                  2.1694179
Z variance eval              0.013005981
total_rewards                [8202.60558273 8158.5091134  8544.70470801 8257.17946169 8325.70968888
 8605.8972472  8344.57999227 8370.27727219 8254.70665527 8340.48546391]
total_rewards_mean           8340.4655185557
total_rewards_std            134.05062428784456
total_rewards_max            8605.897247204748
total_rewards_min            8158.5091133999595
Number of train steps total  161000
Number of env steps total    807000
Number of rollouts total     0
Train Time (s)               32.4697908628732
(Previous) Eval Time (s)     27.63518008682877
Sample Time (s)              21.437140248250216
Epoch Time (s)               81.54211119795218
Total Train Time (s)         13355.745125736576
Epoch                        160
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:13:34.951727 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #160 | Epoch Duration: 82.45482444763184
2020-01-11 13:13:34.951957 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #160 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1710582
Z variance train             0.012960616
KL Divergence                30.515244
KL Loss                      3.0515244
QF Loss                      541.72076
VF Loss                      391.02557
Policy Loss                  -2659.5867
Q Predictions Mean           2664.122
Q Predictions Std            880.4134
Q Predictions Max            3469.4194
Q Predictions Min            121.6832
V Predictions Mean           2644.1023
V Predictions Std            876.82654
V Predictions Max            3442.1982
V Predictions Min            105.4444
Log Pis Mean                 3.4008212
Log Pis Std                  4.78595
Log Pis Max                  16.434406
Log Pis Min                  -6.613274
Policy mu Mean               -0.13765144
Policy mu Std                1.2866412
Policy mu Max                3.2824528
Policy mu Min                -2.7179706
Policy log std Mean          -0.6652009
Policy log std Std           0.3941817
Policy log std Max           -0.05624205
Policy log std Min           -2.7297373
Z mean eval                  2.1655755
Z variance eval              0.014214613
total_rewards                [8099.94006133 8167.32459464 8257.26241321 8303.75253973 8254.84442949
 8046.39010227 8099.02356375 8160.19886168 8092.15345837 8211.39967521]
total_rewards_mean           8169.228969966609
total_rewards_std            81.11707377019452
total_rewards_max            8303.75253972667
total_rewards_min            8046.390102265963
Number of train steps total  162000
Number of env steps total    812000
Number of rollouts total     0
Train Time (s)               31.936776144895703
(Previous) Eval Time (s)     28.54758922290057
Sample Time (s)              22.604899014811963
Epoch Time (s)               83.08926438260823
Total Train Time (s)         13438.980610733852
Epoch                        161
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:14:58.191410 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #161 | Epoch Duration: 83.2392737865448
2020-01-11 13:14:58.191658 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #161 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1669714
Z variance train             0.014210914
KL Divergence                30.007301
KL Loss                      3.0007303
QF Loss                      3509.3289
VF Loss                      518.5312
Policy Loss                  -2796.788
Q Predictions Mean           2806.7036
Q Predictions Std            711.47784
Q Predictions Max            3504.0176
Q Predictions Min            97.70087
V Predictions Mean           2812.1353
V Predictions Std            709.28094
V Predictions Max            3527.7708
V Predictions Min            115.684845
Log Pis Mean                 4.4185305
Log Pis Std                  4.6406803
Log Pis Max                  17.608948
Log Pis Min                  -5.0928106
Policy mu Mean               -0.16481362
Policy mu Std                1.343435
Policy mu Max                2.6524968
Policy mu Min                -3.396403
Policy log std Mean          -0.7074659
Policy log std Std           0.39325824
Policy log std Max           0.03947586
Policy log std Min           -2.5490289
Z mean eval                  2.1748815
Z variance eval              0.010858184
total_rewards                [8476.36278425 8253.97637014 8284.96491802 8442.04014319 8239.25395211
 8248.08684507 3271.24051223 8147.87642314 8439.1778131  8654.72169791]
total_rewards_mean           7845.770145915629
total_rewards_std            1531.4542902685248
total_rewards_max            8654.72169791136
total_rewards_min            3271.240512230066
Number of train steps total  163000
Number of env steps total    817000
Number of rollouts total     0
Train Time (s)               32.199974542018026
(Previous) Eval Time (s)     28.697162138298154
Sample Time (s)              21.68065315578133
Epoch Time (s)               82.57778983609751
Total Train Time (s)         13520.847769537475
Epoch                        162
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:16:20.059058 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #162 | Epoch Duration: 81.86723279953003
2020-01-11 13:16:20.059304 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #162 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.174609
Z variance train             0.010878979
KL Divergence                30.90638
KL Loss                      3.090638
QF Loss                      419.08328
VF Loss                      159.76161
Policy Loss                  -2783.644
Q Predictions Mean           2779.6377
Q Predictions Std            804.0906
Q Predictions Max            3529.5251
Q Predictions Min            78.02862
V Predictions Mean           2783.2769
V Predictions Std            798.8961
V Predictions Max            3514.6987
V Predictions Min            110.62862
Log Pis Mean                 4.13972
Log Pis Std                  4.448639
Log Pis Max                  17.953396
Log Pis Min                  -6.615619
Policy mu Mean               -0.09892393
Policy mu Std                1.3380995
Policy mu Max                3.1350775
Policy mu Min                -2.9906292
Policy log std Mean          -0.71696645
Policy log std Std           0.3966439
Policy log std Max           -0.05039394
Policy log std Min           -2.65165
Z mean eval                  2.16568
Z variance eval              0.022873867
total_rewards                [8229.81716236 8244.07644588 8257.51512198 8269.64558066 8361.15359317
 8201.39307414 8364.60204365 8539.99478251 8293.10329527 8648.9653141 ]
total_rewards_mean           8341.026641371334
total_rewards_std            138.20489848700578
total_rewards_max            8648.96531409905
total_rewards_min            8201.393074135114
Number of train steps total  164000
Number of env steps total    822000
Number of rollouts total     0
Train Time (s)               32.98062768206
(Previous) Eval Time (s)     27.986317292321473
Sample Time (s)              22.74931017216295
Epoch Time (s)               83.71625514654443
Total Train Time (s)         13605.065778617747
Epoch                        163
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:17:44.279285 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #163 | Epoch Duration: 84.21983814239502
2020-01-11 13:17:44.279473 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #163 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.166281
Z variance train             0.022862151
KL Divergence                29.473824
KL Loss                      2.9473825
QF Loss                      629.7709
VF Loss                      130.5994
Policy Loss                  -2846.6323
Q Predictions Mean           2842.9453
Q Predictions Std            700.7001
Q Predictions Max            3543.0557
Q Predictions Min            94.47828
V Predictions Mean           2844.417
V Predictions Std            694.47406
V Predictions Max            3554.136
V Predictions Min            108.022484
Log Pis Mean                 4.157975
Log Pis Std                  4.6733356
Log Pis Max                  16.821898
Log Pis Min                  -6.384578
Policy mu Mean               -0.15417977
Policy mu Std                1.331062
Policy mu Max                2.7439165
Policy mu Min                -2.7177057
Policy log std Mean          -0.7120936
Policy log std Std           0.38676226
Policy log std Max           0.0086301565
Policy log std Min           -2.576136
Z mean eval                  2.1748798
Z variance eval              0.018965434
total_rewards                [8219.58300013 8420.37895809 8320.75910237 8303.12013761 7954.93734154
 8173.32211931 8153.44788183 8310.52779949 7908.68044639 8359.98127498]
total_rewards_mean           8212.473806174095
total_rewards_std            160.69316879055128
total_rewards_max            8420.378958091467
total_rewards_min            7908.68044639193
Number of train steps total  165000
Number of env steps total    827000
Number of rollouts total     0
Train Time (s)               32.18664012989029
(Previous) Eval Time (s)     28.489611845929176
Sample Time (s)              22.754182788543403
Epoch Time (s)               83.43043476436287
Total Train Time (s)         13687.096014835406
Epoch                        164
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:19:06.312846 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #164 | Epoch Duration: 82.0332293510437
2020-01-11 13:19:06.313032 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #164 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.175464
Z variance train             0.019055964
KL Divergence                29.775196
KL Loss                      2.9775198
QF Loss                      601.7307
VF Loss                      303.30115
Policy Loss                  -2773.6519
Q Predictions Mean           2775.8154
Q Predictions Std            713.75635
Q Predictions Max            3498.1023
Q Predictions Min            98.72823
V Predictions Mean           2766.0005
V Predictions Std            709.13
V Predictions Max            3512.482
V Predictions Min            99.84457
Log Pis Mean                 4.1663322
Log Pis Std                  4.0161157
Log Pis Max                  14.012211
Log Pis Min                  -5.0645766
Policy mu Mean               -0.12358788
Policy mu Std                1.3212898
Policy mu Max                2.8414638
Policy mu Min                -3.0020294
Policy log std Mean          -0.70111674
Policy log std Std           0.38520968
Policy log std Max           0.14287704
Policy log std Min           -2.4891844
Z mean eval                  2.151649
Z variance eval              0.015551589
total_rewards                [8039.96656793 8464.42623389 8406.18784284 8472.74279395 8259.00237781
 8638.71358436 8424.51548038 8422.75466618 8441.11466642 8637.81456213]
total_rewards_mean           8420.72387758888
total_rewards_std            164.63271074116298
total_rewards_max            8638.713584356521
total_rewards_min            8039.966567929045
Number of train steps total  166000
Number of env steps total    832000
Number of rollouts total     0
Train Time (s)               32.4438710231334
(Previous) Eval Time (s)     27.092116343788803
Sample Time (s)              22.196449742652476
Epoch Time (s)               81.73243710957468
Total Train Time (s)         13768.84188422421
Epoch                        165
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:20:28.060929 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #165 | Epoch Duration: 81.7477376461029
2020-01-11 13:20:28.061255 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #165 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1522832
Z variance train             0.015551744
KL Divergence                29.543638
KL Loss                      2.9543638
QF Loss                      861.64166
VF Loss                      415.15454
Policy Loss                  -2632.791
Q Predictions Mean           2632.8745
Q Predictions Std            800.7468
Q Predictions Max            3398.1582
Q Predictions Min            91.48517
V Predictions Mean           2640.9004
V Predictions Std            796.5296
V Predictions Max            3406.344
V Predictions Min            93.33141
Log Pis Mean                 4.0421505
Log Pis Std                  4.9423714
Log Pis Max                  36.666397
Log Pis Min                  -5.789901
Policy mu Mean               -0.08218036
Policy mu Std                1.3369756
Policy mu Max                6.289949
Policy mu Min                -5.6987963
Policy log std Mean          -0.7073717
Policy log std Std           0.38669866
Policy log std Max           0.65917134
Policy log std Min           -2.4734476
Z mean eval                  2.1688173
Z variance eval              0.016570847
total_rewards                [8259.4340206  8629.87727786 8579.09681932 8556.82068386 8395.30840031
 8548.68858561 8906.00811868 8399.48046464 8720.79725734 8439.29390349]
total_rewards_mean           8543.480553170908
total_rewards_std            174.93820265544375
total_rewards_max            8906.008118675029
total_rewards_min            8259.434020604913
Number of train steps total  167000
Number of env steps total    837000
Number of rollouts total     0
Train Time (s)               32.31722186226398
(Previous) Eval Time (s)     27.107090051751584
Sample Time (s)              22.316013004630804
Epoch Time (s)               81.74032491864637
Total Train Time (s)         13851.967588198837
Epoch                        166
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:21:51.188908 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #166 | Epoch Duration: 83.12745714187622
2020-01-11 13:21:51.189113 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #166 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.169198
Z variance train             0.01651583
KL Divergence                30.049644
KL Loss                      3.0049646
QF Loss                      302.8443
VF Loss                      136.39145
Policy Loss                  -2713.68
Q Predictions Mean           2711.9937
Q Predictions Std            842.2739
Q Predictions Max            3482.4666
Q Predictions Min            99.43801
V Predictions Mean           2708.212
V Predictions Std            838.00885
V Predictions Max            3464.1143
V Predictions Min            98.93197
Log Pis Mean                 4.215662
Log Pis Std                  4.1973977
Log Pis Max                  13.698294
Log Pis Min                  -4.776114
Policy mu Mean               -0.11331111
Policy mu Std                1.3591719
Policy mu Max                2.8281724
Policy mu Min                -2.8064005
Policy log std Mean          -0.6884372
Policy log std Std           0.38625476
Policy log std Max           0.07525736
Policy log std Min           -2.6204925
Z mean eval                  2.1605563
Z variance eval              0.011455504
total_rewards                [8382.97185551 8195.44935824 8339.59833157 8324.23237442 8262.85107056
 8352.30952772 8333.13939758 8271.54119936 8123.42673695 8240.80464055]
total_rewards_mean           8282.632449246874
total_rewards_std            75.93467165878499
total_rewards_max            8382.971855505491
total_rewards_min            8123.4267369468
Number of train steps total  168000
Number of env steps total    842000
Number of rollouts total     0
Train Time (s)               32.253836817108095
(Previous) Eval Time (s)     28.49390060873702
Sample Time (s)              22.184308847412467
Epoch Time (s)               82.93204627325758
Total Train Time (s)         13933.113986016251
Epoch                        167
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:23:12.336385 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #167 | Epoch Duration: 81.14712333679199
2020-01-11 13:23:12.336591 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #167 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1631608
Z variance train             0.011473628
KL Divergence                30.803967
KL Loss                      3.0803967
QF Loss                      579.1387
VF Loss                      166.38017
Policy Loss                  -2803.6963
Q Predictions Mean           2802.982
Q Predictions Std            724.9704
Q Predictions Max            3490.7314
Q Predictions Min            120.048256
V Predictions Mean           2802.4062
V Predictions Std            725.3629
V Predictions Max            3466.6233
V Predictions Min            108.59888
Log Pis Mean                 4.529895
Log Pis Std                  4.411736
Log Pis Max                  16.078285
Log Pis Min                  -5.445009
Policy mu Mean               -0.15306813
Policy mu Std                1.3663051
Policy mu Max                2.6738825
Policy mu Min                -3.2899528
Policy log std Mean          -0.70974034
Policy log std Std           0.38388225
Policy log std Max           -0.03130266
Policy log std Min           -2.7281032
Z mean eval                  2.1685703
Z variance eval              0.007972
total_rewards                [8406.69938312 8582.78047879 8339.85780719 8681.12512202 8639.57270943
 8774.80129471 8526.57793607 8653.86389717 8495.99998097 8739.25267889]
total_rewards_mean           8584.053128834974
total_rewards_std            134.16213425986922
total_rewards_max            8774.80129470524
total_rewards_min            8339.857807186525
Number of train steps total  169000
Number of env steps total    847000
Number of rollouts total     0
Train Time (s)               32.5951568428427
(Previous) Eval Time (s)     26.708627664018422
Sample Time (s)              22.599341060500592
Epoch Time (s)               81.90312556736171
Total Train Time (s)         14016.030942118261
Epoch                        168
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:24:35.254572 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #168 | Epoch Duration: 82.9178307056427
2020-01-11 13:24:35.254718 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #168 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1667483
Z variance train             0.007983036
KL Divergence                31.342255
KL Loss                      3.1342256
QF Loss                      882.99713
VF Loss                      459.3475
Policy Loss                  -2766.6726
Q Predictions Mean           2763.5461
Q Predictions Std            794.5885
Q Predictions Max            3512.4114
Q Predictions Min            104.48339
V Predictions Mean           2768.1936
V Predictions Std            792.9538
V Predictions Max            3483.6084
V Predictions Min            105.471085
Log Pis Mean                 4.704301
Log Pis Std                  4.863737
Log Pis Max                  15.959921
Log Pis Min                  -4.7189775
Policy mu Mean               -0.14056568
Policy mu Std                1.3779981
Policy mu Max                4.727532
Policy mu Min                -2.7378557
Policy log std Mean          -0.7103374
Policy log std Std           0.39875862
Policy log std Max           -0.052495778
Policy log std Min           -2.851142
Z mean eval                  2.2038207
Z variance eval              0.009045398
total_rewards                [8413.73125389 8070.50420539 4568.65701964 8314.92877818 8051.53928728
 8029.45772827 8512.82419425 8199.88311927 7978.88521857 1267.89955853]
total_rewards_mean           7140.8310363274095
total_rewards_std            2242.6728307029566
total_rewards_max            8512.824194245835
total_rewards_min            1267.8995585296811
Number of train steps total  170000
Number of env steps total    852000
Number of rollouts total     0
Train Time (s)               32.320627447683364
(Previous) Eval Time (s)     27.722990276291966
Sample Time (s)              21.704000238329172
Epoch Time (s)               81.7476179623045
Total Train Time (s)         14097.59427313134
Epoch                        169
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:25:56.821142 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #169 | Epoch Duration: 81.56631064414978
2020-01-11 13:25:56.821322 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #169 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2026305
Z variance train             0.009038573
KL Divergence                31.4452
KL Loss                      3.14452
QF Loss                      534.20526
VF Loss                      258.1293
Policy Loss                  -2828.897
Q Predictions Mean           2831.3408
Q Predictions Std            679.627
Q Predictions Max            3493.1575
Q Predictions Min            88.73053
V Predictions Mean           2830.5688
V Predictions Std            676.93195
V Predictions Max            3499.0598
V Predictions Min            102.54018
Log Pis Mean                 4.383283
Log Pis Std                  4.4419017
Log Pis Max                  16.450771
Log Pis Min                  -7.1141253
Policy mu Mean               -0.08657404
Policy mu Std                1.3680065
Policy mu Max                3.9902823
Policy mu Min                -2.8494825
Policy log std Mean          -0.699058
Policy log std Std           0.36272112
Policy log std Max           0.031098366
Policy log std Min           -2.6377742
Z mean eval                  2.1612115
Z variance eval              0.00840072
total_rewards                [8290.14506568 8630.34966887 8508.26635439 8453.53908703 8557.12844672
 8613.60960602 8537.36778551 8303.8388728  8441.50181925 8255.97944083]
total_rewards_mean           8459.17261470964
total_rewards_std            128.68672676502723
total_rewards_max            8630.349668870773
total_rewards_min            8255.979440834235
Number of train steps total  171000
Number of env steps total    857000
Number of rollouts total     0
Train Time (s)               32.161389937624335
(Previous) Eval Time (s)     27.541303574107587
Sample Time (s)              22.56612768024206
Epoch Time (s)               82.26882119197398
Total Train Time (s)         14180.810064418707
Epoch                        170
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:27:20.040601 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #170 | Epoch Duration: 83.21915698051453
2020-01-11 13:27:20.040802 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #170 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1610477
Z variance train             0.008403895
KL Divergence                31.234488
KL Loss                      3.1234488
QF Loss                      558.047
VF Loss                      285.93826
Policy Loss                  -2784.5137
Q Predictions Mean           2795.9312
Q Predictions Std            797.0648
Q Predictions Max            3580.4355
Q Predictions Min            102.12215
V Predictions Mean           2797.5898
V Predictions Std            793.1001
V Predictions Max            3567.28
V Predictions Min            105.9998
Log Pis Mean                 3.9836402
Log Pis Std                  4.316862
Log Pis Max                  13.378947
Log Pis Min                  -5.7061806
Policy mu Mean               -0.072469026
Policy mu Std                1.3339747
Policy mu Max                2.8003051
Policy mu Min                -2.863253
Policy log std Mean          -0.68844557
Policy log std Std           0.3778439
Policy log std Max           0.14966619
Policy log std Min           -2.4936337
Z mean eval                  2.1902947
Z variance eval              0.0108958855
total_rewards                [8264.20879001 8288.82005058 8459.09039862 8387.04577643 8370.18232368
 8566.39719559 8231.9561798  8263.19556451 8372.29962103 8142.08023893]
total_rewards_mean           8334.527613917437
total_rewards_std            115.9373112219732
total_rewards_max            8566.39719559325
total_rewards_min            8142.080238930463
Number of train steps total  172000
Number of env steps total    862000
Number of rollouts total     0
Train Time (s)               32.19271402899176
(Previous) Eval Time (s)     28.491293444298208
Sample Time (s)              22.75798770133406
Epoch Time (s)               83.44199517462403
Total Train Time (s)         14263.511980766896
Epoch                        171
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:28:42.744769 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #171 | Epoch Duration: 82.70381116867065
2020-01-11 13:28:42.744977 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #171 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.192122
Z variance train             0.010868586
KL Divergence                31.347183
KL Loss                      3.1347184
QF Loss                      868.23676
VF Loss                      161.67984
Policy Loss                  -2865.65
Q Predictions Mean           2866.3337
Q Predictions Std            661.33044
Q Predictions Max            3537.289
Q Predictions Min            94.92277
V Predictions Mean           2862.4402
V Predictions Std            651.7874
V Predictions Max            3522.557
V Predictions Min            98.013504
Log Pis Mean                 4.538002
Log Pis Std                  4.4060307
Log Pis Max                  14.86231
Log Pis Min                  -6.5945315
Policy mu Mean               -0.026469626
Policy mu Std                1.3883978
Policy mu Max                3.7622716
Policy mu Min                -3.2624235
Policy log std Mean          -0.68867683
Policy log std Std           0.35682368
Policy log std Max           0.08361256
Policy log std Min           -2.8073144
Z mean eval                  2.1598158
Z variance eval              0.010527335
total_rewards                [8535.07867381 8708.7372515  8596.75905993 8553.08074658 8735.29591357
 8451.72357209 8675.34937832 8496.20711341 8645.41239634 8761.59180427]
total_rewards_mean           8615.923590982367
total_rewards_std            100.31473140288021
total_rewards_max            8761.591804266818
total_rewards_min            8451.723572087574
Number of train steps total  173000
Number of env steps total    867000
Number of rollouts total     0
Train Time (s)               32.202936307061464
(Previous) Eval Time (s)     27.752759610768408
Sample Time (s)              22.724454111419618
Epoch Time (s)               82.68015002924949
Total Train Time (s)         14347.33307537809
Epoch                        172
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:30:06.567909 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #172 | Epoch Duration: 83.8227813243866
2020-01-11 13:30:06.568117 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #172 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1600502
Z variance train             0.010540567
KL Divergence                31.090147
KL Loss                      3.1090147
QF Loss                      594.60254
VF Loss                      164.14493
Policy Loss                  -2892.645
Q Predictions Mean           2891.8071
Q Predictions Std            668.01166
Q Predictions Max            3515.6978
Q Predictions Min            99.55593
V Predictions Mean           2896.0654
V Predictions Std            664.8419
V Predictions Max            3502.2524
V Predictions Min            96.603455
Log Pis Mean                 4.936455
Log Pis Std                  5.019488
Log Pis Max                  20.221407
Log Pis Min                  -6.756613
Policy mu Mean               -0.16185905
Policy mu Std                1.4103508
Policy mu Max                3.297838
Policy mu Min                -2.754206
Policy log std Mean          -0.71321255
Policy log std Std           0.38029778
Policy log std Max           -0.03395334
Policy log std Min           -2.5858603
Z mean eval                  2.1648152
Z variance eval              0.008551662
total_rewards                [8253.70767244 8351.71341665 8230.09456064 8234.58328714 8350.06397107
 8135.84320851 8214.77210547 8273.71028071 8144.26533834 8315.63639373]
total_rewards_mean           8250.43902347096
total_rewards_std            71.64289795135831
total_rewards_max            8351.71341665464
total_rewards_min            8135.8432085146915
Number of train steps total  174000
Number of env steps total    872000
Number of rollouts total     0
Train Time (s)               32.477429947815835
(Previous) Eval Time (s)     28.895091965794563
Sample Time (s)              22.85416153864935
Epoch Time (s)               84.22668345225975
Total Train Time (s)         14430.384973485488
Epoch                        173
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:31:29.622122 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #173 | Epoch Duration: 83.05386662483215
2020-01-11 13:31:29.622310 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #173 | Started Training: True
