---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0058326833
Z variance train             0.6952301
KL Divergence                0.1469768
KL Loss                      0.01469768
QF Loss                      1096.0537
VF Loss                      134.23282
Policy Loss                  -11.559128
Q Predictions Mean           0.008233771
Q Predictions Std            0.012814306
Q Predictions Max            0.04206539
Q Predictions Min            -0.02449881
V Predictions Mean           0.0064341715
V Predictions Std            0.013787466
V Predictions Max            0.0484702
V Predictions Min            -0.022130998
Log Pis Mean                 -11.472197
Log Pis Std                  0.8767863
Log Pis Max                  -9.05932
Log Pis Min                  -14.125285
Policy mu Mean               0.0016821767
Policy mu Std                0.010037625
Policy mu Max                0.037136186
Policy mu Min                -0.02831097
Policy log std Mean          8.041704e-05
Policy log std Std           0.010179829
Policy log std Max           0.026718998
Policy log std Min           -0.034992058
Z mean eval                  0.054413926
Z variance eval              0.8308446
total_rewards                [ 76.70637422  76.48264171  76.58868154  76.62822764  94.31105297
  81.44148577  81.25811529  76.86447289 105.14665759  85.33482314]
total_rewards_mean           83.07625327718303
total_rewards_std            9.114305288011114
total_rewards_max            105.14665758764197
total_rewards_min            76.48264170812162
Number of train steps total  1000
Number of env steps total    7000
Number of rollouts total     0
Train Time (s)               28.07400479633361
(Previous) Eval Time (s)     0
Sample Time (s)              19.44052276853472
Epoch Time (s)               47.51452756486833
Total Train Time (s)         48.02341976296157
Epoch                        0
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:16:29.640994 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #0 | Epoch Duration: 48.027963638305664
2020-01-10 18:16:29.641264 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #0 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.056043006
Z variance train             0.82817936
KL Divergence                0.056827202
KL Loss                      0.0056827203
QF Loss                      28.805588
VF Loss                      20.434093
Policy Loss                  -40.986233
Q Predictions Mean           29.819742
Q Predictions Std            23.717487
Q Predictions Max            138.1879
Q Predictions Min            17.38671
V Predictions Mean           41.349747
V Predictions Std            23.166662
V Predictions Max            149.95357
V Predictions Min            26.422953
Log Pis Mean                 -11.589502
Log Pis Std                  0.65305054
Log Pis Max                  -8.384132
Log Pis Min                  -13.714687
Policy mu Mean               -0.0053963903
Policy mu Std                0.09200074
Policy mu Max                0.7732209
Policy mu Min                -0.8160324
Policy log std Mean          -0.13393469
Policy log std Std           0.021077141
Policy log std Max           -0.052993372
Policy log std Min           -0.29792815
Z mean eval                  0.0127270995
Z variance eval              0.73557854
total_rewards                [143.38860641  81.1935327   71.57996396  81.4784317   81.58868894
  81.28832453  76.49114456  88.26079724  76.55748878  81.16581498]
total_rewards_mean           86.29927937966238
total_rewards_std            19.477577007405895
total_rewards_max            143.38860640537223
total_rewards_min            71.57996395769614
Number of train steps total  2000
Number of env steps total    12000
Number of rollouts total     0
Train Time (s)               27.85772487707436
(Previous) Eval Time (s)     0.5132128507830203
Sample Time (s)              13.66343351546675
Epoch Time (s)               42.03437124332413
Total Train Time (s)         90.04587569041178
Epoch                        1
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:17:11.663641 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #1 | Epoch Duration: 42.02217936515808
2020-01-10 18:17:11.663856 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #1 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011158152
Z variance train             0.72889364
KL Divergence                0.11381082
KL Loss                      0.011381082
QF Loss                      29.734713
VF Loss                      28.66847
Policy Loss                  -53.846725
Q Predictions Mean           42.09821
Q Predictions Std            58.75579
Q Predictions Max            321.2953
Q Predictions Min            17.107006
V Predictions Mean           52.02818
V Predictions Std            59.13592
V Predictions Max            326.20602
V Predictions Min            26.062658
Log Pis Mean                 -10.932015
Log Pis Std                  2.1012826
Log Pis Max                  -0.5960698
Log Pis Min                  -14.025029
Policy mu Mean               0.006129952
Policy mu Std                0.2508453
Policy mu Max                1.5143558
Policy mu Min                -1.2096674
Policy log std Mean          -0.14960432
Policy log std Std           0.054979846
Policy log std Max           -0.05516535
Policy log std Min           -0.5305394
Z mean eval                  0.012813196
Z variance eval              0.66823655
total_rewards                [ 94.91368159 149.9712586  163.70138997 114.41287676 207.50951705
 243.70297665 184.19475039 161.85734431  83.13108202 244.14499395]
total_rewards_mean           164.75398712994152
total_rewards_std            53.89255551576256
total_rewards_max            244.14499395484265
total_rewards_min            83.1310820153196
Number of train steps total  3000
Number of env steps total    17000
Number of rollouts total     0
Train Time (s)               29.907842500600964
(Previous) Eval Time (s)     0.5007483097724617
Sample Time (s)              13.645100407768041
Epoch Time (s)               44.053691218141466
Total Train Time (s)         134.59965923428535
Epoch                        2
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:17:56.218306 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #2 | Epoch Duration: 44.55429124832153
2020-01-10 18:17:56.218496 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #2 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012987572
Z variance train             0.6684264
KL Divergence                0.17953977
KL Loss                      0.017953977
QF Loss                      282.51083
VF Loss                      51.068653
Policy Loss                  -63.858524
Q Predictions Mean           53.913208
Q Predictions Std            87.47704
Q Predictions Max            448.2394
Q Predictions Min            17.785908
V Predictions Mean           61.720547
V Predictions Std            84.92431
V Predictions Max            438.47354
V Predictions Min            25.56304
Log Pis Mean                 -10.724955
Log Pis Std                  2.5292666
Log Pis Max                  1.1779332
Log Pis Min                  -14.748277
Policy mu Mean               0.043990627
Policy mu Std                0.2659044
Policy mu Max                1.6815864
Policy mu Min                -1.3560401
Policy log std Mean          -0.14253137
Policy log std Std           0.055719133
Policy log std Max           4.1790307e-05
Policy log std Min           -0.6090744
Z mean eval                  0.017843015
Z variance eval              0.633819
total_rewards                [147.24070959 251.46863157 320.04851281 251.91641086  81.23905492
 178.91370631  91.459217   119.12026178  81.85839907 158.03593026]
total_rewards_mean           168.13008341596677
total_rewards_std            78.08486062080789
total_rewards_max            320.0485128137936
total_rewards_min            81.23905491517533
Number of train steps total  4000
Number of env steps total    22000
Number of rollouts total     0
Train Time (s)               27.365097501780838
(Previous) Eval Time (s)     1.0010582143440843
Sample Time (s)              13.44310741731897
Epoch Time (s)               41.80926313344389
Total Train Time (s)         176.2834681966342
Epoch                        3
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:18:37.903903 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #3 | Epoch Duration: 41.68519115447998
2020-01-10 18:18:37.904226 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #3 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017598549
Z variance train             0.6339625
KL Divergence                0.23444518
KL Loss                      0.023444518
QF Loss                      792.37805
VF Loss                      140.95865
Policy Loss                  -83.46926
Q Predictions Mean           74.00551
Q Predictions Std            126.88896
Q Predictions Max            573.80743
Q Predictions Min            16.547346
V Predictions Mean           82.248634
V Predictions Std            125.5823
V Predictions Max            584.9868
V Predictions Min            25.844734
Log Pis Mean                 -10.332216
Log Pis Std                  3.0816948
Log Pis Max                  0.8519976
Log Pis Min                  -14.321962
Policy mu Mean               0.045506798
Policy mu Std                0.3393598
Policy mu Max                2.0789206
Policy mu Min                -1.4613286
Policy log std Mean          -0.15258037
Policy log std Std           0.07801445
Policy log std Max           -0.042639047
Policy log std Min           -0.64696026
Z mean eval                  0.025483033
Z variance eval              0.59037894
total_rewards                [437.18867862 281.52808395 415.97075926 375.87586837 344.2767924
 309.677727   428.67664647 368.93950427 313.33561288 298.16557585]
total_rewards_mean           357.3635249056268
total_rewards_std            53.85926174195251
total_rewards_max            437.1886786176177
total_rewards_min            281.52808394652294
Number of train steps total  5000
Number of env steps total    27000
Number of rollouts total     0
Train Time (s)               30.416287067811936
(Previous) Eval Time (s)     0.8767276811413467
Sample Time (s)              14.024593932554126
Epoch Time (s)               45.31760868150741
Total Train Time (s)         222.90357937524095
Epoch                        4
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:19:24.524379 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #4 | Epoch Duration: 46.61999988555908
2020-01-10 18:19:24.524590 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #4 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025477832
Z variance train             0.59028614
KL Divergence                0.30868775
KL Loss                      0.030868774
QF Loss                      2049.0044
VF Loss                      101.39503
Policy Loss                  -91.95936
Q Predictions Mean           88.31565
Q Predictions Std            159.72987
Q Predictions Max            669.4842
Q Predictions Min            17.794113
V Predictions Mean           94.351425
V Predictions Std            148.7654
V Predictions Max            655.01776
V Predictions Min            28.98047
Log Pis Mean                 -10.100298
Log Pis Std                  3.7279644
Log Pis Max                  4.863374
Log Pis Min                  -13.312058
Policy mu Mean               0.042331003
Policy mu Std                0.35703218
Policy mu Max                2.201228
Policy mu Min                -1.4969262
Policy log std Mean          -0.16241081
Policy log std Std           0.077007316
Policy log std Max           -0.030488748
Policy log std Min           -0.6946025
Z mean eval                  0.02037416
Z variance eval              0.5373589
total_rewards                [366.08265903 425.13939393 692.32417163 356.2420528  287.60513703
 306.8284354  633.07734354 753.12151566 446.57672143 468.44764371]
total_rewards_mean           473.54450741706813
total_rewards_std            155.6439777718196
total_rewards_max            753.1215156557299
total_rewards_min            287.60513703470303
Number of train steps total  6000
Number of env steps total    32000
Number of rollouts total     0
Train Time (s)               26.459600113797933
(Previous) Eval Time (s)     2.1788655798882246
Sample Time (s)              14.515389536973089
Epoch Time (s)               43.153855230659246
Total Train Time (s)         266.6271453425288
Epoch                        5
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:20:08.251928 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #5 | Epoch Duration: 43.72706699371338
2020-01-10 18:20:08.252260 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #5 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020565713
Z variance train             0.5372708
KL Divergence                0.42211437
KL Loss                      0.04221144
QF Loss                      429.4404
VF Loss                      237.56151
Policy Loss                  -135.05579
Q Predictions Mean           126.89357
Q Predictions Std            206.05052
Q Predictions Max            740.96704
Q Predictions Min            17.821224
V Predictions Mean           141.64166
V Predictions Std            209.9796
V Predictions Max            746.55115
V Predictions Min            28.954437
Log Pis Mean                 -9.212425
Log Pis Std                  4.831298
Log Pis Max                  8.598116
Log Pis Min                  -13.888796
Policy mu Mean               0.070189044
Policy mu Std                0.44801486
Policy mu Max                2.244586
Policy mu Min                -1.8165473
Policy log std Mean          -0.1692065
Policy log std Std           0.09775431
Policy log std Max           -0.011415292
Policy log std Min           -0.68852526
Z mean eval                  0.017701048
Z variance eval              0.49919042
total_rewards                [217.03744249 302.54155118 182.51697497 288.38438401 223.53095265
 209.96933078 220.06778842 291.70573108 292.9418699  273.30222293]
total_rewards_mean           250.19982484073518
total_rewards_std            41.47219927575712
total_rewards_max            302.54155118235457
total_rewards_min            182.51697496506756
Number of train steps total  7000
Number of env steps total    37000
Number of rollouts total     0
Train Time (s)               30.70167098985985
(Previous) Eval Time (s)     2.7518000369891524
Sample Time (s)              14.840898233931512
Epoch Time (s)               48.29436926078051
Total Train Time (s)         313.6509791868739
Epoch                        6
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:20:55.275046 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #6 | Epoch Duration: 47.02256989479065
2020-01-10 18:20:55.275247 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #6 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017727062
Z variance train             0.4992052
KL Divergence                0.50900745
KL Loss                      0.050900746
QF Loss                      1335.6299
VF Loss                      456.3025
Policy Loss                  -178.98083
Q Predictions Mean           172.96063
Q Predictions Std            264.8745
Q Predictions Max            830.5262
Q Predictions Min            18.323406
V Predictions Mean           184.5603
V Predictions Std            263.68298
V Predictions Max            857.3492
V Predictions Min            28.524223
Log Pis Mean                 -8.141666
Log Pis Std                  6.1263194
Log Pis Max                  11.831881
Log Pis Min                  -13.53581
Policy mu Mean               0.059788514
Policy mu Std                0.5538025
Policy mu Max                2.4305286
Policy mu Min                -1.9677081
Policy log std Mean          -0.19255698
Policy log std Std           0.1165971
Policy log std Max           -0.015580725
Policy log std Min           -0.7340178
Z mean eval                  0.016183876
Z variance eval              0.46598133
total_rewards                [313.04835101 332.62296726 299.49079907 324.53699716 350.94842634
 358.63787796 415.59924522 282.24577842 281.96223167 356.70616801]
total_rewards_mean           331.57988421168034
total_rewards_std            38.88115409538275
total_rewards_max            415.59924522217057
total_rewards_min            281.9622316711171
Number of train steps total  8000
Number of env steps total    42000
Number of rollouts total     0
Train Time (s)               29.99180360417813
(Previous) Eval Time (s)     1.4797451528720558
Sample Time (s)              14.515162801370025
Epoch Time (s)               45.98671155842021
Total Train Time (s)         359.9648782410659
Epoch                        7
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:21:41.590909 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #7 | Epoch Duration: 46.315468311309814
2020-01-10 18:21:41.591209 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #7 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016212892
Z variance train             0.46596813
KL Divergence                0.60148615
KL Loss                      0.060148615
QF Loss                      363.92804
VF Loss                      251.21255
Policy Loss                  -156.59662
Q Predictions Mean           145.61392
Q Predictions Std            268.9105
Q Predictions Max            960.06464
Q Predictions Min            15.916364
V Predictions Mean           152.18222
V Predictions Std            257.5917
V Predictions Max            924.64923
V Predictions Min            26.938023
Log Pis Mean                 -9.037186
Log Pis Std                  5.412168
Log Pis Max                  10.73988
Log Pis Min                  -14.534502
Policy mu Mean               0.080568165
Policy mu Std                0.4534902
Policy mu Max                2.261407
Policy mu Min                -1.867022
Policy log std Mean          -0.16927768
Policy log std Std           0.103066064
Policy log std Max           -0.0012102276
Policy log std Min           -0.6809919
Z mean eval                  0.018896528
Z variance eval              0.44401807
total_rewards                [400.8539623  307.68352485 348.12819619 202.94675427 280.10612203
 308.33863706 402.97822872 309.67417976 375.554969   335.74446822]
total_rewards_mean           327.2009042401056
total_rewards_std            57.19872994098558
total_rewards_max            402.9782287207369
total_rewards_min            202.94675426693374
Number of train steps total  9000
Number of env steps total    47000
Number of rollouts total     0
Train Time (s)               29.041709031909704
(Previous) Eval Time (s)     1.8081778907217085
Sample Time (s)              15.242943601682782
Epoch Time (s)               46.092830524314195
Total Train Time (s)         406.3384142643772
Epoch                        8
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:22:27.966187 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #8 | Epoch Duration: 46.37475347518921
2020-01-10 18:22:27.966446 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #8 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01889966
Z variance train             0.44396615
KL Divergence                0.6691991
KL Loss                      0.066919915
QF Loss                      449.33197
VF Loss                      129.91182
Policy Loss                  -158.6708
Q Predictions Mean           149.48181
Q Predictions Std            275.019
Q Predictions Max            986.289
Q Predictions Min            17.160603
V Predictions Mean           156.44983
V Predictions Std            268.6801
V Predictions Max            977.0878
V Predictions Min            23.854511
Log Pis Mean                 -8.812423
Log Pis Std                  6.1210556
Log Pis Max                  18.009422
Log Pis Min                  -13.703266
Policy mu Mean               0.076462016
Policy mu Std                0.48115045
Policy mu Max                2.487758
Policy mu Min                -1.9026136
Policy log std Mean          -0.17368858
Policy log std Std           0.103818744
Policy log std Max           -0.02431959
Policy log std Min           -0.7001261
Z mean eval                  0.01919584
Z variance eval              0.41061935
total_rewards                [263.67465944 396.30119742 379.33029927 338.14929669 314.10481342
 287.54581355 245.21591562 291.02042233 340.65710717 279.20656224]
total_rewards_mean           313.520608714402
total_rewards_std            46.941874979648375
total_rewards_max            396.3011974155822
total_rewards_min            245.21591562070498
Number of train steps total  10000
Number of env steps total    52000
Number of rollouts total     0
Train Time (s)               29.37958288192749
(Previous) Eval Time (s)     2.0898464978672564
Sample Time (s)              15.913882202468812
Epoch Time (s)               47.38331158226356
Total Train Time (s)         453.37779325572774
Epoch                        9
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:23:15.005063 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #9 | Epoch Duration: 47.038429737091064
2020-01-10 18:23:15.005214 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #9 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01917705
Z variance train             0.41060847
KL Divergence                0.77344084
KL Loss                      0.07734408
QF Loss                      427.48358
VF Loss                      154.9581
Policy Loss                  -179.90735
Q Predictions Mean           168.73495
Q Predictions Std            310.03244
Q Predictions Max            1075.7642
Q Predictions Min            16.197674
V Predictions Mean           183.66829
V Predictions Std            311.81848
V Predictions Max            1040.7246
V Predictions Min            21.824114
Log Pis Mean                 -9.276833
Log Pis Std                  4.9260254
Log Pis Max                  11.469994
Log Pis Min                  -13.907295
Policy mu Mean               0.084552206
Policy mu Std                0.44890904
Policy mu Max                2.435639
Policy mu Min                -1.899501
Policy log std Mean          -0.16415176
Policy log std Std           0.09884575
Policy log std Max           -0.046184983
Policy log std Min           -0.7173912
Z mean eval                  0.020105043
Z variance eval              0.40045628
total_rewards                [376.66575034 287.51259139 313.86007032 313.18940335 433.09308409
 259.16428594 300.93770397 276.02775974 349.62299577 353.15597637]
total_rewards_mean           326.32296212688937
total_rewards_std            49.71470899760189
total_rewards_max            433.0930840875302
total_rewards_min            259.1642859374414
Number of train steps total  11000
Number of env steps total    57000
Number of rollouts total     0
Train Time (s)               29.53097669314593
(Previous) Eval Time (s)     1.7446745741181076
Sample Time (s)              14.397250947076827
Epoch Time (s)               45.672902214340866
Total Train Time (s)         499.1245957426727
Epoch                        10
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:24:00.753836 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #10 | Epoch Duration: 45.748459577560425
2020-01-10 18:24:00.754064 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #10 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020193402
Z variance train             0.4003869
KL Divergence                0.8270619
KL Loss                      0.08270619
QF Loss                      509.67303
VF Loss                      188.11479
Policy Loss                  -225.82648
Q Predictions Mean           213.64943
Q Predictions Std            360.42136
Q Predictions Max            1101.268
Q Predictions Min            16.513659
V Predictions Mean           222.86691
V Predictions Std            357.9317
V Predictions Max            1076.5975
V Predictions Min            26.136509
Log Pis Mean                 -8.433476
Log Pis Std                  5.885137
Log Pis Max                  13.043144
Log Pis Min                  -13.438625
Policy mu Mean               0.06932642
Policy mu Std                0.5047428
Policy mu Max                2.560092
Policy mu Min                -1.8647106
Policy log std Mean          -0.17931062
Policy log std Std           0.10693204
Policy log std Max           -0.0445123
Policy log std Min           -0.7609233
Z mean eval                  0.023733398
Z variance eval              0.3783256
total_rewards                [249.85710655 304.97360503 276.29030297 303.70823893 302.07725456
 259.1616143  242.33706154 245.90125165 294.13338319 265.63816495]
total_rewards_mean           274.4077983667989
total_rewards_std            23.883613868299896
total_rewards_max            304.97360502985225
total_rewards_min            242.33706153690702
Number of train steps total  12000
Number of env steps total    62000
Number of rollouts total     0
Train Time (s)               29.552116066217422
(Previous) Eval Time (s)     1.8199798529967666
Sample Time (s)              15.374527959618717
Epoch Time (s)               46.74662387883291
Total Train Time (s)         545.8700591004454
Epoch                        11
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:24:47.501675 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #11 | Epoch Duration: 46.74739980697632
2020-01-10 18:24:47.501959 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #11 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023748865
Z variance train             0.37827802
KL Divergence                0.9203953
KL Loss                      0.09203953
QF Loss                      516.8019
VF Loss                      160.43974
Policy Loss                  -217.94984
Q Predictions Mean           209.26492
Q Predictions Std            369.05768
Q Predictions Max            1127.92
Q Predictions Min            12.972704
V Predictions Mean           222.29239
V Predictions Std            372.34326
V Predictions Max            1149.655
V Predictions Min            19.373148
Log Pis Mean                 -8.614812
Log Pis Std                  5.599145
Log Pis Max                  11.657046
Log Pis Min                  -13.233217
Policy mu Mean               0.10298844
Policy mu Std                0.48799282
Policy mu Max                2.5353563
Policy mu Min                -1.8706094
Policy log std Mean          -0.18199167
Policy log std Std           0.107402414
Policy log std Max           -0.028425306
Policy log std Min           -0.8340601
Z mean eval                  0.025295135
Z variance eval              0.36218002
total_rewards                [268.14042471 271.54150781 444.02654767 336.88255031 303.21119968
 289.07301291 269.42174753 236.96855913 255.72276949 286.97749122]
total_rewards_mean           296.196581045521
total_rewards_std            55.63451185771637
total_rewards_max            444.02654766603973
total_rewards_min            236.9685591344233
Number of train steps total  13000
Number of env steps total    67000
Number of rollouts total     0
Train Time (s)               28.846329268068075
(Previous) Eval Time (s)     1.8204516773112118
Sample Time (s)              14.770802801009268
Epoch Time (s)               45.437583746388555
Total Train Time (s)         591.1903416090645
Epoch                        12
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:25:32.821275 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #12 | Epoch Duration: 45.31910967826843
2020-01-10 18:25:32.821468 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #12 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025325129
Z variance train             0.3621642
KL Divergence                0.9950371
KL Loss                      0.09950371
QF Loss                      424.78174
VF Loss                      211.11203
Policy Loss                  -203.17538
Q Predictions Mean           192.56866
Q Predictions Std            351.66617
Q Predictions Max            1205.8975
Q Predictions Min            17.263962
V Predictions Mean           200.25098
V Predictions Std            345.71863
V Predictions Max            1177.125
V Predictions Min            25.25182
Log Pis Mean                 -8.943547
Log Pis Std                  5.440773
Log Pis Max                  14.101913
Log Pis Min                  -13.788811
Policy mu Mean               0.060860436
Policy mu Std                0.4820692
Policy mu Max                2.5523498
Policy mu Min                -2.0396767
Policy log std Mean          -0.1790824
Policy log std Std           0.10846852
Policy log std Max           -0.043271072
Policy log std Min           -0.75801367
Z mean eval                  0.0257968
Z variance eval              0.3451813
total_rewards                [289.44780153 318.25154768 267.64861627 325.69034024 454.23095316
 282.7021436  311.54276159 252.80566843 287.32253123 282.64652392]
total_rewards_mean           307.2288887653993
total_rewards_std            53.42032341951192
total_rewards_max            454.2309531622125
total_rewards_min            252.8056684260374
Number of train steps total  14000
Number of env steps total    72000
Number of rollouts total     0
Train Time (s)               27.97297855792567
(Previous) Eval Time (s)     1.7016995348967612
Sample Time (s)              14.327519420068711
Epoch Time (s)               44.002197512891144
Total Train Time (s)         635.4203544179909
Epoch                        13
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:26:17.056178 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #13 | Epoch Duration: 44.23452115058899
2020-01-10 18:26:17.056471 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #13 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025726208
Z variance train             0.34518066
KL Divergence                1.0815973
KL Loss                      0.108159736
QF Loss                      290.16364
VF Loss                      139.62639
Policy Loss                  -211.70673
Q Predictions Mean           203.43523
Q Predictions Std            375.06393
Q Predictions Max            1206.2394
Q Predictions Min            18.991856
V Predictions Mean           212.8956
V Predictions Std            373.2084
V Predictions Max            1234.5706
V Predictions Min            28.755749
Log Pis Mean                 -8.90415
Log Pis Std                  5.2591023
Log Pis Max                  11.8939085
Log Pis Min                  -13.361626
Policy mu Mean               0.06433079
Policy mu Std                0.46787152
Policy mu Max                2.556254
Policy mu Min                -1.8482867
Policy log std Mean          -0.17955767
Policy log std Std           0.10300694
Policy log std Max           -0.069270924
Policy log std Min           -0.78914225
Z mean eval                  0.030519256
Z variance eval              0.3402341
total_rewards                [291.66868211 317.64182357 291.02644006 323.29740403 358.19315956
 295.84686107 315.08719313 356.75980053 348.5226619  320.48328001]
total_rewards_mean           321.8527305977225
total_rewards_std            24.198191000507126
total_rewards_max            358.1931595597193
total_rewards_min            291.02644006497934
Number of train steps total  15000
Number of env steps total    77000
Number of rollouts total     0
Train Time (s)               29.134020518045872
(Previous) Eval Time (s)     1.9337448189035058
Sample Time (s)              14.183808698318899
Epoch Time (s)               45.25157403526828
Total Train Time (s)         680.5725797289051
Epoch                        14
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:27:02.206859 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #14 | Epoch Duration: 45.150150537490845
2020-01-10 18:27:02.207082 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #14 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030465912
Z variance train             0.34022382
KL Divergence                1.0982702
KL Loss                      0.10982702
QF Loss                      586.1839
VF Loss                      297.72916
Policy Loss                  -222.16042
Q Predictions Mean           213.99374
Q Predictions Std            382.96497
Q Predictions Max            1229.7307
Q Predictions Min            18.208565
V Predictions Mean           220.2927
V Predictions Std            375.3722
V Predictions Max            1240.7189
V Predictions Min            24.976
Log Pis Mean                 -8.930431
Log Pis Std                  5.008998
Log Pis Max                  8.941965
Log Pis Min                  -14.86006
Policy mu Mean               0.067400776
Policy mu Std                0.4917381
Policy mu Max                2.4450095
Policy mu Min                -2.1761584
Policy log std Mean          -0.17815661
Policy log std Std           0.10287109
Policy log std Max           -0.027608268
Policy log std Min           -0.71165204
Z mean eval                  0.034040958
Z variance eval              0.32821602
total_rewards                [284.36819679 293.95853871 272.60299861 311.52341195 269.7033637
 315.49718037 293.98894404 333.83127213 331.67969057 273.82843342]
total_rewards_mean           298.0982030297761
total_rewards_std            22.705415976663062
total_rewards_max            333.83127212920067
total_rewards_min            269.70336370184117
Number of train steps total  16000
Number of env steps total    82000
Number of rollouts total     0
Train Time (s)               30.396215680986643
(Previous) Eval Time (s)     1.8320693303830922
Sample Time (s)              14.716521728783846
Epoch Time (s)               46.94480674015358
Total Train Time (s)         727.44381608814
Epoch                        15
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:27:49.078203 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #15 | Epoch Duration: 46.870957136154175
2020-01-10 18:27:49.078401 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #15 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033988066
Z variance train             0.3282563
KL Divergence                1.15795
KL Loss                      0.11579501
QF Loss                      620.2591
VF Loss                      170.28937
Policy Loss                  -261.6382
Q Predictions Mean           252.74069
Q Predictions Std            420.13763
Q Predictions Max            1265.5465
Q Predictions Min            16.457357
V Predictions Mean           263.35788
V Predictions Std            418.29636
V Predictions Max            1258.3914
V Predictions Min            26.182137
Log Pis Mean                 -8.179572
Log Pis Std                  5.973585
Log Pis Max                  12.93039
Log Pis Min                  -13.457066
Policy mu Mean               0.07782741
Policy mu Std                0.5292389
Policy mu Max                2.4435298
Policy mu Min                -1.7526683
Policy log std Mean          -0.1913018
Policy log std Std           0.116332166
Policy log std Max           -0.05932612
Policy log std Min           -0.76137716
Z mean eval                  0.036823224
Z variance eval              0.32183138
total_rewards                [434.03353077 338.67569    417.24125433 350.18049879 365.42479198
 377.25914853 366.45491439 297.14096633 331.16518363 357.65724314]
total_rewards_mean           363.52332218876677
total_rewards_std            37.87043891723845
total_rewards_max            434.0335307700876
total_rewards_min            297.14096633473764
Number of train steps total  17000
Number of env steps total    87000
Number of rollouts total     0
Train Time (s)               30.68416219810024
(Previous) Eval Time (s)     1.757945055142045
Sample Time (s)              15.291342379525304
Epoch Time (s)               47.73344963276759
Total Train Time (s)         775.5077126557007
Epoch                        16
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:28:37.144241 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #16 | Epoch Duration: 48.06568360328674
2020-01-10 18:28:37.144454 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #16 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036813032
Z variance train             0.32169417
KL Divergence                1.1838117
KL Loss                      0.118381165
QF Loss                      479.72974
VF Loss                      235.31424
Policy Loss                  -245.52617
Q Predictions Mean           236.1871
Q Predictions Std            401.37195
Q Predictions Max            1266.2959
Q Predictions Min            15.949271
V Predictions Mean           241.57573
V Predictions Std            393.92603
V Predictions Max            1272.9762
V Predictions Min            25.01774
Log Pis Mean                 -8.345785
Log Pis Std                  5.8420873
Log Pis Max                  11.254019
Log Pis Min                  -13.438822
Policy mu Mean               0.10241984
Policy mu Std                0.51254505
Policy mu Max                2.4860554
Policy mu Min                -1.8619708
Policy log std Mean          -0.18546534
Policy log std Std           0.10808584
Policy log std Max           -0.059661835
Policy log std Min           -0.70414305
Z mean eval                  0.037647475
Z variance eval              0.3208233
total_rewards                [308.53163985 319.49377534 336.11798009 360.91628002 362.87829365
 313.22714621 372.30983027 337.52784206 285.40437197 414.41027198]
total_rewards_mean           341.0817431435804
total_rewards_std            35.580095559395325
total_rewards_max            414.4102719806079
total_rewards_min            285.4043719690922
Number of train steps total  18000
Number of env steps total    92000
Number of rollouts total     0
Train Time (s)               29.74538654787466
(Previous) Eval Time (s)     2.0898836348205805
Sample Time (s)              14.320422414224595
Epoch Time (s)               46.155692596919835
Total Train Time (s)         821.5771852061152
Epoch                        17
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:29:23.214901 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #17 | Epoch Duration: 46.07021379470825
2020-01-10 18:29:23.215189 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #17 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037905596
Z variance train             0.32092947
KL Divergence                1.1790171
KL Loss                      0.117901705
QF Loss                      440.59485
VF Loss                      253.96494
Policy Loss                  -221.3528
Q Predictions Mean           210.18091
Q Predictions Std            370.66394
Q Predictions Max            1324.8231
Q Predictions Min            17.356033
V Predictions Mean           216.18405
V Predictions Std            362.34122
V Predictions Max            1283.6797
V Predictions Min            28.7055
Log Pis Mean                 -8.604006
Log Pis Std                  5.4559846
Log Pis Max                  10.067706
Log Pis Min                  -14.791357
Policy mu Mean               0.07666325
Policy mu Std                0.5126564
Policy mu Max                2.4784017
Policy mu Min                -1.6896602
Policy log std Mean          -0.18634008
Policy log std Std           0.11081578
Policy log std Max           -0.066835366
Policy log std Min           -0.6974933
Z mean eval                  0.043008305
Z variance eval              0.31278685
total_rewards                [344.45293467 306.85753228 310.7737925  350.64515019 373.5981505
 290.54965502 330.66181738 398.88380872 285.62951199 426.25232754]
total_rewards_mean           341.83046808029314
total_rewards_std            44.24536922765967
total_rewards_max            426.252327544163
total_rewards_min            285.6295119887447
Number of train steps total  19000
Number of env steps total    97000
Number of rollouts total     0
Train Time (s)               30.257435540668666
(Previous) Eval Time (s)     2.0041194148361683
Sample Time (s)              14.49753241892904
Epoch Time (s)               46.759087374433875
Total Train Time (s)         868.3364415490068
Epoch                        18
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:30:09.976907 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #18 | Epoch Duration: 46.76150584220886
2020-01-10 18:30:09.977200 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #18 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04294114
Z variance train             0.31284097
KL Divergence                1.2184696
KL Loss                      0.12184697
QF Loss                      376.08337
VF Loss                      127.342255
Policy Loss                  -219.54092
Q Predictions Mean           208.16675
Q Predictions Std            359.6377
Q Predictions Max            1266.0428
Q Predictions Min            15.742927
V Predictions Mean           217.7912
V Predictions Std            359.4795
V Predictions Max            1303.2362
V Predictions Min            26.22999
Log Pis Mean                 -8.865077
Log Pis Std                  5.273268
Log Pis Max                  15.192863
Log Pis Min                  -13.70646
Policy mu Mean               0.07710296
Policy mu Std                0.477852
Policy mu Max                2.4905832
Policy mu Min                -1.9721724
Policy log std Mean          -0.18026377
Policy log std Std           0.1012363
Policy log std Max           -0.08204214
Policy log std Min           -0.76623905
Z mean eval                  0.047412775
Z variance eval              0.29997286
total_rewards                [365.47439461 372.37751917 356.810615   333.30388968 306.40438966
 317.83362832 322.54410128 377.44244283 368.85669428 404.09233484]
total_rewards_mean           352.51400096797863
total_rewards_std            29.53959237953541
total_rewards_max            404.0923348416988
total_rewards_min            306.40438966402894
Number of train steps total  20000
Number of env steps total    102000
Number of rollouts total     0
Train Time (s)               27.4862366062589
(Previous) Eval Time (s)     2.006230320315808
Sample Time (s)              15.152953885030001
Epoch Time (s)               44.64542081160471
Total Train Time (s)         912.840828796383
Epoch                        19
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:30:54.482703 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #19 | Epoch Duration: 44.50520443916321
2020-01-10 18:30:54.483006 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #19 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04749315
Z variance train             0.29994184
KL Divergence                1.2883927
KL Loss                      0.12883927
QF Loss                      395.59485
VF Loss                      255.69754
Policy Loss                  -180.09749
Q Predictions Mean           169.66446
Q Predictions Std            338.88312
Q Predictions Max            1515.3885
Q Predictions Min            18.548195
V Predictions Mean           176.8955
V Predictions Std            330.8747
V Predictions Max            1409.2136
V Predictions Min            27.270754
Log Pis Mean                 -9.286646
Log Pis Std                  5.0915446
Log Pis Max                  12.685326
Log Pis Min                  -13.879165
Policy mu Mean               0.07865753
Policy mu Std                0.43808016
Policy mu Max                2.7814014
Policy mu Min                -1.8553487
Policy log std Mean          -0.16866857
Policy log std Std           0.098267235
Policy log std Max           -0.07658867
Policy log std Min           -0.7545402
Z mean eval                  0.04834462
Z variance eval              0.29537097
total_rewards                [356.29449433 412.97303008 375.89875004 356.19744124 357.62348338
 286.6105106  288.43818031 360.77925749 324.86221337 458.65655934]
total_rewards_mean           357.8333920173148
total_rewards_std            49.518993837661476
total_rewards_max            458.65655933525727
total_rewards_min            286.61051059842856
Number of train steps total  21000
Number of env steps total    107000
Number of rollouts total     0
Train Time (s)               27.590650307945907
(Previous) Eval Time (s)     1.8657281370833516
Sample Time (s)              15.043463693466038
Epoch Time (s)               44.499842138495296
Total Train Time (s)         957.6512748175301
Epoch                        20
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:31:39.295381 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #20 | Epoch Duration: 44.812166690826416
2020-01-10 18:31:39.295668 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #20 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.048266347
Z variance train             0.29537612
KL Divergence                1.307803
KL Loss                      0.13078031
QF Loss                      520.54443
VF Loss                      121.76765
Policy Loss                  -242.36673
Q Predictions Mean           234.15889
Q Predictions Std            397.0437
Q Predictions Max            1292.5901
Q Predictions Min            16.888805
V Predictions Mean           243.65155
V Predictions Std            394.89517
V Predictions Max            1293.8818
V Predictions Min            25.310438
Log Pis Mean                 -8.821828
Log Pis Std                  4.840367
Log Pis Max                  7.0700226
Log Pis Min                  -13.214195
Policy mu Mean               0.07616374
Policy mu Std                0.47709453
Policy mu Max                2.3362932
Policy mu Min                -1.812032
Policy log std Mean          -0.17877547
Policy log std Std           0.1043239
Policy log std Max           -0.063407056
Policy log std Min           -0.66410553
Z mean eval                  0.05260427
Z variance eval              0.28883728
total_rewards                [375.0770293  392.72363692 357.79850939 346.65007947 401.3812127
 517.86220493 370.72074804 333.51011217 340.21378419 396.33290567]
total_rewards_mean           383.2270222761794
total_rewards_std            50.24676905131508
total_rewards_max            517.86220492668
total_rewards_min            333.5101121714685
Number of train steps total  22000
Number of env steps total    112000
Number of rollouts total     0
Train Time (s)               27.245232727844268
(Previous) Eval Time (s)     2.177779223769903
Sample Time (s)              14.64215253200382
Epoch Time (s)               44.06516448361799
Total Train Time (s)         1001.7272097943351
Epoch                        21
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:32:23.372130 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #21 | Epoch Duration: 44.0761981010437
2020-01-10 18:32:23.372407 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #21 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.052861564
Z variance train             0.2888359
KL Divergence                1.3497586
KL Loss                      0.13497587
QF Loss                      416.11798
VF Loss                      156.12386
Policy Loss                  -249.77446
Q Predictions Mean           239.19989
Q Predictions Std            386.57053
Q Predictions Max            1316.7441
Q Predictions Min            18.449114
V Predictions Mean           249.38692
V Predictions Std            386.32852
V Predictions Max            1296.221
V Predictions Min            25.885769
Log Pis Mean                 -8.451639
Log Pis Std                  5.4705625
Log Pis Max                  11.924088
Log Pis Min                  -13.692337
Policy mu Mean               0.098237105
Policy mu Std                0.51210517
Policy mu Max                2.565071
Policy mu Min                -2.0375743
Policy log std Mean          -0.18693627
Policy log std Std           0.11360939
Policy log std Max           -0.02420675
Policy log std Min           -0.7273039
Z mean eval                  0.060346346
Z variance eval              0.27639413
total_rewards                [496.77795461 403.73063495 322.63822129 385.50385114 382.52133153
 270.38713811 341.22265278 423.47389771 317.59144387 465.10978371]
total_rewards_mean           380.89569096995416
total_rewards_std            66.38251225608123
total_rewards_max            496.77795461167574
total_rewards_min            270.3871381144163
Number of train steps total  23000
Number of env steps total    117000
Number of rollouts total     0
Train Time (s)               28.792947520967573
(Previous) Eval Time (s)     2.1885625990107656
Sample Time (s)              14.530646201223135
Epoch Time (s)               45.51215632120147
Total Train Time (s)         1047.2941684988327
Epoch                        22
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:33:08.939444 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #22 | Epoch Duration: 45.56683158874512
2020-01-10 18:33:08.939650 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #22 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06008328
Z variance train             0.27640072
KL Divergence                1.4277792
KL Loss                      0.14277792
QF Loss                      589.71173
VF Loss                      219.16583
Policy Loss                  -253.6863
Q Predictions Mean           245.00194
Q Predictions Std            394.4331
Q Predictions Max            1293.1285
Q Predictions Min            18.197187
V Predictions Mean           255.3138
V Predictions Std            394.49908
V Predictions Max            1319.7876
V Predictions Min            26.897398
Log Pis Mean                 -8.7302885
Log Pis Std                  5.105197
Log Pis Max                  11.402178
Log Pis Min                  -14.490823
Policy mu Mean               0.08433892
Policy mu Std                0.4929085
Policy mu Max                2.3410904
Policy mu Min                -1.8486053
Policy log std Mean          -0.18430403
Policy log std Std           0.112730555
Policy log std Max           -0.050537035
Policy log std Min           -0.78096694
Z mean eval                  0.06044901
Z variance eval              0.2743731
total_rewards                [348.32848267 361.78682058 395.06703408 321.0050904  316.29014408
 351.59101061 392.93420049 423.25574108 510.76238844 483.99601416]
total_rewards_mean           390.5016926579379
total_rewards_std            62.25568776581017
total_rewards_max            510.76238843658825
total_rewards_min            316.2901440766744
Number of train steps total  24000
Number of env steps total    122000
Number of rollouts total     0
Train Time (s)               28.122186624910682
(Previous) Eval Time (s)     2.242952947039157
Sample Time (s)              14.34771200409159
Epoch Time (s)               44.71285157604143
Total Train Time (s)         1092.1686711222865
Epoch                        23
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:33:53.814438 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #23 | Epoch Duration: 44.874632120132446
2020-01-10 18:33:53.814628 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #23 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.060757983
Z variance train             0.27434644
KL Divergence                1.4455721
KL Loss                      0.14455722
QF Loss                      458.9263
VF Loss                      204.92632
Policy Loss                  -269.3025
Q Predictions Mean           258.8258
Q Predictions Std            417.63843
Q Predictions Max            1306.6703
Q Predictions Min            19.208103
V Predictions Mean           264.64285
V Predictions Std            412.1112
V Predictions Max            1294.8921
V Predictions Min            28.442558
Log Pis Mean                 -8.379164
Log Pis Std                  5.355378
Log Pis Max                  10.480431
Log Pis Min                  -13.133204
Policy mu Mean               0.13258082
Policy mu Std                0.5057917
Policy mu Max                2.5241625
Policy mu Min                -1.9820722
Policy log std Mean          -0.19017549
Policy log std Std           0.115680575
Policy log std Max           -0.08540964
Policy log std Min           -0.83963144
Z mean eval                  0.06353116
Z variance eval              0.28241548
total_rewards                [503.29095349 481.7272065  550.8651653  358.02088928 297.99498653
 392.30272436 316.28214771 358.69422047 691.25105269 342.17025098]
total_rewards_mean           429.25995973120524
total_rewards_std            118.60017763952236
total_rewards_max            691.2510526912088
total_rewards_min            297.994986532958
Number of train steps total  25000
Number of env steps total    127000
Number of rollouts total     0
Train Time (s)               31.372239738237113
(Previous) Eval Time (s)     2.404495502822101
Sample Time (s)              14.48362832609564
Epoch Time (s)               48.260363567154855
Total Train Time (s)         1140.66968005104
Epoch                        24
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:34:42.318051 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #24 | Epoch Duration: 48.50326657295227
2020-01-10 18:34:42.318241 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #24 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06356458
Z variance train             0.2824616
KL Divergence                1.3961315
KL Loss                      0.13961315
QF Loss                      378.7669
VF Loss                      112.22792
Policy Loss                  -276.5993
Q Predictions Mean           269.04517
Q Predictions Std            438.2717
Q Predictions Max            1300.8162
Q Predictions Min            17.978199
V Predictions Mean           276.83325
V Predictions Std            432.85107
V Predictions Max            1320.6819
V Predictions Min            25.575651
Log Pis Mean                 -8.580681
Log Pis Std                  5.314486
Log Pis Max                  9.0719595
Log Pis Min                  -14.009889
Policy mu Mean               0.1345827
Policy mu Std                0.5031806
Policy mu Max                2.314824
Policy mu Min                -1.747617
Policy log std Mean          -0.18898875
Policy log std Std           0.11202905
Policy log std Max           -0.04142137
Policy log std Min           -0.6673774
Z mean eval                  0.067470275
Z variance eval              0.26938987
total_rewards                [465.28895217 575.74504984 400.99566985 678.41273765 301.52419314
 337.27601269 511.09679158 380.00877589 371.68250676 539.27226351]
total_rewards_mean           456.13029530795075
total_rewards_std            113.0177358727393
total_rewards_max            678.4127376483614
total_rewards_min            301.5241931354769
Number of train steps total  26000
Number of env steps total    132000
Number of rollouts total     0
Train Time (s)               29.852612355258316
(Previous) Eval Time (s)     2.6471386151388288
Sample Time (s)              14.88149814400822
Epoch Time (s)               47.381249114405364
Total Train Time (s)         1188.1886953446083
Epoch                        25
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:35:29.838943 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #25 | Epoch Duration: 47.52051401138306
2020-01-10 18:35:29.839211 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #25 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06745306
Z variance train             0.2693812
KL Divergence                1.4741787
KL Loss                      0.14741787
QF Loss                      707.10803
VF Loss                      233.91795
Policy Loss                  -267.6972
Q Predictions Mean           261.11484
Q Predictions Std            405.99905
Q Predictions Max            1352.902
Q Predictions Min            17.805634
V Predictions Mean           267.1916
V Predictions Std            398.4142
V Predictions Max            1349.9786
V Predictions Min            29.49473
Log Pis Mean                 -8.029875
Log Pis Std                  6.1218467
Log Pis Max                  19.332108
Log Pis Min                  -14.01127
Policy mu Mean               0.13048774
Policy mu Std                0.540313
Policy mu Max                2.4485126
Policy mu Min                -2.3359313
Policy log std Mean          -0.1977697
Policy log std Std           0.12701729
Policy log std Max           -0.06565531
Policy log std Min           -0.8971897
Z mean eval                  0.07090014
Z variance eval              0.267474
total_rewards                [322.89244363 373.52254811 502.29580588 496.2521785  345.12355521
 391.25210326 341.50444261 420.83986502 356.05043253 476.64518643]
total_rewards_mean           402.637856116751
total_rewards_std            64.07494893350528
total_rewards_max            502.2958058809851
total_rewards_min            322.8924436282934
Number of train steps total  27000
Number of env steps total    137000
Number of rollouts total     0
Train Time (s)               30.410582433920354
(Previous) Eval Time (s)     2.786124211270362
Sample Time (s)              15.162646552082151
Epoch Time (s)               48.35935319727287
Total Train Time (s)         1236.143880458083
Epoch                        26
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:36:17.793709 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #26 | Epoch Duration: 47.9543035030365
2020-01-10 18:36:17.793888 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #26 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0709705
Z variance train             0.26748228
KL Divergence                1.5005403
KL Loss                      0.15005402
QF Loss                      506.2517
VF Loss                      165.98827
Policy Loss                  -249.19081
Q Predictions Mean           240.39285
Q Predictions Std            396.4265
Q Predictions Max            1326.945
Q Predictions Min            16.51717
V Predictions Mean           249.79736
V Predictions Std            389.74948
V Predictions Max            1313.5691
V Predictions Min            30.614023
Log Pis Mean                 -8.759819
Log Pis Std                  5.175242
Log Pis Max                  15.661969
Log Pis Min                  -14.314182
Policy mu Mean               0.10719437
Policy mu Std                0.48052293
Policy mu Max                2.4319663
Policy mu Min                -2.050119
Policy log std Mean          -0.18294919
Policy log std Std           0.10543698
Policy log std Max           -0.07943801
Policy log std Min           -0.7737639
Z mean eval                  0.07452296
Z variance eval              0.26774037
total_rewards                [299.96362712 358.97984993 461.458138   388.080753   480.58603667
 432.42030327 283.63699275 408.40152474 462.49956061 787.73645071]
total_rewards_mean           436.3763236789138
total_rewards_std            133.33364214325616
total_rewards_max            787.7364507096069
total_rewards_min            283.6369927502834
Number of train steps total  28000
Number of env steps total    142000
Number of rollouts total     0
Train Time (s)               27.9041876103729
(Previous) Eval Time (s)     2.3807971766218543
Sample Time (s)              14.866403551772237
Epoch Time (s)               45.15138833876699
Total Train Time (s)         1281.7519109509885
Epoch                        27
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:37:03.404156 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #27 | Epoch Duration: 45.61013197898865
2020-01-10 18:37:03.404383 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #27 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07449082
Z variance train             0.2676855
KL Divergence                1.4961333
KL Loss                      0.14961334
QF Loss                      419.534
VF Loss                      596.85785
Policy Loss                  -284.30948
Q Predictions Mean           275.9621
Q Predictions Std            427.23114
Q Predictions Max            1322.5807
Q Predictions Min            17.185942
V Predictions Mean           287.90283
V Predictions Std            424.84082
V Predictions Max            1342.3563
V Predictions Min            27.367252
Log Pis Mean                 -8.273943
Log Pis Std                  5.263603
Log Pis Max                  6.538555
Log Pis Min                  -12.855019
Policy mu Mean               0.12351457
Policy mu Std                0.5057755
Policy mu Max                2.51097
Policy mu Min                -1.9333879
Policy log std Mean          -0.1870132
Policy log std Std           0.11095801
Policy log std Max           -0.047211237
Policy log std Min           -0.76577
Z mean eval                  0.075122915
Z variance eval              0.25738782
total_rewards                [378.07174824 394.38320578 476.95999068 481.29496296 572.31140524
 583.70303377 273.85504268 316.09106379 305.22930454 284.53265053]
total_rewards_mean           406.6432408213872
total_rewards_std            110.14002888185139
total_rewards_max            583.7030337674165
total_rewards_min            273.8550426780246
Number of train steps total  29000
Number of env steps total    147000
Number of rollouts total     0
Train Time (s)               28.637616583146155
(Previous) Eval Time (s)     2.839248728007078
Sample Time (s)              15.061953753698617
Epoch Time (s)               46.53881906485185
Total Train Time (s)         1327.9296580548398
Epoch                        28
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:37:49.582106 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #28 | Epoch Duration: 46.17755460739136
2020-01-10 18:37:49.582277 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #28 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07519637
Z variance train             0.25735533
KL Divergence                1.5689657
KL Loss                      0.15689658
QF Loss                      595.73883
VF Loss                      204.4251
Policy Loss                  -274.22598
Q Predictions Mean           265.4394
Q Predictions Std            424.53833
Q Predictions Max            1373.4279
Q Predictions Min            15.766169
V Predictions Mean           270.2663
V Predictions Std            416.20322
V Predictions Max            1329.7798
V Predictions Min            23.827713
Log Pis Mean                 -9.117685
Log Pis Std                  4.5700774
Log Pis Max                  9.74398
Log Pis Min                  -16.007223
Policy mu Mean               0.0939896
Policy mu Std                0.47056574
Policy mu Max                2.7142878
Policy mu Min                -1.8064928
Policy log std Mean          -0.17830905
Policy log std Std           0.10277683
Policy log std Max           -0.05427271
Policy log std Min           -0.8516612
Z mean eval                  0.07354412
Z variance eval              0.25571066
total_rewards                [510.8123633  413.82650441 387.44420196 358.32551887 233.61144355
 581.57142749 434.33960195 384.89925218 344.43598478 424.29711956]
total_rewards_mean           407.35634180639715
total_rewards_std            89.19758434616577
total_rewards_max            581.57142749083
total_rewards_min            233.61144354731124
Number of train steps total  30000
Number of env steps total    152000
Number of rollouts total     0
Train Time (s)               28.50445739692077
(Previous) Eval Time (s)     2.477695527020842
Sample Time (s)              14.077352504245937
Epoch Time (s)               45.05950542818755
Total Train Time (s)         1372.8624402433634
Epoch                        29
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:38:34.518002 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #29 | Epoch Duration: 44.93554949760437
2020-01-10 18:38:34.518298 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #29 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07311803
Z variance train             0.25568774
KL Divergence                1.5903733
KL Loss                      0.15903734
QF Loss                      306.7881
VF Loss                      201.20154
Policy Loss                  -268.79227
Q Predictions Mean           260.90247
Q Predictions Std            423.89096
Q Predictions Max            1326.0955
Q Predictions Min            14.772324
V Predictions Mean           271.2245
V Predictions Std            425.36276
V Predictions Max            1360.0585
V Predictions Min            21.50914
Log Pis Mean                 -8.818242
Log Pis Std                  5.2458816
Log Pis Max                  16.942333
Log Pis Min                  -14.937386
Policy mu Mean               0.09933926
Policy mu Std                0.47678658
Policy mu Max                2.7551103
Policy mu Min                -2.5220718
Policy log std Mean          -0.18545619
Policy log std Std           0.10899918
Policy log std Max           -0.07547817
Policy log std Min           -0.85118824
Z mean eval                  0.076857775
Z variance eval              0.2503298
total_rewards                [365.92366554 587.55989873 444.28238732 391.76860337 413.00254812
 370.79573634 449.66883444 365.48762715 397.69335304 363.17810329]
total_rewards_mean           414.9360757332687
total_rewards_std            64.94533030186588
total_rewards_max            587.5598987258508
total_rewards_min            363.1781032933876
Number of train steps total  31000
Number of env steps total    157000
Number of rollouts total     0
Train Time (s)               29.339934944175184
(Previous) Eval Time (s)     2.3534650462679565
Sample Time (s)              14.672052232082933
Epoch Time (s)               46.36545222252607
Total Train Time (s)         1419.2545330272987
Epoch                        30
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:39:20.909657 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #30 | Epoch Duration: 46.3911566734314
2020-01-10 18:39:20.909851 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #30 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07675657
Z variance train             0.25030994
KL Divergence                1.630304
KL Loss                      0.1630304
QF Loss                      646.9778
VF Loss                      351.41418
Policy Loss                  -264.75745
Q Predictions Mean           258.65814
Q Predictions Std            421.73926
Q Predictions Max            1382.878
Q Predictions Min            17.087914
V Predictions Mean           270.7279
V Predictions Std            421.59808
V Predictions Max            1385.5587
V Predictions Min            21.740084
Log Pis Mean                 -8.535409
Log Pis Std                  5.1937265
Log Pis Max                  16.826786
Log Pis Min                  -12.918938
Policy mu Mean               0.11166004
Policy mu Std                0.49876437
Policy mu Max                2.5398378
Policy mu Min                -2.295317
Policy log std Mean          -0.18971793
Policy log std Std           0.114045724
Policy log std Max           -0.08151432
Policy log std Min           -0.84451723
Z mean eval                  0.077063404
Z variance eval              0.24829745
total_rewards                [330.34425213 472.47416619 476.10755135 392.32737885 378.16950561
 566.97462124 441.97874511 410.20964301 485.83402196 418.88707585]
total_rewards_mean           437.3306961306051
total_rewards_std            63.21992974152018
total_rewards_max            566.9746212438445
total_rewards_min            330.34425212785777
Number of train steps total  32000
Number of env steps total    162000
Number of rollouts total     0
Train Time (s)               30.061023687943816
(Previous) Eval Time (s)     2.3789298380725086
Sample Time (s)              14.651121148839593
Epoch Time (s)               47.09107467485592
Total Train Time (s)         1466.6076230471954
Epoch                        31
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:40:08.263885 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #31 | Epoch Duration: 47.35390615463257
2020-01-10 18:40:08.264053 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #31 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07710009
Z variance train             0.2483176
KL Divergence                1.6376894
KL Loss                      0.16376893
QF Loss                      633.3739
VF Loss                      308.69095
Policy Loss                  -307.1281
Q Predictions Mean           301.08615
Q Predictions Std            460.28436
Q Predictions Max            1377.3513
Q Predictions Min            15.757421
V Predictions Mean           313.20874
V Predictions Std            462.25766
V Predictions Max            1377.0671
V Predictions Min            26.922901
Log Pis Mean                 -8.720402
Log Pis Std                  4.9675164
Log Pis Max                  13.247938
Log Pis Min                  -13.268082
Policy mu Mean               0.11565436
Policy mu Std                0.4929501
Policy mu Max                2.5765245
Policy mu Min                -2.1653345
Policy log std Mean          -0.19111823
Policy log std Std           0.11366291
Policy log std Max           0.038578957
Policy log std Min           -0.8252287
Z mean eval                  0.075649515
Z variance eval              0.24128702
total_rewards                [396.39624241 367.17316147 364.5679921  392.86047428 387.31074192
 454.05334697 323.05345334 297.96570208 632.39237467 352.60367442]
total_rewards_mean           396.8377163659026
total_rewards_std            88.29731938040996
total_rewards_max            632.3923746708879
total_rewards_min            297.965702083624
Number of train steps total  33000
Number of env steps total    167000
Number of rollouts total     0
Train Time (s)               30.086195063777268
(Previous) Eval Time (s)     2.641470046248287
Sample Time (s)              15.088220663368702
Epoch Time (s)               47.81588577339426
Total Train Time (s)         1514.2446968718432
Epoch                        32
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:40:55.902901 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #32 | Epoch Duration: 47.638654947280884
2020-01-10 18:40:55.903125 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #32 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07569021
Z variance train             0.24123271
KL Divergence                1.6948951
KL Loss                      0.16948952
QF Loss                      312.93884
VF Loss                      162.91876
Policy Loss                  -272.53387
Q Predictions Mean           264.13803
Q Predictions Std            431.3992
Q Predictions Max            1363.7695
Q Predictions Min            18.926277
V Predictions Mean           272.997
V Predictions Std            428.49622
V Predictions Max            1373.5566
V Predictions Min            30.05374
Log Pis Mean                 -8.44823
Log Pis Std                  5.292596
Log Pis Max                  9.134952
Log Pis Min                  -14.771905
Policy mu Mean               0.109092645
Policy mu Std                0.49713832
Policy mu Max                2.2404606
Policy mu Min                -2.0151048
Policy log std Mean          -0.18606794
Policy log std Std           0.11209877
Policy log std Max           -0.06998356
Policy log std Min           -0.7101392
Z mean eval                  0.07224205
Z variance eval              0.23401356
total_rewards                [340.46756876 408.61968164 328.8186454  446.07561184 492.50553717
 564.72294449 414.05468048 568.75864489 474.56766416 459.22007489]
total_rewards_mean           449.7811053706373
total_rewards_std            77.1115185517776
total_rewards_max            568.7586448876489
total_rewards_min            328.8186453976216
Number of train steps total  34000
Number of env steps total    172000
Number of rollouts total     0
Train Time (s)               26.8084783940576
(Previous) Eval Time (s)     2.463960826396942
Sample Time (s)              14.824873632285744
Epoch Time (s)               44.09731285274029
Total Train Time (s)         1558.7317127618007
Epoch                        33
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:41:40.393425 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #33 | Epoch Duration: 44.49009323120117
2020-01-10 18:41:40.393732 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #33 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.072085455
Z variance train             0.23404446
KL Divergence                1.752306
KL Loss                      0.1752306
QF Loss                      725.35767
VF Loss                      518.0855
Policy Loss                  -287.95178
Q Predictions Mean           276.16074
Q Predictions Std            429.71445
Q Predictions Max            1400.7202
Q Predictions Min            13.44331
V Predictions Mean           282.64404
V Predictions Std            425.25174
V Predictions Max            1383.6528
V Predictions Min            12.886461
Log Pis Mean                 -8.543211
Log Pis Std                  5.3982954
Log Pis Max                  18.072039
Log Pis Min                  -14.913155
Policy mu Mean               0.13963208
Policy mu Std                0.49752378
Policy mu Max                2.8719153
Policy mu Min                -2.873848
Policy log std Mean          -0.1888073
Policy log std Std           0.10797903
Policy log std Max           -0.06795153
Policy log std Min           -0.8205447
Z mean eval                  0.070543036
Z variance eval              0.23104873
total_rewards                [394.41648851 462.95763248 479.05987882 316.38217097 562.5417329
 312.20665549 365.85693117 359.0518139  451.17123371 344.71992761]
total_rewards_mean           404.8364465560094
total_rewards_std            77.23192580593201
total_rewards_max            562.541732897464
total_rewards_min            312.20665549384165
Number of train steps total  35000
Number of env steps total    177000
Number of rollouts total     0
Train Time (s)               29.65988288866356
(Previous) Eval Time (s)     2.8564751013182104
Sample Time (s)              14.642881444189698
Epoch Time (s)               47.15923943417147
Total Train Time (s)         1605.2951434766874
Epoch                        34
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:42:26.958872 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #34 | Epoch Duration: 46.56489181518555
2020-01-10 18:42:26.959146 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #34 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07054403
Z variance train             0.23106083
KL Divergence                1.7844524
KL Loss                      0.17844525
QF Loss                      735.3191
VF Loss                      319.58112
Policy Loss                  -264.29895
Q Predictions Mean           253.43729
Q Predictions Std            409.9892
Q Predictions Max            1396.4685
Q Predictions Min            16.905834
V Predictions Mean           263.64987
V Predictions Std            407.103
V Predictions Max            1386.1447
V Predictions Min            29.411093
Log Pis Mean                 -8.647006
Log Pis Std                  5.3996353
Log Pis Max                  16.138384
Log Pis Min                  -13.488781
Policy mu Mean               0.13301511
Policy mu Std                0.4940456
Policy mu Max                2.7924213
Policy mu Min                -2.4347625
Policy log std Mean          -0.18599038
Policy log std Std           0.11045283
Policy log std Max           -0.059082627
Policy log std Min           -0.83544254
Z mean eval                  0.06851625
Z variance eval              0.23090644
total_rewards                [326.75610157 339.64130282 518.48637405 236.81474392 254.39276729
 346.27903839 370.48588016 285.54872481 319.84850343 406.79005506]
total_rewards_mean           340.5043491503279
total_rewards_std            76.68566865019697
total_rewards_max            518.4863740481684
total_rewards_min            236.81474392413142
Number of train steps total  36000
Number of env steps total    182000
Number of rollouts total     0
Train Time (s)               28.898961955681443
(Previous) Eval Time (s)     2.2618635832332075
Sample Time (s)              15.094688445329666
Epoch Time (s)               46.25551398424432
Total Train Time (s)         1651.3856873637997
Epoch                        35
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:43:13.047721 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #35 | Epoch Duration: 46.08837699890137
2020-01-10 18:43:13.047908 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #35 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.068708934
Z variance train             0.23083338
KL Divergence                1.7723147
KL Loss                      0.17723148
QF Loss                      634.9258
VF Loss                      454.59436
Policy Loss                  -321.97003
Q Predictions Mean           315.68933
Q Predictions Std            452.05725
Q Predictions Max            1390.2203
Q Predictions Min            16.37507
V Predictions Mean           322.4224
V Predictions Std            444.89636
V Predictions Max            1378.5068
V Predictions Min            13.031582
Log Pis Mean                 -7.973175
Log Pis Std                  5.356464
Log Pis Max                  9.16981
Log Pis Min                  -12.951699
Policy mu Mean               0.16730724
Policy mu Std                0.52566266
Policy mu Max                2.3662813
Policy mu Min                -1.8236136
Policy log std Mean          -0.19908097
Policy log std Std           0.118263096
Policy log std Max           -0.046322092
Policy log std Min           -0.65936625
Z mean eval                  0.067467295
Z variance eval              0.22402962
total_rewards                [285.76225291 404.72596837 591.19416016 410.85977765 348.83533891
 708.4422555  353.24353343 498.82324869 430.14675951 370.79011103]
total_rewards_mean           440.2823406152156
total_rewards_std            120.41086476006082
total_rewards_max            708.4422554985572
total_rewards_min            285.7622529072779
Number of train steps total  37000
Number of env steps total    187000
Number of rollouts total     0
Train Time (s)               29.43502045609057
(Previous) Eval Time (s)     2.0944630848243833
Sample Time (s)              15.007344298064709
Epoch Time (s)               46.53682783897966
Total Train Time (s)         1698.4554422916844
Epoch                        36
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:44:00.119307 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #36 | Epoch Duration: 47.07125473022461
2020-01-10 18:44:00.119497 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #36 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06752057
Z variance train             0.22406927
KL Divergence                1.8240983
KL Loss                      0.18240984
QF Loss                      477.15723
VF Loss                      242.75613
Policy Loss                  -256.3601
Q Predictions Mean           243.2154
Q Predictions Std            397.63232
Q Predictions Max            1390.6609
Q Predictions Min            15.747646
V Predictions Mean           253.6962
V Predictions Std            396.78934
V Predictions Max            1399.5023
V Predictions Min            26.354536
Log Pis Mean                 -8.488961
Log Pis Std                  5.3442163
Log Pis Max                  12.193266
Log Pis Min                  -12.83714
Policy mu Mean               0.16084988
Policy mu Std                0.47282317
Policy mu Max                2.37641
Policy mu Min                -1.6655641
Policy log std Mean          -0.1861924
Policy log std Std           0.11006806
Policy log std Max           -0.08575863
Policy log std Min           -0.7442971
Z mean eval                  0.06476614
Z variance eval              0.21952227
total_rewards                [401.18156744 411.25201047 431.7042906  313.1720865  363.61363293
 389.08016379 230.91519651 275.69831081 634.70595822 533.45778793]
total_rewards_mean           398.478100519657
total_rewards_std            112.70791892608612
total_rewards_max            634.7059582192699
total_rewards_min            230.91519650840593
Number of train steps total  38000
Number of env steps total    192000
Number of rollouts total     0
Train Time (s)               28.311438297852874
(Previous) Eval Time (s)     2.6285948711447418
Sample Time (s)              15.602520405314863
Epoch Time (s)               46.54255357431248
Total Train Time (s)         1744.9813335835934
Epoch                        37
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:44:46.647774 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #37 | Epoch Duration: 46.528106927871704
2020-01-10 18:44:46.648021 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #37 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06449141
Z variance train             0.21950233
KL Divergence                1.8656461
KL Loss                      0.18656461
QF Loss                      632.18475
VF Loss                      366.8207
Policy Loss                  -283.14316
Q Predictions Mean           278.34085
Q Predictions Std            452.1845
Q Predictions Max            1396.1362
Q Predictions Min            17.025286
V Predictions Mean           289.17337
V Predictions Std            449.94714
V Predictions Max            1382.3978
V Predictions Min            29.365171
Log Pis Mean                 -8.519749
Log Pis Std                  5.1575823
Log Pis Max                  7.956127
Log Pis Min                  -13.875981
Policy mu Mean               0.12458329
Policy mu Std                0.4845235
Policy mu Max                2.4987185
Policy mu Min                -1.8120395
Policy log std Mean          -0.18438868
Policy log std Std           0.11032452
Policy log std Max           -0.057816923
Policy log std Min           -0.80766237
Z mean eval                  0.061061494
Z variance eval              0.21480438
total_rewards                [726.85213509 308.78940625 433.62130958 492.91213818 416.73520753
 598.56198298 226.12235077 334.05304169 343.97172805 462.09493987]
total_rewards_mean           434.3714239991972
total_rewards_std            139.42206278423762
total_rewards_max            726.8521350868954
total_rewards_min            226.1223507678305
Number of train steps total  39000
Number of env steps total    197000
Number of rollouts total     0
Train Time (s)               30.06010342389345
(Previous) Eval Time (s)     2.6138536506332457
Sample Time (s)              14.989127045031637
Epoch Time (s)               47.663084119558334
Total Train Time (s)         1792.7974860477261
Epoch                        38
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:45:34.463188 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #38 | Epoch Duration: 47.81500434875488
2020-01-10 18:45:34.463328 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #38 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.061149634
Z variance train             0.21486571
KL Divergence                1.9108815
KL Loss                      0.19108815
QF Loss                      229.88657
VF Loss                      124.3402
Policy Loss                  -263.88962
Q Predictions Mean           253.68393
Q Predictions Std            429.94687
Q Predictions Max            1426.798
Q Predictions Min            17.140087
V Predictions Mean           259.76645
V Predictions Std            422.93457
V Predictions Max            1411.375
V Predictions Min            28.456589
Log Pis Mean                 -8.864034
Log Pis Std                  4.672903
Log Pis Max                  7.0200005
Log Pis Min                  -13.220898
Policy mu Mean               0.109464705
Policy mu Std                0.47281456
Policy mu Max                2.2114317
Policy mu Min                -1.8783911
Policy log std Mean          -0.18326664
Policy log std Std           0.10789739
Policy log std Max           -0.07489814
Policy log std Min           -0.6911335
Z mean eval                  0.061048996
Z variance eval              0.21317509
total_rewards                [362.18253481 321.82910258 328.20401567 304.40389979 413.62123879
 278.65004044 257.586719   361.03493633 585.04957766 386.31902009]
total_rewards_mean           359.8881085174803
total_rewards_std            87.6847616533309
total_rewards_max            585.0495776644317
total_rewards_min            257.5867190008766
Number of train steps total  40000
Number of env steps total    202000
Number of rollouts total     0
Train Time (s)               28.56821842910722
(Previous) Eval Time (s)     2.765498989727348
Sample Time (s)              15.502181211486459
Epoch Time (s)               46.835898630321026
Total Train Time (s)         1839.158522624988
Epoch                        39
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:46:20.827685 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #39 | Epoch Duration: 46.3642053604126
2020-01-10 18:46:20.827971 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #39 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.061127227
Z variance train             0.21315686
KL Divergence                1.9324515
KL Loss                      0.19324516
QF Loss                      433.76004
VF Loss                      112.61423
Policy Loss                  -260.24915
Q Predictions Mean           249.10327
Q Predictions Std            425.66904
Q Predictions Max            1394.6487
Q Predictions Min            16.466688
V Predictions Mean           260.82858
V Predictions Std            424.44217
V Predictions Max            1395.5325
V Predictions Min            26.2429
Log Pis Mean                 -8.9532
Log Pis Std                  5.060437
Log Pis Max                  11.260677
Log Pis Min                  -13.558026
Policy mu Mean               0.08943007
Policy mu Std                0.471062
Policy mu Max                2.3107946
Policy mu Min                -2.0048194
Policy log std Mean          -0.18324693
Policy log std Std           0.11044882
Policy log std Max           -0.04828669
Policy log std Min           -0.70684874
Z mean eval                  0.06061719
Z variance eval              0.21908097
total_rewards                [481.41815497 338.02579183 385.81638885 380.59405424 383.32575966
 515.65891492 353.11860803 511.13812031 355.17147857 358.91663688]
total_rewards_mean           406.3183908245232
total_rewards_std            65.23056340014905
total_rewards_max            515.6589149175011
total_rewards_min            338.02579183411143
Number of train steps total  41000
Number of env steps total    207000
Number of rollouts total     0
Train Time (s)               29.37916994187981
(Previous) Eval Time (s)     2.2935030637308955
Sample Time (s)              15.046517287380993
Epoch Time (s)               46.7191902929917
Total Train Time (s)         1886.3362390529364
Epoch                        40
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:47:08.005765 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #40 | Epoch Duration: 47.17760467529297
2020-01-10 18:47:08.005961 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #40 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.060628913
Z variance train             0.21902986
KL Divergence                1.8837495
KL Loss                      0.18837495
QF Loss                      465.20813
VF Loss                      350.55823
Policy Loss                  -312.44284
Q Predictions Mean           305.27405
Q Predictions Std            464.64966
Q Predictions Max            1373.2157
Q Predictions Min            17.792439
V Predictions Mean           317.16412
V Predictions Std            465.4722
V Predictions Max            1418.0153
V Predictions Min            27.952585
Log Pis Mean                 -8.252048
Log Pis Std                  5.476054
Log Pis Max                  11.749509
Log Pis Min                  -14.635162
Policy mu Mean               0.11958125
Policy mu Std                0.5275799
Policy mu Max                2.1597743
Policy mu Min                -1.7310485
Policy log std Mean          -0.19187252
Policy log std Std           0.11403767
Policy log std Max           -0.046594106
Policy log std Min           -0.6754937
Z mean eval                  0.058975983
Z variance eval              0.21330726
total_rewards                [439.35571468 310.10121698 416.3690046  343.39415305 362.99789523
 441.12859251 406.25677113 753.95561103 565.62137958 390.4270118 ]
total_rewards_mean           442.96073505860466
total_rewards_std            122.70008322674231
total_rewards_max            753.9556110311613
total_rewards_min            310.1012169837729
Number of train steps total  42000
Number of env steps total    212000
Number of rollouts total     0
Train Time (s)               28.121662674937397
(Previous) Eval Time (s)     2.751653949264437
Sample Time (s)              15.851657079998404
Epoch Time (s)               46.72497370420024
Total Train Time (s)         1933.1021690377966
Epoch                        41
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:47:54.772926 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #41 | Epoch Duration: 46.76681566238403
2020-01-10 18:47:54.773130 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #41 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.058925927
Z variance train             0.21325834
KL Divergence                1.9244871
KL Loss                      0.19244872
QF Loss                      618.60596
VF Loss                      123.29894
Policy Loss                  -308.03516
Q Predictions Mean           302.21182
Q Predictions Std            442.2882
Q Predictions Max            1408.2361
Q Predictions Min            14.975464
V Predictions Mean           309.87125
V Predictions Std            436.2058
V Predictions Max            1409.9604
V Predictions Min            28.314535
Log Pis Mean                 -8.242598
Log Pis Std                  5.199874
Log Pis Max                  7.2736244
Log Pis Min                  -16.298977
Policy mu Mean               0.15561819
Policy mu Std                0.51430494
Policy mu Max                2.2081418
Policy mu Min                -2.1530826
Policy log std Mean          -0.19632603
Policy log std Std           0.11378673
Policy log std Max           -0.062217683
Policy log std Min           -0.70918155
Z mean eval                  0.057864875
Z variance eval              0.21223155
total_rewards                [531.89171415 521.82613596 402.23940717 430.20713424 362.11667386
 319.71389432 607.69676061 674.25442522 447.89267026 292.90723114]
total_rewards_mean           459.07460469341476
total_rewards_std            117.58122157183598
total_rewards_max            674.2544252230373
total_rewards_min            292.9072311350431
Number of train steps total  43000
Number of env steps total    217000
Number of rollouts total     0
Train Time (s)               29.876233558170497
(Previous) Eval Time (s)     2.793188137933612
Sample Time (s)              15.50439037103206
Epoch Time (s)               48.17381206713617
Total Train Time (s)         1981.2631133543327
Epoch                        42
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:48:42.936707 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #42 | Epoch Duration: 48.16339683532715
2020-01-10 18:48:42.936950 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #42 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.057839967
Z variance train             0.21223135
KL Divergence                1.9346758
KL Loss                      0.19346759
QF Loss                      868.8207
VF Loss                      254.52472
Policy Loss                  -289.66888
Q Predictions Mean           285.02982
Q Predictions Std            460.1375
Q Predictions Max            1420.2006
Q Predictions Min            14.913112
V Predictions Mean           296.0226
V Predictions Std            458.49716
V Predictions Max            1409.6
V Predictions Min            24.444632
Log Pis Mean                 -8.44869
Log Pis Std                  5.3673396
Log Pis Max                  11.149096
Log Pis Min                  -13.006442
Policy mu Mean               0.12419265
Policy mu Std                0.4886939
Policy mu Max                2.2321818
Policy mu Min                -2.0328095
Policy log std Mean          -0.1894725
Policy log std Std           0.11657756
Policy log std Max           -0.05097288
Policy log std Min           -0.7617391
Z mean eval                  0.057677448
Z variance eval              0.20763497
total_rewards                [365.84301597 596.84481327 396.10163102 386.42119261 415.92740231
 391.22500604 477.51385838 411.76042777 406.07749846 531.20393657]
total_rewards_mean           437.89187824003994
total_rewards_std            70.34558587243394
total_rewards_max            596.8448132670455
total_rewards_min            365.84301597443
Number of train steps total  44000
Number of env steps total    222000
Number of rollouts total     0
Train Time (s)               29.415200907271355
(Previous) Eval Time (s)     2.782473268918693
Sample Time (s)              15.323828437831253
Epoch Time (s)               47.5215026140213
Total Train Time (s)         2028.7039079563692
Epoch                        43
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:49:30.379259 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #43 | Epoch Duration: 47.44210696220398
2020-01-10 18:49:30.379484 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #43 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.057653077
Z variance train             0.20761128
KL Divergence                1.9761007
KL Loss                      0.19761007
QF Loss                      758.7517
VF Loss                      102.18637
Policy Loss                  -292.66544
Q Predictions Mean           285.48706
Q Predictions Std            454.13318
Q Predictions Max            1442.5701
Q Predictions Min            15.26025
V Predictions Mean           293.77856
V Predictions Std            449.10184
V Predictions Max            1408.4337
V Predictions Min            24.956488
Log Pis Mean                 -8.2952175
Log Pis Std                  5.532467
Log Pis Max                  9.672121
Log Pis Min                  -13.489283
Policy mu Mean               0.15372531
Policy mu Std                0.5053267
Policy mu Max                2.220722
Policy mu Min                -1.6948655
Policy log std Mean          -0.19288717
Policy log std Std           0.11621113
Policy log std Max           -0.088102415
Policy log std Min           -0.8294046
Z mean eval                  0.055144258
Z variance eval              0.20736916
total_rewards                [551.80530526 299.3650434  574.73337159 569.29573609 601.18875412
 584.40846453 341.3743827  338.04991658 328.70053969 834.93610183]
total_rewards_mean           502.3857615792368
total_rewards_std            162.34155321166537
total_rewards_max            834.9361018309452
total_rewards_min            299.36504340143057
Number of train steps total  45000
Number of env steps total    227000
Number of rollouts total     0
Train Time (s)               30.049361408688128
(Previous) Eval Time (s)     2.7028127517551184
Sample Time (s)              15.371022967621684
Epoch Time (s)               48.12319712806493
Total Train Time (s)         2076.9848831701092
Epoch                        44
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:50:18.661771 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #44 | Epoch Duration: 48.282081842422485
2020-01-10 18:50:18.662020 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #44 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.055297147
Z variance train             0.20734882
KL Divergence                1.9759644
KL Loss                      0.19759645
QF Loss                      572.3775
VF Loss                      159.4213
Policy Loss                  -325.02182
Q Predictions Mean           314.3524
Q Predictions Std            475.94266
Q Predictions Max            1423.729
Q Predictions Min            16.700748
V Predictions Mean           322.15408
V Predictions Std            472.01984
V Predictions Max            1426.9369
V Predictions Min            28.147303
Log Pis Mean                 -8.523071
Log Pis Std                  4.981628
Log Pis Max                  9.822711
Log Pis Min                  -14.054959
Policy mu Mean               0.12840277
Policy mu Std                0.51693213
Policy mu Max                2.4882362
Policy mu Min                -1.9536452
Policy log std Mean          -0.19164109
Policy log std Std           0.11364066
Policy log std Max           -0.07185815
Policy log std Min           -0.7436504
Z mean eval                  0.05499495
Z variance eval              0.20845318
total_rewards                [333.95116096 438.56220286 458.82239748 289.38019095 687.50364851
 469.55614242 444.47768528 407.44970241 700.50010486 556.78949444]
total_rewards_mean           478.6992730164673
total_rewards_std            128.07184682650683
total_rewards_max            700.5001048612164
total_rewards_min            289.3801909450915
Number of train steps total  46000
Number of env steps total    232000
Number of rollouts total     0
Train Time (s)               28.95242449408397
(Previous) Eval Time (s)     2.861392774619162
Sample Time (s)              15.885226044338197
Epoch Time (s)               47.69904331304133
Total Train Time (s)         2124.846480135806
Epoch                        45
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:51:06.524254 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #45 | Epoch Duration: 47.862016916275024
2020-01-10 18:51:06.524524 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #45 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05502355
Z variance train             0.20846288
KL Divergence                1.9681617
KL Loss                      0.19681618
QF Loss                      631.23883
VF Loss                      132.52344
Policy Loss                  -389.81845
Q Predictions Mean           381.88647
Q Predictions Std            504.82748
Q Predictions Max            1443.0292
Q Predictions Min            16.145977
V Predictions Mean           387.46045
V Predictions Std            497.69077
V Predictions Max            1448.7268
V Predictions Min            25.09509
Log Pis Mean                 -7.793885
Log Pis Std                  5.185053
Log Pis Max                  6.057217
Log Pis Min                  -13.803915
Policy mu Mean               0.16199401
Policy mu Std                0.55916536
Policy mu Max                2.2998133
Policy mu Min                -2.159678
Policy log std Mean          -0.20552267
Policy log std Std           0.12311974
Policy log std Max           -0.028983608
Policy log std Min           -0.7793852
Z mean eval                  0.05493179
Z variance eval              0.20847395
total_rewards                [333.30640812 397.53548696 397.920823   562.03450243 388.13200522
 471.52833312 386.50147415 388.27955689 407.97098846 410.28784792]
total_rewards_mean           414.3497426276266
total_rewards_std            58.6519974434973
total_rewards_max            562.0345024313369
total_rewards_min            333.3064081181012
Number of train steps total  47000
Number of env steps total    237000
Number of rollouts total     0
Train Time (s)               28.780391518957913
(Previous) Eval Time (s)     3.0240674037486315
Sample Time (s)              15.628536849282682
Epoch Time (s)               47.432995771989226
Total Train Time (s)         2172.1095556849614
Epoch                        46
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:51:53.790646 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #46 | Epoch Duration: 47.2659010887146
2020-01-10 18:51:53.790905 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #46 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.054832287
Z variance train             0.20851707
KL Divergence                1.9619955
KL Loss                      0.19619955
QF Loss                      563.7736
VF Loss                      183.5419
Policy Loss                  -317.86368
Q Predictions Mean           309.5315
Q Predictions Std            471.16562
Q Predictions Max            1410.3815
Q Predictions Min            18.527342
V Predictions Mean           317.7494
V Predictions Std            470.32758
V Predictions Max            1435.6466
V Predictions Min            22.864746
Log Pis Mean                 -8.215149
Log Pis Std                  5.5967455
Log Pis Max                  11.709699
Log Pis Min                  -15.062069
Policy mu Mean               0.11918133
Policy mu Std                0.5266056
Policy mu Max                2.8718219
Policy mu Min                -2.1790109
Policy log std Mean          -0.19440599
Policy log std Std           0.11864989
Policy log std Max           0.03375733
Policy log std Min           -0.8122005
Z mean eval                  0.05294656
Z variance eval              0.20273383
total_rewards                [512.91151224 549.77411431 544.28751977 333.87498221 423.44394614
 531.08207889 528.85730142 625.76248972 346.58130896 346.41401332]
total_rewards_mean           474.29892669815234
total_rewards_std            98.08131656852396
total_rewards_max            625.7624897223828
total_rewards_min            333.87498221151293
Number of train steps total  48000
Number of env steps total    242000
Number of rollouts total     0
Train Time (s)               29.992644269950688
(Previous) Eval Time (s)     2.8566961023025215
Sample Time (s)              14.558768478222191
Epoch Time (s)               47.4081088504754
Total Train Time (s)         2219.572987737134
Epoch                        47
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:52:41.252717 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #47 | Epoch Duration: 47.46162128448486
2020-01-10 18:52:41.252886 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #47 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05292474
Z variance train             0.20273693
KL Divergence                2.0176373
KL Loss                      0.20176373
QF Loss                      452.3009
VF Loss                      160.87376
Policy Loss                  -328.65808
Q Predictions Mean           321.51733
Q Predictions Std            489.27573
Q Predictions Max            1464.2544
Q Predictions Min            17.59993
V Predictions Mean           326.2052
V Predictions Std            482.5409
V Predictions Max            1422.7197
V Predictions Min            23.244501
Log Pis Mean                 -9.1922655
Log Pis Std                  4.155115
Log Pis Max                  9.605139
Log Pis Min                  -14.557643
Policy mu Mean               0.113279775
Policy mu Std                0.4593607
Policy mu Max                2.3459308
Policy mu Min                -2.0462968
Policy log std Mean          -0.1836716
Policy log std Std           0.10233687
Policy log std Max           -0.05112011
Policy log std Min           -0.70370334
Z mean eval                  0.052569233
Z variance eval              0.19816259
total_rewards                [304.70926946 631.73154181 350.68803471 295.23510041 419.58440776
 334.9010911  364.23854873 616.54252863 671.65762271 457.75421859]
total_rewards_mean           444.704236391194
total_rewards_std            136.4283241133271
total_rewards_max            671.6576227120768
total_rewards_min            295.2351004056543
Number of train steps total  49000
Number of env steps total    247000
Number of rollouts total     0
Train Time (s)               28.972232873085886
(Previous) Eval Time (s)     2.9099656301550567
Sample Time (s)              15.174305133987218
Epoch Time (s)               47.05650363722816
Total Train Time (s)         2266.4011849300005
Epoch                        48
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:53:28.085245 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #48 | Epoch Duration: 46.832199811935425
2020-01-10 18:53:28.085529 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #48 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.052394163
Z variance train             0.19813876
KL Divergence                2.0682926
KL Loss                      0.20682926
QF Loss                      551.1388
VF Loss                      199.52185
Policy Loss                  -326.55353
Q Predictions Mean           320.30975
Q Predictions Std            461.04926
Q Predictions Max            1441.5763
Q Predictions Min            20.933718
V Predictions Mean           327.77472
V Predictions Std            457.66763
V Predictions Max            1452.0583
V Predictions Min            28.150742
Log Pis Mean                 -8.694656
Log Pis Std                  4.412686
Log Pis Max                  5.3019886
Log Pis Min                  -13.062882
Policy mu Mean               0.14684685
Policy mu Std                0.4917721
Policy mu Max                2.343265
Policy mu Min                -2.4962401
Policy log std Mean          -0.19527242
Policy log std Std           0.11215237
Policy log std Max           -0.05679506
Policy log std Min           -0.7118468
Z mean eval                  0.052771337
Z variance eval              0.1976796
total_rewards                [624.35514576 381.48334532 647.27397407 592.7021959  337.68052865
 496.38403974 505.51429125 317.17474525 521.11448488 542.77126666]
total_rewards_mean           496.64540174852266
total_rewards_std            110.35060345820666
total_rewards_max            647.2739740714969
total_rewards_min            317.17474525426485
Number of train steps total  50000
Number of env steps total    252000
Number of rollouts total     0
Train Time (s)               29.6387547547929
(Previous) Eval Time (s)     2.6853926139883697
Sample Time (s)              15.35027790395543
Epoch Time (s)               47.6744252727367
Total Train Time (s)         2314.304562740959
Epoch                        49
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:54:15.988098 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #49 | Epoch Duration: 47.902353286743164
2020-01-10 18:54:15.988290 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #49 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.052661914
Z variance train             0.19767639
KL Divergence                2.0764174
KL Loss                      0.20764175
QF Loss                      509.60837
VF Loss                      155.32089
Policy Loss                  -405.38147
Q Predictions Mean           399.10352
Q Predictions Std            509.6202
Q Predictions Max            1454.168
Q Predictions Min            17.252094
V Predictions Mean           406.20563
V Predictions Std            505.0195
V Predictions Max            1467.8822
V Predictions Min            28.39806
Log Pis Mean                 -7.329221
Log Pis Std                  5.580095
Log Pis Max                  6.4943957
Log Pis Min                  -14.329434
Policy mu Mean               0.19135767
Policy mu Std                0.5769896
Policy mu Max                2.282282
Policy mu Min                -1.8786446
Policy log std Mean          -0.20934185
Policy log std Std           0.12191504
Policy log std Max           -0.043911666
Policy log std Min           -0.690775
Z mean eval                  0.05095006
Z variance eval              0.19460562
total_rewards                [ 633.28848635 1118.81082438  391.95102135  941.82657559  785.54715729
  458.6381259   397.50187488  454.55673027  313.85667652  426.37181586]
total_rewards_mean           592.2349288398084
total_rewards_std            256.5919965882652
total_rewards_max            1118.810824384294
total_rewards_min            313.856676517532
Number of train steps total  51000
Number of env steps total    257000
Number of rollouts total     0
Train Time (s)               28.10394454281777
(Previous) Eval Time (s)     2.913055815268308
Sample Time (s)              15.40587470587343
Epoch Time (s)               46.42287506395951
Total Train Time (s)         2361.535105658695
Epoch                        50
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:55:03.219173 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #50 | Epoch Duration: 47.230740785598755
2020-01-10 18:55:03.219341 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #50 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.050997514
Z variance train             0.19461535
KL Divergence                2.107809
KL Loss                      0.2107809
QF Loss                      677.15094
VF Loss                      214.42662
Policy Loss                  -368.53925
Q Predictions Mean           360.66614
Q Predictions Std            500.96765
Q Predictions Max            1465.4336
Q Predictions Min            14.2770815
V Predictions Mean           368.34586
V Predictions Std            497.2864
V Predictions Max            1463.195
V Predictions Min            24.694635
Log Pis Mean                 -8.058878
Log Pis Std                  5.1260223
Log Pis Max                  5.7057886
Log Pis Min                  -13.463812
Policy mu Mean               0.17486209
Policy mu Std                0.52729356
Policy mu Max                2.1512058
Policy mu Min                -1.9319104
Policy log std Mean          -0.2043811
Policy log std Std           0.12359242
Policy log std Max           -0.08849114
Policy log std Min           -0.7581008
Z mean eval                  0.05180139
Z variance eval              0.18922475
total_rewards                [339.40562938 571.15720891 324.01467478 510.55652561 521.12999946
 488.27522791 264.35749189 577.08381159 424.92386842 500.07095878]
total_rewards_mean           452.09753967181234
total_rewards_std            103.28572093480281
total_rewards_max            577.0838115915546
total_rewards_min            264.35749188711856
Number of train steps total  52000
Number of env steps total    262000
Number of rollouts total     0
Train Time (s)               28.953416743781418
(Previous) Eval Time (s)     3.7206378718838096
Sample Time (s)              15.404344980139285
Epoch Time (s)               48.07839959580451
Total Train Time (s)         2409.0295669492334
Epoch                        51
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:55:50.718589 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #51 | Epoch Duration: 47.49907422065735
2020-01-10 18:55:50.718914 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #51 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.051880352
Z variance train             0.18921664
KL Divergence                2.1660244
KL Loss                      0.21660244
QF Loss                      738.56055
VF Loss                      149.78796
Policy Loss                  -348.22122
Q Predictions Mean           342.88104
Q Predictions Std            489.4673
Q Predictions Max            1462.2009
Q Predictions Min            16.468279
V Predictions Mean           345.58185
V Predictions Std            479.6263
V Predictions Max            1463.8153
V Predictions Min            24.041918
Log Pis Mean                 -8.337919
Log Pis Std                  4.9621706
Log Pis Max                  9.571594
Log Pis Min                  -13.534017
Policy mu Mean               0.15423247
Policy mu Std                0.5130867
Policy mu Max                2.4746463
Policy mu Min                -2.0106883
Policy log std Mean          -0.19259632
Policy log std Std           0.11529893
Policy log std Max           -0.05647345
Policy log std Min           -0.68287694
Z mean eval                  0.052110035
Z variance eval              0.18754062
total_rewards                [522.12330223 486.47383458 553.64082914 431.18092634 425.43382656
 443.55213988 390.67661969 447.86062896 463.92894292 384.02329149]
total_rewards_mean           454.8894341786445
total_rewards_std            51.09254184435932
total_rewards_max            553.6408291390753
total_rewards_min            384.02329148535335
Number of train steps total  53000
Number of env steps total    267000
Number of rollouts total     0
Train Time (s)               29.337612344883382
(Previous) Eval Time (s)     3.1410077367909253
Sample Time (s)              14.786245379131287
Epoch Time (s)               47.264865460805595
Total Train Time (s)         2455.9566576168872
Epoch                        52
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:56:37.646642 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #52 | Epoch Duration: 46.92747473716736
2020-01-10 18:56:37.646908 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #52 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.052166183
Z variance train             0.1875366
KL Divergence                2.1863327
KL Loss                      0.21863328
QF Loss                      592.2448
VF Loss                      173.52321
Policy Loss                  -350.98932
Q Predictions Mean           343.3743
Q Predictions Std            502.6125
Q Predictions Max            1472.3278
Q Predictions Min            17.396595
V Predictions Mean           347.6486
V Predictions Std            493.267
V Predictions Max            1460.8776
V Predictions Min            26.524076
Log Pis Mean                 -8.261487
Log Pis Std                  5.250941
Log Pis Max                  5.938769
Log Pis Min                  -14.122036
Policy mu Mean               0.15144193
Policy mu Std                0.53074646
Policy mu Max                2.3312654
Policy mu Min                -1.9523895
Policy log std Mean          -0.19988877
Policy log std Std           0.11920903
Policy log std Max           -0.044039503
Policy log std Min           -0.69689786
Z mean eval                  0.05247301
Z variance eval              0.19659397
total_rewards                [487.86667141 780.49785758 361.68136224 736.64558183 430.33347022
 459.11599257 444.11845155 467.07271181 719.12605121 404.47265873]
total_rewards_mean           529.0930809155984
total_rewards_std            146.0715405546758
total_rewards_max            780.49785758419
total_rewards_min            361.68136224434767
Number of train steps total  54000
Number of env steps total    272000
Number of rollouts total     0
Train Time (s)               29.405104795005172
(Previous) Eval Time (s)     2.8033539783209562
Sample Time (s)              15.163821263704449
Epoch Time (s)               47.37228003703058
Total Train Time (s)         2503.755238433834
Epoch                        53
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:57:25.447922 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #53 | Epoch Duration: 47.800779819488525
2020-01-10 18:57:25.448193 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #53 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.052313752
Z variance train             0.19653039
KL Divergence                2.0943868
KL Loss                      0.20943868
QF Loss                      913.27814
VF Loss                      165.7413
Policy Loss                  -377.10266
Q Predictions Mean           369.32513
Q Predictions Std            496.55295
Q Predictions Max            1472.051
Q Predictions Min            15.574758
V Predictions Mean           378.21063
V Predictions Std            494.5115
V Predictions Max            1461.1
V Predictions Min            24.476778
Log Pis Mean                 -7.9063725
Log Pis Std                  5.096348
Log Pis Max                  11.100575
Log Pis Min                  -12.873631
Policy mu Mean               0.16986285
Policy mu Std                0.5400235
Policy mu Max                2.604579
Policy mu Min                -1.8962703
Policy log std Mean          -0.20552883
Policy log std Std           0.12330931
Policy log std Max           -0.067517
Policy log std Min           -0.7618009
Z mean eval                  0.05285403
Z variance eval              0.18786576
total_rewards                [370.00203923 609.94088014 486.97907046 425.20547026 431.35872982
 419.43382111 322.14236161 448.19516219 455.47266498 453.27313954]
total_rewards_mean           442.2003339342656
total_rewards_std            71.43382686381652
total_rewards_max            609.9408801439728
total_rewards_min            322.1423616075615
Number of train steps total  55000
Number of env steps total    277000
Number of rollouts total     0
Train Time (s)               29.544628193136305
(Previous) Eval Time (s)     3.23157563759014
Sample Time (s)              15.103885744698346
Epoch Time (s)               47.88008957542479
Total Train Time (s)         2551.2140518524684
Epoch                        54
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:58:12.906292 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #54 | Epoch Duration: 47.45788908004761
2020-01-10 18:58:12.906458 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #54 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.052895837
Z variance train             0.18791635
KL Divergence                2.178265
KL Loss                      0.21782652
QF Loss                      373.93063
VF Loss                      294.10327
Policy Loss                  -328.76477
Q Predictions Mean           319.91263
Q Predictions Std            455.55795
Q Predictions Max            1467.4849
Q Predictions Min            14.672165
V Predictions Mean           332.00317
V Predictions Std            454.4953
V Predictions Max            1468.6511
V Predictions Min            28.339508
Log Pis Mean                 -7.915146
Log Pis Std                  5.475192
Log Pis Max                  10.701864
Log Pis Min                  -12.872934
Policy mu Mean               0.16525833
Policy mu Std                0.53263146
Policy mu Max                2.4215508
Policy mu Min                -2.3048832
Policy log std Mean          -0.19934298
Policy log std Std           0.11510062
Policy log std Max           -0.027319632
Policy log std Min           -0.7032553
Z mean eval                  0.05427609
Z variance eval              0.1929049
total_rewards                [563.77373638 395.50655118 466.49240262 398.68202385 450.94209034
 512.30515745 553.97815256 459.33787767 402.91549658 344.11552861]
total_rewards_mean           454.8049017219605
total_rewards_std            68.4095069138021
total_rewards_max            563.773736377976
total_rewards_min            344.1155286068299
Number of train steps total  56000
Number of env steps total    282000
Number of rollouts total     0
Train Time (s)               29.612082125619054
(Previous) Eval Time (s)     2.809118981938809
Sample Time (s)              14.642541883513331
Epoch Time (s)               47.063742991071194
Total Train Time (s)         2598.2623136998154
Epoch                        55
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:58:59.958392 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #55 | Epoch Duration: 47.051753520965576
2020-01-10 18:58:59.958685 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #55 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.054372203
Z variance train             0.1928606
KL Divergence                2.1280375
KL Loss                      0.21280375
QF Loss                      567.07184
VF Loss                      253.85277
Policy Loss                  -332.7091
Q Predictions Mean           326.1825
Q Predictions Std            493.28433
Q Predictions Max            1499.007
Q Predictions Min            15.068592
V Predictions Mean           330.13208
V Predictions Std            482.25955
V Predictions Max            1456.6028
V Predictions Min            24.276312
Log Pis Mean                 -8.094526
Log Pis Std                  5.360708
Log Pis Max                  9.259875
Log Pis Min                  -13.554456
Policy mu Mean               0.15547276
Policy mu Std                0.51009417
Policy mu Max                2.0743737
Policy mu Min                -2.0840044
Policy log std Mean          -0.19438925
Policy log std Std           0.11096976
Policy log std Max           -0.046764024
Policy log std Min           -0.679855
Z mean eval                  0.054860987
Z variance eval              0.18747114
total_rewards                [554.03586485 428.22701521 454.98828202 587.0988831  564.72040646
 449.22554133 618.45350674 559.12331949 518.9721478  357.10942727]
total_rewards_mean           509.1954394277317
total_rewards_std            78.68238695321183
total_rewards_max            618.4535067447998
total_rewards_min            357.1094272677001
Number of train steps total  57000
Number of env steps total    287000
Number of rollouts total     0
Train Time (s)               31.55522852903232
(Previous) Eval Time (s)     2.7968473536893725
Sample Time (s)              15.406065572984517
Epoch Time (s)               49.75814145570621
Total Train Time (s)         2648.6390900309198
Epoch                        56
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:59:50.335097 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #56 | Epoch Duration: 50.37619161605835
2020-01-10 18:59:50.335292 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #56 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05488683
Z variance train             0.1874723
KL Divergence                2.1983516
KL Loss                      0.21983516
QF Loss                      490.96088
VF Loss                      212.0051
Policy Loss                  -340.81146
Q Predictions Mean           331.39673
Q Predictions Std            493.03223
Q Predictions Max            1484.319
Q Predictions Min            15.310037
V Predictions Mean           335.7619
V Predictions Std            484.84872
V Predictions Max            1466.7358
V Predictions Min            23.870245
Log Pis Mean                 -8.208284
Log Pis Std                  5.3435087
Log Pis Max                  11.529324
Log Pis Min                  -13.3849125
Policy mu Mean               0.15136452
Policy mu Std                0.53143716
Policy mu Max                2.8078837
Policy mu Min                -2.1300771
Policy log std Mean          -0.1985215
Policy log std Std           0.12457074
Policy log std Max           -0.04132215
Policy log std Min           -0.7930511
Z mean eval                  0.055101644
Z variance eval              0.18951866
total_rewards                [683.30059702 381.65701845 375.81936603 491.18173746 320.06660487
 529.96054999 555.08620285 530.19942664 573.51696354 518.89574505]
total_rewards_mean           495.96842119093435
total_rewards_std            102.9184992805348
total_rewards_max            683.3005970221985
total_rewards_min            320.0666048739533
Number of train steps total  58000
Number of env steps total    292000
Number of rollouts total     0
Train Time (s)               29.92888205870986
(Previous) Eval Time (s)     3.414639593102038
Sample Time (s)              15.569766778033227
Epoch Time (s)               48.913288429845124
Total Train Time (s)         2697.18105755141
Epoch                        57
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:00:38.877496 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #57 | Epoch Duration: 48.542070150375366
2020-01-10 19:00:38.877641 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #57 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.055277877
Z variance train             0.18948542
KL Divergence                2.1819906
KL Loss                      0.21819906
QF Loss                      647.1181
VF Loss                      560.47235
Policy Loss                  -438.4054
Q Predictions Mean           429.1432
Q Predictions Std            544.96246
Q Predictions Max            1483.782
Q Predictions Min            15.661069
V Predictions Mean           430.24103
V Predictions Std            531.4871
V Predictions Max            1484.3604
V Predictions Min            26.890541
Log Pis Mean                 -7.403731
Log Pis Std                  5.5869274
Log Pis Max                  8.272204
Log Pis Min                  -14.371599
Policy mu Mean               0.1888563
Policy mu Std                0.5624241
Policy mu Max                2.4468899
Policy mu Min                -2.1583555
Policy log std Mean          -0.21157978
Policy log std Std           0.12810338
Policy log std Max           -0.036609434
Policy log std Min           -0.725216
Z mean eval                  0.055945735
Z variance eval              0.183646
total_rewards                [581.94642397 554.53990142 477.68330068 401.79367494 433.03785027
 465.11223264 484.47172658 457.63020926 598.88060625 615.47835382]
total_rewards_mean           507.0574279839144
total_rewards_std            70.84087693410223
total_rewards_max            615.4783538244923
total_rewards_min            401.7936749395179
Number of train steps total  59000
Number of env steps total    297000
Number of rollouts total     0
Train Time (s)               28.255586883984506
(Previous) Eval Time (s)     3.0431041410192847
Sample Time (s)              15.30225224327296
Epoch Time (s)               46.60094326827675
Total Train Time (s)         2743.9346259692684
Epoch                        58
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:01:25.633765 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #58 | Epoch Duration: 46.75599670410156
2020-01-10 19:01:25.633958 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #58 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.056336123
Z variance train             0.1836278
KL Divergence                2.2447743
KL Loss                      0.22447744
QF Loss                      436.26324
VF Loss                      590.32294
Policy Loss                  -326.0384
Q Predictions Mean           315.52283
Q Predictions Std            480.10788
Q Predictions Max            1483.0121
Q Predictions Min            13.171864
V Predictions Mean           313.41815
V Predictions Std            461.6731
V Predictions Max            1461.202
V Predictions Min            21.686565
Log Pis Mean                 -8.665829
Log Pis Std                  4.591591
Log Pis Max                  4.4580884
Log Pis Min                  -13.219149
Policy mu Mean               0.15084627
Policy mu Std                0.4856527
Policy mu Max                2.233676
Policy mu Min                -1.9771116
Policy log std Mean          -0.19090058
Policy log std Std           0.1124097
Policy log std Max           -0.07589186
Policy log std Min           -0.75733185
Z mean eval                  0.05711884
Z variance eval              0.19100025
total_rewards                [400.40391466 356.4858449  529.64218784 254.51462785 216.99194133
 554.05893211 691.68372954 410.3317673  554.55254866 408.54569804]
total_rewards_mean           437.7211192239699
total_rewards_std            138.56755526130166
total_rewards_max            691.6837295393211
total_rewards_min            216.99194133216156
Number of train steps total  60000
Number of env steps total    302000
Number of rollouts total     0
Train Time (s)               28.70942292176187
(Previous) Eval Time (s)     3.197861331049353
Sample Time (s)              15.740273261908442
Epoch Time (s)               47.647557514719665
Total Train Time (s)         2790.979160121642
Epoch                        59
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:02:12.680879 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #59 | Epoch Duration: 47.0467574596405
2020-01-10 19:02:12.681091 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #59 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.057210356
Z variance train             0.19102848
KL Divergence                2.1859984
KL Loss                      0.21859984
QF Loss                      394.94336
VF Loss                      164.46848
Policy Loss                  -362.81717
Q Predictions Mean           356.34634
Q Predictions Std            502.4623
Q Predictions Max            1489.4364
Q Predictions Min            18.418177
V Predictions Mean           359.28763
V Predictions Std            493.5962
V Predictions Max            1472.3096
V Predictions Min            26.530323
Log Pis Mean                 -8.177139
Log Pis Std                  5.1157956
Log Pis Max                  9.72048
Log Pis Min                  -13.5320215
Policy mu Mean               0.14567605
Policy mu Std                0.51622146
Policy mu Max                2.1333778
Policy mu Min                -1.7502288
Policy log std Mean          -0.20021275
Policy log std Std           0.118116476
Policy log std Max           -0.046832755
Policy log std Min           -0.7172616
Z mean eval                  0.058963727
Z variance eval              0.18170944
total_rewards                [473.50025164 500.33459925 526.81173996 414.70514517 647.52496332
 499.17005382 502.94898033 470.83169671 663.98433436 630.59070839]
total_rewards_mean           533.0402472968798
total_rewards_std            80.21747684681542
total_rewards_max            663.9843343639868
total_rewards_min            414.7051451741101
Number of train steps total  61000
Number of env steps total    307000
Number of rollouts total     0
Train Time (s)               28.528963828925043
(Previous) Eval Time (s)     2.596811051014811
Sample Time (s)              15.922149201855063
Epoch Time (s)               47.04792408179492
Total Train Time (s)         2838.7614636141807
Epoch                        60
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:03:00.462171 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #60 | Epoch Duration: 47.780919313430786
2020-01-10 19:03:00.462319 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #60 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.059139065
Z variance train             0.18165903
KL Divergence                2.2945194
KL Loss                      0.22945194
QF Loss                      469.54346
VF Loss                      343.07742
Policy Loss                  -350.42108
Q Predictions Mean           340.6975
Q Predictions Std            503.2664
Q Predictions Max            1487.3093
Q Predictions Min            15.946404
V Predictions Mean           347.14026
V Predictions Std            497.18027
V Predictions Max            1459.066
V Predictions Min            26.835974
Log Pis Mean                 -8.442846
Log Pis Std                  4.929884
Log Pis Max                  5.404495
Log Pis Min                  -13.720801
Policy mu Mean               0.13974845
Policy mu Std                0.49657387
Policy mu Max                2.0977154
Policy mu Min                -1.9847546
Policy log std Mean          -0.19506353
Policy log std Std           0.11481668
Policy log std Max           -0.072006784
Policy log std Min           -0.7052943
Z mean eval                  0.06256729
Z variance eval              0.17894971
total_rewards                [638.91828151 623.88104787 355.14068007 454.94260152 470.38806515
 978.83876414 306.03875027 956.28895244 614.13888266 839.68851022]
total_rewards_mean           623.8264535848808
total_rewards_std            225.55027385607525
total_rewards_max            978.8387641357406
total_rewards_min            306.03875026999873
Number of train steps total  62000
Number of env steps total    312000
Number of rollouts total     0
Train Time (s)               28.28275008779019
(Previous) Eval Time (s)     3.3295040782541037
Sample Time (s)              14.699839332140982
Epoch Time (s)               46.31209349818528
Total Train Time (s)         2885.6099046953022
Epoch                        61
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:03:47.312348 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #61 | Epoch Duration: 46.849910259246826
2020-01-10 19:03:47.312535 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #61 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.062230356
Z variance train             0.17892316
KL Divergence                2.3233333
KL Loss                      0.23233333
QF Loss                      523.3862
VF Loss                      258.6006
Policy Loss                  -394.40045
Q Predictions Mean           384.92496
Q Predictions Std            525.6506
Q Predictions Max            1494.6228
Q Predictions Min            15.091722
V Predictions Mean           396.07852
V Predictions Std            526.4925
V Predictions Max            1500.3529
V Predictions Min            24.439732
Log Pis Mean                 -8.078514
Log Pis Std                  5.0947175
Log Pis Max                  10.002331
Log Pis Min                  -14.891397
Policy mu Mean               0.14326932
Policy mu Std                0.5272694
Policy mu Max                1.9922649
Policy mu Min                -2.2400012
Policy log std Mean          -0.203835
Policy log std Std           0.12109532
Policy log std Max           -0.02292063
Policy log std Min           -0.66080445
Z mean eval                  0.06374952
Z variance eval              0.17685041
total_rewards                [674.32735796 440.32521544 403.6359535  431.37277953 460.92472237
 453.78022529 571.64364176 392.24538787 412.19235672 575.46491391]
total_rewards_mean           481.5912554333889
total_rewards_std            88.52692353988999
total_rewards_max            674.3273579597916
total_rewards_min            392.24538786919527
Number of train steps total  63000
Number of env steps total    317000
Number of rollouts total     0
Train Time (s)               28.281461289618164
(Previous) Eval Time (s)     3.8670299192890525
Sample Time (s)              15.423148879781365
Epoch Time (s)               47.57164008868858
Total Train Time (s)         2932.1888240277767
Epoch                        62
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:04:33.892216 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #62 | Epoch Duration: 46.579561948776245
2020-01-10 19:04:33.892410 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #62 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06351521
Z variance train             0.17690834
KL Divergence                2.343508
KL Loss                      0.2343508
QF Loss                      589.29675
VF Loss                      263.43088
Policy Loss                  -422.76166
Q Predictions Mean           418.0148
Q Predictions Std            544.45825
Q Predictions Max            1500.5345
Q Predictions Min            15.320072
V Predictions Mean           418.29938
V Predictions Std            533.1742
V Predictions Max            1492.0785
V Predictions Min            25.856396
Log Pis Mean                 -7.6713457
Log Pis Std                  5.189043
Log Pis Max                  5.9579806
Log Pis Min                  -12.72308
Policy mu Mean               0.16588536
Policy mu Std                0.5516708
Policy mu Max                2.126182
Policy mu Min                -1.8116708
Policy log std Mean          -0.20824255
Policy log std Std           0.12481777
Policy log std Max           -0.0791149
Policy log std Min           -0.6946342
Z mean eval                  0.064088084
Z variance eval              0.17902303
total_rewards                [ 427.67640018 1027.65958889  608.28484067  568.98236973  394.47046301
  531.03697793  507.56399944  610.14765416  561.76221641  668.05211472]
total_rewards_mean           590.5636625131866
total_rewards_std            165.670555870918
total_rewards_max            1027.6595888872434
total_rewards_min            394.4704630100093
Number of train steps total  64000
Number of env steps total    322000
Number of rollouts total     0
Train Time (s)               29.5793292298913
(Previous) Eval Time (s)     2.874653724953532
Sample Time (s)              15.224870905280113
Epoch Time (s)               47.678853860124946
Total Train Time (s)         2980.3296053344384
Epoch                        63
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:05:22.034999 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #63 | Epoch Duration: 48.14245581626892
2020-01-10 19:05:22.035198 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #63 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06415793
Z variance train             0.17898111
KL Divergence                2.3309133
KL Loss                      0.23309134
QF Loss                      428.12738
VF Loss                      129.2545
Policy Loss                  -394.36285
Q Predictions Mean           385.16156
Q Predictions Std            530.0829
Q Predictions Max            1479.1871
Q Predictions Min            17.377625
V Predictions Mean           394.68622
V Predictions Std            525.13367
V Predictions Max            1506.276
V Predictions Min            27.725893
Log Pis Mean                 -8.133754
Log Pis Std                  5.0927234
Log Pis Max                  15.645012
Log Pis Min                  -14.753168
Policy mu Mean               0.15759704
Policy mu Std                0.5336427
Policy mu Max                2.8469489
Policy mu Min                -2.3563132
Policy log std Mean          -0.20406395
Policy log std Std           0.123871945
Policy log std Max           -0.04937978
Policy log std Min           -0.8628002
Z mean eval                  0.06398843
Z variance eval              0.17887208
total_rewards                [484.59468903 386.04412954 375.74438077 405.5666275  514.35625481
 419.23729776 480.18746928 603.82758482 629.52791345 407.64656651]
total_rewards_mean           470.6732913470722
total_rewards_std            84.96345289134578
total_rewards_max            629.5279134460858
total_rewards_min            375.7443807667391
Number of train steps total  65000
Number of env steps total    327000
Number of rollouts total     0
Train Time (s)               28.84367781318724
(Previous) Eval Time (s)     3.3379511600360274
Sample Time (s)              16.115846116561443
Epoch Time (s)               48.29747508978471
Total Train Time (s)         3028.024296731688
Epoch                        64
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:06:09.731135 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #64 | Epoch Duration: 47.695778131484985
2020-01-10 19:06:09.731305 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #64 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06392891
Z variance train             0.17886809
KL Divergence                2.3539495
KL Loss                      0.23539495
QF Loss                      702.3433
VF Loss                      199.12497
Policy Loss                  -397.40265
Q Predictions Mean           388.625
Q Predictions Std            525.60455
Q Predictions Max            1513.896
Q Predictions Min            15.04479
V Predictions Mean           400.7736
V Predictions Std            528.32275
V Predictions Max            1525.0316
V Predictions Min            26.171732
Log Pis Mean                 -8.131986
Log Pis Std                  4.9088206
Log Pis Max                  9.43655
Log Pis Min                  -13.496551
Policy mu Mean               0.18546483
Policy mu Std                0.518275
Policy mu Max                2.2481954
Policy mu Min                -2.1414587
Policy log std Mean          -0.2045134
Policy log std Std           0.12229574
Policy log std Max           -0.062014878
Policy log std Min           -0.7310409
Z mean eval                  0.06703157
Z variance eval              0.18258162
total_rewards                [398.00868723 557.75976354 671.62079761 405.79070206 414.98716414
 349.24504917 594.59910731 410.4421458  438.93601577 416.63202929]
total_rewards_mean           465.8021461918273
total_rewards_std            98.98254524313427
total_rewards_max            671.620797608727
total_rewards_min            349.24504916563967
Number of train steps total  66000
Number of env steps total    332000
Number of rollouts total     0
Train Time (s)               29.039086082018912
(Previous) Eval Time (s)     2.7359877382405102
Sample Time (s)              14.95768222771585
Epoch Time (s)               46.73275604797527
Total Train Time (s)         3074.862975896802
Epoch                        65
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:06:56.572018 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #65 | Epoch Duration: 46.84053134918213
2020-01-10 19:06:56.572254 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #65 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.067208394
Z variance train             0.18257245
KL Divergence                2.33629
KL Loss                      0.23362899
QF Loss                      470.2871
VF Loss                      190.9648
Policy Loss                  -361.53033
Q Predictions Mean           354.89368
Q Predictions Std            500.1619
Q Predictions Max            1532.8373
Q Predictions Min            16.39086
V Predictions Mean           356.1763
V Predictions Std            491.60117
V Predictions Max            1514.4393
V Predictions Min            23.63777
Log Pis Mean                 -8.218601
Log Pis Std                  4.97036
Log Pis Max                  7.813325
Log Pis Min                  -13.730883
Policy mu Mean               0.18275356
Policy mu Std                0.5250716
Policy mu Max                2.157035
Policy mu Min                -1.8371931
Policy log std Mean          -0.20423496
Policy log std Std           0.12490917
Policy log std Max           -0.054283544
Policy log std Min           -0.7687874
Z mean eval                  0.07050316
Z variance eval              0.17955084
total_rewards                [430.68168697 449.42342876 569.57420087 516.53435823 425.52227815
 478.74876604 562.59217886 303.23298189 473.37352855 478.9893427 ]
total_rewards_mean           468.8672751005841
total_rewards_std            72.5041446280829
total_rewards_max            569.5742008684105
total_rewards_min            303.2329818895295
Number of train steps total  67000
Number of env steps total    337000
Number of rollouts total     0
Train Time (s)               30.925021305214614
(Previous) Eval Time (s)     2.8434714446775615
Sample Time (s)              16.003857701085508
Epoch Time (s)               49.77235045097768
Total Train Time (s)         3124.397966630757
Epoch                        66
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:07:46.107513 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #66 | Epoch Duration: 49.535086154937744
2020-01-10 19:07:46.107663 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #66 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06989389
Z variance train             0.17950907
KL Divergence                2.3775654
KL Loss                      0.23775654
QF Loss                      703.5105
VF Loss                      385.81314
Policy Loss                  -379.23663
Q Predictions Mean           375.00153
Q Predictions Std            511.61255
Q Predictions Max            1528.6505
Q Predictions Min            15.254405
V Predictions Mean           387.10626
V Predictions Std            513.02313
V Predictions Max            1527.158
V Predictions Min            25.384268
Log Pis Mean                 -8.202248
Log Pis Std                  4.817983
Log Pis Max                  10.498009
Log Pis Min                  -14.237687
Policy mu Mean               0.14615595
Policy mu Std                0.52871966
Policy mu Max                2.2236538
Policy mu Min                -2.1074462
Policy log std Mean          -0.202754
Policy log std Std           0.12102117
Policy log std Max           -0.036472328
Policy log std Min           -0.7373354
Z mean eval                  0.07243027
Z variance eval              0.17549261
total_rewards                [491.332785   598.84838923 721.59505204 503.13411215 376.37920602
 653.96981359 476.71429923 401.69800169 397.19105385 412.02068729]
total_rewards_mean           503.2883400083536
total_rewards_std            112.40842158118491
total_rewards_max            721.595052043269
total_rewards_min            376.3792060222746
Number of train steps total  68000
Number of env steps total    342000
Number of rollouts total     0
Train Time (s)               27.798441278282553
(Previous) Eval Time (s)     2.6059334888122976
Sample Time (s)              14.710106507875025
Epoch Time (s)               45.114481274969876
Total Train Time (s)         3170.211628019344
Epoch                        67
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:08:31.922507 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #67 | Epoch Duration: 45.81467366218567
2020-01-10 19:08:31.922685 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #67 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07187448
Z variance train             0.17547898
KL Divergence                2.4107301
KL Loss                      0.24107301
QF Loss                      998.0627
VF Loss                      183.50842
Policy Loss                  -373.08676
Q Predictions Mean           366.37057
Q Predictions Std            505.99863
Q Predictions Max            1470.269
Q Predictions Min            16.970705
V Predictions Mean           375.55942
V Predictions Std            504.63193
V Predictions Max            1475.1946
V Predictions Min            26.738895
Log Pis Mean                 -8.097445
Log Pis Std                  5.057472
Log Pis Max                  13.380533
Log Pis Min                  -13.890743
Policy mu Mean               0.15553486
Policy mu Std                0.51392454
Policy mu Max                2.541996
Policy mu Min                -1.8370247
Policy log std Mean          -0.20319219
Policy log std Std           0.12072366
Policy log std Max           -0.08877878
Policy log std Min           -0.75919807
Z mean eval                  0.07286509
Z variance eval              0.17797069
total_rewards                [596.81287643 718.58197794 389.3204738  442.69905439 442.07700969
 743.42089298 422.63508123 511.1042206  361.28930839 480.16957377]
total_rewards_mean           510.81104692157476
total_rewards_std            126.4384129699595
total_rewards_max            743.4208929805579
total_rewards_min            361.28930839434395
Number of train steps total  69000
Number of env steps total    347000
Number of rollouts total     0
Train Time (s)               28.562138034962118
(Previous) Eval Time (s)     3.3058418347500265
Sample Time (s)              15.682508184108883
Epoch Time (s)               47.55048805382103
Total Train Time (s)         3217.686350424774
Epoch                        68
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:09:19.399543 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #68 | Epoch Duration: 47.476699352264404
2020-01-10 19:09:19.399760 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #68 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.072935365
Z variance train             0.17793517
KL Divergence                2.3793094
KL Loss                      0.23793094
QF Loss                      826.297
VF Loss                      164.95297
Policy Loss                  -425.77423
Q Predictions Mean           414.67563
Q Predictions Std            540.7276
Q Predictions Max            1506.81
Q Predictions Min            15.660431
V Predictions Mean           422.47668
V Predictions Std            538.02576
V Predictions Max            1514.3097
V Predictions Min            24.436754
Log Pis Mean                 -7.801108
Log Pis Std                  5.0854173
Log Pis Max                  6.0442157
Log Pis Min                  -14.229221
Policy mu Mean               0.1437485
Policy mu Std                0.53407013
Policy mu Max                2.1645293
Policy mu Min                -2.315469
Policy log std Mean          -0.20605485
Policy log std Std           0.11957845
Policy log std Max           -0.05208713
Policy log std Min           -0.7216494
Z mean eval                  0.07505369
Z variance eval              0.17229877
total_rewards                [537.82374589 784.21175355 750.18663668 835.04327795 629.47247413
 535.78775527 456.79379072 962.32108218 547.6143331  659.52885022]
total_rewards_mean           669.8783699698446
total_rewards_std            151.60333945902974
total_rewards_max            962.3210821845332
total_rewards_min            456.7937907228573
Number of train steps total  70000
Number of env steps total    352000
Number of rollouts total     0
Train Time (s)               30.044058325700462
(Previous) Eval Time (s)     3.2317560124211013
Sample Time (s)              15.683361530303955
Epoch Time (s)               48.95917586842552
Total Train Time (s)         3267.340070386417
Epoch                        69
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:10:09.055141 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #69 | Epoch Duration: 49.65518546104431
2020-01-10 19:10:09.055363 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #69 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0748817
Z variance train             0.17236672
KL Divergence                2.4570131
KL Loss                      0.24570131
QF Loss                      737.08887
VF Loss                      184.66052
Policy Loss                  -431.2089
Q Predictions Mean           426.91522
Q Predictions Std            551.51306
Q Predictions Max            1538.6418
Q Predictions Min            16.506668
V Predictions Mean           431.96393
V Predictions Std            545.5491
V Predictions Max            1542.2189
V Predictions Min            24.076283
Log Pis Mean                 -7.7250767
Log Pis Std                  5.159061
Log Pis Max                  6.5745325
Log Pis Min                  -13.7460785
Policy mu Mean               0.17472088
Policy mu Std                0.54719615
Policy mu Max                2.2404308
Policy mu Min                -1.9759271
Policy log std Mean          -0.2068088
Policy log std Std           0.12347523
Policy log std Max           -0.01760374
Policy log std Min           -0.6784769
Z mean eval                  0.07494198
Z variance eval              0.17513375
total_rewards                [ 760.67227456  501.68981035  534.27077108  533.22469439  664.65573877
  712.2301171   734.48408815  523.14606717  805.35626246 1023.20421248]
total_rewards_mean           679.29340365245
total_rewards_std            156.02139860920607
total_rewards_max            1023.2042124799091
total_rewards_min            501.6898103504759
Number of train steps total  71000
Number of env steps total    357000
Number of rollouts total     0
Train Time (s)               28.428817940875888
(Previous) Eval Time (s)     3.9274881719611585
Sample Time (s)              16.34583072271198
Epoch Time (s)               48.70213683554903
Total Train Time (s)         3316.512153682299
Epoch                        70
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:10:58.227362 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #70 | Epoch Duration: 49.17184591293335
2020-01-10 19:10:58.227525 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #70 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.075242445
Z variance train             0.17511714
KL Divergence                2.418065
KL Loss                      0.2418065
QF Loss                      443.66763
VF Loss                      202.21085
Policy Loss                  -405.3396
Q Predictions Mean           398.16364
Q Predictions Std            548.79926
Q Predictions Max            1541.6478
Q Predictions Min            16.562561
V Predictions Mean           399.2142
V Predictions Std            538.3829
V Predictions Max            1528.0447
V Predictions Min            23.655546
Log Pis Mean                 -8.123079
Log Pis Std                  5.1827135
Log Pis Max                  16.10641
Log Pis Min                  -13.001947
Policy mu Mean               0.14071958
Policy mu Std                0.5265752
Policy mu Max                2.324731
Policy mu Min                -2.6119585
Policy log std Mean          -0.20085186
Policy log std Std           0.123075284
Policy log std Max           0.044496596
Policy log std Min           -0.75908834
Z mean eval                  0.078435495
Z variance eval              0.17529672
total_rewards                [831.42809433 681.76188166 533.5519479  735.06503835 676.20519204
 556.34354442 329.87940326 456.63074316 389.58901088 643.49622667]
total_rewards_mean           583.3951082694085
total_rewards_std            150.84507155632784
total_rewards_max            831.4280943345145
total_rewards_min            329.8794032648548
Number of train steps total  72000
Number of env steps total    362000
Number of rollouts total     0
Train Time (s)               29.830969718750566
(Previous) Eval Time (s)     4.396891771815717
Sample Time (s)              16.239987748209387
Epoch Time (s)               50.46784923877567
Total Train Time (s)         3366.212575906422
Epoch                        71
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:11:47.931501 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #71 | Epoch Duration: 49.70382642745972
2020-01-10 19:11:47.931754 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #71 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07851999
Z variance train             0.17523131
KL Divergence                2.441573
KL Loss                      0.2441573
QF Loss                      685.3821
VF Loss                      186.15265
Policy Loss                  -422.05692
Q Predictions Mean           410.49475
Q Predictions Std            547.62445
Q Predictions Max            1546.2565
Q Predictions Min            16.935518
V Predictions Mean           420.50595
V Predictions Std            550.2105
V Predictions Max            1545.8005
V Predictions Min            25.779745
Log Pis Mean                 -7.9080496
Log Pis Std                  5.1124454
Log Pis Max                  5.211029
Log Pis Min                  -14.769003
Policy mu Mean               0.17599007
Policy mu Std                0.5455304
Policy mu Max                2.1325834
Policy mu Min                -1.9408325
Policy log std Mean          -0.20757544
Policy log std Std           0.121763274
Policy log std Max           -0.03440731
Policy log std Min           -0.6988192
Z mean eval                  0.077946834
Z variance eval              0.16899721
total_rewards                [366.81720081 343.53221145 600.83260077 409.00133039 621.95084455
 735.59124633 673.54501404 609.81085768 439.41425831 395.62976326]
total_rewards_mean           519.6125327576441
total_rewards_std            135.62322894522637
total_rewards_max            735.5912463255248
total_rewards_min            343.5322114520339
Number of train steps total  73000
Number of env steps total    367000
Number of rollouts total     0
Train Time (s)               30.24762400565669
(Previous) Eval Time (s)     3.632535771932453
Sample Time (s)              16.67781088454649
Epoch Time (s)               50.55797066213563
Total Train Time (s)         3416.44238396734
Epoch                        72
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:12:38.163296 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #72 | Epoch Duration: 50.23130512237549
2020-01-10 19:12:38.163578 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #72 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07748062
Z variance train             0.16896997
KL Divergence                2.5062418
KL Loss                      0.25062418
QF Loss                      595.6101
VF Loss                      288.36694
Policy Loss                  -422.11337
Q Predictions Mean           414.5111
Q Predictions Std            522.65735
Q Predictions Max            1509.0394
Q Predictions Min            17.201082
V Predictions Mean           428.0794
V Predictions Std            528.3618
V Predictions Max            1554.5474
V Predictions Min            24.623446
Log Pis Mean                 -7.4811554
Log Pis Std                  5.3410716
Log Pis Max                  8.396592
Log Pis Min                  -14.403568
Policy mu Mean               0.20694144
Policy mu Std                0.5471389
Policy mu Max                2.015942
Policy mu Min                -1.7334703
Policy log std Mean          -0.21129839
Policy log std Std           0.1241369
Policy log std Max           -0.07842173
Policy log std Min           -0.6921972
Z mean eval                  0.08000753
Z variance eval              0.16843714
total_rewards                [506.03872862 858.73594058 482.44312769 565.44420163 554.07908155
 400.56168715 671.2150493  488.10045936 541.85089362 554.03793527]
total_rewards_mean           562.2507104776031
total_rewards_std            118.95710659480288
total_rewards_max            858.7359405802121
total_rewards_min            400.5616871505448
Number of train steps total  74000
Number of env steps total    372000
Number of rollouts total     0
Train Time (s)               28.669041437562555
(Previous) Eval Time (s)     3.305585321970284
Sample Time (s)              15.99780952418223
Epoch Time (s)               47.97243628371507
Total Train Time (s)         3464.530839710962
Epoch                        73
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:13:26.254771 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #73 | Epoch Duration: 48.090938568115234
2020-01-10 19:13:26.255078 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #73 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07993146
Z variance train             0.16843598
KL Divergence                2.4990804
KL Loss                      0.24990804
QF Loss                      441.0578
VF Loss                      106.54009
Policy Loss                  -376.62167
Q Predictions Mean           368.7987
Q Predictions Std            521.29126
Q Predictions Max            1550.3892
Q Predictions Min            15.164082
V Predictions Mean           379.3151
V Predictions Std            519.53046
V Predictions Max            1557.4825
V Predictions Min            26.069607
Log Pis Mean                 -8.12871
Log Pis Std                  5.067148
Log Pis Max                  7.217819
Log Pis Min                  -14.279886
Policy mu Mean               0.1619362
Policy mu Std                0.5093772
Policy mu Max                2.0827146
Policy mu Min                -2.1225543
Policy log std Mean          -0.19647251
Policy log std Std           0.11722377
Policy log std Max           -0.041989982
Policy log std Min           -0.7143139
Z mean eval                  0.08140719
Z variance eval              0.16811313
total_rewards                [560.19419789 473.87281949 538.25277292 349.77165046 649.1331626
 311.98485685 404.83541742 436.64418988 291.3699094  463.35768213]
total_rewards_mean           447.9416659038977
total_rewards_std            108.05874607525317
total_rewards_max            649.1331626040902
total_rewards_min            291.36990940462607
Number of train steps total  75000
Number of env steps total    377000
Number of rollouts total     0
Train Time (s)               29.79075339110568
(Previous) Eval Time (s)     3.4237741040997207
Sample Time (s)              16.155663682613522
Epoch Time (s)               49.370191177818924
Total Train Time (s)         3513.3777599059977
Epoch                        74
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:14:15.100642 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #74 | Epoch Duration: 48.84536051750183
2020-01-10 19:14:15.100785 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #74 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08139937
Z variance train             0.16814387
KL Divergence                2.5056353
KL Loss                      0.25056353
QF Loss                      592.8383
VF Loss                      189.93434
Policy Loss                  -433.18445
Q Predictions Mean           421.8954
Q Predictions Std            536.51404
Q Predictions Max            1546.63
Q Predictions Min            16.419106
V Predictions Mean           435.5255
V Predictions Std            539.23193
V Predictions Max            1555.6453
V Predictions Min            29.02465
Log Pis Mean                 -7.361286
Log Pis Std                  5.6631103
Log Pis Max                  11.82995
Log Pis Min                  -15.139048
Policy mu Mean               0.16570075
Policy mu Std                0.5648047
Policy mu Max                2.9113135
Policy mu Min                -3.2320945
Policy log std Mean          -0.21792383
Policy log std Std           0.13720852
Policy log std Max           0.0017064065
Policy log std Min           -0.81350315
Z mean eval                  0.08197312
Z variance eval              0.16599329
total_rewards                [589.22184305 325.25046132 564.75280468 454.04317035 525.78074126
 465.72242913 317.21841278 383.2944615  507.32300733 860.95493901]
total_rewards_mean           499.3562270415722
total_rewards_std            149.66954742875598
total_rewards_max            860.9549390126116
total_rewards_min            317.2184127838754
Number of train steps total  76000
Number of env steps total    382000
Number of rollouts total     0
Train Time (s)               28.69791462412104
(Previous) Eval Time (s)     2.898687087930739
Sample Time (s)              16.518881137482822
Epoch Time (s)               48.1154828495346
Total Train Time (s)         3562.003291362431
Epoch                        75
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:15:03.728628 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #75 | Epoch Duration: 48.62770223617554
2020-01-10 19:15:03.728846 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #75 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08236688
Z variance train             0.16599502
KL Divergence                2.5415664
KL Loss                      0.25415665
QF Loss                      790.1883
VF Loss                      212.31479
Policy Loss                  -432.4289
Q Predictions Mean           423.93762
Q Predictions Std            562.03625
Q Predictions Max            1562.578
Q Predictions Min            16.978922
V Predictions Mean           430.91388
V Predictions Std            559.8075
V Predictions Max            1564.8418
V Predictions Min            28.03821
Log Pis Mean                 -7.9409885
Log Pis Std                  5.2105026
Log Pis Max                  6.257602
Log Pis Min                  -14.21825
Policy mu Mean               0.18989982
Policy mu Std                0.5320027
Policy mu Max                2.1501226
Policy mu Min                -1.8587546
Policy log std Mean          -0.21089964
Policy log std Std           0.12811531
Policy log std Max           -0.0669432
Policy log std Min           -0.7282754
Z mean eval                  0.083543114
Z variance eval              0.16387138
total_rewards                [777.51771857 380.55043275 471.93307538 529.88950031 574.21665073
 416.90230706 682.60380462 541.29861277 642.46428686 551.96196904]
total_rewards_mean           556.9338358101288
total_rewards_std            114.45959246647251
total_rewards_max            777.5177185735923
total_rewards_min            380.550432754325
Number of train steps total  77000
Number of env steps total    387000
Number of rollouts total     0
Train Time (s)               28.982150639872998
(Previous) Eval Time (s)     3.4106012820266187
Sample Time (s)              16.870591037906706
Epoch Time (s)               49.26334295980632
Total Train Time (s)         3611.6898906053975
Epoch                        76
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:15:53.418766 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #76 | Epoch Duration: 49.68973159790039
2020-01-10 19:15:53.419035 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #76 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08350806
Z variance train             0.16385576
KL Divergence                2.5702329
KL Loss                      0.2570233
QF Loss                      843.6976
VF Loss                      297.29926
Policy Loss                  -421.79898
Q Predictions Mean           417.39578
Q Predictions Std            540.2178
Q Predictions Max            1581.4192
Q Predictions Min            16.904278
V Predictions Mean           418.41254
V Predictions Std            530.0381
V Predictions Max            1581.5768
V Predictions Min            25.088865
Log Pis Mean                 -7.7569327
Log Pis Std                  5.4610176
Log Pis Max                  15.1029
Log Pis Min                  -14.264317
Policy mu Mean               0.17958213
Policy mu Std                0.54086965
Policy mu Max                2.5424309
Policy mu Min                -1.9701868
Policy log std Mean          -0.20533946
Policy log std Std           0.12220839
Policy log std Max           -0.051918194
Policy log std Min           -0.7102263
Z mean eval                  0.08274623
Z variance eval              0.16538797
total_rewards                [412.93942631 407.34175003 558.66864471 573.6960346  638.9337445
 369.79734098 543.77431777 633.50583018 961.7475614  814.63908052]
total_rewards_mean           591.5043731007809
total_rewards_std            175.92941312022595
total_rewards_max            961.7475613980611
total_rewards_min            369.79734098487125
Number of train steps total  78000
Number of env steps total    392000
Number of rollouts total     0
Train Time (s)               27.630319064948708
(Previous) Eval Time (s)     3.83668390288949
Sample Time (s)              15.871917000040412
Epoch Time (s)               47.33891996787861
Total Train Time (s)         3658.983250196092
Epoch                        77
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:16:40.714616 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #77 | Epoch Duration: 47.295347452163696
2020-01-10 19:16:40.714917 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #77 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08276658
Z variance train             0.16538534
KL Divergence                2.5622683
KL Loss                      0.25622684
QF Loss                      536.3258
VF Loss                      210.7392
Policy Loss                  -429.81134
Q Predictions Mean           425.34882
Q Predictions Std            542.8783
Q Predictions Max            1567.2083
Q Predictions Min            14.797942
V Predictions Mean           434.4127
V Predictions Std            541.6011
V Predictions Max            1569.6608
V Predictions Min            23.797857
Log Pis Mean                 -7.53553
Log Pis Std                  5.3225026
Log Pis Max                  7.3941774
Log Pis Min                  -12.971193
Policy mu Mean               0.18356787
Policy mu Std                0.5614791
Policy mu Max                2.583323
Policy mu Min                -2.3942447
Policy log std Mean          -0.21514076
Policy log std Std           0.13201356
Policy log std Max           -0.059420213
Policy log std Min           -0.8111089
Z mean eval                  0.08437639
Z variance eval              0.16206023
total_rewards                [769.54246677 557.97287994 767.4682203  362.82483722 682.7997716
 489.91584035 642.26276352 728.77509511 489.03551206 993.89729377]
total_rewards_mean           648.4494680629441
total_rewards_std            172.0891531333844
total_rewards_max            993.8972937698268
total_rewards_min            362.82483721871876
Number of train steps total  79000
Number of env steps total    397000
Number of rollouts total     0
Train Time (s)               30.250762628391385
(Previous) Eval Time (s)     3.792833521962166
Sample Time (s)              16.483042172156274
Epoch Time (s)               50.526638322509825
Total Train Time (s)         3709.7377125420608
Epoch                        78
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:17:31.471783 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #78 | Epoch Duration: 50.75661635398865
2020-01-10 19:17:31.472089 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #78 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0847892
Z variance train             0.16201426
KL Divergence                2.5989082
KL Loss                      0.25989082
QF Loss                      952.14746
VF Loss                      332.705
Policy Loss                  -429.50955
Q Predictions Mean           419.83286
Q Predictions Std            549.4934
Q Predictions Max            1578.0757
Q Predictions Min            14.483223
V Predictions Mean           423.84497
V Predictions Std            538.9168
V Predictions Max            1551.3287
V Predictions Min            26.188316
Log Pis Mean                 -7.916849
Log Pis Std                  5.4060555
Log Pis Max                  20.999664
Log Pis Min                  -13.155464
Policy mu Mean               0.1701555
Policy mu Std                0.5439248
Policy mu Max                3.000787
Policy mu Min                -2.5763626
Policy log std Mean          -0.20909297
Policy log std Std           0.12768297
Policy log std Max           -0.016712487
Policy log std Min           -0.85147715
Z mean eval                  0.0847667
Z variance eval              0.1571128
total_rewards                [ 690.34233713  454.35727271  848.45927283  363.68804439 1260.35837649
  468.26510277  524.804243    746.2359077   396.02217547  592.63925071]
total_rewards_mean           634.5171983194193
total_rewards_std            256.3517636692695
total_rewards_max            1260.3583764893267
total_rewards_min            363.6880443858834
Number of train steps total  80000
Number of env steps total    402000
Number of rollouts total     0
Train Time (s)               30.654760632198304
(Previous) Eval Time (s)     4.0225235456600785
Sample Time (s)              15.710936232935637
Epoch Time (s)               50.38822041079402
Total Train Time (s)         3759.922546380665
Epoch                        79
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:18:21.658493 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #79 | Epoch Duration: 50.18616580963135
2020-01-10 19:18:21.658763 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #79 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.084660575
Z variance train             0.1571249
KL Divergence                2.6673784
KL Loss                      0.26673785
QF Loss                      546.34924
VF Loss                      219.12616
Policy Loss                  -433.04907
Q Predictions Mean           426.42966
Q Predictions Std            573.6034
Q Predictions Max            1577.1495
Q Predictions Min            15.809026
V Predictions Mean           436.25357
V Predictions Std            572.1369
V Predictions Max            1612.9517
V Predictions Min            28.466288
Log Pis Mean                 -7.962944
Log Pis Std                  5.183541
Log Pis Max                  13.220518
Log Pis Min                  -13.397182
Policy mu Mean               0.1772813
Policy mu Std                0.5431739
Policy mu Max                2.0154448
Policy mu Min                -1.7124903
Policy log std Mean          -0.21308431
Policy log std Std           0.13446435
Policy log std Max           -0.06652783
Policy log std Min           -0.74581933
Z mean eval                  0.08348928
Z variance eval              0.15647891
total_rewards                [611.98968373 941.84429944 805.51432118 448.27981637 634.15357173
 629.27164403 513.3590545  884.45172823 585.18510302 314.34579846]
total_rewards_mean           636.8395020684868
total_rewards_std            184.64708975400978
total_rewards_max            941.844299435688
total_rewards_min            314.3457984586491
Number of train steps total  81000
Number of env steps total    407000
Number of rollouts total     0
Train Time (s)               31.241049374919385
(Previous) Eval Time (s)     3.820171410217881
Sample Time (s)              16.186761753167957
Epoch Time (s)               51.24798253830522
Total Train Time (s)         3811.1365087614395
Epoch                        80
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:19:12.873070 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #80 | Epoch Duration: 51.214115619659424
2020-01-10 19:19:12.873215 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #80 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08358337
Z variance train             0.15647373
KL Divergence                2.6659632
KL Loss                      0.26659632
QF Loss                      500.118
VF Loss                      364.7413
Policy Loss                  -463.4417
Q Predictions Mean           451.7873
Q Predictions Std            573.59064
Q Predictions Max            1592.459
Q Predictions Min            14.504319
V Predictions Mean           456.24182
V Predictions Std            564.0423
V Predictions Max            1590.1847
V Predictions Min            23.848907
Log Pis Mean                 -7.7000303
Log Pis Std                  5.1925597
Log Pis Max                  13.692345
Log Pis Min                  -12.873077
Policy mu Mean               0.17771769
Policy mu Std                0.5480092
Policy mu Max                2.4217985
Policy mu Min                -2.8498569
Policy log std Mean          -0.21363401
Policy log std Std           0.129173
Policy log std Max           -0.03562884
Policy log std Min           -0.70786124
Z mean eval                  0.08213893
Z variance eval              0.15746959
total_rewards                [422.52114549 489.2077448  426.07254919 710.04154932 362.22997275
 348.4375665  755.0403547  351.89783982 525.34355205 377.53497857]
total_rewards_mean           476.8327253201167
total_rewards_std            139.60891843678345
total_rewards_max            755.0403547033193
total_rewards_min            348.4375665004551
Number of train steps total  82000
Number of env steps total    412000
Number of rollouts total     0
Train Time (s)               27.91494226595387
(Previous) Eval Time (s)     3.7860330836847425
Sample Time (s)              14.910303380805999
Epoch Time (s)               46.61127873044461
Total Train Time (s)         3856.8598786578514
Epoch                        81
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:19:58.599871 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #81 | Epoch Duration: 45.726492404937744
2020-01-10 19:19:58.600134 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #81 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08214001
Z variance train             0.15747505
KL Divergence                2.6428967
KL Loss                      0.26428968
QF Loss                      668.4893
VF Loss                      430.86725
Policy Loss                  -464.79263
Q Predictions Mean           452.60342
Q Predictions Std            582.9206
Q Predictions Max            1590.2982
Q Predictions Min            17.178257
V Predictions Mean           453.7391
V Predictions Std            573.03186
V Predictions Max            1584.0248
V Predictions Min            25.51841
Log Pis Mean                 -7.8346863
Log Pis Std                  5.0147862
Log Pis Max                  9.601648
Log Pis Min                  -14.533342
Policy mu Mean               0.1470464
Policy mu Std                0.5459545
Policy mu Max                2.1518283
Policy mu Min                -2.6250815
Policy log std Mean          -0.2088465
Policy log std Std           0.12577775
Policy log std Max           -0.06113662
Policy log std Min           -0.6931896
Z mean eval                  0.08452369
Z variance eval              0.15293312
total_rewards                [777.96237088 838.27027817 814.900069   541.53347605 675.54138635
 438.6855085  867.93440319 738.11647225 535.14348562 748.22826145]
total_rewards_mean           697.6315711460304
total_rewards_std            138.38219669831253
total_rewards_max            867.934403189538
total_rewards_min            438.68550849925464
Number of train steps total  83000
Number of env steps total    417000
Number of rollouts total     0
Train Time (s)               28.355181811843067
(Previous) Eval Time (s)     2.9009291199035943
Sample Time (s)              15.650811087340117
Epoch Time (s)               46.90692201908678
Total Train Time (s)         3905.2318292818964
Epoch                        82
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:20:46.971418 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #82 | Epoch Duration: 48.37107992172241
2020-01-10 19:20:46.971643 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #82 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08489923
Z variance train             0.15291937
KL Divergence                2.692742
KL Loss                      0.2692742
QF Loss                      621.12195
VF Loss                      198.36539
Policy Loss                  -383.34912
Q Predictions Mean           376.02866
Q Predictions Std            538.8529
Q Predictions Max            1607.786
Q Predictions Min            17.645966
V Predictions Mean           384.8695
V Predictions Std            538.0307
V Predictions Max            1607.459
V Predictions Min            25.127726
Log Pis Mean                 -8.160025
Log Pis Std                  4.9932623
Log Pis Max                  5.9572926
Log Pis Min                  -13.351402
Policy mu Mean               0.16036463
Policy mu Std                0.51047486
Policy mu Max                2.2248785
Policy mu Min                -1.7633681
Policy log std Mean          -0.20181948
Policy log std Std           0.12026615
Policy log std Max           -0.007052511
Policy log std Min           -0.74224347
Z mean eval                  0.08608176
Z variance eval              0.15260549
total_rewards                [403.61721092 610.21380534 639.3516115  946.90332305 494.18111574
 660.19897655 655.5386388  617.46332827 639.70381854 704.9122191 ]
total_rewards_mean           637.2084047805664
total_rewards_std            133.23301425439874
total_rewards_max            946.9033230466863
total_rewards_min            403.6172109220403
Number of train steps total  84000
Number of env steps total    422000
Number of rollouts total     0
Train Time (s)               28.796982176136225
(Previous) Eval Time (s)     4.364828363060951
Sample Time (s)              17.32526326738298
Epoch Time (s)               50.487073806580156
Total Train Time (s)         3955.043085965328
Epoch                        83
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:21:36.785983 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #83 | Epoch Duration: 49.81419348716736
2020-01-10 19:21:36.786184 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #83 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0856204
Z variance train             0.15259735
KL Divergence                2.6935081
KL Loss                      0.26935083
QF Loss                      625.3059
VF Loss                      309.54703
Policy Loss                  -450.31067
Q Predictions Mean           448.8714
Q Predictions Std            582.7851
Q Predictions Max            1588.6609
Q Predictions Min            16.849848
V Predictions Mean           457.95276
V Predictions Std            578.95264
V Predictions Max            1595.0002
V Predictions Min            27.045477
Log Pis Mean                 -7.319423
Log Pis Std                  5.868153
Log Pis Max                  11.112621
Log Pis Min                  -14.372536
Policy mu Mean               0.17566255
Policy mu Std                0.56931853
Policy mu Max                2.3467243
Policy mu Min                -2.8790786
Policy log std Mean          -0.2120773
Policy log std Std           0.13176982
Policy log std Max           0.056851402
Policy log std Min           -0.70105684
Z mean eval                  0.087278865
Z variance eval              0.14801057
total_rewards                [814.54498294 644.68357267 523.6254319  605.24499784 856.32028181
 719.21876677 835.10516971 463.26837856 630.70298457 432.4220858 ]
total_rewards_mean           652.5136652585048
total_rewards_std            144.64373977930225
total_rewards_max            856.3202818144455
total_rewards_min            432.422085801806
Number of train steps total  85000
Number of env steps total    427000
Number of rollouts total     0
Train Time (s)               28.568216062150896
(Previous) Eval Time (s)     3.6916347187943757
Sample Time (s)              16.041907711420208
Epoch Time (s)               48.30175849236548
Total Train Time (s)         4003.655459221918
Epoch                        84
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:22:25.398962 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #84 | Epoch Duration: 48.612622022628784
2020-01-10 19:22:25.399168 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #84 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08722372
Z variance train             0.1480222
KL Divergence                2.756969
KL Loss                      0.2756969
QF Loss                      710.79205
VF Loss                      211.42502
Policy Loss                  -478.96805
Q Predictions Mean           471.42474
Q Predictions Std            594.7575
Q Predictions Max            1605.1869
Q Predictions Min            13.209159
V Predictions Mean           481.6501
V Predictions Std            595.0945
V Predictions Max            1605.4268
V Predictions Min            15.496822
Log Pis Mean                 -7.611172
Log Pis Std                  5.231862
Log Pis Max                  11.030508
Log Pis Min                  -13.043573
Policy mu Mean               0.19795106
Policy mu Std                0.54674065
Policy mu Max                2.3056931
Policy mu Min                -1.8832275
Policy log std Mean          -0.21457618
Policy log std Std           0.12754622
Policy log std Max           -0.044089437
Policy log std Min           -0.7149719
Z mean eval                  0.08483784
Z variance eval              0.14821605
total_rewards                [ 367.17310466 1448.14849453  602.30528226  681.94295116  647.47495429
  906.10672577  768.33564882  772.63767685  504.1307257   624.92099588]
total_rewards_mean           732.3176559923306
total_rewards_std            277.3287585954738
total_rewards_max            1448.148494533296
total_rewards_min            367.1731046559376
Number of train steps total  86000
Number of env steps total    432000
Number of rollouts total     0
Train Time (s)               29.860274642240256
(Previous) Eval Time (s)     4.002219962887466
Sample Time (s)              16.681831831578165
Epoch Time (s)               50.54432643670589
Total Train Time (s)         4054.8272267356515
Epoch                        85
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:23:16.572005 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #85 | Epoch Duration: 51.17267966270447
2020-01-10 19:23:16.572231 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #85 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08463236
Z variance train             0.14821519
KL Divergence                2.7711232
KL Loss                      0.27711233
QF Loss                      475.36096
VF Loss                      439.46494
Policy Loss                  -427.51358
Q Predictions Mean           420.86652
Q Predictions Std            563.46765
Q Predictions Max            1610.0155
Q Predictions Min            15.709076
V Predictions Mean           436.53436
V Predictions Std            568.7555
V Predictions Max            1625.6234
V Predictions Min            30.630468
Log Pis Mean                 -7.9350033
Log Pis Std                  5.356392
Log Pis Max                  8.282875
Log Pis Min                  -13.339846
Policy mu Mean               0.16707253
Policy mu Std                0.5284178
Policy mu Max                2.173271
Policy mu Min                -2.0820112
Policy log std Mean          -0.20741837
Policy log std Std           0.12505834
Policy log std Max           -0.02630438
Policy log std Min           -0.70905507
Z mean eval                  0.0868859
Z variance eval              0.14251631
total_rewards                [526.18676756 758.97703672 695.64127986 315.00071984 715.83783128
 508.68914194 639.57494154 503.39090883 839.2074561  681.30654744]
total_rewards_mean           618.3812631108788
total_rewards_std            146.35633140359027
total_rewards_max            839.2074561030098
total_rewards_min            315.0007198418632
Number of train steps total  87000
Number of env steps total    437000
Number of rollouts total     0
Train Time (s)               31.16448884876445
(Previous) Eval Time (s)     4.6302565559744835
Sample Time (s)              16.921627413947135
Epoch Time (s)               52.71637281868607
Total Train Time (s)         4106.635549239814
Epoch                        86
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:24:08.383928 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #86 | Epoch Duration: 51.81150817871094
2020-01-10 19:24:08.384231 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #86 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.086760394
Z variance train             0.14248547
KL Divergence                2.8320985
KL Loss                      0.28320986
QF Loss                      766.6648
VF Loss                      373.6175
Policy Loss                  -480.51642
Q Predictions Mean           474.73108
Q Predictions Std            571.2847
Q Predictions Max            1616.641
Q Predictions Min            13.23162
V Predictions Mean           487.36957
V Predictions Std            574.8536
V Predictions Max            1626.4913
V Predictions Min            26.293823
Log Pis Mean                 -7.6165953
Log Pis Std                  5.3399806
Log Pis Max                  9.932411
Log Pis Min                  -14.45177
Policy mu Mean               0.1708077
Policy mu Std                0.5722885
Policy mu Max                2.3912766
Policy mu Min                -2.0149255
Policy log std Mean          -0.2150402
Policy log std Std           0.12787858
Policy log std Max           -0.053793646
Policy log std Min           -0.8837827
Z mean eval                  0.08454771
Z variance eval              0.1432378
total_rewards                [583.5867194  656.174489   629.19954783 677.23546339 745.74240898
 503.53715848 483.99912113 523.82948631 635.4132475  601.82484105]
total_rewards_mean           604.0542483093184
total_rewards_std            78.19209606195776
total_rewards_max            745.7424089837979
total_rewards_min            483.99912113432976
Number of train steps total  88000
Number of env steps total    442000
Number of rollouts total     0
Train Time (s)               30.262341923546046
(Previous) Eval Time (s)     3.7250466248951852
Sample Time (s)              17.02848206181079
Epoch Time (s)               51.01587061025202
Total Train Time (s)         4157.552232609596
Epoch                        87
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:24:59.301356 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #87 | Epoch Duration: 50.916898250579834
2020-01-10 19:24:59.301556 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #87 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08426683
Z variance train             0.14322636
KL Divergence                2.8363483
KL Loss                      0.28363484
QF Loss                      624.4661
VF Loss                      200.25601
Policy Loss                  -444.3379
Q Predictions Mean           435.8751
Q Predictions Std            571.39404
Q Predictions Max            1618.4133
Q Predictions Min            15.777546
V Predictions Mean           448.21103
V Predictions Std            573.1729
V Predictions Max            1630.9949
V Predictions Min            26.070864
Log Pis Mean                 -7.5759773
Log Pis Std                  5.4892073
Log Pis Max                  14.970667
Log Pis Min                  -14.786559
Policy mu Mean               0.18312299
Policy mu Std                0.5488649
Policy mu Max                2.116956
Policy mu Min                -2.5107062
Policy log std Mean          -0.21207224
Policy log std Std           0.12498785
Policy log std Max           -0.0370768
Policy log std Min           -0.7034781
Z mean eval                  0.08665343
Z variance eval              0.13952003
total_rewards                [ 812.41098288 1212.11079958  509.35250956  861.79789272  696.05979276
  941.83421583  670.18963601  770.45159556  706.34477368  465.336647  ]
total_rewards_mean           764.588884557302
total_rewards_std            203.7547612747634
total_rewards_max            1212.1107995771908
total_rewards_min            465.33664700341626
Number of train steps total  89000
Number of env steps total    447000
Number of rollouts total     0
Train Time (s)               30.232655704952776
(Previous) Eval Time (s)     3.625771447084844
Sample Time (s)              16.032385980710387
Epoch Time (s)               49.89081313274801
Total Train Time (s)         4208.544036954176
Epoch                        88
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:25:50.295066 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #88 | Epoch Duration: 50.99334263801575
2020-01-10 19:25:50.295287 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #88 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08699666
Z variance train             0.13946822
KL Divergence                2.9026818
KL Loss                      0.29026818
QF Loss                      734.8064
VF Loss                      247.58383
Policy Loss                  -456.5694
Q Predictions Mean           447.50082
Q Predictions Std            568.7335
Q Predictions Max            1646.0314
Q Predictions Min            17.278307
V Predictions Mean           455.80072
V Predictions Std            566.27924
V Predictions Max            1640.3005
V Predictions Min            27.236483
Log Pis Mean                 -7.3379536
Log Pis Std                  5.8021083
Log Pis Max                  12.52339
Log Pis Min                  -17.37882
Policy mu Mean               0.20668945
Policy mu Std                0.5576228
Policy mu Max                2.3134181
Policy mu Min                -1.9635452
Policy log std Mean          -0.21511324
Policy log std Std           0.12659729
Policy log std Max           -0.038865283
Policy log std Min           -0.6701726
Z mean eval                  0.085504465
Z variance eval              0.13486186
total_rewards                [573.94917847 539.94803761 666.54365413 864.06645513 599.81037503
 635.41948471 634.49839902 529.85996297 644.37931207 363.48531791]
total_rewards_mean           605.1960177048061
total_rewards_std            119.76940614563615
total_rewards_max            864.0664551250459
total_rewards_min            363.48531791077016
Number of train steps total  90000
Number of env steps total    452000
Number of rollouts total     0
Train Time (s)               31.159705112222582
(Previous) Eval Time (s)     4.728001464158297
Sample Time (s)              17.873930926900357
Epoch Time (s)               53.761637503281236
Total Train Time (s)         4261.506454571616
Epoch                        89
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:26:43.259925 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #89 | Epoch Duration: 52.964457511901855
2020-01-10 19:26:43.260156 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #89 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08534758
Z variance train             0.13485992
KL Divergence                2.9700263
KL Loss                      0.29700264
QF Loss                      944.4426
VF Loss                      224.6025
Policy Loss                  -484.8903
Q Predictions Mean           474.646
Q Predictions Std            579.96155
Q Predictions Max            1634.5963
Q Predictions Min            15.671376
V Predictions Mean           483.25403
V Predictions Std            580.54535
V Predictions Max            1645.655
V Predictions Min            24.600178
Log Pis Mean                 -7.0624986
Log Pis Std                  5.809189
Log Pis Max                  14.253908
Log Pis Min                  -14.354021
Policy mu Mean               0.22387828
Policy mu Std                0.5842413
Policy mu Max                2.3640442
Policy mu Min                -2.0898829
Policy log std Mean          -0.22808994
Policy log std Std           0.13729778
Policy log std Max           -0.073580585
Policy log std Min           -0.72938305
Z mean eval                  0.08328243
Z variance eval              0.13631193
total_rewards                [ 526.75956223  855.93192347 1142.01452969  563.37535315  630.38641229
  602.61343719 1268.31844977 1094.95387225  733.16876955  633.68374898]
total_rewards_mean           805.120605857566
total_rewards_std            256.25560736404015
total_rewards_max            1268.3184497749412
total_rewards_min            526.7595622313369
Number of train steps total  91000
Number of env steps total    457000
Number of rollouts total     0
Train Time (s)               28.721076005138457
(Previous) Eval Time (s)     3.930474378168583
Sample Time (s)              17.369047079235315
Epoch Time (s)               50.020597462542355
Total Train Time (s)         4312.480719428044
Epoch                        90
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:27:34.236921 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #90 | Epoch Duration: 50.97657513618469
2020-01-10 19:27:34.237167 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #90 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08370169
Z variance train             0.13642715
KL Divergence                2.9249816
KL Loss                      0.29249817
QF Loss                      545.6112
VF Loss                      226.89612
Policy Loss                  -448.38193
Q Predictions Mean           436.5732
Q Predictions Std            564.06573
Q Predictions Max            1622.6792
Q Predictions Min            17.352707
V Predictions Mean           444.68195
V Predictions Std            562.1652
V Predictions Max            1622.2316
V Predictions Min            24.23902
Log Pis Mean                 -7.8313584
Log Pis Std                  5.1826487
Log Pis Max                  8.890979
Log Pis Min                  -13.646014
Policy mu Mean               0.175555
Policy mu Std                0.5319575
Policy mu Max                2.0332606
Policy mu Min                -1.9732715
Policy log std Mean          -0.2069815
Policy log std Std           0.12244842
Policy log std Max           -0.043153405
Policy log std Min           -0.6540364
Z mean eval                  0.081561014
Z variance eval              0.13882896
total_rewards                [ 493.88724658 1229.37879214  536.04172907  667.49770342  853.22992973
 1018.95077314 1222.94933992 1044.95496007  705.43699184  559.49666055]
total_rewards_mean           833.1824126465453
total_rewards_std            266.59655457683834
total_rewards_max            1229.3787921411572
total_rewards_min            493.88724658300924
Number of train steps total  92000
Number of env steps total    462000
Number of rollouts total     0
Train Time (s)               29.952926198020577
(Previous) Eval Time (s)     4.88615095987916
Sample Time (s)              16.607952166348696
Epoch Time (s)               51.44702932424843
Total Train Time (s)         4364.011936846655
Epoch                        91
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:28:25.769742 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #91 | Epoch Duration: 51.53237271308899
2020-01-10 19:28:25.769981 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #91 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08147154
Z variance train             0.13883455
KL Divergence                2.9022574
KL Loss                      0.29022574
QF Loss                      750.371
VF Loss                      306.30035
Policy Loss                  -527.73425
Q Predictions Mean           515.88086
Q Predictions Std            613.90686
Q Predictions Max            1653.8918
Q Predictions Min            15.047263
V Predictions Mean           519.16296
V Predictions Std            607.81305
V Predictions Max            1650.5477
V Predictions Min            23.2796
Log Pis Mean                 -7.423759
Log Pis Std                  5.3561673
Log Pis Max                  11.975271
Log Pis Min                  -13.491543
Policy mu Mean               0.17831898
Policy mu Std                0.5847518
Policy mu Max                2.278201
Policy mu Min                -2.404498
Policy log std Mean          -0.22400106
Policy log std Std           0.13773397
Policy log std Max           -0.046696857
Policy log std Min           -0.79212236
Z mean eval                  0.081452474
Z variance eval              0.13750458
total_rewards                [1072.42048296 1001.95012883  499.05414282  460.54261283  871.97899662
  468.12552224  953.11994905  648.3895236   712.56625938  649.38995962]
total_rewards_mean           733.7537577957099
total_rewards_std            216.5622308304915
total_rewards_max            1072.4204829604928
total_rewards_min            460.542612832498
Number of train steps total  93000
Number of env steps total    467000
Number of rollouts total     0
Train Time (s)               29.13750141998753
(Previous) Eval Time (s)     4.971158695872873
Sample Time (s)              17.66132955858484
Epoch Time (s)               51.76998967444524
Total Train Time (s)         4415.361328924075
Epoch                        92
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:29:17.119404 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #92 | Epoch Duration: 51.3492648601532
2020-01-10 19:29:17.119560 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #92 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0812072
Z variance train             0.13752943
KL Divergence                2.9258704
KL Loss                      0.29258704
QF Loss                      565.6627
VF Loss                      240.68307
Policy Loss                  -486.43378
Q Predictions Mean           480.01587
Q Predictions Std            591.7602
Q Predictions Max            1645.8685
Q Predictions Min            13.210207
V Predictions Mean           490.99646
V Predictions Std            591.77765
V Predictions Max            1658.2754
V Predictions Min            24.868994
Log Pis Mean                 -7.2676454
Log Pis Std                  5.76075
Log Pis Max                  7.862551
Log Pis Min                  -13.641155
Policy mu Mean               0.15702501
Policy mu Std                0.59213006
Policy mu Max                2.4519088
Policy mu Min                -2.324213
Policy log std Mean          -0.22003403
Policy log std Std           0.13263156
Policy log std Max           -0.0014902651
Policy log std Min           -0.7806892
Z mean eval                  0.079099275
Z variance eval              0.13116367
total_rewards                [1172.97587352  686.51016265  964.75380596  424.31313943  676.43620038
  540.4927155   812.10753466  684.19671391  523.81700201  610.56412442]
total_rewards_mean           709.6167272430815
total_rewards_std            211.40389195602972
total_rewards_max            1172.9758735208043
total_rewards_min            424.31313942971303
Number of train steps total  94000
Number of env steps total    472000
Number of rollouts total     0
Train Time (s)               29.257998079061508
(Previous) Eval Time (s)     4.550113103818148
Sample Time (s)              16.48043925780803
Epoch Time (s)               50.288550440687686
Total Train Time (s)         4465.578277855646
Epoch                        93
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:30:07.341360 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #93 | Epoch Duration: 50.221633434295654
2020-01-10 19:30:07.341658 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #93 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07927301
Z variance train             0.13116246
KL Divergence                3.0286102
KL Loss                      0.30286103
QF Loss                      699.66907
VF Loss                      445.44543
Policy Loss                  -512.09906
Q Predictions Mean           509.0913
Q Predictions Std            602.9227
Q Predictions Max            1646.8486
Q Predictions Min            15.455569
V Predictions Mean           522.36115
V Predictions Std            607.435
V Predictions Max            1681.6864
V Predictions Min            25.888718
Log Pis Mean                 -7.264071
Log Pis Std                  5.6020665
Log Pis Max                  10.775833
Log Pis Min                  -13.526523
Policy mu Mean               0.17628081
Policy mu Std                0.57538664
Policy mu Max                2.0686965
Policy mu Min                -1.9580562
Policy log std Mean          -0.22343113
Policy log std Std           0.13517931
Policy log std Max           -0.049477346
Policy log std Min           -0.71144205
Z mean eval                  0.077393755
Z variance eval              0.13191923
total_rewards                [ 767.27644641 1146.65858107  934.33074084 1241.56267898  721.04544567
  577.02571692  516.03453853  607.18628947 1171.90174909 1127.79107245]
total_rewards_mean           881.0813259414601
total_rewards_std            262.30636611002086
total_rewards_max            1241.562678978216
total_rewards_min            516.0345385293397
Number of train steps total  95000
Number of env steps total    477000
Number of rollouts total     0
Train Time (s)               29.961018837988377
(Previous) Eval Time (s)     4.482876083813608
Sample Time (s)              16.10987473744899
Epoch Time (s)               50.553769659250975
Total Train Time (s)         4516.735178925097
Epoch                        94
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:30:58.500562 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #94 | Epoch Duration: 51.15865731239319
2020-01-10 19:30:58.500848 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #94 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.077585675
Z variance train             0.13194886
KL Divergence                3.033986
KL Loss                      0.3033986
QF Loss                      738.7051
VF Loss                      323.5286
Policy Loss                  -440.24835
Q Predictions Mean           434.10425
Q Predictions Std            581.6528
Q Predictions Max            1671.3733
Q Predictions Min            15.310394
V Predictions Mean           437.04987
V Predictions Std            576.6892
V Predictions Max            1664.5222
V Predictions Min            26.458065
Log Pis Mean                 -7.8320456
Log Pis Std                  5.1008773
Log Pis Max                  5.9728074
Log Pis Min                  -13.324635
Policy mu Mean               0.16451941
Policy mu Std                0.538471
Policy mu Max                2.3321123
Policy mu Min                -2.5969605
Policy log std Mean          -0.20844188
Policy log std Std           0.12643272
Policy log std Max           -0.026451893
Policy log std Min           -0.7203541
Z mean eval                  0.076908536
Z variance eval              0.13000321
total_rewards                [ 743.002797    615.20576968  930.33576168  742.42898002  682.72077227
  837.96223734 1163.76415527  864.31338862  695.87751175  619.64801005]
total_rewards_mean           789.5259383677114
total_rewards_std            158.62749330622455
total_rewards_max            1163.764155269622
total_rewards_min            615.2057696818016
Number of train steps total  96000
Number of env steps total    482000
Number of rollouts total     0
Train Time (s)               29.092064212076366
(Previous) Eval Time (s)     5.08745955536142
Sample Time (s)              16.707505298312753
Epoch Time (s)               50.88702906575054
Total Train Time (s)         4567.214637851808
Epoch                        95
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:31:48.980323 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #95 | Epoch Duration: 50.479241132736206
2020-01-10 19:31:48.980483 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #95 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07671334
Z variance train             0.13000992
KL Divergence                3.0561638
KL Loss                      0.30561638
QF Loss                      495.8783
VF Loss                      166.15175
Policy Loss                  -490.09518
Q Predictions Mean           483.74686
Q Predictions Std            619.4815
Q Predictions Max            1662.8053
Q Predictions Min            15.561727
V Predictions Mean           492.51135
V Predictions Std            618.4192
V Predictions Max            1674.5685
V Predictions Min            24.06473
Log Pis Mean                 -7.4986134
Log Pis Std                  5.3872824
Log Pis Max                  11.0107565
Log Pis Min                  -13.624991
Policy mu Mean               0.19169617
Policy mu Std                0.53980565
Policy mu Max                2.233528
Policy mu Min                -2.26215
Policy log std Mean          -0.21409413
Policy log std Std           0.1306256
Policy log std Max           -0.03586159
Policy log std Min           -0.69590914
Z mean eval                  0.07737422
Z variance eval              0.13109721
total_rewards                [423.30768446 645.53074299 383.54854326 523.04631439 477.80814451
 572.94137558 411.13844128 709.83464684 714.6367047  441.70164023]
total_rewards_mean           530.3494238243638
total_rewards_std            117.96168854590175
total_rewards_max            714.6367047032984
total_rewards_min            383.54854326337704
Number of train steps total  97000
Number of env steps total    487000
Number of rollouts total     0
Train Time (s)               28.617864227853715
(Previous) Eval Time (s)     4.679377915337682
Sample Time (s)              16.376173664350063
Epoch Time (s)               49.67341580754146
Total Train Time (s)         4615.323789976537
Epoch                        96
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:32:37.090773 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #96 | Epoch Duration: 48.11016345024109
2020-01-10 19:32:37.090955 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #96 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.077592574
Z variance train             0.1311545
KL Divergence                3.0617535
KL Loss                      0.30617535
QF Loss                      865.0183
VF Loss                      276.729
Policy Loss                  -558.82623
Q Predictions Mean           551.94464
Q Predictions Std            647.2287
Q Predictions Max            1693.4498
Q Predictions Min            14.345992
V Predictions Mean           553.7455
V Predictions Std            637.80774
V Predictions Max            1676.6467
V Predictions Min            24.846766
Log Pis Mean                 -7.0282116
Log Pis Std                  5.816865
Log Pis Max                  13.992428
Log Pis Min                  -13.104
Policy mu Mean               0.18760182
Policy mu Std                0.57986957
Policy mu Max                2.243546
Policy mu Min                -2.194384
Policy log std Mean          -0.2208596
Policy log std Std           0.1334106
Policy log std Max           -0.024826288
Policy log std Min           -0.674366
Z mean eval                  0.078048475
Z variance eval              0.13527249
total_rewards                [ 612.96101768  889.11139342  882.23473652  560.33839338  640.38649928
 1147.25907769  827.19575757  532.99143295  575.89454683  543.06479728]
total_rewards_mean           721.14376526039
total_rewards_std            194.75088565903525
total_rewards_max            1147.2590776915708
total_rewards_min            532.9914329463954
Number of train steps total  98000
Number of env steps total    492000
Number of rollouts total     0
Train Time (s)               29.42655768804252
(Previous) Eval Time (s)     3.1158571606501937
Sample Time (s)              15.518162112683058
Epoch Time (s)               48.06057696137577
Total Train Time (s)         4664.632439881563
Epoch                        97
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:33:26.403591 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #97 | Epoch Duration: 49.31246519088745
2020-01-10 19:33:26.403909 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #97 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07859279
Z variance train             0.13522288
KL Divergence                3.0142977
KL Loss                      0.30142978
QF Loss                      602.64294
VF Loss                      312.70795
Policy Loss                  -487.84348
Q Predictions Mean           478.1012
Q Predictions Std            611.62396
Q Predictions Max            1689.5925
Q Predictions Min            13.737334
V Predictions Mean           481.93457
V Predictions Std            604.524
V Predictions Max            1679.9961
V Predictions Min            24.196255
Log Pis Mean                 -7.767334
Log Pis Std                  5.244333
Log Pis Max                  10.284809
Log Pis Min                  -13.00566
Policy mu Mean               0.16363658
Policy mu Std                0.54040736
Policy mu Max                2.142451
Policy mu Min                -2.2644162
Policy log std Mean          -0.20868772
Policy log std Std           0.12973145
Policy log std Max           -0.009776309
Policy log std Min           -0.73508775
Z mean eval                  0.07846065
Z variance eval              0.13393149
total_rewards                [796.8636143  605.1195994  560.64364066 428.74885972 449.25668669
 756.71016622 798.70858748 412.71340611 682.85222722 461.07411707]
total_rewards_mean           595.2690904864451
total_rewards_std            147.4589570522352
total_rewards_max            798.7085874785964
total_rewards_min            412.71340610774854
Number of train steps total  99000
Number of env steps total    497000
Number of rollouts total     0
Train Time (s)               30.439670982770622
(Previous) Eval Time (s)     4.367448745761067
Sample Time (s)              17.263367432169616
Epoch Time (s)               52.070487160701305
Total Train Time (s)         4716.191066147294
Epoch                        98
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:34:17.963140 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #98 | Epoch Duration: 51.55893564224243
2020-01-10 19:34:17.963442 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #98 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07869927
Z variance train             0.13392302
KL Divergence                3.0221128
KL Loss                      0.30221128
QF Loss                      596.6007
VF Loss                      264.37473
Policy Loss                  -586.66034
Q Predictions Mean           577.807
Q Predictions Std            671.70703
Q Predictions Max            1703.5234
Q Predictions Min            15.426311
V Predictions Mean           585.40063
V Predictions Std            667.55396
V Predictions Max            1708.3878
V Predictions Min            27.573147
Log Pis Mean                 -7.0101976
Log Pis Std                  5.651733
Log Pis Max                  9.614008
Log Pis Min                  -13.553629
Policy mu Mean               0.19151315
Policy mu Std                0.5872477
Policy mu Max                2.683962
Policy mu Min                -2.0552578
Policy log std Mean          -0.22926067
Policy log std Std           0.14474075
Policy log std Max           -0.07752471
Policy log std Min           -0.81756294
Z mean eval                  0.07834592
Z variance eval              0.12865658
total_rewards                [ 710.05366576  799.88346244  821.63216533 1092.79126671  757.74424298
  621.7168738   773.30806487  560.4497385   483.04481542  621.71140141]
total_rewards_mean           724.2335697212168
total_rewards_std            161.49121839539782
total_rewards_max            1092.7912667107144
total_rewards_min            483.04481541713943
Number of train steps total  100000
Number of env steps total    502000
Number of rollouts total     0
Train Time (s)               28.486337542999536
(Previous) Eval Time (s)     3.8555826591327786
Sample Time (s)              16.27454407280311
Epoch Time (s)               48.616464274935424
Total Train Time (s)         4765.361993419938
Epoch                        99
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:35:07.134758 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #99 | Epoch Duration: 49.17114853858948
2020-01-10 19:35:07.134956 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #99 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.078292355
Z variance train             0.1286561
KL Divergence                3.0923076
KL Loss                      0.30923077
QF Loss                      618.28467
VF Loss                      174.9131
Policy Loss                  -485.51074
Q Predictions Mean           476.61536
Q Predictions Std            604.7164
Q Predictions Max            1674.6866
Q Predictions Min            17.001068
V Predictions Mean           483.21088
V Predictions Std            602.04645
V Predictions Max            1682.6733
V Predictions Min            25.873457
Log Pis Mean                 -6.9874682
Log Pis Std                  5.91226
Log Pis Max                  11.675655
Log Pis Min                  -15.966562
Policy mu Mean               0.20008734
Policy mu Std                0.56779
Policy mu Max                2.2142794
Policy mu Min                -1.9965479
Policy log std Mean          -0.21861462
Policy log std Std           0.13452058
Policy log std Max           -0.047219507
Policy log std Min           -0.7248382
Z mean eval                  0.07907621
Z variance eval              0.13155952
total_rewards                [ 829.5483334   744.98713286 1283.66095371  534.6387307  1279.75315546
  892.05759912 1573.99044931  815.6154694   782.09983944  478.94983133]
total_rewards_mean           921.5301494729425
total_rewards_std            331.94647843067344
total_rewards_max            1573.9904493065449
total_rewards_min            478.94983133195353
Number of train steps total  101000
Number of env steps total    507000
Number of rollouts total     0
Train Time (s)               30.668282662983984
(Previous) Eval Time (s)     4.409951804205775
Sample Time (s)              17.1199469990097
Epoch Time (s)               52.19818146619946
Total Train Time (s)         4818.6580420406535
Epoch                        100
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:36:00.435044 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #100 | Epoch Duration: 53.29979372024536
2020-01-10 19:36:00.435416 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #100 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07904286
Z variance train             0.13166615
KL Divergence                3.0568714
KL Loss                      0.30568716
QF Loss                      816.3999
VF Loss                      285.80402
Policy Loss                  -506.5933
Q Predictions Mean           494.52466
Q Predictions Std            629.0897
Q Predictions Max            1706.9495
Q Predictions Min            14.203755
V Predictions Mean           506.76617
V Predictions Std            631.4507
V Predictions Max            1709.6135
V Predictions Min            22.191833
Log Pis Mean                 -7.405303
Log Pis Std                  5.7774806
Log Pis Max                  13.881322
Log Pis Min                  -13.11356
Policy mu Mean               0.16659597
Policy mu Std                0.5599776
Policy mu Max                2.2195358
Policy mu Min                -2.5241766
Policy log std Mean          -0.21738787
Policy log std Std           0.13581865
Policy log std Max           -0.08141237
Policy log std Min           -0.8779402
Z mean eval                  0.07909142
Z variance eval              0.1257678
total_rewards                [ 914.3734606   638.13205658  840.98934673  524.93550591 1105.22076537
  712.12974527 1094.51488408  792.23504862  709.75281178 1108.25368261]
total_rewards_mean           844.053730754869
total_rewards_std            196.9926157578858
total_rewards_max            1108.2536826063672
total_rewards_min            524.9355059128313
Number of train steps total  102000
Number of env steps total    512000
Number of rollouts total     0
Train Time (s)               29.985677314922214
(Previous) Eval Time (s)     5.511259275022894
Sample Time (s)              16.818098575342447
Epoch Time (s)               52.315035165287554
Total Train Time (s)         4870.626769701019
Epoch                        101
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:36:52.407384 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #101 | Epoch Duration: 51.97173619270325
2020-01-10 19:36:52.407659 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #101 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.079174265
Z variance train             0.12578063
KL Divergence                3.1514523
KL Loss                      0.31514522
QF Loss                      646.68823
VF Loss                      253.23456
Policy Loss                  -574.4719
Q Predictions Mean           567.7566
Q Predictions Std            647.4859
Q Predictions Max            1716.038
Q Predictions Min            15.065566
V Predictions Mean           570.9357
V Predictions Std            641.2269
V Predictions Max            1701.195
V Predictions Min            23.942778
Log Pis Mean                 -6.704004
Log Pis Std                  5.906859
Log Pis Max                  15.62129
Log Pis Min                  -14.179894
Policy mu Mean               0.22002998
Policy mu Std                0.60973835
Policy mu Max                2.655732
Policy mu Min                -3.1918862
Policy log std Mean          -0.2322303
Policy log std Std           0.13968484
Policy log std Max           -0.037971914
Policy log std Min           -0.84356797
Z mean eval                  0.07945769
Z variance eval              0.12757786
total_rewards                [882.41708671 867.46661256 808.16594912 920.15319409 930.26575177
 547.75842555 498.21078704 760.98002373 657.45340308 501.98237655]
total_rewards_mean           737.4853610198754
total_rewards_std            164.0412428774531
total_rewards_max            930.2657517709118
total_rewards_min            498.2107870396713
Number of train steps total  103000
Number of env steps total    517000
Number of rollouts total     0
Train Time (s)               30.35818051220849
(Previous) Eval Time (s)     5.167628235183656
Sample Time (s)              17.381157831288874
Epoch Time (s)               52.90696657868102
Total Train Time (s)         4922.692161572631
Epoch                        102
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:37:44.473299 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #102 | Epoch Duration: 52.065415143966675
2020-01-10 19:37:44.473603 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #102 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08008643
Z variance train             0.1276129
KL Divergence                3.0968149
KL Loss                      0.3096815
QF Loss                      851.732
VF Loss                      195.39255
Policy Loss                  -514.45087
Q Predictions Mean           502.83273
Q Predictions Std            625.97284
Q Predictions Max            1730.242
Q Predictions Min            15.101295
V Predictions Mean           510.31293
V Predictions Std            624.6292
V Predictions Max            1717.2112
V Predictions Min            23.370998
Log Pis Mean                 -7.380838
Log Pis Std                  5.766716
Log Pis Max                  15.25946
Log Pis Min                  -15.618342
Policy mu Mean               0.1646856
Policy mu Std                0.56399703
Policy mu Max                2.1625154
Policy mu Min                -2.2239778
Policy log std Mean          -0.22140181
Policy log std Std           0.13409388
Policy log std Max           0.06273648
Policy log std Min           -0.7234309
Z mean eval                  0.08134721
Z variance eval              0.12029521
total_rewards                [571.81558354 738.08428724 807.3232755  848.68233109 892.97607044
 592.70711796 457.77051575 655.50657447 773.74271385 830.27076383]
total_rewards_mean           716.8879233646564
total_rewards_std            134.338800446789
total_rewards_max            892.9760704404227
total_rewards_min            457.7705157479797
Number of train steps total  104000
Number of env steps total    522000
Number of rollouts total     0
Train Time (s)               30.59501967113465
(Previous) Eval Time (s)     4.3257830971851945
Sample Time (s)              16.674509970471263
Epoch Time (s)               51.59531273879111
Total Train Time (s)         4974.050639472902
Epoch                        103
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:38:35.836151 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #103 | Epoch Duration: 51.36229181289673
2020-01-10 19:38:35.836385 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #103 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.081521995
Z variance train             0.12028022
KL Divergence                3.228449
KL Loss                      0.32284492
QF Loss                      661.01086
VF Loss                      181.94695
Policy Loss                  -581.06525
Q Predictions Mean           574.5283
Q Predictions Std            630.9306
Q Predictions Max            1737.2565
Q Predictions Min            14.918989
V Predictions Mean           579.23413
V Predictions Std            625.4988
V Predictions Max            1729.8649
V Predictions Min            26.170923
Log Pis Mean                 -6.3697963
Log Pis Std                  5.9238915
Log Pis Max                  10.311815
Log Pis Min                  -13.581451
Policy mu Mean               0.21764836
Policy mu Std                0.6177679
Policy mu Max                2.058559
Policy mu Min                -2.00565
Policy log std Mean          -0.23444813
Policy log std Std           0.1421113
Policy log std Max           -0.04045248
Policy log std Min           -0.7628933
Z mean eval                  0.08008665
Z variance eval              0.11673598
total_rewards                [ 638.1311104  1038.51083404  725.24101113 1409.33219949  686.38368657
  710.83207736  478.04444775  505.59077599  611.10232774  757.46466608]
total_rewards_mean           756.0633136557773
total_rewards_std            262.5533481377783
total_rewards_max            1409.332199490207
total_rewards_min            478.0444477527456
Number of train steps total  105000
Number of env steps total    527000
Number of rollouts total     0
Train Time (s)               29.148309679236263
(Previous) Eval Time (s)     4.092453727964312
Sample Time (s)              16.86026818724349
Epoch Time (s)               50.101031594444066
Total Train Time (s)         5024.388712068554
Epoch                        104
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:39:26.173068 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #104 | Epoch Duration: 50.3365113735199
2020-01-10 19:39:26.173249 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #104 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08017744
Z variance train             0.1167238
KL Divergence                3.2988136
KL Loss                      0.32988137
QF Loss                      858.63525
VF Loss                      331.97864
Policy Loss                  -542.80035
Q Predictions Mean           531.3032
Q Predictions Std            631.38525
Q Predictions Max            1714.4973
Q Predictions Min            16.122715
V Predictions Mean           541.8805
V Predictions Std            631.9481
V Predictions Max            1738.3289
V Predictions Min            27.218596
Log Pis Mean                 -7.2550497
Log Pis Std                  5.457736
Log Pis Max                  6.881275
Log Pis Min                  -13.822659
Policy mu Mean               0.2015469
Policy mu Std                0.57336354
Policy mu Max                2.2237458
Policy mu Min                -1.9177077
Policy log std Mean          -0.2236376
Policy log std Std           0.13613991
Policy log std Max           -0.056567155
Policy log std Min           -0.75674725
Z mean eval                  0.07915036
Z variance eval              0.11400585
total_rewards                [ 772.62867501  666.19020463  417.03701688 1157.16839775 1311.18543411
  880.89051207 1028.64917327  886.46912553  694.04275135  857.71011403]
total_rewards_mean           867.1971404637067
total_rewards_std            242.87819531489242
total_rewards_max            1311.185434113626
total_rewards_min            417.03701688313856
Number of train steps total  106000
Number of env steps total    532000
Number of rollouts total     0
Train Time (s)               29.821832736954093
(Previous) Eval Time (s)     4.327637515962124
Sample Time (s)              16.133267145603895
Epoch Time (s)               50.28273739852011
Total Train Time (s)         5075.526710285805
Epoch                        105
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:40:17.314158 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #105 | Epoch Duration: 51.14072632789612
2020-01-10 19:40:17.314467 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #105 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0791151
Z variance train             0.11398747
KL Divergence                3.3437657
KL Loss                      0.33437657
QF Loss                      1038.5344
VF Loss                      270.7187
Policy Loss                  -627.767
Q Predictions Mean           616.70386
Q Predictions Std            672.9857
Q Predictions Max            1725.0106
Q Predictions Min            17.52378
V Predictions Mean           626.3331
V Predictions Std            671.01733
V Predictions Max            1744.005
V Predictions Min            27.74387
Log Pis Mean                 -6.8619313
Log Pis Std                  5.377736
Log Pis Max                  9.256976
Log Pis Min                  -13.443987
Policy mu Mean               0.2026103
Policy mu Std                0.6057733
Policy mu Max                2.1423678
Policy mu Min                -2.0812821
Policy log std Mean          -0.23487863
Policy log std Std           0.14049019
Policy log std Max           -0.062378094
Policy log std Min           -0.8793348
Z mean eval                  0.077223785
Z variance eval              0.11701135
total_rewards                [ 624.47428626  886.14714861 1250.4473757   857.30033351  673.6782219
  607.59011662  730.36645101  416.80686993 1052.38813693  537.41565861]
total_rewards_mean           763.6614599084617
total_rewards_std            238.437989392449
total_rewards_max            1250.4473756991263
total_rewards_min            416.80686993373024
Number of train steps total  107000
Number of env steps total    537000
Number of rollouts total     0
Train Time (s)               31.340556893963367
(Previous) Eval Time (s)     5.185311019886285
Sample Time (s)              16.753983889706433
Epoch Time (s)               53.279851803556085
Total Train Time (s)         5127.736985226627
Epoch                        106
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:41:09.527619 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #106 | Epoch Duration: 52.21289563179016
2020-01-10 19:41:09.527930 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #106 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07728202
Z variance train             0.11702208
KL Divergence                3.3186932
KL Loss                      0.33186933
QF Loss                      1271.329
VF Loss                      359.63254
Policy Loss                  -586.59235
Q Predictions Mean           580.07367
Q Predictions Std            645.0504
Q Predictions Max            1748.088
Q Predictions Min            16.898636
V Predictions Mean           585.71936
V Predictions Std            639.71063
V Predictions Max            1735.3269
V Predictions Min            27.49564
Log Pis Mean                 -6.732945
Log Pis Std                  5.9158773
Log Pis Max                  13.690415
Log Pis Min                  -13.804308
Policy mu Mean               0.21760857
Policy mu Std                0.6085029
Policy mu Max                2.6194787
Policy mu Min                -2.14703
Policy log std Mean          -0.22680001
Policy log std Std           0.14000201
Policy log std Max           -0.022884995
Policy log std Min           -0.8510914
Z mean eval                  0.0773403
Z variance eval              0.1108314
total_rewards                [ 850.09513014  533.38553512  843.05122987 1149.87357552  605.09599723
 1232.89762086  744.09441954  937.05302231  665.9773939   979.60595984]
total_rewards_mean           854.1129884336704
total_rewards_std            215.89182755861356
total_rewards_max            1232.8976208617446
total_rewards_min            533.3855351174524
Number of train steps total  108000
Number of env steps total    542000
Number of rollouts total     0
Train Time (s)               31.668143230024725
(Previous) Eval Time (s)     4.118049644865096
Sample Time (s)              16.806452243123204
Epoch Time (s)               52.592645118013024
Total Train Time (s)         5181.027880683076
Epoch                        107
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:42:02.819374 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #107 | Epoch Duration: 53.291224002838135
2020-01-10 19:42:02.819586 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #107 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07703644
Z variance train             0.11077316
KL Divergence                3.426742
KL Loss                      0.34267423
QF Loss                      1013.15125
VF Loss                      315.0353
Policy Loss                  -609.7996
Q Predictions Mean           598.11633
Q Predictions Std            670.2821
Q Predictions Max            1728.8805
Q Predictions Min            14.903282
V Predictions Mean           613.3739
V Predictions Std            677.07385
V Predictions Max            1749.8082
V Predictions Min            23.650124
Log Pis Mean                 -6.890933
Log Pis Std                  5.75908
Log Pis Max                  16.034164
Log Pis Min                  -12.6702385
Policy mu Mean               0.22545448
Policy mu Std                0.60102624
Policy mu Max                2.752432
Policy mu Min                -2.1613865
Policy log std Mean          -0.22943558
Policy log std Std           0.14060909
Policy log std Max           0.0900393
Policy log std Min           -0.856744
Z mean eval                  0.07491733
Z variance eval              0.10746435
total_rewards                [ 642.02908109 2581.32127083 1419.63172511 1348.91879854  842.43781891
  538.1041669  1007.66443569  898.64100669  724.70208615 1952.14240322]
total_rewards_mean           1195.5592793143514
total_rewards_std            614.4095559017392
total_rewards_max            2581.321270834845
total_rewards_min            538.1041669045851
Number of train steps total  109000
Number of env steps total    547000
Number of rollouts total     0
Train Time (s)               30.59054965013638
(Previous) Eval Time (s)     4.816294653806835
Sample Time (s)              16.793555340729654
Epoch Time (s)               52.20039964467287
Total Train Time (s)         5235.973649427295
Epoch                        108
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:42:57.766113 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #108 | Epoch Duration: 54.946367502212524
2020-01-10 19:42:57.766272 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #108 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07505669
Z variance train             0.107475325
KL Divergence                3.479839
KL Loss                      0.34798393
QF Loss                      838.2106
VF Loss                      201.25928
Policy Loss                  -579.9729
Q Predictions Mean           571.1436
Q Predictions Std            649.044
Q Predictions Max            1756.885
Q Predictions Min            15.174127
V Predictions Mean           580.34424
V Predictions Std            646.5339
V Predictions Max            1752.984
V Predictions Min            28.02318
Log Pis Mean                 -6.795284
Log Pis Std                  5.8239627
Log Pis Max                  13.736293
Log Pis Min                  -13.328293
Policy mu Mean               0.20413493
Policy mu Std                0.6059054
Policy mu Max                2.6181076
Policy mu Min                -2.3667815
Policy log std Mean          -0.23021598
Policy log std Std           0.14144075
Policy log std Max           -0.011465684
Policy log std Min           -0.8385585
Z mean eval                  0.07329822
Z variance eval              0.10689038
total_rewards                [1133.29939767  634.03126396  442.60290257 1119.94630142  739.64161735
  581.56745712  737.24456586  420.73071693 2404.70702858 1043.64583585]
total_rewards_mean           925.7417087313485
total_rewards_std            551.7435946498056
total_rewards_max            2404.7070285810364
total_rewards_min            420.7307169342528
Number of train steps total  110000
Number of env steps total    552000
Number of rollouts total     0
Train Time (s)               31.886845189146698
(Previous) Eval Time (s)     7.561991636175662
Sample Time (s)              17.583581047598273
Epoch Time (s)               57.03241787292063
Total Train Time (s)         5290.733307969291
Epoch                        109
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:43:52.530871 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #109 | Epoch Duration: 54.764427185058594
2020-01-10 19:43:52.531179 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #109 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0729449
Z variance train             0.10688619
KL Divergence                3.4585485
KL Loss                      0.34585485
QF Loss                      575.0835
VF Loss                      387.35068
Policy Loss                  -532.7192
Q Predictions Mean           527.6427
Q Predictions Std            654.0156
Q Predictions Max            1738.2335
Q Predictions Min            15.017004
V Predictions Mean           540.3415
V Predictions Std            654.917
V Predictions Max            1767.8618
V Predictions Min            27.885715
Log Pis Mean                 -7.047427
Log Pis Std                  5.8061996
Log Pis Max                  8.067343
Log Pis Min                  -14.67092
Policy mu Mean               0.21706374
Policy mu Std                0.5649494
Policy mu Max                2.3198783
Policy mu Min                -2.379479
Policy log std Mean          -0.22203822
Policy log std Std           0.13630076
Policy log std Max           -0.07606004
Policy log std Min           -0.7966962
Z mean eval                  0.07107599
Z variance eval              0.10687685
total_rewards                [ 584.44951823  887.69540725  567.00018737  702.52932961  550.16169813
 1018.05737377  613.10479247 1043.21641051  673.52360383 1380.10453322]
total_rewards_mean           801.9842854379967
total_rewards_std            259.7060549072536
total_rewards_max            1380.1045332201243
total_rewards_min            550.161698130329
Number of train steps total  111000
Number of env steps total    557000
Number of rollouts total     0
Train Time (s)               31.572845601011068
(Previous) Eval Time (s)     5.293673264794052
Sample Time (s)              17.134410458616912
Epoch Time (s)               54.00092932442203
Total Train Time (s)         5344.027940570377
Epoch                        110
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:44:45.827513 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #110 | Epoch Duration: 53.29610776901245
2020-01-10 19:44:45.827740 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #110 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07116554
Z variance train             0.10688327
KL Divergence                3.5004742
KL Loss                      0.35004744
QF Loss                      1181.8901
VF Loss                      479.1266
Policy Loss                  -600.6654
Q Predictions Mean           589.3098
Q Predictions Std            657.33264
Q Predictions Max            1758.7366
Q Predictions Min            13.023487
V Predictions Mean           598.02527
V Predictions Std            657.4495
V Predictions Max            1766.6105
V Predictions Min            23.424786
Log Pis Mean                 -6.448933
Log Pis Std                  5.876077
Log Pis Max                  13.9509735
Log Pis Min                  -14.230065
Policy mu Mean               0.22924674
Policy mu Std                0.6072379
Policy mu Max                2.3119562
Policy mu Min                -2.986501
Policy log std Mean          -0.23195486
Policy log std Std           0.14182988
Policy log std Max           -0.025174186
Policy log std Min           -0.7444943
Z mean eval                  0.069848746
Z variance eval              0.105844185
total_rewards                [ 455.30204253  705.21979042  881.19520055  985.84971696  656.93688478
  547.59579757  600.47648188  618.80363791 1024.90370912  989.55311315]
total_rewards_mean           746.5836374856658
total_rewards_std            195.88987299012857
total_rewards_max            1024.9037091240884
total_rewards_min            455.3020425294265
Number of train steps total  112000
Number of env steps total    562000
Number of rollouts total     0
Train Time (s)               27.667228335049003
(Previous) Eval Time (s)     4.588559529744089
Sample Time (s)              17.16215696465224
Epoch Time (s)               49.41794482944533
Total Train Time (s)         5393.040757659357
Epoch                        111
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:45:34.842199 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #111 | Epoch Duration: 49.01429557800293
2020-01-10 19:45:34.842392 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #111 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.069658086
Z variance train             0.105835654
KL Divergence                3.5367198
KL Loss                      0.353672
QF Loss                      728.6974
VF Loss                      193.35187
Policy Loss                  -551.6766
Q Predictions Mean           542.2947
Q Predictions Std            644.90924
Q Predictions Max            1774.3911
Q Predictions Min            17.158464
V Predictions Mean           548.6067
V Predictions Std            640.5265
V Predictions Max            1764.9103
V Predictions Min            28.545498
Log Pis Mean                 -6.930938
Log Pis Std                  5.8179526
Log Pis Max                  8.822022
Log Pis Min                  -14.3374195
Policy mu Mean               0.18741782
Policy mu Std                0.58928126
Policy mu Max                2.4480178
Policy mu Min                -2.1050682
Policy log std Mean          -0.22441205
Policy log std Std           0.1373234
Policy log std Max           -0.055356026
Policy log std Min           -0.7077796
Z mean eval                  0.06910411
Z variance eval              0.10078082
total_rewards                [2393.0356065   685.73111113  966.82169883  932.38735974 1399.36972728
  814.57958986  631.00174773  787.59823172  789.27803607 1086.60388811]
total_rewards_mean           1048.6406996958576
total_rewards_std            494.81121006321956
total_rewards_max            2393.0356065002466
total_rewards_min            631.0017477318313
Number of train steps total  113000
Number of env steps total    567000
Number of rollouts total     0
Train Time (s)               29.251854528672993
(Previous) Eval Time (s)     4.184567602816969
Sample Time (s)              16.788450602907687
Epoch Time (s)               50.22487273439765
Total Train Time (s)         5445.35442804778
Epoch                        112
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:46:27.159259 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #112 | Epoch Duration: 52.316697120666504
2020-01-10 19:46:27.159577 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #112 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06910522
Z variance train             0.100820854
KL Divergence                3.621169
KL Loss                      0.3621169
QF Loss                      719.9168
VF Loss                      328.8875
Policy Loss                  -480.14062
Q Predictions Mean           474.93292
Q Predictions Std            606.3966
Q Predictions Max            1775.0492
Q Predictions Min            15.687178
V Predictions Mean           486.60855
V Predictions Std            605.5538
V Predictions Max            1776.5271
V Predictions Min            24.630903
Log Pis Mean                 -6.977851
Log Pis Std                  6.1296163
Log Pis Max                  15.52659
Log Pis Min                  -15.254621
Policy mu Mean               0.21951912
Policy mu Std                0.56924987
Policy mu Max                2.3373132
Policy mu Min                -2.3772764
Policy log std Mean          -0.21986687
Policy log std Std           0.13621019
Policy log std Max           -0.07599589
Policy log std Min           -0.7908772
Z mean eval                  0.06927718
Z variance eval              0.098808214
total_rewards                [724.00491795 527.94564578 410.74670861 684.11425353 865.98723347
 916.43096076 958.62351584 725.3461346  745.64975303 805.91053442]
total_rewards_mean           736.475965798254
total_rewards_std            160.00544140308327
total_rewards_max            958.6235158377751
total_rewards_min            410.74670861278577
Number of train steps total  114000
Number of env steps total    572000
Number of rollouts total     0
Train Time (s)               31.660066077951342
(Previous) Eval Time (s)     6.276063110213727
Sample Time (s)              17.529689284972847
Epoch Time (s)               55.465818473137915
Total Train Time (s)         5499.2037998130545
Epoch                        113
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:47:21.011677 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #113 | Epoch Duration: 53.85184192657471
2020-01-10 19:47:21.011984 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #113 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06932729
Z variance train             0.09881826
KL Divergence                3.6537573
KL Loss                      0.36537573
QF Loss                      746.53784
VF Loss                      276.78958
Policy Loss                  -567.23724
Q Predictions Mean           560.7627
Q Predictions Std            669.94763
Q Predictions Max            1783.0582
Q Predictions Min            14.437466
V Predictions Mean           573.19336
V Predictions Std            670.2483
V Predictions Max            1796.4602
V Predictions Min            24.816092
Log Pis Mean                 -6.875036
Log Pis Std                  6.125635
Log Pis Max                  28.193539
Log Pis Min                  -12.657325
Policy mu Mean               0.20779108
Policy mu Std                0.56980187
Policy mu Max                2.9994588
Policy mu Min                -2.5454972
Policy log std Mean          -0.22306624
Policy log std Std           0.13993675
Policy log std Max           -0.050394394
Policy log std Min           -0.8855348
Z mean eval                  0.06858408
Z variance eval              0.095778726
total_rewards                [439.58046305 735.16148309 396.20437695 958.51812423 521.42456897
 505.28167137 532.09880141 426.40317856 828.37594381 525.80004504]
total_rewards_mean           586.8848656485812
total_rewards_std            178.85865441311185
total_rewards_max            958.5181242333164
total_rewards_min            396.2043769499861
Number of train steps total  115000
Number of env steps total    577000
Number of rollouts total     0
Train Time (s)               30.376707090996206
(Previous) Eval Time (s)     4.661793961189687
Sample Time (s)              16.84790709707886
Epoch Time (s)               51.88640814926475
Total Train Time (s)         5550.007444102783
Epoch                        114
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:48:11.816651 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #114 | Epoch Duration: 50.80445122718811
2020-01-10 19:48:11.816834 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #114 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06870487
Z variance train             0.09579955
KL Divergence                3.7160084
KL Loss                      0.37160084
QF Loss                      640.33716
VF Loss                      294.6831
Policy Loss                  -567.3788
Q Predictions Mean           560.1688
Q Predictions Std            674.1147
Q Predictions Max            1801.7832
Q Predictions Min            15.855105
V Predictions Mean           560.5254
V Predictions Std            662.72534
V Predictions Max            1775.7961
V Predictions Min            27.069815
Log Pis Mean                 -6.6392136
Log Pis Std                  6.182586
Log Pis Max                  14.507552
Log Pis Min                  -12.736542
Policy mu Mean               0.21967593
Policy mu Std                0.60406256
Policy mu Max                2.269489
Policy mu Min                -2.9019976
Policy log std Mean          -0.23182775
Policy log std Std           0.14576948
Policy log std Max           -0.07695208
Policy log std Min           -0.7546724
Z mean eval                  0.06894416
Z variance eval              0.09627144
total_rewards                [ 706.62393533 1726.20943354  549.34512322  396.27368252 1112.69344243
 1539.37890275 1128.69648025  744.05800277 1110.23307272  395.22412036]
total_rewards_mean           940.873619590798
total_rewards_std            436.9976372985793
total_rewards_max            1726.2094335398888
total_rewards_min            395.2241203644524
Number of train steps total  116000
Number of env steps total    582000
Number of rollouts total     0
Train Time (s)               29.41136733116582
(Previous) Eval Time (s)     3.5794899659231305
Sample Time (s)              17.819645361509174
Epoch Time (s)               50.810502658598125
Total Train Time (s)         5602.491340268403
Epoch                        115
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:49:04.302753 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #115 | Epoch Duration: 52.48575758934021
2020-01-10 19:49:04.302982 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #115 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.068954065
Z variance train             0.09626275
KL Divergence                3.7123425
KL Loss                      0.37123427
QF Loss                      1137.3069
VF Loss                      465.51056
Policy Loss                  -512.9277
Q Predictions Mean           506.03046
Q Predictions Std            650.0119
Q Predictions Max            1764.3761
Q Predictions Min            15.80231
V Predictions Mean           518.9822
V Predictions Std            653.7177
V Predictions Max            1777.1152
V Predictions Min            25.145952
Log Pis Mean                 -7.398997
Log Pis Std                  5.6057596
Log Pis Max                  6.5903444
Log Pis Min                  -12.690598
Policy mu Mean               0.18183708
Policy mu Std                0.5783271
Policy mu Max                2.283806
Policy mu Min                -2.5201557
Policy log std Mean          -0.21914965
Policy log std Std           0.1397459
Policy log std Max           -0.034824774
Policy log std Min           -0.7313075
Z mean eval                  0.063152134
Z variance eval              0.09108377
total_rewards                [ 564.57541906 1033.71324027  595.08835602 1287.86622512 1394.26209975
  804.27698681 1022.66858119  555.13584797  905.85702341  389.12685954]
total_rewards_mean           855.2570639141338
total_rewards_std            316.58227194366015
total_rewards_max            1394.2620997537929
total_rewards_min            389.12685954104944
Number of train steps total  117000
Number of env steps total    587000
Number of rollouts total     0
Train Time (s)               29.545147823169827
(Previous) Eval Time (s)     5.254446031991392
Sample Time (s)              17.16281591448933
Epoch Time (s)               51.96240976965055
Total Train Time (s)         5654.337301480118
Epoch                        116
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:49:56.150256 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #116 | Epoch Duration: 51.84710097312927
2020-01-10 19:49:56.150448 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #116 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06285802
Z variance train             0.09107672
KL Divergence                3.8272276
KL Loss                      0.38272277
QF Loss                      1071.0537
VF Loss                      412.65686
Policy Loss                  -605.82666
Q Predictions Mean           596.54816
Q Predictions Std            675.20795
Q Predictions Max            1790.8893
Q Predictions Min            16.046986
V Predictions Mean           612.4284
V Predictions Std            678.9575
V Predictions Max            1798.3246
V Predictions Min            28.533619
Log Pis Mean                 -6.5730505
Log Pis Std                  5.823535
Log Pis Max                  8.829964
Log Pis Min                  -15.471424
Policy mu Mean               0.24202117
Policy mu Std                0.61193806
Policy mu Max                2.264978
Policy mu Min                -2.1601171
Policy log std Mean          -0.2412492
Policy log std Std           0.14908071
Policy log std Max           -0.05318363
Policy log std Min           -0.8810509
Z mean eval                  0.06268127
Z variance eval              0.091734335
total_rewards                [673.41476495 654.36991116 457.62712163 929.3364833  493.13386248
 601.59593303 777.90339168 821.11701277 930.70972382 810.36056904]
total_rewards_mean           714.9568773864405
total_rewards_std            158.2761172730808
total_rewards_max            930.7097238246785
total_rewards_min            457.6271216327193
Number of train steps total  118000
Number of env steps total    592000
Number of rollouts total     0
Train Time (s)               29.11768696922809
(Previous) Eval Time (s)     5.1388394152745605
Sample Time (s)              17.274205594323575
Epoch Time (s)               51.530731978826225
Total Train Time (s)         5704.82045111293
Epoch                        117
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:50:46.636760 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #117 | Epoch Duration: 50.486138105392456
2020-01-10 19:50:46.637016 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #117 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0627717
Z variance train             0.09176324
KL Divergence                3.8190281
KL Loss                      0.3819028
QF Loss                      1530.1163
VF Loss                      281.373
Policy Loss                  -628.7963
Q Predictions Mean           629.47656
Q Predictions Std            682.29254
Q Predictions Max            1816.6157
Q Predictions Min            15.625192
V Predictions Mean           629.7422
V Predictions Std            672.1506
V Predictions Max            1819.2249
V Predictions Min            27.042345
Log Pis Mean                 -6.247574
Log Pis Std                  6.181583
Log Pis Max                  13.167095
Log Pis Min                  -13.983601
Policy mu Mean               0.2308666
Policy mu Std                0.6316705
Policy mu Max                2.197192
Policy mu Min                -2.298717
Policy log std Mean          -0.24350531
Policy log std Std           0.14885916
Policy log std Max           -0.056101985
Policy log std Min           -0.74291366
Z mean eval                  0.061699796
Z variance eval              0.0888738
total_rewards                [ 674.41676142 1548.83736603  581.36055875  779.10687732  747.99066528
 1047.87213931  762.63584363  492.21210136  598.63970938 1250.64954908]
total_rewards_mean           848.3721571570708
total_rewards_std            317.0608213485451
total_rewards_max            1548.8373660343777
total_rewards_min            492.21210136039343
Number of train steps total  119000
Number of env steps total    597000
Number of rollouts total     0
Train Time (s)               29.478402095846832
(Previous) Eval Time (s)     4.093935553915799
Sample Time (s)              16.308544875588268
Epoch Time (s)               49.8808825253509
Total Train Time (s)         5755.71411463758
Epoch                        118
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:51:37.533615 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #118 | Epoch Duration: 50.8963840007782
2020-01-10 19:51:37.533875 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #118 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.062008716
Z variance train             0.08887803
KL Divergence                3.8723788
KL Loss                      0.38723788
QF Loss                      1187.9003
VF Loss                      339.71832
Policy Loss                  -652.08734
Q Predictions Mean           639.05835
Q Predictions Std            700.4651
Q Predictions Max            1809.2456
Q Predictions Min            17.824976
V Predictions Mean           647.93024
V Predictions Std            699.2851
V Predictions Max            1830.353
V Predictions Min            24.590063
Log Pis Mean                 -6.1984944
Log Pis Std                  6.177597
Log Pis Max                  11.012258
Log Pis Min                  -14.483406
Policy mu Mean               0.23401165
Policy mu Std                0.63034946
Policy mu Max                2.35633
Policy mu Min                -2.6943736
Policy log std Mean          -0.24514583
Policy log std Std           0.15201072
Policy log std Max           -0.053169206
Policy log std Min           -0.7792633
Z mean eval                  0.058020372
Z variance eval              0.08466556
total_rewards                [ 773.28924211  514.11600626  665.93749324  545.45777455 1280.37054369
  808.92752535  923.06374278 1504.08832899  760.70153926  734.76300853]
total_rewards_mean           851.0715204753609
total_rewards_std            297.7659272850329
total_rewards_max            1504.0883289922544
total_rewards_min            514.1160062600491
Number of train steps total  120000
Number of env steps total    602000
Number of rollouts total     0
Train Time (s)               29.435001477599144
(Previous) Eval Time (s)     5.109130760654807
Sample Time (s)              16.74820353090763
Epoch Time (s)               51.29233576916158
Total Train Time (s)         5806.886795778759
Epoch                        119
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:52:28.709323 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #119 | Epoch Duration: 51.17522573471069
2020-01-10 19:52:28.709579 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #119 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05813829
Z variance train             0.084678635
KL Divergence                3.9736934
KL Loss                      0.39736935
QF Loss                      840.50024
VF Loss                      208.35895
Policy Loss                  -572.38086
Q Predictions Mean           566.1007
Q Predictions Std            681.7896
Q Predictions Max            1835.3525
Q Predictions Min            16.132076
V Predictions Mean           577.90137
V Predictions Std            682.5042
V Predictions Max            1834.4347
V Predictions Min            27.405518
Log Pis Mean                 -6.6873
Log Pis Std                  6.300193
Log Pis Max                  16.726612
Log Pis Min                  -13.686106
Policy mu Mean               0.2063105
Policy mu Std                0.60697895
Policy mu Max                2.2900257
Policy mu Min                -2.411013
Policy log std Mean          -0.22820479
Policy log std Std           0.14346598
Policy log std Max           -0.07309347
Policy log std Min           -0.82347757
Z mean eval                  0.052480698
Z variance eval              0.08348994
total_rewards                [2152.40243143 1548.25429502  560.97157856 1005.73715778 3024.65173636
 1444.50824896  898.88861474  927.9314092   588.58993826  727.15308248]
total_rewards_mean           1287.908849279333
total_rewards_std            744.875913230429
total_rewards_max            3024.651736359746
total_rewards_min            560.9715785585596
Number of train steps total  121000
Number of env steps total    607000
Number of rollouts total     0
Train Time (s)               29.181339436210692
(Previous) Eval Time (s)     4.991708172019571
Sample Time (s)              17.66205171169713
Epoch Time (s)               51.835099319927394
Total Train Time (s)         5861.69132839283
Epoch                        120
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:53:23.515090 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #120 | Epoch Duration: 54.8053092956543
2020-01-10 19:53:23.515337 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #120 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.052448142
Z variance train             0.083511874
KL Divergence                4.0022354
KL Loss                      0.40022355
QF Loss                      1783.1947
VF Loss                      290.23962
Policy Loss                  -710.10913
Q Predictions Mean           699.8346
Q Predictions Std            697.0663
Q Predictions Max            1827.2382
Q Predictions Min            15.128986
V Predictions Mean           707.4336
V Predictions Std            695.139
V Predictions Max            1845.0992
V Predictions Min            24.101906
Log Pis Mean                 -5.383744
Log Pis Std                  6.5345974
Log Pis Max                  19.675447
Log Pis Min                  -14.287443
Policy mu Mean               0.2510813
Policy mu Std                0.66856
Policy mu Max                2.1748161
Policy mu Min                -2.1680639
Policy log std Mean          -0.25689209
Policy log std Std           0.15210472
Policy log std Max           -0.031368062
Policy log std Min           -0.83998364
Z mean eval                  0.05339852
Z variance eval              0.084503934
total_rewards                [1459.14625075  721.0552659  1495.61862855 1826.01649203  886.56466668
 1007.06999856  758.45756592  832.92173486  694.34489955  736.53230744]
total_rewards_mean           1041.7727810236393
total_rewards_std            382.24763979879657
total_rewards_max            1826.016492027927
total_rewards_min            694.3448995504696
Number of train steps total  122000
Number of env steps total    612000
Number of rollouts total     0
Train Time (s)               28.570401578210294
(Previous) Eval Time (s)     7.961630459874868
Sample Time (s)              18.592409945093095
Epoch Time (s)               55.12444198317826
Total Train Time (s)         5915.076804067474
Epoch                        121
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:54:16.901888 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #121 | Epoch Duration: 53.386364459991455
2020-01-10 19:54:16.902093 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #121 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05342067
Z variance train             0.08451833
KL Divergence                3.9732041
KL Loss                      0.39732042
QF Loss                      860.0832
VF Loss                      373.44547
Policy Loss                  -606.6092
Q Predictions Mean           595.916
Q Predictions Std            700.7488
Q Predictions Max            1822.0831
Q Predictions Min            14.530637
V Predictions Mean           600.98206
V Predictions Std            697.181
V Predictions Max            1814.9547
V Predictions Min            26.245882
Log Pis Mean                 -6.5082827
Log Pis Std                  6.1109905
Log Pis Max                  9.215873
Log Pis Min                  -12.950298
Policy mu Mean               0.24372031
Policy mu Std                0.6172361
Policy mu Max                2.1284876
Policy mu Min                -2.1962497
Policy log std Mean          -0.23708007
Policy log std Std           0.14865965
Policy log std Max           -0.030476823
Policy log std Min           -0.77097356
Z mean eval                  0.052585106
Z variance eval              0.079855666
total_rewards                [1418.62874361  881.55112142  363.65558621 1203.43691887  742.83368013
 1442.98004655 1016.92403608 1558.22675226 1322.45574368  979.71152435]
total_rewards_mean           1093.0404153163468
total_rewards_std            350.38471177188734
total_rewards_max            1558.2267522586728
total_rewards_min            363.6555862140411
Number of train steps total  123000
Number of env steps total    617000
Number of rollouts total     0
Train Time (s)               28.82170864380896
(Previous) Eval Time (s)     6.223241825122386
Sample Time (s)              18.559669078327715
Epoch Time (s)               53.60461954725906
Total Train Time (s)         5968.67931650253
Epoch                        122
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:55:10.508126 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #122 | Epoch Duration: 53.60586953163147
2020-01-10 19:55:10.508366 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #122 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05273086
Z variance train             0.079816215
KL Divergence                4.1066303
KL Loss                      0.41066304
QF Loss                      1060.0898
VF Loss                      266.096
Policy Loss                  -561.88855
Q Predictions Mean           554.9138
Q Predictions Std            689.0946
Q Predictions Max            1843.2532
Q Predictions Min            15.146368
V Predictions Mean           557.6776
V Predictions Std            677.65875
V Predictions Max            1837.4044
V Predictions Min            28.64676
Log Pis Mean                 -6.852813
Log Pis Std                  5.890943
Log Pis Max                  9.08453
Log Pis Min                  -13.560209
Policy mu Mean               0.23990788
Policy mu Std                0.58788306
Policy mu Max                2.5208948
Policy mu Min                -2.1243546
Policy log std Mean          -0.23456761
Policy log std Std           0.146469
Policy log std Max           -0.08411555
Policy log std Min           -0.8377891
Z mean eval                  0.05306811
Z variance eval              0.07999178
total_rewards                [1219.9248495  1000.51601497  627.06175671 2023.08248582  869.68896225
 1263.25975559 1113.75219094  859.62897367  930.18361056  522.88316249]
total_rewards_mean           1042.998176249584
total_rewards_std            395.86671197743937
total_rewards_max            2023.0824858207936
total_rewards_min            522.8831624875635
Number of train steps total  124000
Number of env steps total    622000
Number of rollouts total     0
Train Time (s)               29.3509532478638
(Previous) Eval Time (s)     6.224158457946032
Sample Time (s)              18.02846524026245
Epoch Time (s)               53.60357694607228
Total Train Time (s)         6022.164527430665
Epoch                        123
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:56:03.994043 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #123 | Epoch Duration: 53.4854793548584
2020-01-10 19:56:03.994261 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #123 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.053129088
Z variance train             0.080012485
KL Divergence                4.102104
KL Loss                      0.41021043
QF Loss                      1234.295
VF Loss                      281.38287
Policy Loss                  -695.06464
Q Predictions Mean           686.84576
Q Predictions Std            699.27496
Q Predictions Max            1843.4845
Q Predictions Min            16.037323
V Predictions Mean           698.69415
V Predictions Std            700.83966
V Predictions Max            1847.6825
V Predictions Min            25.284441
Log Pis Mean                 -5.7081046
Log Pis Std                  6.4000998
Log Pis Max                  15.035889
Log Pis Min                  -13.752399
Policy mu Mean               0.24269177
Policy mu Std                0.65158224
Policy mu Max                2.4148648
Policy mu Min                -2.9516354
Policy log std Mean          -0.2470946
Policy log std Std           0.14788648
Policy log std Max           -0.008434877
Policy log std Min           -0.8163954
Z mean eval                  0.050496142
Z variance eval              0.07895823
total_rewards                [ 999.52478121 1280.60118421 1172.98753623  701.94852154  558.1871401
  768.02476457  830.00961952  588.44199595  678.00930684  696.78509783]
total_rewards_mean           827.4519947998027
total_rewards_std            232.9535570661109
total_rewards_max            1280.6011842121957
total_rewards_min            558.1871400969973
Number of train steps total  125000
Number of env steps total    627000
Number of rollouts total     0
Train Time (s)               30.7356523796916
(Previous) Eval Time (s)     6.105768384877592
Sample Time (s)              18.727060948032886
Epoch Time (s)               55.56848171260208
Total Train Time (s)         6076.649323506281
Epoch                        124
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:56:58.481513 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #124 | Epoch Duration: 54.48701500892639
2020-01-10 19:56:58.481819 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #124 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.050130196
Z variance train             0.07896353
KL Divergence                4.130799
KL Loss                      0.4130799
QF Loss                      773.18555
VF Loss                      288.78812
Policy Loss                  -608.28125
Q Predictions Mean           600.8898
Q Predictions Std            710.76624
Q Predictions Max            1844.9589
Q Predictions Min            16.16882
V Predictions Mean           603.558
V Predictions Std            701.66895
V Predictions Max            1846.7025
V Predictions Min            27.480019
Log Pis Mean                 -6.6850424
Log Pis Std                  6.1086845
Log Pis Max                  10.761111
Log Pis Min                  -14.611896
Policy mu Mean               0.21936665
Policy mu Std                0.59953964
Policy mu Max                2.5334337
Policy mu Min                -2.3853471
Policy log std Mean          -0.23138297
Policy log std Std           0.14488311
Policy log std Max           -0.07050805
Policy log std Min           -0.78993225
Z mean eval                  0.049146555
Z variance eval              0.07932913
total_rewards                [2185.08174734  897.12107953  484.78519039  712.66863655 2218.72509013
  942.5495248   684.55881833  459.56132836  691.45365988 1333.28775343]
total_rewards_mean           1060.979282874972
total_rewards_std            617.4361321731899
total_rewards_max            2218.7250901295856
total_rewards_min            459.56132835880095
Number of train steps total  126000
Number of env steps total    632000
Number of rollouts total     0
Train Time (s)               29.973064777906984
(Previous) Eval Time (s)     5.024006125982851
Sample Time (s)              18.450793168041855
Epoch Time (s)               53.44786407193169
Total Train Time (s)         6131.65892726602
Epoch                        125
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:57:53.493254 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #125 | Epoch Duration: 55.011253356933594
2020-01-10 19:57:53.493466 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #125 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.049161755
Z variance train             0.07932834
KL Divergence                4.0966716
KL Loss                      0.40966716
QF Loss                      781.0619
VF Loss                      276.34543
Policy Loss                  -681.0696
Q Predictions Mean           671.88336
Q Predictions Std            725.9967
Q Predictions Max            1863.3363
Q Predictions Min            16.831661
V Predictions Mean           675.18756
V Predictions Std            719.8128
V Predictions Max            1858.3813
V Predictions Min            27.281776
Log Pis Mean                 -6.0851
Log Pis Std                  6.1479645
Log Pis Max                  11.468126
Log Pis Min                  -14.560292
Policy mu Mean               0.18784212
Policy mu Std                0.6597629
Policy mu Max                2.5573034
Policy mu Min                -2.6824913
Policy log std Mean          -0.24354121
Policy log std Std           0.14900047
Policy log std Max           -0.041615985
Policy log std Min           -0.8198621
Z mean eval                  0.044696607
Z variance eval              0.08100006
total_rewards                [1005.31213317 1280.37009691  684.94203512  973.44302158  676.80408482
 1835.18639348 1030.09033075  920.46552134  639.41426025  603.53012198]
total_rewards_mean           964.9557999394121
total_rewards_std            355.35263575755044
total_rewards_max            1835.1863934822543
total_rewards_min            603.5301219757863
Number of train steps total  127000
Number of env steps total    637000
Number of rollouts total     0
Train Time (s)               29.440406229812652
(Previous) Eval Time (s)     6.5870716399513185
Sample Time (s)              17.763929625041783
Epoch Time (s)               53.79140749480575
Total Train Time (s)         6184.5872665103525
Epoch                        126
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:58:46.422916 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #126 | Epoch Duration: 52.929285764694214
2020-01-10 19:58:46.423138 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #126 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.044678926
Z variance train             0.08100779
KL Divergence                4.0576525
KL Loss                      0.40576527
QF Loss                      829.60925
VF Loss                      330.21375
Policy Loss                  -708.1453
Q Predictions Mean           700.7417
Q Predictions Std            715.8694
Q Predictions Max            1862.6879
Q Predictions Min            15.511472
V Predictions Mean           705.568
V Predictions Std            709.41534
V Predictions Max            1875.3229
V Predictions Min            24.185585
Log Pis Mean                 -5.851516
Log Pis Std                  6.301472
Log Pis Max                  13.553543
Log Pis Min                  -13.528417
Policy mu Mean               0.24029331
Policy mu Std                0.6570752
Policy mu Max                2.5175116
Policy mu Min                -2.2319016
Policy log std Mean          -0.25172126
Policy log std Std           0.15210219
Policy log std Max           -0.059667885
Policy log std Min           -0.8403343
Z mean eval                  0.045956872
Z variance eval              0.07968919
total_rewards                [2151.84750293 1248.58359295  656.45302232 1828.01142629  774.93490096
  578.29780336  830.26902381  734.00186464  912.95804333 1700.77764047]
total_rewards_mean           1141.6134821060239
total_rewards_std            530.8810031297357
total_rewards_max            2151.8475029326482
total_rewards_min            578.2978033575711
Number of train steps total  128000
Number of env steps total    642000
Number of rollouts total     0
Train Time (s)               29.632669256068766
(Previous) Eval Time (s)     5.724651925265789
Sample Time (s)              18.34745584987104
Epoch Time (s)               53.704777031205595
Total Train Time (s)         6239.281945460476
Epoch                        127
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:59:41.119020 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #127 | Epoch Duration: 54.69571876525879
2020-01-10 19:59:41.119214 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #127 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046027638
Z variance train             0.07969178
KL Divergence                4.1141233
KL Loss                      0.41141233
QF Loss                      1242.9583
VF Loss                      467.7934
Policy Loss                  -719.2179
Q Predictions Mean           709.06116
Q Predictions Std            741.43726
Q Predictions Max            1868.4491
Q Predictions Min            17.775805
V Predictions Mean           723.0152
V Predictions Std            743.0699
V Predictions Max            1872.5936
V Predictions Min            28.368683
Log Pis Mean                 -5.656287
Log Pis Std                  6.9612527
Log Pis Max                  20.424452
Log Pis Min                  -14.187653
Policy mu Mean               0.2797548
Policy mu Std                0.6735869
Policy mu Max                2.7717116
Policy mu Min                -2.8481975
Policy log std Mean          -0.2563727
Policy log std Std           0.1543456
Policy log std Max           -0.05356726
Policy log std Min           -0.8111422
Z mean eval                  0.045661904
Z variance eval              0.07796587
total_rewards                [1195.08772699 1214.74586999  962.78892345 1018.22306441 1299.4177501
 1511.89723797  620.16582475  937.93874054 1451.04196489 3432.10790741]
total_rewards_mean           1364.3415010501021
total_rewards_std            733.2699066258731
total_rewards_max            3432.1079074114236
total_rewards_min            620.1658247546135
Number of train steps total  129000
Number of env steps total    647000
Number of rollouts total     0
Train Time (s)               29.377211935818195
(Previous) Eval Time (s)     6.715292289387435
Sample Time (s)              17.461507672443986
Epoch Time (s)               53.554011897649616
Total Train Time (s)         6294.596420743503
Epoch                        128
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:00:36.435860 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #128 | Epoch Duration: 55.31643199920654
2020-01-10 20:00:36.436093 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #128 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04593741
Z variance train             0.07797885
KL Divergence                4.14795
KL Loss                      0.414795
QF Loss                      928.7538
VF Loss                      424.79208
Policy Loss                  -640.3641
Q Predictions Mean           629.09314
Q Predictions Std            721.81696
Q Predictions Max            1886.5105
Q Predictions Min            16.806293
V Predictions Mean           633.5265
V Predictions Std            714.859
V Predictions Max            1873.795
V Predictions Min            26.591534
Log Pis Mean                 -6.2328997
Log Pis Std                  6.5378785
Log Pis Max                  14.9376955
Log Pis Min                  -15.682207
Policy mu Mean               0.21507594
Policy mu Std                0.63429457
Policy mu Max                2.366396
Policy mu Min                -2.417121
Policy log std Mean          -0.24387096
Policy log std Std           0.1518742
Policy log std Max           -0.04279244
Policy log std Min           -0.7774774
Z mean eval                  0.044474162
Z variance eval              0.07618626
total_rewards                [ 560.32563295 1864.85262945  917.08279558 1044.77408607 1188.60915842
  966.86337141  807.05228229 2780.23320842  772.46677236 1158.44056399]
total_rewards_mean           1206.0700500943851
total_rewards_std            620.1225908425018
total_rewards_max            2780.2332084199493
total_rewards_min            560.3256329535683
Number of train steps total  130000
Number of env steps total    652000
Number of rollouts total     0
Train Time (s)               30.383901475928724
(Previous) Eval Time (s)     8.477438502013683
Sample Time (s)              19.16843366343528
Epoch Time (s)               58.02977364137769
Total Train Time (s)         6351.112454016227
Epoch                        129
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:01:32.956616 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #129 | Epoch Duration: 56.52031993865967
2020-01-10 20:01:32.956935 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #129 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.044601064
Z variance train             0.07617487
KL Divergence                4.2135324
KL Loss                      0.42135325
QF Loss                      1107.04
VF Loss                      436.0867
Policy Loss                  -753.38086
Q Predictions Mean           744.74365
Q Predictions Std            753.2691
Q Predictions Max            1882.927
Q Predictions Min            16.977545
V Predictions Mean           757.6898
V Predictions Std            754.0006
V Predictions Max            1904.4117
V Predictions Min            30.02235
Log Pis Mean                 -5.563938
Log Pis Std                  6.618018
Log Pis Max                  11.563185
Log Pis Min                  -13.777894
Policy mu Mean               0.24361286
Policy mu Std                0.66330194
Policy mu Max                2.228711
Policy mu Min                -2.4418814
Policy log std Mean          -0.25333253
Policy log std Std           0.15218033
Policy log std Max           -0.05573956
Policy log std Min           -0.8041079
Z mean eval                  0.043852977
Z variance eval              0.07571353
total_rewards                [1048.35877804 1260.05694384  555.23921306 1637.25539272  901.97752044
 1196.13370204  550.97269966  717.4797564   659.22650207 1313.55920504]
total_rewards_mean           984.0259713299495
total_rewards_std            348.6099646749031
total_rewards_max            1637.2553927152685
total_rewards_min            550.972699655105
Number of train steps total  131000
Number of env steps total    657000
Number of rollouts total     0
Train Time (s)               30.03333900682628
(Previous) Eval Time (s)     6.967649010941386
Sample Time (s)              17.712196587584913
Epoch Time (s)               54.71318460535258
Total Train Time (s)         6404.819737305399
Epoch                        130
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:02:26.665144 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #130 | Epoch Duration: 53.70795655250549
2020-01-10 20:02:26.665410 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #130 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043872677
Z variance train             0.07572128
KL Divergence                4.2151303
KL Loss                      0.42151305
QF Loss                      1549.7751
VF Loss                      686.57446
Policy Loss                  -686.5461
Q Predictions Mean           676.39966
Q Predictions Std            742.2037
Q Predictions Max            1897.8313
Q Predictions Min            16.0276
V Predictions Mean           674.0183
V Predictions Std            730.1392
V Predictions Max            1889.5409
V Predictions Min            25.823074
Log Pis Mean                 -5.7673697
Log Pis Std                  6.265822
Log Pis Max                  11.521034
Log Pis Min                  -13.109542
Policy mu Mean               0.24343294
Policy mu Std                0.644453
Policy mu Max                2.3448672
Policy mu Min                -2.8111699
Policy log std Mean          -0.24435027
Policy log std Std           0.14885397
Policy log std Max           0.054727063
Policy log std Min           -0.777859
Z mean eval                  0.044617943
Z variance eval              0.075152636
total_rewards                [1048.88576447  736.12705493  389.35189895 1513.81632492  932.17286414
  942.56344371  561.65944421  763.17575712 1051.86346676  741.60683797]
total_rewards_mean           868.122285717006
total_rewards_std            293.35716141469595
total_rewards_max            1513.816324922396
total_rewards_min            389.35189894570044
Number of train steps total  132000
Number of env steps total    662000
Number of rollouts total     0
Train Time (s)               30.221008902881294
(Previous) Eval Time (s)     5.962110390421003
Sample Time (s)              18.185721646994352
Epoch Time (s)               54.36884094029665
Total Train Time (s)         6458.5948939062655
Epoch                        131
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:03:20.441645 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #131 | Epoch Duration: 53.77604866027832
2020-01-10 20:03:20.441819 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #131 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043940138
Z variance train             0.07515599
KL Divergence                4.255366
KL Loss                      0.4255366
QF Loss                      1472.803
VF Loss                      658.4097
Policy Loss                  -738.40283
Q Predictions Mean           730.3777
Q Predictions Std            756.06323
Q Predictions Max            1904.2714
Q Predictions Min            17.205702
V Predictions Mean           737.8516
V Predictions Std            756.9128
V Predictions Max            1913.6774
V Predictions Min            26.522957
Log Pis Mean                 -5.397064
Log Pis Std                  6.873315
Log Pis Max                  17.735256
Log Pis Min                  -13.35359
Policy mu Mean               0.24024801
Policy mu Std                0.6781064
Policy mu Max                2.4605181
Policy mu Min                -2.6785414
Policy log std Mean          -0.25525278
Policy log std Std           0.1587908
Policy log std Max           -0.05510144
Policy log std Min           -0.8417462
Z mean eval                  0.041675434
Z variance eval              0.072774105
total_rewards                [1173.58254371 1971.32164276 1028.94209104 1924.98780737 2188.96334435
  898.31400366 2552.73176354 1814.0112933   901.65528069  850.12921602]
total_rewards_mean           1530.4638986429777
total_rewards_std            595.4674105977642
total_rewards_max            2552.7317635365625
total_rewards_min            850.1292160180186
Number of train steps total  133000
Number of env steps total    667000
Number of rollouts total     0
Train Time (s)               32.73431638814509
(Previous) Eval Time (s)     5.369018587749451
Sample Time (s)              17.622606061864644
Epoch Time (s)               55.725941037759185
Total Train Time (s)         6518.931753893383
Epoch                        132
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:04:20.780692 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #132 | Epoch Duration: 60.33871912956238
2020-01-10 20:04:20.780901 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #132 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.041815933
Z variance train             0.07278056
KL Divergence                4.309789
KL Loss                      0.43097892
QF Loss                      921.84283
VF Loss                      297.12183
Policy Loss                  -775.53143
Q Predictions Mean           766.75793
Q Predictions Std            763.2933
Q Predictions Max            1912.2323
Q Predictions Min            13.627495
V Predictions Mean           775.49194
V Predictions Std            760.0106
V Predictions Max            1900.5802
V Predictions Min            27.083483
Log Pis Mean                 -5.6557875
Log Pis Std                  6.3212643
Log Pis Max                  16.367327
Log Pis Min                  -12.53951
Policy mu Mean               0.24526052
Policy mu Std                0.6667184
Policy mu Max                2.260893
Policy mu Min                -2.4828336
Policy log std Mean          -0.2539477
Policy log std Std           0.15451199
Policy log std Max           -0.015771054
Policy log std Min           -0.7761258
Z mean eval                  0.041056883
Z variance eval              0.07299688
total_rewards                [1506.72075138  609.11977186  749.06829529 1675.01869361  816.88002112
 1138.15377565 1204.38848001  544.26633134 1021.16694319 1305.04777516]
total_rewards_mean           1056.9830838610037
total_rewards_std            359.34508704647715
total_rewards_max            1675.0186936131577
total_rewards_min            544.2663313373309
Number of train steps total  134000
Number of env steps total    672000
Number of rollouts total     0
Train Time (s)               33.64587543811649
(Previous) Eval Time (s)     9.981491434853524
Sample Time (s)              18.17554415203631
Epoch Time (s)               61.802911025006324
Total Train Time (s)         6577.260328265373
Epoch                        133
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:05:19.111464 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #133 | Epoch Duration: 58.3304078578949
2020-01-10 20:05:19.111638 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #133 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040911935
Z variance train             0.072975405
KL Divergence                4.2884207
KL Loss                      0.42884207
QF Loss                      859.96246
VF Loss                      272.18265
Policy Loss                  -753.6578
Q Predictions Mean           745.1042
Q Predictions Std            745.8652
Q Predictions Max            1920.2765
Q Predictions Min            15.645634
V Predictions Mean           759.50574
V Predictions Std            749.3552
V Predictions Max            1931.356
V Predictions Min            26.877626
Log Pis Mean                 -5.278556
Log Pis Std                  6.5982633
Log Pis Max                  17.639107
Log Pis Min                  -14.072407
Policy mu Mean               0.2302241
Policy mu Std                0.68456614
Policy mu Max                2.941588
Policy mu Min                -2.8856387
Policy log std Mean          -0.25732484
Policy log std Std           0.15566766
Policy log std Max           -0.061148964
Policy log std Min           -0.87129426
Z mean eval                  0.03657046
Z variance eval              0.07421291
total_rewards                [ 877.16374979  976.88380466 1198.52536738  669.26810568 1073.98651014
 1924.36815629  839.78470253 1573.8660821  1277.21817702  732.83895226]
total_rewards_mean           1114.3903607852876
total_rewards_std            373.7263866455124
total_rewards_max            1924.368156294083
total_rewards_min            669.2681056846296
Number of train steps total  135000
Number of env steps total    677000
Number of rollouts total     0
Train Time (s)               30.212511277291924
(Previous) Eval Time (s)     6.508685092907399
Sample Time (s)              17.742167880292982
Epoch Time (s)               54.463364250492305
Total Train Time (s)         6631.67248412827
Epoch                        134
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:06:13.526827 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #134 | Epoch Duration: 54.41503572463989
2020-01-10 20:06:13.527048 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #134 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036437582
Z variance train             0.07422939
KL Divergence                4.2370815
KL Loss                      0.42370817
QF Loss                      899.0509
VF Loss                      358.2352
Policy Loss                  -738.3476
Q Predictions Mean           728.9749
Q Predictions Std            775.701
Q Predictions Max            1907.0527
Q Predictions Min            15.136856
V Predictions Mean           740.7986
V Predictions Std            779.8589
V Predictions Max            1922.497
V Predictions Min            25.116838
Log Pis Mean                 -5.885681
Log Pis Std                  6.2798004
Log Pis Max                  12.554679
Log Pis Min                  -13.030993
Policy mu Mean               0.2375019
Policy mu Std                0.65168315
Policy mu Max                2.586802
Policy mu Min                -2.3690398
Policy log std Mean          -0.25257474
Policy log std Std           0.15524942
Policy log std Max           0.04827845
Policy log std Min           -0.8493413
Z mean eval                  0.035033725
Z variance eval              0.07340371
total_rewards                [ 614.86391908 1938.29404682 1348.11487652 1017.94414355 1433.87392843
 2174.92217068 1626.54242119  791.63084513 1788.24736423  552.1367946 ]
total_rewards_mean           1328.6570510223953
total_rewards_std            538.2057290613726
total_rewards_max            2174.9221706832764
total_rewards_min            552.1367945998089
Number of train steps total  136000
Number of env steps total    682000
Number of rollouts total     0
Train Time (s)               29.539088860619813
(Previous) Eval Time (s)     6.460038790944964
Sample Time (s)              18.860195657704026
Epoch Time (s)               54.8593233092688
Total Train Time (s)         6688.602691291366
Epoch                        135
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:07:10.459813 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #135 | Epoch Duration: 56.932559967041016
2020-01-10 20:07:10.460089 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #135 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03505411
Z variance train             0.07339892
KL Divergence                4.2598505
KL Loss                      0.42598507
QF Loss                      1226.4939
VF Loss                      226.895
Policy Loss                  -731.96155
Q Predictions Mean           724.8501
Q Predictions Std            767.19336
Q Predictions Max            1909.0591
Q Predictions Min            15.068309
V Predictions Mean           733.6454
V Predictions Std            766.2472
V Predictions Max            1927.2109
V Predictions Min            25.09951
Log Pis Mean                 -5.280695
Log Pis Std                  6.923543
Log Pis Max                  17.579947
Log Pis Min                  -13.272882
Policy mu Mean               0.25085992
Policy mu Std                0.67426395
Policy mu Max                2.9008474
Policy mu Min                -2.4968364
Policy log std Mean          -0.25639623
Policy log std Std           0.157399
Policy log std Max           -0.05160433
Policy log std Min           -0.7925242
Z mean eval                  0.03534832
Z variance eval              0.07343028
total_rewards                [ 614.26404976 2471.88750339  984.03942439  761.41943321  353.22397979
 1125.16647681  793.76208454 1242.64041791  895.13511629 1861.2738762 ]
total_rewards_mean           1110.28123622875
total_rewards_std            594.8936554703034
total_rewards_max            2471.887503386658
total_rewards_min            353.2239797913219
Number of train steps total  137000
Number of env steps total    687000
Number of rollouts total     0
Train Time (s)               30.75570689002052
(Previous) Eval Time (s)     8.532925253733993
Sample Time (s)              19.435499149374664
Epoch Time (s)               58.724131293129176
Total Train Time (s)         6745.300059909467
Epoch                        136
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:08:07.157699 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #136 | Epoch Duration: 56.69742155075073
2020-01-10 20:08:07.157922 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #136 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03535579
Z variance train             0.07344908
KL Divergence                4.2736197
KL Loss                      0.42736197
QF Loss                      1014.94653
VF Loss                      488.7382
Policy Loss                  -644.9063
Q Predictions Mean           639.6162
Q Predictions Std            753.87555
Q Predictions Max            1953.0278
Q Predictions Min            15.393262
V Predictions Mean           640.9621
V Predictions Std            743.9656
V Predictions Max            1934.9971
V Predictions Min            23.335766
Log Pis Mean                 -6.8874655
Log Pis Std                  6.014697
Log Pis Max                  13.211145
Log Pis Min                  -13.553668
Policy mu Mean               0.19692548
Policy mu Std                0.61014336
Policy mu Max                2.401468
Policy mu Min                -2.5410023
Policy log std Mean          -0.23355472
Policy log std Std           0.14755197
Policy log std Max           -0.043489233
Policy log std Min           -0.86337805
Z mean eval                  0.037066758
Z variance eval              0.07176197
total_rewards                [1063.64550133  462.86049834  577.26554033  793.92684844 1224.11990254
 1252.64354133 1402.92320846  913.42550284  587.92577004 1912.93766609]
total_rewards_mean           1019.1673979753457
total_rewards_std            423.93718498732704
total_rewards_max            1912.9376660917726
total_rewards_min            462.86049834025613
Number of train steps total  138000
Number of env steps total    692000
Number of rollouts total     0
Train Time (s)               30.311199880205095
(Previous) Eval Time (s)     6.50588534027338
Sample Time (s)              18.137796123046428
Epoch Time (s)               54.9548813435249
Total Train Time (s)         6799.747405691538
Epoch                        137
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:09:01.610384 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #137 | Epoch Duration: 54.45228862762451
2020-01-10 20:09:01.610683 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #137 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037182137
Z variance train             0.07177043
KL Divergence                4.318894
KL Loss                      0.43188938
QF Loss                      1185.6172
VF Loss                      635.4535
Policy Loss                  -766.9065
Q Predictions Mean           759.48157
Q Predictions Std            775.62714
Q Predictions Max            1937.1073
Q Predictions Min            14.731312
V Predictions Mean           771.95544
V Predictions Std            776.5127
V Predictions Max            1944.1234
V Predictions Min            28.002821
Log Pis Mean                 -4.912983
Log Pis Std                  7.170162
Log Pis Max                  18.334072
Log Pis Min                  -13.673217
Policy mu Mean               0.27096394
Policy mu Std                0.67950654
Policy mu Max                2.3330953
Policy mu Min                -2.9184299
Policy log std Mean          -0.25684243
Policy log std Std           0.15794349
Policy log std Max           -0.07046274
Policy log std Min           -0.87274677
Z mean eval                  0.03500054
Z variance eval              0.071565434
total_rewards                [4097.71453484 3103.58323845 1898.44256136 1563.18880084 1764.34719071
  958.65312722 1386.85036956 1315.81072009 2340.61194251 1503.1851327 ]
total_rewards_mean           1993.2387618286211
total_rewards_std            903.6485783372232
total_rewards_max            4097.714534842996
total_rewards_min            958.6531272231449
Number of train steps total  139000
Number of env steps total    697000
Number of rollouts total     0
Train Time (s)               30.828430864959955
(Previous) Eval Time (s)     6.002920250874013
Sample Time (s)              18.12247800268233
Epoch Time (s)               54.953829118516296
Total Train Time (s)         6861.6744098560885
Epoch                        138
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:10:03.541601 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #138 | Epoch Duration: 61.93067789077759
2020-01-10 20:10:03.541903 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #138 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03525027
Z variance train             0.071559325
KL Divergence                4.337258
KL Loss                      0.4337258
QF Loss                      1433.7631
VF Loss                      367.87332
Policy Loss                  -795.04736
Q Predictions Mean           785.2471
Q Predictions Std            777.566
Q Predictions Max            1955.8634
Q Predictions Min            15.769971
V Predictions Mean           788.43164
V Predictions Std            769.6059
V Predictions Max            1939.3916
V Predictions Min            29.158863
Log Pis Mean                 -4.583227
Log Pis Std                  7.3918796
Log Pis Max                  17.88439
Log Pis Min                  -13.475793
Policy mu Mean               0.2340347
Policy mu Std                0.711954
Policy mu Max                2.5614781
Policy mu Min                -3.0574396
Policy log std Mean          -0.26110917
Policy log std Std           0.1596487
Policy log std Max           -0.038501896
Policy log std Min           -0.7739307
Z mean eval                  0.036866613
Z variance eval              0.071829565
total_rewards                [ 819.1660392   564.34994951  352.06206032  658.69685315 1786.6821357
  770.48272257 1449.54386826  863.93734473 1637.97129781 1116.01203016]
total_rewards_mean           1001.8904301406612
total_rewards_std            455.1245356197058
total_rewards_max            1786.6821356986127
total_rewards_min            352.0620603152686
Number of train steps total  140000
Number of env steps total    702000
Number of rollouts total     0
Train Time (s)               31.23234604485333
(Previous) Eval Time (s)     12.979470582213253
Sample Time (s)              19.450811546761543
Epoch Time (s)               63.662628173828125
Total Train Time (s)         6918.501568629406
Epoch                        139
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:11:00.371178 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #139 | Epoch Duration: 56.8290319442749
2020-01-10 20:11:00.371470 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #139 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036986392
Z variance train             0.07183764
KL Divergence                4.32147
KL Loss                      0.432147
QF Loss                      1180.2651
VF Loss                      289.20935
Policy Loss                  -775.8509
Q Predictions Mean           769.8834
Q Predictions Std            816.14886
Q Predictions Max            1970.0103
Q Predictions Min            13.338215
V Predictions Mean           773.911
V Predictions Std            808.07184
V Predictions Max            1958.2383
V Predictions Min            27.372902
Log Pis Mean                 -5.4092956
Log Pis Std                  6.8532753
Log Pis Max                  13.748753
Log Pis Min                  -13.023031
Policy mu Mean               0.2555179
Policy mu Std                0.6502926
Policy mu Max                2.2524922
Policy mu Min                -2.4258118
Policy log std Mean          -0.25352836
Policy log std Std           0.15620735
Policy log std Max           -0.02201476
Policy log std Min           -0.83088326
Z mean eval                  0.037635107
Z variance eval              0.071903676
total_rewards                [ 934.34357494 1035.54400685  567.59674354  818.13203947  848.83676916
  678.27638888  877.77520507 1660.23909079  830.6744777  1420.92478934]
total_rewards_mean           967.2343085738712
total_rewards_std            315.90291880351964
total_rewards_max            1660.2390907896392
total_rewards_min            567.5967435400834
Number of train steps total  141000
Number of env steps total    707000
Number of rollouts total     0
Train Time (s)               26.828109943773597
(Previous) Eval Time (s)     6.145559025928378
Sample Time (s)              17.929350710473955
Epoch Time (s)               50.90301968017593
Total Train Time (s)         6968.924419444054
Epoch                        140
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:11:50.794958 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #140 | Epoch Duration: 50.42327165603638
2020-01-10 20:11:50.795167 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #140 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037586026
Z variance train             0.07187331
KL Divergence                4.3253417
KL Loss                      0.4325342
QF Loss                      1487.4976
VF Loss                      612.0613
Policy Loss                  -756.2658
Q Predictions Mean           750.8413
Q Predictions Std            789.8876
Q Predictions Max            1961.7247
Q Predictions Min            16.502617
V Predictions Mean           767.5434
V Predictions Std            794.47046
V Predictions Max            1988.4253
V Predictions Min            27.075663
Log Pis Mean                 -5.150487
Log Pis Std                  7.267796
Log Pis Max                  22.108175
Log Pis Min                  -13.555801
Policy mu Mean               0.23558412
Policy mu Std                0.6898171
Policy mu Max                3.0470395
Policy mu Min                -2.6154177
Policy log std Mean          -0.2513099
Policy log std Std           0.15719855
Policy log std Max           0.044935048
Policy log std Min           -0.9062541
Z mean eval                  0.037125587
Z variance eval              0.07229094
total_rewards                [3119.31271232  880.05698855 1619.53847306 3760.6396684   959.10634015
 2234.2564959  1305.72400863 1472.45224762 1362.91827325 2755.18850359]
total_rewards_mean           1946.9193711472685
total_rewards_std            927.2758534245111
total_rewards_max            3760.63966840195
total_rewards_min            880.0569885463528
Number of train steps total  142000
Number of env steps total    712000
Number of rollouts total     0
Train Time (s)               31.494269351940602
(Previous) Eval Time (s)     5.6655437969602644
Sample Time (s)              18.304231321439147
Epoch Time (s)               55.46404447034001
Total Train Time (s)         7030.989505250938
Epoch                        141
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:12:52.864006 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #141 | Epoch Duration: 62.06864070892334
2020-01-10 20:12:52.864321 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #141 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0372346
Z variance train             0.07229964
KL Divergence                4.298156
KL Loss                      0.4298156
QF Loss                      984.8795
VF Loss                      344.01605
Policy Loss                  -827.76373
Q Predictions Mean           822.86475
Q Predictions Std            778.4942
Q Predictions Max            1975.7097
Q Predictions Min            14.337363
V Predictions Mean           830.2554
V Predictions Std            777.99915
V Predictions Max            1988.6573
V Predictions Min            26.919924
Log Pis Mean                 -4.4750896
Log Pis Std                  7.1601806
Log Pis Max                  17.553436
Log Pis Min                  -14.163613
Policy mu Mean               0.25784585
Policy mu Std                0.71842337
Policy mu Max                2.5513752
Policy mu Min                -2.3965726
Policy log std Mean          -0.26328927
Policy log std Std           0.16184688
Policy log std Max           -0.018583313
Policy log std Min           -0.96042204
Z mean eval                  0.03535944
Z variance eval              0.069655985
total_rewards                [1075.11981554 1068.83797613 1240.8881456  1524.53339534 1192.97586824
 1334.09706216 2140.92891484 1948.51943352  878.17746947 1179.40909073]
total_rewards_mean           1358.348717155618
total_rewards_std            381.66776025794013
total_rewards_max            2140.9289148351386
total_rewards_min            878.1774694679094
Number of train steps total  143000
Number of env steps total    717000
Number of rollouts total     0
Train Time (s)               29.3945464217104
(Previous) Eval Time (s)     12.269825408235192
Sample Time (s)              18.98232551664114
Epoch Time (s)               60.646697346586734
Total Train Time (s)         7087.658136010636
Epoch                        142
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:13:49.534713 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #142 | Epoch Duration: 56.67015528678894
2020-01-10 20:13:49.534957 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #142 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035341054
Z variance train             0.06966807
KL Divergence                4.38151
KL Loss                      0.43815097
QF Loss                      1378.2844
VF Loss                      661.07324
Policy Loss                  -798.79126
Q Predictions Mean           794.0543
Q Predictions Std            795.63416
Q Predictions Max            1981.9811
Q Predictions Min            18.174301
V Predictions Mean           812.85443
V Predictions Std            799.897
V Predictions Max            1999.5878
V Predictions Min            27.566748
Log Pis Mean                 -5.5725365
Log Pis Std                  6.41273
Log Pis Max                  14.603925
Log Pis Min                  -13.682769
Policy mu Mean               0.24176957
Policy mu Std                0.6630635
Policy mu Max                2.1985626
Policy mu Min                -3.1935678
Policy log std Mean          -0.25041732
Policy log std Std           0.14988524
Policy log std Max           -0.028225183
Policy log std Min           -0.8205875
Z mean eval                  0.035407383
Z variance eval              0.06975417
total_rewards                [2316.52640679  723.98851486  924.02301128 1865.47781185 1099.26401299
 1343.54694548 1488.88259708 1270.30552221 1021.12935482 1154.17453306]
total_rewards_mean           1320.7318710417471
total_rewards_std            447.1827912253824
total_rewards_max            2316.526406792023
total_rewards_min            723.9885148620585
Number of train steps total  144000
Number of env steps total    722000
Number of rollouts total     0
Train Time (s)               28.341759735252708
(Previous) Eval Time (s)     8.29297487763688
Sample Time (s)              19.646510053426027
Epoch Time (s)               56.281244666315615
Total Train Time (s)         7143.43027746398
Epoch                        143
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:14:45.308228 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #143 | Epoch Duration: 55.77310585975647
2020-01-10 20:14:45.308437 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #143 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035246365
Z variance train             0.0697792
KL Divergence                4.382925
KL Loss                      0.4382925
QF Loss                      1403.0671
VF Loss                      548.7315
Policy Loss                  -812.5742
Q Predictions Mean           805.75256
Q Predictions Std            822.0556
Q Predictions Max            2000.9332
Q Predictions Min            15.44367
V Predictions Mean           807.6245
V Predictions Std            813.47577
V Predictions Max            1986.9327
V Predictions Min            28.38718
Log Pis Mean                 -5.4511757
Log Pis Std                  6.9931087
Log Pis Max                  21.434662
Log Pis Min                  -13.962599
Policy mu Mean               0.23075402
Policy mu Std                0.68092763
Policy mu Max                2.8520133
Policy mu Min                -2.5373032
Policy log std Mean          -0.25447133
Policy log std Std           0.16107538
Policy log std Max           -0.05045423
Policy log std Min           -0.88703644
Z mean eval                  0.035838768
Z variance eval              0.06834377
total_rewards                [ 543.62122199 1012.3114512  1078.03172999 1453.01889371  795.93849475
 1825.27168304 2863.19465435 1239.9443326  2125.92587455 2311.65593504]
total_rewards_mean           1524.8914271206966
total_rewards_std            700.3263914440464
total_rewards_max            2863.194654346681
total_rewards_min            543.6212219854027
Number of train steps total  145000
Number of env steps total    727000
Number of rollouts total     0
Train Time (s)               28.391421175096184
(Previous) Eval Time (s)     7.784510727971792
Sample Time (s)              18.212134221568704
Epoch Time (s)               54.38806612463668
Total Train Time (s)         7199.438404024113
Epoch                        144
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:15:41.321253 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #144 | Epoch Duration: 56.01265263557434
2020-01-10 20:15:41.321585 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #144 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03582567
Z variance train             0.06833446
KL Divergence                4.409648
KL Loss                      0.4409648
QF Loss                      1033.4534
VF Loss                      255.12987
Policy Loss                  -877.9879
Q Predictions Mean           875.0631
Q Predictions Std            824.4936
Q Predictions Max            2014.2999
Q Predictions Min            16.61599
V Predictions Mean           880.09705
V Predictions Std            818.82367
V Predictions Max            1987.0043
V Predictions Min            27.740253
Log Pis Mean                 -4.564384
Log Pis Std                  7.000337
Log Pis Max                  14.947648
Log Pis Min                  -15.019312
Policy mu Mean               0.26572832
Policy mu Std                0.7134633
Policy mu Max                2.7664413
Policy mu Min                -2.6926131
Policy log std Mean          -0.27575603
Policy log std Std           0.16608831
Policy log std Max           -0.054202437
Policy log std Min           -0.9277035
Z mean eval                  0.03562316
Z variance eval              0.07018842
total_rewards                [2355.45111387 1262.56046236 1121.88902898 1753.94399461 1196.66716852
 1390.41252911 2599.17621804 1486.31827953 2151.91969169  817.21371026]
total_rewards_mean           1613.555219696079
total_rewards_std            554.1005226442126
total_rewards_max            2599.1762180388782
total_rewards_min            817.213710257403
Number of train steps total  146000
Number of env steps total    732000
Number of rollouts total     0
Train Time (s)               29.548777902964503
(Previous) Eval Time (s)     9.408747131936252
Sample Time (s)              19.10384306125343
Epoch Time (s)               58.06136809615418
Total Train Time (s)         7257.938697618432
Epoch                        145
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:16:39.822670 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #145 | Epoch Duration: 58.500864028930664
2020-01-10 20:16:39.822880 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #145 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035676226
Z variance train             0.07019062
KL Divergence                4.351918
KL Loss                      0.43519184
QF Loss                      1578.9229
VF Loss                      463.5412
Policy Loss                  -876.24243
Q Predictions Mean           867.6122
Q Predictions Std            827.21606
Q Predictions Max            2023.713
Q Predictions Min            19.591429
V Predictions Mean           869.3475
V Predictions Std            819.5595
V Predictions Max            2008.2524
V Predictions Min            28.67249
Log Pis Mean                 -4.2266374
Log Pis Std                  7.6345015
Log Pis Max                  17.908747
Log Pis Min                  -12.742495
Policy mu Mean               0.25466034
Policy mu Std                0.7568976
Policy mu Max                2.5794156
Policy mu Min                -2.754119
Policy log std Mean          -0.2737757
Policy log std Std           0.16607483
Policy log std Max           -0.03408184
Policy log std Min           -0.8827286
Z mean eval                  0.033684023
Z variance eval              0.068966284
total_rewards                [ 717.20881781  646.12384533 1809.43027986 1024.62008818  817.99706033
 1292.93801548 1077.57929192 1716.98726705 1859.1091421  1425.0667014 ]
total_rewards_mean           1238.7060509467192
total_rewards_std            429.994672289111
total_rewards_max            1859.1091421041265
total_rewards_min            646.1238453272942
Number of train steps total  147000
Number of env steps total    737000
Number of rollouts total     0
Train Time (s)               31.181528009008616
(Previous) Eval Time (s)     9.84790949523449
Sample Time (s)              19.29134810436517
Epoch Time (s)               60.320785608608276
Total Train Time (s)         7316.298360310961
Epoch                        146
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:17:38.184781 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #146 | Epoch Duration: 58.36173748970032
2020-01-10 20:17:38.185004 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #146 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033915095
Z variance train             0.06897712
KL Divergence                4.392834
KL Loss                      0.43928343
QF Loss                      1435.9707
VF Loss                      598.35315
Policy Loss                  -826.0524
Q Predictions Mean           819.7947
Q Predictions Std            803.2006
Q Predictions Max            1995.8275
Q Predictions Min            13.441498
V Predictions Mean           835.2376
V Predictions Std            802.8196
V Predictions Max            2005.0764
V Predictions Min            24.58782
Log Pis Mean                 -5.044426
Log Pis Std                  6.948749
Log Pis Max                  18.999046
Log Pis Min                  -13.390934
Policy mu Mean               0.23388153
Policy mu Std                0.70335907
Policy mu Max                2.6119275
Policy mu Min                -2.625391
Policy log std Mean          -0.26250705
Policy log std Std           0.15929823
Policy log std Max           -0.045541406
Policy log std Min           -0.8737272
Z mean eval                  0.03514383
Z variance eval              0.06907757
total_rewards                [1325.15369199 1472.61853914 1047.8299999  1209.82883594 2087.12273367
 1378.76481604  565.94681176  888.57379488  826.70089321 1041.70288607]
total_rewards_mean           1184.4243002604621
total_rewards_std            399.14585497383024
total_rewards_max            2087.1227336679394
total_rewards_min            565.9468117593992
Number of train steps total  148000
Number of env steps total    742000
Number of rollouts total     0
Train Time (s)               29.307928061578423
(Previous) Eval Time (s)     7.888507903087884
Sample Time (s)              18.369105544872582
Epoch Time (s)               55.56554150953889
Total Train Time (s)         7371.36531662615
Epoch                        147
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:18:33.252725 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #147 | Epoch Duration: 55.06756925582886
2020-01-10 20:18:33.252879 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #147 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034877785
Z variance train             0.06904412
KL Divergence                4.4153624
KL Loss                      0.44153625
QF Loss                      1164.6886
VF Loss                      492.4836
Policy Loss                  -844.1597
Q Predictions Mean           841.4729
Q Predictions Std            821.8715
Q Predictions Max            2024.3708
Q Predictions Min            15.104547
V Predictions Mean           842.5908
V Predictions Std            815.3235
V Predictions Max            2024.5824
V Predictions Min            26.022173
Log Pis Mean                 -5.2351937
Log Pis Std                  6.7328463
Log Pis Max                  16.894989
Log Pis Min                  -15.525944
Policy mu Mean               0.2554662
Policy mu Std                0.7041849
Policy mu Max                2.6629145
Policy mu Min                -2.8187973
Policy log std Mean          -0.26826978
Policy log std Std           0.16694753
Policy log std Max           -0.04818462
Policy log std Min           -0.89279896
Z mean eval                  0.03523856
Z variance eval              0.06695466
total_rewards                [ 452.1543781  1378.35157657 1009.97629174 1141.96593498  553.59400552
  841.56712012  936.68196227  736.40580319  856.64605709 1395.47858099]
total_rewards_mean           930.2821710563094
total_rewards_std            298.2879250142251
total_rewards_max            1395.478580988085
total_rewards_min            452.154378097979
Number of train steps total  149000
Number of env steps total    747000
Number of rollouts total     0
Train Time (s)               32.079945819918066
(Previous) Eval Time (s)     7.390214202925563
Sample Time (s)              18.086767819710076
Epoch Time (s)               57.556927842553705
Total Train Time (s)         7427.015191642102
Epoch                        148
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:19:28.906292 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #148 | Epoch Duration: 55.65326714515686
2020-01-10 20:19:28.906530 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #148 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035261802
Z variance train             0.06690757
KL Divergence                4.4697495
KL Loss                      0.44697496
QF Loss                      1629.6992
VF Loss                      498.51752
Policy Loss                  -907.8249
Q Predictions Mean           902.25323
Q Predictions Std            839.97076
Q Predictions Max            2032.3345
Q Predictions Min            15.448609
V Predictions Mean           912.5557
V Predictions Std            839.6241
V Predictions Max            2027.037
V Predictions Min            25.796658
Log Pis Mean                 -4.8411684
Log Pis Std                  7.0334625
Log Pis Max                  18.586353
Log Pis Min                  -13.904748
Policy mu Mean               0.23715883
Policy mu Std                0.7238822
Policy mu Max                2.4606905
Policy mu Min                -2.8045201
Policy log std Mean          -0.2772559
Policy log std Std           0.16969961
Policy log std Max           0.0034442842
Policy log std Min           -0.8055001
Z mean eval                  0.034282364
Z variance eval              0.064399734
total_rewards                [4978.75377472 1074.76736494 1969.98114102 1858.69409974 1277.56069868
 1765.33839607  539.37844119 1739.01238953 4004.87206773 1517.66091247]
total_rewards_mean           2072.6019286088067
total_rewards_std            1293.3624803188313
total_rewards_max            4978.7537747166725
total_rewards_min            539.378441193064
Number of train steps total  150000
Number of env steps total    752000
Number of rollouts total     0
Train Time (s)               31.0397896762006
(Previous) Eval Time (s)     5.48622857267037
Sample Time (s)              18.99842408299446
Epoch Time (s)               55.52444233186543
Total Train Time (s)         7489.686620832887
Epoch                        149
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:20:31.577945 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #149 | Epoch Duration: 62.67123532295227
2020-01-10 20:20:31.578098 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #149 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034352377
Z variance train             0.06440076
KL Divergence                4.554348
KL Loss                      0.4554348
QF Loss                      1037.2352
VF Loss                      870.02277
Policy Loss                  -748.92804
Q Predictions Mean           739.88446
Q Predictions Std            822.0834
Q Predictions Max            2032.0496
Q Predictions Min            16.1029
V Predictions Mean           750.2782
V Predictions Std            821.32745
V Predictions Max            2029.0028
V Predictions Min            27.412493
Log Pis Mean                 -5.8932877
Log Pis Std                  6.561278
Log Pis Max                  18.275093
Log Pis Min                  -13.190204
Policy mu Mean               0.2446831
Policy mu Std                0.6573297
Policy mu Max                2.6405923
Policy mu Min                -3.4344876
Policy log std Mean          -0.24669425
Policy log std Std           0.15332256
Policy log std Max           -0.029676951
Policy log std Min           -0.8431938
Z mean eval                  0.035393275
Z variance eval              0.06521252
total_rewards                [1773.55262902 1266.42896639 1179.67702436  981.89641909  688.49356504
 2171.9600547  2934.8485518   929.11842821 2020.10340682 2779.96494745]
total_rewards_mean           1672.6043992867212
total_rewards_std            748.7381903243947
total_rewards_max            2934.8485517955255
total_rewards_min            688.4935650353225
Number of train steps total  151000
Number of env steps total    757000
Number of rollouts total     0
Train Time (s)               30.53308603586629
(Previous) Eval Time (s)     12.632692839950323
Sample Time (s)              18.146012344863266
Epoch Time (s)               61.31179122067988
Total Train Time (s)         7548.66249633953
Epoch                        150
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:21:30.557144 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #150 | Epoch Duration: 58.9789023399353
2020-01-10 20:21:30.557338 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #150 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035432957
Z variance train             0.065177515
KL Divergence                4.526952
KL Loss                      0.4526952
QF Loss                      2116.8413
VF Loss                      867.7871
Policy Loss                  -738.1142
Q Predictions Mean           729.681
Q Predictions Std            784.77277
Q Predictions Max            2055.1396
Q Predictions Min            15.119546
V Predictions Mean           745.4968
V Predictions Std            788.039
V Predictions Max            2030.9524
V Predictions Min            24.891735
Log Pis Mean                 -5.150299
Log Pis Std                  7.3356857
Log Pis Max                  23.75356
Log Pis Min                  -12.945562
Policy mu Mean               0.1946327
Policy mu Std                0.7114063
Policy mu Max                2.8001156
Policy mu Min                -2.782471
Policy log std Mean          -0.26387027
Policy log std Std           0.16427751
Policy log std Max           -0.012212679
Policy log std Min           -0.9552017
Z mean eval                  0.035054415
Z variance eval              0.0642457
total_rewards                [1370.51397675 2218.08768112 1302.47862134 1504.27757895 2073.12673528
 2313.43178549 3654.25099097 1743.85931113 1551.69283845  914.43200351]
total_rewards_mean           1864.6151522981158
total_rewards_std            726.4970540855328
total_rewards_max            3654.250990967439
total_rewards_min            914.4320035091681
Number of train steps total  152000
Number of env steps total    762000
Number of rollouts total     0
Train Time (s)               27.715290745720267
(Previous) Eval Time (s)     10.299474556930363
Sample Time (s)              18.673646301496774
Epoch Time (s)               56.688411604147404
Total Train Time (s)         7606.057791810483
Epoch                        151
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:22:27.953891 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #151 | Epoch Duration: 57.39640951156616
2020-01-10 20:22:27.954092 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #151 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034978148
Z variance train             0.06425418
KL Divergence                4.5663404
KL Loss                      0.45663404
QF Loss                      1208.8905
VF Loss                      664.8878
Policy Loss                  -943.54034
Q Predictions Mean           931.9538
Q Predictions Std            847.3447
Q Predictions Max            2061.059
Q Predictions Min            16.392529
V Predictions Mean           933.0667
V Predictions Std            837.89905
V Predictions Max            2046.9941
V Predictions Min            24.423931
Log Pis Mean                 -4.4553356
Log Pis Std                  7.1614757
Log Pis Max                  21.376266
Log Pis Min                  -16.393112
Policy mu Mean               0.2663189
Policy mu Std                0.71670467
Policy mu Max                2.5911572
Policy mu Min                -2.7052476
Policy log std Mean          -0.2794912
Policy log std Std           0.16862422
Policy log std Max           0.034848884
Policy log std Min           -0.9288389
Z mean eval                  0.031048274
Z variance eval              0.0644558
total_rewards                [2143.94333688 1181.42877024 2119.90528218 1117.28304827 1096.06668036
 1732.35797362 2481.33868236 1429.56556199 1069.62718743 1321.52577666]
total_rewards_mean           1569.3042299988279
total_rewards_std            490.0089275689303
total_rewards_max            2481.3386823550695
total_rewards_min            1069.6271874300353
Number of train steps total  153000
Number of env steps total    767000
Number of rollouts total     0
Train Time (s)               30.811701458878815
(Previous) Eval Time (s)     11.00718175014481
Sample Time (s)              19.449690759181976
Epoch Time (s)               61.2685739682056
Total Train Time (s)         7665.8783623767085
Epoch                        152
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:23:27.779069 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #152 | Epoch Duration: 59.824803590774536
2020-01-10 20:23:27.779342 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #152 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031098615
Z variance train             0.06445937
KL Divergence                4.573895
KL Loss                      0.4573895
QF Loss                      1591.2175
VF Loss                      462.15494
Policy Loss                  -897.38275
Q Predictions Mean           888.0648
Q Predictions Std            832.4733
Q Predictions Max            2043.5913
Q Predictions Min            16.145039
V Predictions Mean           893.9797
V Predictions Std            829.5032
V Predictions Max            2038.1572
V Predictions Min            25.77217
Log Pis Mean                 -4.647893
Log Pis Std                  7.0795918
Log Pis Max                  20.736933
Log Pis Min                  -14.314436
Policy mu Mean               0.24183683
Policy mu Std                0.7276579
Policy mu Max                3.0143638
Policy mu Min                -2.6976523
Policy log std Mean          -0.27253672
Policy log std Std           0.1651027
Policy log std Max           -0.028975047
Policy log std Min           -0.9369832
Z mean eval                  0.03213852
Z variance eval              0.06526528
total_rewards                [3612.34960801 1062.55849209 4064.00051809 1587.96789032 1359.80141639
 2256.01948169 1892.44719549 2453.4521825  1425.19758807 2210.51898629]
total_rewards_mean           2192.4313358953723
total_rewards_std            927.6497718618104
total_rewards_max            4064.000518093331
total_rewards_min            1062.5584920899894
Number of train steps total  154000
Number of env steps total    772000
Number of rollouts total     0
Train Time (s)               30.684279548935592
(Previous) Eval Time (s)     9.563055540900677
Sample Time (s)              18.977285417728126
Epoch Time (s)               59.224620507564396
Total Train Time (s)         7729.104183244519
Epoch                        153
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:24:31.005029 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #153 | Epoch Duration: 63.22549223899841
2020-01-10 20:24:31.005198 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #153 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0323209
Z variance train             0.06524616
KL Divergence                4.5419054
KL Loss                      0.45419055
QF Loss                      947.1791
VF Loss                      410.9711
Policy Loss                  -841.50543
Q Predictions Mean           834.37836
Q Predictions Std            840.5975
Q Predictions Max            2055.3203
Q Predictions Min            17.280865
V Predictions Mean           843.1918
V Predictions Std            841.0215
V Predictions Max            2061.5134
V Predictions Min            28.22217
Log Pis Mean                 -5.065077
Log Pis Std                  7.22255
Log Pis Max                  22.369934
Log Pis Min                  -15.354989
Policy mu Mean               0.2359773
Policy mu Std                0.7103107
Policy mu Max                2.702932
Policy mu Min                -3.828039
Policy log std Mean          -0.26676914
Policy log std Std           0.16006929
Policy log std Max           -0.059901096
Policy log std Min           -0.7922279
Z mean eval                  0.030849915
Z variance eval              0.06588049
total_rewards                [ 973.72610191  982.48847559 1056.23629425 4908.9068876  2424.92497326
  625.11709585 1576.04398236 1002.78690663  632.84090616 4929.85764489]
total_rewards_mean           1911.2929268501325
total_rewards_std            1583.0519347016773
total_rewards_max            4929.857644889301
total_rewards_min            625.117095849917
Number of train steps total  155000
Number of env steps total    777000
Number of rollouts total     0
Train Time (s)               29.42088347999379
(Previous) Eval Time (s)     13.563595452811569
Sample Time (s)              18.92417359771207
Epoch Time (s)               61.90865253051743
Total Train Time (s)         7788.918307143729
Epoch                        154
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:25:30.820407 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #154 | Epoch Duration: 59.815083265304565
2020-01-10 20:25:30.820591 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #154 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030708084
Z variance train             0.06589402
KL Divergence                4.5192804
KL Loss                      0.45192805
QF Loss                      1687.4844
VF Loss                      404.1734
Policy Loss                  -871.5986
Q Predictions Mean           863.50977
Q Predictions Std            837.7221
Q Predictions Max            2069.229
Q Predictions Min            14.435888
V Predictions Mean           874.9791
V Predictions Std            836.34247
V Predictions Max            2072.2744
V Predictions Min            28.346798
Log Pis Mean                 -4.4793615
Log Pis Std                  7.38007
Log Pis Max                  20.649763
Log Pis Min                  -14.636772
Policy mu Mean               0.23575856
Policy mu Std                0.72163975
Policy mu Max                2.8799314
Policy mu Min                -2.868363
Policy log std Mean          -0.26665014
Policy log std Std           0.16239372
Policy log std Max           -0.05191326
Policy log std Min           -0.843796
Z mean eval                  0.03263221
Z variance eval              0.066682376
total_rewards                [1215.12015029 1379.95963631 3241.35256738 1239.80287959 4136.36852329
 2051.33063363 1848.85429527  723.1060202   898.97617805 2227.67018082]
total_rewards_mean           1896.2541064816219
total_rewards_std            1024.4904057127433
total_rewards_max            4136.36852328736
total_rewards_min            723.1060201996432
Number of train steps total  156000
Number of env steps total    782000
Number of rollouts total     0
Train Time (s)               28.5908275982365
(Previous) Eval Time (s)     11.469718744046986
Sample Time (s)              19.094761430751532
Epoch Time (s)               59.15530777303502
Total Train Time (s)         7847.835874528624
Epoch                        155
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:26:29.742525 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #155 | Epoch Duration: 58.921788930892944
2020-01-10 20:26:29.742779 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #155 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03270852
Z variance train             0.06668749
KL Divergence                4.503337
KL Loss                      0.45033368
QF Loss                      1148.0789
VF Loss                      377.48422
Policy Loss                  -912.31274
Q Predictions Mean           908.49475
Q Predictions Std            841.28925
Q Predictions Max            2071.552
Q Predictions Min            17.723522
V Predictions Mean           912.55334
V Predictions Std            835.4189
V Predictions Max            2074.7725
V Predictions Min            28.296179
Log Pis Mean                 -3.872551
Log Pis Std                  7.3917565
Log Pis Max                  28.656021
Log Pis Min                  -12.606259
Policy mu Mean               0.2792863
Policy mu Std                0.7473039
Policy mu Max                2.9602003
Policy mu Min                -3.1781828
Policy log std Mean          -0.28288502
Policy log std Std           0.1705206
Policy log std Max           -0.027275376
Policy log std Min           -0.8304714
Z mean eval                  0.03165979
Z variance eval              0.066048786
total_rewards                [ 801.77332284 1985.74867124 1287.78382634 1038.26260498 1016.63234836
 1936.59924239 1238.07475429  687.5899989   806.75645992  505.49399227]
total_rewards_mean           1130.4715221534118
total_rewards_std            473.1493702659582
total_rewards_max            1985.7486712390719
total_rewards_min            505.49399227430956
Number of train steps total  157000
Number of env steps total    787000
Number of rollouts total     0
Train Time (s)               29.18125886283815
(Previous) Eval Time (s)     11.23582197772339
Sample Time (s)              18.399876076728106
Epoch Time (s)               58.816956917289644
Total Train Time (s)         7902.263584100641
Epoch                        156
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:27:24.172592 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #156 | Epoch Duration: 54.42960834503174
2020-01-10 20:27:24.172826 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #156 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031667646
Z variance train             0.06602927
KL Divergence                4.4912443
KL Loss                      0.44912443
QF Loss                      1180.6575
VF Loss                      392.48947
Policy Loss                  -915.5771
Q Predictions Mean           910.8113
Q Predictions Std            865.8359
Q Predictions Max            2073.3147
Q Predictions Min            15.737384
V Predictions Mean           914.47687
V Predictions Std            862.34143
V Predictions Max            2066.9404
V Predictions Min            26.861547
Log Pis Mean                 -4.465926
Log Pis Std                  7.3136706
Log Pis Max                  16.597595
Log Pis Min                  -14.759158
Policy mu Mean               0.22556995
Policy mu Std                0.73184204
Policy mu Max                2.4498847
Policy mu Min                -2.4721367
Policy log std Mean          -0.27527452
Policy log std Std           0.16718148
Policy log std Max           -0.08229819
Policy log std Min           -0.88266057
Z mean eval                  0.03126305
Z variance eval              0.06859911
total_rewards                [2910.08609064  400.88121471 1507.48668965  936.23585519 2195.1929587
 2509.54403988 1168.07563896 1406.47656313 2233.02352847  768.02427956]
total_rewards_mean           1603.5026858904482
total_rewards_std            781.1317219523895
total_rewards_max            2910.086090636151
total_rewards_min            400.88121471400194
Number of train steps total  158000
Number of env steps total    792000
Number of rollouts total     0
Train Time (s)               30.412847386673093
(Previous) Eval Time (s)     6.848197241779417
Sample Time (s)              19.21028873929754
Epoch Time (s)               56.47133336775005
Total Train Time (s)         7961.241881957278
Epoch                        157
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:28:23.155379 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #157 | Epoch Duration: 58.98234438896179
2020-01-10 20:28:23.155690 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #157 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03133298
Z variance train             0.06854442
KL Divergence                4.401528
KL Loss                      0.4401528
QF Loss                      1538.3319
VF Loss                      804.7046
Policy Loss                  -838.16473
Q Predictions Mean           830.73676
Q Predictions Std            852.6001
Q Predictions Max            2082.6553
Q Predictions Min            17.34243
V Predictions Mean           825.7773
V Predictions Std            840.0432
V Predictions Max            2054.2837
V Predictions Min            26.188562
Log Pis Mean                 -5.5735493
Log Pis Std                  6.6837964
Log Pis Max                  18.48571
Log Pis Min                  -13.210118
Policy mu Mean               0.23774894
Policy mu Std                0.6817684
Policy mu Max                2.372854
Policy mu Min                -2.7327845
Policy log std Mean          -0.25692904
Policy log std Std           0.15796681
Policy log std Max           -0.060302675
Policy log std Min           -0.8550329
Z mean eval                  0.03174346
Z variance eval              0.06867932
total_rewards                [1160.64697621 1766.1066356  1658.19188481 1937.77925882 1196.66362171
  579.74247439 1510.78288595  962.2574695  1482.73566941 3062.57883252]
total_rewards_mean           1531.7485708915842
total_rewards_std            637.3923193099076
total_rewards_max            3062.578832524825
total_rewards_min            579.7424743868119
Number of train steps total  159000
Number of env steps total    797000
Number of rollouts total     0
Train Time (s)               30.83744539413601
(Previous) Eval Time (s)     9.358889567200094
Sample Time (s)              18.07798546133563
Epoch Time (s)               58.274320422671735
Total Train Time (s)         8019.0171181089245
Epoch                        158
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:29:20.932490 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #158 | Epoch Duration: 57.77654671669006
2020-01-10 20:29:20.932714 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #158 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031601273
Z variance train             0.06866474
KL Divergence                4.3975773
KL Loss                      0.43975773
QF Loss                      1313.9602
VF Loss                      414.37076
Policy Loss                  -894.71545
Q Predictions Mean           892.42236
Q Predictions Std            859.277
Q Predictions Max            2079.4702
Q Predictions Min            16.679195
V Predictions Mean           893.1888
V Predictions Std            851.4385
V Predictions Max            2075.8608
V Predictions Min            25.089397
Log Pis Mean                 -4.72808
Log Pis Std                  6.9659348
Log Pis Max                  16.787994
Log Pis Min                  -15.492394
Policy mu Mean               0.24621212
Policy mu Std                0.7121695
Policy mu Max                2.985907
Policy mu Min                -2.4639895
Policy log std Mean          -0.2724423
Policy log std Std           0.16868193
Policy log std Max           0.006594941
Policy log std Min           -0.92719626
Z mean eval                  0.03217522
Z variance eval              0.06657338
total_rewards                [1013.92381279 1106.38768866 1021.74104183 2114.46777973  606.21193888
 1590.15348933 1434.66458743 1142.68614702 1755.48336474 4943.61910323]
total_rewards_mean           1672.9338953625133
total_rewards_std            1164.5236196162275
total_rewards_max            4943.619103227818
total_rewards_min            606.2119388755112
Number of train steps total  160000
Number of env steps total    802000
Number of rollouts total     0
Train Time (s)               29.959326812066138
(Previous) Eval Time (s)     8.860854378901422
Sample Time (s)              19.182359338272363
Epoch Time (s)               58.00254052923992
Total Train Time (s)         8078.03471539868
Epoch                        159
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:30:19.953263 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #159 | Epoch Duration: 59.02036786079407
2020-01-10 20:30:19.953492 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #159 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031916466
Z variance train             0.06658074
KL Divergence                4.4629683
KL Loss                      0.44629684
QF Loss                      1905.6339
VF Loss                      584.1171
Policy Loss                  -862.8893
Q Predictions Mean           856.5419
Q Predictions Std            846.5857
Q Predictions Max            2088.059
Q Predictions Min            14.238593
V Predictions Mean           868.9308
V Predictions Std            844.3758
V Predictions Max            2087.5256
V Predictions Min            26.065655
Log Pis Mean                 -4.9938507
Log Pis Std                  7.3401656
Log Pis Max                  23.349846
Log Pis Min                  -13.731112
Policy mu Mean               0.24804194
Policy mu Std                0.70225114
Policy mu Max                2.570414
Policy mu Min                -3.2707634
Policy log std Mean          -0.25859246
Policy log std Std           0.15713894
Policy log std Max           -0.058444604
Policy log std Min           -0.8889476
Z mean eval                  0.032445617
Z variance eval              0.06497843
total_rewards                [ 929.78987797 1565.60995064 2941.95802435 1761.73146469 1009.58229951
 1348.66972279 1639.84826596 2048.30491279 3131.81340619 1717.8871854 ]
total_rewards_mean           1809.519511028807
total_rewards_std            693.7624436525048
total_rewards_max            3131.8134061923224
total_rewards_min            929.7898779656632
Number of train steps total  161000
Number of env steps total    807000
Number of rollouts total     0
Train Time (s)               31.756944031920284
(Previous) Eval Time (s)     9.878328058868647
Sample Time (s)              19.637614319566637
Epoch Time (s)               61.27288641035557
Total Train Time (s)         8140.020271338522
Epoch                        160
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:31:21.940545 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #160 | Epoch Duration: 61.986881494522095
2020-01-10 20:31:21.940744 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #160 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032066427
Z variance train             0.06497042
KL Divergence                4.520313
KL Loss                      0.45203128
QF Loss                      1583.9597
VF Loss                      307.11804
Policy Loss                  -911.382
Q Predictions Mean           909.5014
Q Predictions Std            860.06104
Q Predictions Max            2110.7178
Q Predictions Min            14.707416
V Predictions Mean           916.3186
V Predictions Std            856.15405
V Predictions Max            2105.4724
V Predictions Min            28.641659
Log Pis Mean                 -4.861906
Log Pis Std                  6.5431957
Log Pis Max                  16.240425
Log Pis Min                  -13.18697
Policy mu Mean               0.21988226
Policy mu Std                0.7088386
Policy mu Max                2.343788
Policy mu Min                -2.7465706
Policy log std Mean          -0.2713931
Policy log std Std           0.16454266
Policy log std Max           -0.021938227
Policy log std Min           -0.9087824
Z mean eval                  0.03336564
Z variance eval              0.06402376
total_rewards                [2772.96635286 2736.00720106 4947.7853637  1699.2783292  1300.8408834
 1193.097189   4687.86545095  912.49051268 3577.57500493 2725.44578938]
total_rewards_mean           2655.3352077162776
total_rewards_std            1348.5785474080558
total_rewards_max            4947.785363695824
total_rewards_min            912.4905126808698
Number of train steps total  162000
Number of env steps total    812000
Number of rollouts total     0
Train Time (s)               28.706157551147044
(Previous) Eval Time (s)     10.592025553341955
Sample Time (s)              18.338398369029164
Epoch Time (s)               57.63658147351816
Total Train Time (s)         8203.409367159009
Epoch                        161
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:32:25.333032 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #161 | Epoch Duration: 63.392125606536865
2020-01-10 20:32:25.333263 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #161 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033513553
Z variance train             0.0639996
KL Divergence                4.5523505
KL Loss                      0.45523506
QF Loss                      1456.5254
VF Loss                      449.21487
Policy Loss                  -861.1816
Q Predictions Mean           851.74
Q Predictions Std            856.27325
Q Predictions Max            2108.3218
Q Predictions Min            12.909324
V Predictions Mean           856.0377
V Predictions Std            851.29504
V Predictions Max            2093.994
V Predictions Min            22.57032
Log Pis Mean                 -5.019525
Log Pis Std                  7.0836153
Log Pis Max                  16.102448
Log Pis Min                  -14.226097
Policy mu Mean               0.21646206
Policy mu Std                0.6975024
Policy mu Max                2.6453524
Policy mu Min                -2.4977376
Policy log std Mean          -0.27044398
Policy log std Std           0.1678144
Policy log std Max           -0.014214188
Policy log std Min           -0.84629893
Z mean eval                  0.034150485
Z variance eval              0.06679324
total_rewards                [1652.54271717  889.51527155 1339.69147278 1377.80138928 3368.39606686
 1413.55426402 1220.19247942 2516.89099194 1809.88540974 3021.74201107]
total_rewards_mean           1861.0212073821992
total_rewards_std            784.58224987749
total_rewards_max            3368.3960668603722
total_rewards_min            889.5152715467727
Number of train steps total  163000
Number of env steps total    817000
Number of rollouts total     0
Train Time (s)               30.367212005890906
(Previous) Eval Time (s)     16.34726141579449
Sample Time (s)              19.00199487619102
Epoch Time (s)               65.71646829787642
Total Train Time (s)         8264.30437753722
Epoch                        162
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:33:26.228710 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #162 | Epoch Duration: 60.89528465270996
2020-01-10 20:33:26.228947 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #162 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033731136
Z variance train             0.06681069
KL Divergence                4.454277
KL Loss                      0.44542772
QF Loss                      1751.2227
VF Loss                      547.4901
Policy Loss                  -985.4497
Q Predictions Mean           979.8476
Q Predictions Std            855.37213
Q Predictions Max            2099.0652
Q Predictions Min            14.277159
V Predictions Mean           995.44244
V Predictions Std            859.6181
V Predictions Max            2110.4001
V Predictions Min            26.09215
Log Pis Mean                 -4.238066
Log Pis Std                  7.163249
Log Pis Max                  15.491269
Log Pis Min                  -16.145891
Policy mu Mean               0.22487208
Policy mu Std                0.7709795
Policy mu Max                2.7706456
Policy mu Min                -3.2001872
Policy log std Mean          -0.2807551
Policy log std Std           0.16478202
Policy log std Max           -0.022955403
Policy log std Min           -0.830262
Z mean eval                  0.034926347
Z variance eval              0.063461
total_rewards                [2177.10271291 1966.00800957  857.28290445  748.17507508  554.72716162
 1842.07898861 3452.71401862 1818.96753857 5032.92397988 4006.46189653]
total_rewards_mean           2245.644228584662
total_rewards_std            1406.5346979102287
total_rewards_max            5032.923979884155
total_rewards_min            554.7271616155737
Number of train steps total  164000
Number of env steps total    822000
Number of rollouts total     0
Train Time (s)               32.19267912907526
(Previous) Eval Time (s)     11.52576954383403
Sample Time (s)              18.30684640072286
Epoch Time (s)               62.02529507363215
Total Train Time (s)         8328.202467984054
Epoch                        163
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:34:30.130402 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #163 | Epoch Duration: 63.901283740997314
2020-01-10 20:34:30.130662 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #163 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03472348
Z variance train             0.06346644
KL Divergence                4.5819187
KL Loss                      0.45819187
QF Loss                      1507.5427
VF Loss                      600.30133
Policy Loss                  -940.0254
Q Predictions Mean           933.8259
Q Predictions Std            882.38696
Q Predictions Max            2095.5176
Q Predictions Min            16.108189
V Predictions Mean           944.2693
V Predictions Std            884.2677
V Predictions Max            2112.9336
V Predictions Min            26.933744
Log Pis Mean                 -4.4197245
Log Pis Std                  7.7021623
Log Pis Max                  20.96985
Log Pis Min                  -15.714471
Policy mu Mean               0.23966293
Policy mu Std                0.73170704
Policy mu Max                2.956918
Policy mu Min                -3.3030648
Policy log std Mean          -0.2792015
Policy log std Std           0.17199862
Policy log std Max           -0.009037547
Policy log std Min           -0.86530566
Z mean eval                  0.034539774
Z variance eval              0.06322025
total_rewards                [2079.8559687   955.95387499 1408.71353602 1623.72081674 2145.79805565
  792.77050405 1161.12358904  599.29309238  679.85586628 3146.51784084]
total_rewards_mean           1459.3603144683814
total_rewards_std            765.9203348541387
total_rewards_max            3146.517840836818
total_rewards_min            599.293092375597
Number of train steps total  165000
Number of env steps total    827000
Number of rollouts total     0
Train Time (s)               30.629673975985497
(Previous) Eval Time (s)     13.401403126772493
Sample Time (s)              18.89428985817358
Epoch Time (s)               62.92536696093157
Total Train Time (s)         8387.092379022855
Epoch                        164
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:35:29.024039 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #164 | Epoch Duration: 58.893176317214966
2020-01-10 20:35:29.024291 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #164 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034986265
Z variance train             0.063204974
KL Divergence                4.603547
KL Loss                      0.46035472
QF Loss                      1455.189
VF Loss                      671.65894
Policy Loss                  -967.949
Q Predictions Mean           957.7465
Q Predictions Std            885.4033
Q Predictions Max            2124.8096
Q Predictions Min            14.494929
V Predictions Mean           953.04767
V Predictions Std            868.9099
V Predictions Max            2099.0327
V Predictions Min            26.222609
Log Pis Mean                 -4.182412
Log Pis Std                  7.7960634
Log Pis Max                  23.300629
Log Pis Min                  -13.719095
Policy mu Mean               0.22692214
Policy mu Std                0.7627699
Policy mu Max                3.0096684
Policy mu Min                -3.1473858
Policy log std Mean          -0.28265345
Policy log std Std           0.16880482
Policy log std Max           0.04129602
Policy log std Min           -0.9907776
Z mean eval                  0.035371672
Z variance eval              0.06267838
total_rewards                [ 879.7049445   864.18543974  502.78837094 1874.70977455 1224.15865343
  891.11829671 2505.08859067 1711.65621253  928.92941727 3879.22798844]
total_rewards_mean           1526.1567688788268
total_rewards_std            969.8297288450362
total_rewards_max            3879.227988442135
total_rewards_min            502.78837094030774
Number of train steps total  166000
Number of env steps total    832000
Number of rollouts total     0
Train Time (s)               31.08094642870128
(Previous) Eval Time (s)     9.368919835891575
Sample Time (s)              19.325312288943678
Epoch Time (s)               59.775178553536534
Total Train Time (s)         8446.659907245077
Epoch                        165
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:36:28.594526 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #165 | Epoch Duration: 59.57003355026245
2020-01-10 20:36:28.594781 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #165 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03563713
Z variance train             0.06266312
KL Divergence                4.623762
KL Loss                      0.4623762
QF Loss                      1470.0469
VF Loss                      566.45374
Policy Loss                  -1014.9216
Q Predictions Mean           1007.10046
Q Predictions Std            896.6086
Q Predictions Max            2112.731
Q Predictions Min            14.68309
V Predictions Mean           1003.1279
V Predictions Std            885.3177
V Predictions Max            2108.6877
V Predictions Min            26.856966
Log Pis Mean                 -4.630645
Log Pis Std                  6.378707
Log Pis Max                  13.179247
Log Pis Min                  -12.561796
Policy mu Mean               0.25838235
Policy mu Std                0.72601825
Policy mu Max                2.548395
Policy mu Min                -2.3872044
Policy log std Mean          -0.27887097
Policy log std Std           0.16293497
Policy log std Max           -0.01642491
Policy log std Min           -0.89018446
Z mean eval                  0.035499435
Z variance eval              0.05999726
total_rewards                [3356.23104226  900.24002849 2212.50086189  506.7035752  1431.29153903
 1786.669111   1157.99325492 1899.24026342 1937.41547983  676.97615317]
total_rewards_mean           1586.526130921699
total_rewards_std            803.5356399038857
total_rewards_max            3356.231042264264
total_rewards_min            506.7035751955253
Number of train steps total  167000
Number of env steps total    837000
Number of rollouts total     0
Train Time (s)               31.285903666634113
(Previous) Eval Time (s)     9.163445875048637
Sample Time (s)              19.82502804044634
Epoch Time (s)               60.27437758212909
Total Train Time (s)         8507.102569940034
Epoch                        166
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:37:29.037992 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #166 | Epoch Duration: 60.443033933639526
2020-01-10 20:37:29.038153 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #166 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035476428
Z variance train             0.059999555
KL Divergence                4.7310953
KL Loss                      0.47310954
QF Loss                      1540.6768
VF Loss                      456.39206
Policy Loss                  -991.83246
Q Predictions Mean           986.4163
Q Predictions Std            888.06647
Q Predictions Max            2124.2668
Q Predictions Min            16.519613
V Predictions Mean           991.53925
V Predictions Std            884.10803
V Predictions Max            2126.308
V Predictions Min            27.33948
Log Pis Mean                 -4.8258767
Log Pis Std                  6.5771413
Log Pis Max                  15.521692
Log Pis Min                  -13.745633
Policy mu Mean               0.25474668
Policy mu Std                0.7049807
Policy mu Max                2.7122262
Policy mu Min                -2.473259
Policy log std Mean          -0.2730508
Policy log std Std           0.16050707
Policy log std Max           -0.02493371
Policy log std Min           -0.85685575
Z mean eval                  0.03654869
Z variance eval              0.06070295
total_rewards                [4950.07896212  724.5330925  2196.41466837  618.43919506  537.64571666
  712.76473199 1681.7170509   580.5379191   971.82596097 3164.6924037 ]
total_rewards_mean           1613.8649701371226
total_rewards_std            1382.4380511064471
total_rewards_max            4950.078962117999
total_rewards_min            537.6457166586761
Number of train steps total  168000
Number of env steps total    842000
Number of rollouts total     0
Train Time (s)               33.72959906980395
(Previous) Eval Time (s)     9.331737066153437
Sample Time (s)              19.939028116874397
Epoch Time (s)               63.00036425283179
Total Train Time (s)         8570.906634467654
Epoch                        167
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:38:32.843444 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #167 | Epoch Duration: 63.8051643371582
2020-01-10 20:38:32.843698 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #167 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03556905
Z variance train             0.060699712
KL Divergence                4.7221193
KL Loss                      0.47221193
QF Loss                      1096.3485
VF Loss                      650.10156
Policy Loss                  -825.88873
Q Predictions Mean           821.5148
Q Predictions Std            895.25543
Q Predictions Max            2118.084
Q Predictions Min            17.896568
V Predictions Mean           838.0124
V Predictions Std            902.3166
V Predictions Max            2150.8164
V Predictions Min            27.817999
Log Pis Mean                 -6.219237
Log Pis Std                  6.4227524
Log Pis Max                  13.240643
Log Pis Min                  -15.698792
Policy mu Mean               0.20278156
Policy mu Std                0.63857615
Policy mu Max                2.5481334
Policy mu Min                -2.6283932
Policy log std Mean          -0.24798073
Policy log std Std           0.1508837
Policy log std Max           -0.06835291
Policy log std Min           -0.8426931
Z mean eval                  0.035579056
Z variance eval              0.058649242
total_rewards                [1312.3728116   710.58162879 1233.82896539 4700.70325427  876.45015339
 1053.94872415 3097.34148686 1055.32691686 1855.87858822 1407.79261844]
total_rewards_mean           1730.4225147966185
total_rewards_std            1179.616472167914
total_rewards_max            4700.703254265072
total_rewards_min            710.5816287867881
Number of train steps total  169000
Number of env steps total    847000
Number of rollouts total     0
Train Time (s)               29.315327988006175
(Previous) Eval Time (s)     10.13619240699336
Sample Time (s)              18.636565032880753
Epoch Time (s)               58.08808542788029
Total Train Time (s)         8628.908436718863
Epoch                        168
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:39:30.847499 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #168 | Epoch Duration: 58.00367212295532
2020-01-10 20:39:30.847671 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #168 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035529263
Z variance train             0.058625203
KL Divergence                4.785776
KL Loss                      0.4785776
QF Loss                      1002.8343
VF Loss                      521.3291
Policy Loss                  -964.4682
Q Predictions Mean           953.5361
Q Predictions Std            877.0832
Q Predictions Max            2115.624
Q Predictions Min            16.99143
V Predictions Mean           971.8702
V Predictions Std            884.31915
V Predictions Max            2140.2524
V Predictions Min            28.601974
Log Pis Mean                 -4.7352543
Log Pis Std                  7.0471153
Log Pis Max                  18.298397
Log Pis Min                  -13.955519
Policy mu Mean               0.24080305
Policy mu Std                0.7108653
Policy mu Max                2.8347945
Policy mu Min                -3.1658983
Policy log std Mean          -0.2701412
Policy log std Std           0.16632657
Policy log std Max           -0.05116182
Policy log std Min           -0.9177153
Z mean eval                  0.03622938
Z variance eval              0.056237943
total_rewards                [ 404.73474757 2296.97700287 1897.19432105 2504.16166976 1223.85829691
 1780.56064075 3984.81643416 4846.82985151  504.52302437 3267.87084803]
total_rewards_mean           2271.152683699612
total_rewards_std            1367.5163879195513
total_rewards_max            4846.829851513747
total_rewards_min            404.7347475734161
Number of train steps total  170000
Number of env steps total    852000
Number of rollouts total     0
Train Time (s)               31.313270152080804
(Previous) Eval Time (s)     10.051411373075098
Sample Time (s)              19.0422430629842
Epoch Time (s)               60.4069245881401
Total Train Time (s)         8692.78613604838
Epoch                        169
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:40:34.726677 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #169 | Epoch Duration: 63.87886953353882
2020-01-10 20:40:34.726883 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #169 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036603905
Z variance train             0.056234963
KL Divergence                4.878684
KL Loss                      0.4878684
QF Loss                      3036.044
VF Loss                      701.9221
Policy Loss                  -1026.9437
Q Predictions Mean           1021.07745
Q Predictions Std            892.8756
Q Predictions Max            2141.8586
Q Predictions Min            17.106258
V Predictions Mean           1015.2745
V Predictions Std            879.0018
V Predictions Max            2127.7686
V Predictions Min            25.001474
Log Pis Mean                 -4.6038733
Log Pis Std                  6.7327666
Log Pis Max                  14.417679
Log Pis Min                  -14.495519
Policy mu Mean               0.23985386
Policy mu Std                0.74910843
Policy mu Max                2.8891404
Policy mu Min                -2.6676888
Policy log std Mean          -0.28143692
Policy log std Std           0.17092252
Policy log std Max           -0.003592506
Policy log std Min           -1.0953944
Z mean eval                  0.034608345
Z variance eval              0.05720576
total_rewards                [2002.89752101 5085.34501512  710.67961415 1782.68542537 3725.50780706
  676.10140442 5023.729895    892.8438961  3415.78247511  943.14728947]
total_rewards_mean           2425.8720342797337
total_rewards_std            1662.391786322584
total_rewards_max            5085.345015119542
total_rewards_min            676.1014044232649
Number of train steps total  171000
Number of env steps total    857000
Number of rollouts total     0
Train Time (s)               29.546120672952384
(Previous) Eval Time (s)     13.523034281097353
Sample Time (s)              19.236594325862825
Epoch Time (s)               62.30574927991256
Total Train Time (s)         8755.762042833492
Epoch                        170
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:41:37.704428 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #170 | Epoch Duration: 62.97742581367493
2020-01-10 20:41:37.704583 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #170 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034677118
Z variance train             0.05720082
KL Divergence                4.8350363
KL Loss                      0.48350364
QF Loss                      1304.3606
VF Loss                      481.72742
Policy Loss                  -1031.547
Q Predictions Mean           1023.60394
Q Predictions Std            892.1948
Q Predictions Max            2134.2139
Q Predictions Min            16.86392
V Predictions Mean           1028.3085
V Predictions Std            887.93695
V Predictions Max            2119.752
V Predictions Min            28.048319
Log Pis Mean                 -3.7591403
Log Pis Std                  7.3349156
Log Pis Max                  22.066093
Log Pis Min                  -13.210235
Policy mu Mean               0.2826666
Policy mu Std                0.7514107
Policy mu Max                2.736985
Policy mu Min                -2.751478
Policy log std Mean          -0.28869596
Policy log std Std           0.1724318
Policy log std Max           -0.033563226
Policy log std Min           -0.93444896
Z mean eval                  0.03645461
Z variance eval              0.05732618
total_rewards                [1957.15675553 4910.21800137 3580.40022188 2587.68491714 2934.33334099
 3610.72060939 3250.06891842 1385.72455663 2916.28572541 2982.49831012]
total_rewards_mean           3011.5091356878265
total_rewards_std            910.7702356328865
total_rewards_max            4910.2180013687075
total_rewards_min            1385.7245566290433
Number of train steps total  172000
Number of env steps total    862000
Number of rollouts total     0
Train Time (s)               29.98495283117518
(Previous) Eval Time (s)     14.194359759800136
Sample Time (s)              19.029257743619382
Epoch Time (s)               63.2085703345947
Total Train Time (s)         8823.031737315934
Epoch                        171
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:42:44.977855 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #171 | Epoch Duration: 67.27312302589417
2020-01-10 20:42:44.978055 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #171 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036711156
Z variance train             0.057343453
KL Divergence                4.8452373
KL Loss                      0.48452374
QF Loss                      1784.1191
VF Loss                      504.1974
Policy Loss                  -1035.8195
Q Predictions Mean           1025.114
Q Predictions Std            917.1044
Q Predictions Max            2144.132
Q Predictions Min            17.322647
V Predictions Mean           1028.743
V Predictions Std            911.81213
V Predictions Max            2142.5256
V Predictions Min            26.340998
Log Pis Mean                 -4.4188213
Log Pis Std                  7.268119
Log Pis Max                  19.801624
Log Pis Min                  -13.503855
Policy mu Mean               0.25084338
Policy mu Std                0.72483236
Policy mu Max                2.4972079
Policy mu Min                -2.874135
Policy log std Mean          -0.27847028
Policy log std Std           0.16691563
Policy log std Max           -0.04050138
Policy log std Min           -0.8518942
Z mean eval                  0.037823886
Z variance eval              0.055317976
total_rewards                [3071.28169532 4944.14326406 1817.51834535 3359.9809919  1133.7216502
  929.08567236 1508.02687126 3823.2277828  1817.22410094 2108.14961845]
total_rewards_mean           2451.2359992658244
total_rewards_std            1231.7032420761475
total_rewards_max            4944.143264060193
total_rewards_min            929.0856723630899
Number of train steps total  173000
Number of env steps total    867000
Number of rollouts total     0
Train Time (s)               31.060454783029854
(Previous) Eval Time (s)     18.258563328068703
Sample Time (s)              20.15225371159613
Epoch Time (s)               69.47127182269469
Total Train Time (s)         8888.935756671242
Epoch                        172
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:43:50.882501 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #172 | Epoch Duration: 65.90429830551147
2020-01-10 20:43:50.882654 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #172 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037854373
Z variance train             0.05531607
KL Divergence                4.9210668
KL Loss                      0.49210668
QF Loss                      1379.5298
VF Loss                      379.2578
Policy Loss                  -1060.8934
Q Predictions Mean           1056.7485
Q Predictions Std            920.0717
Q Predictions Max            2153.2678
Q Predictions Min            15.890201
V Predictions Mean           1059.7217
V Predictions Std            912.12964
V Predictions Max            2144.3389
V Predictions Min            25.692823
Log Pis Mean                 -5.138942
Log Pis Std                  6.4463973
Log Pis Max                  16.412498
Log Pis Min                  -13.34101
Policy mu Mean               0.23136644
Policy mu Std                0.70409226
Policy mu Max                2.5401099
Policy mu Min                -2.5576158
Policy log std Mean          -0.2785342
Policy log std Std           0.1657426
Policy log std Max           -0.07212192
Policy log std Min           -0.8813806
Z mean eval                  0.036955617
Z variance eval              0.05530156
total_rewards                [ 958.41575414 5039.38399721 2122.34948764 5029.98789734 1763.39355278
 3178.89013197 1260.58810032 1941.85419999 2024.96746499 4468.10899481]
total_rewards_mean           2778.79395811873
total_rewards_std            1467.6992000073071
total_rewards_max            5039.383997207951
total_rewards_min            958.4157541421846
Number of train steps total  174000
Number of env steps total    872000
Number of rollouts total     0
Train Time (s)               29.815601617097855
(Previous) Eval Time (s)     14.69120289804414
Sample Time (s)              18.85100649576634
Epoch Time (s)               63.357811010908335
Total Train Time (s)         8953.885165725835
Epoch                        173
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:44:55.836830 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #173 | Epoch Duration: 64.95402312278748
2020-01-10 20:44:55.837115 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #173 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0368185
Z variance train             0.0553074
KL Divergence                4.9302816
KL Loss                      0.49302816
QF Loss                      1281.4944
VF Loss                      371.7483
Policy Loss                  -998.02295
Q Predictions Mean           989.1136
Q Predictions Std            893.7114
Q Predictions Max            2127.993
Q Predictions Min            14.718544
V Predictions Mean           1005.5449
V Predictions Std            896.31104
V Predictions Max            2151.8118
V Predictions Min            26.04771
Log Pis Mean                 -4.5770826
Log Pis Std                  7.018559
Log Pis Max                  18.802269
Log Pis Min                  -13.108779
Policy mu Mean               0.25413805
Policy mu Std                0.73089594
Policy mu Max                2.533586
Policy mu Min                -2.9084253
Policy log std Mean          -0.27317417
Policy log std Std           0.16617532
Policy log std Max           -0.030958757
Policy log std Min           -0.83555675
Z mean eval                  0.03690244
Z variance eval              0.05564921
total_rewards                [1337.37312071 1265.68663545 3423.78340889 4883.9247864  2117.98255212
  714.02229412 2785.8184949  2846.73917771 4893.94158589 2538.33586792]
total_rewards_mean           2680.7607924086687
total_rewards_std            1354.8047533344125
total_rewards_max            4893.941585885355
total_rewards_min            714.022294115854
Number of train steps total  175000
Number of env steps total    877000
Number of rollouts total     0
Train Time (s)               30.43362140096724
(Previous) Eval Time (s)     16.287098618224263
Sample Time (s)              19.447502365335822
Epoch Time (s)               66.16822238452733
Total Train Time (s)         9019.893953047227
Epoch                        174
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:46:01.850004 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #174 | Epoch Duration: 66.01264882087708
2020-01-10 20:46:01.850309 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #174 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036813516
Z variance train             0.055659104
KL Divergence                4.9096713
KL Loss                      0.49096712
QF Loss                      1527.011
VF Loss                      516.38983
Policy Loss                  -952.07764
Q Predictions Mean           949.84845
Q Predictions Std            907.685
Q Predictions Max            2151.309
Q Predictions Min            13.602624
V Predictions Mean           952.56934
V Predictions Std            899.2441
V Predictions Max            2149.9841
V Predictions Min            23.574516
Log Pis Mean                 -4.9033813
Log Pis Std                  7.082966
Log Pis Max                  18.51905
Log Pis Min                  -13.964746
Policy mu Mean               0.21507196
Policy mu Std                0.7225591
Policy mu Max                2.7188027
Policy mu Min                -3.2283068
Policy log std Mean          -0.269821
Policy log std Std           0.16709952
Policy log std Max           -0.012163505
Policy log std Min           -0.94945574
Z mean eval                  0.037485026
Z variance eval              0.056041002
total_rewards                [1500.86125095 2803.91415317 1310.70496283  905.96709158 2083.00474531
  670.29706591  774.41540098 1632.47007846 1104.76925533 1842.70611509]
total_rewards_mean           1462.911011962387
total_rewards_std            626.1886524364894
total_rewards_max            2803.9141531721534
total_rewards_min            670.2970659139277
Number of train steps total  176000
Number of env steps total    882000
Number of rollouts total     0
Train Time (s)               32.144943316001445
(Previous) Eval Time (s)     16.131200041156262
Sample Time (s)              19.131123459897935
Epoch Time (s)               67.40726681705564
Total Train Time (s)         9079.750911362004
Epoch                        175
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:47:01.724244 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #175 | Epoch Duration: 59.873695611953735
2020-01-10 20:47:01.724544 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #175 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037192594
Z variance train             0.056017853
KL Divergence                4.8828917
KL Loss                      0.48828918
QF Loss                      1051.7312
VF Loss                      389.41983
Policy Loss                  -982.41785
Q Predictions Mean           976.10284
Q Predictions Std            929.8504
Q Predictions Max            2159.4058
Q Predictions Min            15.533054
V Predictions Mean           980.9706
V Predictions Std            927.4725
V Predictions Max            2153.1562
V Predictions Min            23.701246
Log Pis Mean                 -5.1757126
Log Pis Std                  6.9053626
Log Pis Max                  19.590027
Log Pis Min                  -12.68718
Policy mu Mean               0.21962857
Policy mu Std                0.6972396
Policy mu Max                3.0505188
Policy mu Min                -3.1429877
Policy log std Mean          -0.2627387
Policy log std Std           0.16213736
Policy log std Max           -0.059851438
Policy log std Min           -0.8270004
Z mean eval                  0.039754458
Z variance eval              0.056943417
total_rewards                [3099.72232215 1680.74373692 2022.29668761 5014.57864442  981.9347859
 3339.48459649 2021.18485178 4989.58551194 1287.63225113 3715.01755331]
total_rewards_mean           2815.2180941638107
total_rewards_std            1377.359393760028
total_rewards_max            5014.57864441804
total_rewards_min            981.934785902091
Number of train steps total  177000
Number of env steps total    887000
Number of rollouts total     0
Train Time (s)               28.31536402227357
(Previous) Eval Time (s)     8.597309589851648
Sample Time (s)              18.934015127830207
Epoch Time (s)               55.846688739955425
Total Train Time (s)         9143.82576554548
Epoch                        176
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:48:05.788817 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #176 | Epoch Duration: 64.06407570838928
2020-01-10 20:48:05.789015 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #176 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039780743
Z variance train             0.056954004
KL Divergence                4.8243766
KL Loss                      0.48243767
QF Loss                      1736.4467
VF Loss                      453.9156
Policy Loss                  -1043.6077
Q Predictions Mean           1040.3594
Q Predictions Std            897.88873
Q Predictions Max            2171.394
Q Predictions Min            17.33849
V Predictions Mean           1043.3068
V Predictions Std            894.21924
V Predictions Max            2163.5544
V Predictions Min            26.19528
Log Pis Mean                 -4.8231363
Log Pis Std                  6.591215
Log Pis Max                  17.871672
Log Pis Min                  -14.51915
Policy mu Mean               0.27654356
Policy mu Std                0.72309226
Policy mu Max                2.6622264
Policy mu Min                -2.493652
Policy log std Mean          -0.2767818
Policy log std Std           0.16100387
Policy log std Max           -0.023548275
Policy log std Min           -0.92351127
Z mean eval                  0.04135581
Z variance eval              0.055487595
total_rewards                [5128.22987753  929.64358632 1330.37866393 1263.56734123 4660.64644218
 3549.01606068 3075.3798905  1683.43168411 2419.74868058 1429.6228626 ]
total_rewards_mean           2546.966508966022
total_rewards_std            1420.1110478442445
total_rewards_max            5128.22987753487
total_rewards_min            929.6435863188852
Number of train steps total  178000
Number of env steps total    892000
Number of rollouts total     0
Train Time (s)               33.67632210673764
(Previous) Eval Time (s)     16.814414781983942
Sample Time (s)              19.299460073467344
Epoch Time (s)               69.79019696218893
Total Train Time (s)         9211.658115356695
Epoch                        177
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:49:13.626205 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #177 | Epoch Duration: 67.83702874183655
2020-01-10 20:49:13.626498 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #177 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.041571736
Z variance train             0.055502106
KL Divergence                4.8913956
KL Loss                      0.48913956
QF Loss                      1825.2269
VF Loss                      537.5379
Policy Loss                  -969.836
Q Predictions Mean           960.46204
Q Predictions Std            878.26526
Q Predictions Max            2164.849
Q Predictions Min            15.40827
V Predictions Mean           964.1564
V Predictions Std            869.9059
V Predictions Max            2158.4543
V Predictions Min            18.747524
Log Pis Mean                 -4.707211
Log Pis Std                  7.0997725
Log Pis Max                  17.86744
Log Pis Min                  -15.669974
Policy mu Mean               0.26075083
Policy mu Std                0.7379732
Policy mu Max                2.811119
Policy mu Min                -3.2796297
Policy log std Mean          -0.28039172
Policy log std Std           0.16643235
Policy log std Max           -0.023747578
Policy log std Min           -0.96200085
Z mean eval                  0.040857762
Z variance eval              0.053408198
total_rewards                [4369.18707902 4963.50540845  827.57728918  608.21746198 3994.58607202
 4990.41510292 4923.78567532 1847.92373417 4936.17600171  753.77935544]
total_rewards_mean           3221.5153180206576
total_rewards_std            1856.147892975165
total_rewards_max            4990.415102915344
total_rewards_min            608.2174619806964
Number of train steps total  179000
Number of env steps total    897000
Number of rollouts total     0
Train Time (s)               30.977295492310077
(Previous) Eval Time (s)     14.860892647877336
Sample Time (s)              19.058709860779345
Epoch Time (s)               64.89689800096676
Total Train Time (s)         9280.850665524602
Epoch                        178
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:50:22.820666 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #178 | Epoch Duration: 69.19394445419312
2020-01-10 20:50:22.820888 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #178 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04101265
Z variance train             0.053398985
KL Divergence                4.9832935
KL Loss                      0.49832937
QF Loss                      1338.3752
VF Loss                      576.0951
Policy Loss                  -1058.0583
Q Predictions Mean           1049.8037
Q Predictions Std            914.76715
Q Predictions Max            2168.703
Q Predictions Min            12.387477
V Predictions Mean           1048.6138
V Predictions Std            903.929
V Predictions Max            2150.5212
V Predictions Min            26.451973
Log Pis Mean                 -3.8178024
Log Pis Std                  7.4894285
Log Pis Max                  17.352844
Log Pis Min                  -13.225046
Policy mu Mean               0.24857773
Policy mu Std                0.75876147
Policy mu Max                2.7729354
Policy mu Min                -2.662925
Policy log std Mean          -0.28609297
Policy log std Std           0.16361548
Policy log std Max           -0.025855802
Policy log std Min           -0.93515384
Z mean eval                  0.041406166
Z variance eval              0.05390364
total_rewards                [3864.38793654 3322.60623367 1450.20468949 1509.93445881  907.83871423
 1552.36283969 1218.83824278 1161.89023778 1083.26940712 1035.12474578]
total_rewards_mean           1710.6457505902424
total_rewards_std            969.9291794190315
total_rewards_max            3864.387936544497
total_rewards_min            907.8387142346053
Number of train steps total  180000
Number of env steps total    902000
Number of rollouts total     0
Train Time (s)               30.773639659862965
(Previous) Eval Time (s)     19.15761212911457
Sample Time (s)              19.613808108028024
Epoch Time (s)               69.54505989700556
Total Train Time (s)         9341.48766893614
Epoch                        179
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:51:23.462587 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #179 | Epoch Duration: 60.64150810241699
2020-01-10 20:51:23.462870 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #179 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.041319117
Z variance train             0.05390083
KL Divergence                4.9562135
KL Loss                      0.49562135
QF Loss                      1784.5615
VF Loss                      489.8689
Policy Loss                  -1127.6543
Q Predictions Mean           1119.8414
Q Predictions Std            910.235
Q Predictions Max            2166.343
Q Predictions Min            16.83186
V Predictions Mean           1132.5281
V Predictions Std            910.14575
V Predictions Max            2177.548
V Predictions Min            23.399843
Log Pis Mean                 -3.4405093
Log Pis Std                  7.421569
Log Pis Max                  24.989515
Log Pis Min                  -13.033765
Policy mu Mean               0.27324036
Policy mu Std                0.7678951
Policy mu Max                2.7641354
Policy mu Min                -2.8527706
Policy log std Mean          -0.29060546
Policy log std Std           0.16199392
Policy log std Max           -0.05702243
Policy log std Min           -0.8828885
Z mean eval                  0.042485334
Z variance eval              0.053511582
total_rewards                [2071.81057561 4329.3634629  5043.18355624 3860.57191447 2272.41898641
 4313.36766979 1567.51975517 1304.27149361 2986.19846866  405.55036663]
total_rewards_mean           2815.4256249488944
total_rewards_std            1453.1487142837077
total_rewards_max            5043.183556237945
total_rewards_min            405.5503666272611
Number of train steps total  181000
Number of env steps total    907000
Number of rollouts total     0
Train Time (s)               28.559020559303463
(Previous) Eval Time (s)     10.253710712306201
Sample Time (s)              18.70992382010445
Epoch Time (s)               57.522655091714114
Total Train Time (s)         9405.987100865692
Epoch                        180
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:52:27.974251 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #180 | Epoch Duration: 64.51114249229431
2020-01-10 20:52:27.974558 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #180 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04238381
Z variance train             0.05350659
KL Divergence                4.9770627
KL Loss                      0.49770626
QF Loss                      1275.5051
VF Loss                      552.2252
Policy Loss                  -998.9861
Q Predictions Mean           993.63727
Q Predictions Std            900.4469
Q Predictions Max            2170.3123
Q Predictions Min            16.15212
V Predictions Mean           1004.2293
V Predictions Std            898.97516
V Predictions Max            2175.8613
V Predictions Min            27.442335
Log Pis Mean                 -4.436183
Log Pis Std                  7.2611
Log Pis Max                  16.172935
Log Pis Min                  -15.523791
Policy mu Mean               0.2645173
Policy mu Std                0.7397066
Policy mu Max                2.5714116
Policy mu Min                -2.9440386
Policy log std Mean          -0.28488243
Policy log std Std           0.17095879
Policy log std Max           0.07725942
Policy log std Min           -0.89854676
Z mean eval                  0.044084754
Z variance eval              0.049705096
total_rewards                [1154.45750923 1246.59036035 1452.11919865 5027.99119298 3156.48326098
 3511.90191969 3246.5359597  5064.27924525 2442.93474349  449.41593692]
total_rewards_mean           2675.2709327229772
total_rewards_std            1528.3659955434755
total_rewards_max            5064.279245251326
total_rewards_min            449.41593691860743
Number of train steps total  182000
Number of env steps total    912000
Number of rollouts total     0
Train Time (s)               30.330880464054644
(Previous) Eval Time (s)     17.241906165611
Sample Time (s)              19.07144526997581
Epoch Time (s)               66.64423189964145
Total Train Time (s)         9470.92077281233
Epoch                        181
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:53:32.899783 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #181 | Epoch Duration: 64.92502450942993
2020-01-10 20:53:32.899965 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #181 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04378993
Z variance train             0.049693197
KL Divergence                5.152337
KL Loss                      0.5152337
QF Loss                      1822.1388
VF Loss                      549.75006
Policy Loss                  -1076.5537
Q Predictions Mean           1075.8931
Q Predictions Std            930.28375
Q Predictions Max            2183.5723
Q Predictions Min            15.557226
V Predictions Mean           1087.2881
V Predictions Std            928.28204
V Predictions Max            2192.9463
V Predictions Min            28.73017
Log Pis Mean                 -4.7962227
Log Pis Std                  6.9256606
Log Pis Max                  21.278378
Log Pis Min                  -13.10825
Policy mu Mean               0.25827026
Policy mu Std                0.7102912
Policy mu Max                3.0743554
Policy mu Min                -2.722146
Policy log std Mean          -0.2773606
Policy log std Std           0.16316237
Policy log std Max           -0.054709956
Policy log std Min           -0.8136482
Z mean eval                  0.0432076
Z variance eval              0.04862938
total_rewards                [4975.96624488 1755.46394236 5015.11984563 4857.28762235 5010.24442618
 2397.60071985 4932.12612219 3180.27937566 5017.27339928 1725.45584382]
total_rewards_mean           3886.681754219694
total_rewards_std            1377.1320523443899
total_rewards_max            5017.2733992833655
total_rewards_min            1725.4558438246106
Number of train steps total  183000
Number of env steps total    917000
Number of rollouts total     0
Train Time (s)               31.987993041984737
(Previous) Eval Time (s)     15.522387328092009
Sample Time (s)              19.6998305269517
Epoch Time (s)               67.21021089702845
Total Train Time (s)         9546.071622894611
Epoch                        182
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:54:48.055743 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #182 | Epoch Duration: 75.15561604499817
2020-01-10 20:54:48.056082 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #182 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043210093
Z variance train             0.048618555
KL Divergence                5.2037926
KL Loss                      0.52037925
QF Loss                      1513.9609
VF Loss                      645.2829
Policy Loss                  -1120.3582
Q Predictions Mean           1115.7975
Q Predictions Std            907.05725
Q Predictions Max            2192.5942
Q Predictions Min            16.03118
V Predictions Mean           1125.7896
V Predictions Std            904.62
V Predictions Max            2211.8857
V Predictions Min            26.363499
Log Pis Mean                 -3.9458506
Log Pis Std                  6.80959
Log Pis Max                  19.759789
Log Pis Min                  -15.052688
Policy mu Mean               0.27378392
Policy mu Std                0.74893063
Policy mu Max                2.5093703
Policy mu Min                -3.2808373
Policy log std Mean          -0.28950858
Policy log std Std           0.1615292
Policy log std Max           -0.046636485
Policy log std Min           -0.9055445
Z mean eval                  0.0423927
Z variance eval              0.05016021
total_rewards                [2857.76913536 1533.98239016 5128.21582052 2126.30698655 2581.49746762
 3683.62680882 3112.49977803 5155.06625041 1318.09405062 2956.3058483 ]
total_rewards_mean           3045.3364536394697
total_rewards_std            1247.8661346436156
total_rewards_max            5155.066250409393
total_rewards_min            1318.0940506226452
Number of train steps total  184000
Number of env steps total    922000
Number of rollouts total     0
Train Time (s)               29.747369992081076
(Previous) Eval Time (s)     23.467420127242804
Sample Time (s)              20.364790994673967
Epoch Time (s)               73.57958111399785
Total Train Time (s)         9613.67594903009
Epoch                        183
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:55:55.660375 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #183 | Epoch Duration: 67.60410404205322
2020-01-10 20:55:55.660528 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #183 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.042424053
Z variance train             0.050160896
KL Divergence                5.1311593
KL Loss                      0.51311594
QF Loss                      1119.1818
VF Loss                      280.92007
Policy Loss                  -1068.0477
Q Predictions Mean           1062.1198
Q Predictions Std            921.94507
Q Predictions Max            2196.4177
Q Predictions Min            19.545015
V Predictions Mean           1065.1501
V Predictions Std            918.1579
V Predictions Max            2208.5066
V Predictions Min            27.550695
Log Pis Mean                 -4.3935785
Log Pis Std                  6.5344143
Log Pis Max                  14.975478
Log Pis Min                  -17.235546
Policy mu Mean               0.33429858
Policy mu Std                0.70204675
Policy mu Max                2.7335622
Policy mu Min                -3.0458436
Policy log std Mean          -0.28524646
Policy log std Std           0.16125055
Policy log std Max           -0.02834367
Policy log std Min           -0.9152366
Z mean eval                  0.04308415
Z variance eval              0.048936374
total_rewards                [2248.40335755 5108.74208734 4002.3544385  2787.32810334 1758.74538753
 1250.2280982  5092.09579255 1985.83888015 1077.30506503 1141.11541661]
total_rewards_mean           2645.215662679322
total_rewards_std            1481.9893795393498
total_rewards_max            5108.742087338098
total_rewards_min            1077.305065026707
Number of train steps total  185000
Number of env steps total    927000
Number of rollouts total     0
Train Time (s)               30.510503518395126
(Previous) Eval Time (s)     17.491622402798384
Sample Time (s)              19.147706917021424
Epoch Time (s)               67.14983283821493
Total Train Time (s)         9679.299180241767
Epoch                        184
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:57:01.288738 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #184 | Epoch Duration: 65.62806272506714
2020-01-10 20:57:01.289003 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #184 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04310996
Z variance train             0.048936624
KL Divergence                5.1983433
KL Loss                      0.51983434
QF Loss                      1132.0864
VF Loss                      363.80887
Policy Loss                  -1062.4219
Q Predictions Mean           1057.3535
Q Predictions Std            933.97595
Q Predictions Max            2196.7935
Q Predictions Min            16.107746
V Predictions Mean           1054.1111
V Predictions Std            923.99304
V Predictions Max            2170.4758
V Predictions Min            24.778542
Log Pis Mean                 -4.787854
Log Pis Std                  6.7470617
Log Pis Max                  13.536746
Log Pis Min                  -13.725691
Policy mu Mean               0.2528943
Policy mu Std                0.69639164
Policy mu Max                2.4158092
Policy mu Min                -2.878755
Policy log std Mean          -0.27459502
Policy log std Std           0.16156302
Policy log std Max           -0.0670821
Policy log std Min           -0.8983844
Z mean eval                  0.040730916
Z variance eval              0.048134573
total_rewards                [2077.49113802 1788.86765587  949.33122507  696.39584784 1413.50124134
 1326.64505047 1218.110038    965.71956654 2478.22089516 1187.68536986]
total_rewards_mean           1410.1968028172837
total_rewards_std            523.6619311985429
total_rewards_max            2478.220895157031
total_rewards_min            696.3958478416254
Number of train steps total  186000
Number of env steps total    932000
Number of rollouts total     0
Train Time (s)               28.68336513917893
(Previous) Eval Time (s)     15.969542117789388
Sample Time (s)              19.288817456457764
Epoch Time (s)               63.94172471342608
Total Train Time (s)         9735.37289664615
Epoch                        185
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:57:57.362581 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #185 | Epoch Duration: 56.073402881622314
2020-01-10 20:57:57.362727 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #185 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040622268
Z variance train             0.0481328
KL Divergence                5.2464485
KL Loss                      0.52464485
QF Loss                      1348.5625
VF Loss                      416.97522
Policy Loss                  -1068.9591
Q Predictions Mean           1067.4402
Q Predictions Std            929.67523
Q Predictions Max            2219.3748
Q Predictions Min            16.690483
V Predictions Mean           1072.6721
V Predictions Std            923.66785
V Predictions Max            2208.212
V Predictions Min            29.04719
Log Pis Mean                 -4.1058893
Log Pis Std                  7.371989
Log Pis Max                  25.94606
Log Pis Min                  -13.603908
Policy mu Mean               0.2952708
Policy mu Std                0.7436399
Policy mu Max                3.0868177
Policy mu Min                -3.3591096
Policy log std Mean          -0.28599343
Policy log std Std           0.16591024
Policy log std Max           -0.017742708
Policy log std Min           -1.0316486
Z mean eval                  0.037984423
Z variance eval              0.046465054
total_rewards                [2617.51954677 5071.08388347 3111.0353857  1536.06635131 1355.54550189
 2325.66737197 3302.05730457 2492.14714697 4584.01091028 1230.09201913]
total_rewards_mean           2762.522542204245
total_rewards_std            1231.9467502428533
total_rewards_max            5071.083883471165
total_rewards_min            1230.0920191253288
Number of train steps total  187000
Number of env steps total    937000
Number of rollouts total     0
Train Time (s)               31.809301215223968
(Previous) Eval Time (s)     8.10090040229261
Sample Time (s)              18.634361004456878
Epoch Time (s)               58.544562621973455
Total Train Time (s)         9801.859154247679
Epoch                        186
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:59:03.851722 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #186 | Epoch Duration: 66.48887872695923
2020-01-10 20:59:03.851916 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #186 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0381198
Z variance train             0.046454154
KL Divergence                5.3413353
KL Loss                      0.53413355
QF Loss                      1862.5532
VF Loss                      409.46066
Policy Loss                  -1114.3948
Q Predictions Mean           1108.0614
Q Predictions Std            947.0263
Q Predictions Max            2223.1606
Q Predictions Min            17.273203
V Predictions Mean           1109.6252
V Predictions Std            937.9876
V Predictions Max            2197.5522
V Predictions Min            29.011345
Log Pis Mean                 -4.626284
Log Pis Std                  6.7320623
Log Pis Max                  19.704807
Log Pis Min                  -13.106439
Policy mu Mean               0.25644627
Policy mu Std                0.70982057
Policy mu Max                2.4616146
Policy mu Min                -2.8212326
Policy log std Mean          -0.27787763
Policy log std Std           0.16320468
Policy log std Max           -0.034402072
Policy log std Min           -0.8453351
Z mean eval                  0.03515008
Z variance eval              0.044601165
total_rewards                [2785.88685811 1570.66089876  911.228185   5004.42203006 5072.40642801
 1868.45761361 3258.03579155 5030.62990816 5031.16578403 2183.81671097]
total_rewards_mean           3271.671020827428
total_rewards_std            1558.478909393923
total_rewards_max            5072.406428012834
total_rewards_min            911.228185003515
Number of train steps total  188000
Number of env steps total    942000
Number of rollouts total     0
Train Time (s)               31.324161848053336
(Previous) Eval Time (s)     16.04487324366346
Sample Time (s)              18.938089470379055
Epoch Time (s)               66.30712456209585
Total Train Time (s)         9871.548860268667
Epoch                        187
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:00:13.545887 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #187 | Epoch Duration: 69.69380211830139
2020-01-10 21:00:13.546178 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #187 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035150696
Z variance train             0.044627465
KL Divergence                5.4215965
KL Loss                      0.5421597
QF Loss                      1867.2566
VF Loss                      265.78897
Policy Loss                  -1124.3887
Q Predictions Mean           1114.9427
Q Predictions Std            934.43207
Q Predictions Max            2207.4504
Q Predictions Min            16.680498
V Predictions Mean           1127.3953
V Predictions Std            936.46155
V Predictions Max            2206.7864
V Predictions Min            27.876438
Log Pis Mean                 -4.506099
Log Pis Std                  6.8251147
Log Pis Max                  16.571152
Log Pis Min                  -14.220602
Policy mu Mean               0.25116885
Policy mu Std                0.7441586
Policy mu Max                2.6375196
Policy mu Min                -2.9047537
Policy log std Mean          -0.2834115
Policy log std Std           0.16328043
Policy log std Max           -0.051580153
Policy log std Min           -0.8511062
Z mean eval                  0.03601303
Z variance eval              0.04317497
total_rewards                [4915.68559869 2629.39638424 3426.04308809 5072.21132871 2703.97151417
 2271.17164369 4810.39094595 4965.58984663 4966.73886419 4962.00093384]
total_rewards_mean           4072.3200148215847
total_rewards_std            1107.3147971120181
total_rewards_max            5072.211328712025
total_rewards_min            2271.171643689497
Number of train steps total  189000
Number of env steps total    947000
Number of rollouts total     0
Train Time (s)               30.80354418605566
(Previous) Eval Time (s)     19.4312450774014
Sample Time (s)              19.091743024997413
Epoch Time (s)               69.32653228845447
Total Train Time (s)         9946.010796285234
Epoch                        188
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:01:28.010265 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #188 | Epoch Duration: 74.46386933326721
2020-01-10 21:01:28.010493 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #188 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035641365
Z variance train             0.043193962
KL Divergence                5.499551
KL Loss                      0.54995507
QF Loss                      1305.4263
VF Loss                      470.8662
Policy Loss                  -1071.8132
Q Predictions Mean           1068.6351
Q Predictions Std            935.44885
Q Predictions Max            2198.8257
Q Predictions Min            15.885109
V Predictions Mean           1077.7937
V Predictions Std            935.2541
V Predictions Max            2210.9614
V Predictions Min            24.278873
Log Pis Mean                 -4.840087
Log Pis Std                  6.7705445
Log Pis Max                  22.111866
Log Pis Min                  -14.342339
Policy mu Mean               0.26822534
Policy mu Std                0.70551264
Policy mu Max                3.419094
Policy mu Min                -2.8854976
Policy log std Mean          -0.27129966
Policy log std Std           0.16175243
Policy log std Max           -0.026408121
Policy log std Min           -0.9185446
Z mean eval                  0.035953
Z variance eval              0.042543225
total_rewards                [5077.74418471 5027.84962904 1237.69896414 5042.8084336  3176.99805967
 3245.64736255 5003.83905211 4256.78024825 1552.35817561 5080.38766147]
total_rewards_mean           3870.2111771145646
total_rewards_std            1422.8671574473717
total_rewards_max            5080.387661470712
total_rewards_min            1237.6989641438377
Number of train steps total  190000
Number of env steps total    952000
Number of rollouts total     0
Train Time (s)               29.707852988969535
(Previous) Eval Time (s)     24.56829989887774
Sample Time (s)              20.039829983841628
Epoch Time (s)               74.3159828716889
Total Train Time (s)         10018.12508303579
Epoch                        189
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:02:40.128844 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #189 | Epoch Duration: 72.11815524101257
2020-01-10 21:02:40.129126 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #189 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035710383
Z variance train             0.04252723
KL Divergence                5.5468807
KL Loss                      0.5546881
QF Loss                      1799.1832
VF Loss                      796.31
Policy Loss                  -1081.919
Q Predictions Mean           1074.7661
Q Predictions Std            914.0839
Q Predictions Max            2193.0056
Q Predictions Min            17.241129
V Predictions Mean           1095.0298
V Predictions Std            919.20056
V Predictions Max            2218.5684
V Predictions Min            25.421572
Log Pis Mean                 -3.7899184
Log Pis Std                  7.5694804
Log Pis Max                  29.480694
Log Pis Min                  -13.6596985
Policy mu Mean               0.26125222
Policy mu Std                0.7669351
Policy mu Max                3.044481
Policy mu Min                -3.2219162
Policy log std Mean          -0.29050317
Policy log std Std           0.17017987
Policy log std Max           -0.0801157
Policy log std Min           -0.9562322
Z mean eval                  0.033542745
Z variance eval              0.044105113
total_rewards                [2449.82818715 1322.16580111 1744.82789724 4042.09752788 4442.83907129
 1090.09935488 2562.6095161  2141.36473094 2108.9880477  4971.55026056]
total_rewards_mean           2687.637039482782
total_rewards_std            1270.532071472246
total_rewards_max            4971.550260562862
total_rewards_min            1090.0993548754238
Number of train steps total  191000
Number of env steps total    957000
Number of rollouts total     0
Train Time (s)               29.29344047792256
(Previous) Eval Time (s)     22.370149481110275
Sample Time (s)              19.30938108637929
Epoch Time (s)               70.97297104541212
Total Train Time (s)         10082.177774849348
Epoch                        190
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:03:44.183688 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #190 | Epoch Duration: 64.05435967445374
2020-01-10 21:03:44.183896 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #190 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0338751
Z variance train             0.044087872
KL Divergence                5.447865
KL Loss                      0.5447865
QF Loss                      1798.2422
VF Loss                      751.1485
Policy Loss                  -1087.9175
Q Predictions Mean           1076.9873
Q Predictions Std            935.9423
Q Predictions Max            2215.5225
Q Predictions Min            13.768699
V Predictions Mean           1078.1609
V Predictions Std            926.15894
V Predictions Max            2216.799
V Predictions Min            23.575464
Log Pis Mean                 -4.380626
Log Pis Std                  7.1229753
Log Pis Max                  20.407925
Log Pis Min                  -13.908377
Policy mu Mean               0.26424852
Policy mu Std                0.72116035
Policy mu Max                2.8272922
Policy mu Min                -2.6099913
Policy log std Mean          -0.27146998
Policy log std Std           0.16090845
Policy log std Max           -0.028888822
Policy log std Min           -0.8729315
Z mean eval                  0.033658758
Z variance eval              0.042360254
total_rewards                [5054.21717904  931.81659279 4444.68783423 1994.41921664 1126.73058575
 4733.7306641  3256.33684892  849.07446403 2908.91598227 1498.37684272]
total_rewards_mean           2679.830621048851
total_rewards_std            1550.5076627589483
total_rewards_max            5054.217179038613
total_rewards_min            849.0744640295418
Number of train steps total  192000
Number of env steps total    962000
Number of rollouts total     0
Train Time (s)               32.31827328586951
(Previous) Eval Time (s)     15.451248966623098
Sample Time (s)              19.029699594248086
Epoch Time (s)               66.79922184674069
Total Train Time (s)         10149.3045098125
Epoch                        191
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:04:51.313868 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #191 | Epoch Duration: 67.12980914115906
2020-01-10 21:04:51.314098 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #191 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033491097
Z variance train             0.042365544
KL Divergence                5.5651855
KL Loss                      0.55651855
QF Loss                      1305.8384
VF Loss                      342.71503
Policy Loss                  -1152.5713
Q Predictions Mean           1141.1012
Q Predictions Std            935.3094
Q Predictions Max            2227.9954
Q Predictions Min            18.318317
V Predictions Mean           1156.3481
V Predictions Std            937.576
V Predictions Max            2219.8787
V Predictions Min            27.511454
Log Pis Mean                 -4.220793
Log Pis Std                  6.65095
Log Pis Max                  14.879238
Log Pis Min                  -13.440561
Policy mu Mean               0.26360255
Policy mu Std                0.75496763
Policy mu Max                2.5234177
Policy mu Min                -2.9178216
Policy log std Mean          -0.28630745
Policy log std Std           0.15912636
Policy log std Max           -0.052561477
Policy log std Min           -0.86381304
Z mean eval                  0.03164665
Z variance eval              0.041655205
total_rewards                [5029.74740842 3011.25088258 5030.56964038 2099.47252587 1714.15614874
 4738.88229296 5014.36114996  881.8972166  1172.12623157 4974.14009068]
total_rewards_mean           3366.6603587758063
total_rewards_std            1678.3692569412592
total_rewards_max            5030.569640378655
total_rewards_min            881.8972166041223
Number of train steps total  193000
Number of env steps total    967000
Number of rollouts total     0
Train Time (s)               32.19214996602386
(Previous) Eval Time (s)     15.781536410097033
Sample Time (s)              20.18801589962095
Epoch Time (s)               68.16170227574185
Total Train Time (s)         10221.07503942633
Epoch                        192
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:06:03.089398 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #192 | Epoch Duration: 71.7750940322876
2020-01-10 21:06:03.089710 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #192 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031547084
Z variance train             0.041653086
KL Divergence                5.5993032
KL Loss                      0.5599303
QF Loss                      1313.1511
VF Loss                      408.43402
Policy Loss                  -1188.9976
Q Predictions Mean           1183.8077
Q Predictions Std            940.1218
Q Predictions Max            2228.141
Q Predictions Min            15.677752
V Predictions Mean           1187.2877
V Predictions Std            934.6658
V Predictions Max            2226.0928
V Predictions Min            26.893053
Log Pis Mean                 -4.1026635
Log Pis Std                  6.857554
Log Pis Max                  15.159134
Log Pis Min                  -13.607664
Policy mu Mean               0.29047945
Policy mu Std                0.7409143
Policy mu Max                2.5852802
Policy mu Min                -2.414989
Policy log std Mean          -0.291981
Policy log std Std           0.1744545
Policy log std Max           -0.03275699
Policy log std Min           -0.9101656
Z mean eval                  0.03144941
Z variance eval              0.039749194
total_rewards                [4304.14671673 4964.73128949 1093.75184392 4973.35963971 5033.62360484
 5012.81683689 5022.10615114 4801.83645772 3620.10445294 4923.66282559]
total_rewards_mean           4375.013981899061
total_rewards_std            1174.3021836706669
total_rewards_max            5033.623604843724
total_rewards_min            1093.7518439193502
Number of train steps total  194000
Number of env steps total    972000
Number of rollouts total     0
Train Time (s)               31.42729291692376
(Previous) Eval Time (s)     19.394596594851464
Sample Time (s)              19.461867063306272
Epoch Time (s)               70.2837565750815
Total Train Time (s)         10297.758670132142
Epoch                        193
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:07:19.776259 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #193 | Epoch Duration: 76.68629288673401
2020-01-10 21:07:19.776559 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #193 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031514984
Z variance train             0.03976647
KL Divergence                5.7078004
KL Loss                      0.57078004
QF Loss                      1579.48
VF Loss                      418.2515
Policy Loss                  -1119.5927
Q Predictions Mean           1106.3639
Q Predictions Std            935.7141
Q Predictions Max            2217.2566
Q Predictions Min            13.824341
V Predictions Mean           1117.1858
V Predictions Std            931.26074
V Predictions Max            2223.8503
V Predictions Min            27.53145
Log Pis Mean                 -3.8588486
Log Pis Std                  7.5690327
Log Pis Max                  19.232239
Log Pis Min                  -12.991938
Policy mu Mean               0.24386992
Policy mu Std                0.7719315
Policy mu Max                2.7658272
Policy mu Min                -3.2084737
Policy log std Mean          -0.28626537
Policy log std Std           0.16216539
Policy log std Max           -0.030334957
Policy log std Min           -0.8034404
Z mean eval                  0.030792445
Z variance eval              0.039445646
total_rewards                [1613.39461465 1782.08779522 3620.11408447 1575.61881985 2040.57263133
 4670.6521404   901.47498061 1732.3740557  5137.20196477 3861.72812298]
total_rewards_mean           2693.5219209981287
total_rewards_std            1411.1190440946796
total_rewards_max            5137.201964771496
total_rewards_min            901.4749806142885
Number of train steps total  195000
Number of env steps total    977000
Number of rollouts total     0
Train Time (s)               31.555955849587917
(Previous) Eval Time (s)     25.796820412855595
Sample Time (s)              20.011347657069564
Epoch Time (s)               77.36412391951308
Total Train Time (s)         10364.622125680093
Epoch                        194
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:08:26.640517 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #194 | Epoch Duration: 66.86375117301941
2020-01-10 21:08:26.640669 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #194 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030917738
Z variance train             0.03944886
KL Divergence                5.7210875
KL Loss                      0.57210875
QF Loss                      1287.3245
VF Loss                      329.33438
Policy Loss                  -1149.8351
Q Predictions Mean           1142.7461
Q Predictions Std            943.97833
Q Predictions Max            2230.2488
Q Predictions Min            13.830819
V Predictions Mean           1147.478
V Predictions Std            940.1813
V Predictions Max            2226.0151
V Predictions Min            24.538599
Log Pis Mean                 -3.8859844
Log Pis Std                  7.5116005
Log Pis Max                  23.596754
Log Pis Min                  -13.159862
Policy mu Mean               0.26146272
Policy mu Std                0.7624166
Policy mu Max                3.189121
Policy mu Min                -3.34482
Policy log std Mean          -0.28408277
Policy log std Std           0.168138
Policy log std Max           -0.025035113
Policy log std Min           -0.89677256
Z mean eval                  0.031202918
Z variance eval              0.041312248
total_rewards                [5025.87262305 5006.31037419 3519.40440427 1147.31922758  973.29737422
 3147.50447625 1339.13392143 2370.60436685 4991.80922922 1098.64185733]
total_rewards_mean           2861.9897854378205
total_rewards_std            1628.1137208125494
total_rewards_max            5025.872623045664
total_rewards_min            973.2973742157972
Number of train steps total  196000
Number of env steps total    982000
Number of rollouts total     0
Train Time (s)               29.881661847699434
(Previous) Eval Time (s)     15.29612409742549
Sample Time (s)              18.76499957824126
Epoch Time (s)               63.94278552336618
Total Train Time (s)         10430.280410445761
Epoch                        195
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:09:32.302334 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #195 | Epoch Duration: 65.66152501106262
2020-01-10 21:09:32.302571 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #195 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031370692
Z variance train             0.041315425
KL Divergence                5.608832
KL Loss                      0.5608832
QF Loss                      1394.5719
VF Loss                      399.99713
Policy Loss                  -1105.4312
Q Predictions Mean           1092.7279
Q Predictions Std            945.7499
Q Predictions Max            2232.1736
Q Predictions Min            15.924878
V Predictions Mean           1108.5964
V Predictions Std            948.90625
V Predictions Max            2240.4443
V Predictions Min            25.869526
Log Pis Mean                 -4.0249815
Log Pis Std                  7.628635
Log Pis Max                  24.207418
Log Pis Min                  -15.867526
Policy mu Mean               0.28549957
Policy mu Std                0.7436075
Policy mu Max                2.4107656
Policy mu Min                -2.8087602
Policy log std Mean          -0.28372732
Policy log std Std           0.16367133
Policy log std Max           -0.036927707
Policy log std Min           -0.895741
Z mean eval                  0.025244066
Z variance eval              0.03921537
total_rewards                [3408.85441674 1623.19997195 5086.6986096  5107.01034257 3086.36910699
 2015.3371325  5098.62875256 2635.92917534 5179.99730121 1899.16502662]
total_rewards_mean           3514.1189836085787
total_rewards_std            1403.2603925473445
total_rewards_max            5179.997301209297
total_rewards_min            1623.1999719478774
Number of train steps total  197000
Number of env steps total    987000
Number of rollouts total     0
Train Time (s)               29.225039602722973
(Previous) Eval Time (s)     17.014558168128133
Sample Time (s)              19.022723250556737
Epoch Time (s)               65.26232102140784
Total Train Time (s)         10499.243702989072
Epoch                        196
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:10:41.267213 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #196 | Epoch Duration: 68.96447777748108
2020-01-10 21:10:41.267410 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #196 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02504307
Z variance train             0.03919342
KL Divergence                5.747039
KL Loss                      0.5747039
QF Loss                      1711.7578
VF Loss                      855.30804
Policy Loss                  -1234.443
Q Predictions Mean           1229.7661
Q Predictions Std            916.28503
Q Predictions Max            2244.7756
Q Predictions Min            15.950275
V Predictions Mean           1248.0668
V Predictions Std            924.20703
V Predictions Max            2280.9248
V Predictions Min            26.106394
Log Pis Mean                 -2.702684
Log Pis Std                  7.6350718
Log Pis Max                  32.32879
Log Pis Min                  -15.420637
Policy mu Mean               0.32207617
Policy mu Std                0.79957825
Policy mu Max                3.3591871
Policy mu Min                -3.2261465
Policy log std Mean          -0.30912653
Policy log std Std           0.17300718
Policy log std Max           0.015136197
Policy log std Min           -0.88061786
Z mean eval                  0.028619999
Z variance eval              0.04059881
total_rewards                [1911.93798803 1219.7575783  3761.87018117 2252.59551449 3880.53954983
 3327.54913008 2129.38747446 5066.83595687 2264.9711961  1221.56027724]
total_rewards_mean           2703.700484657577
total_rewards_std            1192.8871780514344
total_rewards_max            5066.835956865962
total_rewards_min            1219.7575783022037
Number of train steps total  198000
Number of env steps total    992000
Number of rollouts total     0
Train Time (s)               32.875448178034276
(Previous) Eval Time (s)     20.71633945312351
Sample Time (s)              19.524504339322448
Epoch Time (s)               73.11629197048023
Total Train Time (s)         10567.697448255494
Epoch                        197
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:11:49.724735 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #197 | Epoch Duration: 68.45716524124146
2020-01-10 21:11:49.725017 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #197 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028622607
Z variance train             0.0405923
KL Divergence                5.6717954
KL Loss                      0.56717956
QF Loss                      1315.8513
VF Loss                      540.70734
Policy Loss                  -1124.3618
Q Predictions Mean           1119.3596
Q Predictions Std            961.1015
Q Predictions Max            2253.9507
Q Predictions Min            16.603373
V Predictions Mean           1122.1548
V Predictions Std            956.227
V Predictions Max            2241.2505
V Predictions Min            27.945763
Log Pis Mean                 -3.8436034
Log Pis Std                  7.327923
Log Pis Max                  18.681961
Log Pis Min                  -13.645176
Policy mu Mean               0.2849666
Policy mu Std                0.74677175
Policy mu Max                3.4794497
Policy mu Min                -2.682502
Policy log std Mean          -0.28143433
Policy log std Std           0.16581333
Policy log std Max           -0.029440105
Policy log std Min           -0.8991608
Z mean eval                  0.027636766
Z variance eval              0.04185867
total_rewards                [3297.98808454 5029.84510447 4420.78584325 5080.39954915 1507.62875079
 5082.03743738 1646.18490469  519.73276743 5046.10702875 3247.23841123]
total_rewards_mean           3487.794788167293
total_rewards_std            1642.2727753954562
total_rewards_max            5082.037437377315
total_rewards_min            519.7327674257405
Number of train steps total  199000
Number of env steps total    997000
Number of rollouts total     0
Train Time (s)               31.465750867966563
(Previous) Eval Time (s)     16.056886028964072
Sample Time (s)              19.186749314889312
Epoch Time (s)               66.70938621181995
Total Train Time (s)         10638.736714628525
Epoch                        198
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:13:00.768135 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #198 | Epoch Duration: 71.04289817810059
2020-01-10 21:13:00.768426 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #198 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027869219
Z variance train             0.041865427
KL Divergence                5.575942
KL Loss                      0.55759424
QF Loss                      987.96765
VF Loss                      553.9047
Policy Loss                  -1162.0703
Q Predictions Mean           1151.4307
Q Predictions Std            942.5211
Q Predictions Max            2247.944
Q Predictions Min            15.833226
V Predictions Mean           1157.5137
V Predictions Std            936.1754
V Predictions Max            2235.1848
V Predictions Min            23.463818
Log Pis Mean                 -3.944435
Log Pis Std                  7.4382577
Log Pis Max                  30.495953
Log Pis Min                  -14.493174
Policy mu Mean               0.24238059
Policy mu Std                0.7694887
Policy mu Max                3.6735609
Policy mu Min                -3.0092115
Policy log std Mean          -0.28706115
Policy log std Std           0.1633652
Policy log std Max           -0.042670965
Policy log std Min           -1.0133165
Z mean eval                  0.028638825
Z variance eval              0.041905575
total_rewards                [4989.19907146 2469.05553962 1002.2045013  1957.01066482 5060.58375283
 2713.99937922 1922.40815867 1650.64097872 1029.91135675 5071.00780094]
total_rewards_mean           2786.6021204332474
total_rewards_std            1560.2096109161794
total_rewards_max            5071.007800944055
total_rewards_min            1002.2045013010869
Number of train steps total  200000
Number of env steps total    1002000
Number of rollouts total     0
Train Time (s)               30.527102175634354
(Previous) Eval Time (s)     20.390069260261953
Sample Time (s)              19.43385523511097
Epoch Time (s)               70.35102667100728
Total Train Time (s)         10705.114419456571
Epoch                        199
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:14:07.146949 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #199 | Epoch Duration: 66.37832140922546
2020-01-10 21:14:07.147106 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #199 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028948318
Z variance train             0.041888136
KL Divergence                5.5944986
KL Loss                      0.55944985
QF Loss                      1361.2643
VF Loss                      477.18073
Policy Loss                  -1280.1552
Q Predictions Mean           1269.7462
Q Predictions Std            959.3044
Q Predictions Max            2267.7517
Q Predictions Min            16.273932
V Predictions Mean           1270.2975
V Predictions Std            950.58527
V Predictions Max            2256.4944
V Predictions Min            25.902422
Log Pis Mean                 -3.5047002
Log Pis Std                  7.2125983
Log Pis Max                  18.087425
Log Pis Min                  -12.912048
Policy mu Mean               0.2990071
Policy mu Std                0.7694043
Policy mu Max                2.7407007
Policy mu Min                -2.3513916
Policy log std Mean          -0.29791978
Policy log std Std           0.16691583
Policy log std Max           -0.072189495
Policy log std Min           -0.91023135
Z mean eval                  0.028144648
Z variance eval              0.039610375
total_rewards                [3619.55793463 1873.32228177 1016.79537283  871.13025161 5086.37205918
  729.77009041  874.76017917 3045.52842484 1549.5187204  3283.52047059]
total_rewards_mean           2195.027578542392
total_rewards_std            1408.8479288342833
total_rewards_max            5086.372059177869
total_rewards_min            729.7700904082803
Number of train steps total  201000
Number of env steps total    1007000
Number of rollouts total     0
Train Time (s)               31.214602364227176
(Previous) Eval Time (s)     16.417085194028914
Sample Time (s)              19.439001207239926
Epoch Time (s)               67.07068876549602
Total Train Time (s)         10768.57494741911
Epoch                        200
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:15:10.609182 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #200 | Epoch Duration: 63.46195864677429
2020-01-10 21:15:10.609360 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #200 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028122285
Z variance train             0.039620213
KL Divergence                5.725684
KL Loss                      0.5725684
QF Loss                      1753.5122
VF Loss                      316.88965
Policy Loss                  -1342.5249
Q Predictions Mean           1338.7216
Q Predictions Std            935.12366
Q Predictions Max            2271.2458
Q Predictions Min            13.265395
V Predictions Mean           1338.0087
V Predictions Std            927.8472
V Predictions Max            2261.3733
V Predictions Min            25.838152
Log Pis Mean                 -3.7413008
Log Pis Std                  6.714703
Log Pis Max                  20.252666
Log Pis Min                  -14.030409
Policy mu Mean               0.27447057
Policy mu Std                0.7697103
Policy mu Max                3.13351
Policy mu Min                -3.172793
Policy log std Mean          -0.28854743
Policy log std Std           0.16122515
Policy log std Max           -0.07859941
Policy log std Min           -0.91736674
Z mean eval                  0.026464108
Z variance eval              0.039156664
total_rewards                [1223.46939983 5023.25268221 5057.50178683 5034.03449117 1435.6688638
 5027.08673208 1705.24026168  945.62197529 5058.42067609 2923.26309546]
total_rewards_mean           3343.3559964430183
total_rewards_std            1764.5780658368826
total_rewards_max            5058.42067609212
total_rewards_min            945.6219752853511
Number of train steps total  202000
Number of env steps total    1012000
Number of rollouts total     0
Train Time (s)               30.469021238852292
(Previous) Eval Time (s)     12.808047960046679
Sample Time (s)              19.31066887965426
Epoch Time (s)               62.58773807855323
Total Train Time (s)         10837.695301702712
Epoch                        201
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:16:19.734214 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #201 | Epoch Duration: 69.12471055984497
2020-01-10 21:16:19.734473 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #201 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026785523
Z variance train             0.03915642
KL Divergence                5.754321
KL Loss                      0.5754321
QF Loss                      1699.6624
VF Loss                      572.8993
Policy Loss                  -1216.0896
Q Predictions Mean           1208.4885
Q Predictions Std            962.6698
Q Predictions Max            2258.2278
Q Predictions Min            15.360878
V Predictions Mean           1203.1671
V Predictions Std            948.9691
V Predictions Max            2240.329
V Predictions Min            26.346325
Log Pis Mean                 -3.823221
Log Pis Std                  6.9701204
Log Pis Max                  20.016808
Log Pis Min                  -13.404871
Policy mu Mean               0.2810054
Policy mu Std                0.74852765
Policy mu Max                2.8387113
Policy mu Min                -2.5715747
Policy log std Mean          -0.28460318
Policy log std Std           0.16232957
Policy log std Max           -0.0051566064
Policy log std Min           -1.0100319
Z mean eval                  0.026462013
Z variance eval              0.03956961
total_rewards                [4980.23128671 1096.19615677 2442.80287291 2950.24897046 4986.9874109
 4813.12513852 4400.2563967  1374.75583618 5015.96819489 2709.46235321]
total_rewards_mean           3477.0034617265205
total_rewards_std            1468.6600694275364
total_rewards_max            5015.968194894949
total_rewards_min            1096.1961567734118
Number of train steps total  203000
Number of env steps total    1017000
Number of rollouts total     0
Train Time (s)               29.107594455126673
(Previous) Eval Time (s)     19.344686604104936
Sample Time (s)              19.153125355020165
Epoch Time (s)               67.60540641425177
Total Train Time (s)         10908.144136316609
Epoch                        202
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:17:30.187806 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #202 | Epoch Duration: 70.45299196243286
2020-01-10 21:17:30.188105 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #202 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027004804
Z variance train             0.039558154
KL Divergence                5.7456737
KL Loss                      0.5745674
QF Loss                      1843.9554
VF Loss                      627.71277
Policy Loss                  -1279.1908
Q Predictions Mean           1268.9924
Q Predictions Std            940.9511
Q Predictions Max            2265.1626
Q Predictions Min            16.950151
V Predictions Mean           1269.742
V Predictions Std            932.95654
V Predictions Max            2272.1965
V Predictions Min            25.337551
Log Pis Mean                 -4.1952295
Log Pis Std                  6.1492968
Log Pis Max                  19.57556
Log Pis Min                  -13.109549
Policy mu Mean               0.31768322
Policy mu Std                0.7297733
Policy mu Max                2.7976143
Policy mu Min                -2.8700938
Policy log std Mean          -0.29056016
Policy log std Std           0.15430866
Policy log std Max           0.009912476
Policy log std Min           -0.99692
Z mean eval                  0.031006401
Z variance eval              0.040733792
total_rewards                [3847.73486126 4202.00189648 1141.32726767 4096.81132958 1267.15403695
 4103.96156295 5065.21777332 5149.80175155 1856.82403558 5096.81653626]
total_rewards_mean           3582.7651051598177
total_rewards_std            1491.1981710514815
total_rewards_max            5149.801751547012
total_rewards_min            1141.327267669891
Number of train steps total  204000
Number of env steps total    1022000
Number of rollouts total     0
Train Time (s)               32.56027152668685
(Previous) Eval Time (s)     22.19210471911356
Sample Time (s)              19.712921069469303
Epoch Time (s)               74.46529731526971
Total Train Time (s)         10980.96366247302
Epoch                        203
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:18:43.008199 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #203 | Epoch Duration: 72.81989336013794
2020-01-10 21:18:43.008385 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #203 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031366456
Z variance train             0.040719297
KL Divergence                5.7035885
KL Loss                      0.5703589
QF Loss                      2170.1714
VF Loss                      513.8741
Policy Loss                  -1300.3542
Q Predictions Mean           1291.8916
Q Predictions Std            937.45166
Q Predictions Max            2276.9412
Q Predictions Min            16.886135
V Predictions Mean           1295.9868
V Predictions Std            932.7869
V Predictions Max            2269.0164
V Predictions Min            26.066572
Log Pis Mean                 -3.1997976
Log Pis Std                  7.4469423
Log Pis Max                  24.471758
Log Pis Min                  -14.110402
Policy mu Mean               0.28244013
Policy mu Std                0.8132476
Policy mu Max                2.7430391
Policy mu Min                -2.9134538
Policy log std Mean          -0.30806738
Policy log std Std           0.17009713
Policy log std Max           -0.04758881
Policy log std Min           -0.991652
Z mean eval                  0.032464474
Z variance eval              0.041018546
total_rewards                [4362.52337464  925.94835179 4586.05498523 5067.2539389  1755.45602816
 3729.36284314 1775.807393   4663.52913858 3278.45025732 1328.72890922]
total_rewards_mean           3147.3115219990473
total_rewards_std            1481.4783426798763
total_rewards_max            5067.253938902917
total_rewards_min            925.9483517863712
Number of train steps total  205000
Number of env steps total    1027000
Number of rollouts total     0
Train Time (s)               28.668740226887167
(Previous) Eval Time (s)     20.546346626244485
Sample Time (s)              19.81535291299224
Epoch Time (s)               69.03043976612389
Total Train Time (s)         11048.053524204995
Epoch                        204
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:19:50.101522 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #204 | Epoch Duration: 67.09300088882446
2020-01-10 21:19:50.101696 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #204 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031967133
Z variance train             0.0410274
KL Divergence                5.638197
KL Loss                      0.5638197
QF Loss                      1554.9751
VF Loss                      567.9967
Policy Loss                  -1260.2593
Q Predictions Mean           1257.4286
Q Predictions Std            959.5478
Q Predictions Max            2268.6033
Q Predictions Min            13.4897175
V Predictions Mean           1270.8276
V Predictions Std            962.4339
V Predictions Max            2284.888
V Predictions Min            25.98063
Log Pis Mean                 -4.4122066
Log Pis Std                  6.783132
Log Pis Max                  17.10992
Log Pis Min                  -14.33546
Policy mu Mean               0.2704121
Policy mu Std                0.744225
Policy mu Max                3.203708
Policy mu Min                -4.214845
Policy log std Mean          -0.28571716
Policy log std Std           0.1614883
Policy log std Max           -0.0084604025
Policy log std Min           -0.8850059
Z mean eval                  0.035412107
Z variance eval              0.039359353
total_rewards                [5088.18754655 4858.48896826 4281.63226367 2412.59494547 5012.32717478
 5124.09177925 5106.16518097  892.16737629 5054.65112447 5093.88395007]
total_rewards_mean           4292.41903097862
total_rewards_std            1383.6445656141561
total_rewards_max            5124.091779247016
total_rewards_min            892.1673762890474
Number of train steps total  206000
Number of env steps total    1032000
Number of rollouts total     0
Train Time (s)               30.246351511683315
(Previous) Eval Time (s)     18.60859286878258
Sample Time (s)              20.2010881411843
Epoch Time (s)               69.0560325216502
Total Train Time (s)         11123.414485485293
Epoch                        205
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:21:05.464715 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #205 | Epoch Duration: 75.36285543441772
2020-01-10 21:21:05.464934 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #205 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035598602
Z variance train             0.039355926
KL Divergence                5.7394633
KL Loss                      0.57394636
QF Loss                      1828.2832
VF Loss                      542.139
Policy Loss                  -1277.2083
Q Predictions Mean           1274.5889
Q Predictions Std            936.1841
Q Predictions Max            2298.019
Q Predictions Min            17.059614
V Predictions Mean           1282.9481
V Predictions Std            932.5705
V Predictions Max            2278.9075
V Predictions Min            28.25006
Log Pis Mean                 -3.3063304
Log Pis Std                  6.9725084
Log Pis Max                  19.982632
Log Pis Min                  -12.831554
Policy mu Mean               0.2989769
Policy mu Std                0.7699621
Policy mu Max                3.2564242
Policy mu Min                -2.9510655
Policy log std Mean          -0.29546046
Policy log std Std           0.15919374
Policy log std Max           -0.0007735491
Policy log std Min           -0.95102775
Z mean eval                  0.034472726
Z variance eval              0.03804194
total_rewards                [1490.1021451  4067.05648321  987.96749916 4414.18217323 5090.72768568
 5169.39080283 4219.4099861  1852.28483789 3449.30163737 5058.99340326]
total_rewards_mean           3579.941665382909
total_rewards_std            1497.5379473081914
total_rewards_max            5169.390802832742
total_rewards_min            987.9674991580861
Number of train steps total  207000
Number of env steps total    1037000
Number of rollouts total     0
Train Time (s)               29.373728330247104
(Previous) Eval Time (s)     24.915077870246023
Sample Time (s)              19.113560297060758
Epoch Time (s)               73.40236649755388
Total Train Time (s)         11192.676010231487
Epoch                        206
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:22:14.730245 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #206 | Epoch Duration: 69.26513314247131
2020-01-10 21:22:14.730499 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #206 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034498744
Z variance train             0.038040318
KL Divergence                5.8290963
KL Loss                      0.58290964
QF Loss                      1373.104
VF Loss                      347.50528
Policy Loss                  -1223.3812
Q Predictions Mean           1217.0999
Q Predictions Std            951.18524
Q Predictions Max            2282.0413
Q Predictions Min            19.805958
V Predictions Mean           1224.6831
V Predictions Std            951.50104
V Predictions Max            2287.803
V Predictions Min            30.839592
Log Pis Mean                 -3.6174128
Log Pis Std                  7.2037735
Log Pis Max                  22.386929
Log Pis Min                  -16.235573
Policy mu Mean               0.29640484
Policy mu Std                0.7668081
Policy mu Max                2.6925306
Policy mu Min                -3.549145
Policy log std Mean          -0.299462
Policy log std Std           0.16624686
Policy log std Max           -0.02434422
Policy log std Min           -0.9247942
Z mean eval                  0.03648317
Z variance eval              0.038894553
total_rewards                [5035.1890061  1072.47541089 5007.1845518  5076.73427365 5058.93455315
 5032.92308223 4311.83657493 5006.70624695 2408.74949341 4493.58619717]
total_rewards_mean           4250.431939028567
total_rewards_std            1313.8991537531115
total_rewards_max            5076.734273653616
total_rewards_min            1072.47541089059
Number of train steps total  208000
Number of env steps total    1042000
Number of rollouts total     0
Train Time (s)               30.660489299334586
(Previous) Eval Time (s)     20.77754511963576
Sample Time (s)              19.790029557421803
Epoch Time (s)               71.22806397639215
Total Train Time (s)         11267.774480172899
Epoch                        207
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:23:29.832955 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #207 | Epoch Duration: 75.10225558280945
2020-01-10 21:23:29.833191 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #207 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036678992
Z variance train             0.0389148
KL Divergence                5.7779417
KL Loss                      0.5777942
QF Loss                      1520.4253
VF Loss                      929.4757
Policy Loss                  -1296.262
Q Predictions Mean           1293.2458
Q Predictions Std            961.7821
Q Predictions Max            2286.485
Q Predictions Min            17.42337
V Predictions Mean           1282.5842
V Predictions Std            949.57715
V Predictions Max            2286.4421
V Predictions Min            24.619106
Log Pis Mean                 -3.3191743
Log Pis Std                  7.582769
Log Pis Max                  30.69828
Log Pis Min                  -14.296112
Policy mu Mean               0.28652745
Policy mu Std                0.76936936
Policy mu Max                2.936515
Policy mu Min                -3.8174112
Policy log std Mean          -0.29027987
Policy log std Std           0.162712
Policy log std Max           -0.009907484
Policy log std Min           -0.9711093
Z mean eval                  0.033214115
Z variance eval              0.037889563
total_rewards                [ 706.38880901 4127.69606782 1377.56071575 2133.57966469 5106.8076764
 2967.98779918 3712.19113366 1810.38514724 1265.73218852 2307.26895763]
total_rewards_mean           2551.5598159905135
total_rewards_std            1332.4407068638882
total_rewards_max            5106.807676398614
total_rewards_min            706.3888090066974
Number of train steps total  209000
Number of env steps total    1047000
Number of rollouts total     0
Train Time (s)               30.35179172223434
(Previous) Eval Time (s)     24.651379307266325
Sample Time (s)              19.54929716512561
Epoch Time (s)               74.55246819462627
Total Train Time (s)         11333.19812258659
Epoch                        208
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:24:35.259698 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #208 | Epoch Duration: 65.4263014793396
2020-01-10 21:24:35.260002 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #208 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033189274
Z variance train             0.03789271
KL Divergence                5.827532
KL Loss                      0.5827532
QF Loss                      1463.153
VF Loss                      543.2438
Policy Loss                  -1300.2306
Q Predictions Mean           1292.0126
Q Predictions Std            950.7056
Q Predictions Max            2288.0007
Q Predictions Min            17.5041
V Predictions Mean           1298.616
V Predictions Std            944.7235
V Predictions Max            2292.0854
V Predictions Min            28.399553
Log Pis Mean                 -3.3707824
Log Pis Std                  6.6908603
Log Pis Max                  16.528126
Log Pis Min                  -14.513618
Policy mu Mean               0.29651
Policy mu Std                0.77883244
Policy mu Max                2.882622
Policy mu Min                -2.9793215
Policy log std Mean          -0.299993
Policy log std Std           0.16701838
Policy log std Max           -0.013679683
Policy log std Min           -0.9008853
Z mean eval                  0.034657255
Z variance eval              0.03920925
total_rewards                [3821.65658821 5081.29522202 1476.85955543 5170.80801426 3058.57645769
  381.84194455 1330.3195131  5190.48796613 1909.5545947   800.81641562]
total_rewards_mean           2822.2216271714888
total_rewards_std            1794.2395320285816
total_rewards_max            5190.487966133367
total_rewards_min            381.8419445512035
Number of train steps total  210000
Number of env steps total    1052000
Number of rollouts total     0
Train Time (s)               31.057226965669543
(Previous) Eval Time (s)     15.524869536980987
Sample Time (s)              19.514442835003138
Epoch Time (s)               66.09653933765367
Total Train Time (s)         11400.542870615143
Epoch                        209
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:25:42.606437 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #209 | Epoch Duration: 67.34623670578003
2020-01-10 21:25:42.606610 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #209 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03460548
Z variance train             0.03919462
KL Divergence                5.724283
KL Loss                      0.57242835
QF Loss                      1492.1387
VF Loss                      473.40176
Policy Loss                  -1260.6292
Q Predictions Mean           1253.6274
Q Predictions Std            986.8698
Q Predictions Max            2309.3125
Q Predictions Min            15.214797
V Predictions Mean           1257.3213
V Predictions Std            983.0391
V Predictions Max            2297.362
V Predictions Min            23.736738
Log Pis Mean                 -4.235394
Log Pis Std                  6.9665065
Log Pis Max                  16.332771
Log Pis Min                  -14.650883
Policy mu Mean               0.25386548
Policy mu Std                0.75384146
Policy mu Max                2.9710464
Policy mu Min                -2.752844
Policy log std Mean          -0.28438592
Policy log std Std           0.1543063
Policy log std Max           0.009982556
Policy log std Min           -0.84428674
Z mean eval                  0.034908377
Z variance eval              0.038075097
total_rewards                [2965.72467809 5090.90139823 5133.09213506 5124.3301249  5134.78845808
 1276.00551554 5088.94156378 2281.34337548 1639.55547446 5075.95657241]
total_rewards_mean           3881.0639296045106
total_rewards_std            1557.022654046902
total_rewards_max            5134.788458081221
total_rewards_min            1276.005515542993
Number of train steps total  211000
Number of env steps total    1057000
Number of rollouts total     0
Train Time (s)               30.954234819859266
(Previous) Eval Time (s)     16.77423836896196
Sample Time (s)              19.689081653021276
Epoch Time (s)               67.4175548418425
Total Train Time (s)         11473.337475717999
Epoch                        210
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:26:55.403529 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #210 | Epoch Duration: 72.79675889015198
2020-01-10 21:26:55.403742 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #210 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034958657
Z variance train             0.03807483
KL Divergence                5.790654
KL Loss                      0.57906544
QF Loss                      2178.9355
VF Loss                      558.839
Policy Loss                  -1315.4186
Q Predictions Mean           1309.7283
Q Predictions Std            977.60895
Q Predictions Max            2314.7832
Q Predictions Min            18.284634
V Predictions Mean           1315.019
V Predictions Std            973.79266
V Predictions Max            2306.6523
V Predictions Min            27.942986
Log Pis Mean                 -3.66768
Log Pis Std                  8.01057
Log Pis Max                  26.85854
Log Pis Min                  -12.970585
Policy mu Mean               0.26530844
Policy mu Std                0.7758993
Policy mu Max                3.1191027
Policy mu Min                -3.1370585
Policy log std Mean          -0.27964997
Policy log std Std           0.16217068
Policy log std Max           -0.04235001
Policy log std Min           -0.88149655
Z mean eval                  0.03256762
Z variance eval              0.03667327
total_rewards                [4212.8542962  5048.97188872 5160.28248781 2010.76381027 5073.46351285
 5059.27343629  996.09543607 1720.09491623 4824.59258316 1214.57973403]
total_rewards_mean           3532.0972101626694
total_rewards_std            1708.6236499046781
total_rewards_max            5160.28248781123
total_rewards_min            996.0954360654214
Number of train steps total  212000
Number of env steps total    1062000
Number of rollouts total     0
Train Time (s)               29.365848303306848
(Previous) Eval Time (s)     22.15313478279859
Sample Time (s)              18.95881540188566
Epoch Time (s)               70.4777984879911
Total Train Time (s)         11541.88062444143
Epoch                        211
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:28:03.960501 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #211 | Epoch Duration: 68.55655932426453
2020-01-10 21:28:03.960734 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #211 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032665353
Z variance train             0.03667303
KL Divergence                5.881998
KL Loss                      0.5881998
QF Loss                      1996.7922
VF Loss                      604.40784
Policy Loss                  -1330.3368
Q Predictions Mean           1325.6576
Q Predictions Std            959.3446
Q Predictions Max            2318.577
Q Predictions Min            14.925591
V Predictions Mean           1326.6272
V Predictions Std            949.4646
V Predictions Max            2304.9656
V Predictions Min            24.22055
Log Pis Mean                 -3.294355
Log Pis Std                  7.2534714
Log Pis Max                  17.331196
Log Pis Min                  -13.92623
Policy mu Mean               0.3132688
Policy mu Std                0.7774508
Policy mu Max                2.6111896
Policy mu Min                -2.8837886
Policy log std Mean          -0.29963493
Policy log std Std           0.16547021
Policy log std Max           -0.029281564
Policy log std Min           -1.0625368
Z mean eval                  0.032630812
Z variance eval              0.037827887
total_rewards                [4668.29613016 2679.58556881 1887.96204407 2810.37390194 5102.81103958
 2838.63523083 4311.18939985 2986.37680099 1506.92145244 2582.75527527]
total_rewards_mean           3137.4906843933086
total_rewards_std            1119.8240833011578
total_rewards_max            5102.811039582071
total_rewards_min            1506.9214524357446
Number of train steps total  213000
Number of env steps total    1067000
Number of rollouts total     0
Train Time (s)               30.287096947897226
(Previous) Eval Time (s)     20.23157817311585
Sample Time (s)              19.314047689549625
Epoch Time (s)               69.8327228105627
Total Train Time (s)         11609.048129312228
Epoch                        212
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:29:11.121329 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #212 | Epoch Duration: 67.16041135787964
2020-01-10 21:29:11.121546 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #212 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032469183
Z variance train             0.0378138
KL Divergence                5.8127794
KL Loss                      0.58127797
QF Loss                      1549.5432
VF Loss                      459.5471
Policy Loss                  -1388.2756
Q Predictions Mean           1381.8162
Q Predictions Std            967.4202
Q Predictions Max            2319.3843
Q Predictions Min            11.90666
V Predictions Mean           1391.8976
V Predictions Std            963.92596
V Predictions Max            2321.7112
V Predictions Min            28.132542
Log Pis Mean                 -4.375554
Log Pis Std                  6.4867277
Log Pis Max                  17.753876
Log Pis Min                  -13.674035
Policy mu Mean               0.2922899
Policy mu Std                0.7240953
Policy mu Max                2.4227726
Policy mu Min                -2.8827932
Policy log std Mean          -0.28689995
Policy log std Std           0.1581551
Policy log std Max           -0.03489615
Policy log std Min           -0.8069431
Z mean eval                  0.03281153
Z variance eval              0.037087224
total_rewards                [2671.29481698 5064.2545023  5100.36826315 4775.47258172 5052.63579571
 5045.28660278 5116.00059052 5083.95464439 4686.30601143 5075.66485258]
total_rewards_mean           4767.1238661555135
total_rewards_std            712.3640146882216
total_rewards_max            5116.00059052362
total_rewards_min            2671.294816981269
Number of train steps total  214000
Number of env steps total    1072000
Number of rollouts total     0
Train Time (s)               29.99349836120382
(Previous) Eval Time (s)     17.558996026869863
Sample Time (s)              19.834889626596123
Epoch Time (s)               67.3873840146698
Total Train Time (s)         11687.34662578348
Epoch                        213
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:30:29.422726 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #213 | Epoch Duration: 78.30099606513977
2020-01-10 21:30:29.422959 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #213 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032680914
Z variance train             0.03710053
KL Divergence                5.8657537
KL Loss                      0.5865754
QF Loss                      1078.0076
VF Loss                      338.67712
Policy Loss                  -1343.7698
Q Predictions Mean           1335.2876
Q Predictions Std            989.1167
Q Predictions Max            2308.6372
Q Predictions Min            14.801392
V Predictions Mean           1343.7899
V Predictions Std            986.04016
V Predictions Max            2313.5408
V Predictions Min            25.307026
Log Pis Mean                 -4.6113625
Log Pis Std                  6.5027814
Log Pis Max                  20.97939
Log Pis Min                  -15.605923
Policy mu Mean               0.28490645
Policy mu Std                0.7106172
Policy mu Max                3.098097
Policy mu Min                -3.1852903
Policy log std Mean          -0.2710302
Policy log std Std           0.1515628
Policy log std Max           -0.046487287
Policy log std Min           -0.8488173
Z mean eval                  0.030323222
Z variance eval              0.03743966
total_rewards                [1630.62601929 5141.58728487 4224.04688145 2880.00518059 5128.44097583
 5160.36274942 2423.32437973 2353.32691718 4359.69801995 5172.35269885]
total_rewards_mean           3847.3771107153234
total_rewards_std            1315.669222948168
total_rewards_max            5172.352698845361
total_rewards_min            1630.6260192924926
Number of train steps total  215000
Number of env steps total    1077000
Number of rollouts total     0
Train Time (s)               30.762075419072062
(Previous) Eval Time (s)     28.472283335402608
Sample Time (s)              19.717486616689712
Epoch Time (s)               78.95184537116438
Total Train Time (s)         11759.53820593888
Epoch                        214
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:31:41.617079 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #214 | Epoch Duration: 72.19393920898438
2020-01-10 21:31:41.617295 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #214 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030332819
Z variance train             0.037450787
KL Divergence                5.836515
KL Loss                      0.5836515
QF Loss                      1293.8826
VF Loss                      279.02866
Policy Loss                  -1447.7789
Q Predictions Mean           1448.7383
Q Predictions Std            976.9746
Q Predictions Max            2328.7493
Q Predictions Min            15.661137
V Predictions Mean           1448.7164
V Predictions Std            968.38055
V Predictions Max            2317.7166
V Predictions Min            27.032785
Log Pis Mean                 -3.9773407
Log Pis Std                  6.4547176
Log Pis Max                  22.18599
Log Pis Min                  -14.12631
Policy mu Mean               0.3377584
Policy mu Std                0.7417687
Policy mu Max                2.6416326
Policy mu Min                -2.8944962
Policy log std Mean          -0.29318428
Policy log std Std           0.15960516
Policy log std Max           -0.04639869
Policy log std Min           -0.88601947
Z mean eval                  0.03063156
Z variance eval              0.037537597
total_rewards                [5129.24735087 4893.93508427 5070.10054132 3293.24257141 5088.60018156
 1511.03702071 2065.70533821 5111.46000143 5101.54259472 1496.04639899]
total_rewards_mean           3876.091708348767
total_rewards_std            1529.882808038298
total_rewards_max            5129.24735087246
total_rewards_min            1496.0463989929642
Number of train steps total  216000
Number of env steps total    1082000
Number of rollouts total     0
Train Time (s)               30.94733469374478
(Previous) Eval Time (s)     21.714067931752652
Sample Time (s)              19.60673160245642
Epoch Time (s)               72.26813422795385
Total Train Time (s)         11832.185777908191
Epoch                        215
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:32:54.267570 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #215 | Epoch Duration: 72.65010285377502
2020-01-10 21:32:54.267778 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #215 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03075192
Z variance train             0.037524458
KL Divergence                5.8263855
KL Loss                      0.58263856
QF Loss                      2417.0854
VF Loss                      498.46432
Policy Loss                  -1399.8876
Q Predictions Mean           1390.8179
Q Predictions Std            966.4675
Q Predictions Max            2331.316
Q Predictions Min            15.556598
V Predictions Mean           1387.613
V Predictions Std            958.3001
V Predictions Max            2321.634
V Predictions Min            25.984928
Log Pis Mean                 -3.143428
Log Pis Std                  7.042554
Log Pis Max                  20.373634
Log Pis Min                  -13.556747
Policy mu Mean               0.3208318
Policy mu Std                0.76232964
Policy mu Max                3.2481048
Policy mu Min                -2.7586038
Policy log std Mean          -0.2958434
Policy log std Std           0.15887192
Policy log std Max           0.062735125
Policy log std Min           -0.86422306
Z mean eval                  0.029311826
Z variance eval              0.037298083
total_rewards                [5167.24180912 5146.40687578  353.8914981  5134.44237141 4562.29546431
 3470.91362643 5131.73337885 4048.66890559 5033.42265646 5197.02133408]
total_rewards_mean           4324.603792011201
total_rewards_std            1434.7199306405964
total_rewards_max            5197.021334075556
total_rewards_min            353.8914980954427
Number of train steps total  217000
Number of env steps total    1087000
Number of rollouts total     0
Train Time (s)               31.793099138885736
(Previous) Eval Time (s)     22.09573476575315
Sample Time (s)              19.653300338424742
Epoch Time (s)               73.54213424306363
Total Train Time (s)         11908.41568608908
Epoch                        216
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:34:10.498987 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #216 | Epoch Duration: 76.23103618621826
2020-01-10 21:34:10.499145 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #216 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029335517
Z variance train             0.03730295
KL Divergence                5.8388605
KL Loss                      0.5838861
QF Loss                      1612.4746
VF Loss                      408.13037
Policy Loss                  -1455.164
Q Predictions Mean           1445.0942
Q Predictions Std            947.73566
Q Predictions Max            2327.682
Q Predictions Min            17.675545
V Predictions Mean           1446.7991
V Predictions Std            943.455
V Predictions Max            2333.025
V Predictions Min            25.472631
Log Pis Mean                 -3.451408
Log Pis Std                  6.7132025
Log Pis Max                  27.34129
Log Pis Min                  -14.453611
Policy mu Mean               0.33688346
Policy mu Std                0.7600541
Policy mu Max                2.8252296
Policy mu Min                -2.8859072
Policy log std Mean          -0.29975745
Policy log std Std           0.15860967
Policy log std Max           -0.033957735
Policy log std Min           -0.94958854
Z mean eval                  0.03184029
Z variance eval              0.038458645
total_rewards                [1411.81345717 5026.98118476 1762.70290984 1914.58610417 2051.29868086
 3061.62359399  875.11784571  885.95494445 1505.61047155 5077.20594904]
total_rewards_mean           2357.2895141526847
total_rewards_std            1471.2367549406317
total_rewards_max            5077.20594904381
total_rewards_min            875.117845708232
Number of train steps total  218000
Number of env steps total    1092000
Number of rollouts total     0
Train Time (s)               32.73581496393308
(Previous) Eval Time (s)     24.784341694787145
Sample Time (s)              19.42119406769052
Epoch Time (s)               76.94135072641075
Total Train Time (s)         11974.246831132565
Epoch                        217
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:35:16.332985 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #217 | Epoch Duration: 65.83371543884277
2020-01-10 21:35:16.333183 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #217 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03186757
Z variance train             0.038444474
KL Divergence                5.791271
KL Loss                      0.57912713
QF Loss                      1267.8069
VF Loss                      540.902
Policy Loss                  -1375.1865
Q Predictions Mean           1366.7683
Q Predictions Std            971.0588
Q Predictions Max            2341.2307
Q Predictions Min            17.053205
V Predictions Mean           1366.6539
V Predictions Std            961.7208
V Predictions Max            2336.7317
V Predictions Min            25.550304
Log Pis Mean                 -4.230542
Log Pis Std                  6.545982
Log Pis Max                  20.602318
Log Pis Min                  -13.000455
Policy mu Mean               0.30885404
Policy mu Std                0.7201469
Policy mu Max                2.9839551
Policy mu Min                -2.5131824
Policy log std Mean          -0.29334402
Policy log std Std           0.15690094
Policy log std Max           -0.03816256
Policy log std Min           -1.038948
Z mean eval                  0.032949157
Z variance eval              0.038509343
total_rewards                [5112.99625365 1373.75279527 5117.35940767 3365.63881363 5140.82183145
 2897.27803596 1984.52357797 1227.08229848 5206.77387689 1194.87968102]
total_rewards_mean           3262.1106571985615
total_rewards_std            1671.3983828397043
total_rewards_max            5206.773876891995
total_rewards_min            1194.8796810219812
Number of train steps total  219000
Number of env steps total    1097000
Number of rollouts total     0
Train Time (s)               29.709178410936147
(Previous) Eval Time (s)     13.676373626105487
Sample Time (s)              19.271276188548654
Epoch Time (s)               62.65682822559029
Total Train Time (s)         12041.855241945013
Epoch                        218
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:36:23.945195 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #218 | Epoch Duration: 67.61186170578003
2020-01-10 21:36:23.945440 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #218 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03263161
Z variance train             0.038503714
KL Divergence                5.797838
KL Loss                      0.57978386
QF Loss                      1214.3235
VF Loss                      603.38214
Policy Loss                  -1408.8208
Q Predictions Mean           1408.5366
Q Predictions Std            991.3612
Q Predictions Max            2344.733
Q Predictions Min            17.010904
V Predictions Mean           1419.157
V Predictions Std            989.8941
V Predictions Max            2348.6292
V Predictions Min            27.752792
Log Pis Mean                 -4.455597
Log Pis Std                  6.30883
Log Pis Max                  18.06321
Log Pis Min                  -14.000421
Policy mu Mean               0.3080543
Policy mu Std                0.71556765
Policy mu Max                2.6761904
Policy mu Min                -2.7390878
Policy log std Mean          -0.2886587
Policy log std Std           0.16086419
Policy log std Max           -0.044519544
Policy log std Min           -0.9254381
Z mean eval                  0.032534502
Z variance eval              0.039104152
total_rewards                [2436.43780403 2797.42249835 1325.58755356 2959.42292135 1196.20718187
 1202.82482779 2025.15599931  953.94488485 1391.9093499  1811.56104929]
total_rewards_mean           1810.0474070308228
total_rewards_std            679.8958719262903
total_rewards_max            2959.4229213540443
total_rewards_min            953.9448848527992
Number of train steps total  220000
Number of env steps total    1102000
Number of rollouts total     0
Train Time (s)               29.272386563010514
(Previous) Eval Time (s)     18.631092065945268
Sample Time (s)              18.98176698666066
Epoch Time (s)               66.88524561561644
Total Train Time (s)         12100.504411782138
Epoch                        219
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:37:22.599373 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #219 | Epoch Duration: 58.65372371673584
2020-01-10 21:37:22.599666 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #219 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03336223
Z variance train             0.03911986
KL Divergence                5.7702913
KL Loss                      0.57702917
QF Loss                      1254.4729
VF Loss                      928.39716
Policy Loss                  -1503.1128
Q Predictions Mean           1494.5886
Q Predictions Std            951.2321
Q Predictions Max            2347.779
Q Predictions Min            14.768613
V Predictions Mean           1490.5771
V Predictions Std            942.7031
V Predictions Max            2355.378
V Predictions Min            25.302753
Log Pis Mean                 -3.4629273
Log Pis Std                  6.4668655
Log Pis Max                  20.931908
Log Pis Min                  -15.134369
Policy mu Mean               0.30762044
Policy mu Std                0.7561257
Policy mu Max                2.7678533
Policy mu Min                -2.7279804
Policy log std Mean          -0.2921504
Policy log std Std           0.15335403
Policy log std Max           -0.008401409
Policy log std Min           -0.9407612
Z mean eval                  0.033749692
Z variance eval              0.038450975
total_rewards                [5158.4239215  5063.65747684 5028.11940697 2213.68481851 5049.33403465
 5042.91603806 3909.87956363 5106.56966142 5080.75856467 1630.35774395]
total_rewards_mean           4328.370123018367
total_rewards_std            1258.8738085981568
total_rewards_max            5158.423921498019
total_rewards_min            1630.357743945138
Number of train steps total  221000
Number of env steps total    1107000
Number of rollouts total     0
Train Time (s)               31.296680506318808
(Previous) Eval Time (s)     10.399283579085022
Sample Time (s)              19.938204342499375
Epoch Time (s)               61.634168427903205
Total Train Time (s)         12177.361021923833
Epoch                        220
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:38:39.457929 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #220 | Epoch Duration: 76.85804033279419
2020-01-10 21:38:39.458120 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #220 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033633865
Z variance train             0.038463235
KL Divergence                5.8105507
KL Loss                      0.5810551
QF Loss                      1419.2617
VF Loss                      378.86246
Policy Loss                  -1442.8102
Q Predictions Mean           1439.1244
Q Predictions Std            958.02875
Q Predictions Max            2349.1614
Q Predictions Min            16.668022
V Predictions Mean           1441.7778
V Predictions Std            954.9035
V Predictions Max            2348.1772
V Predictions Min            25.252584
Log Pis Mean                 -3.6499655
Log Pis Std                  6.7096844
Log Pis Max                  23.367428
Log Pis Min                  -13.135724
Policy mu Mean               0.33246443
Policy mu Std                0.73420805
Policy mu Max                2.7258728
Policy mu Min                -3.0855663
Policy log std Mean          -0.29459882
Policy log std Std           0.1572883
Policy log std Max           -0.018537626
Policy log std Min           -0.8654705
Z mean eval                  0.03415552
Z variance eval              0.039584927
total_rewards                [5093.68112273 2089.05788793 5125.68868141 2733.99127289 1436.92648896
 5164.67949993 5093.00684584 3468.4452111  5107.16963574 5071.91108431]
total_rewards_mean           4038.4557730844
total_rewards_std            1395.7384922615465
total_rewards_max            5164.679499930603
total_rewards_min            1436.9264889586648
Number of train steps total  222000
Number of env steps total    1112000
Number of rollouts total     0
Train Time (s)               31.342354838270694
(Previous) Eval Time (s)     25.622821923345327
Sample Time (s)              19.63640833646059
Epoch Time (s)               76.60158509807661
Total Train Time (s)         12251.600540840998
Epoch                        221
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:39:53.700829 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #221 | Epoch Duration: 74.24254369735718
2020-01-10 21:39:53.701046 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #221 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0340193
Z variance train             0.03956348
KL Divergence                5.7520404
KL Loss                      0.5752041
QF Loss                      1165.6418
VF Loss                      369.7165
Policy Loss                  -1396.5554
Q Predictions Mean           1392.1285
Q Predictions Std            998.4635
Q Predictions Max            2366.889
Q Predictions Min            16.20194
V Predictions Mean           1397.8462
V Predictions Std            993.67175
V Predictions Max            2357.72
V Predictions Min            28.5747
Log Pis Mean                 -4.400017
Log Pis Std                  6.7246413
Log Pis Max                  23.433918
Log Pis Min                  -14.824168
Policy mu Mean               0.33234158
Policy mu Std                0.6986633
Policy mu Max                2.649563
Policy mu Min                -3.2264583
Policy log std Mean          -0.28055325
Policy log std Std           0.15337689
Policy log std Max           -0.05122745
Policy log std Min           -0.8630383
Z mean eval                  0.034213014
Z variance eval              0.038455784
total_rewards                [1153.87234481 5092.07048221 5125.58496719 1369.7781046  4536.52642021
 2122.14864918 5149.3287277   774.77436028 1021.94592193 3797.72429957]
total_rewards_mean           3014.3754277675152
total_rewards_std            1794.7271694860876
total_rewards_max            5149.328727696921
total_rewards_min            774.7743602787531
Number of train steps total  223000
Number of env steps total    1117000
Number of rollouts total     0
Train Time (s)               30.31411249190569
(Previous) Eval Time (s)     23.26345787709579
Sample Time (s)              19.529111430514604
Epoch Time (s)               73.10668179951608
Total Train Time (s)         12319.553529313765
Epoch                        222
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:41:01.655111 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #222 | Epoch Duration: 67.95391249656677
2020-01-10 21:41:01.655258 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #222 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03419198
Z variance train             0.038467158
KL Divergence                5.8309927
KL Loss                      0.5830993
QF Loss                      2432.7139
VF Loss                      600.6559
Policy Loss                  -1464.7794
Q Predictions Mean           1457.4141
Q Predictions Std            963.52246
Q Predictions Max            2361.3882
Q Predictions Min            16.12774
V Predictions Mean           1469.5422
V Predictions Std            962.885
V Predictions Max            2357.656
V Predictions Min            27.820335
Log Pis Mean                 -3.529057
Log Pis Std                  6.5600157
Log Pis Max                  24.085508
Log Pis Min                  -12.9020405
Policy mu Mean               0.26559472
Policy mu Std                0.79449815
Policy mu Max                2.7954812
Policy mu Min                -2.57893
Policy log std Mean          -0.29591846
Policy log std Std           0.15613224
Policy log std Max           -0.06360232
Policy log std Min           -0.8545892
Z mean eval                  0.035459388
Z variance eval              0.03895615
total_rewards                [5147.49769682 4494.93969776 5161.83334479 5154.02203269 5092.87781124
 1285.33201224 3497.73111163 1857.17406041 3069.8292623  1338.54410591]
total_rewards_mean           3609.9781135777944
total_rewards_std            1551.7253441852818
total_rewards_max            5161.833344786496
total_rewards_min            1285.33201223877
Number of train steps total  224000
Number of env steps total    1122000
Number of rollouts total     0
Train Time (s)               30.741760935168713
(Previous) Eval Time (s)     18.110354244709015
Sample Time (s)              19.223109069745988
Epoch Time (s)               68.07522424962372
Total Train Time (s)         12390.809492504224
Epoch                        223
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:42:12.915413 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #223 | Epoch Duration: 71.26002359390259
2020-01-10 21:42:12.915625 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #223 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035560302
Z variance train             0.0389627
KL Divergence                5.80883
KL Loss                      0.58088297
QF Loss                      1474.2556
VF Loss                      680.0696
Policy Loss                  -1485.5643
Q Predictions Mean           1477.7574
Q Predictions Std            944.5654
Q Predictions Max            2355.528
Q Predictions Min            16.944304
V Predictions Mean           1494.8455
V Predictions Std            946.8842
V Predictions Max            2363.817
V Predictions Min            29.856136
Log Pis Mean                 -3.3865004
Log Pis Std                  6.613677
Log Pis Max                  21.368397
Log Pis Min                  -15.658547
Policy mu Mean               0.33597004
Policy mu Std                0.76645494
Policy mu Max                3.2025514
Policy mu Min                -2.9538767
Policy log std Mean          -0.30532354
Policy log std Std           0.15727651
Policy log std Max           -0.053314403
Policy log std Min           -1.1676152
Z mean eval                  0.035852566
Z variance eval              0.039399207
total_rewards                [2133.01109818  925.58630441 1918.4283109  2705.40094105 5356.70040288
 4448.96947232 3184.775272   5299.91503116 5137.83753606 1542.82586295]
total_rewards_mean           3265.345023193423
total_rewards_std            1589.9174260261252
total_rewards_max            5356.700402880825
total_rewards_min            925.5863044143023
Number of train steps total  225000
Number of env steps total    1127000
Number of rollouts total     0
Train Time (s)               30.228503271006048
(Previous) Eval Time (s)     21.294833038933575
Sample Time (s)              19.100492233410478
Epoch Time (s)               70.6238285433501
Total Train Time (s)         12458.479822502937
Epoch                        224
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:43:20.587789 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #224 | Epoch Duration: 67.67200422286987
2020-01-10 21:43:20.588248 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #224 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03613829
Z variance train             0.039394453
KL Divergence                5.789915
KL Loss                      0.57899153
QF Loss                      1068.3994
VF Loss                      391.88138
Policy Loss                  -1434.3608
Q Predictions Mean           1424.1355
Q Predictions Std            1015.32056
Q Predictions Max            2366.8394
Q Predictions Min            14.841655
V Predictions Mean           1426.7333
V Predictions Std            1008.2951
V Predictions Max            2363.1777
V Predictions Min            26.69734
Log Pis Mean                 -4.4822054
Log Pis Std                  6.673278
Log Pis Max                  18.623453
Log Pis Min                  -14.110594
Policy mu Mean               0.28248787
Policy mu Std                0.7320216
Policy mu Max                3.0089958
Policy mu Min                -3.9620743
Policy log std Mean          -0.2825534
Policy log std Std           0.15332268
Policy log std Max           0.011157393
Policy log std Min           -0.853279
Z mean eval                  0.03718474
Z variance eval              0.036363907
total_rewards                [5288.84494816 1111.43030249 1067.60653836 2656.83811727 2577.15862936
  738.79727253 5210.74840745 2023.41500996 5149.42074493 5150.23349334]
total_rewards_mean           3097.4493463861277
total_rewards_std            1814.9082757596718
total_rewards_max            5288.844948160463
total_rewards_min            738.7972725263286
Number of train steps total  226000
Number of env steps total    1132000
Number of rollouts total     0
Train Time (s)               31.392721224110574
(Previous) Eval Time (s)     18.34264274314046
Sample Time (s)              19.445488347206265
Epoch Time (s)               69.1808523144573
Total Train Time (s)         12527.249011011329
Epoch                        225
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:44:29.361046 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #225 | Epoch Duration: 68.77257466316223
2020-01-10 21:44:29.361323 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #225 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037443023
Z variance train             0.03636397
KL Divergence                5.9587684
KL Loss                      0.5958769
QF Loss                      1156.8265
VF Loss                      961.9318
Policy Loss                  -1501.7439
Q Predictions Mean           1497.4447
Q Predictions Std            993.90656
Q Predictions Max            2386.7705
Q Predictions Min            14.813761
V Predictions Mean           1488.9036
V Predictions Std            978.4125
V Predictions Max            2360.0432
V Predictions Min            28.254065
Log Pis Mean                 -3.52598
Log Pis Std                  6.807019
Log Pis Max                  25.566418
Log Pis Min                  -14.882128
Policy mu Mean               0.27841058
Policy mu Std                0.75206363
Policy mu Max                3.022871
Policy mu Min                -2.9091737
Policy log std Mean          -0.29289556
Policy log std Std           0.15713243
Policy log std Max           -0.052422874
Policy log std Min           -0.87174994
Z mean eval                  0.03860988
Z variance eval              0.038716868
total_rewards                [5283.63068268 5273.74513574 5263.70231411 3382.22390297 5241.3164022
  666.07400778 5275.70143983 2847.37561622 5230.28409502 5247.96023526]
total_rewards_mean           4371.201383180406
total_rewards_std            1501.7892776696897
total_rewards_max            5283.630682679448
total_rewards_min            666.0740077798473
Number of train steps total  227000
Number of env steps total    1137000
Number of rollouts total     0
Train Time (s)               28.30432291282341
(Previous) Eval Time (s)     17.934049931820482
Sample Time (s)              20.56921824021265
Epoch Time (s)               66.80759108485654
Total Train Time (s)         12600.259936752263
Epoch                        226
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:45:42.375741 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #226 | Epoch Duration: 73.01420855522156
2020-01-10 21:45:42.376026 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #226 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.038794223
Z variance train             0.03870794
KL Divergence                5.861021
KL Loss                      0.5861021
QF Loss                      1287.7378
VF Loss                      523.36096
Policy Loss                  -1529.7524
Q Predictions Mean           1520.2213
Q Predictions Std            968.5761
Q Predictions Max            2389.7344
Q Predictions Min            17.189987
V Predictions Mean           1521.5833
V Predictions Std            962.9405
V Predictions Max            2383.0479
V Predictions Min            28.345337
Log Pis Mean                 -3.8384905
Log Pis Std                  6.399178
Log Pis Max                  21.093752
Log Pis Min                  -13.47272
Policy mu Mean               0.31823146
Policy mu Std                0.76317847
Policy mu Max                2.750542
Policy mu Min                -3.3047845
Policy log std Mean          -0.30263585
Policy log std Std           0.15793803
Policy log std Max           -0.023307487
Policy log std Min           -0.87449354
Z mean eval                  0.041429907
Z variance eval              0.037809618
total_rewards                [4756.16219262 3793.49333988 1592.26127236 1251.13766771 1935.50983976
 1719.32060087 1537.53105425 1405.15507433 1530.37899213 1865.57816258]
total_rewards_mean           2138.65281964795
total_rewards_std            1106.2151259872116
total_rewards_max            4756.162192620002
total_rewards_min            1251.1376677107407
Number of train steps total  228000
Number of env steps total    1142000
Number of rollouts total     0
Train Time (s)               28.0862593697384
(Previous) Eval Time (s)     24.140299579128623
Sample Time (s)              20.20744275767356
Epoch Time (s)               72.43400170654058
Total Train Time (s)         12660.528202068992
Epoch                        227
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:46:42.647876 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #227 | Epoch Duration: 60.271628618240356
2020-01-10 21:46:42.648135 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #227 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04114164
Z variance train             0.037807036
KL Divergence                5.88801
KL Loss                      0.588801
QF Loss                      1266.7744
VF Loss                      532.97864
Policy Loss                  -1498.8855
Q Predictions Mean           1496.9741
Q Predictions Std            980.22577
Q Predictions Max            2385.7717
Q Predictions Min            13.828944
V Predictions Mean           1506.7539
V Predictions Std            975.74365
V Predictions Max            2386.1338
V Predictions Min            27.009495
Log Pis Mean                 -3.9864783
Log Pis Std                  6.7444844
Log Pis Max                  23.068798
Log Pis Min                  -16.489006
Policy mu Mean               0.3187378
Policy mu Std                0.74985254
Policy mu Max                2.6227412
Policy mu Min                -3.2016332
Policy log std Mean          -0.2852603
Policy log std Std           0.15439525
Policy log std Max           -0.019187935
Policy log std Min           -0.97180796
Z mean eval                  0.041716237
Z variance eval              0.039573997
total_rewards                [1633.71014625 5056.72078075 1989.98946201 5142.08358682 4937.75434165
 1033.1178831  5068.41240226 2123.53742463 3514.19841612 2257.40293633]
total_rewards_mean           3275.692737993277
total_rewards_std            1563.0518522652899
total_rewards_max            5142.083586824413
total_rewards_min            1033.1178831007549
Number of train steps total  229000
Number of env steps total    1147000
Number of rollouts total     0
Train Time (s)               30.117431653663516
(Previous) Eval Time (s)     11.977574851829559
Sample Time (s)              19.394325049594045
Epoch Time (s)               61.48933155508712
Total Train Time (s)         12728.78063135501
Epoch                        228
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:47:50.904635 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #228 | Epoch Duration: 68.25629663467407
2020-01-10 21:47:50.904897 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #228 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.041416984
Z variance train             0.039574213
KL Divergence                5.7701035
KL Loss                      0.57701033
QF Loss                      1738.7914
VF Loss                      601.6638
Policy Loss                  -1588.1663
Q Predictions Mean           1589.4303
Q Predictions Std            934.09705
Q Predictions Max            2409.998
Q Predictions Min            17.253706
V Predictions Mean           1594.6611
V Predictions Std            931.93634
V Predictions Max            2406.9163
V Predictions Min            27.908245
Log Pis Mean                 -3.2776666
Log Pis Std                  6.1412487
Log Pis Max                  16.787449
Log Pis Min                  -12.892127
Policy mu Mean               0.30673274
Policy mu Std                0.77476275
Policy mu Max                2.8437543
Policy mu Min                -2.8044488
Policy log std Mean          -0.3037455
Policy log std Std           0.1563517
Policy log std Max           -0.017057009
Policy log std Min           -0.93594015
Z mean eval                  0.04329015
Z variance eval              0.039760817
total_rewards                [2863.15317669 5207.25181884 2143.96441692 5268.88600141  680.88694135
 2933.8534036  3859.37548957  545.20760115 1845.71804726 1742.73182879]
total_rewards_mean           2709.1028725584956
total_rewards_std            1580.6770590323615
total_rewards_max            5268.886001410332
total_rewards_min            545.2076011495234
Number of train steps total  230000
Number of env steps total    1152000
Number of rollouts total     0
Train Time (s)               29.639224193058908
(Previous) Eval Time (s)     18.74424656573683
Sample Time (s)              20.156762095168233
Epoch Time (s)               68.54023285396397
Total Train Time (s)         12793.44053101074
Epoch                        229
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:48:55.565570 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #229 | Epoch Duration: 64.66049575805664
2020-01-10 21:48:55.565762 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #229 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04337622
Z variance train             0.03976754
KL Divergence                5.7624607
KL Loss                      0.5762461
QF Loss                      1745.1875
VF Loss                      544.93195
Policy Loss                  -1621.1045
Q Predictions Mean           1621.3145
Q Predictions Std            959.8568
Q Predictions Max            2408.9775
Q Predictions Min            15.62228
V Predictions Mean           1619.4153
V Predictions Std            956.3047
V Predictions Max            2395.7063
V Predictions Min            27.316645
Log Pis Mean                 -3.279817
Log Pis Std                  6.502512
Log Pis Max                  21.280605
Log Pis Min                  -15.4568
Policy mu Mean               0.31394726
Policy mu Std                0.75875896
Policy mu Max                3.181608
Policy mu Min                -2.6288304
Policy log std Mean          -0.299186
Policy log std Std           0.14860435
Policy log std Max           -0.07744649
Policy log std Min           -1.0568589
Z mean eval                  0.04172145
Z variance eval              0.038029544
total_rewards                [2477.74907422 5125.30221918 3821.20340228 5145.36453428 4919.71258238
 5000.47984715 3709.30315632 5046.18669337 4983.73281397 2150.69318996]
total_rewards_mean           4237.972751310987
total_rewards_std            1085.1073283127378
total_rewards_max            5145.3645342783175
total_rewards_min            2150.6931899637884
Number of train steps total  231000
Number of env steps total    1157000
Number of rollouts total     0
Train Time (s)               31.077676753047854
(Previous) Eval Time (s)     14.86417895089835
Sample Time (s)              19.44311852939427
Epoch Time (s)               65.38497423334047
Total Train Time (s)         12869.126217152923
Epoch                        230
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:50:11.255730 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #230 | Epoch Duration: 75.6897931098938
2020-01-10 21:50:11.256024 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #230 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.041842643
Z variance train             0.038022593
KL Divergence                5.872095
KL Loss                      0.5872095
QF Loss                      1669.2642
VF Loss                      729.87335
Policy Loss                  -1531.0288
Q Predictions Mean           1520.3427
Q Predictions Std            991.5613
Q Predictions Max            2403.2314
Q Predictions Min            16.16765
V Predictions Mean           1522.8901
V Predictions Std            985.54376
V Predictions Max            2402.158
V Predictions Min            25.228325
Log Pis Mean                 -3.154763
Log Pis Std                  7.6438813
Log Pis Max                  33.255318
Log Pis Min                  -12.38895
Policy mu Mean               0.2573355
Policy mu Std                0.7835338
Policy mu Max                2.9312727
Policy mu Min                -2.9024246
Policy log std Mean          -0.297984
Policy log std Std           0.15587008
Policy log std Max           0.017841324
Policy log std Min           -0.8722164
Z mean eval                  0.04023288
Z variance eval              0.040519025
total_rewards                [1357.18882852 5146.45447611 1512.14233874 5138.38766044 5239.23592314
 5140.74093866 5236.89633747 1244.11446475 2181.07795163 4061.75225778]
total_rewards_mean           3625.799117723453
total_rewards_std            1722.150165165957
total_rewards_max            5239.235923138009
total_rewards_min            1244.114464749598
Number of train steps total  232000
Number of env steps total    1162000
Number of rollouts total     0
Train Time (s)               30.267913268413395
(Previous) Eval Time (s)     25.168670741375536
Sample Time (s)              19.692120105959475
Epoch Time (s)               75.1287041157484
Total Train Time (s)         12939.69354567537
Epoch                        231
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:51:21.826173 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #231 | Epoch Duration: 70.56992030143738
2020-01-10 21:51:21.826437 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #231 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040188417
Z variance train             0.040529262
KL Divergence                5.742132
KL Loss                      0.5742132
QF Loss                      1446.9865
VF Loss                      400.33542
Policy Loss                  -1663.6642
Q Predictions Mean           1660.0194
Q Predictions Std            936.62994
Q Predictions Max            2411.1206
Q Predictions Min            16.85568
V Predictions Mean           1662.3768
V Predictions Std            931.0865
V Predictions Max            2409.662
V Predictions Min            28.589409
Log Pis Mean                 -3.2788033
Log Pis Std                  6.664256
Log Pis Max                  22.381767
Log Pis Min                  -13.389063
Policy mu Mean               0.30280694
Policy mu Std                0.7837962
Policy mu Max                3.2878098
Policy mu Min                -3.315475
Policy log std Mean          -0.29035947
Policy log std Std           0.1546486
Policy log std Max           -0.016770594
Policy log std Min           -1.1424499
Z mean eval                  0.042657714
Z variance eval              0.040649477
total_rewards                [2090.36574365 3573.05687621  963.42598389 4444.95871278 3426.23224675
 3624.25715672 4398.05330821 3517.52723744 1500.57859145 3923.04289238]
total_rewards_mean           3146.1498749486145
total_rewards_std            1143.3197877471216
total_rewards_max            4444.958712780444
total_rewards_min            963.4259838889342
Number of train steps total  233000
Number of env steps total    1167000
Number of rollouts total     0
Train Time (s)               28.749567646998912
(Previous) Eval Time (s)     20.6095730853267
Sample Time (s)              20.281919309403747
Epoch Time (s)               69.64106004172936
Total Train Time (s)         13007.869964275043
Epoch                        232
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:52:30.007454 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #232 | Epoch Duration: 68.18071460723877
2020-01-10 21:52:30.007890 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #232 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.042455636
Z variance train             0.040646855
KL Divergence                5.7175837
KL Loss                      0.5717584
QF Loss                      1947.4712
VF Loss                      427.30484
Policy Loss                  -1490.1118
Q Predictions Mean           1486.1936
Q Predictions Std            985.0719
Q Predictions Max            2421.948
Q Predictions Min            16.645847
V Predictions Mean           1493.1696
V Predictions Std            981.83386
V Predictions Max            2417.257
V Predictions Min            29.646788
Log Pis Mean                 -3.6271899
Log Pis Std                  6.666305
Log Pis Max                  24.71354
Log Pis Min                  -13.041916
Policy mu Mean               0.34375548
Policy mu Std                0.7429153
Policy mu Max                2.996075
Policy mu Min                -3.359384
Policy log std Mean          -0.28556144
Policy log std Std           0.1537377
Policy log std Max           0.013138846
Policy log std Min           -0.9393882
Z mean eval                  0.0427872
Z variance eval              0.038833234
total_rewards                [2390.42479617 3625.69027175 2109.8790196  5265.75041348 5271.74189523
 2370.69315614 4484.23142325 1551.61329423 3500.44635504 3216.88416556]
total_rewards_mean           3378.735479045259
total_rewards_std            1241.3579465802766
total_rewards_max            5271.741895231759
total_rewards_min            1551.6132942340707
Number of train steps total  234000
Number of env steps total    1172000
Number of rollouts total     0
Train Time (s)               29.580155069939792
(Previous) Eval Time (s)     19.148853308986872
Sample Time (s)              19.529262833297253
Epoch Time (s)               68.25827121222392
Total Train Time (s)         13075.968511351384
Epoch                        233
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:53:38.107370 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #233 | Epoch Duration: 68.09926700592041
2020-01-10 21:53:38.107588 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #233 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04283346
Z variance train             0.038828783
KL Divergence                5.8137875
KL Loss                      0.58137876
QF Loss                      1713.5913
VF Loss                      420.0228
Policy Loss                  -1598.7625
Q Predictions Mean           1590.6721
Q Predictions Std            958.38745
Q Predictions Max            2413.5757
Q Predictions Min            16.4549
V Predictions Mean           1594.2753
V Predictions Std            954.58044
V Predictions Max            2422.983
V Predictions Min            29.738127
Log Pis Mean                 -2.9916306
Log Pis Std                  6.482249
Log Pis Max                  22.403671
Log Pis Min                  -13.839676
Policy mu Mean               0.35142305
Policy mu Std                0.7680625
Policy mu Max                2.6372848
Policy mu Min                -3.1501255
Policy log std Mean          -0.29536474
Policy log std Std           0.1583001
Policy log std Max           -0.051561706
Policy log std Min           -1.0315367
Z mean eval                  0.043143902
Z variance eval              0.037853707
total_rewards                [5132.76656538 2703.52774142 5134.2898527  5137.137708   1464.68554246
 2677.40998481 5145.18459965 5173.36343333 5222.04661915 4534.60939904]
total_rewards_mean           4232.502144593217
total_rewards_std            1328.4435246999712
total_rewards_max            5222.046619146478
total_rewards_min            1464.6855424601802
Number of train steps total  235000
Number of env steps total    1177000
Number of rollouts total     0
Train Time (s)               28.644945167936385
(Previous) Eval Time (s)     18.989557108841836
Sample Time (s)              19.947077014949173
Epoch Time (s)               67.5815792917274
Total Train Time (s)         13148.968990134541
Epoch                        234
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:54:51.112868 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #234 | Epoch Duration: 73.00494003295898
2020-01-10 21:54:51.113270 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #234 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04327449
Z variance train             0.037861478
KL Divergence                5.886643
KL Loss                      0.5886643
QF Loss                      1108.7185
VF Loss                      471.36063
Policy Loss                  -1495.1938
Q Predictions Mean           1485.345
Q Predictions Std            1008.0291
Q Predictions Max            2408.6128
Q Predictions Min            17.034163
V Predictions Mean           1492.4512
V Predictions Std            1008.4327
V Predictions Max            2411.1038
V Predictions Min            29.656738
Log Pis Mean                 -4.014985
Log Pis Std                  6.7577276
Log Pis Max                  25.47107
Log Pis Min                  -14.516317
Policy mu Mean               0.29396933
Policy mu Std                0.73465896
Policy mu Max                2.8793066
Policy mu Min                -2.8309264
Policy log std Mean          -0.27707455
Policy log std Std           0.14900438
Policy log std Max           -0.035037093
Policy log std Min           -0.9712986
Z mean eval                  0.042620696
Z variance eval              0.03831544
total_rewards                [1443.84808639 3842.76650483 1424.77243659 5341.48801583 2408.74269567
 2626.36663506 2034.57537455 1440.271731   4302.46204148 3274.96313765]
total_rewards_mean           2814.0256659064135
total_rewards_std            1279.6837032517492
total_rewards_max            5341.4880158303995
total_rewards_min            1424.7724365931986
Number of train steps total  236000
Number of env steps total    1182000
Number of rollouts total     0
Train Time (s)               29.770895558875054
(Previous) Eval Time (s)     24.412604053970426
Sample Time (s)              19.305047106929123
Epoch Time (s)               73.4885467197746
Total Train Time (s)         13213.608381623402
Epoch                        235
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:55:55.755379 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #235 | Epoch Duration: 64.64187359809875
2020-01-10 21:55:55.755631 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #235 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.042543914
Z variance train             0.03831149
KL Divergence                5.87084
KL Loss                      0.587084
QF Loss                      2329.335
VF Loss                      545.8301
Policy Loss                  -1525.8525
Q Predictions Mean           1520.8394
Q Predictions Std            1002.01196
Q Predictions Max            2408.7654
Q Predictions Min            8.226335
V Predictions Mean           1527.3104
V Predictions Std            1000.07666
V Predictions Max            2417.3154
V Predictions Min            25.87277
Log Pis Mean                 -3.5384488
Log Pis Std                  6.417698
Log Pis Max                  23.442068
Log Pis Min                  -12.782278
Policy mu Mean               0.31794268
Policy mu Std                0.73554456
Policy mu Max                2.552212
Policy mu Min                -2.8094902
Policy log std Mean          -0.29392198
Policy log std Std           0.15348719
Policy log std Max           0.021442324
Policy log std Min           -0.9243922
Z mean eval                  0.043948617
Z variance eval              0.0376643
total_rewards                [1314.31547513 1735.69781345 5261.66989271 1675.91689342 3481.01514584
 2115.42576354 1373.80356707 2903.71566433 2813.92003958 5191.67999749]
total_rewards_mean           2786.716025257683
total_rewards_std            1391.3719200630173
total_rewards_max            5261.669892713714
total_rewards_min            1314.3154751275622
Number of train steps total  237000
Number of env steps total    1187000
Number of rollouts total     0
Train Time (s)               31.841576118953526
(Previous) Eval Time (s)     15.565617760643363
Sample Time (s)              19.137880694586784
Epoch Time (s)               66.54507457418367
Total Train Time (s)         13280.53639140958
Epoch                        236
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:57:02.688855 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #236 | Epoch Duration: 66.93289971351624
2020-01-10 21:57:02.689294 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #236 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043821607
Z variance train             0.037655454
KL Divergence                5.925145
KL Loss                      0.5925145
QF Loss                      1335.959
VF Loss                      484.8392
Policy Loss                  -1665.4695
Q Predictions Mean           1661.9496
Q Predictions Std            944.25165
Q Predictions Max            2415.441
Q Predictions Min            17.001232
V Predictions Mean           1662.6045
V Predictions Std            939.9301
V Predictions Max            2413.2415
V Predictions Min            27.369448
Log Pis Mean                 -2.7813482
Log Pis Std                  6.450047
Log Pis Max                  21.723705
Log Pis Min                  -14.941367
Policy mu Mean               0.31723407
Policy mu Std                0.7857352
Policy mu Max                3.0118754
Policy mu Min                -2.9078865
Policy log std Mean          -0.3081323
Policy log std Std           0.15634352
Policy log std Max           -0.004076615
Policy log std Min           -0.9268413
Z mean eval                  0.044158477
Z variance eval              0.039968718
total_rewards                [5183.08849315 5170.82506761 5220.78015909 5270.73493358 3438.03695289
 2016.67316148 2555.42391257 3761.68807456 1009.14890869 2303.6160785 ]
total_rewards_mean           3593.0015742110327
total_rewards_std            1497.832204364293
total_rewards_max            5270.734933577232
total_rewards_min            1009.1489086873326
Number of train steps total  238000
Number of env steps total    1192000
Number of rollouts total     0
Train Time (s)               30.582031853031367
(Previous) Eval Time (s)     15.953113955911249
Sample Time (s)              20.29176701279357
Epoch Time (s)               66.82691282173619
Total Train Time (s)         13351.777677750215
Epoch                        237
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:58:13.931874 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #237 | Epoch Duration: 71.2423164844513
2020-01-10 21:58:13.932102 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #237 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043875795
Z variance train             0.039953582
KL Divergence                5.8270416
KL Loss                      0.5827042
QF Loss                      1743.6748
VF Loss                      1129.7224
Policy Loss                  -1582.2479
Q Predictions Mean           1580.7903
Q Predictions Std            962.01044
Q Predictions Max            2418.702
Q Predictions Min            17.643684
V Predictions Mean           1606.8608
V Predictions Std            968.1076
V Predictions Max            2445.4756
V Predictions Min            26.792366
Log Pis Mean                 -3.2538877
Log Pis Std                  6.7608633
Log Pis Max                  22.46505
Log Pis Min                  -19.327307
Policy mu Mean               0.3363918
Policy mu Std                0.77667147
Policy mu Max                2.7232478
Policy mu Min                -3.0225487
Policy log std Mean          -0.3031584
Policy log std Std           0.15940835
Policy log std Max           -0.045643896
Policy log std Min           -1.1371409
Z mean eval                  0.04637776
Z variance eval              0.040578138
total_rewards                [1897.92705371  773.30246871 5225.05195645 2177.40273039 4309.26320382
 3231.29490523  958.16577483 5255.59461227 5290.10782457 2742.10825984]
total_rewards_mean           3186.0218789814535
total_rewards_std            1667.0270328598751
total_rewards_max            5290.107824566182
total_rewards_min            773.3024687117309
Number of train steps total  239000
Number of env steps total    1197000
Number of rollouts total     0
Train Time (s)               31.31967031210661
(Previous) Eval Time (s)     20.36819818802178
Sample Time (s)              18.879204785916954
Epoch Time (s)               70.56707328604534
Total Train Time (s)         13420.864945566282
Epoch                        238
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:59:23.024653 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #238 | Epoch Duration: 69.09226417541504
2020-01-10 21:59:23.025036 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #238 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046513647
Z variance train             0.040572084
KL Divergence                5.820902
KL Loss                      0.5820902
QF Loss                      1294.3695
VF Loss                      525.6453
Policy Loss                  -1644.544
Q Predictions Mean           1642.5991
Q Predictions Std            975.58435
Q Predictions Max            2450.7368
Q Predictions Min            14.634184
V Predictions Mean           1633.2694
V Predictions Std            962.9903
V Predictions Max            2436.3418
V Predictions Min            23.07191
Log Pis Mean                 -3.713776
Log Pis Std                  6.1974363
Log Pis Max                  25.4208
Log Pis Min                  -14.607997
Policy mu Mean               0.3036946
Policy mu Std                0.7553506
Policy mu Max                2.9565077
Policy mu Min                -3.9598165
Policy log std Mean          -0.29365957
Policy log std Std           0.15953441
Policy log std Max           -0.033338055
Policy log std Min           -1.0771701
Z mean eval                  0.045347545
Z variance eval              0.039846197
total_rewards                [4484.89115975 1222.89696598 3900.34843607 1384.7437836  1886.46276557
 5244.82623609 2235.59679799 2705.83516625 5227.63657556 1897.4647681 ]
total_rewards_mean           3019.0702654975626
total_rewards_std            1480.102834543786
total_rewards_max            5244.826236094519
total_rewards_min            1222.8969659813351
Number of train steps total  240000
Number of env steps total    1202000
Number of rollouts total     0
Train Time (s)               30.774870521388948
(Previous) Eval Time (s)     18.89309736387804
Sample Time (s)              19.442824194207788
Epoch Time (s)               69.11079207947478
Total Train Time (s)         13488.436322812922
Epoch                        239
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:00:30.596912 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #239 | Epoch Duration: 67.57167625427246
2020-01-10 22:00:30.597077 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #239 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04527057
Z variance train             0.03984988
KL Divergence                5.8570766
KL Loss                      0.58570766
QF Loss                      1087.882
VF Loss                      603.45605
Policy Loss                  -1682.5745
Q Predictions Mean           1678.5328
Q Predictions Std            956.79517
Q Predictions Max            2432.975
Q Predictions Min            16.210093
V Predictions Mean           1676.0576
V Predictions Std            948.695
V Predictions Max            2429.653
V Predictions Min            27.050735
Log Pis Mean                 -3.3321335
Log Pis Std                  6.570448
Log Pis Max                  23.473885
Log Pis Min                  -13.897055
Policy mu Mean               0.32188204
Policy mu Std                0.7566287
Policy mu Max                3.6403105
Policy mu Min                -3.6421013
Policy log std Mean          -0.29369622
Policy log std Std           0.14965896
Policy log std Max           -0.020262897
Policy log std Min           -0.8869981
Z mean eval                  0.04475643
Z variance eval              0.038338043
total_rewards                [2889.14984224 4376.39796841 1985.32432077 2850.7076727  2642.90135848
 3946.41316781 5368.90540478 1366.78549875 3254.59470683 1339.18039612]
total_rewards_mean           3002.036033689607
total_rewards_std            1228.1706954995336
total_rewards_max            5368.905404779954
total_rewards_min            1339.1803961230987
Number of train steps total  241000
Number of env steps total    1207000
Number of rollouts total     0
Train Time (s)               30.081444647163153
(Previous) Eval Time (s)     17.353658710140735
Sample Time (s)              19.500678778626025
Epoch Time (s)               66.93578213592991
Total Train Time (s)         13555.047901172657
Epoch                        240
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:01:37.213851 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #240 | Epoch Duration: 66.61660122871399
2020-01-10 22:01:37.214133 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #240 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.044927895
Z variance train             0.03833783
KL Divergence                5.9332266
KL Loss                      0.5933227
QF Loss                      2239.6367
VF Loss                      335.6813
Policy Loss                  -1706.2567
Q Predictions Mean           1705.6985
Q Predictions Std            926.97516
Q Predictions Max            2450.8728
Q Predictions Min            14.285945
V Predictions Mean           1705.3918
V Predictions Std            920.62225
V Predictions Max            2443.694
V Predictions Min            22.86319
Log Pis Mean                 -3.1112819
Log Pis Std                  6.6514883
Log Pis Max                  23.430208
Log Pis Min                  -14.318382
Policy mu Mean               0.33873
Policy mu Std                0.7756234
Policy mu Max                2.708753
Policy mu Min                -3.75276
Policy log std Mean          -0.30005696
Policy log std Std           0.1549625
Policy log std Max           -0.03856919
Policy log std Min           -0.9113892
Z mean eval                  0.045292784
Z variance eval              0.039564814
total_rewards                [2781.7555893  3070.68867658 4080.69418102 4030.41650397 2099.89894673
 3938.74597983 5067.67016996 2760.71649882 5216.45331354 1523.50051208]
total_rewards_mean           3457.0540371814677
total_rewards_std            1153.6880056001767
total_rewards_max            5216.453313539683
total_rewards_min            1523.5005120758742
Number of train steps total  242000
Number of env steps total    1212000
Number of rollouts total     0
Train Time (s)               30.321414501871914
(Previous) Eval Time (s)     17.03412104398012
Sample Time (s)              19.167701745405793
Epoch Time (s)               66.52323729125783
Total Train Time (s)         13624.724613187369
Epoch                        241
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:02:46.895506 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #241 | Epoch Duration: 69.68105244636536
2020-01-10 22:02:46.895925 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #241 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045434203
Z variance train             0.039558988
KL Divergence                5.863311
KL Loss                      0.58633107
QF Loss                      1056.2969
VF Loss                      330.2472
Policy Loss                  -1664.5319
Q Predictions Mean           1662.8822
Q Predictions Std            958.9718
Q Predictions Max            2444.7056
Q Predictions Min            15.1735
V Predictions Mean           1662.29
V Predictions Std            951.5273
V Predictions Max            2431.9026
V Predictions Min            25.301132
Log Pis Mean                 -3.2497504
Log Pis Std                  6.4140406
Log Pis Max                  20.12231
Log Pis Min                  -17.318867
Policy mu Mean               0.2953539
Policy mu Std                0.77725524
Policy mu Max                2.5743387
Policy mu Min                -3.266532
Policy log std Mean          -0.2959111
Policy log std Std           0.15395571
Policy log std Max           0.007016659
Policy log std Min           -1.0112762
Z mean eval                  0.04577956
Z variance eval              0.038640104
total_rewards                [1135.94374626 5258.1489151  4686.21614312 1134.4562766  5378.15032793
  623.21531409 5360.40968209 1228.15282574 4394.17675881 2168.05912017]
total_rewards_mean           3136.692910991973
total_rewards_std            1932.9305768693432
total_rewards_max            5378.150327927619
total_rewards_min            623.2153140880083
Number of train steps total  243000
Number of env steps total    1217000
Number of rollouts total     0
Train Time (s)               30.37555193528533
(Previous) Eval Time (s)     20.191615296062082
Sample Time (s)              20.05687533179298
Epoch Time (s)               70.62404256314039
Total Train Time (s)         13692.204081282951
Epoch                        242
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:03:54.379477 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #242 | Epoch Duration: 67.48331117630005
2020-01-10 22:03:54.379748 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #242 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04562955
Z variance train             0.03864049
KL Divergence                5.932513
KL Loss                      0.59325135
QF Loss                      1453.6565
VF Loss                      503.9274
Policy Loss                  -1706.019
Q Predictions Mean           1700.9241
Q Predictions Std            940.7881
Q Predictions Max            2438.5703
Q Predictions Min            15.133312
V Predictions Mean           1705.0281
V Predictions Std            936.5085
V Predictions Max            2437.0173
V Predictions Min            25.778357
Log Pis Mean                 -3.4155447
Log Pis Std                  6.441983
Log Pis Max                  20.2522
Log Pis Min                  -14.850185
Policy mu Mean               0.3059894
Policy mu Std                0.7594782
Policy mu Max                2.879174
Policy mu Min                -2.6025727
Policy log std Mean          -0.29443783
Policy log std Std           0.15658809
Policy log std Max           0.0075283945
Policy log std Min           -1.1025577
Z mean eval                  0.04349626
Z variance eval              0.037821613
total_rewards                [5243.98480448 5290.10130312 4504.15797994 5292.1263381  2499.43381814
 5264.8140902  5192.77749328 5280.98810951 5285.84476901 4441.11568461]
total_rewards_mean           4829.534439041166
total_rewards_std            837.7012298078092
total_rewards_max            5292.126338104394
total_rewards_min            2499.4338181426015
Number of train steps total  244000
Number of env steps total    1222000
Number of rollouts total     0
Train Time (s)               30.20021388027817
(Previous) Eval Time (s)     17.050550816114992
Sample Time (s)              19.94926033169031
Epoch Time (s)               67.20002502808347
Total Train Time (s)         13769.06113910349
Epoch                        243
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:05:11.238814 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #243 | Epoch Duration: 76.85882830619812
2020-01-10 22:05:11.239108 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #243 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04327079
Z variance train             0.037829034
KL Divergence                5.9555297
KL Loss                      0.595553
QF Loss                      1690.2639
VF Loss                      478.35004
Policy Loss                  -1645.6556
Q Predictions Mean           1633.6082
Q Predictions Std            958.4972
Q Predictions Max            2441.339
Q Predictions Min            13.565253
V Predictions Mean           1646.709
V Predictions Std            954.7697
V Predictions Max            2443.7517
V Predictions Min            26.7785
Log Pis Mean                 -3.0800507
Log Pis Std                  6.9854755
Log Pis Max                  25.562168
Log Pis Min                  -13.380584
Policy mu Mean               0.3237093
Policy mu Std                0.7819935
Policy mu Max                2.8286502
Policy mu Min                -2.8954072
Policy log std Mean          -0.30844715
Policy log std Std           0.1525531
Policy log std Max           -0.07624387
Policy log std Min           -0.9644981
Z mean eval                  0.044371977
Z variance eval              0.036339767
total_rewards                [2426.33908304 3686.92118632 4455.40169998 4010.24038198 1023.52688282
 5289.93988574 2532.01088659 5339.77255964 3270.49686696 5236.33948693]
total_rewards_mean           3727.0988919993697
total_rewards_std            1362.7619848777833
total_rewards_max            5339.772559643362
total_rewards_min            1023.5268828153584
Number of train steps total  245000
Number of env steps total    1227000
Number of rollouts total     0
Train Time (s)               30.651755258906633
(Previous) Eval Time (s)     26.70901366136968
Sample Time (s)              20.12237021373585
Epoch Time (s)               77.48313913401216
Total Train Time (s)         13841.198112062644
Epoch                        244
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:06:23.377119 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #244 | Epoch Duration: 72.13780450820923
2020-01-10 22:06:23.377328 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #244 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04412715
Z variance train             0.036349412
KL Divergence                6.0389633
KL Loss                      0.6038963
QF Loss                      1481.2988
VF Loss                      612.80206
Policy Loss                  -1798.2487
Q Predictions Mean           1792.2644
Q Predictions Std            866.3468
Q Predictions Max            2453.5483
Q Predictions Min            18.87435
V Predictions Mean           1802.7842
V Predictions Std            864.02686
V Predictions Max            2454.2148
V Predictions Min            29.121511
Log Pis Mean                 -2.6200128
Log Pis Std                  6.432815
Log Pis Max                  18.956963
Log Pis Min                  -15.050383
Policy mu Mean               0.3547756
Policy mu Std                0.8037954
Policy mu Max                2.8416414
Policy mu Min                -2.8915381
Policy log std Mean          -0.3188039
Policy log std Std           0.15706092
Policy log std Max           -0.015537277
Policy log std Min           -0.9404345
Z mean eval                  0.045015495
Z variance eval              0.03697781
total_rewards                [5218.01934824 5151.30234476 5342.22821186 4370.43507335 5228.23944223
 5244.13916388 4672.4981347   864.42240354 5189.25046974 1748.75767638]
total_rewards_mean           4302.929226867747
total_rewards_std            1537.9586939742478
total_rewards_max            5342.228211858284
total_rewards_min            864.4224035396473
Number of train steps total  246000
Number of env steps total    1232000
Number of rollouts total     0
Train Time (s)               30.57841501617804
(Previous) Eval Time (s)     21.363318449817598
Sample Time (s)              18.60569280060008
Epoch Time (s)               70.54742626659572
Total Train Time (s)         13915.456295217853
Epoch                        245
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:07:37.643919 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #245 | Epoch Duration: 74.26627135276794
2020-01-10 22:07:37.644393 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #245 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04492306
Z variance train             0.03699801
KL Divergence                5.9921
KL Loss                      0.59920996
QF Loss                      2139.1675
VF Loss                      882.31604
Policy Loss                  -1707.5817
Q Predictions Mean           1699.9503
Q Predictions Std            953.6073
Q Predictions Max            2455.17
Q Predictions Min            16.391329
V Predictions Mean           1700.6396
V Predictions Std            947.44794
V Predictions Max            2446.3474
V Predictions Min            27.799845
Log Pis Mean                 -3.5368612
Log Pis Std                  7.068317
Log Pis Max                  23.643353
Log Pis Min                  -16.086409
Policy mu Mean               0.29995593
Policy mu Std                0.77308726
Policy mu Max                2.9719582
Policy mu Min                -3.652371
Policy log std Mean          -0.3014482
Policy log std Std           0.15371743
Policy log std Max           -0.03788416
Policy log std Min           -1.005395
Z mean eval                  0.04640891
Z variance eval              0.036916714
total_rewards                [5276.25382893 4967.71890594 2316.61276888 5011.41829906 3033.0684043
 2296.05801192 3973.94187085 5171.51520117 5238.95279266 5279.37295382]
total_rewards_mean           4256.491303753672
total_rewards_std            1189.432068379026
total_rewards_max            5279.372953822226
total_rewards_min            2296.0580119246897
Number of train steps total  247000
Number of env steps total    1237000
Number of rollouts total     0
Train Time (s)               29.946553009096533
(Previous) Eval Time (s)     25.081869488116354
Sample Time (s)              19.87256888858974
Epoch Time (s)               74.90099138580263
Total Train Time (s)         13989.465692387894
Epoch                        246
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:08:51.651822 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #246 | Epoch Duration: 74.00717306137085
2020-01-10 22:08:51.652001 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #246 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046064086
Z variance train             0.03691939
KL Divergence                5.9326386
KL Loss                      0.59326386
QF Loss                      1523.6062
VF Loss                      808.0415
Policy Loss                  -1741.1743
Q Predictions Mean           1739.5073
Q Predictions Std            910.6313
Q Predictions Max            2453.0261
Q Predictions Min            15.760167
V Predictions Mean           1758.9463
V Predictions Std            913.0559
V Predictions Max            2484.9514
V Predictions Min            25.383781
Log Pis Mean                 -3.3718305
Log Pis Std                  6.020606
Log Pis Max                  19.54868
Log Pis Min                  -13.926701
Policy mu Mean               0.34523422
Policy mu Std                0.7617092
Policy mu Max                3.1993613
Policy mu Min                -3.9551792
Policy log std Mean          -0.29805622
Policy log std Std           0.15440224
Policy log std Max           -0.026248157
Policy log std Min           -1.0095205
Z mean eval                  0.04546443
Z variance eval              0.036716558
total_rewards                [1718.04546332 3070.39190304  998.50319144 1128.52842087 2047.09514745
  787.8101547  1174.88224416 5230.15049617  721.1916276  2044.70176794]
total_rewards_mean           1892.1300416681574
total_rewards_std            1307.4784622623456
total_rewards_max            5230.150496173585
total_rewards_min            721.1916275983261
Number of train steps total  248000
Number of env steps total    1242000
Number of rollouts total     0
Train Time (s)               31.76973367901519
(Previous) Eval Time (s)     24.18775484384969
Sample Time (s)              19.511304075364023
Epoch Time (s)               75.4687925982289
Total Train Time (s)         14050.93508171197
Epoch                        247
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:09:53.127221 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #247 | Epoch Duration: 61.47506237030029
2020-01-10 22:09:53.127498 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #247 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04581988
Z variance train             0.03672193
KL Divergence                5.975382
KL Loss                      0.5975382
QF Loss                      1198.0244
VF Loss                      374.5726
Policy Loss                  -1733.8723
Q Predictions Mean           1724.9792
Q Predictions Std            936.00146
Q Predictions Max            2456.008
Q Predictions Min            19.437023
V Predictions Mean           1732.9602
V Predictions Std            934.85333
V Predictions Max            2464.8384
V Predictions Min            29.991783
Log Pis Mean                 -3.0970876
Log Pis Std                  6.8120875
Log Pis Max                  25.19485
Log Pis Min                  -13.684394
Policy mu Mean               0.3604987
Policy mu Std                0.7727656
Policy mu Max                3.1676953
Policy mu Min                -2.8177977
Policy log std Mean          -0.3088559
Policy log std Std           0.15774293
Policy log std Max           -0.07928275
Policy log std Min           -0.9605954
Z mean eval                  0.046831805
Z variance eval              0.03558085
total_rewards                [1384.51722588 2616.95364047 2793.85010807 2656.46314419 1364.99908051
 5252.99113024 5242.06045531 4862.36014157 1191.24090289 1341.99500345]
total_rewards_mean           2870.743083256132
total_rewards_std            1581.6117858948605
total_rewards_max            5252.991130235653
total_rewards_min            1191.2409028890982
Number of train steps total  249000
Number of env steps total    1247000
Number of rollouts total     0
Train Time (s)               30.12672841688618
(Previous) Eval Time (s)     10.193648112937808
Sample Time (s)              19.114916518796235
Epoch Time (s)               59.435293048620224
Total Train Time (s)         14116.41764147114
Epoch                        248
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:10:58.610125 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #248 | Epoch Duration: 65.48244094848633
2020-01-10 22:10:58.610274 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #248 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046554897
Z variance train             0.035571538
KL Divergence                6.0253572
KL Loss                      0.6025357
QF Loss                      1602.7
VF Loss                      586.4351
Policy Loss                  -1754.3069
Q Predictions Mean           1748.6409
Q Predictions Std            929.45776
Q Predictions Max            2461.7964
Q Predictions Min            13.964859
V Predictions Mean           1762.1101
V Predictions Std            930.1514
V Predictions Max            2471.1033
V Predictions Min            25.537764
Log Pis Mean                 -2.7603226
Log Pis Std                  6.422924
Log Pis Max                  20.211105
Log Pis Min                  -13.73385
Policy mu Mean               0.35632354
Policy mu Std                0.75813913
Policy mu Max                3.234362
Policy mu Min                -2.3376467
Policy log std Mean          -0.2973547
Policy log std Std           0.15473503
Policy log std Max           -0.0152064115
Policy log std Min           -0.9519964
Z mean eval                  0.046688564
Z variance eval              0.03430043
total_rewards                [5142.81988064 5265.40438889 1633.74868661 5211.53813893 5255.31716944
 2887.19061943 2512.64105095 5199.65308805 4455.237435   5190.31531229]
total_rewards_mean           4275.386577021645
total_rewards_std            1315.505209888566
total_rewards_max            5265.404388888151
total_rewards_min            1633.7486866082174
Number of train steps total  250000
Number of env steps total    1252000
Number of rollouts total     0
Train Time (s)               29.371140057221055
(Previous) Eval Time (s)     16.240527171175927
Sample Time (s)              19.24593177717179
Epoch Time (s)               64.85759900556877
Total Train Time (s)         14190.125231180806
Epoch                        249
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:12:12.323562 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #249 | Epoch Duration: 73.71313619613647
2020-01-10 22:12:12.323873 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #249 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046754077
Z variance train             0.034292366
KL Divergence                6.1428137
KL Loss                      0.61428136
QF Loss                      1903.627
VF Loss                      379.3749
Policy Loss                  -1860.4832
Q Predictions Mean           1854.6348
Q Predictions Std            879.6615
Q Predictions Max            2480.1792
Q Predictions Min            17.403282
V Predictions Mean           1863.3464
V Predictions Std            878.705
V Predictions Max            2484.4404
V Predictions Min            27.337915
Log Pis Mean                 -2.7288198
Log Pis Std                  6.527014
Log Pis Max                  22.897055
Log Pis Min                  -13.151428
Policy mu Mean               0.34842408
Policy mu Std                0.7860995
Policy mu Max                3.1163158
Policy mu Min                -2.8047447
Policy log std Mean          -0.3140061
Policy log std Std           0.15236847
Policy log std Max           -0.01208473
Policy log std Min           -0.93897015
Z mean eval                  0.04579317
Z variance eval              0.033884473
total_rewards                [1394.00766681 5047.49323189 5270.56373778 5138.57832229 5162.2688888
 4385.29667941 2258.35992477 2721.56760088 5141.37103456 3748.77016262]
total_rewards_mean           4026.8277249807084
total_rewards_std            1353.6912488628484
total_rewards_max            5270.563737777231
total_rewards_min            1394.0076668059153
Number of train steps total  251000
Number of env steps total    1257000
Number of rollouts total     0
Train Time (s)               31.790105491876602
(Previous) Eval Time (s)     25.095712705980986
Sample Time (s)              19.647457882761955
Epoch Time (s)               76.53327608061954
Total Train Time (s)         14264.665131893475
Epoch                        250
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:13:26.865879 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #250 | Epoch Duration: 74.54178285598755
2020-01-10 22:13:26.866081 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #250 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045623858
Z variance train             0.033894785
KL Divergence                6.1558523
KL Loss                      0.61558527
QF Loss                      1710.2336
VF Loss                      361.06653
Policy Loss                  -1784.0363
Q Predictions Mean           1778.1917
Q Predictions Std            896.9643
Q Predictions Max            2461.4346
Q Predictions Min            14.732462
V Predictions Mean           1782.8613
V Predictions Std            892.12463
V Predictions Max            2466.1753
V Predictions Min            25.332363
Log Pis Mean                 -2.7491992
Log Pis Std                  7.082111
Log Pis Max                  30.908258
Log Pis Min                  -16.8527
Policy mu Mean               0.3140578
Policy mu Std                0.8107396
Policy mu Max                2.87881
Policy mu Min                -2.9531424
Policy log std Mean          -0.30580458
Policy log std Std           0.1537823
Policy log std Max           0.04372719
Policy log std Min           -1.0664663
Z mean eval                  0.044591263
Z variance eval              0.034462996
total_rewards                [2080.89540118 2894.19615223 2090.05484742 1991.42977669 1892.53297321
 1342.22202856 1334.1340486  3804.38308119 5249.51240472 5284.88052542]
total_rewards_mean           2796.424123923466
total_rewards_std            1412.960297475169
total_rewards_max            5284.8805254245735
total_rewards_min            1334.13404860209
Number of train steps total  252000
Number of env steps total    1262000
Number of rollouts total     0
Train Time (s)               28.222252022940665
(Previous) Eval Time (s)     23.103889661375433
Sample Time (s)              19.23341958038509
Epoch Time (s)               70.55956126470119
Total Train Time (s)         14327.45534059126
Epoch                        251
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:14:29.662052 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #251 | Epoch Duration: 62.795774936676025
2020-01-10 22:14:29.662366 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #251 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.044818144
Z variance train             0.034459654
KL Divergence                6.0978155
KL Loss                      0.60978156
QF Loss                      1058.9283
VF Loss                      614.0307
Policy Loss                  -1705.3489
Q Predictions Mean           1696.9106
Q Predictions Std            978.75165
Q Predictions Max            2474.0063
Q Predictions Min            16.814224
V Predictions Mean           1695.2417
V Predictions Std            969.2077
V Predictions Max            2465.9482
V Predictions Min            26.549055
Log Pis Mean                 -3.9659479
Log Pis Std                  5.986618
Log Pis Max                  21.344643
Log Pis Min                  -13.07359
Policy mu Mean               0.3725936
Policy mu Std                0.7235718
Policy mu Max                2.6060684
Policy mu Min                -2.3018093
Policy log std Mean          -0.29067448
Policy log std Std           0.14848271
Policy log std Max           0.03213519
Policy log std Min           -1.0268118
Z mean eval                  0.044258893
Z variance eval              0.033232305
total_rewards                [5330.15141849 5293.0352161  5239.65257818 2784.87353834 1267.2000971
 1440.35951912 1205.44006349 3754.90219987 3483.48330005 3024.03382672]
total_rewards_mean           3282.3131757462847
total_rewards_std            1562.455191846432
total_rewards_max            5330.151418487032
total_rewards_min            1205.440063492427
Number of train steps total  253000
Number of env steps total    1267000
Number of rollouts total     0
Train Time (s)               30.876704288180918
(Previous) Eval Time (s)     15.33976936712861
Sample Time (s)              19.559536036103964
Epoch Time (s)               65.77600969141349
Total Train Time (s)         14396.77089978708
Epoch                        252
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:15:38.981268 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #252 | Epoch Duration: 69.31858921051025
2020-01-10 22:15:38.981634 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #252 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.044175196
Z variance train             0.033225782
KL Divergence                6.1790385
KL Loss                      0.6179039
QF Loss                      1427.3219
VF Loss                      360.81097
Policy Loss                  -1821.9916
Q Predictions Mean           1812.6599
Q Predictions Std            914.45013
Q Predictions Max            2464.6785
Q Predictions Min            15.0691395
V Predictions Mean           1821.2812
V Predictions Std            911.1789
V Predictions Max            2472.4954
V Predictions Min            25.386642
Log Pis Mean                 -3.0150561
Log Pis Std                  6.2315335
Log Pis Max                  31.035069
Log Pis Min                  -13.827909
Policy mu Mean               0.33886814
Policy mu Std                0.7559966
Policy mu Max                3.5295281
Policy mu Min                -2.7726538
Policy log std Mean          -0.3051104
Policy log std Std           0.1515225
Policy log std Max           -0.054875724
Policy log std Min           -0.9234431
Z mean eval                  0.045944367
Z variance eval              0.03443531
total_rewards                [2203.19466655 4636.20117098 5209.39097987 4307.906785   5182.53440017
 2401.17435377 3400.7368075  3834.97233727 1235.612242    759.7555548 ]
total_rewards_mean           3317.1479297910955
total_rewards_std            1516.899148528742
total_rewards_max            5209.390979872892
total_rewards_min            759.7555547988683
Number of train steps total  254000
Number of env steps total    1272000
Number of rollouts total     0
Train Time (s)               30.79924609605223
(Previous) Eval Time (s)     18.88205445976928
Sample Time (s)              19.264038195833564
Epoch Time (s)               68.94533875165507
Total Train Time (s)         14465.652959780302
Epoch                        253
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:16:47.865787 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #253 | Epoch Duration: 68.88395500183105
2020-01-10 22:16:47.866017 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #253 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046253733
Z variance train             0.034434512
KL Divergence                6.078804
KL Loss                      0.6078804
QF Loss                      1858.918
VF Loss                      936.557
Policy Loss                  -1823.6176
Q Predictions Mean           1817.2068
Q Predictions Std            909.0657
Q Predictions Max            2481.0315
Q Predictions Min            15.995248
V Predictions Mean           1811.3593
V Predictions Std            898.2057
V Predictions Max            2452.583
V Predictions Min            27.289915
Log Pis Mean                 -2.685443
Log Pis Std                  6.8130164
Log Pis Max                  23.209583
Log Pis Min                  -12.637444
Policy mu Mean               0.34285596
Policy mu Std                0.80039585
Policy mu Max                3.3318913
Policy mu Min                -3.6413052
Policy log std Mean          -0.30653518
Policy log std Std           0.15200202
Policy log std Max           0.0037908852
Policy log std Min           -1.0844762
Z mean eval                  0.04602558
Z variance eval              0.032309048
total_rewards                [1898.14119928 1443.36340187 1533.28968514 3872.53934587 5205.99066467
 4958.11733289 2897.86993136 5208.02711663 3539.10404766 5184.19056597]
total_rewards_mean           3574.06332913445
total_rewards_std            1479.9338335867083
total_rewards_max            5208.027116634063
total_rewards_min            1443.3634018735627
Number of train steps total  255000
Number of env steps total    1277000
Number of rollouts total     0
Train Time (s)               30.035377531778067
(Previous) Eval Time (s)     18.8203620351851
Sample Time (s)              18.972718944773078
Epoch Time (s)               67.82845851173624
Total Train Time (s)         14535.045235555153
Epoch                        254
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:17:57.266027 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #254 | Epoch Duration: 69.39970016479492
2020-01-10 22:17:57.266447 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #254 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046014126
Z variance train             0.032304734
KL Divergence                6.223476
KL Loss                      0.6223476
QF Loss                      1557.6404
VF Loss                      480.7534
Policy Loss                  -1844.4645
Q Predictions Mean           1836.4132
Q Predictions Std            933.05475
Q Predictions Max            2486.9407
Q Predictions Min            16.487167
V Predictions Mean           1839.1277
V Predictions Std            926.37244
V Predictions Max            2488.3457
V Predictions Min            25.495955
Log Pis Mean                 -2.8759449
Log Pis Std                  6.8093266
Log Pis Max                  38.512352
Log Pis Min                  -13.77673
Policy mu Mean               0.34383988
Policy mu Std                0.76097256
Policy mu Max                2.9155068
Policy mu Min                -3.2717953
Policy log std Mean          -0.30609614
Policy log std Std           0.15036976
Policy log std Max           -0.087230235
Policy log std Min           -0.985015
Z mean eval                  0.044054195
Z variance eval              0.033514693
total_rewards                [4732.55262728 4952.79573654 5265.64426891 5220.00384232 5184.04860323
 5246.19140329 1868.79262042 5288.57045028 5310.07837762 1470.00659514]
total_rewards_mean           4453.868452503377
total_rewards_std            1405.3236968381955
total_rewards_max            5310.078377624134
total_rewards_min            1470.0065951350996
Number of train steps total  256000
Number of env steps total    1282000
Number of rollouts total     0
Train Time (s)               31.768336253706366
(Previous) Eval Time (s)     20.391266179736704
Sample Time (s)              19.205735445022583
Epoch Time (s)               71.36533787846565
Total Train Time (s)         14612.064283619635
Epoch                        255
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:19:14.287312 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #255 | Epoch Duration: 77.02061700820923
2020-01-10 22:19:14.287603 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #255 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04431633
Z variance train             0.03351134
KL Divergence                6.119444
KL Loss                      0.6119444
QF Loss                      1748.3262
VF Loss                      484.07776
Policy Loss                  -1805.3829
Q Predictions Mean           1800.0009
Q Predictions Std            918.8822
Q Predictions Max            2484.1082
Q Predictions Min            14.966358
V Predictions Mean           1811.0614
V Predictions Std            917.53357
V Predictions Max            2489.369
V Predictions Min            27.471846
Log Pis Mean                 -3.6570828
Log Pis Std                  6.1612163
Log Pis Max                  21.75326
Log Pis Min                  -13.416044
Policy mu Mean               0.3223109
Policy mu Std                0.7761507
Policy mu Max                2.9204192
Policy mu Min                -3.0661263
Policy log std Mean          -0.29611433
Policy log std Std           0.14725862
Policy log std Max           -0.03791789
Policy log std Min           -0.8945288
Z mean eval                  0.04385542
Z variance eval              0.031601645
total_rewards                [2904.65066804 3125.71781501 5094.80676535 4413.07561584 3809.23424811
 4160.34861946 5094.90483236 5129.32314593 1333.3140762  5176.65204362]
total_rewards_mean           4024.2027829914928
total_rewards_std            1198.3133783997794
total_rewards_max            5176.652043624012
total_rewards_min            1333.3140761968195
Number of train steps total  257000
Number of env steps total    1287000
Number of rollouts total     0
Train Time (s)               32.103923671878874
(Previous) Eval Time (s)     26.046258277259767
Sample Time (s)              19.461076219566166
Epoch Time (s)               77.61125816870481
Total Train Time (s)         14686.921096454374
Epoch                        256
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:20:29.147204 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #256 | Epoch Duration: 74.85939407348633
2020-01-10 22:20:29.147430 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #256 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043710016
Z variance train             0.03159497
KL Divergence                6.2534013
KL Loss                      0.62534016
QF Loss                      1205.1654
VF Loss                      403.20496
Policy Loss                  -1820.0815
Q Predictions Mean           1818.3351
Q Predictions Std            929.63525
Q Predictions Max            2488.3716
Q Predictions Min            19.945396
V Predictions Mean           1826.1924
V Predictions Std            927.408
V Predictions Max            2480.6233
V Predictions Min            28.121801
Log Pis Mean                 -3.3737993
Log Pis Std                  5.867406
Log Pis Max                  13.632038
Log Pis Min                  -15.941832
Policy mu Mean               0.3562775
Policy mu Std                0.7379507
Policy mu Max                2.9309576
Policy mu Min                -2.4914498
Policy log std Mean          -0.29863736
Policy log std Std           0.15077083
Policy log std Max           -0.021593593
Policy log std Min           -0.9979993
Z mean eval                  0.04120574
Z variance eval              0.030811321
total_rewards                [3268.13710959 5116.52221848 5294.84442482 5208.27716746 2748.14536669
 5182.14745563 2061.71714409 5157.48809737 3784.52013836 2422.80025378]
total_rewards_mean           4024.459937626837
total_rewards_std            1245.316844510809
total_rewards_max            5294.844424815217
total_rewards_min            2061.717144094493
Number of train steps total  258000
Number of env steps total    1292000
Number of rollouts total     0
Train Time (s)               31.458914621267468
(Previous) Eval Time (s)     23.294073538854718
Sample Time (s)              19.640184436924756
Epoch Time (s)               74.39317259704694
Total Train Time (s)         14762.018059502821
Epoch                        257
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:21:44.245847 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #257 | Epoch Duration: 75.09825778007507
2020-01-10 22:21:44.246044 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #257 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04101197
Z variance train             0.03079904
KL Divergence                6.3096447
KL Loss                      0.63096446
QF Loss                      999.1875
VF Loss                      548.29083
Policy Loss                  -1840.6609
Q Predictions Mean           1836.6284
Q Predictions Std            931.47235
Q Predictions Max            2495.9458
Q Predictions Min            17.939491
V Predictions Mean           1845.868
V Predictions Std            925.52313
V Predictions Max            2495.9705
V Predictions Min            31.606459
Log Pis Mean                 -3.071632
Log Pis Std                  6.379184
Log Pis Max                  21.2416
Log Pis Min                  -13.381122
Policy mu Mean               0.38136813
Policy mu Std                0.7412515
Policy mu Max                2.69709
Policy mu Min                -3.2570143
Policy log std Mean          -0.2974301
Policy log std Std           0.15170571
Policy log std Max           -0.03524535
Policy log std Min           -1.042486
Z mean eval                  0.04182426
Z variance eval              0.030714069
total_rewards                [1542.15794396 4903.53285032 3376.54541528 5228.09616683 5164.73648788
 3927.15368501 2460.78527161 5216.08620682 1098.01665942 1288.86148193]
total_rewards_mean           3420.597216906129
total_rewards_std            1624.1595929933728
total_rewards_max            5228.096166831481
total_rewards_min            1098.0166594187074
Number of train steps total  259000
Number of env steps total    1297000
Number of rollouts total     0
Train Time (s)               30.27634391700849
(Previous) Eval Time (s)     23.998848831281066
Sample Time (s)              19.994435489177704
Epoch Time (s)               74.26962823746726
Total Train Time (s)         14832.348294549622
Epoch                        258
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:22:54.582461 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #258 | Epoch Duration: 70.33623480796814
2020-01-10 22:22:54.582785 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #258 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.041293696
Z variance train             0.030712962
KL Divergence                6.3411255
KL Loss                      0.63411254
QF Loss                      1359.3671
VF Loss                      530.0421
Policy Loss                  -1896.3707
Q Predictions Mean           1897.5348
Q Predictions Std            877.3312
Q Predictions Max            2489.4812
Q Predictions Min            16.925127
V Predictions Mean           1905.0789
V Predictions Std            875.62006
V Predictions Max            2492.4219
V Predictions Min            29.576591
Log Pis Mean                 -3.0263424
Log Pis Std                  5.93422
Log Pis Max                  28.623425
Log Pis Min                  -13.73077
Policy mu Mean               0.3251373
Policy mu Std                0.76819086
Policy mu Max                2.7731519
Policy mu Min                -2.5458965
Policy log std Mean          -0.31194228
Policy log std Std           0.15331608
Policy log std Max           -0.006794527
Policy log std Min           -1.0107476
Z mean eval                  0.041611694
Z variance eval              0.030490357
total_rewards                [5178.31346283 5108.57027022 1524.48079854 5177.91863423 5199.4748723
 2725.84327193 5183.83731183 1979.08736197 5196.74212571 5039.85927598]
total_rewards_mean           4231.41273855343
total_rewards_std            1437.3166933005625
total_rewards_max            5199.474872301378
total_rewards_min            1524.4807985384539
Number of train steps total  260000
Number of env steps total    1302000
Number of rollouts total     0
Train Time (s)               30.204966506920755
(Previous) Eval Time (s)     20.065080446191132
Sample Time (s)              20.206059756223112
Epoch Time (s)               70.476106709335
Total Train Time (s)         14906.852315116674
Epoch                        259
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:24:09.091542 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #259 | Epoch Duration: 74.50849628448486
2020-01-10 22:24:09.091864 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #259 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04173519
Z variance train             0.030472586
KL Divergence                6.367944
KL Loss                      0.6367944
QF Loss                      1626.5078
VF Loss                      504.5596
Policy Loss                  -1927.2882
Q Predictions Mean           1929.107
Q Predictions Std            877.95123
Q Predictions Max            2512.216
Q Predictions Min            15.914051
V Predictions Mean           1915.6162
V Predictions Std            868.5833
V Predictions Max            2495.3557
V Predictions Min            27.458162
Log Pis Mean                 -3.1916986
Log Pis Std                  6.0786867
Log Pis Max                  21.369635
Log Pis Min                  -14.952079
Policy mu Mean               0.2862917
Policy mu Std                0.7903441
Policy mu Max                3.122334
Policy mu Min                -2.2015603
Policy log std Mean          -0.3167186
Policy log std Std           0.14719148
Policy log std Max           -0.04700531
Policy log std Min           -0.9220248
Z mean eval                  0.038581025
Z variance eval              0.031028977
total_rewards                [ 962.68008895 1656.74676776 5217.44977693 1539.86929772 4730.33442562
 5240.38889594 2180.32432948 2433.21900024 5224.87254041 5177.26713676]
total_rewards_mean           3436.315225981171
total_rewards_std            1726.192794114774
total_rewards_max            5240.388895935765
total_rewards_min            962.6800889478767
Number of train steps total  261000
Number of env steps total    1307000
Number of rollouts total     0
Train Time (s)               29.47041170904413
(Previous) Eval Time (s)     24.09714180417359
Sample Time (s)              19.51555730542168
Epoch Time (s)               73.0831108186394
Total Train Time (s)         14975.608168225735
Epoch                        260
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:25:17.853075 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #260 | Epoch Duration: 68.76094508171082
2020-01-10 22:25:17.853410 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #260 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.038439054
Z variance train             0.031029422
KL Divergence                6.314392
KL Loss                      0.6314392
QF Loss                      1418.4246
VF Loss                      1024.3496
Policy Loss                  -1872.9685
Q Predictions Mean           1871.3838
Q Predictions Std            900.4298
Q Predictions Max            2518.7952
Q Predictions Min            15.848248
V Predictions Mean           1891.2725
V Predictions Std            904.56964
V Predictions Max            2522.8162
V Predictions Min            23.96138
Log Pis Mean                 -2.414671
Log Pis Std                  6.8753676
Log Pis Max                  25.876331
Log Pis Min                  -12.43674
Policy mu Mean               0.36983916
Policy mu Std                0.7854666
Policy mu Max                2.7676477
Policy mu Min                -3.8854153
Policy log std Mean          -0.30961215
Policy log std Std           0.15432563
Policy log std Max           -0.010918781
Policy log std Min           -1.1902467
Z mean eval                  0.040639475
Z variance eval              0.03147713
total_rewards                [5202.15324496 1478.90738176 2880.97123391 1427.08058383 3938.78570536
 2184.10154819 1081.96780154 2486.15539882 2678.90765448 5220.737257  ]
total_rewards_mean           2857.9767809839855
total_rewards_std            1413.3083877486667
total_rewards_max            5220.73725699595
total_rewards_min            1081.967801536436
Number of train steps total  262000
Number of env steps total    1312000
Number of rollouts total     0
Train Time (s)               31.20113766985014
(Previous) Eval Time (s)     19.77465305617079
Sample Time (s)              19.115757818799466
Epoch Time (s)               70.0915485448204
Total Train Time (s)         15042.585458472371
Epoch                        261
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:26:24.835751 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #261 | Epoch Duration: 66.98209404945374
2020-01-10 22:26:24.836084 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #261 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04036647
Z variance train             0.03146959
KL Divergence                6.253211
KL Loss                      0.6253211
QF Loss                      1631.7635
VF Loss                      417.3072
Policy Loss                  -1843.2556
Q Predictions Mean           1835.3877
Q Predictions Std            917.59
Q Predictions Max            2507.0503
Q Predictions Min            21.880936
V Predictions Mean           1849.2603
V Predictions Std            916.17975
V Predictions Max            2518.4673
V Predictions Min            31.639845
Log Pis Mean                 -3.7142694
Log Pis Std                  6.2527113
Log Pis Max                  22.560453
Log Pis Min                  -13.557387
Policy mu Mean               0.35883877
Policy mu Std                0.74494356
Policy mu Max                3.203988
Policy mu Min                -3.6197784
Policy log std Mean          -0.29366338
Policy log std Std           0.14722922
Policy log std Max           -0.045606382
Policy log std Min           -1.0855813
Z mean eval                  0.03815492
Z variance eval              0.031136533
total_rewards                [5264.82429792 3470.2608192  5264.16533361 5223.50102613 5200.92941879
 2610.95021934 1435.2636643  5266.86134872 1954.32762656 5197.13967898]
total_rewards_mean           4088.8223433550384
total_rewards_std            1485.5638172156396
total_rewards_max            5266.861348716067
total_rewards_min            1435.2636642997732
Number of train steps total  263000
Number of env steps total    1317000
Number of rollouts total     0
Train Time (s)               31.160232258960605
(Previous) Eval Time (s)     16.66487690899521
Sample Time (s)              20.142131824512035
Epoch Time (s)               67.96724099246785
Total Train Time (s)         15117.134228212759
Epoch                        262
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:27:39.406571 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #262 | Epoch Duration: 74.57023119926453
2020-01-10 22:27:39.406887 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #262 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03800435
Z variance train             0.031151915
KL Divergence                6.2770405
KL Loss                      0.6277041
QF Loss                      1258.3636
VF Loss                      737.46924
Policy Loss                  -1883.408
Q Predictions Mean           1887.2439
Q Predictions Std            882.5871
Q Predictions Max            2504.4646
Q Predictions Min            14.495511
V Predictions Mean           1900.1685
V Predictions Std            881.8643
V Predictions Max            2513.0823
V Predictions Min            26.181963
Log Pis Mean                 -3.1167402
Log Pis Std                  5.7148237
Log Pis Max                  16.088875
Log Pis Min                  -12.683647
Policy mu Mean               0.38080087
Policy mu Std                0.7469894
Policy mu Max                3.009706
Policy mu Min                -3.3601878
Policy log std Mean          -0.3018028
Policy log std Std           0.15499967
Policy log std Max           0.084134266
Policy log std Min           -0.9685974
Z mean eval                  0.039289284
Z variance eval              0.031441897
total_rewards                [5195.97941845 5334.58024026 5304.94529176 2350.79921037 4875.42711244
 1591.81777822 2191.66561504 5226.49679967 2248.27309768 3610.30377261]
total_rewards_mean           3793.028833649279
total_rewards_std            1475.3419328726447
total_rewards_max            5334.580240256119
total_rewards_min            1591.8177782186108
Number of train steps total  264000
Number of env steps total    1322000
Number of rollouts total     0
Train Time (s)               33.005044838413596
(Previous) Eval Time (s)     23.267531509976834
Sample Time (s)              20.4632630571723
Epoch Time (s)               76.73583940556273
Total Train Time (s)         15192.226301939227
Epoch                        263
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:28:54.484644 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #263 | Epoch Duration: 75.07752752304077
2020-01-10 22:28:54.484902 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #263 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039381366
Z variance train             0.03142719
KL Divergence                6.2727323
KL Loss                      0.62727326
QF Loss                      792.4442
VF Loss                      564.4058
Policy Loss                  -1971.0239
Q Predictions Mean           1967.5295
Q Predictions Std            856.6935
Q Predictions Max            2512.1802
Q Predictions Min            21.744602
V Predictions Mean           1969.6255
V Predictions Std            852.5861
V Predictions Max            2513.8171
V Predictions Min            30.128517
Log Pis Mean                 -3.0577424
Log Pis Std                  6.063567
Log Pis Max                  30.93778
Log Pis Min                  -13.288755
Policy mu Mean               0.36825538
Policy mu Std                0.7486817
Policy mu Max                2.9041185
Policy mu Min                -2.7671363
Policy log std Mean          -0.3108548
Policy log std Std           0.14647594
Policy log std Max           -0.036517493
Policy log std Min           -0.9118347
Z mean eval                  0.034986086
Z variance eval              0.030952599
total_rewards                [1922.49253988 5251.57118992 5258.38474148 1287.56277628  857.97311722
 1475.59762225 1299.95163958 5287.20181649 5237.63829385 1169.80876436]
total_rewards_mean           2904.8182501306724
total_rewards_std            1938.1152139803007
total_rewards_max            5287.201816489682
total_rewards_min            857.9731172186436
Number of train steps total  265000
Number of env steps total    1327000
Number of rollouts total     0
Train Time (s)               31.148346145171672
(Previous) Eval Time (s)     21.608867703936994
Sample Time (s)              19.544520064722747
Epoch Time (s)               72.30173391383141
Total Train Time (s)         15259.928324314766
Epoch                        264
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:30:02.196514 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #264 | Epoch Duration: 67.71138334274292
2020-01-10 22:30:02.196847 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #264 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035161942
Z variance train             0.030958619
KL Divergence                6.322424
KL Loss                      0.6322424
QF Loss                      1518.4072
VF Loss                      721.3235
Policy Loss                  -1813.0117
Q Predictions Mean           1809.7878
Q Predictions Std            970.76337
Q Predictions Max            2524.9563
Q Predictions Min            15.668155
V Predictions Mean           1798.7048
V Predictions Std            958.61957
V Predictions Max            2512.5784
V Predictions Min            24.855515
Log Pis Mean                 -4.009309
Log Pis Std                  6.259169
Log Pis Max                  23.472769
Log Pis Min                  -17.259163
Policy mu Mean               0.32968172
Policy mu Std                0.7188454
Policy mu Max                2.86568
Policy mu Min                -2.6230657
Policy log std Mean          -0.290382
Policy log std Std           0.14903398
Policy log std Max           -0.056250393
Policy log std Min           -1.0064836
Z mean eval                  0.03509235
Z variance eval              0.030931467
total_rewards                [2923.84463459 5248.2697108  5251.30479408 3020.58140275 5207.66474925
 4986.77009566 2250.38326986 5317.44712269 4746.20552491 2633.94884507]
total_rewards_mean           4158.642014966102
total_rewards_std            1210.022837125578
total_rewards_max            5317.447122687485
total_rewards_min            2250.3832698553488
Number of train steps total  266000
Number of env steps total    1332000
Number of rollouts total     0
Train Time (s)               32.2398831397295
(Previous) Eval Time (s)     17.01819316809997
Sample Time (s)              19.23211292270571
Epoch Time (s)               68.49018923053518
Total Train Time (s)         15335.129381057806
Epoch                        265
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:31:17.396244 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #265 | Epoch Duration: 75.19917345046997
2020-01-10 22:31:17.396466 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #265 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035211805
Z variance train             0.03094497
KL Divergence                6.3225985
KL Loss                      0.63225985
QF Loss                      1763.0564
VF Loss                      679.4428
Policy Loss                  -1949.8041
Q Predictions Mean           1948.3103
Q Predictions Std            848.6925
Q Predictions Max            2517.4739
Q Predictions Min            15.947787
V Predictions Mean           1950.799
V Predictions Std            847.4975
V Predictions Max            2527.1594
V Predictions Min            25.938854
Log Pis Mean                 -2.4310403
Log Pis Std                  6.594424
Log Pis Max                  30.163631
Log Pis Min                  -13.295082
Policy mu Mean               0.35669875
Policy mu Std                0.78857327
Policy mu Max                2.984364
Policy mu Min                -3.279421
Policy log std Mean          -0.31721994
Policy log std Std           0.15751655
Policy log std Max           -0.041882664
Policy log std Min           -0.9641072
Z mean eval                  0.031752992
Z variance eval              0.029160867
total_rewards                [4602.16412495 4377.80228418 5278.4984038  5204.32251214  873.79566201
 4108.58241121 5216.52313374 5179.85136381 5226.31165776 5247.58719386]
total_rewards_mean           4531.543874745433
total_rewards_std            1283.8276262802365
total_rewards_max            5278.498403801394
total_rewards_min            873.7956620106373
Number of train steps total  267000
Number of env steps total    1337000
Number of rollouts total     0
Train Time (s)               31.067203066311777
(Previous) Eval Time (s)     23.726876161061227
Sample Time (s)              19.66390373976901
Epoch Time (s)               74.45798296714202
Total Train Time (s)         15411.656379782129
Epoch                        266
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:32:33.924926 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #266 | Epoch Duration: 76.52830767631531
2020-01-10 22:32:33.925074 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #266 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032017276
Z variance train             0.029166246
KL Divergence                6.4405193
KL Loss                      0.64405197
QF Loss                      1131.137
VF Loss                      266.15012
Policy Loss                  -1930.2277
Q Predictions Mean           1926.8015
Q Predictions Std            909.7392
Q Predictions Max            2520.828
Q Predictions Min            15.267494
V Predictions Mean           1925.3679
V Predictions Std            901.35
V Predictions Max            2521.8982
V Predictions Min            27.762245
Log Pis Mean                 -4.10617
Log Pis Std                  5.7750044
Log Pis Max                  19.38028
Log Pis Min                  -12.994457
Policy mu Mean               0.37337235
Policy mu Std                0.7003536
Policy mu Max                2.5380912
Policy mu Min                -2.9003043
Policy log std Mean          -0.2934084
Policy log std Std           0.14981431
Policy log std Max           -0.034597278
Policy log std Min           -1.094646
Z mean eval                  0.02927028
Z variance eval              0.029744063
total_rewards                [3214.77568002 2090.34923248  937.66697676 5328.43143226 3171.27806541
 2698.60170969 2267.8859477  5139.60727158 1928.68480962 2267.12572324]
total_rewards_mean           2904.4406848760345
total_rewards_std            1318.1804135981613
total_rewards_max            5328.4314322647815
total_rewards_min            937.6669767582919
Number of train steps total  268000
Number of env steps total    1342000
Number of rollouts total     0
Train Time (s)               28.587480958085507
(Previous) Eval Time (s)     25.796882405877113
Sample Time (s)              20.605284248944372
Epoch Time (s)               74.98964761290699
Total Train Time (s)         15476.535460623447
Epoch                        267
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:33:38.807551 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #267 | Epoch Duration: 64.88235020637512
2020-01-10 22:33:38.807758 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #267 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029129628
Z variance train             0.029729787
KL Divergence                6.38073
KL Loss                      0.638073
QF Loss                      2268.0767
VF Loss                      605.47125
Policy Loss                  -1904.4755
Q Predictions Mean           1902.2422
Q Predictions Std            890.5388
Q Predictions Max            2521.5608
Q Predictions Min            16.446556
V Predictions Mean           1913.4779
V Predictions Std            891.0063
V Predictions Max            2533.616
V Predictions Min            25.568321
Log Pis Mean                 -3.0562668
Log Pis Std                  6.5071907
Log Pis Max                  30.276596
Log Pis Min                  -13.83776
Policy mu Mean               0.360495
Policy mu Std                0.75130737
Policy mu Max                2.847066
Policy mu Min                -3.6063757
Policy log std Mean          -0.3094418
Policy log std Std           0.15214668
Policy log std Max           -0.02279596
Policy log std Min           -1.1020274
Z mean eval                  0.026209135
Z variance eval              0.030207211
total_rewards                [2907.03074509 5169.88367339 1707.90609251 3908.62728045 5403.38918643
 5234.93681392 5304.1088461  2692.3352413  1660.04558875 5318.97311987]
total_rewards_mean           3930.7236587813322
total_rewards_std            1479.7835931579523
total_rewards_max            5403.389186430462
total_rewards_min            1660.0455887456937
Number of train steps total  269000
Number of env steps total    1347000
Number of rollouts total     0
Train Time (s)               31.243031003978103
(Previous) Eval Time (s)     15.68926660111174
Sample Time (s)              18.668275407515466
Epoch Time (s)               65.60057301260531
Total Train Time (s)         15549.161482773256
Epoch                        268
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:34:51.439611 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #268 | Epoch Duration: 72.63164234161377
2020-01-10 22:34:51.439964 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #268 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026078809
Z variance train             0.030214036
KL Divergence                6.3378506
KL Loss                      0.63378507
QF Loss                      1371.1877
VF Loss                      437.5358
Policy Loss                  -1918.9652
Q Predictions Mean           1916.5995
Q Predictions Std            889.1934
Q Predictions Max            2536.04
Q Predictions Min            17.82644
V Predictions Mean           1920.8726
V Predictions Std            885.2543
V Predictions Max            2536.3218
V Predictions Min            26.356308
Log Pis Mean                 -2.8744884
Log Pis Std                  7.0017376
Log Pis Max                  29.877476
Log Pis Min                  -17.039906
Policy mu Mean               0.364967
Policy mu Std                0.7687106
Policy mu Max                3.6194246
Policy mu Min                -3.358286
Policy log std Mean          -0.3010767
Policy log std Std           0.1540286
Policy log std Max           0.0091894865
Policy log std Min           -0.9819174
Z mean eval                  0.024386538
Z variance eval              0.030635241
total_rewards                [5266.25073659 2765.90906143 5032.07852763 5168.68736852 3606.2907659
 5251.15741068 2969.4463137  5061.78302459 4948.33175589 3831.44152625]
total_rewards_mean           4390.137649118657
total_rewards_std            941.9599126172037
total_rewards_max            5266.250736589722
total_rewards_min            2765.9090614315846
Number of train steps total  270000
Number of env steps total    1352000
Number of rollouts total     0
Train Time (s)               32.14803109085187
(Previous) Eval Time (s)     22.720041133929044
Sample Time (s)              20.106686000712216
Epoch Time (s)               74.97475822549313
Total Train Time (s)         15626.711299937684
Epoch                        269
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:36:08.993660 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #269 | Epoch Duration: 77.5534451007843
2020-01-10 22:36:08.993945 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #269 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024437116
Z variance train             0.03063457
KL Divergence                6.3105545
KL Loss                      0.6310555
QF Loss                      1305.6025
VF Loss                      317.30533
Policy Loss                  -2005.593
Q Predictions Mean           2002.5984
Q Predictions Std            843.79
Q Predictions Max            2529.853
Q Predictions Min            18.476694
V Predictions Mean           2009.5413
V Predictions Std            843.3217
V Predictions Max            2548.2913
V Predictions Min            27.924185
Log Pis Mean                 -3.6103923
Log Pis Std                  5.573767
Log Pis Max                  17.899809
Log Pis Min                  -18.558453
Policy mu Mean               0.347181
Policy mu Std                0.72588855
Policy mu Max                2.7840838
Policy mu Min                -3.1825671
Policy log std Mean          -0.29380175
Policy log std Std           0.14392559
Policy log std Max           -0.023110062
Policy log std Min           -0.9630724
Z mean eval                  0.022470422
Z variance eval              0.031168606
total_rewards                [3296.93536325 1598.3022177  4519.37101784 5269.71235198 3364.0239305
 3655.70394938  738.71570938 1132.64167173 1285.95823469 1676.31888661]
total_rewards_mean           2653.7683333062587
total_rewards_std            1488.8657356104784
total_rewards_max            5269.712351976703
total_rewards_min            738.7157093820797
Number of train steps total  271000
Number of env steps total    1357000
Number of rollouts total     0
Train Time (s)               28.326684914994985
(Previous) Eval Time (s)     25.298446730244905
Sample Time (s)              19.877931668423116
Epoch Time (s)               73.503063313663
Total Train Time (s)         15689.64575047139
Epoch                        270
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:37:11.932946 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #270 | Epoch Duration: 62.93875765800476
2020-01-10 22:37:11.933236 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #270 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022673784
Z variance train             0.031157335
KL Divergence                6.274152
KL Loss                      0.6274152
QF Loss                      1257.7798
VF Loss                      592.0379
Policy Loss                  -2012.7732
Q Predictions Mean           2010.6091
Q Predictions Std            838.98303
Q Predictions Max            2546.8296
Q Predictions Min            11.603132
V Predictions Mean           2012.7219
V Predictions Std            830.8696
V Predictions Max            2535.767
V Predictions Min            22.757734
Log Pis Mean                 -3.5467749
Log Pis Std                  5.7698183
Log Pis Max                  24.948437
Log Pis Min                  -14.7312355
Policy mu Mean               0.4009343
Policy mu Std                0.717281
Policy mu Max                3.3099122
Policy mu Min                -2.9199963
Policy log std Mean          -0.29903057
Policy log std Std           0.14434671
Policy log std Max           -0.035623007
Policy log std Min           -0.90839624
Z mean eval                  0.023617785
Z variance eval              0.03087456
total_rewards                [5180.24936756 1132.75367931  778.54208958 1186.05742953 5144.71593213
 4980.31796433 1443.53339314 2831.55303148 2850.62505653 1437.67177793]
total_rewards_mean           2696.601972152884
total_rewards_std            1702.3650045345296
total_rewards_max            5180.249367557604
total_rewards_min            778.5420895834146
Number of train steps total  272000
Number of env steps total    1362000
Number of rollouts total     0
Train Time (s)               30.81027228711173
(Previous) Eval Time (s)     14.733820754103363
Sample Time (s)              19.77846052777022
Epoch Time (s)               65.32255356898531
Total Train Time (s)         15755.77800675761
Epoch                        271
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:38:18.069558 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #271 | Epoch Duration: 66.1360867023468
2020-01-10 22:38:18.069844 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #271 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023377182
Z variance train             0.030876394
KL Divergence                6.2984977
KL Loss                      0.6298498
QF Loss                      1202.81
VF Loss                      521.6581
Policy Loss                  -1831.6304
Q Predictions Mean           1827.2117
Q Predictions Std            945.1866
Q Predictions Max            2536.0374
Q Predictions Min            13.803177
V Predictions Mean           1836.478
V Predictions Std            944.9495
V Predictions Max            2552.3994
V Predictions Min            25.42434
Log Pis Mean                 -3.8879256
Log Pis Std                  6.3977103
Log Pis Max                  34.808075
Log Pis Min                  -12.5998955
Policy mu Mean               0.32110226
Policy mu Std                0.73161316
Policy mu Max                3.5090044
Policy mu Min                -4.7665863
Policy log std Mean          -0.2937273
Policy log std Std           0.15442589
Policy log std Max           -0.020499215
Policy log std Min           -0.94945323
Z mean eval                  0.02082814
Z variance eval              0.033193212
total_rewards                [ 691.53017584 5300.69197354 1139.66149438 1094.10457458 5312.3042246
 1408.4869337  3780.7389152  4653.18010717 2318.26720872 3388.71711236]
total_rewards_mean           2908.768272009471
total_rewards_std            1716.6934470746212
total_rewards_max            5312.304224601497
total_rewards_min            691.530175839947
Number of train steps total  273000
Number of env steps total    1367000
Number of rollouts total     0
Train Time (s)               31.233114338014275
(Previous) Eval Time (s)     15.547030790243298
Sample Time (s)              19.258812594227493
Epoch Time (s)               66.03895772248507
Total Train Time (s)         15823.015186991543
Epoch                        272
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:39:25.313206 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #272 | Epoch Duration: 67.2431378364563
2020-01-10 22:39:25.313465 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #272 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020721424
Z variance train             0.033186335
KL Divergence                6.1557426
KL Loss                      0.6155743
QF Loss                      2037.3712
VF Loss                      589.79004
Policy Loss                  -1962.0647
Q Predictions Mean           1955.7295
Q Predictions Std            865.82306
Q Predictions Max            2534.8403
Q Predictions Min            16.422224
V Predictions Mean           1968.0411
V Predictions Std            862.9583
V Predictions Max            2546.7114
V Predictions Min            23.50099
Log Pis Mean                 -3.9482865
Log Pis Std                  5.504664
Log Pis Max                  13.420942
Log Pis Min                  -13.600612
Policy mu Mean               0.36520547
Policy mu Std                0.70756656
Policy mu Max                2.7270896
Policy mu Min                -3.6370554
Policy log std Mean          -0.2953725
Policy log std Std           0.14697644
Policy log std Max           0.042672083
Policy log std Min           -1.0434902
Z mean eval                  0.022035217
Z variance eval              0.03260125
total_rewards                [4453.72028545 1378.27390866 3037.81444177 5076.91791927 5091.55988376
 5229.74680988 2590.16262436 5232.21859296 1095.72068455 2682.44253014]
total_rewards_mean           3586.8577680801072
total_rewards_std            1543.9746863915962
total_rewards_max            5232.218592959387
total_rewards_min            1095.7206845485323
Number of train steps total  274000
Number of env steps total    1372000
Number of rollouts total     0
Train Time (s)               31.55398309091106
(Previous) Eval Time (s)     16.75087448209524
Sample Time (s)              19.793664255645126
Epoch Time (s)               68.09852182865143
Total Train Time (s)         15895.2375794705
Epoch                        273
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:40:37.539929 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #273 | Epoch Duration: 72.22625255584717
2020-01-10 22:40:37.540222 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #273 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022224396
Z variance train             0.032597456
KL Divergence                6.1894293
KL Loss                      0.6189429
QF Loss                      1786.5898
VF Loss                      670.572
Policy Loss                  -2018.4083
Q Predictions Mean           2019.2675
Q Predictions Std            831.61084
Q Predictions Max            2566.4834
Q Predictions Min            17.29116
V Predictions Mean           2008.2688
V Predictions Std            823.0169
V Predictions Max            2534.4502
V Predictions Min            27.971682
Log Pis Mean                 -3.2922487
Log Pis Std                  5.9500766
Log Pis Max                  20.90326
Log Pis Min                  -13.717058
Policy mu Mean               0.3987535
Policy mu Std                0.7254048
Policy mu Max                2.4840946
Policy mu Min                -3.4411957
Policy log std Mean          -0.30077863
Policy log std Std           0.15006512
Policy log std Max           -0.04342743
Policy log std Min           -0.9042618
Z mean eval                  0.020957578
Z variance eval              0.03176288
total_rewards                [2725.5802416  1183.7431777  5194.73390903 5263.03373543 2274.5070454
 5221.67174095 5222.9471353  4182.2420243  5199.53970533 5177.22467766]
total_rewards_mean           4164.52233926971
total_rewards_std            1453.6433061564512
total_rewards_max            5263.0337354344965
total_rewards_min            1183.7431776959843
Number of train steps total  275000
Number of env steps total    1377000
Number of rollouts total     0
Train Time (s)               31.13209810294211
(Previous) Eval Time (s)     20.87829412287101
Sample Time (s)              19.561129457317293
Epoch Time (s)               71.57152168313041
Total Train Time (s)         15970.073731075507
Epoch                        274
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:41:52.381573 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #274 | Epoch Duration: 74.84112763404846
2020-01-10 22:41:52.381859 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #274 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020940233
Z variance train             0.03177071
KL Divergence                6.245083
KL Loss                      0.6245083
QF Loss                      1187.4294
VF Loss                      769.1653
Policy Loss                  -2106.3884
Q Predictions Mean           2102.677
Q Predictions Std            744.8494
Q Predictions Max            2553.3423
Q Predictions Min            21.632502
V Predictions Mean           2094.0854
V Predictions Std            744.0154
V Predictions Max            2549.8845
V Predictions Min            32.11138
Log Pis Mean                 -2.4984837
Log Pis Std                  5.49849
Log Pis Max                  18.86473
Log Pis Min                  -14.798332
Policy mu Mean               0.38171673
Policy mu Std                0.75571394
Policy mu Max                2.808072
Policy mu Min                -2.4828315
Policy log std Mean          -0.31556243
Policy log std Std           0.15350103
Policy log std Max           -0.019270517
Policy log std Min           -1.0947897
Z mean eval                  0.023550237
Z variance eval              0.030608397
total_rewards                [5293.33820888 5229.45113541 5321.69154907 5259.19032802 1929.5224981
 4593.55547588 3160.08799051 1823.32661275 2049.4885347  5264.75023447]
total_rewards_mean           3992.4402567787606
total_rewards_std            1483.3328585291558
total_rewards_max            5321.691549073708
total_rewards_min            1823.3266127456
Number of train steps total  276000
Number of env steps total    1382000
Number of rollouts total     0
Train Time (s)               29.232578422874212
(Previous) Eval Time (s)     24.147545346058905
Sample Time (s)              19.355363915208727
Epoch Time (s)               72.73548768414184
Total Train Time (s)         16040.923290714622
Epoch                        275
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:43:03.236074 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #275 | Epoch Duration: 70.85397672653198
2020-01-10 22:43:03.236363 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #275 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023634668
Z variance train             0.030609194
KL Divergence                6.3418493
KL Loss                      0.63418496
QF Loss                      1684.9701
VF Loss                      477.37006
Policy Loss                  -2079.3596
Q Predictions Mean           2073.5706
Q Predictions Std            819.9756
Q Predictions Max            2569.4907
Q Predictions Min            17.31657
V Predictions Mean           2074.4912
V Predictions Std            812.56146
V Predictions Max            2553.9312
V Predictions Min            26.688028
Log Pis Mean                 -3.3073244
Log Pis Std                  5.9336805
Log Pis Max                  30.734446
Log Pis Min                  -12.45608
Policy mu Mean               0.38379747
Policy mu Std                0.73985845
Policy mu Max                2.5850213
Policy mu Min                -2.9207678
Policy log std Mean          -0.30152044
Policy log std Std           0.14683633
Policy log std Max           -0.0146032125
Policy log std Min           -0.935761
Z mean eval                  0.023939036
Z variance eval              0.03212385
total_rewards                [1922.87197976 3278.85409149 5224.84608984 2280.75724119 5274.08643712
 2924.34643984 2261.04360753 5177.63432546 4306.69387695 1347.27169602]
total_rewards_mean           3399.8405785202826
total_rewards_std            1414.5949911007242
total_rewards_max            5274.086437118262
total_rewards_min            1347.2716960156627
Number of train steps total  277000
Number of env steps total    1387000
Number of rollouts total     0
Train Time (s)               33.09165578195825
(Previous) Eval Time (s)     22.265719070099294
Sample Time (s)              20.220577453728765
Epoch Time (s)               75.57795230578631
Total Train Time (s)         16113.108652350027
Epoch                        276
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:44:15.422661 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #276 | Epoch Duration: 72.18609023094177
2020-01-10 22:44:15.422827 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #276 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024233464
Z variance train             0.032128163
KL Divergence                6.246858
KL Loss                      0.6246858
QF Loss                      975.95123
VF Loss                      378.38458
Policy Loss                  -1940.6448
Q Predictions Mean           1933.9592
Q Predictions Std            916.2338
Q Predictions Max            2543.7595
Q Predictions Min            17.285757
V Predictions Mean           1939.9009
V Predictions Std            918.11847
V Predictions Max            2562.844
V Predictions Min            26.72378
Log Pis Mean                 -4.617774
Log Pis Std                  5.1546187
Log Pis Max                  18.655876
Log Pis Min                  -14.428265
Policy mu Mean               0.37491405
Policy mu Std                0.6770888
Policy mu Max                2.5546958
Policy mu Min                -2.6040037
Policy log std Mean          -0.2862477
Policy log std Std           0.13769047
Policy log std Max           -0.05695784
Policy log std Min           -0.816489
Z mean eval                  0.01953978
Z variance eval              0.033164702
total_rewards                [1392.60266975 3760.95063354 5116.82352972 2386.57505831 1553.06298472
 5142.96372048 3177.91045543 3281.32081268 5068.48280522  757.37087546]
total_rewards_mean           3163.8063545307527
total_rewards_std            1544.5516860950784
total_rewards_max            5142.963720476959
total_rewards_min            757.3708754614765
Number of train steps total  278000
Number of env steps total    1392000
Number of rollouts total     0
Train Time (s)               33.540430368855596
(Previous) Eval Time (s)     18.873541154898703
Sample Time (s)              19.441174376755953
Epoch Time (s)               71.85514590051025
Total Train Time (s)         16184.60382598266
Epoch                        277
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:45:26.923261 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #277 | Epoch Duration: 71.50029039382935
2020-01-10 22:45:26.923507 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #277 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019428331
Z variance train             0.0331576
KL Divergence                6.1549754
KL Loss                      0.6154975
QF Loss                      2119.9517
VF Loss                      417.33792
Policy Loss                  -1973.8512
Q Predictions Mean           1973.8442
Q Predictions Std            876.6943
Q Predictions Max            2551.4126
Q Predictions Min            19.613308
V Predictions Mean           1975.4252
V Predictions Std            873.7688
V Predictions Max            2561.325
V Predictions Min            32.814617
Log Pis Mean                 -3.7669792
Log Pis Std                  5.9271216
Log Pis Max                  17.945938
Log Pis Min                  -16.138515
Policy mu Mean               0.32560512
Policy mu Std                0.75064635
Policy mu Max                2.8380508
Policy mu Min                -3.2830453
Policy log std Mean          -0.3049811
Policy log std Std           0.15303656
Policy log std Max           -0.030442074
Policy log std Min           -0.98482394
Z mean eval                  0.020927086
Z variance eval              0.032777257
total_rewards                [2596.2193755  3670.58025239 5257.58307747 1532.11956953 1208.43128444
 5276.25092209 5200.69618211 5204.83219476 5268.40743408 5207.09070245]
total_rewards_mean           4042.2210994821485
total_rewards_std            1584.7438230538294
total_rewards_max            5276.250922087103
total_rewards_min            1208.4312844444855
Number of train steps total  279000
Number of env steps total    1397000
Number of rollouts total     0
Train Time (s)               30.45200662408024
(Previous) Eval Time (s)     18.518320141825825
Sample Time (s)              20.006689028348774
Epoch Time (s)               68.97701579425484
Total Train Time (s)         16257.588316244539
Epoch                        278
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:46:39.909884 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #278 | Epoch Duration: 72.98619318008423
2020-01-10 22:46:39.910083 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #278 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020805089
Z variance train             0.032759365
KL Divergence                6.210182
KL Loss                      0.62101823
QF Loss                      812.797
VF Loss                      514.86414
Policy Loss                  -1982.6823
Q Predictions Mean           1985.3187
Q Predictions Std            905.93854
Q Predictions Max            2578.22
Q Predictions Min            14.199143
V Predictions Mean           1997.1349
V Predictions Std            905.9853
V Predictions Max            2584.9424
V Predictions Min            23.880049
Log Pis Mean                 -4.471617
Log Pis Std                  5.1078897
Log Pis Max                  13.397146
Log Pis Min                  -12.527321
Policy mu Mean               0.36292988
Policy mu Std                0.66643304
Policy mu Max                2.8421779
Policy mu Min                -2.5534728
Policy log std Mean          -0.2867163
Policy log std Std           0.13778365
Policy log std Max           0.051126346
Policy log std Min           -0.94346344
Z mean eval                  0.020568285
Z variance eval              0.0348728
total_rewards                [3010.95760344 1167.79946559 2418.26730121 1992.28005026 1276.96252689
  669.02934806 5348.80276178 5243.94497328 4810.48458799 3272.11236277]
total_rewards_mean           2921.064098127211
total_rewards_std            1641.798644275567
total_rewards_max            5348.802761782018
total_rewards_min            669.0293480609574
Number of train steps total  280000
Number of env steps total    1402000
Number of rollouts total     0
Train Time (s)               29.55515231611207
(Previous) Eval Time (s)     22.52712468104437
Sample Time (s)              19.257393484469503
Epoch Time (s)               71.33967048162594
Total Train Time (s)         16323.494899836835
Epoch                        279
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:47:45.819031 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #279 | Epoch Duration: 65.90880846977234
2020-01-10 22:47:45.819224 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #279 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020618057
Z variance train             0.034864653
KL Divergence                6.0497465
KL Loss                      0.6049747
QF Loss                      1397.7083
VF Loss                      344.17023
Policy Loss                  -2094.8557
Q Predictions Mean           2090.0598
Q Predictions Std            757.98065
Q Predictions Max            2587.406
Q Predictions Min            19.162237
V Predictions Mean           2099.3323
V Predictions Std            756.38324
V Predictions Max            2590.8816
V Predictions Min            28.248184
Log Pis Mean                 -2.91041
Log Pis Std                  6.1624694
Log Pis Max                  24.260681
Log Pis Min                  -14.235875
Policy mu Mean               0.36796355
Policy mu Std                0.7693631
Policy mu Max                2.7916358
Policy mu Min                -2.6640015
Policy log std Mean          -0.31735587
Policy log std Std           0.15063976
Policy log std Max           -0.043350473
Policy log std Min           -0.98830265
Z mean eval                  0.021387445
Z variance eval              0.034382302
total_rewards                [5329.04670494 5284.40905842 3621.11966467 5360.68566734 5250.20249705
 4628.41258381 4312.41033219 2865.57493734 2535.45390542 5326.50524865]
total_rewards_mean           4451.382059982187
total_rewards_std            1030.5615198386315
total_rewards_max            5360.685667338119
total_rewards_min            2535.4539054206807
Number of train steps total  281000
Number of env steps total    1407000
Number of rollouts total     0
Train Time (s)               32.03822758141905
(Previous) Eval Time (s)     17.095989214256406
Sample Time (s)              19.978134816046804
Epoch Time (s)               69.11235161172226
Total Train Time (s)         16399.67202048702
Epoch                        280
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:49:01.998247 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #280 | Epoch Duration: 76.17886734008789
2020-01-10 22:49:01.998440 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #280 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021380778
Z variance train             0.03438139
KL Divergence                6.0909853
KL Loss                      0.60909855
QF Loss                      1704.9221
VF Loss                      446.9551
Policy Loss                  -2040.3557
Q Predictions Mean           2034.5199
Q Predictions Std            841.7961
Q Predictions Max            2578.6646
Q Predictions Min            22.110615
V Predictions Mean           2046.6641
V Predictions Std            841.5295
V Predictions Max            2586.6482
V Predictions Min            31.633202
Log Pis Mean                 -3.1848845
Log Pis Std                  6.080637
Log Pis Max                  21.27113
Log Pis Min                  -12.334542
Policy mu Mean               0.3737369
Policy mu Std                0.72989434
Policy mu Max                2.8753924
Policy mu Min                -2.8709736
Policy log std Mean          -0.30606046
Policy log std Std           0.15530108
Policy log std Max           0.0017932355
Policy log std Min           -1.1297244
Z mean eval                  0.0226756
Z variance eval              0.035545103
total_rewards                [1081.47831048 5157.57440087 5218.15428418 5160.6505824  4059.05416344
 5159.78379733 5105.48162183 2959.25781202  921.73180115 5229.946272  ]
total_rewards_mean           4005.311304570377
total_rewards_std            1653.2028788251016
total_rewards_max            5229.946271997656
total_rewards_min            921.7318011511022
Number of train steps total  282000
Number of env steps total    1412000
Number of rollouts total     0
Train Time (s)               30.488655182998627
(Previous) Eval Time (s)     24.162173992022872
Sample Time (s)              19.660336944740266
Epoch Time (s)               74.31116611976177
Total Train Time (s)         16473.135160140228
Epoch                        281
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:50:15.466433 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #281 | Epoch Duration: 73.46782541275024
2020-01-10 22:50:15.466702 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #281 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022575077
Z variance train             0.035533886
KL Divergence                6.007953
KL Loss                      0.6007953
QF Loss                      1036.0305
VF Loss                      420.4051
Policy Loss                  -2068.5886
Q Predictions Mean           2061.3164
Q Predictions Std            804.7829
Q Predictions Max            2563.8108
Q Predictions Min            18.413048
V Predictions Mean           2070.0527
V Predictions Std            802.1301
V Predictions Max            2565.1504
V Predictions Min            27.560537
Log Pis Mean                 -3.16727
Log Pis Std                  5.6978526
Log Pis Max                  26.260067
Log Pis Min                  -13.496144
Policy mu Mean               0.34263515
Policy mu Std                0.7635793
Policy mu Max                2.763075
Policy mu Min                -2.7639399
Policy log std Mean          -0.30985788
Policy log std Std           0.15077701
Policy log std Max           0.08981365
Policy log std Min           -1.0858479
Z mean eval                  0.023358162
Z variance eval              0.034009993
total_rewards                [1130.84448832 5226.67758945 5339.63822543 1502.96832937 1784.69749642
 3363.43365845 5277.7638488  5411.74970929 5281.37494526 2146.09825825]
total_rewards_mean           3646.524654902851
total_rewards_std            1747.4127676318021
total_rewards_max            5411.749709286365
total_rewards_min            1130.8444883218963
Number of train steps total  283000
Number of env steps total    1417000
Number of rollouts total     0
Train Time (s)               31.798643342684954
(Previous) Eval Time (s)     23.318490631878376
Sample Time (s)              19.67643063189462
Epoch Time (s)               74.79356460645795
Total Train Time (s)         16544.88913180027
Epoch                        282
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:51:27.221877 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #282 | Epoch Duration: 71.75499820709229
2020-01-10 22:51:27.222028 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #282 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02323853
Z variance train             0.034003444
KL Divergence                6.099079
KL Loss                      0.6099079
QF Loss                      1024.7205
VF Loss                      690.4468
Policy Loss                  -2173.7483
Q Predictions Mean           2170.9653
Q Predictions Std            741.3183
Q Predictions Max            2583.6023
Q Predictions Min            17.445929
V Predictions Mean           2185.0183
V Predictions Std            742.715
V Predictions Max            2595.3032
V Predictions Min            23.204668
Log Pis Mean                 -3.36565
Log Pis Std                  5.6140265
Log Pis Max                  16.6917
Log Pis Min                  -15.192122
Policy mu Mean               0.38598257
Policy mu Std                0.7394808
Policy mu Max                2.4753523
Policy mu Min                -3.2073822
Policy log std Mean          -0.3041362
Policy log std Std           0.14782177
Policy log std Max           -0.07010819
Policy log std Min           -1.157417
Z mean eval                  0.025955457
Z variance eval              0.033516817
total_rewards                [5306.4790057  2915.66743273 1303.3199028  1828.72370852 5149.05992612
 2879.18552241 3402.9379634  1521.67491982 3569.48324823 2013.16898366]
total_rewards_mean           2988.970061339234
total_rewards_std            1336.2394122069468
total_rewards_max            5306.479005704668
total_rewards_min            1303.3199028011304
Number of train steps total  284000
Number of env steps total    1422000
Number of rollouts total     0
Train Time (s)               29.20390593400225
(Previous) Eval Time (s)     20.2796060112305
Sample Time (s)              19.86821362376213
Epoch Time (s)               69.35172556899488
Total Train Time (s)         16610.92947231373
Epoch                        283
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:52:33.265828 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #283 | Epoch Duration: 66.04367399215698
2020-01-10 22:52:33.266016 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #283 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025750538
Z variance train             0.033511627
KL Divergence                6.1304073
KL Loss                      0.61304075
QF Loss                      1968.749
VF Loss                      537.51575
Policy Loss                  -2069.7017
Q Predictions Mean           2066.5996
Q Predictions Std            800.177
Q Predictions Max            2577.7927
Q Predictions Min            18.695187
V Predictions Mean           2071.1997
V Predictions Std            793.1968
V Predictions Max            2564.8977
V Predictions Min            30.317247
Log Pis Mean                 -2.943143
Log Pis Std                  5.8305345
Log Pis Max                  30.979605
Log Pis Min                  -13.088004
Policy mu Mean               0.39087954
Policy mu Std                0.74342823
Policy mu Max                3.0463917
Policy mu Min                -2.874936
Policy log std Mean          -0.3177983
Policy log std Std           0.15092891
Policy log std Max           -0.008566037
Policy log std Min           -1.0516379
Z mean eval                  0.024552524
Z variance eval              0.03304248
total_rewards                [5281.56418199 3307.26989933 4051.44297408 5343.35757442  815.17145368
 5329.2817838  1405.36800939 3107.11845771 5260.92643647 5261.60794389]
total_rewards_mean           3916.310871475774
total_rewards_std            1627.2849972486897
total_rewards_max            5343.357574417172
total_rewards_min            815.1714536809742
Number of train steps total  285000
Number of env steps total    1427000
Number of rollouts total     0
Train Time (s)               29.593883990775794
(Previous) Eval Time (s)     16.971218270715326
Sample Time (s)              19.129524925723672
Epoch Time (s)               65.69462718721479
Total Train Time (s)         16681.332064154558
Epoch                        284
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:53:43.672334 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #284 | Epoch Duration: 70.40616869926453
2020-01-10 22:53:43.672565 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #284 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024328804
Z variance train             0.033043183
KL Divergence                6.1812153
KL Loss                      0.61812156
QF Loss                      878.352
VF Loss                      758.90247
Policy Loss                  -2171.4714
Q Predictions Mean           2173.6538
Q Predictions Std            720.6045
Q Predictions Max            2586.0303
Q Predictions Min            19.668186
V Predictions Mean           2186.7915
V Predictions Std            718.2353
V Predictions Max            2594.732
V Predictions Min            30.78316
Log Pis Mean                 -3.5859253
Log Pis Std                  5.0356402
Log Pis Max                  14.940099
Log Pis Min                  -13.790367
Policy mu Mean               0.37353483
Policy mu Std                0.7276639
Policy mu Max                3.271042
Policy mu Min                -2.5890088
Policy log std Mean          -0.30324823
Policy log std Std           0.13937879
Policy log std Max           -0.036522254
Policy log std Min           -1.0814049
Z mean eval                  0.024453256
Z variance eval              0.034175586
total_rewards                [5035.22041396 3586.18212705 5265.40087081 5274.03384491 4550.94850325
 5152.46038639 5256.18590168  768.38628823 1001.4658363  5305.59380295]
total_rewards_mean           4119.587797552797
total_rewards_std            1693.3144253895089
total_rewards_max            5305.5938029506115
total_rewards_min            768.3862882303997
Number of train steps total  286000
Number of env steps total    1432000
Number of rollouts total     0
Train Time (s)               31.838163318112493
(Previous) Eval Time (s)     21.682410541921854
Sample Time (s)              19.96913735428825
Epoch Time (s)               73.4897112143226
Total Train Time (s)         16756.905955061782
Epoch                        285
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:54:59.252379 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #285 | Epoch Duration: 75.57959723472595
2020-01-10 22:54:59.252693 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #285 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024473118
Z variance train             0.034179643
KL Divergence                6.085781
KL Loss                      0.60857815
QF Loss                      776.83154
VF Loss                      256.3059
Policy Loss                  -2168.2815
Q Predictions Mean           2164.1074
Q Predictions Std            714.6703
Q Predictions Max            2581.3281
Q Predictions Min            15.69574
V Predictions Mean           2165.0366
V Predictions Std            712.2833
V Predictions Max            2579.4207
V Predictions Min            26.32191
Log Pis Mean                 -3.6105354
Log Pis Std                  5.195037
Log Pis Max                  16.198053
Log Pis Min                  -12.315929
Policy mu Mean               0.39231846
Policy mu Std                0.72367394
Policy mu Max                3.0984156
Policy mu Min                -2.948668
Policy log std Mean          -0.30404213
Policy log std Std           0.13954374
Policy log std Max           0.07300398
Policy log std Min           -1.1456298
Z mean eval                  0.027866032
Z variance eval              0.033922337
total_rewards                [5351.18612803 5274.1223187  1056.79484601  911.33941836 2007.64115108
 4343.36100652 1443.17011865  364.78721576 5262.94389398 5033.12898183]
total_rewards_mean           3104.847507892309
total_rewards_std            2003.5048521606934
total_rewards_max            5351.186128025557
total_rewards_min            364.787215764221
Number of train steps total  287000
Number of env steps total    1437000
Number of rollouts total     0
Train Time (s)               30.989286500029266
(Previous) Eval Time (s)     23.771942209918052
Sample Time (s)              20.422937414608896
Epoch Time (s)               75.18416612455621
Total Train Time (s)         16825.961580780335
Epoch                        286
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:56:08.311888 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #286 | Epoch Duration: 69.05895066261292
2020-01-10 22:56:08.312176 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #286 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028047746
Z variance train             0.0339124
KL Divergence                6.132217
KL Loss                      0.6132217
QF Loss                      1832.4327
VF Loss                      602.7639
Policy Loss                  -2129.9158
Q Predictions Mean           2126.7258
Q Predictions Std            765.4521
Q Predictions Max            2590.3308
Q Predictions Min            17.734291
V Predictions Mean           2130.9832
V Predictions Std            763.7742
V Predictions Max            2593.228
V Predictions Min            26.791882
Log Pis Mean                 -3.7413197
Log Pis Std                  5.339474
Log Pis Max                  18.32248
Log Pis Min                  -13.979051
Policy mu Mean               0.3948897
Policy mu Std                0.7104857
Policy mu Max                2.7884164
Policy mu Min                -2.7309494
Policy log std Mean          -0.30717328
Policy log std Std           0.14566329
Policy log std Max           0.09886283
Policy log std Min           -1.2616137
Z mean eval                  0.026143068
Z variance eval              0.035043623
total_rewards                [4051.6070254  3962.17504366 5253.22201474 2194.73029049 2135.97669753
 5371.91713636 5321.95152499 4545.29966298 1390.95422266 5309.37950144]
total_rewards_mean           3953.7213120254614
total_rewards_std            1439.9820342697728
total_rewards_max            5371.917136361456
total_rewards_min            1390.9542226635044
Number of train steps total  288000
Number of env steps total    1442000
Number of rollouts total     0
Train Time (s)               31.262750206980854
(Previous) Eval Time (s)     17.646379567217082
Sample Time (s)              19.6160913198255
Epoch Time (s)               68.52522109402344
Total Train Time (s)         16899.35534338327
Epoch                        287
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:57:21.707589 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #287 | Epoch Duration: 73.39522051811218
2020-01-10 22:57:21.707767 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #287 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026239771
Z variance train             0.035050016
KL Divergence                6.0490036
KL Loss                      0.60490036
QF Loss                      1233.1384
VF Loss                      391.16376
Policy Loss                  -2146.038
Q Predictions Mean           2136.9268
Q Predictions Std            789.45197
Q Predictions Max            2580.5437
Q Predictions Min            16.259945
V Predictions Mean           2139.398
V Predictions Std            783.60754
V Predictions Max            2580.5315
V Predictions Min            26.99299
Log Pis Mean                 -3.9247239
Log Pis Std                  5.825497
Log Pis Max                  28.592926
Log Pis Min                  -14.191395
Policy mu Mean               0.40212414
Policy mu Std                0.69679385
Policy mu Max                2.9276652
Policy mu Min                -3.474233
Policy log std Mean          -0.29597148
Policy log std Std           0.14785728
Policy log std Max           -0.004522398
Policy log std Min           -1.0693934
Z mean eval                  0.026332
Z variance eval              0.036847226
total_rewards                [3855.47591232 1412.46643669 1352.740185   5129.70098399 1166.45624805
 3162.41577555 3882.32765885 1129.47849505 3264.38260554 1961.84375388]
total_rewards_mean           2631.7288054925043
total_rewards_std            1340.0834761103608
total_rewards_max            5129.70098399319
total_rewards_min            1129.478495048067
Number of train steps total  289000
Number of env steps total    1447000
Number of rollouts total     0
Train Time (s)               29.33431091811508
(Previous) Eval Time (s)     22.51606353605166
Sample Time (s)              19.41593021573499
Epoch Time (s)               71.26630466990173
Total Train Time (s)         16963.574892261997
Epoch                        288
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:58:25.931462 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #288 | Epoch Duration: 64.22352170944214
2020-01-10 22:58:25.931701 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #288 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026063627
Z variance train             0.036849044
KL Divergence                5.959747
KL Loss                      0.5959747
QF Loss                      1006.9844
VF Loss                      1161.6329
Policy Loss                  -2191.7175
Q Predictions Mean           2188.9565
Q Predictions Std            709.25323
Q Predictions Max            2582.6436
Q Predictions Min            18.26158
V Predictions Mean           2212.5415
V Predictions Std            709.7357
V Predictions Max            2605.632
V Predictions Min            29.087402
Log Pis Mean                 -3.740868
Log Pis Std                  5.5116224
Log Pis Max                  19.472168
Log Pis Min                  -12.467224
Policy mu Mean               0.3507529
Policy mu Std                0.7112892
Policy mu Max                2.8225815
Policy mu Min                -2.8717248
Policy log std Mean          -0.30345705
Policy log std Std           0.13821013
Policy log std Max           -0.04853089
Policy log std Min           -0.9875674
Z mean eval                  0.02821136
Z variance eval              0.034729548
total_rewards                [5155.40974083 4583.28086136 2029.99081403 2342.68172146 5200.65438113
 4123.24606554 5215.78474957  979.87054396 2866.78422973 3088.63121401]
total_rewards_mean           3558.633432161153
total_rewards_std            1432.6768616736715
total_rewards_max            5215.784749569147
total_rewards_min            979.8705439623618
Number of train steps total  290000
Number of env steps total    1452000
Number of rollouts total     0
Train Time (s)               31.53554046014324
(Previous) Eval Time (s)     15.472975015640259
Sample Time (s)              19.935103794559836
Epoch Time (s)               66.94361927034333
Total Train Time (s)         17035.595936453436
Epoch                        289
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:59:37.955187 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #289 | Epoch Duration: 72.02329111099243
2020-01-10 22:59:37.955368 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #289 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028191265
Z variance train             0.034737214
KL Divergence                6.101731
KL Loss                      0.6101731
QF Loss                      1396.3508
VF Loss                      499.62238
Policy Loss                  -2172.652
Q Predictions Mean           2175.9248
Q Predictions Std            766.2201
Q Predictions Max            2614.667
Q Predictions Min            17.36577
V Predictions Mean           2167.9585
V Predictions Std            759.463
V Predictions Max            2609.6023
V Predictions Min            26.49587
Log Pis Mean                 -3.5577648
Log Pis Std                  5.620529
Log Pis Max                  17.885029
Log Pis Min                  -15.833452
Policy mu Mean               0.3502688
Policy mu Std                0.7436219
Policy mu Max                3.357684
Policy mu Min                -3.0622492
Policy log std Mean          -0.30548948
Policy log std Std           0.13839863
Policy log std Max           -0.06399053
Policy log std Min           -1.0465937
Z mean eval                  0.02711622
Z variance eval              0.035327256
total_rewards                [2872.36072091 5286.41712551 3429.86586895 5259.11731832 5326.84853766
 2765.22565239 5242.52726526 1638.84567986 5344.20263143  680.03359232]
total_rewards_mean           3784.5444392615013
total_rewards_std            1661.5003415281983
total_rewards_max            5344.20263142719
total_rewards_min            680.0335923208584
Number of train steps total  291000
Number of env steps total    1457000
Number of rollouts total     0
Train Time (s)               29.633486432023346
(Previous) Eval Time (s)     20.552343375980854
Sample Time (s)              19.08797572599724
Epoch Time (s)               69.27380553400144
Total Train Time (s)         17105.74538588198
Epoch                        290
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:00:48.110415 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #290 | Epoch Duration: 70.1548683643341
2020-01-10 23:00:48.110728 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #290 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027002115
Z variance train             0.035327278
KL Divergence                6.0237055
KL Loss                      0.60237056
QF Loss                      794.57355
VF Loss                      390.4052
Policy Loss                  -2101.3975
Q Predictions Mean           2096.3184
Q Predictions Std            844.43555
Q Predictions Max            2615.4243
Q Predictions Min            16.381083
V Predictions Mean           2108.001
V Predictions Std            843.4938
V Predictions Max            2622.784
V Predictions Min            27.610756
Log Pis Mean                 -3.5394483
Log Pis Std                  6.000514
Log Pis Max                  28.745464
Log Pis Min                  -13.468493
Policy mu Mean               0.3805913
Policy mu Std                0.71769094
Policy mu Max                2.9112284
Policy mu Min                -2.9708867
Policy log std Mean          -0.3098599
Policy log std Std           0.1409882
Policy log std Max           -0.05204512
Policy log std Min           -1.129515
Z mean eval                  0.031245004
Z variance eval              0.035206944
total_rewards                [5221.30696895 5236.84897882 1173.52419484 2902.21737858 2480.281815
 4311.06267182 2125.92266525 1223.78883717 2741.70642289 3023.11713253]
total_rewards_mean           3043.977706584557
total_rewards_std            1387.051278887498
total_rewards_max            5236.848978821629
total_rewards_min            1173.5241948370226
Number of train steps total  292000
Number of env steps total    1462000
Number of rollouts total     0
Train Time (s)               30.524326706305146
(Previous) Eval Time (s)     21.43306451383978
Sample Time (s)              19.33911715587601
Epoch Time (s)               71.29650837602094
Total Train Time (s)         17172.544718225487
Epoch                        291
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:01:54.912796 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #291 | Epoch Duration: 66.8018536567688
2020-01-10 23:01:54.912999 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #291 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031281177
Z variance train             0.035212327
KL Divergence                6.0322905
KL Loss                      0.60322905
QF Loss                      1167.6483
VF Loss                      389.62323
Policy Loss                  -2209.7234
Q Predictions Mean           2211.393
Q Predictions Std            730.85974
Q Predictions Max            2604.8293
Q Predictions Min            21.870785
V Predictions Mean           2209.5005
V Predictions Std            724.48773
V Predictions Max            2625.0203
V Predictions Min            32.553455
Log Pis Mean                 -3.2282348
Log Pis Std                  4.990443
Log Pis Max                  15.320194
Log Pis Min                  -12.218042
Policy mu Mean               0.39047822
Policy mu Std                0.7119281
Policy mu Max                3.3343885
Policy mu Min                -2.5186741
Policy log std Mean          -0.30322266
Policy log std Std           0.14223526
Policy log std Max           -0.010537423
Policy log std Min           -0.9715104
Z mean eval                  0.026281008
Z variance eval              0.035317052
total_rewards                [5130.09803717 4570.47709511 4247.62537977 5244.99349779 1299.04218058
 5261.76048996 5225.59923582 5118.33772024 1658.51474302 3182.17771612]
total_rewards_mean           4093.8626095579916
total_rewards_std            1446.276697229511
total_rewards_max            5261.760489958773
total_rewards_min            1299.0421805837598
Number of train steps total  293000
Number of env steps total    1467000
Number of rollouts total     0
Train Time (s)               30.04119637887925
(Previous) Eval Time (s)     16.938079012092203
Sample Time (s)              19.686759483534843
Epoch Time (s)               66.6660348745063
Total Train Time (s)         17245.697632013354
Epoch                        292
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:03:08.071224 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #292 | Epoch Duration: 73.15803980827332
2020-01-10 23:03:08.071533 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #292 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02641496
Z variance train             0.035324406
KL Divergence                6.0333824
KL Loss                      0.60333824
QF Loss                      1439.956
VF Loss                      558.59924
Policy Loss                  -2181.91
Q Predictions Mean           2177.6785
Q Predictions Std            740.7075
Q Predictions Max            2626.0725
Q Predictions Min            20.729769
V Predictions Mean           2180.6643
V Predictions Std            736.02563
V Predictions Max            2621.886
V Predictions Min            32.90861
Log Pis Mean                 -3.459555
Log Pis Std                  6.002577
Log Pis Max                  25.745512
Log Pis Min                  -13.190149
Policy mu Mean               0.41699624
Policy mu Std                0.72212386
Policy mu Max                3.3445656
Policy mu Min                -5.9236083
Policy log std Mean          -0.30457154
Policy log std Std           0.14414468
Policy log std Max           -0.01998204
Policy log std Min           -1.2160697
Z mean eval                  0.026790682
Z variance eval              0.035777785
total_rewards                [3158.065545   2487.13543605 2069.78560595 4049.7228758  1943.00401493
 4237.06968436 5127.22433906 5290.37337198 5246.26721008 3002.28447172]
total_rewards_mean           3661.0932554921756
total_rewards_std            1238.9102418592015
total_rewards_max            5290.373371984131
total_rewards_min            1943.004014927284
Number of train steps total  294000
Number of env steps total    1472000
Number of rollouts total     0
Train Time (s)               30.516876671928912
(Previous) Eval Time (s)     23.429741096217185
Sample Time (s)              18.965374300722033
Epoch Time (s)               72.91199206886813
Total Train Time (s)         17315.677032388747
Epoch                        293
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:04:18.052850 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #293 | Epoch Duration: 69.98109889030457
2020-01-10 23:04:18.053067 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #293 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027063686
Z variance train             0.03576401
KL Divergence                5.987089
KL Loss                      0.5987089
QF Loss                      1136.9819
VF Loss                      381.45227
Policy Loss                  -2259.3005
Q Predictions Mean           2254.351
Q Predictions Std            701.6812
Q Predictions Max            2626.6658
Q Predictions Min            23.817457
V Predictions Mean           2250.604
V Predictions Std            698.4832
V Predictions Max            2617.084
V Predictions Min            32.887733
Log Pis Mean                 -3.387772
Log Pis Std                  5.5081344
Log Pis Max                  26.076153
Log Pis Min                  -13.516915
Policy mu Mean               0.38774547
Policy mu Std                0.71780664
Policy mu Max                2.6764987
Policy mu Min                -3.4683206
Policy log std Mean          -0.30487204
Policy log std Std           0.14066525
Policy log std Max           -0.027122594
Policy log std Min           -0.9101244
Z mean eval                  0.02734754
Z variance eval              0.035451133
total_rewards                [3924.41114334 5201.43147665 3197.01919381 5089.09826706 5293.38347116
 1574.28657186 5303.79191258 5253.33072825 5292.14865548 1961.61326138]
total_rewards_mean           4209.051468156809
total_rewards_std            1396.2573424698205
total_rewards_max            5303.791912580759
total_rewards_min            1574.286571861554
Number of train steps total  295000
Number of env steps total    1477000
Number of rollouts total     0
Train Time (s)               31.66114181978628
(Previous) Eval Time (s)     20.498580549377948
Sample Time (s)              19.68418070860207
Epoch Time (s)               71.8439030777663
Total Train Time (s)         17390.078725750092
Epoch                        294
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:05:32.460885 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #294 | Epoch Duration: 74.4076452255249
2020-01-10 23:05:32.461197 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #294 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027508024
Z variance train             0.035460435
KL Divergence                6.019426
KL Loss                      0.6019426
QF Loss                      1586.8982
VF Loss                      412.8592
Policy Loss                  -2220.3616
Q Predictions Mean           2220.1074
Q Predictions Std            733.3611
Q Predictions Max            2616.8613
Q Predictions Min            19.798525
V Predictions Mean           2213.9934
V Predictions Std            728.0203
V Predictions Max            2613.454
V Predictions Min            29.144802
Log Pis Mean                 -4.220626
Log Pis Std                  5.50564
Log Pis Max                  24.234697
Log Pis Min                  -13.245258
Policy mu Mean               0.33440986
Policy mu Std                0.72035223
Policy mu Max                3.0683787
Policy mu Min                -2.919733
Policy log std Mean          -0.28648686
Policy log std Std           0.13890404
Policy log std Max           -0.066102214
Policy log std Min           -1.071769
Z mean eval                  0.0263547
Z variance eval              0.03450904
total_rewards                [ 862.66277826 1367.54032062 5287.77251589 3325.04424199 4941.43321352
 5299.04929647 4869.50433662 4795.29710769 5043.89608946 5315.90115974]
total_rewards_mean           4110.810106025802
total_rewards_std            1598.3597560411963
total_rewards_max            5315.901159739006
total_rewards_min            862.6627782565694
Number of train steps total  296000
Number of env steps total    1482000
Number of rollouts total     0
Train Time (s)               30.491787836886942
(Previous) Eval Time (s)     23.06199363898486
Sample Time (s)              19.43550750007853
Epoch Time (s)               72.98928897595033
Total Train Time (s)         17463.295676828828
Epoch                        295
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:06:45.683379 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #295 | Epoch Duration: 73.22189831733704
2020-01-10 23:06:45.683716 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #295 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025897484
Z variance train             0.03450795
KL Divergence                6.062248
KL Loss                      0.60622483
QF Loss                      1735.8347
VF Loss                      873.3866
Policy Loss                  -2223.9382
Q Predictions Mean           2222.7173
Q Predictions Std            708.05804
Q Predictions Max            2617.296
Q Predictions Min            21.298681
V Predictions Mean           2237.8794
V Predictions Std            706.31885
V Predictions Max            2630.6226
V Predictions Min            31.675152
Log Pis Mean                 -3.7562542
Log Pis Std                  5.444943
Log Pis Max                  15.99234
Log Pis Min                  -14.408057
Policy mu Mean               0.37485442
Policy mu Std                0.7016383
Policy mu Max                2.7302456
Policy mu Min                -2.8279307
Policy log std Mean          -0.2997582
Policy log std Std           0.14806424
Policy log std Max           0.0033944398
Policy log std Min           -1.0879779
Z mean eval                  0.028139973
Z variance eval              0.034593195
total_rewards                [5323.67087626 4292.61124745 5203.86851642 4160.67824564 2298.05224588
 1913.02207777 2855.62662817 2627.59643249 1527.27261766 1089.97843114]
total_rewards_mean           3129.2377318886697
total_rewards_std            1440.776345207776
total_rewards_max            5323.67087626335
total_rewards_min            1089.9784311370436
Number of train steps total  297000
Number of env steps total    1487000
Number of rollouts total     0
Train Time (s)               32.54464835207909
(Previous) Eval Time (s)     23.294286811724305
Sample Time (s)              19.588486397638917
Epoch Time (s)               75.42742156144232
Total Train Time (s)         17533.451802802272
Epoch                        296
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:07:55.841888 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #296 | Epoch Duration: 70.1579225063324
2020-01-10 23:07:55.842110 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #296 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028464204
Z variance train             0.034589447
KL Divergence                6.0406218
KL Loss                      0.6040622
QF Loss                      1209.5071
VF Loss                      354.51917
Policy Loss                  -2309.3303
Q Predictions Mean           2308.2756
Q Predictions Std            615.29346
Q Predictions Max            2626.6672
Q Predictions Min            23.105623
V Predictions Mean           2304.7314
V Predictions Std            612.9021
V Predictions Max            2623.5256
V Predictions Min            31.770786
Log Pis Mean                 -3.3981557
Log Pis Std                  5.0733023
Log Pis Max                  17.324192
Log Pis Min                  -14.205215
Policy mu Mean               0.39487052
Policy mu Std                0.717073
Policy mu Max                2.7784045
Policy mu Min                -2.9194613
Policy log std Mean          -0.3061893
Policy log std Std           0.14253913
Policy log std Max           0.022776008
Policy log std Min           -0.9954275
Z mean eval                  0.024079261
Z variance eval              0.03426664
total_rewards                [5146.31574212 2454.80194469 5197.83135291 1271.13575537 1183.25166381
 1973.13881165 1228.0461801  1369.2664834  5104.63897936 1211.92147078]
total_rewards_mean           2614.0348384209565
total_rewards_std            1703.3647870125844
total_rewards_max            5197.831352913966
total_rewards_min            1183.2516638129957
Number of train steps total  298000
Number of env steps total    1492000
Number of rollouts total     0
Train Time (s)               30.624872886110097
(Previous) Eval Time (s)     18.02446510596201
Sample Time (s)              20.059012663550675
Epoch Time (s)               68.70835065562278
Total Train Time (s)         17599.22385956114
Epoch                        297
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:09:01.619701 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #297 | Epoch Duration: 65.7774121761322
2020-01-10 23:09:01.620003 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #297 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024075663
Z variance train             0.034272145
KL Divergence                6.0740614
KL Loss                      0.60740614
QF Loss                      1894.2416
VF Loss                      498.89975
Policy Loss                  -2234.3162
Q Predictions Mean           2236.5112
Q Predictions Std            721.3841
Q Predictions Max            2643.04
Q Predictions Min            20.261707
V Predictions Mean           2226.692
V Predictions Std            713.7745
V Predictions Max            2625.471
V Predictions Min            31.30316
Log Pis Mean                 -3.1537793
Log Pis Std                  5.568202
Log Pis Max                  21.446651
Log Pis Min                  -14.314697
Policy mu Mean               0.360063
Policy mu Std                0.7571569
Policy mu Max                2.8150299
Policy mu Min                -3.6395137
Policy log std Mean          -0.3238057
Policy log std Std           0.14826
Policy log std Max           -0.047675952
Policy log std Min           -1.3476084
Z mean eval                  0.026474107
Z variance eval              0.032834698
total_rewards                [5193.96728683 1770.61124231 5336.42864902 5176.64291786 4317.78247779
 5076.12883469 2833.91098925 5232.87317093 5205.50573787 2078.83418515]
total_rewards_mean           4222.2685491693155
total_rewards_std            1354.8110608605155
total_rewards_max            5336.428649016424
total_rewards_min            1770.6112423098111
Number of train steps total  299000
Number of env steps total    1497000
Number of rollouts total     0
Train Time (s)               32.7050615507178
(Previous) Eval Time (s)     15.093220954760909
Sample Time (s)              19.781650598160923
Epoch Time (s)               67.57993310363963
Total Train Time (s)         17676.52426893264
Epoch                        298
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:10:18.924640 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #298 | Epoch Duration: 77.30440998077393
2020-01-10 23:10:18.924930 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #298 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026175594
Z variance train             0.032827068
KL Divergence                6.2010384
KL Loss                      0.62010384
QF Loss                      1288.5591
VF Loss                      754.94763
Policy Loss                  -2211.2563
Q Predictions Mean           2208.3672
Q Predictions Std            756.53455
Q Predictions Max            2646.4949
Q Predictions Min            19.175747
V Predictions Mean           2213.7756
V Predictions Std            754.4317
V Predictions Max            2645.293
V Predictions Min            32.095165
Log Pis Mean                 -3.9067812
Log Pis Std                  5.788307
Log Pis Max                  25.854189
Log Pis Min                  -15.016595
Policy mu Mean               0.36206126
Policy mu Std                0.7252928
Policy mu Max                3.0538921
Policy mu Min                -3.0390024
Policy log std Mean          -0.30316487
Policy log std Std           0.14267693
Policy log std Max           -0.045913428
Policy log std Min           -1.0156341
Z mean eval                  0.025295088
Z variance eval              0.03225626
total_rewards                [4131.37916599 1296.23971307 2140.99897306 1651.53248699 1610.2040208
 5125.21469197 4830.88073356 4376.56174406 2400.36493455 1269.38961889]
total_rewards_mean           2883.276608293938
total_rewards_std            1471.479295749183
total_rewards_max            5125.214691967808
total_rewards_min            1269.389618889601
Number of train steps total  300000
Number of env steps total    1502000
Number of rollouts total     0
Train Time (s)               30.300939603243023
(Previous) Eval Time (s)     24.817346253897995
Sample Time (s)              19.351118290331215
Epoch Time (s)               74.46940414747223
Total Train Time (s)         17742.22479476733
Epoch                        299
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:11:24.627843 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #299 | Epoch Duration: 65.70269989967346
2020-01-10 23:11:24.628053 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #299 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025214395
Z variance train             0.03225872
KL Divergence                6.2110906
KL Loss                      0.62110907
QF Loss                      1239.0695
VF Loss                      286.99796
Policy Loss                  -2272.4673
Q Predictions Mean           2267.0908
Q Predictions Std            679.2472
Q Predictions Max            2631.6704
Q Predictions Min            20.829382
V Predictions Mean           2278.9526
V Predictions Std            678.96735
V Predictions Max            2646.7776
V Predictions Min            28.525723
Log Pis Mean                 -3.3177404
Log Pis Std                  5.449566
Log Pis Max                  18.66275
Log Pis Min                  -13.781292
Policy mu Mean               0.36839762
Policy mu Std                0.75333965
Policy mu Max                2.803789
Policy mu Min                -3.1385138
Policy log std Mean          -0.31440386
Policy log std Std           0.14352034
Policy log std Max           0.037221223
Policy log std Min           -1.0112567
Z mean eval                  0.024854295
Z variance eval              0.033109747
total_rewards                [1091.68345346 5146.22413084 2962.41280123 5162.14027984 1501.15329911
 2417.57961963 5347.4509306  3661.89810237 4012.98789417 5191.98702107]
total_rewards_mean           3649.5517532320955
total_rewards_std            1518.8936803986178
total_rewards_max            5347.45093059859
total_rewards_min            1091.6834534565219
Number of train steps total  301000
Number of env steps total    1507000
Number of rollouts total     0
Train Time (s)               32.47448695125058
(Previous) Eval Time (s)     16.050346865784377
Sample Time (s)              19.07185355015099
Epoch Time (s)               67.59668736718595
Total Train Time (s)         17814.523754208814
Epoch                        300
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:12:36.930021 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #300 | Epoch Duration: 72.30181908607483
2020-01-10 23:12:36.930209 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #300 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024526482
Z variance train             0.03310614
KL Divergence                6.1444654
KL Loss                      0.6144466
QF Loss                      1105.0292
VF Loss                      480.17453
Policy Loss                  -2252.819
Q Predictions Mean           2254.2837
Q Predictions Std            727.2667
Q Predictions Max            2660.0247
Q Predictions Min            17.174883
V Predictions Mean           2248.7378
V Predictions Std            719.9463
V Predictions Max            2650.9065
V Predictions Min            30.161516
Log Pis Mean                 -3.6464999
Log Pis Std                  5.1917033
Log Pis Max                  21.88206
Log Pis Min                  -13.226996
Policy mu Mean               0.35447648
Policy mu Std                0.7283005
Policy mu Max                2.5531218
Policy mu Min                -2.536634
Policy log std Mean          -0.3075276
Policy log std Std           0.14024287
Policy log std Max           -0.020574093
Policy log std Min           -0.99635524
Z mean eval                  0.02444635
Z variance eval              0.03357396
total_rewards                [2666.60886068 3277.87159661  820.22791688 3120.2639622  5327.01743351
 5377.42624165 2500.65166716 5259.40606328 2231.66176544 3587.97383907]
total_rewards_mean           3416.9109346477862
total_rewards_std            1434.3490447367792
total_rewards_max            5377.426241653297
total_rewards_min            820.2279168821531
Number of train steps total  302000
Number of env steps total    1512000
Number of rollouts total     0
Train Time (s)               30.577103154733777
(Previous) Eval Time (s)     20.75515061011538
Sample Time (s)              19.510322967078537
Epoch Time (s)               70.84257673192769
Total Train Time (s)         17884.185916346963
Epoch                        301
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:13:46.598075 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #301 | Epoch Duration: 69.66768622398376
2020-01-10 23:13:46.598363 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #301 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024282787
Z variance train             0.033566914
KL Divergence                6.1091876
KL Loss                      0.61091876
QF Loss                      779.53534
VF Loss                      624.79614
Policy Loss                  -2265.032
Q Predictions Mean           2263.7273
Q Predictions Std            711.225
Q Predictions Max            2654.0583
Q Predictions Min            18.416597
V Predictions Mean           2275.04
V Predictions Std            710.5818
V Predictions Max            2665.6604
V Predictions Min            27.221159
Log Pis Mean                 -3.8620613
Log Pis Std                  5.347317
Log Pis Max                  24.204206
Log Pis Min                  -15.949123
Policy mu Mean               0.35785824
Policy mu Std                0.712165
Policy mu Max                3.1767218
Policy mu Min                -2.7736313
Policy log std Mean          -0.30990005
Policy log std Std           0.14618883
Policy log std Max           -0.049032547
Policy log std Min           -1.0545851
Z mean eval                  0.025652856
Z variance eval              0.03359996
total_rewards                [5096.35583101 5367.64651487 1310.25579765 5232.60317181 1074.37127616
 5121.17523577 5290.4006047  5163.51228087 4945.33251074 1609.60922747]
total_rewards_mean           4021.1262451070215
total_rewards_std            1768.1877122461708
total_rewards_max            5367.646514869861
total_rewards_min            1074.3712761615084
Number of train steps total  303000
Number of env steps total    1517000
Number of rollouts total     0
Train Time (s)               30.07850739872083
(Previous) Eval Time (s)     19.579949777573347
Sample Time (s)              19.450290152337402
Epoch Time (s)               69.10874732863158
Total Train Time (s)         17956.31921792822
Epoch                        302
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:14:58.733003 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #302 | Epoch Duration: 72.13443541526794
2020-01-10 23:14:58.733197 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #302 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025574496
Z variance train             0.03359681
KL Divergence                6.093503
KL Loss                      0.6093503
QF Loss                      986.8185
VF Loss                      541.1786
Policy Loss                  -2250.103
Q Predictions Mean           2245.7676
Q Predictions Std            751.28955
Q Predictions Max            2645.637
Q Predictions Min            19.015676
V Predictions Mean           2239.2634
V Predictions Std            742.6628
V Predictions Max            2626.142
V Predictions Min            27.112001
Log Pis Mean                 -4.2762904
Log Pis Std                  4.936101
Log Pis Max                  18.173704
Log Pis Min                  -14.115304
Policy mu Mean               0.32418704
Policy mu Std                0.69027734
Policy mu Max                2.4814186
Policy mu Min                -3.93434
Policy log std Mean          -0.29301
Policy log std Std           0.14246194
Policy log std Max           -0.046828263
Policy log std Min           -1.0490096
Z mean eval                  0.024015516
Z variance eval              0.030971896
total_rewards                [2326.45907093 5450.25702675 5340.73769852 5187.01493296 2101.40737927
 1290.3090508  5428.57592018 2273.23262117 4278.25019216 1876.77274924]
total_rewards_mean           3555.3016641975496
total_rewards_std            1633.6508642098981
total_rewards_max            5450.257026751092
total_rewards_min            1290.3090507984025
Number of train steps total  304000
Number of env steps total    1522000
Number of rollouts total     0
Train Time (s)               29.15946770692244
(Previous) Eval Time (s)     22.6053436701186
Sample Time (s)              20.025743530131876
Epoch Time (s)               71.79055490717292
Total Train Time (s)         18025.348140732385
Epoch                        303
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:16:07.764847 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #303 | Epoch Duration: 69.03152465820312
2020-01-10 23:16:07.765016 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #303 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023463637
Z variance train             0.030983865
KL Divergence                6.2915106
KL Loss                      0.62915105
QF Loss                      1305.6206
VF Loss                      552.7652
Policy Loss                  -2329.2524
Q Predictions Mean           2323.8591
Q Predictions Std            591.8919
Q Predictions Max            2631.7485
Q Predictions Min            20.9174
V Predictions Mean           2337.3857
V Predictions Std            586.912
V Predictions Max            2639.5862
V Predictions Min            33.173
Log Pis Mean                 -3.6246302
Log Pis Std                  5.4233665
Log Pis Max                  36.13604
Log Pis Min                  -14.33036
Policy mu Mean               0.40162113
Policy mu Std                0.7197159
Policy mu Max                2.6440654
Policy mu Min                -3.4316053
Policy log std Mean          -0.29503846
Policy log std Std           0.1432305
Policy log std Max           0.08762626
Policy log std Min           -1.110906
Z mean eval                  0.024478951
Z variance eval              0.03186393
total_rewards                [5212.96378388 5216.07504664 5280.59925455 2284.60473438 5295.87826136
 5397.17344036 5201.00776034 2924.3517668  5286.54165733 1091.57283042]
total_rewards_mean           4319.076853605204
total_rewards_std            1511.9360281622075
total_rewards_max            5397.173440362696
total_rewards_min            1091.5728304210415
Number of train steps total  305000
Number of env steps total    1527000
Number of rollouts total     0
Train Time (s)               30.37983210477978
(Previous) Eval Time (s)     19.84601680515334
Sample Time (s)              19.249878929462284
Epoch Time (s)               69.4757278393954
Total Train Time (s)         18100.244168547448
Epoch                        304
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:17:22.666083 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #304 | Epoch Duration: 74.9009165763855
2020-01-10 23:17:22.666340 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #304 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02483063
Z variance train             0.03187118
KL Divergence                6.2142653
KL Loss                      0.6214265
QF Loss                      1576.4358
VF Loss                      518.23035
Policy Loss                  -2284.3052
Q Predictions Mean           2283.7969
Q Predictions Std            701.9437
Q Predictions Max            2668.851
Q Predictions Min            22.907085
V Predictions Mean           2282.2158
V Predictions Std            693.74384
V Predictions Max            2665.956
V Predictions Min            33.391098
Log Pis Mean                 -3.671021
Log Pis Std                  5.5410075
Log Pis Max                  24.910667
Log Pis Min                  -14.228443
Policy mu Mean               0.35539526
Policy mu Std                0.7286158
Policy mu Max                3.315059
Policy mu Min                -2.7447615
Policy log std Mean          -0.30569276
Policy log std Std           0.14723185
Policy log std Max           -0.0020885766
Policy log std Min           -0.9984094
Z mean eval                  0.021483833
Z variance eval              0.031213824
total_rewards                [5258.48538057  646.95056099 5314.34242813 2369.37876673 5281.33863784
 4009.20784507 5285.96417676 4484.70448301  949.52810237 5321.77252136]
total_rewards_mean           3892.1672902834753
total_rewards_std            1779.8844308229843
total_rewards_max            5321.772521356097
total_rewards_min            646.9505609944913
Number of train steps total  306000
Number of env steps total    1532000
Number of rollouts total     0
Train Time (s)               30.985376867931336
(Previous) Eval Time (s)     25.270860956981778
Sample Time (s)              19.427834012545645
Epoch Time (s)               75.68407183745876
Total Train Time (s)         18172.223980725743
Epoch                        305
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:18:34.650309 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #305 | Epoch Duration: 71.98376488685608
2020-01-10 23:18:34.650546 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #305 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02138317
Z variance train             0.031215753
KL Divergence                6.257465
KL Loss                      0.6257465
QF Loss                      1449.9026
VF Loss                      494.36777
Policy Loss                  -2230.2034
Q Predictions Mean           2226.2905
Q Predictions Std            751.1598
Q Predictions Max            2656.75
Q Predictions Min            16.638842
V Predictions Mean           2237.662
V Predictions Std            752.7925
V Predictions Max            2674.998
V Predictions Min            24.84134
Log Pis Mean                 -4.349391
Log Pis Std                  5.111919
Log Pis Max                  21.588518
Log Pis Min                  -12.594364
Policy mu Mean               0.3488146
Policy mu Std                0.7000432
Policy mu Max                3.561005
Policy mu Min                -3.3391058
Policy log std Mean          -0.30097318
Policy log std Std           0.1494014
Policy log std Max           -0.025157928
Policy log std Min           -1.0237594
Z mean eval                  0.019841949
Z variance eval              0.030744454
total_rewards                [4078.81151475 3705.25030676 5256.15291749 2503.74460858 5351.16075612
 2029.94043528 5294.22410112 5203.72912778 4780.59690902 5011.2324168 ]
total_rewards_mean           4321.484309368464
total_rewards_std            1154.9432809819214
total_rewards_max            5351.1607561172095
total_rewards_min            2029.9404352805275
Number of train steps total  307000
Number of env steps total    1537000
Number of rollouts total     0
Train Time (s)               31.435278099030256
(Previous) Eval Time (s)     21.570255289785564
Sample Time (s)              19.51474163495004
Epoch Time (s)               72.52027502376586
Total Train Time (s)         18247.22377580451
Epoch                        306
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:19:49.653623 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #306 | Epoch Duration: 75.00289750099182
2020-01-10 23:19:49.653849 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #306 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019787982
Z variance train             0.030756596
KL Divergence                6.300247
KL Loss                      0.63002473
QF Loss                      1846.3231
VF Loss                      416.06705
Policy Loss                  -2335.6028
Q Predictions Mean           2334.9355
Q Predictions Std            609.69086
Q Predictions Max            2663.1436
Q Predictions Min            16.898996
V Predictions Mean           2331.9756
V Predictions Std            612.3803
V Predictions Max            2662.9954
V Predictions Min            24.86668
Log Pis Mean                 -3.0551383
Log Pis Std                  5.422165
Log Pis Max                  19.314268
Log Pis Min                  -13.434118
Policy mu Mean               0.3737802
Policy mu Std                0.7530291
Policy mu Max                3.4620774
Policy mu Min                -3.090894
Policy log std Mean          -0.31569725
Policy log std Std           0.14241143
Policy log std Max           0.008082271
Policy log std Min           -1.1211282
Z mean eval                  0.02230493
Z variance eval              0.031229544
total_rewards                [1434.70361295 4699.92612675 5292.70916633 5291.02385796 2373.06053909
 3144.13677007 2176.06666986 3654.16101015 2008.52029585 3810.21651609]
total_rewards_mean           3388.4524565098573
total_rewards_std            1322.7380015583028
total_rewards_max            5292.709166334211
total_rewards_min            1434.7036129486767
Number of train steps total  308000
Number of env steps total    1542000
Number of rollouts total     0
Train Time (s)               30.31813966995105
(Previous) Eval Time (s)     24.05255261901766
Sample Time (s)              20.236686183139682
Epoch Time (s)               74.6073784721084
Total Train Time (s)         18317.29600620037
Epoch                        307
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:20:59.732471 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #307 | Epoch Duration: 70.07841324806213
2020-01-10 23:20:59.732794 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #307 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022137066
Z variance train             0.031232873
KL Divergence                6.267115
KL Loss                      0.62671155
QF Loss                      2029.9316
VF Loss                      734.89874
Policy Loss                  -2269.3892
Q Predictions Mean           2267.5312
Q Predictions Std            702.4858
Q Predictions Max            2674.3425
Q Predictions Min            13.889495
V Predictions Mean           2283.391
V Predictions Std            702.5579
V Predictions Max            2686.0366
V Predictions Min            26.029415
Log Pis Mean                 -3.57305
Log Pis Std                  5.59402
Log Pis Max                  22.085663
Log Pis Min                  -13.730786
Policy mu Mean               0.34351894
Policy mu Std                0.7578308
Policy mu Max                2.9076197
Policy mu Min                -3.364973
Policy log std Mean          -0.30545095
Policy log std Std           0.14456552
Policy log std Max           0.008899093
Policy log std Min           -1.0754573
Z mean eval                  0.0245759
Z variance eval              0.030449202
total_rewards                [3405.27892124 1230.11373388 5380.16022936 5308.39363467 1234.40781577
 5296.60506556 1530.7239122   429.57941402 4310.11561363 1677.55402335]
total_rewards_mean           2980.2932363675604
total_rewards_std            1868.4089435955536
total_rewards_max            5380.160229355803
total_rewards_min            429.57941402040524
Number of train steps total  309000
Number of env steps total    1547000
Number of rollouts total     0
Train Time (s)               31.44128985516727
(Previous) Eval Time (s)     19.523212103173137
Sample Time (s)              19.007456528954208
Epoch Time (s)               69.97195848729461
Total Train Time (s)         18384.589128310326
Epoch                        308
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:22:07.027952 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #308 | Epoch Duration: 67.2948842048645
2020-01-10 23:22:07.028228 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #308 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024166478
Z variance train             0.030427104
KL Divergence                6.322955
KL Loss                      0.63229555
QF Loss                      1194.388
VF Loss                      571.83435
Policy Loss                  -2328.1467
Q Predictions Mean           2332.5059
Q Predictions Std            651.7787
Q Predictions Max            2670.4187
Q Predictions Min            18.966125
V Predictions Mean           2336.6174
V Predictions Std            648.7134
V Predictions Max            2676.6584
V Predictions Min            29.734596
Log Pis Mean                 -4.0893426
Log Pis Std                  5.30851
Log Pis Max                  25.055891
Log Pis Min                  -12.494718
Policy mu Mean               0.40929118
Policy mu Std                0.68090314
Policy mu Max                3.608132
Policy mu Min                -2.7568924
Policy log std Mean          -0.3041416
Policy log std Std           0.15005194
Policy log std Max           -0.051454082
Policy log std Min           -1.0851138
Z mean eval                  0.022749888
Z variance eval              0.03216954
total_rewards                [2245.20500212 1937.81041914 5232.43298133 3142.44082769 3500.16263696
 1456.49668667 2939.89506706 2358.67953523 5173.84988035 1829.462234  ]
total_rewards_mean           2981.643527055305
total_rewards_std            1258.6457264119226
total_rewards_max            5232.432981330469
total_rewards_min            1456.496686674569
Number of train steps total  310000
Number of env steps total    1552000
Number of rollouts total     0
Train Time (s)               31.0611909260042
(Previous) Eval Time (s)     16.845788937993348
Sample Time (s)              18.95009832503274
Epoch Time (s)               66.85707818903029
Total Train Time (s)         18451.541605284438
Epoch                        309
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:23:13.983147 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #309 | Epoch Duration: 66.95475268363953
2020-01-10 23:23:13.983345 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #309 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022616198
Z variance train             0.032160573
KL Divergence                6.2092257
KL Loss                      0.62092257
QF Loss                      1214.2485
VF Loss                      748.9567
Policy Loss                  -2340.8103
Q Predictions Mean           2338.654
Q Predictions Std            633.5338
Q Predictions Max            2687.6226
Q Predictions Min            23.66148
V Predictions Mean           2339.3618
V Predictions Std            635.7667
V Predictions Max            2690.6208
V Predictions Min            33.57332
Log Pis Mean                 -3.3236027
Log Pis Std                  6.0130577
Log Pis Max                  25.712826
Log Pis Min                  -14.841259
Policy mu Mean               0.34372735
Policy mu Std                0.7566646
Policy mu Max                3.1805902
Policy mu Min                -3.5832977
Policy log std Mean          -0.30495596
Policy log std Std           0.14724767
Policy log std Max           0.059461713
Policy log std Min           -1.1071664
Z mean eval                  0.02542695
Z variance eval              0.0319992
total_rewards                [5392.49217544 5167.14970145 5422.63217645 1227.85609078 5418.00021389
 4955.89942546 2519.7627821  2804.55453495 1140.53035358 5416.52111069]
total_rewards_mean           3946.5398564807665
total_rewards_std            1723.6332641517315
total_rewards_max            5422.632176453237
total_rewards_min            1140.5303535791218
Number of train steps total  311000
Number of env steps total    1557000
Number of rollouts total     0
Train Time (s)               31.212144789285958
(Previous) Eval Time (s)     16.943206263240427
Sample Time (s)              19.33342112507671
Epoch Time (s)               67.4887721776031
Total Train Time (s)         18523.67504686676
Epoch                        310
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:24:26.122068 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #310 | Epoch Duration: 72.13854217529297
2020-01-10 23:24:26.122337 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #310 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0254024
Z variance train             0.032012112
KL Divergence                6.2220736
KL Loss                      0.62220734
QF Loss                      1445.4424
VF Loss                      566.8277
Policy Loss                  -2320.5798
Q Predictions Mean           2318.5786
Q Predictions Std            653.4532
Q Predictions Max            2666.5613
Q Predictions Min            20.548725
V Predictions Mean           2323.1628
V Predictions Std            652.19525
V Predictions Max            2670.7615
V Predictions Min            31.028547
Log Pis Mean                 -3.031624
Log Pis Std                  5.5103283
Log Pis Max                  16.977692
Log Pis Min                  -12.952127
Policy mu Mean               0.32327327
Policy mu Std                0.7693774
Policy mu Max                3.026872
Policy mu Min                -3.5695717
Policy log std Mean          -0.32028162
Policy log std Std           0.14510883
Policy log std Max           0.0014899969
Policy log std Min           -1.0837734
Z mean eval                  0.024641793
Z variance eval              0.031917013
total_rewards                [2919.9036586  2105.33017217 5407.27186982 5259.4772008  1337.27198735
 3894.25843491 4963.94224699 5309.59409889 5257.51081981 1610.96151066]
total_rewards_mean           3806.5521999989273
total_rewards_std            1580.6081031582487
total_rewards_max            5407.271869816001
total_rewards_min            1337.2719873502774
Number of train steps total  312000
Number of env steps total    1562000
Number of rollouts total     0
Train Time (s)               31.862440687138587
(Previous) Eval Time (s)     21.59261954575777
Sample Time (s)              18.516346820630133
Epoch Time (s)               71.97140705352649
Total Train Time (s)         18595.76006593369
Epoch                        311
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:25:38.212866 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #311 | Epoch Duration: 72.0902955532074
2020-01-10 23:25:38.213180 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #311 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024449736
Z variance train             0.03191731
KL Divergence                6.214424
KL Loss                      0.62144244
QF Loss                      2026.8142
VF Loss                      756.4277
Policy Loss                  -2382.7698
Q Predictions Mean           2376.49
Q Predictions Std            547.8715
Q Predictions Max            2659.6814
Q Predictions Min            23.239477
V Predictions Mean           2397.278
V Predictions Std            548.02856
V Predictions Max            2686.28
V Predictions Min            32.36666
Log Pis Mean                 -3.6555748
Log Pis Std                  5.0804453
Log Pis Max                  15.843869
Log Pis Min                  -15.134192
Policy mu Mean               0.4038367
Policy mu Std                0.71633714
Policy mu Max                3.106846
Policy mu Min                -3.3473017
Policy log std Mean          -0.3080246
Policy log std Std           0.14509954
Policy log std Max           -0.0013684034
Policy log std Min           -1.2559189
Z mean eval                  0.024270805
Z variance eval              0.031462934
total_rewards                [4997.71056754 1933.21385374 5260.50658315 5195.54701621 1820.6701698
 3755.88590754 5107.17225649 5188.05443365 1301.73183967 5309.0131313 ]
total_rewards_mean           3986.950575908584
total_rewards_std            1572.3892131131993
total_rewards_max            5309.013131300999
total_rewards_min            1301.7318396681148
Number of train steps total  313000
Number of env steps total    1567000
Number of rollouts total     0
Train Time (s)               30.170014621689916
(Previous) Eval Time (s)     21.71119043743238
Sample Time (s)              19.64362771064043
Epoch Time (s)               71.52483276976272
Total Train Time (s)         18669.810694494285
Epoch                        312
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:26:52.264972 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #312 | Epoch Duration: 74.05157995223999
2020-01-10 23:26:52.265156 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #312 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024534546
Z variance train             0.03146795
KL Divergence                6.2578015
KL Loss                      0.62578017
QF Loss                      1159.7258
VF Loss                      725.8721
Policy Loss                  -2348.5576
Q Predictions Mean           2345.8645
Q Predictions Std            651.1431
Q Predictions Max            2689.3289
Q Predictions Min            18.982347
V Predictions Mean           2343.7935
V Predictions Std            642.1341
V Predictions Max            2685.9634
V Predictions Min            29.615768
Log Pis Mean                 -2.848918
Log Pis Std                  5.7611527
Log Pis Max                  21.952332
Log Pis Min                  -12.144859
Policy mu Mean               0.38723946
Policy mu Std                0.7466527
Policy mu Max                3.2983513
Policy mu Min                -2.9039173
Policy log std Mean          -0.31068408
Policy log std Std           0.14052652
Policy log std Max           -0.06990658
Policy log std Min           -1.0083205
Z mean eval                  0.021803834
Z variance eval              0.032272656
total_rewards                [5334.74179512 3182.29904835 1417.90186759  677.99084101 5332.37705415
 2757.32930219 2467.81279991 5306.31542784 4311.55542521 5287.26046922]
total_rewards_mean           3607.5584030594537
total_rewards_std            1665.5529124903128
total_rewards_max            5334.7417951160505
total_rewards_min            677.9908410058613
Number of train steps total  314000
Number of env steps total    1572000
Number of rollouts total     0
Train Time (s)               31.46274380525574
(Previous) Eval Time (s)     24.23762546107173
Sample Time (s)              18.99562077410519
Epoch Time (s)               74.69599004043266
Total Train Time (s)         18740.814760214183
Epoch                        313
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:28:03.271288 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #313 | Epoch Duration: 71.00601649284363
2020-01-10 23:28:03.271439 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #313 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021822985
Z variance train             0.032266222
KL Divergence                6.175435
KL Loss                      0.6175435
QF Loss                      1036.5334
VF Loss                      396.14545
Policy Loss                  -2384.482
Q Predictions Mean           2381.2913
Q Predictions Std            611.27216
Q Predictions Max            2670.5374
Q Predictions Min            16.421402
V Predictions Mean           2383.315
V Predictions Std            608.3353
V Predictions Max            2675.5938
V Predictions Min            28.870749
Log Pis Mean                 -4.17443
Log Pis Std                  5.038242
Log Pis Max                  20.436148
Log Pis Min                  -13.861921
Policy mu Mean               0.36133215
Policy mu Std                0.69393384
Policy mu Max                3.0277946
Policy mu Min                -3.528883
Policy log std Mean          -0.28852212
Policy log std Std           0.1405481
Policy log std Max           -0.013995886
Policy log std Min           -1.0096619
Z mean eval                  0.021219408
Z variance eval              0.03153681
total_rewards                [5503.64458555 2263.43549461 5415.68685693 5433.76331689 5415.22939491
 2124.09003507 5319.92010245 2163.12513074 1320.65749678 1702.16095227]
total_rewards_mean           3666.171336619313
total_rewards_std            1769.7227302483516
total_rewards_max            5503.6445855531465
total_rewards_min            1320.657496780738
Number of train steps total  315000
Number of env steps total    1577000
Number of rollouts total     0
Train Time (s)               30.83793775131926
(Previous) Eval Time (s)     20.54734066920355
Sample Time (s)              19.11953661078587
Epoch Time (s)               70.50481503130868
Total Train Time (s)         18811.18550889427
Epoch                        314
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:29:13.646140 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #314 | Epoch Duration: 70.37456750869751
2020-01-10 23:29:13.646350 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #314 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02126157
Z variance train             0.031530578
KL Divergence                6.231641
KL Loss                      0.6231641
QF Loss                      720.06433
VF Loss                      421.50726
Policy Loss                  -2333.1628
Q Predictions Mean           2325.9355
Q Predictions Std            692.812
Q Predictions Max            2689.0012
Q Predictions Min            16.585161
V Predictions Mean           2333.799
V Predictions Std            693.78827
V Predictions Max            2693.5137
V Predictions Min            26.279789
Log Pis Mean                 -4.002096
Log Pis Std                  4.5532274
Log Pis Max                  16.296078
Log Pis Min                  -14.30831
Policy mu Mean               0.4223984
Policy mu Std                0.6730956
Policy mu Max                2.9692733
Policy mu Min                -2.3038106
Policy log std Mean          -0.295156
Policy log std Std           0.13923717
Policy log std Max           0.024654552
Policy log std Min           -0.9656062
Z mean eval                  0.022712681
Z variance eval              0.030560538
total_rewards                [5430.77870815 5392.03948652 3390.98543304 1831.54791187 5450.04781977
 3093.14765891 5392.44162203 1142.07702037 2039.41951306 2035.41754424]
total_rewards_mean           3519.7902717960314
total_rewards_std            1657.9224457747462
total_rewards_max            5450.047819766364
total_rewards_min            1142.0770203724521
Number of train steps total  316000
Number of env steps total    1582000
Number of rollouts total     0
Train Time (s)               32.128250932786614
(Previous) Eval Time (s)     20.416780380066484
Sample Time (s)              19.63557722652331
Epoch Time (s)               72.18060853937641
Total Train Time (s)         18882.54307799181
Epoch                        315
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:30:25.007007 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #315 | Epoch Duration: 71.36049771308899
2020-01-10 23:30:25.007211 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #315 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022758303
Z variance train             0.03055738
KL Divergence                6.3039513
KL Loss                      0.6303951
QF Loss                      1274.722
VF Loss                      259.82547
Policy Loss                  -2385.406
Q Predictions Mean           2380.0732
Q Predictions Std            610.9371
Q Predictions Max            2692.8752
Q Predictions Min            22.123287
V Predictions Mean           2387.1416
V Predictions Std            609.71704
V Predictions Max            2713.1465
V Predictions Min            31.383238
Log Pis Mean                 -3.1505063
Log Pis Std                  5.640636
Log Pis Max                  29.528687
Log Pis Min                  -13.0029
Policy mu Mean               0.4065406
Policy mu Std                0.74390525
Policy mu Max                2.8456144
Policy mu Min                -2.7101421
Policy log std Mean          -0.31036368
Policy log std Std           0.14024702
Policy log std Max           0.051838934
Policy log std Min           -1.0193062
Z mean eval                  0.021078296
Z variance eval              0.03142597
total_rewards                [5414.81514826 5433.23247487 5488.50874991 1650.35117179 5316.57636752
 2350.82228788 5440.19676182 5426.69022967 5444.05344276 1880.43851515]
total_rewards_mean           4384.5685149630735
total_rewards_std            1595.432202685787
total_rewards_max            5488.5087499080055
total_rewards_min            1650.3511717905496
Number of train steps total  317000
Number of env steps total    1587000
Number of rollouts total     0
Train Time (s)               31.5605485457927
(Previous) Eval Time (s)     19.59634022321552
Sample Time (s)              19.327258130535483
Epoch Time (s)               70.4841468995437
Total Train Time (s)         18956.96160074789
Epoch                        316
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:31:39.431807 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #316 | Epoch Duration: 74.42439556121826
2020-01-10 23:31:39.432116 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #316 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02107183
Z variance train             0.031426504
KL Divergence                6.233399
KL Loss                      0.6233399
QF Loss                      1173.8746
VF Loss                      502.03204
Policy Loss                  -2353.321
Q Predictions Mean           2352.561
Q Predictions Std            672.74243
Q Predictions Max            2687.582
Q Predictions Min            21.510712
V Predictions Mean           2360.3015
V Predictions Std            674.15424
V Predictions Max            2708.1975
V Predictions Min            31.190538
Log Pis Mean                 -3.5844395
Log Pis Std                  4.589694
Log Pis Max                  15.664734
Log Pis Min                  -12.334974
Policy mu Mean               0.39681867
Policy mu Std                0.6912114
Policy mu Max                2.522897
Policy mu Min                -2.8092532
Policy log std Mean          -0.29898387
Policy log std Std           0.13855292
Policy log std Max           -0.018589929
Policy log std Min           -1.192306
Z mean eval                  0.023325747
Z variance eval              0.032508653
total_rewards                [2010.87829103 1862.3205329   860.72674157 4584.83327822 1398.25995449
 5373.4416278  1525.91824275 5384.88928487 5373.19713415 3694.15547409]
total_rewards_mean           3206.862056186804
total_rewards_std            1763.6969846882437
total_rewards_max            5384.889284874783
total_rewards_min            860.7267415687505
Number of train steps total  318000
Number of env steps total    1592000
Number of rollouts total     0
Train Time (s)               28.77387972502038
(Previous) Eval Time (s)     23.53624962689355
Sample Time (s)              19.914027174934745
Epoch Time (s)               72.22415652684867
Total Train Time (s)         19023.863666813355
Epoch                        317
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:32:46.338648 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #317 | Epoch Duration: 66.90629529953003
2020-01-10 23:32:46.338912 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #317 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023174921
Z variance train             0.03251087
KL Divergence                6.1542826
KL Loss                      0.61542827
QF Loss                      1270.8025
VF Loss                      376.10822
Policy Loss                  -2413.2434
Q Predictions Mean           2412.0078
Q Predictions Std            546.42804
Q Predictions Max            2735.2717
Q Predictions Min            17.6834
V Predictions Mean           2417.2751
V Predictions Std            547.6888
V Predictions Max            2727.2417
V Predictions Min            31.324192
Log Pis Mean                 -3.7137423
Log Pis Std                  5.2548637
Log Pis Max                  29.521027
Log Pis Min                  -14.600697
Policy mu Mean               0.37829715
Policy mu Std                0.717302
Policy mu Max                2.6878617
Policy mu Min                -2.9636776
Policy log std Mean          -0.3135406
Policy log std Std           0.13872077
Policy log std Max           -0.009784296
Policy log std Min           -1.1086007
Z mean eval                  0.021402843
Z variance eval              0.031456064
total_rewards                [2448.97282281 1701.59591669  987.91945556 1376.14832389 2820.9059775
 5415.66122174 5505.8916278   810.11698405 1349.68896332  625.20342552]
total_rewards_mean           2304.2104718872497
total_rewards_std            1707.0259339395916
total_rewards_max            5505.8916277954995
total_rewards_min            625.2034255171932
Number of train steps total  319000
Number of env steps total    1597000
Number of rollouts total     0
Train Time (s)               30.37630267580971
(Previous) Eval Time (s)     18.21806687489152
Sample Time (s)              19.468081578612328
Epoch Time (s)               68.06245112931356
Total Train Time (s)         19086.218090210576
Epoch                        318
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:33:48.697249 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #318 | Epoch Duration: 62.35812497138977
2020-01-10 23:33:48.697503 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #318 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02148945
Z variance train             0.03145968
KL Divergence                6.2331696
KL Loss                      0.62331694
QF Loss                      1530.2526
VF Loss                      485.24393
Policy Loss                  -2401.9133
Q Predictions Mean           2397.7268
Q Predictions Std            582.63306
Q Predictions Max            2700.5261
Q Predictions Min            21.155827
V Predictions Mean           2399.275
V Predictions Std            577.29816
V Predictions Max            2699.0376
V Predictions Min            31.463144
Log Pis Mean                 -3.179788
Log Pis Std                  5.724967
Log Pis Max                  17.99012
Log Pis Min                  -15.800234
Policy mu Mean               0.4361868
Policy mu Std                0.71535635
Policy mu Max                2.9461224
Policy mu Min                -3.3801954
Policy log std Mean          -0.30312288
Policy log std Std           0.15178445
Policy log std Max           -0.03167866
Policy log std Min           -1.1787902
Z mean eval                  0.021829195
Z variance eval              0.029856369
total_rewards                [4973.37886341 5095.25015154 5485.909889   4898.65524768 4501.13893782
 4480.22888058  647.22299792 2485.60134435 1778.89439169 3187.67973895]
total_rewards_mean           3753.396044294894
total_rewards_std            1554.47305879942
total_rewards_max            5485.9098890014275
total_rewards_min            647.2229979170578
Number of train steps total  320000
Number of env steps total    1602000
Number of rollouts total     0
Train Time (s)               30.163668400142342
(Previous) Eval Time (s)     12.513405452948064
Sample Time (s)              20.06776370247826
Epoch Time (s)               62.744837555568665
Total Train Time (s)         19156.807081900537
Epoch                        319
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:34:59.290311 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #319 | Epoch Duration: 70.59259581565857
2020-01-10 23:34:59.290617 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #319 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021657895
Z variance train             0.029870149
KL Divergence                6.3601856
KL Loss                      0.6360186
QF Loss                      1063.5549
VF Loss                      417.04822
Policy Loss                  -2364.9983
Q Predictions Mean           2355.9492
Q Predictions Std            637.037
Q Predictions Max            2677.9814
Q Predictions Min            22.72818
V Predictions Mean           2366.0977
V Predictions Std            637.02734
V Predictions Max            2701.9258
V Predictions Min            35.81782
Log Pis Mean                 -2.7449856
Log Pis Std                  5.569252
Log Pis Max                  23.463757
Log Pis Min                  -12.9643955
Policy mu Mean               0.39546517
Policy mu Std                0.75844413
Policy mu Max                2.8533716
Policy mu Min                -2.4884875
Policy log std Mean          -0.31906286
Policy log std Std           0.1541866
Policy log std Max           -0.05419209
Policy log std Min           -1.0291203
Z mean eval                  0.020030772
Z variance eval              0.030504558
total_rewards                [4554.03328828 2534.95345724 1377.71782463 2907.92618141 3183.59674847
 2644.2967054  5467.62272036 5429.86259402 5412.52512691 5494.49229883]
total_rewards_mean           3900.702694554184
total_rewards_std            1461.3455233245154
total_rewards_max            5494.492298825817
total_rewards_min            1377.7178246292176
Number of train steps total  321000
Number of env steps total    1607000
Number of rollouts total     0
Train Time (s)               31.73237428208813
(Previous) Eval Time (s)     20.36077371519059
Sample Time (s)              19.170273539144546
Epoch Time (s)               71.26342153642327
Total Train Time (s)         19228.966260882095
Epoch                        320
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:36:11.453781 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #320 | Epoch Duration: 72.16291308403015
2020-01-10 23:36:11.454092 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #320 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020139163
Z variance train             0.030508777
KL Divergence                6.3175426
KL Loss                      0.6317543
QF Loss                      1849.4275
VF Loss                      686.6756
Policy Loss                  -2423.4993
Q Predictions Mean           2426.7915
Q Predictions Std            581.5925
Q Predictions Max            2728.9014
Q Predictions Min            22.38505
V Predictions Mean           2416.4326
V Predictions Std            573.7107
V Predictions Max            2729.7615
V Predictions Min            33.06193
Log Pis Mean                 -3.5459878
Log Pis Std                  5.0866475
Log Pis Max                  15.323067
Log Pis Min                  -17.341465
Policy mu Mean               0.3805285
Policy mu Std                0.7341206
Policy mu Max                3.1772492
Policy mu Min                -3.283011
Policy log std Mean          -0.29933918
Policy log std Std           0.1503905
Policy log std Max           -0.015296176
Policy log std Min           -1.0720731
Z mean eval                  0.01985716
Z variance eval              0.030795421
total_rewards                [2290.41300581 2206.97850141 2221.49132173 3043.08671976 1687.2667109
 1256.21870144 3956.24498059 2050.60903613 4815.44419046  825.47605459]
total_rewards_mean           2435.3229222811046
total_rewards_std            1146.9920912809102
total_rewards_max            4815.444190455361
total_rewards_min            825.4760545908192
Number of train steps total  322000
Number of env steps total    1612000
Number of rollouts total     0
Train Time (s)               31.321536132134497
(Previous) Eval Time (s)     21.25993193499744
Sample Time (s)              19.401125808712095
Epoch Time (s)               71.98259387584403
Total Train Time (s)         19293.07808832638
Epoch                        321
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:37:15.570739 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #321 | Epoch Duration: 64.11641907691956
2020-01-10 23:37:15.571008 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #321 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019811252
Z variance train             0.030787095
KL Divergence                6.287793
KL Loss                      0.62877935
QF Loss                      1842.47
VF Loss                      484.75378
Policy Loss                  -2357.2852
Q Predictions Mean           2352.144
Q Predictions Std            629.77747
Q Predictions Max            2717.7712
Q Predictions Min            20.503782
V Predictions Mean           2353.79
V Predictions Std            627.0701
V Predictions Max            2706.9648
V Predictions Min            30.973135
Log Pis Mean                 -3.485794
Log Pis Std                  6.022442
Log Pis Max                  21.820686
Log Pis Min                  -14.488286
Policy mu Mean               0.38560605
Policy mu Std                0.7446595
Policy mu Max                3.1412153
Policy mu Min                -3.545559
Policy log std Mean          -0.30955818
Policy log std Std           0.14610264
Policy log std Max           -0.02996669
Policy log std Min           -1.12082
Z mean eval                  0.01859883
Z variance eval              0.031054666
total_rewards                [1475.76445022 5350.57120334 5246.99678774 4555.6074261  4626.91170049
 1872.03532379 2435.56319684 5410.75372379 5236.30637277 5192.09346082]
total_rewards_mean           4140.260364590111
total_rewards_std            1489.001658100278
total_rewards_max            5410.753723792127
total_rewards_min            1475.7644502190356
Number of train steps total  323000
Number of env steps total    1617000
Number of rollouts total     0
Train Time (s)               30.564424181822687
(Previous) Eval Time (s)     13.393431797157973
Sample Time (s)              19.47318809805438
Epoch Time (s)               63.43104407703504
Total Train Time (s)         19366.645214278717
Epoch                        322
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:38:29.143523 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #322 | Epoch Duration: 73.57228755950928
2020-01-10 23:38:29.143867 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #322 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018376898
Z variance train             0.031049747
KL Divergence                6.2665253
KL Loss                      0.62665254
QF Loss                      1540.6542
VF Loss                      566.1602
Policy Loss                  -2376.5452
Q Predictions Mean           2370.4102
Q Predictions Std            626.63794
Q Predictions Max            2697.5908
Q Predictions Min            16.605326
V Predictions Mean           2382.9163
V Predictions Std            629.1012
V Predictions Max            2713.179
V Predictions Min            26.631104
Log Pis Mean                 -3.5049903
Log Pis Std                  6.062342
Log Pis Max                  32.940887
Log Pis Min                  -12.938523
Policy mu Mean               0.35678825
Policy mu Std                0.74213773
Policy mu Max                3.685497
Policy mu Min                -3.323392
Policy log std Mean          -0.3109658
Policy log std Std           0.15356888
Policy log std Max           -0.024111055
Policy log std Min           -1.0788698
Z mean eval                  0.017453186
Z variance eval              0.032308355
total_rewards                [1854.48693844 5305.2360783  2430.92452991 3439.58907299 5343.24196286
 2781.27830578 3027.17975486 5053.35036637 2993.20397294 2245.96977697]
total_rewards_mean           3447.446075943312
total_rewards_std            1243.6050575377362
total_rewards_max            5343.24196286419
total_rewards_min            1854.4869384418255
Number of train steps total  324000
Number of env steps total    1622000
Number of rollouts total     0
Train Time (s)               33.345718265045434
(Previous) Eval Time (s)     23.534372174646705
Sample Time (s)              19.929838039912283
Epoch Time (s)               76.80992847960442
Total Train Time (s)         19439.555853608064
Epoch                        323
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:39:42.059520 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #323 | Epoch Duration: 72.91540122032166
2020-01-10 23:39:42.059817 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #323 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017603692
Z variance train             0.032302044
KL Divergence                6.1824737
KL Loss                      0.6182474
QF Loss                      1344.3428
VF Loss                      276.09152
Policy Loss                  -2421.1616
Q Predictions Mean           2417.1416
Q Predictions Std            577.1951
Q Predictions Max            2698.3076
Q Predictions Min            20.674927
V Predictions Mean           2422.35
V Predictions Std            578.2129
V Predictions Max            2700.2966
V Predictions Min            30.150503
Log Pis Mean                 -3.5356903
Log Pis Std                  5.4352794
Log Pis Max                  30.218735
Log Pis Min                  -15.781192
Policy mu Mean               0.38462615
Policy mu Std                0.7265994
Policy mu Max                3.0930572
Policy mu Min                -2.9334486
Policy log std Mean          -0.31235382
Policy log std Std           0.13824484
Policy log std Max           -0.04452084
Policy log std Min           -1.0149131
Z mean eval                  0.017444942
Z variance eval              0.0319407
total_rewards                [2224.16951339 5463.57294571 1582.71078413 5491.82877295 2410.77743828
 1036.18049272 2197.58941714  803.76462759 1900.63382215 1520.14292633]
total_rewards_mean           2463.1370740380994
total_rewards_std            1583.5552322436943
total_rewards_max            5491.82877295041
total_rewards_min            803.7646275861063
Number of train steps total  325000
Number of env steps total    1627000
Number of rollouts total     0
Train Time (s)               33.342389199882746
(Previous) Eval Time (s)     19.639515921939164
Sample Time (s)              19.103477980475873
Epoch Time (s)               72.08538310229778
Total Train Time (s)         19505.383114500437
Epoch                        324
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:40:47.891663 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #324 | Epoch Duration: 65.83161997795105
2020-01-10 23:40:47.891939 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #324 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01747394
Z variance train             0.03193874
KL Divergence                6.216809
KL Loss                      0.6216809
QF Loss                      1138.8552
VF Loss                      351.62878
Policy Loss                  -2403.362
Q Predictions Mean           2395.4368
Q Predictions Std            630.72577
Q Predictions Max            2708.1772
Q Predictions Min            22.378656
V Predictions Mean           2403.5508
V Predictions Std            626.4613
V Predictions Max            2710.3857
V Predictions Min            34.777443
Log Pis Mean                 -4.2303324
Log Pis Std                  4.7802224
Log Pis Max                  14.72613
Log Pis Min                  -15.498141
Policy mu Mean               0.38154984
Policy mu Std                0.6792828
Policy mu Max                3.0880697
Policy mu Min                -2.3957691
Policy log std Mean          -0.28463855
Policy log std Std           0.14866856
Policy log std Max           -0.0034421682
Policy log std Min           -1.0564538
Z mean eval                  0.017925614
Z variance eval              0.031456694
total_rewards                [5443.79586178 5393.66717205 5397.79039391 1643.39945325 2355.39065378
 5202.73917108 3923.26057636 5449.12779301 1085.54495575 5349.62207244]
total_rewards_mean           4124.433810341809
total_rewards_std            1671.8884749263302
total_rewards_max            5449.12779300987
total_rewards_min            1085.544955753633
Number of train steps total  326000
Number of env steps total    1632000
Number of rollouts total     0
Train Time (s)               30.693366405554116
(Previous) Eval Time (s)     13.385451220907271
Sample Time (s)              19.09482832532376
Epoch Time (s)               63.17364595178515
Total Train Time (s)         19578.42950951075
Epoch                        325
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:42:00.943156 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #325 | Epoch Duration: 73.05101251602173
2020-01-10 23:42:00.943392 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #325 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01795923
Z variance train             0.031447988
KL Divergence                6.2436104
KL Loss                      0.62436104
QF Loss                      2235.6423
VF Loss                      721.2191
Policy Loss                  -2425.0476
Q Predictions Mean           2420.6445
Q Predictions Std            587.4614
Q Predictions Max            2722.065
Q Predictions Min            24.156948
V Predictions Mean           2422.0513
V Predictions Std            581.5248
V Predictions Max            2720.889
V Predictions Min            34.42951
Log Pis Mean                 -4.3272796
Log Pis Std                  5.173565
Log Pis Max                  27.953358
Log Pis Min                  -13.398078
Policy mu Mean               0.33655503
Policy mu Std                0.7067247
Policy mu Max                2.8262074
Policy mu Min                -3.0555162
Policy log std Mean          -0.2947068
Policy log std Std           0.14047845
Policy log std Max           -0.040336087
Policy log std Min           -1.0092417
Z mean eval                  0.019447364
Z variance eval              0.02996255
total_rewards                [5286.6116437  1391.61313778 5213.98886707 5285.36555007 5339.58131907
 5230.10119554 5237.60313353 2835.73427233 2841.36981458 3643.64218876]
total_rewards_mean           4230.561112243298
total_rewards_std            1368.12349242401
total_rewards_max            5339.581319069885
total_rewards_min            1391.6131377810402
Number of train steps total  327000
Number of env steps total    1637000
Number of rollouts total     0
Train Time (s)               33.746251803822815
(Previous) Eval Time (s)     23.26251716678962
Sample Time (s)              19.419114728458226
Epoch Time (s)               76.42788369907066
Total Train Time (s)         19655.06783891702
Epoch                        326
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:43:17.586038 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #326 | Epoch Duration: 76.64244651794434
2020-01-10 23:43:17.586313 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #326 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019477978
Z variance train             0.029963905
KL Divergence                6.36009
KL Loss                      0.636009
QF Loss                      1070.4629
VF Loss                      352.54724
Policy Loss                  -2480.38
Q Predictions Mean           2481.149
Q Predictions Std            522.20844
Q Predictions Max            2723.1062
Q Predictions Min            18.791763
V Predictions Mean           2476.7651
V Predictions Std            518.7148
V Predictions Max            2710.7812
V Predictions Min            28.549894
Log Pis Mean                 -3.8768425
Log Pis Std                  4.7514706
Log Pis Max                  22.853956
Log Pis Min                  -12.517551
Policy mu Mean               0.3331456
Policy mu Std                0.72956544
Policy mu Max                2.5807257
Policy mu Min                -3.1445184
Policy log std Mean          -0.3078269
Policy log std Std           0.13687095
Policy log std Max           0.0072231144
Policy log std Min           -0.9526956
Z mean eval                  0.021473812
Z variance eval              0.029076582
total_rewards                [5212.08822474 4195.76315803 5454.85592888  910.30010379 5301.95257181
 4479.11875768 5302.51414335 5373.41959518 2832.62236604 1457.71562495]
total_rewards_mean           4052.0350474440047
total_rewards_std            1627.1661250328673
total_rewards_max            5454.855928880584
total_rewards_min            910.3001037938277
Number of train steps total  328000
Number of env steps total    1642000
Number of rollouts total     0
Train Time (s)               30.553392936941236
(Previous) Eval Time (s)     23.47674634680152
Sample Time (s)              20.335283683612943
Epoch Time (s)               74.3654229673557
Total Train Time (s)         19728.749133954756
Epoch                        327
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:44:31.272429 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #327 | Epoch Duration: 73.6858925819397
2020-01-10 23:44:31.272713 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #327 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021630129
Z variance train             0.029086685
KL Divergence                6.4293833
KL Loss                      0.6429383
QF Loss                      1966.811
VF Loss                      593.2332
Policy Loss                  -2402.0984
Q Predictions Mean           2403.488
Q Predictions Std            592.66327
Q Predictions Max            2729.9211
Q Predictions Min            20.636667
V Predictions Mean           2399.106
V Predictions Std            592.721
V Predictions Max            2715.3064
V Predictions Min            31.842617
Log Pis Mean                 -2.5857944
Log Pis Std                  5.4994826
Log Pis Max                  20.655603
Log Pis Min                  -12.668425
Policy mu Mean               0.40809637
Policy mu Std                0.7474652
Policy mu Max                2.754403
Policy mu Min                -3.1926587
Policy log std Mean          -0.31721362
Policy log std Std           0.14336763
Policy log std Max           -0.00883925
Policy log std Min           -1.2362945
Z mean eval                  0.016748745
Z variance eval              0.028405014
total_rewards                [3617.68414278 3461.28176794 1243.53662465 5383.16466233 2810.55464095
 5174.719351   2601.07756686 5283.95258078 5323.34080545 4133.04874403]
total_rewards_mean           3903.23608867675
total_rewards_std            1342.5044469480292
total_rewards_max            5383.164662330411
total_rewards_min            1243.536624646777
Number of train steps total  329000
Number of env steps total    1647000
Number of rollouts total     0
Train Time (s)               29.799625700805336
(Previous) Eval Time (s)     22.796871098689735
Sample Time (s)              19.49689589161426
Epoch Time (s)               72.09339269110933
Total Train Time (s)         19800.24845197657
Epoch                        328
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:45:42.774357 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #328 | Epoch Duration: 71.5014135837555
2020-01-10 23:45:42.774548 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #328 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016724786
Z variance train             0.02840129
KL Divergence                6.4891744
KL Loss                      0.64891744
QF Loss                      1379.1654
VF Loss                      478.4523
Policy Loss                  -2403.7668
Q Predictions Mean           2399.919
Q Predictions Std            612.16205
Q Predictions Max            2711.593
Q Predictions Min            20.264708
V Predictions Mean           2396.6216
V Predictions Std            607.2164
V Predictions Max            2707.4553
V Predictions Min            29.725044
Log Pis Mean                 -3.2679806
Log Pis Std                  5.5563045
Log Pis Max                  33.565914
Log Pis Min                  -12.90358
Policy mu Mean               0.36352408
Policy mu Std                0.7313682
Policy mu Max                2.8726416
Policy mu Min                -2.9449656
Policy log std Mean          -0.29988682
Policy log std Std           0.14380533
Policy log std Max           0.043703347
Policy log std Min           -0.98652077
Z mean eval                  0.02061956
Z variance eval              0.027457234
total_rewards                [3192.88225566 5304.11199268 3919.89305109 5213.85640865 5344.75837844
  449.48017998 1056.32523654 5349.69688851 3711.23282124 5250.93285856]
total_rewards_mean           3879.3170071332584
total_rewards_std            1738.851810586083
total_rewards_max            5349.69688850513
total_rewards_min            449.48017998282387
Number of train steps total  330000
Number of env steps total    1652000
Number of rollouts total     0
Train Time (s)               31.319844160228968
(Previous) Eval Time (s)     22.204573920927942
Sample Time (s)              19.082722440361977
Epoch Time (s)               72.60714052151889
Total Train Time (s)         19872.883880461566
Epoch                        329
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:46:55.413633 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #329 | Epoch Duration: 72.63891506195068
2020-01-10 23:46:55.413849 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #329 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020794634
Z variance train             0.02745151
KL Divergence                6.579957
KL Loss                      0.6579957
QF Loss                      2014.5171
VF Loss                      780.36993
Policy Loss                  -2454.864
Q Predictions Mean           2452.7441
Q Predictions Std            539.5244
Q Predictions Max            2723.3083
Q Predictions Min            17.013315
V Predictions Mean           2451.3562
V Predictions Std            532.3924
V Predictions Max            2710.3828
V Predictions Min            33.26338
Log Pis Mean                 -3.1548867
Log Pis Std                  5.5283065
Log Pis Max                  23.546131
Log Pis Min                  -13.423528
Policy mu Mean               0.41988346
Policy mu Std                0.7165153
Policy mu Max                3.036149
Policy mu Min                -2.3638668
Policy log std Mean          -0.30640772
Policy log std Std           0.1430217
Policy log std Max           -0.038405664
Policy log std Min           -1.0386996
Z mean eval                  0.019645719
Z variance eval              0.027617713
total_rewards                [5210.52753778 5127.20066505 5112.37049891 5237.64461683 5200.45986837
 2933.17811712 5293.96453152 1322.47466814 5278.63606362 3238.56311832]
total_rewards_mean           4395.501968565452
total_rewards_std            1325.8305984140748
total_rewards_max            5293.964531524197
total_rewards_min            1322.4746681438128
Number of train steps total  331000
Number of env steps total    1657000
Number of rollouts total     0
Train Time (s)               31.637730001937598
(Previous) Eval Time (s)     22.236058328766376
Sample Time (s)              19.963472105562687
Epoch Time (s)               73.83726043626666
Total Train Time (s)         19949.880002554506
Epoch                        330
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:48:12.413094 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #330 | Epoch Duration: 76.99908638000488
2020-01-10 23:48:12.413285 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #330 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019793253
Z variance train             0.027616683
KL Divergence                6.5626106
KL Loss                      0.6562611
QF Loss                      3328.4321
VF Loss                      876.2855
Policy Loss                  -2464.7024
Q Predictions Mean           2458.1167
Q Predictions Std            493.411
Q Predictions Max            2727.015
Q Predictions Min            24.798334
V Predictions Mean           2458.6392
V Predictions Std            492.60034
V Predictions Max            2717.6
V Predictions Min            37.24473
Log Pis Mean                 -3.283987
Log Pis Std                  5.5028386
Log Pis Max                  22.345917
Log Pis Min                  -12.972156
Policy mu Mean               0.38193625
Policy mu Std                0.7392808
Policy mu Max                2.6720078
Policy mu Min                -2.9010477
Policy log std Mean          -0.30414987
Policy log std Std           0.1423004
Policy log std Max           -0.003688693
Policy log std Min           -1.0777307
Z mean eval                  0.018264195
Z variance eval              0.028458843
total_rewards                [5429.54414377 4133.90158794 5426.76721936 2962.09045849  830.89743896
 3070.55153396 5353.22632232 5317.16171693 5395.43491148 2342.95929068]
total_rewards_mean           4026.253462389501
total_rewards_std            1559.9294545545715
total_rewards_max            5429.544143771599
total_rewards_min            830.8974389585571
Number of train steps total  332000
Number of env steps total    1662000
Number of rollouts total     0
Train Time (s)               29.5330494903028
(Previous) Eval Time (s)     25.397512178868055
Sample Time (s)              20.137665949761868
Epoch Time (s)               75.06822761893272
Total Train Time (s)         20022.518887685146
Epoch                        331
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:49:25.054465 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #331 | Epoch Duration: 72.64103770256042
2020-01-10 23:49:25.054667 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #331 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018087823
Z variance train             0.028463801
KL Divergence                6.4995575
KL Loss                      0.64995575
QF Loss                      1649.8031
VF Loss                      606.7989
Policy Loss                  -2438.8518
Q Predictions Mean           2435.7515
Q Predictions Std            559.1089
Q Predictions Max            2722.9365
Q Predictions Min            23.88629
V Predictions Mean           2444.0596
V Predictions Std            558.81525
V Predictions Max            2721.7534
V Predictions Min            32.49575
Log Pis Mean                 -3.1255355
Log Pis Std                  5.080932
Log Pis Max                  17.282364
Log Pis Min                  -17.550858
Policy mu Mean               0.43737906
Policy mu Std                0.7201955
Policy mu Max                2.8038065
Policy mu Min                -2.68672
Policy log std Mean          -0.31553677
Policy log std Std           0.143783
Policy log std Max           -0.06453725
Policy log std Min           -1.0328782
Z mean eval                  0.02003743
Z variance eval              0.028039057
total_rewards                [2195.1809123   903.77214439 5338.15805882 2924.95488667 3698.56052413
 2760.02173707 5197.37930698 5480.97326946 2111.16963131 1446.47369709]
total_rewards_mean           3205.6644168226912
total_rewards_std            1575.572444966311
total_rewards_max            5480.973269460438
total_rewards_min            903.7721443894326
Number of train steps total  333000
Number of env steps total    1667000
Number of rollouts total     0
Train Time (s)               31.930081771221012
(Previous) Eval Time (s)     22.969976343214512
Sample Time (s)              19.79678344214335
Epoch Time (s)               74.69684155657887
Total Train Time (s)         20092.310124119744
Epoch                        332
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:50:34.849488 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #332 | Epoch Duration: 69.79465794563293
2020-01-10 23:50:34.849694 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #332 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019900892
Z variance train             0.02803812
KL Divergence                6.535313
KL Loss                      0.6535313
QF Loss                      1971.6444
VF Loss                      559.9162
Policy Loss                  -2516.3018
Q Predictions Mean           2507.8022
Q Predictions Std            370.57928
Q Predictions Max            2729.1748
Q Predictions Min            31.270592
V Predictions Mean           2517.7732
V Predictions Std            367.21353
V Predictions Max            2724.4885
V Predictions Min            40.080692
Log Pis Mean                 -2.6398244
Log Pis Std                  6.076977
Log Pis Max                  34.07802
Log Pis Min                  -12.699196
Policy mu Mean               0.37406954
Policy mu Std                0.7734524
Policy mu Max                2.950269
Policy mu Min                -2.678898
Policy log std Mean          -0.32411763
Policy log std Std           0.15347691
Policy log std Max           0.14834358
Policy log std Min           -1.3893197
Z mean eval                  0.016633179
Z variance eval              0.027008552
total_rewards                [5352.3161342  1580.71531751 1674.61830654 5207.80221159 3834.87370844
 2407.15181975 2037.32010483 5310.98930243 3149.3917014  5254.28071674]
total_rewards_mean           3580.94593234466
total_rewards_std            1523.9360984515888
total_rewards_max            5352.31613420243
total_rewards_min            1580.7153175096971
Number of train steps total  334000
Number of env steps total    1672000
Number of rollouts total     0
Train Time (s)               32.99964746227488
(Previous) Eval Time (s)     18.06743088690564
Sample Time (s)              19.415889408439398
Epoch Time (s)               70.48296775761992
Total Train Time (s)         20164.687020203564
Epoch                        333
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:51:47.231226 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #333 | Epoch Duration: 72.3813681602478
2020-01-10 23:51:47.231469 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #333 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016755637
Z variance train             0.02701218
KL Divergence                6.6224914
KL Loss                      0.66224915
QF Loss                      1648.2322
VF Loss                      374.63034
Policy Loss                  -2446.1367
Q Predictions Mean           2448.039
Q Predictions Std            574.7503
Q Predictions Max            2718.5403
Q Predictions Min            21.113224
V Predictions Mean           2446.2617
V Predictions Std            572.3194
V Predictions Max            2720.6016
V Predictions Min            32.015278
Log Pis Mean                 -3.9403973
Log Pis Std                  5.3565736
Log Pis Max                  25.905495
Log Pis Min                  -13.933243
Policy mu Mean               0.39071494
Policy mu Std                0.68343306
Policy mu Max                3.0629895
Policy mu Min                -2.9176617
Policy log std Mean          -0.3017304
Policy log std Std           0.13699903
Policy log std Max           0.00904493
Policy log std Min           -1.0725716
Z mean eval                  0.02042556
Z variance eval              0.027360026
total_rewards                [5169.18891739 2349.69487894 5242.30641398 5387.0161627  2779.92204845
 5432.05182909 5427.75398299 1425.24690142 5409.81334305 5414.00820736]
total_rewards_mean           4403.700268536349
total_rewards_std            1487.3499987258351
total_rewards_max            5432.051829088407
total_rewards_min            1425.2469014246549
Number of train steps total  335000
Number of env steps total    1677000
Number of rollouts total     0
Train Time (s)               31.32546585192904
(Previous) Eval Time (s)     19.965519635006785
Sample Time (s)              19.530866914894432
Epoch Time (s)               70.82185240183026
Total Train Time (s)         20239.68231703434
Epoch                        334
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:53:02.233462 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #334 | Epoch Duration: 75.00178933143616
2020-01-10 23:53:02.233727 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #334 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020421283
Z variance train             0.027361652
KL Divergence                6.5944176
KL Loss                      0.65944177
QF Loss                      1600.0946
VF Loss                      469.27292
Policy Loss                  -2479.6453
Q Predictions Mean           2477.269
Q Predictions Std            482.75128
Q Predictions Max            2719.0286
Q Predictions Min            22.549416
V Predictions Mean           2482.605
V Predictions Std            479.52878
V Predictions Max            2735.6057
V Predictions Min            35.534256
Log Pis Mean                 -3.544259
Log Pis Std                  5.484453
Log Pis Max                  35.92189
Log Pis Min                  -14.195108
Policy mu Mean               0.3830659
Policy mu Std                0.7264526
Policy mu Max                2.8758757
Policy mu Min                -3.6158266
Policy log std Mean          -0.31449497
Policy log std Std           0.14477327
Policy log std Max           -0.06646477
Policy log std Min           -1.0575838
Z mean eval                  0.019250743
Z variance eval              0.029148351
total_rewards                [5315.93696656 1550.07767724 3657.84404557 5366.79812318 1612.41694204
 5373.35507169 5339.19598869 5447.25709539 5376.75160105 2272.63225023]
total_rewards_mean           4131.226576165019
total_rewards_std            1609.3698603216267
total_rewards_max            5447.257095394256
total_rewards_min            1550.077677241125
Number of train steps total  336000
Number of env steps total    1682000
Number of rollouts total     0
Train Time (s)               30.567072823178023
(Previous) Eval Time (s)     24.145052250940353
Sample Time (s)              20.03588609304279
Epoch Time (s)               74.74801116716117
Total Train Time (s)         20312.91742641339
Epoch                        335
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:54:15.468627 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #335 | Epoch Duration: 73.23472428321838
2020-01-10 23:54:15.468777 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #335 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019210268
Z variance train             0.029147455
KL Divergence                6.456545
KL Loss                      0.6456545
QF Loss                      1261.8575
VF Loss                      537.6918
Policy Loss                  -2503.4236
Q Predictions Mean           2497.5159
Q Predictions Std            458.752
Q Predictions Max            2742.2139
Q Predictions Min            21.895159
V Predictions Mean           2503.5122
V Predictions Std            454.63745
V Predictions Max            2752.0364
V Predictions Min            30.714073
Log Pis Mean                 -3.0528502
Log Pis Std                  5.8206697
Log Pis Max                  25.970772
Log Pis Min                  -13.346821
Policy mu Mean               0.37365457
Policy mu Std                0.74147207
Policy mu Max                2.9098234
Policy mu Min                -3.033593
Policy log std Mean          -0.31759173
Policy log std Std           0.13814528
Policy log std Max           -0.06151814
Policy log std Min           -1.1180503
Z mean eval                  0.015997017
Z variance eval              0.029263249
total_rewards                [1141.50276419  846.46637763 1883.83467913 3510.66537412 3150.58492973
 1135.54541198 5431.36644586 5524.12867245 3619.41518996 4526.61322834]
total_rewards_mean           3077.012307337992
total_rewards_std            1674.3617422375132
total_rewards_max            5524.128672445015
total_rewards_min            846.4663776301991
Number of train steps total  337000
Number of env steps total    1687000
Number of rollouts total     0
Train Time (s)               30.15976649383083
(Previous) Eval Time (s)     22.63144944095984
Sample Time (s)              20.091613243799657
Epoch Time (s)               72.88282917859033
Total Train Time (s)         20379.67334703915
Epoch                        336
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:55:22.227874 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #336 | Epoch Duration: 66.75898241996765
2020-01-10 23:55:22.228063 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #336 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01593371
Z variance train             0.029263068
KL Divergence                6.4466515
KL Loss                      0.6446652
QF Loss                      1197.3362
VF Loss                      834.5677
Policy Loss                  -2463.8079
Q Predictions Mean           2467.1575
Q Predictions Std            522.69183
Q Predictions Max            2729.4387
Q Predictions Min            14.065225
V Predictions Mean           2471.3105
V Predictions Std            516.9285
V Predictions Max            2734.4827
V Predictions Min            24.708014
Log Pis Mean                 -3.525993
Log Pis Std                  5.102271
Log Pis Max                  25.013973
Log Pis Min                  -13.159203
Policy mu Mean               0.38233906
Policy mu Std                0.72754973
Policy mu Max                2.982385
Policy mu Min                -2.8558936
Policy log std Mean          -0.30132967
Policy log std Std           0.14900126
Policy log std Max           -0.012497097
Policy log std Min           -0.9666875
Z mean eval                  0.020338994
Z variance eval              0.031269122
total_rewards                [5420.54131554 5373.04885974 5168.45912169 2101.64157576 5352.32446398
 4360.32383656 1661.01977872 5397.69009984 5371.52550268 5413.24628788]
total_rewards_mean           4561.982084239617
total_rewards_std            1377.5104966843649
total_rewards_max            5420.541315536779
total_rewards_min            1661.0197787228922
Number of train steps total  338000
Number of env steps total    1692000
Number of rollouts total     0
Train Time (s)               29.997536584269255
(Previous) Eval Time (s)     16.50722450017929
Sample Time (s)              19.201305576134473
Epoch Time (s)               65.70606666058302
Total Train Time (s)         20454.183106390294
Epoch                        337
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:56:36.740035 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #337 | Epoch Duration: 74.51184749603271
2020-01-10 23:56:36.740241 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #337 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020382654
Z variance train             0.03127348
KL Divergence                6.302353
KL Loss                      0.6302353
QF Loss                      1332.2465
VF Loss                      610.51013
Policy Loss                  -2487.604
Q Predictions Mean           2485.0796
Q Predictions Std            479.8121
Q Predictions Max            2753.6787
Q Predictions Min            24.122177
V Predictions Mean           2497.382
V Predictions Std            480.46902
V Predictions Max            2748.0276
V Predictions Min            35.899372
Log Pis Mean                 -4.167069
Log Pis Std                  5.2817435
Log Pis Max                  25.798073
Log Pis Min                  -13.595632
Policy mu Mean               0.36129177
Policy mu Std                0.7067898
Policy mu Max                3.2348895
Policy mu Min                -2.95695
Policy log std Mean          -0.30216593
Policy log std Std           0.14353098
Policy log std Max           -0.026088625
Policy log std Min           -1.0118855
Z mean eval                  0.022995088
Z variance eval              0.032463502
total_rewards                [3028.56459488 5407.62120296 4455.77598348 1550.66652886 1623.05690206
 3114.72005353  882.25209425 5214.1387025  2255.03110824 1868.68558452]
total_rewards_mean           2940.051275527921
total_rewards_std            1520.2834883735518
total_rewards_max            5407.621202959982
total_rewards_min            882.2520942527119
Number of train steps total  339000
Number of env steps total    1697000
Number of rollouts total     0
Train Time (s)               32.79288029810414
(Previous) Eval Time (s)     25.312685414217412
Sample Time (s)              20.012957745231688
Epoch Time (s)               78.11852345755324
Total Train Time (s)         20523.374720797874
Epoch                        338
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:57:45.935558 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #338 | Epoch Duration: 69.19517207145691
2020-01-10 23:57:45.935778 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #338 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022838438
Z variance train             0.032445453
KL Divergence                6.2156997
KL Loss                      0.62157
QF Loss                      1198.9023
VF Loss                      479.4288
Policy Loss                  -2535.0095
Q Predictions Mean           2536.1514
Q Predictions Std            425.07166
Q Predictions Max            2754.342
Q Predictions Min            19.096119
V Predictions Mean           2540.8735
V Predictions Std            425.67007
V Predictions Max            2760.2776
V Predictions Min            34.459896
Log Pis Mean                 -3.6373768
Log Pis Std                  5.2984457
Log Pis Max                  34.062836
Log Pis Min                  -16.645405
Policy mu Mean               0.32775834
Policy mu Std                0.7398511
Policy mu Max                2.86364
Policy mu Min                -2.9708526
Policy log std Mean          -0.3057115
Policy log std Std           0.13943559
Policy log std Max           -0.047346875
Policy log std Min           -0.96195704
Z mean eval                  0.021389829
Z variance eval              0.031658746
total_rewards                [1613.29220185 1934.24637047 1160.38301615 1171.71195809 2140.22181856
 5486.27621358 1436.68534806 2747.80805851  735.96463307  999.58246857]
total_rewards_mean           1942.6172086908532
total_rewards_std            1309.9962330019328
total_rewards_max            5486.276213581444
total_rewards_min            735.9646330737168
Number of train steps total  340000
Number of env steps total    1702000
Number of rollouts total     0
Train Time (s)               30.268252500798553
(Previous) Eval Time (s)     16.38897516671568
Sample Time (s)              19.928403643425554
Epoch Time (s)               66.58563131093979
Total Train Time (s)         20584.3241992807
Epoch                        339
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:58:46.891984 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #339 | Epoch Duration: 60.95599699020386
2020-01-10 23:58:46.892286 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #339 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02101055
Z variance train             0.031668004
KL Divergence                6.259652
KL Loss                      0.62596524
QF Loss                      2139.6384
VF Loss                      535.4582
Policy Loss                  -2509.4094
Q Predictions Mean           2503.9663
Q Predictions Std            479.36996
Q Predictions Max            2727.2996
Q Predictions Min            17.659649
V Predictions Mean           2525.3032
V Predictions Std            481.63925
V Predictions Max            2748.8833
V Predictions Min            26.372145
Log Pis Mean                 -3.8889656
Log Pis Std                  5.299627
Log Pis Max                  23.620518
Log Pis Min                  -12.837549
Policy mu Mean               0.35876638
Policy mu Std                0.7101021
Policy mu Max                3.1649559
Policy mu Min                -3.1403627
Policy log std Mean          -0.30531383
Policy log std Std           0.13909605
Policy log std Max           -0.030362159
Policy log std Min           -1.1125317
Z mean eval                  0.019338237
Z variance eval              0.031003807
total_rewards                [5355.54742227 3595.35783902 1426.30512031 1584.11761374 2648.33378923
 5192.30603871 2420.23983243 1766.47250279 1938.4155837  3143.36026912]
total_rewards_mean           2907.045601132869
total_rewards_std            1350.2958337924229
total_rewards_max            5355.54742226788
total_rewards_min            1426.3051203096256
Number of train steps total  341000
Number of env steps total    1707000
Number of rollouts total     0
Train Time (s)               29.909502000082284
(Previous) Eval Time (s)     10.758992438670248
Sample Time (s)              19.587690675165504
Epoch Time (s)               60.256185113918036
Total Train Time (s)         20650.839742474724
Epoch                        340
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:59:53.409725 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #340 | Epoch Duration: 66.51720809936523
2020-01-10 23:59:53.409933 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #340 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019057488
Z variance train             0.030998453
KL Divergence                6.283947
KL Loss                      0.6283947
QF Loss                      2310.382
VF Loss                      707.9503
Policy Loss                  -2405.4136
Q Predictions Mean           2404.7976
Q Predictions Std            604.36816
Q Predictions Max            2750.5867
Q Predictions Min            23.946234
V Predictions Mean           2415.6736
V Predictions Std            610.57196
V Predictions Max            2774.0557
V Predictions Min            28.856667
Log Pis Mean                 -2.6926053
Log Pis Std                  6.916603
Log Pis Max                  35.63913
Log Pis Min                  -16.505112
Policy mu Mean               0.35351253
Policy mu Std                0.7938796
Policy mu Max                3.6772091
Policy mu Min                -4.287804
Policy log std Mean          -0.32135695
Policy log std Std           0.14676408
Policy log std Max           -0.017957553
Policy log std Min           -1.0260973
Z mean eval                  0.01991253
Z variance eval              0.030382354
total_rewards                [1360.12859615 3153.22197841 3327.43328904 5427.43941317 2658.47767474
 4915.52617502 5458.84200805 3641.76519145 5267.45361576 1467.33552139]
total_rewards_mean           3667.7623463169816
total_rewards_std            1482.8120332198378
total_rewards_max            5458.842008054631
total_rewards_min            1360.128596149871
Number of train steps total  342000
Number of env steps total    1712000
Number of rollouts total     0
Train Time (s)               30.705565471202135
(Previous) Eval Time (s)     17.019679524935782
Sample Time (s)              18.606984939891845
Epoch Time (s)               66.33222993602976
Total Train Time (s)         20720.157709282357
Epoch                        341
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:01:02.731530 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #341 | Epoch Duration: 69.32143974304199
2020-01-11 00:01:02.731717 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #341 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019820657
Z variance train             0.030389443
KL Divergence                6.336866
KL Loss                      0.6336866
QF Loss                      1479.7507
VF Loss                      404.02893
Policy Loss                  -2524.1218
Q Predictions Mean           2518.887
Q Predictions Std            439.62518
Q Predictions Max            2737.0022
Q Predictions Min            23.932749
V Predictions Mean           2522.9062
V Predictions Std            439.31818
V Predictions Max            2742.6284
V Predictions Min            33.219627
Log Pis Mean                 -3.1005354
Log Pis Std                  5.1567583
Log Pis Max                  21.967495
Log Pis Min                  -13.170756
Policy mu Mean               0.33737075
Policy mu Std                0.7552033
Policy mu Max                3.0427718
Policy mu Min                -2.8154404
Policy log std Mean          -0.31340575
Policy log std Std           0.14490816
Policy log std Max           -0.039371386
Policy log std Min           -1.0275317
Z mean eval                  0.02857365
Z variance eval              0.030649185
total_rewards                [ 436.22785213 2158.40473659 1447.68002915 5281.58642274 2476.95760986
 1337.50174962 3223.76556114 2804.7314838  4796.2153185  3140.3522608 ]
total_rewards_mean           2710.3423024335525
total_rewards_std            1429.3107119866238
total_rewards_max            5281.586422738846
total_rewards_min            436.22785212962293
Number of train steps total  343000
Number of env steps total    1717000
Number of rollouts total     0
Train Time (s)               31.468266579788178
(Previous) Eval Time (s)     20.008586538024247
Sample Time (s)              19.36757521610707
Epoch Time (s)               70.8444283339195
Total Train Time (s)         20786.62484918395
Epoch                        342
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:02:09.200998 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #342 | Epoch Duration: 66.46912169456482
2020-01-11 00:02:09.201236 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #342 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028604085
Z variance train             0.030646766
KL Divergence                6.3251486
KL Loss                      0.6325149
QF Loss                      1668.1648
VF Loss                      738.04126
Policy Loss                  -2495.9353
Q Predictions Mean           2497.4033
Q Predictions Std            508.5439
Q Predictions Max            2754.3376
Q Predictions Min            17.121983
V Predictions Mean           2491.7334
V Predictions Std            508.23227
V Predictions Max            2752.0298
V Predictions Min            27.76513
Log Pis Mean                 -3.9301846
Log Pis Std                  5.3350344
Log Pis Max                  20.694958
Log Pis Min                  -15.675814
Policy mu Mean               0.31204513
Policy mu Std                0.7478895
Policy mu Max                3.1585004
Policy mu Min                -3.2141013
Policy log std Mean          -0.30541968
Policy log std Std           0.13884112
Policy log std Max           -0.053588904
Policy log std Min           -1.0438237
Z mean eval                  0.025265375
Z variance eval              0.029498458
total_rewards                [5356.20384701 3581.10633231 5421.02951611 5339.81288389 4161.95432578
 5324.14939714 5272.62821863 3962.87490159 5375.2519232  3659.9398133 ]
total_rewards_mean           4745.495115895901
total_rewards_std            753.5963786339029
total_rewards_max            5421.029516109859
total_rewards_min            3581.1063323124513
Number of train steps total  344000
Number of env steps total    1722000
Number of rollouts total     0
Train Time (s)               28.226871132384986
(Previous) Eval Time (s)     15.632975758984685
Sample Time (s)              18.737073800060898
Epoch Time (s)               62.59692069143057
Total Train Time (s)         20860.395335996523
Epoch                        343
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:03:22.975480 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #343 | Epoch Duration: 73.77408695220947
2020-01-11 00:03:22.975685 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #343 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025411785
Z variance train             0.029501636
KL Divergence                6.4165497
KL Loss                      0.64165497
QF Loss                      942.72845
VF Loss                      511.23773
Policy Loss                  -2498.381
Q Predictions Mean           2497.2095
Q Predictions Std            529.95184
Q Predictions Max            2753.1956
Q Predictions Min            25.12306
V Predictions Mean           2488.82
V Predictions Std            528.5834
V Predictions Max            2746.6226
V Predictions Min            36.401615
Log Pis Mean                 -3.5331945
Log Pis Std                  5.2951922
Log Pis Max                  16.22271
Log Pis Min                  -15.522459
Policy mu Mean               0.29985595
Policy mu Std                0.75154394
Policy mu Max                2.608488
Policy mu Min                -2.5873046
Policy log std Mean          -0.29821467
Policy log std Std           0.13559707
Policy log std Max           0.06136352
Policy log std Min           -0.8851599
Z mean eval                  0.023604736
Z variance eval              0.029713443
total_rewards                [ 891.83790195 5172.74531872 5180.96228404 1467.0900524  1996.02091341
 2762.46450589 5180.04263962 1859.91887384 4962.47025274 5295.40353692]
total_rewards_mean           3476.8956279535223
total_rewards_std            1738.7989974744355
total_rewards_max            5295.403536919759
total_rewards_min            891.8379019507568
Number of train steps total  345000
Number of env steps total    1727000
Number of rollouts total     0
Train Time (s)               30.827524945139885
(Previous) Eval Time (s)     26.8098287708126
Sample Time (s)              19.32197776529938
Epoch Time (s)               76.95933148125187
Total Train Time (s)         20929.986183893867
Epoch                        344
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:04:32.571514 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #344 | Epoch Duration: 69.59565305709839
2020-01-11 00:04:32.571773 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #344 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02421904
Z variance train             0.029718291
KL Divergence                6.3935003
KL Loss                      0.63935006
QF Loss                      2580.9604
VF Loss                      559.09033
Policy Loss                  -2458.2246
Q Predictions Mean           2459.6763
Q Predictions Std            619.628
Q Predictions Max            2753.1833
Q Predictions Min            22.120136
V Predictions Mean           2450.553
V Predictions Std            617.34393
V Predictions Max            2749.836
V Predictions Min            31.22765
Log Pis Mean                 -3.5466917
Log Pis Std                  5.1431394
Log Pis Max                  23.35006
Log Pis Min                  -13.469818
Policy mu Mean               0.2862939
Policy mu Std                0.7510291
Policy mu Max                2.8182225
Policy mu Min                -2.7202687
Policy log std Mean          -0.30898958
Policy log std Std           0.13972643
Policy log std Max           0.007288754
Policy log std Min           -0.99467266
Z mean eval                  0.024964264
Z variance eval              0.029345483
total_rewards                [1179.05501283 5438.14176457 3803.99631274 5343.78698572 3300.88223725
 2598.4489413  1561.52100373 2598.16761105 5473.07843563 5224.77626202]
total_rewards_mean           3652.185456683944
total_rewards_std            1571.4603255070544
total_rewards_max            5473.078435625018
total_rewards_min            1179.0550128293326
Number of train steps total  346000
Number of env steps total    1732000
Number of rollouts total     0
Train Time (s)               33.224433690775186
(Previous) Eval Time (s)     19.44582003587857
Sample Time (s)              19.005785007029772
Epoch Time (s)               71.67603873368353
Total Train Time (s)         21002.09762926353
Epoch                        345
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:05:44.685782 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #345 | Epoch Duration: 72.11381244659424
2020-01-11 00:05:44.686002 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #345 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025059903
Z variance train             0.029346908
KL Divergence                6.401846
KL Loss                      0.6401846
QF Loss                      919.67664
VF Loss                      284.74152
Policy Loss                  -2481.4045
Q Predictions Mean           2484.142
Q Predictions Std            587.15295
Q Predictions Max            2756.899
Q Predictions Min            22.122343
V Predictions Mean           2483.891
V Predictions Std            585.74304
V Predictions Max            2762.16
V Predictions Min            33.46106
Log Pis Mean                 -3.8247652
Log Pis Std                  4.745501
Log Pis Max                  22.642029
Log Pis Min                  -12.441871
Policy mu Mean               0.35013434
Policy mu Std                0.7114023
Policy mu Max                2.6216948
Policy mu Min                -2.7228894
Policy log std Mean          -0.3004768
Policy log std Std           0.13547991
Policy log std Max           -0.058222905
Policy log std Min           -1.0311905
Z mean eval                  0.024779147
Z variance eval              0.029318977
total_rewards                [5369.01134684 5255.83787056 1072.17159796 1841.63706956 4406.90533376
 2649.51105108 5274.03437203 2866.716141   4339.85636148 5318.0914454 ]
total_rewards_mean           3839.377258967807
total_rewards_std            1522.293976526265
total_rewards_max            5369.011346836072
total_rewards_min            1072.1715979591536
Number of train steps total  347000
Number of env steps total    1737000
Number of rollouts total     0
Train Time (s)               30.387530652806163
(Previous) Eval Time (s)     19.883264258038253
Sample Time (s)              19.49782935436815
Epoch Time (s)               69.76862426521257
Total Train Time (s)         21073.128363885917
Epoch                        346
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:06:55.719659 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #346 | Epoch Duration: 71.03351140022278
2020-01-11 00:06:55.719874 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #346 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024879828
Z variance train             0.029319067
KL Divergence                6.403879
KL Loss                      0.64038795
QF Loss                      1985.4412
VF Loss                      272.17685
Policy Loss                  -2538.277
Q Predictions Mean           2530.71
Q Predictions Std            460.6455
Q Predictions Max            2751.13
Q Predictions Min            28.83017
V Predictions Mean           2545.2927
V Predictions Std            464.98175
V Predictions Max            2767.0898
V Predictions Min            36.641846
Log Pis Mean                 -3.983835
Log Pis Std                  4.38123
Log Pis Max                  23.24244
Log Pis Min                  -12.829168
Policy mu Mean               0.37233722
Policy mu Std                0.68131953
Policy mu Max                2.977762
Policy mu Min                -2.630477
Policy log std Mean          -0.3065835
Policy log std Std           0.13251355
Policy log std Max           0.009204403
Policy log std Min           -0.9346714
Z mean eval                  0.025352802
Z variance eval              0.030109327
total_rewards                [5420.00151665 3865.97057453 2666.15312401 5300.8935786  2204.86574349
 5229.2771314  1252.97691879 5413.49308085 1032.66247807 5317.14921402]
total_rewards_mean           3770.3443360411356
total_rewards_std            1726.1553907394657
total_rewards_max            5420.001516652245
total_rewards_min            1032.6624780663328
Number of train steps total  348000
Number of env steps total    1742000
Number of rollouts total     0
Train Time (s)               31.92853275826201
(Previous) Eval Time (s)     21.14782413095236
Sample Time (s)              19.3572539803572
Epoch Time (s)               72.43361086957157
Total Train Time (s)         21145.575660358183
Epoch                        347
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:08:08.173163 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #347 | Epoch Duration: 72.45311903953552
2020-01-11 00:08:08.173423 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #347 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02513358
Z variance train             0.030113423
KL Divergence                6.345181
KL Loss                      0.6345181
QF Loss                      811.2191
VF Loss                      362.6266
Policy Loss                  -2520.741
Q Predictions Mean           2515.7493
Q Predictions Std            521.3639
Q Predictions Max            2751.6733
Q Predictions Min            20.919666
V Predictions Mean           2527.5068
V Predictions Std            523.0463
V Predictions Max            2768.4878
V Predictions Min            32.920895
Log Pis Mean                 -3.4700265
Log Pis Std                  4.4541802
Log Pis Max                  16.580505
Log Pis Min                  -11.990383
Policy mu Mean               0.3688621
Policy mu Std                0.71578693
Policy mu Max                2.8619752
Policy mu Min                -2.583658
Policy log std Mean          -0.3133962
Policy log std Std           0.14519568
Policy log std Max           -0.03794708
Policy log std Min           -1.0491087
Z mean eval                  0.02930263
Z variance eval              0.029342284
total_rewards                [5427.47572049 4758.77247111 4941.86348363 5399.35331636 5271.74184768
 5425.61751578 1797.49735191 5343.18726021 5288.65046774 5355.31518861]
total_rewards_mean           4900.947462350571
total_rewards_std            1055.6532418314794
total_rewards_max            5427.47572048768
total_rewards_min            1797.4973519054938
Number of train steps total  349000
Number of env steps total    1747000
Number of rollouts total     0
Train Time (s)               30.367552044335753
(Previous) Eval Time (s)     21.166989273857325
Sample Time (s)              20.585472392383963
Epoch Time (s)               72.12001371057704
Total Train Time (s)         21224.7560445657
Epoch                        348
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:09:27.359380 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #348 | Epoch Duration: 79.18571662902832
2020-01-11 00:09:27.359717 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #348 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02942494
Z variance train             0.029337395
KL Divergence                6.4024506
KL Loss                      0.6402451
QF Loss                      720.9541
VF Loss                      351.3096
Policy Loss                  -2552.667
Q Predictions Mean           2546.7505
Q Predictions Std            449.6752
Q Predictions Max            2743.0674
Q Predictions Min            16.71281
V Predictions Mean           2543.891
V Predictions Std            445.23492
V Predictions Max            2740.6248
V Predictions Min            30.403894
Log Pis Mean                 -4.2091293
Log Pis Std                  4.5479803
Log Pis Max                  15.060488
Log Pis Min                  -15.245937
Policy mu Mean               0.34586927
Policy mu Std                0.7103396
Policy mu Max                2.4232435
Policy mu Min                -2.470735
Policy log std Mean          -0.3001916
Policy log std Std           0.13260767
Policy log std Max           -0.023474514
Policy log std Min           -0.83996516
Z mean eval                  0.029373804
Z variance eval              0.029595803
total_rewards                [3322.21990964 5343.41300055 1109.87228584 2128.62022574 5335.81639191
 1707.39785452 5417.0648234  5319.74315745 5441.78340551 3988.53906658]
total_rewards_mean           3911.447012114084
total_rewards_std            1640.4183605118826
total_rewards_max            5441.783405511065
total_rewards_min            1109.8722858432209
Number of train steps total  350000
Number of env steps total    1752000
Number of rollouts total     0
Train Time (s)               30.183211406692863
(Previous) Eval Time (s)     28.232322894968092
Sample Time (s)              19.39237781241536
Epoch Time (s)               77.80791211407632
Total Train Time (s)         21295.402993735857
Epoch                        349
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:10:38.011233 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #349 | Epoch Duration: 70.65123319625854
2020-01-11 00:10:38.011516 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #349 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02929244
Z variance train             0.029598797
KL Divergence                6.3855324
KL Loss                      0.63855326
QF Loss                      2313.0283
VF Loss                      891.1058
Policy Loss                  -2494.1624
Q Predictions Mean           2492.2385
Q Predictions Std            503.8196
Q Predictions Max            2760.0554
Q Predictions Min            23.490227
V Predictions Mean           2499.669
V Predictions Std            495.30148
V Predictions Max            2764.4758
V Predictions Min            33.085014
Log Pis Mean                 -3.10913
Log Pis Std                  5.508976
Log Pis Max                  17.70145
Log Pis Min                  -13.436038
Policy mu Mean               0.3793942
Policy mu Std                0.7554526
Policy mu Max                3.2324324
Policy mu Min                -2.9877741
Policy log std Mean          -0.31013736
Policy log std Std           0.15016252
Policy log std Max           -0.018961951
Policy log std Min           -1.245886
Z mean eval                  0.022822095
Z variance eval              0.03097555
total_rewards                [5385.05278823 5424.69551558 3412.20925317 1996.81415639 5370.14729437
 3953.52308821 1952.71481992 4827.42173684 2950.54446418 2119.02865803]
total_rewards_mean           3739.215177491458
total_rewards_std            1379.172576207361
total_rewards_max            5424.695515577483
total_rewards_min            1952.7148199231933
Number of train steps total  351000
Number of env steps total    1757000
Number of rollouts total     0
Train Time (s)               28.988891321700066
(Previous) Eval Time (s)     21.07536533009261
Sample Time (s)              19.902378061786294
Epoch Time (s)               69.96663471357897
Total Train Time (s)         21365.18767486699
Epoch                        350
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:11:47.802355 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #350 | Epoch Duration: 69.79060077667236
2020-01-11 00:11:47.802635 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #350 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023265969
Z variance train             0.03097566
KL Divergence                6.283615
KL Loss                      0.6283615
QF Loss                      1350.7156
VF Loss                      313.15936
Policy Loss                  -2534.4922
Q Predictions Mean           2530.3896
Q Predictions Std            478.68436
Q Predictions Max            2763.976
Q Predictions Min            15.5271845
V Predictions Mean           2536.2412
V Predictions Std            479.66037
V Predictions Max            2762.6206
V Predictions Min            25.329477
Log Pis Mean                 -3.459958
Log Pis Std                  5.6651964
Log Pis Max                  21.708775
Log Pis Min                  -14.065119
Policy mu Mean               0.32686475
Policy mu Std                0.75365
Policy mu Max                2.7920434
Policy mu Min                -2.7406628
Policy log std Mean          -0.30509603
Policy log std Std           0.13998424
Policy log std Max           0.11257321
Policy log std Min           -0.8438924
Z mean eval                  0.023552716
Z variance eval              0.031737894
total_rewards                [5475.76913849 5489.31405729 5262.71751961 5382.94192125 5278.37990077
 5366.37141222 4052.25131893 3005.58003093 4433.05146776 5336.80331368]
total_rewards_mean           4908.318008092208
total_rewards_std            782.2993493676099
total_rewards_max            5489.3140572922675
total_rewards_min            3005.580030928577
Number of train steps total  352000
Number of env steps total    1762000
Number of rollouts total     0
Train Time (s)               30.81427953299135
(Previous) Eval Time (s)     20.89902359014377
Sample Time (s)              19.748615299351513
Epoch Time (s)               71.46191842248663
Total Train Time (s)         21443.474252228625
Epoch                        351
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:13:06.093426 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #351 | Epoch Duration: 78.29057288169861
2020-01-11 00:13:06.093681 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #351 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02323597
Z variance train             0.031730797
KL Divergence                6.241067
KL Loss                      0.6241067
QF Loss                      1184.3601
VF Loss                      517.2991
Policy Loss                  -2535.9717
Q Predictions Mean           2531.4592
Q Predictions Std            491.87585
Q Predictions Max            2757.6223
Q Predictions Min            16.616014
V Predictions Mean           2548.3462
V Predictions Std            490.24875
V Predictions Max            2777.866
V Predictions Min            27.7897
Log Pis Mean                 -3.868527
Log Pis Std                  4.7723207
Log Pis Max                  24.084509
Log Pis Min                  -14.173346
Policy mu Mean               0.3763064
Policy mu Std                0.6982953
Policy mu Max                3.3069656
Policy mu Min                -2.888935
Policy log std Mean          -0.3027036
Policy log std Std           0.13750002
Policy log std Max           -0.040203772
Policy log std Min           -1.349004
Z mean eval                  0.022089703
Z variance eval              0.03177347
total_rewards                [2765.91029953 3003.69695316 3468.42793211 5445.04841951 2169.91802206
 5453.47048461 2102.71898359 5401.27795148 5423.91387439 2230.93046039]
total_rewards_mean           3746.531338083357
total_rewards_std            1429.1968628609318
total_rewards_max            5453.470484610652
total_rewards_min            2102.718983585161
Number of train steps total  353000
Number of env steps total    1767000
Number of rollouts total     0
Train Time (s)               30.868982936721295
(Previous) Eval Time (s)     27.727362843696028
Sample Time (s)              19.593194941990077
Epoch Time (s)               78.1895407224074
Total Train Time (s)         21515.102811185177
Epoch                        352
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:14:17.728201 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #352 | Epoch Duration: 71.63427758216858
2020-01-11 00:14:17.728524 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #352 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02212602
Z variance train             0.03177757
KL Divergence                6.250136
KL Loss                      0.6250136
QF Loss                      1082.6082
VF Loss                      775.9405
Policy Loss                  -2557.6182
Q Predictions Mean           2558.4202
Q Predictions Std            449.1533
Q Predictions Max            2763.642
Q Predictions Min            22.052471
V Predictions Mean           2552.7925
V Predictions Std            446.29892
V Predictions Max            2762.6667
V Predictions Min            29.67987
Log Pis Mean                 -3.6313324
Log Pis Std                  5.2908015
Log Pis Max                  24.355228
Log Pis Min                  -13.523175
Policy mu Mean               0.34325066
Policy mu Std                0.73967516
Policy mu Max                2.8966353
Policy mu Min                -2.8690674
Policy log std Mean          -0.30756143
Policy log std Std           0.14208895
Policy log std Max           -0.062144578
Policy log std Min           -1.0638278
Z mean eval                  0.02617078
Z variance eval              0.029307913
total_rewards                [3336.5890534  2204.58128146 2354.58130924 5419.55187588  909.18506313
 5538.74984807 1841.944536   1707.88974198 5444.82998745 5149.30832799]
total_rewards_mean           3390.721102459122
total_rewards_std            1729.5741996294055
total_rewards_max            5538.749848070405
total_rewards_min            909.1850631258337
Number of train steps total  354000
Number of env steps total    1772000
Number of rollouts total     0
Train Time (s)               31.3502192562446
(Previous) Eval Time (s)     21.171779872849584
Sample Time (s)              19.23499425407499
Epoch Time (s)               71.75699338316917
Total Train Time (s)         21584.303641145583
Epoch                        353
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:15:26.931273 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #353 | Epoch Duration: 69.2025396823883
2020-01-11 00:15:26.931473 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #353 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026428184
Z variance train             0.029301316
KL Divergence                6.426175
KL Loss                      0.6426175
QF Loss                      1244.8923
VF Loss                      731.4222
Policy Loss                  -2508.342
Q Predictions Mean           2505.8293
Q Predictions Std            566.37524
Q Predictions Max            2785.437
Q Predictions Min            21.248386
V Predictions Mean           2494.8083
V Predictions Std            560.08466
V Predictions Max            2766.103
V Predictions Min            31.345495
Log Pis Mean                 -3.3045282
Log Pis Std                  5.2703524
Log Pis Max                  23.15195
Log Pis Min                  -13.302112
Policy mu Mean               0.3426508
Policy mu Std                0.7372144
Policy mu Max                2.9929478
Policy mu Min                -2.897037
Policy log std Mean          -0.3119318
Policy log std Std           0.14984463
Policy log std Max           0.020208254
Policy log std Min           -1.1706793
Z mean eval                  0.025427436
Z variance eval              0.028883282
total_rewards                [1343.6796794  3830.93047316 1977.31565035 5359.39845442 2232.44183008
 1564.55948178 2615.82161288 5476.48552634 3606.39801409 2050.74474301]
total_rewards_mean           3005.777546552198
total_rewards_std            1422.8550775182505
total_rewards_max            5476.485526338102
total_rewards_min            1343.6796794041118
Number of train steps total  355000
Number of env steps total    1777000
Number of rollouts total     0
Train Time (s)               30.841718554031104
(Previous) Eval Time (s)     18.616971840150654
Sample Time (s)              19.177587451413274
Epoch Time (s)               68.63627784559503
Total Train Time (s)         21651.04749733256
Epoch                        354
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:16:33.680475 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #354 | Epoch Duration: 66.74884724617004
2020-01-11 00:16:33.680728 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #354 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025694609
Z variance train             0.028886024
KL Divergence                6.4520807
KL Loss                      0.64520806
QF Loss                      2687.7944
VF Loss                      930.8848
Policy Loss                  -2547.015
Q Predictions Mean           2539.3777
Q Predictions Std            452.1029
Q Predictions Max            2770.468
Q Predictions Min            22.47209
V Predictions Mean           2544.2852
V Predictions Std            449.8071
V Predictions Max            2769.5732
V Predictions Min            34.557453
Log Pis Mean                 -3.1660414
Log Pis Std                  5.8019423
Log Pis Max                  32.72104
Log Pis Min                  -12.38379
Policy mu Mean               0.3562896
Policy mu Std                0.75237286
Policy mu Max                3.5050871
Policy mu Min                -3.923742
Policy log std Mean          -0.3178708
Policy log std Std           0.15450579
Policy log std Max           -0.06370196
Policy log std Min           -1.306338
Z mean eval                  0.023229748
Z variance eval              0.030525854
total_rewards                [2588.09694932 1814.14061026 2765.99718019 5479.75103228 4414.2557458
 5377.76780127 3927.29756492 3377.91447497 5467.50247649 5256.58231243]
total_rewards_mean           4046.930614793323
total_rewards_std            1290.6023150098902
total_rewards_max            5479.75103228308
total_rewards_min            1814.1406102634985
Number of train steps total  356000
Number of env steps total    1782000
Number of rollouts total     0
Train Time (s)               29.95714853424579
(Previous) Eval Time (s)     16.72923617856577
Sample Time (s)              20.160611073486507
Epoch Time (s)               66.84699578629807
Total Train Time (s)         21723.772505051456
Epoch                        355
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:17:46.409864 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #355 | Epoch Duration: 72.72894239425659
2020-01-11 00:17:46.410066 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #355 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023099285
Z variance train             0.030510638
KL Divergence                6.3211274
KL Loss                      0.63211274
QF Loss                      2404.5354
VF Loss                      870.4613
Policy Loss                  -2493.9978
Q Predictions Mean           2497.4897
Q Predictions Std            579.86566
Q Predictions Max            2788.301
Q Predictions Min            21.198156
V Predictions Mean           2501.5547
V Predictions Std            576.2902
V Predictions Max            2798.0364
V Predictions Min            32.19146
Log Pis Mean                 -4.615631
Log Pis Std                  4.92338
Log Pis Max                  15.847602
Log Pis Min                  -13.487906
Policy mu Mean               0.34059632
Policy mu Std                0.6941571
Policy mu Max                2.733454
Policy mu Min                -2.4197435
Policy log std Mean          -0.29746482
Policy log std Std           0.14782222
Policy log std Max           0.005052224
Policy log std Min           -1.0104487
Z mean eval                  0.022833284
Z variance eval              0.029975574
total_rewards                [3026.00933173 2127.09396096 5505.19811544 2595.33404744 4418.99181972
 1475.80645314 3185.42261442 3002.52958801 2246.01993326 4527.89771232]
total_rewards_mean           3211.030357643591
total_rewards_std            1184.5304769583418
total_rewards_max            5505.198115435314
total_rewards_min            1475.8064531399941
Number of train steps total  357000
Number of env steps total    1787000
Number of rollouts total     0
Train Time (s)               31.248344636056572
(Previous) Eval Time (s)     22.610803805291653
Sample Time (s)              19.101318672299385
Epoch Time (s)               72.96046711364761
Total Train Time (s)         21791.301995316986
Epoch                        356
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:18:53.942745 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #356 | Epoch Duration: 67.53253149986267
2020-01-11 00:18:53.942943 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #356 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023130745
Z variance train             0.029981265
KL Divergence                6.3642254
KL Loss                      0.6364226
QF Loss                      1462.1669
VF Loss                      421.56952
Policy Loss                  -2555.1028
Q Predictions Mean           2549.3162
Q Predictions Std            500.99692
Q Predictions Max            2789.9797
Q Predictions Min            19.974854
V Predictions Mean           2543.494
V Predictions Std            497.76355
V Predictions Max            2776.595
V Predictions Min            28.093204
Log Pis Mean                 -4.346155
Log Pis Std                  4.677863
Log Pis Max                  14.478532
Log Pis Min                  -15.603282
Policy mu Mean               0.33902785
Policy mu Std                0.70711595
Policy mu Max                2.9554217
Policy mu Min                -3.6156316
Policy log std Mean          -0.29705104
Policy log std Std           0.13790412
Policy log std Max           -0.05383333
Policy log std Min           -1.142407
Z mean eval                  0.02525649
Z variance eval              0.031000122
total_rewards                [1774.86025664 4149.58945047 3038.71497793 1716.14121391 1716.65591051
 4652.96953458 4254.1629861  1405.98529973 1713.8718438  4157.32155214]
total_rewards_mean           2858.027302581433
total_rewards_std            1255.2832295255978
total_rewards_max            4652.969534579444
total_rewards_min            1405.985299730341
Number of train steps total  358000
Number of env steps total    1792000
Number of rollouts total     0
Train Time (s)               28.83474346017465
(Previous) Eval Time (s)     17.18256508372724
Sample Time (s)              19.941461000591516
Epoch Time (s)               65.9587695444934
Total Train Time (s)         21855.109107699245
Epoch                        357
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:19:57.775630 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #357 | Epoch Duration: 63.832539796829224
2020-01-11 00:19:57.775865 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #357 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02502631
Z variance train             0.031003082
KL Divergence                6.292863
KL Loss                      0.6292863
QF Loss                      1402.0176
VF Loss                      390.50385
Policy Loss                  -2514.2817
Q Predictions Mean           2513.8967
Q Predictions Std            526.5272
Q Predictions Max            2770.964
Q Predictions Min            23.751356
V Predictions Mean           2520.0708
V Predictions Std            531.6147
V Predictions Max            2777.151
V Predictions Min            29.576532
Log Pis Mean                 -3.4344258
Log Pis Std                  5.645923
Log Pis Max                  38.366066
Log Pis Min                  -13.94391
Policy mu Mean               0.3103406
Policy mu Std                0.75754666
Policy mu Max                2.516854
Policy mu Min                -4.589873
Policy log std Mean          -0.30324605
Policy log std Std           0.1379824
Policy log std Max           -0.025399514
Policy log std Min           -1.153711
Z mean eval                  0.024286708
Z variance eval              0.032527514
total_rewards                [1709.09955329 4899.72208632 1870.88333497 2771.62800853 5558.96786983
 5300.79380729 5536.4762123  2586.78696534 5177.47065175 2488.04650621]
total_rewards_mean           3789.9874995830373
total_rewards_std            1543.0983051121905
total_rewards_max            5558.967869829739
total_rewards_min            1709.0995532944469
Number of train steps total  359000
Number of env steps total    1797000
Number of rollouts total     0
Train Time (s)               29.27249744301662
(Previous) Eval Time (s)     15.055994176771492
Sample Time (s)              19.441717579960823
Epoch Time (s)               63.77020919974893
Total Train Time (s)         21924.251561964862
Epoch                        358
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:21:06.902279 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #358 | Epoch Duration: 69.1262059211731
2020-01-11 00:21:06.902583 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #358 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024184946
Z variance train             0.032528885
KL Divergence                6.1748705
KL Loss                      0.6174871
QF Loss                      2155.8582
VF Loss                      601.96765
Policy Loss                  -2489.0032
Q Predictions Mean           2477.6982
Q Predictions Std            548.3472
Q Predictions Max            2771.2349
Q Predictions Min            21.470823
V Predictions Mean           2494.8289
V Predictions Std            545.6895
V Predictions Max            2777.6536
V Predictions Min            31.560984
Log Pis Mean                 -3.2771192
Log Pis Std                  5.0793567
Log Pis Max                  17.199974
Log Pis Min                  -15.204506
Policy mu Mean               0.3546798
Policy mu Std                0.7532914
Policy mu Max                2.6944509
Policy mu Min                -2.5588646
Policy log std Mean          -0.30700618
Policy log std Std           0.13772191
Policy log std Max           -0.0188509
Policy log std Min           -0.98278105
Z mean eval                  0.027846968
Z variance eval              0.032176245
total_rewards                [4420.09472678 1273.42950663 3786.99871629 5293.06100999 5357.00601163
 2722.8843128  5286.67710297 2652.56055724 1208.0734075  2213.62388204]
total_rewards_mean           3421.4409233857828
total_rewards_std            1546.2972240791817
total_rewards_max            5357.006011630391
total_rewards_min            1208.0734074988698
Number of train steps total  360000
Number of env steps total    1802000
Number of rollouts total     0
Train Time (s)               32.93015168979764
(Previous) Eval Time (s)     20.411650354973972
Sample Time (s)              20.70090483268723
Epoch Time (s)               74.04270687745884
Total Train Time (s)         21996.52218812192
Epoch                        359
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:22:19.177535 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #359 | Epoch Duration: 72.27471280097961
2020-01-11 00:22:19.177791 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #359 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027635252
Z variance train             0.032169633
KL Divergence                6.194113
KL Loss                      0.6194113
QF Loss                      1804.422
VF Loss                      617.6628
Policy Loss                  -2527.1978
Q Predictions Mean           2525.6702
Q Predictions Std            495.92438
Q Predictions Max            2782.684
Q Predictions Min            23.850672
V Predictions Mean           2520.483
V Predictions Std            491.3098
V Predictions Max            2762.0015
V Predictions Min            34.365334
Log Pis Mean                 -4.212368
Log Pis Std                  5.6636276
Log Pis Max                  21.136942
Log Pis Min                  -14.032497
Policy mu Mean               0.309036
Policy mu Std                0.7411428
Policy mu Max                2.6813457
Policy mu Min                -2.9212618
Policy log std Mean          -0.30951405
Policy log std Std           0.14414878
Policy log std Max           -0.050160915
Policy log std Min           -0.96537703
Z mean eval                  0.02379344
Z variance eval              0.033541046
total_rewards                [2340.53372376 5210.60115188 5390.4266811  1798.62489493 2640.92685149
 5366.61216102 1461.45316467 1223.95432388 5484.4002705  4219.06891796]
total_rewards_mean           3513.6602141202943
total_rewards_std            1695.589924272099
total_rewards_max            5484.400270503961
total_rewards_min            1223.9543238827055
Number of train steps total  361000
Number of env steps total    1807000
Number of rollouts total     0
Train Time (s)               30.971035636030138
(Previous) Eval Time (s)     18.643298488110304
Sample Time (s)              19.273048433940858
Epoch Time (s)               68.8873825580813
Total Train Time (s)         22066.678598699626
Epoch                        360
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:23:29.336346 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #360 | Epoch Duration: 70.15837001800537
2020-01-11 00:23:29.336504 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #360 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02378163
Z variance train             0.033538047
KL Divergence                6.1071796
KL Loss                      0.61071795
QF Loss                      1267.9661
VF Loss                      556.8266
Policy Loss                  -2548.6301
Q Predictions Mean           2543.5044
Q Predictions Std            498.1432
Q Predictions Max            2788.1213
Q Predictions Min            20.183369
V Predictions Mean           2549.349
V Predictions Std            499.34097
V Predictions Max            2795.8716
V Predictions Min            31.507189
Log Pis Mean                 -3.4618762
Log Pis Std                  6.019196
Log Pis Max                  27.48356
Log Pis Min                  -15.233112
Policy mu Mean               0.27467567
Policy mu Std                0.76590997
Policy mu Max                2.7754836
Policy mu Min                -3.1776226
Policy log std Mean          -0.30748862
Policy log std Std           0.14238125
Policy log std Max           -0.04484155
Policy log std Min           -1.2540137
Z mean eval                  0.026476974
Z variance eval              0.033640135
total_rewards                [3135.25947329 5276.27904582 5282.43259488 5380.09464251 4713.0855829
 5427.06090001 5308.79634534 2044.23293443 2986.59564261 1023.43878086]
total_rewards_mean           4057.727594264413
total_rewards_std            1544.749359758073
total_rewards_max            5427.060900006483
total_rewards_min            1023.4387808603468
Number of train steps total  362000
Number of env steps total    1812000
Number of rollouts total     0
Train Time (s)               31.54714347468689
(Previous) Eval Time (s)     19.91398415900767
Sample Time (s)              19.095190240535885
Epoch Time (s)               70.55631787423044
Total Train Time (s)         22140.834935029503
Epoch                        361
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:24:43.499750 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #361 | Epoch Duration: 74.1630790233612
2020-01-11 00:24:43.500093 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #361 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0269426
Z variance train             0.033638097
KL Divergence                6.092757
KL Loss                      0.60927576
QF Loss                      1259.6003
VF Loss                      444.156
Policy Loss                  -2494.0432
Q Predictions Mean           2494.1682
Q Predictions Std            597.9642
Q Predictions Max            2783.1377
Q Predictions Min            23.280079
V Predictions Mean           2494.2751
V Predictions Std            594.4744
V Predictions Max            2772.9927
V Predictions Min            34.37179
Log Pis Mean                 -3.9662187
Log Pis Std                  4.9932346
Log Pis Max                  15.624054
Log Pis Min                  -15.19754
Policy mu Mean               0.3325165
Policy mu Std                0.72188604
Policy mu Max                2.5271623
Policy mu Min                -2.2626777
Policy log std Mean          -0.3083198
Policy log std Std           0.13057679
Policy log std Max           -0.08250544
Policy log std Min           -0.98728997
Z mean eval                  0.02272622
Z variance eval              0.035295907
total_rewards                [5470.71038621 5493.15998398 3203.9783375  5425.29872999 5496.99951515
 5445.7936062  4010.06502233 5244.53055004 4115.48949725 5463.59300928]
total_rewards_mean           4936.961863792823
total_rewards_std            794.6316132817878
total_rewards_max            5496.999515153308
total_rewards_min            3203.9783375006755
Number of train steps total  363000
Number of env steps total    1817000
Number of rollouts total     0
Train Time (s)               31.42908567469567
(Previous) Eval Time (s)     23.520386742893606
Sample Time (s)              19.18007826944813
Epoch Time (s)               74.12955068703741
Total Train Time (s)         22217.427331751212
Epoch                        362
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:26:00.093930 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #362 | Epoch Duration: 76.59362363815308
2020-01-11 00:26:00.094151 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #362 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022970174
Z variance train             0.03529664
KL Divergence                5.9841995
KL Loss                      0.59841996
QF Loss                      1112.4111
VF Loss                      360.04333
Policy Loss                  -2582.1965
Q Predictions Mean           2580.8804
Q Predictions Std            438.81998
Q Predictions Max            2786.6162
Q Predictions Min            21.46318
V Predictions Mean           2577.4556
V Predictions Std            437.7376
V Predictions Max            2791.337
V Predictions Min            32.14607
Log Pis Mean                 -4.5434284
Log Pis Std                  4.5734177
Log Pis Max                  24.387955
Log Pis Min                  -13.026934
Policy mu Mean               0.34158343
Policy mu Std                0.6908303
Policy mu Max                2.6706634
Policy mu Min                -3.30374
Policy log std Mean          -0.29145473
Policy log std Std           0.14111243
Policy log std Max           -0.0534494
Policy log std Min           -1.113127
Z mean eval                  0.021698214
Z variance eval              0.033129048
total_rewards                [2282.21876185  518.99008268 1791.18495077 5296.92562266 5328.29252767
 5356.69149524 4245.35491239 5017.15962799 5211.92603214 5340.27959314]
total_rewards_mean           4038.9023606533665
total_rewards_std            1719.8502310312542
total_rewards_max            5356.69149524227
total_rewards_min            518.990082679162
Number of train steps total  364000
Number of env steps total    1822000
Number of rollouts total     0
Train Time (s)               32.58891788404435
(Previous) Eval Time (s)     25.984202005900443
Sample Time (s)              18.865410076919943
Epoch Time (s)               77.43852996686473
Total Train Time (s)         22291.732839219272
Epoch                        363
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:27:14.406749 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #363 | Epoch Duration: 74.31242728233337
2020-01-11 00:27:14.407035 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #363 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021547478
Z variance train             0.03312673
KL Divergence                6.1523657
KL Loss                      0.6152366
QF Loss                      1443.6682
VF Loss                      530.6305
Policy Loss                  -2509.3157
Q Predictions Mean           2510.103
Q Predictions Std            588.5692
Q Predictions Max            2782.8992
Q Predictions Min            24.857302
V Predictions Mean           2519.653
V Predictions Std            591.62317
V Predictions Max            2822.1733
V Predictions Min            33.309032
Log Pis Mean                 -4.3686323
Log Pis Std                  4.946107
Log Pis Max                  17.139454
Log Pis Min                  -13.8563795
Policy mu Mean               0.32141495
Policy mu Std                0.70119876
Policy mu Max                2.5080276
Policy mu Min                -2.947582
Policy log std Mean          -0.30509079
Policy log std Std           0.13376623
Policy log std Max           -0.01780641
Policy log std Min           -1.0576936
Z mean eval                  0.02181445
Z variance eval              0.033695783
total_rewards                [2505.15469523 1810.92858892 3614.81558772 2559.02220185 5511.89156036
 5435.77759896 2025.44899089 1166.54009586 1623.79237717 3414.98665203]
total_rewards_mean           2966.835834896605
total_rewards_std            1443.6177353345288
total_rewards_max            5511.891560355506
total_rewards_min            1166.540095858407
Number of train steps total  365000
Number of env steps total    1827000
Number of rollouts total     0
Train Time (s)               31.13969836710021
(Previous) Eval Time (s)     22.857766028959304
Sample Time (s)              19.403282702434808
Epoch Time (s)               73.40074709849432
Total Train Time (s)         22358.067429440096
Epoch                        364
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:28:20.742803 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #364 | Epoch Duration: 66.33556962013245
2020-01-11 00:28:20.742970 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #364 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021998135
Z variance train             0.03370789
KL Divergence                6.078127
KL Loss                      0.6078127
QF Loss                      1415.7968
VF Loss                      470.66498
Policy Loss                  -2565.4417
Q Predictions Mean           2565.3535
Q Predictions Std            464.4016
Q Predictions Max            2788.531
Q Predictions Min            21.287825
V Predictions Mean           2559.6748
V Predictions Std            462.16736
V Predictions Max            2787.7268
V Predictions Min            30.847729
Log Pis Mean                 -4.0176153
Log Pis Std                  5.2510915
Log Pis Max                  20.699615
Log Pis Min                  -15.660818
Policy mu Mean               0.3314697
Policy mu Std                0.71056384
Policy mu Max                2.905642
Policy mu Min                -2.8510065
Policy log std Mean          -0.3040209
Policy log std Std           0.14420421
Policy log std Max           -0.060731612
Policy log std Min           -1.1575294
Z mean eval                  0.02549613
Z variance eval              0.035317205
total_rewards                [2321.77000573 2918.8919595  5432.58179238 5650.37954132 4080.11727761
 1152.02694522 4881.79130418 2238.86244656 2023.93914727 5392.8088232 ]
total_rewards_mean           3609.3169242971503
total_rewards_std            1583.54743129564
total_rewards_max            5650.379541321504
total_rewards_min            1152.0269452207394
Number of train steps total  366000
Number of env steps total    1832000
Number of rollouts total     0
Train Time (s)               31.44285753276199
(Previous) Eval Time (s)     15.792269029654562
Sample Time (s)              19.340117373038083
Epoch Time (s)               66.57524393545464
Total Train Time (s)         22428.436150772497
Epoch                        365
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:29:31.117086 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #365 | Epoch Duration: 70.37396383285522
2020-01-11 00:29:31.117354 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #365 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025464082
Z variance train             0.035311393
KL Divergence                5.965408
KL Loss                      0.5965408
QF Loss                      2403.2817
VF Loss                      978.19104
Policy Loss                  -2566.927
Q Predictions Mean           2566.067
Q Predictions Std            460.37878
Q Predictions Max            2774.6882
Q Predictions Min            20.986061
V Predictions Mean           2572.3538
V Predictions Std            461.76007
V Predictions Max            2784.4507
V Predictions Min            33.196842
Log Pis Mean                 -4.1986217
Log Pis Std                  4.3706384
Log Pis Max                  14.860456
Log Pis Min                  -14.10677
Policy mu Mean               0.29016712
Policy mu Std                0.71071035
Policy mu Max                2.5849078
Policy mu Min                -2.1208758
Policy log std Mean          -0.28137782
Policy log std Std           0.13355526
Policy log std Max           0.18960635
Policy log std Min           -0.95674574
Z mean eval                  0.02828013
Z variance eval              0.034507554
total_rewards                [5499.42324742 5441.47461927 5456.33150939 5247.90825131 1656.55611473
 5401.14378109 5366.75001844 3746.36781505 1326.89194864 4066.63645805]
total_rewards_mean           4320.948376338708
total_rewards_std            1533.3438012302763
total_rewards_max            5499.423247417591
total_rewards_min            1326.8919486417417
Number of train steps total  367000
Number of env steps total    1837000
Number of rollouts total     0
Train Time (s)               29.661842074245214
(Previous) Eval Time (s)     19.59065878810361
Sample Time (s)              19.844344270415604
Epoch Time (s)               69.09684513276443
Total Train Time (s)         22502.522077854257
Epoch                        366
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:30:45.209769 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #366 | Epoch Duration: 74.09219813346863
2020-01-11 00:30:45.210082 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #366 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028431457
Z variance train             0.034516763
KL Divergence                6.0286226
KL Loss                      0.6028623
QF Loss                      1066.8837
VF Loss                      506.24496
Policy Loss                  -2573.323
Q Predictions Mean           2568.5513
Q Predictions Std            480.24625
Q Predictions Max            2786.7559
Q Predictions Min            22.090614
V Predictions Mean           2565.3167
V Predictions Std            479.70682
V Predictions Max            2782.292
V Predictions Min            34.4962
Log Pis Mean                 -4.5823946
Log Pis Std                  5.1555777
Log Pis Max                  26.3375
Log Pis Min                  -13.516001
Policy mu Mean               0.3283783
Policy mu Std                0.69198275
Policy mu Max                2.8622267
Policy mu Min                -2.9693584
Policy log std Mean          -0.29549864
Policy log std Std           0.13132735
Policy log std Max           -0.047940195
Policy log std Min           -1.0367389
Z mean eval                  0.03113478
Z variance eval              0.033382557
total_rewards                [5316.28180257 5323.54315228 5322.32084377 5372.34922594 5468.2947422
 4007.29575574 5457.43340505 5519.63255208 3840.51198797 5481.38013137]
total_rewards_mean           5110.904359897067
total_rewards_std            598.6998851075408
total_rewards_max            5519.632552083359
total_rewards_min            3840.511987968798
Number of train steps total  368000
Number of env steps total    1842000
Number of rollouts total     0
Train Time (s)               33.237442003097385
(Previous) Eval Time (s)     24.58564708987251
Sample Time (s)              19.94351544417441
Epoch Time (s)               77.7666045371443
Total Train Time (s)         22583.666115598753
Epoch                        367
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:32:06.359749 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #367 | Epoch Duration: 81.14942359924316
2020-01-11 00:32:06.360053 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #367 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030965945
Z variance train             0.033382587
KL Divergence                6.10249
KL Loss                      0.610249
QF Loss                      1530.0402
VF Loss                      752.70807
Policy Loss                  -2584.659
Q Predictions Mean           2586.7922
Q Predictions Std            386.82193
Q Predictions Max            2801.0728
Q Predictions Min            25.640978
V Predictions Mean           2598.2766
V Predictions Std            387.4738
V Predictions Max            2805.9177
V Predictions Min            35.36505
Log Pis Mean                 -4.207567
Log Pis Std                  5.886544
Log Pis Max                  26.90741
Log Pis Min                  -14.615836
Policy mu Mean               0.3410234
Policy mu Std                0.73732895
Policy mu Max                3.0193703
Policy mu Min                -3.48317
Policy log std Mean          -0.31501168
Policy log std Std           0.14074297
Policy log std Max           -0.032252632
Policy log std Min           -1.0582196
Z mean eval                  0.03569631
Z variance eval              0.034157317
total_rewards                [2205.2792581  1995.53316033 5704.21780493 1370.55959328 2764.74990736
 5091.59051934 2768.2770195  1260.90039795 5762.73971779 5754.07829289]
total_rewards_mean           3467.7925671482144
total_rewards_std            1792.9316849851868
total_rewards_max            5762.739717792596
total_rewards_min            1260.9003979530169
Number of train steps total  369000
Number of env steps total    1847000
Number of rollouts total     0
Train Time (s)               32.508262692950666
(Previous) Eval Time (s)     27.96816257806495
Sample Time (s)              19.728924523107708
Epoch Time (s)               80.20534979412332
Total Train Time (s)         22653.828467386775
Epoch                        368
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:33:16.527605 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #368 | Epoch Duration: 70.16732835769653
2020-01-11 00:33:16.527876 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #368 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03566881
Z variance train             0.034157414
KL Divergence                6.044913
KL Loss                      0.6044913
QF Loss                      2245.1868
VF Loss                      663.1484
Policy Loss                  -2597.146
Q Predictions Mean           2592.7292
Q Predictions Std            413.4171
Q Predictions Max            2782.776
Q Predictions Min            23.407907
V Predictions Mean           2586.8896
V Predictions Std            414.30502
V Predictions Max            2780.0432
V Predictions Min            34.08241
Log Pis Mean                 -4.2882133
Log Pis Std                  4.958643
Log Pis Max                  20.630821
Log Pis Min                  -13.980745
Policy mu Mean               0.33224136
Policy mu Std                0.69727176
Policy mu Max                2.7142992
Policy mu Min                -3.9566336
Policy log std Mean          -0.29669428
Policy log std Std           0.13625579
Policy log std Max           -0.07318924
Policy log std Min           -1.1057875
Z mean eval                  0.029675424
Z variance eval              0.034615733
total_rewards                [5343.82660291 5366.33064656 5435.4899117  5385.37378721 5386.59662503
 1379.88350197 5394.20872429 5294.59096492  866.27145903 5399.77497687]
total_rewards_mean           4525.234720049664
total_rewards_std            1705.314488043448
total_rewards_max            5435.489911695181
total_rewards_min            866.2714590339812
Number of train steps total  370000
Number of env steps total    1852000
Number of rollouts total     0
Train Time (s)               28.68547239108011
(Previous) Eval Time (s)     17.92981107113883
Sample Time (s)              19.163375227712095
Epoch Time (s)               65.77865868993104
Total Train Time (s)         22726.12001019437
Epoch                        369
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:34:28.821353 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #369 | Epoch Duration: 72.29329657554626
2020-01-11 00:34:28.821585 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #369 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029454809
Z variance train             0.034629323
KL Divergence                6.0155935
KL Loss                      0.60155934
QF Loss                      1384.0592
VF Loss                      607.13226
Policy Loss                  -2592.3499
Q Predictions Mean           2589.7593
Q Predictions Std            425.8406
Q Predictions Max            2790.043
Q Predictions Min            25.170273
V Predictions Mean           2590.489
V Predictions Std            431.8857
V Predictions Max            2790.553
V Predictions Min            35.857227
Log Pis Mean                 -3.9227824
Log Pis Std                  5.5255046
Log Pis Max                  24.925362
Log Pis Min                  -13.5347805
Policy mu Mean               0.27379355
Policy mu Std                0.74504405
Policy mu Max                2.8375788
Policy mu Min                -3.2107117
Policy log std Mean          -0.29050446
Policy log std Std           0.14336945
Policy log std Max           0.05405791
Policy log std Min           -0.9969285
Z mean eval                  0.03152205
Z variance eval              0.03670975
total_rewards                [5447.32367269 3352.13001482 5547.54624114 5373.82040324 2088.49253872
 5352.364582   2849.77766362 5475.19650742 2265.76248783 4178.81300593]
total_rewards_mean           4193.1227117425715
total_rewards_std            1358.1354909444415
total_rewards_max            5547.546241142513
total_rewards_min            2088.4925387229255
Number of train steps total  371000
Number of env steps total    1857000
Number of rollouts total     0
Train Time (s)               31.24153720913455
(Previous) Eval Time (s)     24.444139114115387
Sample Time (s)              19.248026018496603
Epoch Time (s)               74.93370234174654
Total Train Time (s)         22799.825626825914
Epoch                        370
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:35:42.529755 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #370 | Epoch Duration: 73.7080409526825
2020-01-11 00:35:42.529916 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #370 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03167703
Z variance train             0.036708713
KL Divergence                5.883834
KL Loss                      0.5883834
QF Loss                      1161.0076
VF Loss                      630.4044
Policy Loss                  -2603.6106
Q Predictions Mean           2599.6946
Q Predictions Std            399.33432
Q Predictions Max            2802.7556
Q Predictions Min            18.90234
V Predictions Mean           2599.476
V Predictions Std            393.9724
V Predictions Max            2797.336
V Predictions Min            28.780972
Log Pis Mean                 -4.3698606
Log Pis Std                  4.918896
Log Pis Max                  26.475416
Log Pis Min                  -15.121668
Policy mu Mean               0.35504195
Policy mu Std                0.68605137
Policy mu Max                2.974916
Policy mu Min                -2.3797169
Policy log std Mean          -0.29150924
Policy log std Std           0.13458277
Policy log std Max           0.005400002
Policy log std Min           -0.98374975
Z mean eval                  0.03237772
Z variance eval              0.036288127
total_rewards                [2305.91415355 5369.01469239 3494.57014901 5442.8685694  4243.16206227
 5497.50263308 5149.83111353 2452.53217902 5433.9806789  5428.78535205]
total_rewards_mean           4481.816158318953
total_rewards_std            1219.6773082549742
total_rewards_max            5497.502633080035
total_rewards_min            2305.9141535459617
Number of train steps total  372000
Number of env steps total    1862000
Number of rollouts total     0
Train Time (s)               28.7356263268739
(Previous) Eval Time (s)     23.218153388239443
Sample Time (s)              19.5427916822955
Epoch Time (s)               71.49657139740884
Total Train Time (s)         22873.108430141583
Epoch                        371
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:36:55.815688 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #371 | Epoch Duration: 73.285635471344
2020-01-11 00:36:55.815895 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #371 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03236125
Z variance train             0.036289796
KL Divergence                5.912548
KL Loss                      0.59125483
QF Loss                      1085.4232
VF Loss                      445.62036
Policy Loss                  -2611.277
Q Predictions Mean           2611.9111
Q Predictions Std            407.0414
Q Predictions Max            2797.411
Q Predictions Min            17.91984
V Predictions Mean           2606.509
V Predictions Std            407.49182
V Predictions Max            2800.4543
V Predictions Min            29.20127
Log Pis Mean                 -4.601416
Log Pis Std                  4.6966867
Log Pis Max                  22.227928
Log Pis Min                  -14.722626
Policy mu Mean               0.32391754
Policy mu Std                0.67976415
Policy mu Max                2.6753335
Policy mu Min                -3.438823
Policy log std Mean          -0.289992
Policy log std Std           0.13861446
Policy log std Max           -0.046385705
Policy log std Min           -1.2374334
Z mean eval                  0.033861928
Z variance eval              0.036079984
total_rewards                [5326.67005956 5281.19089388  536.06511005 1969.00670635 1718.81927317
 2039.1401385  2542.08323369 3402.44720403 5387.9354764  2376.09669186]
total_rewards_mean           3057.945478749095
total_rewards_std            1635.4017674956883
total_rewards_max            5387.935476401625
total_rewards_min            536.0651100535324
Number of train steps total  373000
Number of env steps total    1867000
Number of rollouts total     0
Train Time (s)               32.54697166569531
(Previous) Eval Time (s)     25.006925063207746
Sample Time (s)              19.453461003955454
Epoch Time (s)               77.00735773285851
Total Train Time (s)         22942.908715934027
Epoch                        372
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:38:05.620109 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #372 | Epoch Duration: 69.80407643318176
2020-01-11 00:38:05.620297 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #372 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033681665
Z variance train             0.03608318
KL Divergence                5.9156685
KL Loss                      0.59156686
QF Loss                      1345.4714
VF Loss                      452.58826
Policy Loss                  -2592.4534
Q Predictions Mean           2585.5068
Q Predictions Std            441.10004
Q Predictions Max            2785.3008
Q Predictions Min            20.749065
V Predictions Mean           2592.648
V Predictions Std            445.85287
V Predictions Max            2802.3816
V Predictions Min            31.59171
Log Pis Mean                 -4.564309
Log Pis Std                  4.606166
Log Pis Max                  12.421053
Log Pis Min                  -14.040489
Policy mu Mean               0.33974528
Policy mu Std                0.6838443
Policy mu Max                2.8889754
Policy mu Min                -2.5908635
Policy log std Mean          -0.30043215
Policy log std Std           0.13841227
Policy log std Max           0.04405448
Policy log std Min           -1.0203383
Z mean eval                  0.035873346
Z variance eval              0.03304938
total_rewards                [5385.25638039 4824.0950178  5088.7548928  5301.33132645 1578.37759382
 5394.32697748 5331.7628557  5206.11121074 5329.33148575 5270.36657535]
total_rewards_mean           4870.97143162937
total_rewards_std            1109.4439471181522
total_rewards_max            5394.326977482712
total_rewards_min            1578.377593818864
Number of train steps total  374000
Number of env steps total    1872000
Number of rollouts total     0
Train Time (s)               31.27976954029873
(Previous) Eval Time (s)     17.803341476246715
Sample Time (s)              19.14655790105462
Epoch Time (s)               68.22966891760007
Total Train Time (s)         23020.74321968481
Epoch                        373
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:39:23.461286 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #373 | Epoch Duration: 77.84081172943115
2020-01-11 00:39:23.461572 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #373 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035862934
Z variance train             0.03304402
KL Divergence                6.136815
KL Loss                      0.6136815
QF Loss                      942.7368
VF Loss                      385.95258
Policy Loss                  -2553.5317
Q Predictions Mean           2550.4158
Q Predictions Std            523.6371
Q Predictions Max            2794.8418
Q Predictions Min            27.095087
V Predictions Mean           2550.2676
V Predictions Std            524.5724
V Predictions Max            2791.735
V Predictions Min            34.538177
Log Pis Mean                 -3.822836
Log Pis Std                  5.007239
Log Pis Max                  21.718292
Log Pis Min                  -13.873421
Policy mu Mean               0.34508032
Policy mu Std                0.7054389
Policy mu Max                3.1562424
Policy mu Min                -2.2392
Policy log std Mean          -0.31331775
Policy log std Std           0.13564791
Policy log std Max           -0.0069761127
Policy log std Min           -1.0747055
Z mean eval                  0.03440581
Z variance eval              0.0330916
total_rewards                [1148.54089016 5100.76691535 3275.14837684 3032.22157233 2490.81467146
 5315.42219786 3485.64452356 5302.52991815 3356.68092466 5244.6887666 ]
total_rewards_mean           3775.2458756976907
total_rewards_std            1350.2443804913785
total_rewards_max            5315.4221978597425
total_rewards_min            1148.5408901583446
Number of train steps total  375000
Number of env steps total    1877000
Number of rollouts total     0
Train Time (s)               30.548039748333395
(Previous) Eval Time (s)     27.414102621842176
Sample Time (s)              19.378841780126095
Epoch Time (s)               77.34098415030167
Total Train Time (s)         23093.438447908964
Epoch                        374
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:40:36.163915 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #374 | Epoch Duration: 72.70212411880493
2020-01-11 00:40:36.164193 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #374 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03448369
Z variance train             0.03309218
KL Divergence                6.131646
KL Loss                      0.6131646
QF Loss                      1038.0138
VF Loss                      339.1965
Policy Loss                  -2637.411
Q Predictions Mean           2632.046
Q Predictions Std            369.02863
Q Predictions Max            2801.738
Q Predictions Min            20.900309
V Predictions Mean           2632.2021
V Predictions Std            369.2868
V Predictions Max            2806.1165
V Predictions Min            26.032948
Log Pis Mean                 -4.1395226
Log Pis Std                  5.354016
Log Pis Max                  28.655283
Log Pis Min                  -15.092499
Policy mu Mean               0.33986703
Policy mu Std                0.7087324
Policy mu Max                3.4122005
Policy mu Min                -3.1366947
Policy log std Mean          -0.30623716
Policy log std Std           0.13865043
Policy log std Max           -0.06227249
Policy log std Min           -1.1169322
Z mean eval                  0.035905123
Z variance eval              0.03497058
total_rewards                [3378.09449075 1546.4760922  3254.0413833  5423.9564531  2073.85494093
 2675.06408043 5591.84405862 1834.39216345 2774.20535099 5521.70284796]
total_rewards_mean           3407.363186174186
total_rewards_std            1482.7654974064408
total_rewards_max            5591.844058620917
total_rewards_min            1546.4760922044957
Number of train steps total  376000
Number of env steps total    1882000
Number of rollouts total     0
Train Time (s)               31.134640061762184
(Previous) Eval Time (s)     22.774930652230978
Sample Time (s)              20.163379666861147
Epoch Time (s)               74.07295038085431
Total Train Time (s)         23164.05574982334
Epoch                        375
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:41:46.785477 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #375 | Epoch Duration: 70.62109565734863
2020-01-11 00:41:46.785690 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #375 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03572874
Z variance train             0.034972146
KL Divergence                5.9913244
KL Loss                      0.5991325
QF Loss                      1187.3793
VF Loss                      394.75055
Policy Loss                  -2614.8699
Q Predictions Mean           2610.459
Q Predictions Std            375.91937
Q Predictions Max            2798.5383
Q Predictions Min            23.640333
V Predictions Mean           2617.5376
V Predictions Std            378.38
V Predictions Max            2793.7598
V Predictions Min            36.3561
Log Pis Mean                 -4.755408
Log Pis Std                  4.3206096
Log Pis Max                  15.706516
Log Pis Min                  -12.878944
Policy mu Mean               0.3409418
Policy mu Std                0.6743034
Policy mu Max                2.7515962
Policy mu Min                -2.6933632
Policy log std Mean          -0.28763232
Policy log std Std           0.13516997
Policy log std Max           -0.04859668
Policy log std Min           -0.97217214
Z mean eval                  0.03471776
Z variance eval              0.034232467
total_rewards                [1228.70525562 3854.02694002 3325.80037801 5307.7735757  5287.89949368
 2974.96536274 5365.40817744 5379.1137217  5353.69065849 1733.55049047]
total_rewards_mean           3981.093405387472
total_rewards_std            1526.6817610996702
total_rewards_max            5379.113721695994
total_rewards_min            1228.7052556249444
Number of train steps total  377000
Number of env steps total    1887000
Number of rollouts total     0
Train Time (s)               29.381539326626807
(Previous) Eval Time (s)     19.322720759082586
Sample Time (s)              20.375494591426104
Epoch Time (s)               69.0797546771355
Total Train Time (s)         23235.959206240717
Epoch                        376
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:42:58.695563 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #376 | Epoch Duration: 71.90968751907349
2020-01-11 00:42:58.695875 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #376 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03442512
Z variance train             0.034226954
KL Divergence                6.034198
KL Loss                      0.6034198
QF Loss                      1745.794
VF Loss                      894.57544
Policy Loss                  -2607.1335
Q Predictions Mean           2611.0024
Q Predictions Std            390.9363
Q Predictions Max            2825.2266
Q Predictions Min            25.33811
V Predictions Mean           2609.8994
V Predictions Std            381.86795
V Predictions Max            2811.7632
V Predictions Min            32.24474
Log Pis Mean                 -4.3341537
Log Pis Std                  5.665739
Log Pis Max                  29.339241
Log Pis Min                  -15.431216
Policy mu Mean               0.35324025
Policy mu Std                0.69919336
Policy mu Max                3.2572622
Policy mu Min                -3.0286167
Policy log std Mean          -0.3049732
Policy log std Std           0.14515704
Policy log std Max           -0.059119925
Policy log std Min           -0.9689003
Z mean eval                  0.0344773
Z variance eval              0.035055134
total_rewards                [1917.45003665 3141.78565587 5554.13563978 1617.9965651  3627.66658096
 2048.49118564 5403.7107064  4092.73635778 5466.5871856  4990.08257449]
total_rewards_mean           3786.064248827838
total_rewards_std            1475.2051785687188
total_rewards_max            5554.135639780113
total_rewards_min            1617.9965651020652
Number of train steps total  378000
Number of env steps total    1892000
Number of rollouts total     0
Train Time (s)               31.638960698619485
(Previous) Eval Time (s)     22.152308360207826
Sample Time (s)              19.869220132473856
Epoch Time (s)               73.66048919130117
Total Train Time (s)         23308.304849115666
Epoch                        377
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:44:11.043614 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #377 | Epoch Duration: 72.3475124835968
2020-01-11 00:44:11.043859 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #377 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03490265
Z variance train             0.035047084
KL Divergence                5.972063
KL Loss                      0.5972063
QF Loss                      1455.5244
VF Loss                      512.3046
Policy Loss                  -2588.0422
Q Predictions Mean           2582.7236
Q Predictions Std            430.66107
Q Predictions Max            2815.0227
Q Predictions Min            32.335392
V Predictions Mean           2582.3447
V Predictions Std            436.05167
V Predictions Max            2811.66
V Predictions Min            38.92349
Log Pis Mean                 -3.3082485
Log Pis Std                  5.6256757
Log Pis Max                  20.583788
Log Pis Min                  -13.287826
Policy mu Mean               0.35657692
Policy mu Std                0.74211925
Policy mu Max                2.8922188
Policy mu Min                -2.5979726
Policy log std Mean          -0.30316487
Policy log std Std           0.13026431
Policy log std Max           -0.0011903793
Policy log std Min           -1.0807682
Z mean eval                  0.03651859
Z variance eval              0.033555575
total_rewards                [5324.8109197  3527.62355388 4734.15540699 5185.08468916 3675.96235729
 5271.76842451 1226.65810516 5256.43193238 5442.58986216 1496.78005769]
total_rewards_mean           4114.18653089172
total_rewards_std            1520.8847786500833
total_rewards_max            5442.589862157462
total_rewards_min            1226.658105162823
Number of train steps total  379000
Number of env steps total    1897000
Number of rollouts total     0
Train Time (s)               30.163881841115654
(Previous) Eval Time (s)     20.83900963002816
Sample Time (s)              19.10004531033337
Epoch Time (s)               70.10293678147718
Total Train Time (s)         23380.57190501131
Epoch                        378
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:45:23.316349 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #378 | Epoch Duration: 72.27231669425964
2020-01-11 00:45:23.316632 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #378 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036806323
Z variance train             0.033540122
KL Divergence                6.086973
KL Loss                      0.60869735
QF Loss                      1573.1438
VF Loss                      249.82011
Policy Loss                  -2618.0867
Q Predictions Mean           2618.4695
Q Predictions Std            417.92966
Q Predictions Max            2818.3596
Q Predictions Min            22.764595
V Predictions Mean           2616.2441
V Predictions Std            416.49823
V Predictions Max            2817.1958
V Predictions Min            34.79822
Log Pis Mean                 -3.8942056
Log Pis Std                  6.0084977
Log Pis Max                  32.510586
Log Pis Min                  -20.196123
Policy mu Mean               0.32683367
Policy mu Std                0.7093562
Policy mu Max                2.6581657
Policy mu Min                -2.8155246
Policy log std Mean          -0.29743516
Policy log std Std           0.14090297
Policy log std Max           -0.07133724
Policy log std Min           -1.0901483
Z mean eval                  0.038902245
Z variance eval              0.03324526
total_rewards                [2006.55398703 5392.79850697 1843.29840809 5382.46517889 5490.2861886
 5401.89767686 1134.2291496  4179.08645073 5358.0071747  5326.29049569]
total_rewards_mean           4151.4913217161975
total_rewards_std            1681.6957132339041
total_rewards_max            5490.286188599102
total_rewards_min            1134.2291496040611
Number of train steps total  380000
Number of env steps total    1902000
Number of rollouts total     0
Train Time (s)               32.45997815672308
(Previous) Eval Time (s)     23.008082111831754
Sample Time (s)              19.434915498830378
Epoch Time (s)               74.90297576738521
Total Train Time (s)         23454.818109183107
Epoch                        379
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:46:37.564790 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #379 | Epoch Duration: 74.24797368049622
2020-01-11 00:46:37.564975 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #379 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.038838398
Z variance train             0.03326615
KL Divergence                6.1073885
KL Loss                      0.6107389
QF Loss                      2072.1802
VF Loss                      415.7094
Policy Loss                  -2575.1912
Q Predictions Mean           2573.8088
Q Predictions Std            484.81317
Q Predictions Max            2799.299
Q Predictions Min            23.757652
V Predictions Mean           2582.389
V Predictions Std            485.24362
V Predictions Max            2812.721
V Predictions Min            32.755314
Log Pis Mean                 -4.197447
Log Pis Std                  5.166477
Log Pis Max                  21.01329
Log Pis Min                  -16.767696
Policy mu Mean               0.31379294
Policy mu Std                0.70504934
Policy mu Max                2.9632406
Policy mu Min                -2.9404087
Policy log std Mean          -0.2932476
Policy log std Std           0.1346168
Policy log std Max           -0.023127444
Policy log std Min           -1.1690784
Z mean eval                  0.03812673
Z variance eval              0.033836205
total_rewards                [3318.65976326 2836.12972587 5483.06692484 5480.78306318 5452.31921775
 5535.25049582 5281.23421157 2388.96420575 1378.5903155  5491.92650424]
total_rewards_mean           4264.692442778169
total_rewards_std            1526.8025308722902
total_rewards_max            5535.250495822409
total_rewards_min            1378.5903155016836
Number of train steps total  381000
Number of env steps total    1907000
Number of rollouts total     0
Train Time (s)               27.833160406909883
(Previous) Eval Time (s)     22.352727509103715
Sample Time (s)              19.66308096377179
Epoch Time (s)               69.84896887978539
Total Train Time (s)         23525.75736568682
Epoch                        380
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:47:48.510664 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #380 | Epoch Duration: 70.94551634788513
2020-01-11 00:47:48.510943 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #380 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.038058273
Z variance train             0.03382558
KL Divergence                6.057637
KL Loss                      0.60576373
QF Loss                      780.93335
VF Loss                      226.44943
Policy Loss                  -2630.051
Q Predictions Mean           2631.651
Q Predictions Std            406.55795
Q Predictions Max            2802.611
Q Predictions Min            16.197641
V Predictions Mean           2631.8364
V Predictions Std            403.84247
V Predictions Max            2806.091
V Predictions Min            31.20272
Log Pis Mean                 -4.578801
Log Pis Std                  4.3623376
Log Pis Max                  15.187462
Log Pis Min                  -13.847429
Policy mu Mean               0.29888678
Policy mu Std                0.6950978
Policy mu Max                2.9393651
Policy mu Min                -2.8679945
Policy log std Mean          -0.28779393
Policy log std Std           0.12527545
Policy log std Max           -0.054108143
Policy log std Min           -1.0656289
Z mean eval                  0.04127594
Z variance eval              0.035144698
total_rewards                [5330.40921071 5280.1838624  4910.80536184 1077.65179127 5314.61162245
 5218.18151827 2489.09365945 5475.48514378 2281.13389523 5149.3597084 ]
total_rewards_mean           4252.691577378584
total_rewards_std            1552.018274734619
total_rewards_max            5475.485143780062
total_rewards_min            1077.6517912714721
Number of train steps total  382000
Number of env steps total    1912000
Number of rollouts total     0
Train Time (s)               28.821023758035153
(Previous) Eval Time (s)     23.44895626278594
Sample Time (s)              19.827108616009355
Epoch Time (s)               72.09708863683045
Total Train Time (s)         23599.179698209744
Epoch                        381
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:49:01.938779 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #381 | Epoch Duration: 73.42761182785034
2020-01-11 00:49:01.939039 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #381 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.041157585
Z variance train             0.035152458
KL Divergence                5.9731455
KL Loss                      0.59731454
QF Loss                      1833.0305
VF Loss                      695.5192
Policy Loss                  -2581.617
Q Predictions Mean           2581.794
Q Predictions Std            512.4931
Q Predictions Max            2806.9731
Q Predictions Min            21.676271
V Predictions Mean           2580.9941
V Predictions Std            515.84454
V Predictions Max            2803.0894
V Predictions Min            31.637573
Log Pis Mean                 -3.8037393
Log Pis Std                  5.293607
Log Pis Max                  22.871828
Log Pis Min                  -12.760957
Policy mu Mean               0.34176773
Policy mu Std                0.70153826
Policy mu Max                2.7830217
Policy mu Min                -2.7079592
Policy log std Mean          -0.29656067
Policy log std Std           0.13581397
Policy log std Max           -0.030948356
Policy log std Min           -1.179637
Z mean eval                  0.040897377
Z variance eval              0.036369972
total_rewards                [5454.33783407 2568.7372759  1175.87584494 2202.23966763  738.63088589
 5214.86402743 3177.79302956 5295.28556433 5434.73920412 5436.17116161]
total_rewards_mean           3669.8674495492332
total_rewards_std            1812.9708286794641
total_rewards_max            5454.337834066056
total_rewards_min            738.6308858934987
Number of train steps total  383000
Number of env steps total    1917000
Number of rollouts total     0
Train Time (s)               31.420026472304016
(Previous) Eval Time (s)     24.77915506158024
Sample Time (s)              19.889142364263535
Epoch Time (s)               76.08832389814779
Total Train Time (s)         23671.34033601638
Epoch                        382
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:50:14.105617 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #382 | Epoch Duration: 72.166344165802
2020-01-11 00:50:14.105933 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #382 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040945824
Z variance train             0.036367334
KL Divergence                5.8846216
KL Loss                      0.5884622
QF Loss                      1222.6038
VF Loss                      817.9574
Policy Loss                  -2645.1597
Q Predictions Mean           2646.8154
Q Predictions Std            303.57404
Q Predictions Max            2801.8938
Q Predictions Min            26.08566
V Predictions Mean           2650.9048
V Predictions Std            314.38986
V Predictions Max            2824.7678
V Predictions Min            36.252625
Log Pis Mean                 -3.8109117
Log Pis Std                  5.328635
Log Pis Max                  24.828543
Log Pis Min                  -12.356688
Policy mu Mean               0.3580484
Policy mu Std                0.71511334
Policy mu Max                2.8109968
Policy mu Min                -3.2438967
Policy log std Mean          -0.3121883
Policy log std Std           0.15162976
Policy log std Max           -0.05740027
Policy log std Min           -1.3495386
Z mean eval                  0.040982746
Z variance eval              0.03709856
total_rewards                [5477.72676609 4372.59337638 5454.34490024 5449.73910713 5270.13170216
 5353.91963545 1174.22445205 5556.4493214  5353.39273307 5462.69636909]
total_rewards_mean           4892.521836306904
total_rewards_std            1280.5639351372863
total_rewards_max            5556.449321399096
total_rewards_min            1174.224452051893
Number of train steps total  384000
Number of env steps total    1922000
Number of rollouts total     0
Train Time (s)               31.006912471260875
(Previous) Eval Time (s)     20.856847723945975
Sample Time (s)              20.225799033418298
Epoch Time (s)               72.08955922862515
Total Train Time (s)         23749.71769315051
Epoch                        383
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:51:32.488832 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #383 | Epoch Duration: 78.38265180587769
2020-01-11 00:51:32.489125 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #383 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040633116
Z variance train             0.037121754
KL Divergence                5.8514886
KL Loss                      0.5851489
QF Loss                      1111.1863
VF Loss                      329.29938
Policy Loss                  -2611.2366
Q Predictions Mean           2611.5574
Q Predictions Std            434.9038
Q Predictions Max            2806.6755
Q Predictions Min            20.583187
V Predictions Mean           2616.607
V Predictions Std            436.11154
V Predictions Max            2813.3008
V Predictions Min            32.06432
Log Pis Mean                 -4.374301
Log Pis Std                  4.726598
Log Pis Max                  22.990044
Log Pis Min                  -13.017181
Policy mu Mean               0.32158768
Policy mu Std                0.69964695
Policy mu Max                2.781194
Policy mu Min                -2.8745792
Policy log std Mean          -0.3028044
Policy log std Std           0.12897277
Policy log std Max           0.1090626
Policy log std Min           -1.0521998
Z mean eval                  0.04156036
Z variance eval              0.036586657
total_rewards                [3278.38511062 5660.06813718 3853.4229432  3827.34020657 1730.06870099
 5446.2550501  2257.12295019 3476.38909221 2068.78344954 1577.04587647]
total_rewards_mean           3317.4881517072413
total_rewards_std            1372.0772897722054
total_rewards_max            5660.068137183183
total_rewards_min            1577.0458764720643
Number of train steps total  385000
Number of env steps total    1927000
Number of rollouts total     0
Train Time (s)               29.23633292131126
(Previous) Eval Time (s)     27.149578604847193
Sample Time (s)              19.898111755028367
Epoch Time (s)               76.28402328118682
Total Train Time (s)         23816.390660220757
Epoch                        384
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:52:39.164588 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #384 | Epoch Duration: 66.6752417087555
2020-01-11 00:52:39.164777 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #384 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04178562
Z variance train             0.036595657
KL Divergence                5.8745556
KL Loss                      0.5874556
QF Loss                      1189.675
VF Loss                      421.78458
Policy Loss                  -2596.4065
Q Predictions Mean           2595.348
Q Predictions Std            499.47543
Q Predictions Max            2819.428
Q Predictions Min            23.882187
V Predictions Mean           2604.4438
V Predictions Std            496.9286
V Predictions Max            2837.629
V Predictions Min            35.15481
Log Pis Mean                 -4.220834
Log Pis Std                  5.74918
Log Pis Max                  28.103996
Log Pis Min                  -14.462383
Policy mu Mean               0.2993879
Policy mu Std                0.7328792
Policy mu Max                3.1146524
Policy mu Min                -3.0050359
Policy log std Mean          -0.3045602
Policy log std Std           0.13750257
Policy log std Max           0.01979366
Policy log std Min           -1.101317
Z mean eval                  0.04010098
Z variance eval              0.036647886
total_rewards                [5316.83056282 5437.80884987 5398.90362856 4951.62685868 5084.19455116
 4190.04982508 2070.59700145 2002.58043776 3709.95104454 2806.09737917]
total_rewards_mean           4096.864013907815
total_rewards_std            1303.9725898952697
total_rewards_max            5437.808849867083
total_rewards_min            2002.580437759967
Number of train steps total  386000
Number of env steps total    1932000
Number of rollouts total     0
Train Time (s)               30.532317936886102
(Previous) Eval Time (s)     17.540481202304363
Sample Time (s)              18.99991593277082
Epoch Time (s)               67.07271507196128
Total Train Time (s)         23888.69524798589
Epoch                        385
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:53:51.472101 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #385 | Epoch Duration: 72.30718922615051
2020-01-11 00:53:51.472316 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #385 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040335987
Z variance train             0.036653403
KL Divergence                5.8772707
KL Loss                      0.58772707
QF Loss                      774.8616
VF Loss                      293.98325
Policy Loss                  -2647.0715
Q Predictions Mean           2642.9468
Q Predictions Std            389.6652
Q Predictions Max            2835.6084
Q Predictions Min            41.274178
V Predictions Mean           2647.0645
V Predictions Std            390.9341
V Predictions Max            2843.2126
V Predictions Min            47.8192
Log Pis Mean                 -4.6414995
Log Pis Std                  4.399825
Log Pis Max                  15.365094
Log Pis Min                  -13.8533535
Policy mu Mean               0.3248333
Policy mu Std                0.6754089
Policy mu Max                2.7835927
Policy mu Min                -2.444428
Policy log std Mean          -0.2900041
Policy log std Std           0.13831992
Policy log std Max           -0.03630869
Policy log std Min           -0.988343
Z mean eval                  0.040014684
Z variance eval              0.03654037
total_rewards                [1295.65341131  797.66801701 2927.10411989 1687.54756942 5303.16012942
 5387.64562247 3881.13542931 3836.24670115 4965.94145066 5090.89030639]
total_rewards_mean           3517.2992757024995
total_rewards_std            1659.0593025611865
total_rewards_max            5387.645622472281
total_rewards_min            797.668017007414
Number of train steps total  387000
Number of env steps total    1937000
Number of rollouts total     0
Train Time (s)               29.664692047983408
(Previous) Eval Time (s)     22.774638106115162
Sample Time (s)              19.66093481145799
Epoch Time (s)               72.10026496555656
Total Train Time (s)         23957.826704204082
Epoch                        386
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:55:00.611027 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #386 | Epoch Duration: 69.13853526115417
2020-01-11 00:55:00.611353 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #386 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040001094
Z variance train             0.03654685
KL Divergence                5.885106
KL Loss                      0.58851063
QF Loss                      1585.7141
VF Loss                      572.3351
Policy Loss                  -2617.6829
Q Predictions Mean           2614.2744
Q Predictions Std            416.77744
Q Predictions Max            2811.0486
Q Predictions Min            22.619177
V Predictions Mean           2617.0122
V Predictions Std            421.7591
V Predictions Max            2815.1328
V Predictions Min            32.509228
Log Pis Mean                 -3.230205
Log Pis Std                  6.539587
Log Pis Max                  31.88417
Log Pis Min                  -13.244837
Policy mu Mean               0.31538397
Policy mu Std                0.7594531
Policy mu Max                3.4282053
Policy mu Min                -3.325304
Policy log std Mean          -0.311125
Policy log std Std           0.140325
Policy log std Max           0.13958426
Policy log std Min           -1.0105168
Z mean eval                  0.041996628
Z variance eval              0.037413478
total_rewards                [5179.01436416  890.36368385 1668.93364582 5437.15214685 5229.90319281
 5334.76104117 1168.79351519 4749.54293465  642.0479011  4354.22041679]
total_rewards_mean           3465.473284238526
total_rewards_std            1974.2114756323988
total_rewards_max            5437.152146849949
total_rewards_min            642.0479011000805
Number of train steps total  388000
Number of env steps total    1942000
Number of rollouts total     0
Train Time (s)               29.617871311027557
(Previous) Eval Time (s)     19.81254763714969
Sample Time (s)              19.231872248928994
Epoch Time (s)               68.66229119710624
Total Train Time (s)         24026.664968024008
Epoch                        387
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:56:09.453258 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #387 | Epoch Duration: 68.84164333343506
2020-01-11 00:56:09.453472 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #387 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04241415
Z variance train             0.03742186
KL Divergence                5.828728
KL Loss                      0.5828728
QF Loss                      1285.6296
VF Loss                      800.637
Policy Loss                  -2629.3452
Q Predictions Mean           2625.7476
Q Predictions Std            454.8191
Q Predictions Max            2830.046
Q Predictions Min            18.380476
V Predictions Mean           2612.37
V Predictions Std            453.91782
V Predictions Max            2829.2156
V Predictions Min            35.41992
Log Pis Mean                 -4.299451
Log Pis Std                  5.799985
Log Pis Max                  30.173763
Log Pis Min                  -14.99333
Policy mu Mean               0.32730108
Policy mu Std                0.7137124
Policy mu Max                2.902914
Policy mu Min                -3.0986583
Policy log std Mean          -0.31087974
Policy log std Std           0.13761592
Policy log std Max           -0.027096115
Policy log std Min           -0.96960163
Z mean eval                  0.042730577
Z variance eval              0.037939012
total_rewards                [5595.25154902 5456.15881126 3164.12831102 3340.70451919 3084.67448402
 1371.46366939 2477.66273153 2990.85618459 4413.89568697 5497.41984109]
total_rewards_mean           3739.2215788074072
total_rewards_std            1364.3682058365948
total_rewards_max            5595.251549020225
total_rewards_min            1371.4636693935781
Number of train steps total  389000
Number of env steps total    1947000
Number of rollouts total     0
Train Time (s)               32.1221014438197
(Previous) Eval Time (s)     19.99161356408149
Sample Time (s)              19.12695489730686
Epoch Time (s)               71.24066990520805
Total Train Time (s)         24098.196169822942
Epoch                        388
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:57:20.986344 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #388 | Epoch Duration: 71.53272223472595
2020-01-11 00:57:20.986495 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #388 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.042848237
Z variance train             0.037949927
KL Divergence                5.8235188
KL Loss                      0.58235186
QF Loss                      1881.7726
VF Loss                      360.7816
Policy Loss                  -2652.258
Q Predictions Mean           2651.8628
Q Predictions Std            346.28723
Q Predictions Max            2812.7493
Q Predictions Min            33.56317
V Predictions Mean           2648.9832
V Predictions Std            344.45175
V Predictions Max            2812.5137
V Predictions Min            41.46523
Log Pis Mean                 -3.8451905
Log Pis Std                  5.5222945
Log Pis Max                  27.530916
Log Pis Min                  -16.438793
Policy mu Mean               0.3353431
Policy mu Std                0.72417337
Policy mu Max                3.4802675
Policy mu Min                -3.544057
Policy log std Mean          -0.3030506
Policy log std Std           0.13707575
Policy log std Max           0.42476094
Policy log std Min           -1.186779
Z mean eval                  0.038908087
Z variance eval              0.03746699
total_rewards                [1287.77630165 5217.8257941  2959.17811315 5455.6666362  4158.28022015
 5422.57793728 3282.09853549 3899.16423614 3357.41764593 3139.45597098]
total_rewards_mean           3817.944139107368
total_rewards_std            1242.4921864175956
total_rewards_max            5455.6666362029955
total_rewards_min            1287.7763016537072
Number of train steps total  390000
Number of env steps total    1952000
Number of rollouts total     0
Train Time (s)               31.215226497966796
(Previous) Eval Time (s)     20.283329125959426
Sample Time (s)              20.00988671509549
Epoch Time (s)               71.50844233902171
Total Train Time (s)         24169.928186350968
Epoch                        389
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:58:32.723152 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #389 | Epoch Duration: 71.73652291297913
2020-01-11 00:58:32.723370 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #389 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.038984258
Z variance train             0.03746677
KL Divergence                5.8463516
KL Loss                      0.5846352
QF Loss                      2108.7778
VF Loss                      767.71216
Policy Loss                  -2626.1956
Q Predictions Mean           2622.805
Q Predictions Std            423.55493
Q Predictions Max            2819.3755
Q Predictions Min            26.09807
V Predictions Mean           2619.688
V Predictions Std            416.17545
V Predictions Max            2802.3313
V Predictions Min            35.78646
Log Pis Mean                 -4.79906
Log Pis Std                  5.4185963
Log Pis Max                  31.71635
Log Pis Min                  -15.324978
Policy mu Mean               0.29542172
Policy mu Std                0.6790082
Policy mu Max                3.101455
Policy mu Min                -3.4233289
Policy log std Mean          -0.28577995
Policy log std Std           0.13650456
Policy log std Max           -0.04607573
Policy log std Min           -1.0496888
Z mean eval                  0.03868327
Z variance eval              0.037937988
total_rewards                [3772.12279203 5543.08783754 5118.27742048 2553.40111743 3165.68506239
 1551.28984427 5350.77931556 1645.4089326  4295.49264832 4633.6436749 ]
total_rewards_mean           3762.9188645517615
total_rewards_std            1405.8432726476021
total_rewards_max            5543.087837543503
total_rewards_min            1551.28984426899
Number of train steps total  391000
Number of env steps total    1957000
Number of rollouts total     0
Train Time (s)               29.75118815386668
(Previous) Eval Time (s)     20.51107255090028
Sample Time (s)              19.569015284534544
Epoch Time (s)               69.8312759893015
Total Train Time (s)         24239.84032783797
Epoch                        390
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:59:42.657674 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #390 | Epoch Duration: 69.93410205841064
2020-01-11 00:59:42.658014 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #390 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.038893152
Z variance train             0.037939783
KL Divergence                5.808688
KL Loss                      0.58086884
QF Loss                      2130.6406
VF Loss                      563.8473
Policy Loss                  -2622.4756
Q Predictions Mean           2621.7876
Q Predictions Std            415.29413
Q Predictions Max            2828.025
Q Predictions Min            24.461126
V Predictions Mean           2615.4756
V Predictions Std            414.93002
V Predictions Max            2818.5776
V Predictions Min            35.895187
Log Pis Mean                 -4.2834225
Log Pis Std                  5.801298
Log Pis Max                  23.867292
Log Pis Min                  -14.168593
Policy mu Mean               0.27203393
Policy mu Std                0.736943
Policy mu Max                3.440902
Policy mu Min                -3.0257463
Policy log std Mean          -0.30830732
Policy log std Std           0.14451258
Policy log std Max           -0.08000241
Policy log std Min           -1.3167171
Z mean eval                  0.043338865
Z variance eval              0.03703825
total_rewards                [3081.60252724 5199.61229187 3036.91463117 5561.82339559 3868.18444129
  959.61209573 5530.73680109 5518.55993577 4875.55709738 3210.99643047]
total_rewards_mean           4084.359964759458
total_rewards_std            1444.916036490439
total_rewards_max            5561.82339558715
total_rewards_min            959.6120957302613
Number of train steps total  392000
Number of env steps total    1962000
Number of rollouts total     0
Train Time (s)               30.647953517269343
(Previous) Eval Time (s)     20.61355267232284
Sample Time (s)              19.944996372330934
Epoch Time (s)               71.20650256192312
Total Train Time (s)         24313.18740270473
Epoch                        391
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:00:56.008823 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #391 | Epoch Duration: 73.35057067871094
2020-01-11 01:00:56.009061 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #391 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043515753
Z variance train             0.037037212
KL Divergence                5.852549
KL Loss                      0.5852549
QF Loss                      1431.9572
VF Loss                      255.85898
Policy Loss                  -2657.6238
Q Predictions Mean           2652.625
Q Predictions Std            332.90372
Q Predictions Max            2821.091
Q Predictions Min            31.13648
V Predictions Mean           2653.82
V Predictions Std            337.08905
V Predictions Max            2828.1716
V Predictions Min            40.77441
Log Pis Mean                 -4.1061106
Log Pis Std                  4.5051517
Log Pis Max                  17.65881
Log Pis Min                  -14.806942
Policy mu Mean               0.352314
Policy mu Std                0.6809574
Policy mu Max                3.148341
Policy mu Min                -2.593377
Policy log std Mean          -0.31087577
Policy log std Std           0.13695793
Policy log std Max           0.05749856
Policy log std Min           -1.1217878
Z mean eval                  0.040655937
Z variance eval              0.035992198
total_rewards                [5385.4122629  5495.50903275 5288.5470142  4483.21784573 3643.84474899
 5364.27014683 5313.32959106 3931.44084192 5314.93874562 5077.86520273]
total_rewards_mean           4929.8375432713265
total_rewards_std            633.4240759485505
total_rewards_max            5495.50903274704
total_rewards_min            3643.844748990607
Number of train steps total  393000
Number of env steps total    1967000
Number of rollouts total     0
Train Time (s)               29.09758970187977
(Previous) Eval Time (s)     22.75731223402545
Sample Time (s)              20.25454733381048
Epoch Time (s)               72.1094492697157
Total Train Time (s)         24389.558581236284
Epoch                        392
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:02:12.382468 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #392 | Epoch Duration: 76.37323117256165
2020-01-11 01:02:12.382638 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #392 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040411685
Z variance train             0.035992455
KL Divergence                5.918415
KL Loss                      0.5918415
QF Loss                      2003.4197
VF Loss                      715.991
Policy Loss                  -2633.2966
Q Predictions Mean           2632.7063
Q Predictions Std            353.41077
Q Predictions Max            2825.9194
Q Predictions Min            23.946224
V Predictions Mean           2641.5208
V Predictions Std            340.63245
V Predictions Max            2823.0676
V Predictions Min            34.64351
Log Pis Mean                 -4.0838284
Log Pis Std                  5.476398
Log Pis Max                  24.336239
Log Pis Min                  -13.10268
Policy mu Mean               0.3098255
Policy mu Std                0.71315074
Policy mu Max                2.7306979
Policy mu Min                -2.7595572
Policy log std Mean          -0.30106646
Policy log std Std           0.1411419
Policy log std Max           -0.045982823
Policy log std Min           -1.1455851
Z mean eval                  0.042631485
Z variance eval              0.03464716
total_rewards                [3081.26287046 2455.67648806  914.16022269 2676.88347532 5539.96199367
 5641.02821915 1151.01722785 3197.02987766 2322.39594428  836.81675684]
total_rewards_mean           2781.623307598221
total_rewards_std            1621.839814990162
total_rewards_max            5641.028219147928
total_rewards_min            836.8167568411824
Number of train steps total  394000
Number of env steps total    1972000
Number of rollouts total     0
Train Time (s)               32.41910632699728
(Previous) Eval Time (s)     27.020735053811222
Sample Time (s)              18.806497051380575
Epoch Time (s)               78.24633843218908
Total Train Time (s)         24455.96758809965
Epoch                        393
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:03:18.794667 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #393 | Epoch Duration: 66.41189765930176
2020-01-11 01:03:18.794860 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #393 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04265422
Z variance train             0.034646016
KL Divergence                6.0232115
KL Loss                      0.60232115
QF Loss                      1078.8219
VF Loss                      375.2756
Policy Loss                  -2628.0867
Q Predictions Mean           2624.7305
Q Predictions Std            433.88187
Q Predictions Max            2830.6782
Q Predictions Min            22.952389
V Predictions Mean           2626.6553
V Predictions Std            433.1089
V Predictions Max            2837.449
V Predictions Min            36.1055
Log Pis Mean                 -4.1165237
Log Pis Std                  4.766012
Log Pis Max                  18.92225
Log Pis Min                  -12.52367
Policy mu Mean               0.32471576
Policy mu Std                0.70701516
Policy mu Max                3.2134714
Policy mu Min                -3.2348025
Policy log std Mean          -0.3000061
Policy log std Std           0.13448322
Policy log std Max           -0.06518947
Policy log std Min           -1.1453991
Z mean eval                  0.041816384
Z variance eval              0.03507408
total_rewards                [5359.59737048 2199.36670767 5171.93539514 5405.4783419  5200.10630596
 5266.95551837 5472.22420013 3707.29566691 5387.06909916 2501.47611946]
total_rewards_mean           4567.1504725183895
total_rewards_std            1212.0675095900706
total_rewards_max            5472.224200132792
total_rewards_min            2199.366707670518
Number of train steps total  395000
Number of env steps total    1977000
Number of rollouts total     0
Train Time (s)               29.835186404176056
(Previous) Eval Time (s)     15.186015159823
Sample Time (s)              19.26525446679443
Epoch Time (s)               64.28645603079349
Total Train Time (s)         24530.998990969732
Epoch                        394
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:04:33.829696 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #394 | Epoch Duration: 75.03470802307129
2020-01-11 01:04:33.829909 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #394 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04190305
Z variance train             0.035069156
KL Divergence                6.0017242
KL Loss                      0.60017246
QF Loss                      1523.9222
VF Loss                      413.13727
Policy Loss                  -2643.912
Q Predictions Mean           2647.0977
Q Predictions Std            378.14236
Q Predictions Max            2830.3162
Q Predictions Min            25.91904
V Predictions Mean           2649.5874
V Predictions Std            374.3811
V Predictions Max            2826.472
V Predictions Min            35.81817
Log Pis Mean                 -4.189522
Log Pis Std                  4.93123
Log Pis Max                  17.88768
Log Pis Min                  -12.83265
Policy mu Mean               0.34956408
Policy mu Std                0.711706
Policy mu Max                2.8860955
Policy mu Min                -2.7955704
Policy log std Mean          -0.30323556
Policy log std Std           0.13797918
Policy log std Max           -0.043213427
Policy log std Min           -1.0969536
Z mean eval                  0.04098412
Z variance eval              0.03558333
total_rewards                [5600.87479964 1783.22716561 5594.99233706 5557.47765023 2800.47328064
 5516.94989824 2128.48652909 4668.14084933 5342.90229786 5682.81163427]
total_rewards_mean           4467.633644198177
total_rewards_std            1502.7982115521058
total_rewards_max            5682.811634271753
total_rewards_min            1783.2271656071794
Number of train steps total  396000
Number of env steps total    1982000
Number of rollouts total     0
Train Time (s)               31.6749829063192
(Previous) Eval Time (s)     25.933950202073902
Sample Time (s)              19.710941834840924
Epoch Time (s)               77.31987494323403
Total Train Time (s)         24606.324616087135
Epoch                        395
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:05:49.159179 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #395 | Epoch Duration: 75.3291015625
2020-01-11 01:05:49.159448 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #395 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.041004375
Z variance train             0.035593893
KL Divergence                5.9647574
KL Loss                      0.5964758
QF Loss                      1081.3291
VF Loss                      718.8241
Policy Loss                  -2648.74
Q Predictions Mean           2646.4424
Q Predictions Std            407.94534
Q Predictions Max            2834.0623
Q Predictions Min            25.961092
V Predictions Mean           2645.0137
V Predictions Std            400.98563
V Predictions Max            2828.514
V Predictions Min            31.66527
Log Pis Mean                 -4.4963465
Log Pis Std                  5.222484
Log Pis Max                  29.198711
Log Pis Min                  -14.150301
Policy mu Mean               0.34236652
Policy mu Std                0.6792013
Policy mu Max                3.0385842
Policy mu Min                -2.9735868
Policy log std Mean          -0.2900559
Policy log std Std           0.1321143
Policy log std Max           -0.02241923
Policy log std Min           -0.95201135
Z mean eval                  0.04258002
Z variance eval              0.0381713
total_rewards                [5291.11434166 5366.33239853 5355.07036352 5369.04223792 5105.25588435
 5320.34318837 5291.90238654 4482.69749435 5270.27415709 5272.97892562]
total_rewards_mean           5212.50113779515
total_rewards_std            253.71634670812708
total_rewards_max            5369.042237917023
total_rewards_min            4482.697494354883
Number of train steps total  397000
Number of env steps total    1987000
Number of rollouts total     0
Train Time (s)               33.229873335920274
(Previous) Eval Time (s)     23.942809735424817
Sample Time (s)              19.767685886472464
Epoch Time (s)               76.94036895781755
Total Train Time (s)         24688.27882737806
Epoch                        396
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:07:11.116527 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #396 | Epoch Duration: 81.95687317848206
2020-01-11 01:07:11.116772 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #396 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.042750627
Z variance train             0.03817052
KL Divergence                5.7896614
KL Loss                      0.57896614
QF Loss                      1307.605
VF Loss                      476.70038
Policy Loss                  -2675.9758
Q Predictions Mean           2667.6023
Q Predictions Std            316.8248
Q Predictions Max            2821.6382
Q Predictions Min            14.566181
V Predictions Mean           2676.9849
V Predictions Std            312.03256
V Predictions Max            2820.0195
V Predictions Min            22.562017
Log Pis Mean                 -4.421183
Log Pis Std                  4.957734
Log Pis Max                  18.460066
Log Pis Min                  -14.232303
Policy mu Mean               0.36836195
Policy mu Std                0.67579865
Policy mu Max                3.079616
Policy mu Min                -3.0542932
Policy log std Mean          -0.29163265
Policy log std Std           0.13258366
Policy log std Max           -0.049511343
Policy log std Min           -1.1952997
Z mean eval                  0.04306327
Z variance eval              0.037600502
total_rewards                [5152.04002529 5351.16195384 5222.86578592 5082.91450486 5392.84590837
 1121.98831385 5137.01194013 2560.1351015  5458.83894283 3474.00254093]
total_rewards_mean           4395.380501751557
total_rewards_std            1423.0792123069805
total_rewards_max            5458.838942831577
total_rewards_min            1121.988313850106
Number of train steps total  398000
Number of env steps total    1992000
Number of rollouts total     0
Train Time (s)               30.746734661981463
(Previous) Eval Time (s)     28.958981491159648
Sample Time (s)              20.41419585701078
Epoch Time (s)               80.1199120101519
Total Train Time (s)         24764.098373065237
Epoch                        397
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:08:26.943425 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #397 | Epoch Duration: 75.82644867897034
2020-01-11 01:08:26.943738 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #397 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04319171
Z variance train             0.03759712
KL Divergence                5.8544717
KL Loss                      0.5854472
QF Loss                      857.5703
VF Loss                      291.3475
Policy Loss                  -2669.8313
Q Predictions Mean           2666.4
Q Predictions Std            370.0266
Q Predictions Max            2827.9954
Q Predictions Min            31.423267
V Predictions Mean           2669.624
V Predictions Std            369.8449
V Predictions Max            2833.1335
V Predictions Min            44.39318
Log Pis Mean                 -4.431754
Log Pis Std                  4.656123
Log Pis Max                  19.216934
Log Pis Min                  -15.708776
Policy mu Mean               0.33556578
Policy mu Std                0.70294285
Policy mu Max                3.1742077
Policy mu Min                -2.8121424
Policy log std Mean          -0.3027796
Policy log std Std           0.1287663
Policy log std Max           0.07746878
Policy log std Min           -1.0110841
Z mean eval                  0.04403698
Z variance eval              0.03694383
total_rewards                [5334.59387357 1378.98461555 5489.16741186 5348.9046151  5246.17781873
 1137.95218923 5349.22056104 2619.51109782 1921.64097777 5368.69568671]
total_rewards_mean           3919.4848847386284
total_rewards_std            1796.845166470461
total_rewards_max            5489.1674118616575
total_rewards_min            1137.952189232052
Number of train steps total  399000
Number of env steps total    1997000
Number of rollouts total     0
Train Time (s)               34.67122284695506
(Previous) Eval Time (s)     24.665161652024835
Sample Time (s)              19.525769614614546
Epoch Time (s)               78.86215411359444
Total Train Time (s)         24839.610722296406
Epoch                        398
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:09:42.461738 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #398 | Epoch Duration: 75.51773357391357
2020-01-11 01:09:42.461997 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #398 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043837104
Z variance train             0.03692684
KL Divergence                5.902482
KL Loss                      0.5902482
QF Loss                      1464.0709
VF Loss                      668.51636
Policy Loss                  -2658.2236
Q Predictions Mean           2655.739
Q Predictions Std            290.0351
Q Predictions Max            2818.0464
Q Predictions Min            78.14002
V Predictions Mean           2669.2751
V Predictions Std            288.56262
V Predictions Max            2831.1448
V Predictions Min            90.79938
Log Pis Mean                 -4.0554323
Log Pis Std                  5.122757
Log Pis Max                  17.685274
Log Pis Min                  -15.26842
Policy mu Mean               0.35444316
Policy mu Std                0.7073461
Policy mu Max                3.650819
Policy mu Min                -2.9127986
Policy log std Mean          -0.3032886
Policy log std Std           0.14666261
Policy log std Max           0.011782065
Policy log std Min           -1.2171465
Z mean eval                  0.04732321
Z variance eval              0.03483174
total_rewards                [2131.64323801 2354.53212411 1222.18853333 5319.48921986 1029.85098705
 3095.81906512 4413.51053566 5267.62449713 2643.36617303 5484.30748145]
total_rewards_mean           3296.23318547621
total_rewards_std            1617.5150003938297
total_rewards_max            5484.307481454133
total_rewards_min            1029.8509870544988
Number of train steps total  400000
Number of env steps total    2002000
Number of rollouts total     0
Train Time (s)               33.90063401311636
(Previous) Eval Time (s)     21.320446759928018
Sample Time (s)              19.9587266407907
Epoch Time (s)               75.17980741383508
Total Train Time (s)         24912.783067482058
Epoch                        399
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:10:55.641200 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #399 | Epoch Duration: 73.17897701263428
2020-01-11 01:10:55.641525 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #399 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.047375936
Z variance train             0.03482343
KL Divergence                6.0421395
KL Loss                      0.60421395
QF Loss                      630.1387
VF Loss                      365.9726
Policy Loss                  -2652.9348
Q Predictions Mean           2649.5603
Q Predictions Std            441.29953
Q Predictions Max            2837.7888
Q Predictions Min            19.2089
V Predictions Mean           2645.449
V Predictions Std            439.03152
V Predictions Max            2836.1536
V Predictions Min            29.586971
Log Pis Mean                 -4.92289
Log Pis Std                  4.410322
Log Pis Max                  13.995659
Log Pis Min                  -19.06099
Policy mu Mean               0.3414933
Policy mu Std                0.674085
Policy mu Max                2.4398851
Policy mu Min                -2.7116838
Policy log std Mean          -0.29926258
Policy log std Std           0.13139693
Policy log std Max           -0.09535704
Policy log std Min           -1.0509896
Z mean eval                  0.048000555
Z variance eval              0.036556304
total_rewards                [5542.71036735 5498.51556797 2347.96492033 5454.82356427 5467.97371055
 2012.82361649 5427.50385203 5314.97815429 5480.66613994 5385.36430928]
total_rewards_mean           4793.332420250408
total_rewards_std            1309.9553609824272
total_rewards_max            5542.710367354535
total_rewards_min            2012.8236164874545
Number of train steps total  401000
Number of env steps total    2007000
Number of rollouts total     0
Train Time (s)               32.821844916790724
(Previous) Eval Time (s)     19.31929396186024
Sample Time (s)              19.710419477894902
Epoch Time (s)               71.85155835654587
Total Train Time (s)         24991.585149263497
Epoch                        400
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:12:14.447399 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #400 | Epoch Duration: 78.80564522743225
2020-01-11 01:12:14.447643 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #400 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.047810063
Z variance train             0.036547463
KL Divergence                5.9233904
KL Loss                      0.59233904
QF Loss                      997.0029
VF Loss                      582.87494
Policy Loss                  -2653.392
Q Predictions Mean           2656.7935
Q Predictions Std            406.57095
Q Predictions Max            2832.9456
Q Predictions Min            23.98758
V Predictions Mean           2666.9038
V Predictions Std            403.0945
V Predictions Max            2843.5981
V Predictions Min            33.66292
Log Pis Mean                 -4.6160955
Log Pis Std                  5.0577726
Log Pis Max                  19.097923
Log Pis Min                  -14.248523
Policy mu Mean               0.38592285
Policy mu Std                0.67112184
Policy mu Max                2.7079353
Policy mu Min                -2.57391
Policy log std Mean          -0.30375227
Policy log std Std           0.13539912
Policy log std Max           -0.0035604686
Policy log std Min           -1.204612
Z mean eval                  0.045659043
Z variance eval              0.038193356
total_rewards                [5248.66122776  790.07264918 3025.51592925 3007.10164206 5251.64400391
 2201.45956529 5037.38345615 5206.49802558  447.33012031 5383.66107361]
total_rewards_mean           3559.9327693089886
total_rewards_std            1836.5948575190025
total_rewards_max            5383.66107361134
total_rewards_min            447.3301203058746
Number of train steps total  402000
Number of env steps total    2012000
Number of rollouts total     0
Train Time (s)               31.144438223913312
(Previous) Eval Time (s)     26.273039714898914
Sample Time (s)              19.003957801964134
Epoch Time (s)               76.42143574077636
Total Train Time (s)         25062.71436911542
Epoch                        401
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:13:25.582072 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #401 | Epoch Duration: 71.13422536849976
2020-01-11 01:13:25.582355 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #401 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045439903
Z variance train             0.03818848
KL Divergence                5.803503
KL Loss                      0.58035034
QF Loss                      1465.7532
VF Loss                      273.14233
Policy Loss                  -2692.9373
Q Predictions Mean           2690.6267
Q Predictions Std            236.54668
Q Predictions Max            2839.2017
Q Predictions Min            24.000557
V Predictions Mean           2697.4436
V Predictions Std            236.05043
V Predictions Max            2842.8872
V Predictions Min            34.545033
Log Pis Mean                 -4.165827
Log Pis Std                  4.7356453
Log Pis Max                  14.432759
Log Pis Min                  -17.194893
Policy mu Mean               0.33961824
Policy mu Std                0.70296264
Policy mu Max                2.9642735
Policy mu Min                -2.38902
Policy log std Mean          -0.29656544
Policy log std Std           0.1305487
Policy log std Max           -0.06915724
Policy log std Min           -0.91434157
Z mean eval                  0.048474282
Z variance eval              0.03837647
total_rewards                [4495.48403253 3099.11494563 3889.00196332 5347.36779888 1912.49991054
 2479.7155492  4273.62496613 5333.48091869 5259.1702195  5422.50808135]
total_rewards_mean           4151.196838576923
total_rewards_std            1216.026986457073
total_rewards_max            5422.5080813456
total_rewards_min            1912.4999105419004
Number of train steps total  403000
Number of env steps total    2017000
Number of rollouts total     0
Train Time (s)               29.596922458149493
(Previous) Eval Time (s)     20.985508199315518
Sample Time (s)              19.87110555358231
Epoch Time (s)               70.45353621104732
Total Train Time (s)         25135.332717106678
Epoch                        402
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:14:38.203633 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #402 | Epoch Duration: 72.62110161781311
2020-01-11 01:14:38.203830 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #402 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04873876
Z variance train             0.038360503
KL Divergence                5.7843795
KL Loss                      0.578438
QF Loss                      1118.5376
VF Loss                      433.19098
Policy Loss                  -2629.091
Q Predictions Mean           2624.0361
Q Predictions Std            486.89154
Q Predictions Max            2825.195
Q Predictions Min            25.857365
V Predictions Mean           2630.852
V Predictions Std            482.5993
V Predictions Max            2830.1743
V Predictions Min            35.90326
Log Pis Mean                 -4.794874
Log Pis Std                  4.723263
Log Pis Max                  18.43067
Log Pis Min                  -14.194331
Policy mu Mean               0.34605268
Policy mu Std                0.6497414
Policy mu Max                2.8101315
Policy mu Min                -2.7776284
Policy log std Mean          -0.28510678
Policy log std Std           0.13264729
Policy log std Max           0.13438612
Policy log std Min           -1.3563046
Z mean eval                  0.045803826
Z variance eval              0.0387994
total_rewards                [1500.52915177 5204.11518888 4901.22925135 3747.56890029 3148.0690948
 3125.24256083 5126.84957986 3187.54017583 4674.53642704 5029.27615894]
total_rewards_mean           3964.4956489586475
total_rewards_std            1161.7165976395231
total_rewards_max            5204.115188876305
total_rewards_min            1500.5291517703743
Number of train steps total  404000
Number of env steps total    2022000
Number of rollouts total     0
Train Time (s)               32.72960554715246
(Previous) Eval Time (s)     23.15279327100143
Sample Time (s)              19.239430140703917
Epoch Time (s)               75.1218289588578
Total Train Time (s)         25210.84999932442
Epoch                        403
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:15:53.724651 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #403 | Epoch Duration: 75.52067995071411
2020-01-11 01:15:53.724842 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #403 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04616938
Z variance train             0.03877973
KL Divergence                5.7518134
KL Loss                      0.57518137
QF Loss                      1012.82214
VF Loss                      207.26399
Policy Loss                  -2690.3066
Q Predictions Mean           2688.6353
Q Predictions Std            353.83408
Q Predictions Max            2838.7856
Q Predictions Min            24.602621
V Predictions Mean           2683.637
V Predictions Std            351.65027
V Predictions Max            2836.5264
V Predictions Min            32.984425
Log Pis Mean                 -4.7191353
Log Pis Std                  4.2571583
Log Pis Max                  19.586246
Log Pis Min                  -13.215547
Policy mu Mean               0.33635274
Policy mu Std                0.66370875
Policy mu Max                2.1956148
Policy mu Min                -2.1253672
Policy log std Mean          -0.2943389
Policy log std Std           0.13029973
Policy log std Max           -0.08013339
Policy log std Min           -0.9647056
Z mean eval                  0.04386998
Z variance eval              0.03881244
total_rewards                [2341.32329575 1742.44420336 4918.46464647 1108.14416738 5345.27106329
 5393.39133156 3634.31022791  704.05064083 2667.40295606 4503.37486522]
total_rewards_mean           3235.8177397833033
total_rewards_std            1673.0790399731106
total_rewards_max            5393.391331556233
total_rewards_min            704.0506408343819
Number of train steps total  405000
Number of env steps total    2027000
Number of rollouts total     0
Train Time (s)               30.20079327886924
(Previous) Eval Time (s)     23.551305117551237
Sample Time (s)              19.51060475036502
Epoch Time (s)               73.2627031467855
Total Train Time (s)         25278.7929143128
Epoch                        404
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:17:01.672571 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #404 | Epoch Duration: 67.94757390022278
2020-01-11 01:17:01.673655 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #404 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043935668
Z variance train             0.03882106
KL Divergence                5.7347984
KL Loss                      0.57347983
QF Loss                      1692.688
VF Loss                      365.6126
Policy Loss                  -2682.3354
Q Predictions Mean           2674.9797
Q Predictions Std            305.64288
Q Predictions Max            2830.204
Q Predictions Min            24.23449
V Predictions Mean           2683.045
V Predictions Std            303.0209
V Predictions Max            2837.4836
V Predictions Min            31.579226
Log Pis Mean                 -4.3172894
Log Pis Std                  4.973567
Log Pis Max                  25.645554
Log Pis Min                  -15.048219
Policy mu Mean               0.29512697
Policy mu Std                0.72323173
Policy mu Max                2.8330908
Policy mu Min                -3.3591194
Policy log std Mean          -0.2980865
Policy log std Std           0.12779415
Policy log std Max           -0.0795512
Policy log std Min           -0.902484
Z mean eval                  0.044685695
Z variance eval              0.03683212
total_rewards                [5349.50924359  785.44337853 5298.84255131 5264.33807991 2261.40164437
 5082.19202196 5147.06210402 5183.83063686 4012.10613253  966.29539112]
total_rewards_mean           3935.102118420133
total_rewards_std            1775.1776065641975
total_rewards_max            5349.5092435875595
total_rewards_min            785.4433785265427
Number of train steps total  406000
Number of env steps total    2032000
Number of rollouts total     0
Train Time (s)               33.38609055476263
(Previous) Eval Time (s)     18.23584759607911
Sample Time (s)              20.08985456265509
Epoch Time (s)               71.71179271349683
Total Train Time (s)         25354.4677231689
Epoch                        405
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:18:17.354144 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #405 | Epoch Duration: 75.68027138710022
2020-01-11 01:18:17.354448 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #405 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.044515613
Z variance train             0.036838394
KL Divergence                5.8630505
KL Loss                      0.5863051
QF Loss                      1624.0927
VF Loss                      754.948
Policy Loss                  -2642.9536
Q Predictions Mean           2645.8027
Q Predictions Std            460.45334
Q Predictions Max            2842.899
Q Predictions Min            17.034714
V Predictions Mean           2656.3074
V Predictions Std            463.6078
V Predictions Max            2861.4216
V Predictions Min            29.636911
Log Pis Mean                 -4.3815727
Log Pis Std                  5.2290444
Log Pis Max                  27.94828
Log Pis Min                  -14.008179
Policy mu Mean               0.32085222
Policy mu Std                0.70340693
Policy mu Max                2.7079318
Policy mu Min                -3.4789207
Policy log std Mean          -0.3062234
Policy log std Std           0.13660976
Policy log std Max           0.016452238
Policy log std Min           -1.1961074
Z mean eval                  0.044551548
Z variance eval              0.035907906
total_rewards                [ 678.20691667 2627.86181078 5365.56927147 5311.95005103 3867.35875371
 2209.81887269 5384.45800573 5313.93270173 4746.53943297 5380.57952558]
total_rewards_mean           4088.627534235805
total_rewards_std            1604.7841819600333
total_rewards_max            5384.458005729353
total_rewards_min            678.2069166656546
Number of train steps total  407000
Number of env steps total    2037000
Number of rollouts total     0
Train Time (s)               30.623487845994532
(Previous) Eval Time (s)     22.20398914022371
Sample Time (s)              18.868574435357004
Epoch Time (s)               71.69605142157525
Total Train Time (s)         25426.882939516567
Epoch                        406
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:19:29.775340 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #406 | Epoch Duration: 72.42064332962036
2020-01-11 01:19:29.775616 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #406 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.044422287
Z variance train             0.03590991
KL Divergence                5.915743
KL Loss                      0.5915743
QF Loss                      1423.4445
VF Loss                      491.1913
Policy Loss                  -2674.3372
Q Predictions Mean           2672.9014
Q Predictions Std            379.9324
Q Predictions Max            2851.0383
Q Predictions Min            26.023275
V Predictions Mean           2676.775
V Predictions Std            377.91638
V Predictions Max            2846.2393
V Predictions Min            35.0272
Log Pis Mean                 -4.646416
Log Pis Std                  4.298831
Log Pis Max                  15.827457
Log Pis Min                  -15.0889635
Policy mu Mean               0.35818896
Policy mu Std                0.68240577
Policy mu Max                2.849367
Policy mu Min                -3.2451098
Policy log std Mean          -0.2973287
Policy log std Std           0.12560847
Policy log std Max           -0.04209046
Policy log std Min           -0.96434784
Z mean eval                  0.04453159
Z variance eval              0.035846375
total_rewards                [2255.36275973 1673.45217775 5563.18849471 4319.46516199 5386.85087404
 2977.51240433 5357.57033857 4314.01204383 1676.50413554 2187.52027804]
total_rewards_mean           3571.143866853205
total_rewards_std            1508.5482124319594
total_rewards_max            5563.188494707743
total_rewards_min            1673.4521777514162
Number of train steps total  408000
Number of env steps total    2042000
Number of rollouts total     0
Train Time (s)               32.095640402287245
(Previous) Eval Time (s)     22.92830810882151
Sample Time (s)              19.44364458275959
Epoch Time (s)               74.46759309386835
Total Train Time (s)         25497.833048332483
Epoch                        407
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:20:40.728711 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #407 | Epoch Duration: 70.95290327072144
2020-01-11 01:20:40.728877 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #407 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.044685557
Z variance train             0.035846844
KL Divergence                5.9216223
KL Loss                      0.59216225
QF Loss                      1354.334
VF Loss                      388.27274
Policy Loss                  -2684.0598
Q Predictions Mean           2674.9888
Q Predictions Std            358.1339
Q Predictions Max            2838.5176
Q Predictions Min            26.295385
V Predictions Mean           2678.6877
V Predictions Std            356.6261
V Predictions Max            2848.625
V Predictions Min            34.236538
Log Pis Mean                 -4.4048166
Log Pis Std                  4.867658
Log Pis Max                  35.374702
Log Pis Min                  -15.36981
Policy mu Mean               0.2993892
Policy mu Std                0.6978332
Policy mu Max                2.9967175
Policy mu Min                -2.7906976
Policy log std Mean          -0.2988343
Policy log std Std           0.13677078
Policy log std Max           -0.016918391
Policy log std Min           -1.0964398
Z mean eval                  0.042629868
Z variance eval              0.038334496
total_rewards                [2302.39804688 2533.85779405 5214.93097212 5191.76265259 5232.0598965
 4029.72149755 1890.47830077 5159.09690665  995.94240456 5247.72711651]
total_rewards_mean           3779.7975588172803
total_rewards_std            1591.7448628454533
total_rewards_max            5247.727116510542
total_rewards_min            995.9424045564186
Number of train steps total  409000
Number of env steps total    2047000
Number of rollouts total     0
Train Time (s)               31.308664282783866
(Previous) Eval Time (s)     19.41329269297421
Sample Time (s)              19.31658584717661
Epoch Time (s)               70.03854282293469
Total Train Time (s)         25569.852241247892
Epoch                        408
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:21:52.750340 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #408 | Epoch Duration: 72.02132654190063
2020-01-11 01:21:52.750529 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #408 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.042983614
Z variance train             0.03832624
KL Divergence                5.7583895
KL Loss                      0.575839
QF Loss                      1263.2234
VF Loss                      584.7471
Policy Loss                  -2653.6177
Q Predictions Mean           2652.0862
Q Predictions Std            443.7784
Q Predictions Max            2843.82
Q Predictions Min            22.38018
V Predictions Mean           2650.044
V Predictions Std            435.21066
V Predictions Max            2838.223
V Predictions Min            35.05657
Log Pis Mean                 -4.705393
Log Pis Std                  5.2766848
Log Pis Max                  30.997313
Log Pis Min                  -18.011337
Policy mu Mean               0.31233886
Policy mu Std                0.69761425
Policy mu Max                3.32146
Policy mu Min                -3.150533
Policy log std Mean          -0.2938366
Policy log std Std           0.1358394
Policy log std Max           -0.04760968
Policy log std Min           -1.1334915
Z mean eval                  0.046889614
Z variance eval              0.039325297
total_rewards                [2237.0918438  2219.26050692 5526.5578099  5427.03901559 5447.32420015
 2211.80293592 5404.830036   2018.23969676 4163.92509159 5321.03967179]
total_rewards_mean           3997.7110808426123
total_rewards_std            1536.5864660624386
total_rewards_max            5526.557809900562
total_rewards_min            2018.2396967552604
Number of train steps total  410000
Number of env steps total    2052000
Number of rollouts total     0
Train Time (s)               33.98358857491985
(Previous) Eval Time (s)     21.395790689159185
Sample Time (s)              19.134202134795487
Epoch Time (s)               74.51358139887452
Total Train Time (s)         25644.489982630592
Epoch                        409
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:23:07.393133 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #409 | Epoch Duration: 74.64246678352356
2020-01-11 01:23:07.393353 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #409 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04687684
Z variance train             0.039298635
KL Divergence                5.7024593
KL Loss                      0.5702459
QF Loss                      1118.6104
VF Loss                      340.7392
Policy Loss                  -2660.8826
Q Predictions Mean           2650.1682
Q Predictions Std            428.0728
Q Predictions Max            2837.509
Q Predictions Min            24.601534
V Predictions Mean           2659.8892
V Predictions Std            423.3688
V Predictions Max            2845.2507
V Predictions Min            32.744526
Log Pis Mean                 -4.19386
Log Pis Std                  5.0275564
Log Pis Max                  17.926382
Log Pis Min                  -14.584716
Policy mu Mean               0.36071086
Policy mu Std                0.68993676
Policy mu Max                2.4487348
Policy mu Min                -2.5649447
Policy log std Mean          -0.29309794
Policy log std Std           0.12944016
Policy log std Max           -0.056479007
Policy log std Min           -1.0491017
Z mean eval                  0.045270704
Z variance eval              0.039316516
total_rewards                [3206.07234766 5452.84598626 5093.06364653 3564.77082541 5330.42313678
 5190.31121206 2701.16675136 5315.73010048 1457.13080725 1015.26413327]
total_rewards_mean           3832.6778947054563
total_rewards_std            1607.02023050596
total_rewards_max            5452.8459862552145
total_rewards_min            1015.2641332729987
Number of train steps total  411000
Number of env steps total    2057000
Number of rollouts total     0
Train Time (s)               31.30213367100805
(Previous) Eval Time (s)     21.52438952215016
Sample Time (s)              20.497252673842013
Epoch Time (s)               73.32377586700022
Total Train Time (s)         25717.929977229796
Epoch                        410
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:24:20.836400 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #410 | Epoch Duration: 73.44289302825928
2020-01-11 01:24:20.836594 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #410 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045301877
Z variance train             0.039311953
KL Divergence                5.7192154
KL Loss                      0.5719215
QF Loss                      1443.0928
VF Loss                      529.7431
Policy Loss                  -2671.9226
Q Predictions Mean           2666.1992
Q Predictions Std            354.5374
Q Predictions Max            2838.9656
Q Predictions Min            19.91095
V Predictions Mean           2677.6753
V Predictions Std            357.0203
V Predictions Max            2866.4797
V Predictions Min            25.052307
Log Pis Mean                 -3.9794338
Log Pis Std                  5.6638856
Log Pis Max                  32.987762
Log Pis Min                  -15.013809
Policy mu Mean               0.30852628
Policy mu Std                0.7319998
Policy mu Max                3.0838993
Policy mu Min                -3.417488
Policy log std Mean          -0.30696648
Policy log std Std           0.14129342
Policy log std Max           -0.052225217
Policy log std Min           -1.1520491
Z mean eval                  0.046744566
Z variance eval              0.03904017
total_rewards                [5397.72644047 5178.91023789 5336.93467579 2184.7820649  5368.04542674
 5269.23858066 3729.68999314 5232.86622082 3236.11775268 5250.13446346]
total_rewards_mean           4618.444585655353
total_rewards_std            1087.3378372131174
total_rewards_max            5397.72644046844
total_rewards_min            2184.782064902314
Number of train steps total  412000
Number of env steps total    2062000
Number of rollouts total     0
Train Time (s)               30.006112546194345
(Previous) Eval Time (s)     21.643185046035796
Sample Time (s)              20.281863579526544
Epoch Time (s)               71.93116117175668
Total Train Time (s)         25793.852515610866
Epoch                        411
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:25:36.761751 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #411 | Epoch Duration: 75.92503881454468
2020-01-11 01:25:36.761931 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #411 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046456832
Z variance train             0.039059836
KL Divergence                5.722473
KL Loss                      0.5722473
QF Loss                      1631.1837
VF Loss                      438.6853
Policy Loss                  -2637.3137
Q Predictions Mean           2636.8828
Q Predictions Std            458.65594
Q Predictions Max            2851.8748
Q Predictions Min            16.49738
V Predictions Mean           2645.4976
V Predictions Std            464.00516
V Predictions Max            2855.9382
V Predictions Min            21.701145
Log Pis Mean                 -4.977452
Log Pis Std                  4.3724995
Log Pis Max                  15.515686
Log Pis Min                  -13.731924
Policy mu Mean               0.29549894
Policy mu Std                0.67248607
Policy mu Max                2.7074764
Policy mu Min                -2.7119086
Policy log std Mean          -0.294474
Policy log std Std           0.12973551
Policy log std Max           0.0016639084
Policy log std Min           -0.93926203
Z mean eval                  0.046992697
Z variance eval              0.038597543
total_rewards                [5250.83977356  858.11815551 1896.82945031 4241.90353814 5309.19636785
 2476.69615486 1903.09720323 5459.70465333 5152.47188663 2073.51470615]
total_rewards_mean           3462.237188956072
total_rewards_std            1691.97230244572
total_rewards_max            5459.704653329977
total_rewards_min            858.1181555141495
Number of train steps total  413000
Number of env steps total    2067000
Number of rollouts total     0
Train Time (s)               32.89344344008714
(Previous) Eval Time (s)     25.63670545304194
Sample Time (s)              20.000980326905847
Epoch Time (s)               78.53112922003493
Total Train Time (s)         25865.888459573034
Epoch                        412
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:26:48.805443 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #412 | Epoch Duration: 72.04335117340088
2020-01-11 01:26:48.805687 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #412 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04730891
Z variance train             0.038583122
KL Divergence                5.746803
KL Loss                      0.57468027
QF Loss                      827.85913
VF Loss                      376.76495
Policy Loss                  -2650.626
Q Predictions Mean           2644.3735
Q Predictions Std            443.02905
Q Predictions Max            2836.9827
Q Predictions Min            24.752338
V Predictions Mean           2643.8298
V Predictions Std            440.1901
V Predictions Max            2841.8274
V Predictions Min            33.904667
Log Pis Mean                 -4.8188863
Log Pis Std                  5.4221253
Log Pis Max                  26.742794
Log Pis Min                  -13.354433
Policy mu Mean               0.31484497
Policy mu Std                0.6775159
Policy mu Max                2.6291916
Policy mu Min                -2.577015
Policy log std Mean          -0.29967952
Policy log std Std           0.13553807
Policy log std Max           0.0114172995
Policy log std Min           -1.0742859
Z mean eval                  0.044640552
Z variance eval              0.03685508
total_rewards                [1464.38303757 3997.48851565 5490.1058115  3543.1936844  2210.66028473
 1770.65023548 4673.42173481 5389.67142401 3126.74118671 1201.25390011]
total_rewards_mean           3286.75698149702
total_rewards_std            1514.0433338648215
total_rewards_max            5490.1058115010965
total_rewards_min            1201.2539001105945
Number of train steps total  414000
Number of env steps total    2072000
Number of rollouts total     0
Train Time (s)               29.32990616513416
(Previous) Eval Time (s)     19.148593062069267
Sample Time (s)              19.72104914067313
Epoch Time (s)               68.19954836787656
Total Train Time (s)         25932.761474934407
Epoch                        413
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:27:55.685404 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #413 | Epoch Duration: 66.87951302528381
2020-01-11 01:27:55.685690 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #413 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04435967
Z variance train             0.036858737
KL Divergence                5.8582907
KL Loss                      0.5858291
QF Loss                      1227.6819
VF Loss                      354.61594
Policy Loss                  -2648.9448
Q Predictions Mean           2650.6345
Q Predictions Std            464.39816
Q Predictions Max            2848.3777
Q Predictions Min            21.517385
V Predictions Mean           2653.3633
V Predictions Std            463.85165
V Predictions Max            2864.517
V Predictions Min            31.795881
Log Pis Mean                 -5.125896
Log Pis Std                  5.0090957
Log Pis Max                  20.40056
Log Pis Min                  -15.149467
Policy mu Mean               0.33113497
Policy mu Std                0.6711197
Policy mu Max                2.898416
Policy mu Min                -2.548377
Policy log std Mean          -0.28866163
Policy log std Std           0.12781
Policy log std Max           -0.06626762
Policy log std Min           -0.9434105
Z mean eval                  0.04632144
Z variance eval              0.03683153
total_rewards                [1633.17703173 5262.48223292 3319.97714976 5259.39350462 1771.9173403
 5410.72666528 5374.39565786 1169.57944616 5271.35591375 4958.35491218]
total_rewards_mean           3943.135985455883
total_rewards_std            1691.1953246756905
total_rewards_max            5410.726665280402
total_rewards_min            1169.5794461593189
Number of train steps total  415000
Number of env steps total    2077000
Number of rollouts total     0
Train Time (s)               31.315489168278873
(Previous) Eval Time (s)     17.828111551702023
Sample Time (s)              19.722994942218065
Epoch Time (s)               68.86659566219896
Total Train Time (s)         26005.57784653455
Epoch                        414
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:29:08.503519 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #414 | Epoch Duration: 72.81764268875122
2020-01-11 01:29:08.503671 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #414 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046610374
Z variance train             0.03682726
KL Divergence                5.8610797
KL Loss                      0.58610797
QF Loss                      1685.1583
VF Loss                      732.37915
Policy Loss                  -2645.1165
Q Predictions Mean           2641.3076
Q Predictions Std            452.11926
Q Predictions Max            2860.2556
Q Predictions Min            25.72887
V Predictions Mean           2636.771
V Predictions Std            456.31522
V Predictions Max            2870.7202
V Predictions Min            33.204533
Log Pis Mean                 -4.305208
Log Pis Std                  5.5966334
Log Pis Max                  29.47888
Log Pis Min                  -15.907612
Policy mu Mean               0.31938013
Policy mu Std                0.71328866
Policy mu Max                2.993977
Policy mu Min                -2.660296
Policy log std Mean          -0.30804235
Policy log std Std           0.13538107
Policy log std Max           -0.038091704
Policy log std Min           -1.1449295
Z mean eval                  0.04213415
Z variance eval              0.037404217
total_rewards                [5607.68122138 5362.72556873 5576.93964597 1799.86626364 1727.63068395
 5354.35880213 1376.33019503 4287.42590133 5512.28372761 5399.40417959]
total_rewards_mean           4200.464618935457
total_rewards_std            1719.7868313837118
total_rewards_max            5607.681221375059
total_rewards_min            1376.3301950316948
Number of train steps total  416000
Number of env steps total    2082000
Number of rollouts total     0
Train Time (s)               30.95749858999625
(Previous) Eval Time (s)     21.77885932987556
Sample Time (s)              19.720760255586356
Epoch Time (s)               72.45711817545816
Total Train Time (s)         26079.697750936262
Epoch                        415
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:30:22.628717 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #415 | Epoch Duration: 74.12489724159241
2020-01-11 01:30:22.628962 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #415 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04185976
Z variance train             0.03741204
KL Divergence                5.8356094
KL Loss                      0.58356094
QF Loss                      1551.9922
VF Loss                      283.51535
Policy Loss                  -2656.0325
Q Predictions Mean           2654.5693
Q Predictions Std            436.37296
Q Predictions Max            2849.098
Q Predictions Min            23.21966
V Predictions Mean           2662.2126
V Predictions Std            438.45044
V Predictions Max            2855.2014
V Predictions Min            33.650085
Log Pis Mean                 -4.2527733
Log Pis Std                  4.4491935
Log Pis Max                  19.099234
Log Pis Min                  -16.272537
Policy mu Mean               0.37547916
Policy mu Std                0.6733264
Policy mu Max                2.5670857
Policy mu Min                -2.497017
Policy log std Mean          -0.3024955
Policy log std Std           0.13730203
Policy log std Max           -0.07227364
Policy log std Min           -1.0328579
Z mean eval                  0.04309278
Z variance eval              0.03854982
total_rewards                [5510.43692106 1289.80219067 3550.76216591 5357.62343184 5340.42313126
 3696.05742986 5423.35837688 5511.93691963 5099.86762559 5165.54638548]
total_rewards_mean           4594.581457818032
total_rewards_std            1300.2115796258752
total_rewards_max            5511.93691963498
total_rewards_min            1289.8021906651495
Number of train steps total  417000
Number of env steps total    2087000
Number of rollouts total     0
Train Time (s)               30.569871336221695
(Previous) Eval Time (s)     23.446299664210528
Sample Time (s)              19.771830946672708
Epoch Time (s)               73.78800194710493
Total Train Time (s)         26155.335411598906
Epoch                        416
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:31:38.274210 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #416 | Epoch Duration: 75.64504218101501
2020-01-11 01:31:38.274522 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #416 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043460023
Z variance train             0.038552366
KL Divergence                5.761429
KL Loss                      0.5761429
QF Loss                      1151.99
VF Loss                      335.88037
Policy Loss                  -2669.8342
Q Predictions Mean           2669.1326
Q Predictions Std            418.1574
Q Predictions Max            2854.8374
Q Predictions Min            25.791267
V Predictions Mean           2665.3467
V Predictions Std            417.849
V Predictions Max            2867.1208
V Predictions Min            35.788475
Log Pis Mean                 -4.227111
Log Pis Std                  4.923641
Log Pis Max                  16.79394
Log Pis Min                  -19.7886
Policy mu Mean               0.3150592
Policy mu Std                0.6980036
Policy mu Max                2.9311209
Policy mu Min                -3.128408
Policy log std Mean          -0.3070123
Policy log std Std           0.1344693
Policy log std Max           -0.08751166
Policy log std Min           -1.0195792
Z mean eval                  0.043197043
Z variance eval              0.04050981
total_rewards                [5533.99498787 5523.47213409 5148.0428311  5438.11572523 5406.98777122
 5483.63137768 5451.85115089  651.72480706 5511.28636413  732.04168116]
total_rewards_mean           4488.11488304203
total_rewards_std            1901.0749325094068
total_rewards_max            5533.994987871199
total_rewards_min            651.7248070588024
Number of train steps total  418000
Number of env steps total    2092000
Number of rollouts total     0
Train Time (s)               32.612098078243434
(Previous) Eval Time (s)     25.30298599600792
Sample Time (s)              19.15527566196397
Epoch Time (s)               77.07035973621532
Total Train Time (s)         26231.451890353113
Epoch                        417
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:32:54.395846 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #417 | Epoch Duration: 76.12112522125244
2020-01-11 01:32:54.396011 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #417 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04335863
Z variance train             0.040507153
KL Divergence                5.6602216
KL Loss                      0.56602216
QF Loss                      1356.1985
VF Loss                      645.4804
Policy Loss                  -2609.1938
Q Predictions Mean           2605.5837
Q Predictions Std            545.45654
Q Predictions Max            2844.337
Q Predictions Min            27.411072
V Predictions Mean           2600.0518
V Predictions Std            547.9676
V Predictions Max            2853.4414
V Predictions Min            38.293118
Log Pis Mean                 -4.6939187
Log Pis Std                  4.6708994
Log Pis Max                  24.487328
Log Pis Min                  -15.119491
Policy mu Mean               0.3430094
Policy mu Std                0.6737886
Policy mu Max                2.616308
Policy mu Min                -2.9416065
Policy log std Mean          -0.28723377
Policy log std Std           0.12939078
Policy log std Max           -0.01877734
Policy log std Min           -1.0717477
Z mean eval                  0.042909823
Z variance eval              0.040111132
total_rewards                [5681.33322096 5428.28394738 2218.64607378 4822.05759658 5437.55099402
  676.92665969 4126.30768236 2267.46233858 5551.94647627 5215.5500467 ]
total_rewards_mean           4142.606503631234
total_rewards_std            1688.9529369887362
total_rewards_max            5681.333220957583
total_rewards_min            676.9266596854077
Number of train steps total  419000
Number of env steps total    2097000
Number of rollouts total     0
Train Time (s)               31.590235503856093
(Previous) Eval Time (s)     24.353438074700534
Sample Time (s)              19.79757041623816
Epoch Time (s)               75.74124399479479
Total Train Time (s)         26305.467988678254
Epoch                        418
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:34:08.416387 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #418 | Epoch Duration: 74.02024626731873
2020-01-11 01:34:08.416594 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #418 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043053277
Z variance train             0.040115338
KL Divergence                5.679472
KL Loss                      0.5679472
QF Loss                      1181.6809
VF Loss                      403.7344
Policy Loss                  -2693.6003
Q Predictions Mean           2695.5566
Q Predictions Std            323.52414
Q Predictions Max            2855.7737
Q Predictions Min            290.59064
V Predictions Mean           2688.5068
V Predictions Std            323.14438
V Predictions Max            2855.0442
V Predictions Min            291.497
Log Pis Mean                 -5.0006475
Log Pis Std                  4.4565406
Log Pis Max                  15.617477
Log Pis Min                  -14.843012
Policy mu Mean               0.31175354
Policy mu Std                0.6762491
Policy mu Max                2.5443163
Policy mu Min                -2.5507705
Policy log std Mean          -0.29425022
Policy log std Std           0.12940598
Policy log std Max           -0.073836036
Policy log std Min           -1.0555611
Z mean eval                  0.043531403
Z variance eval              0.041401893
total_rewards                [5432.66444807 5469.14169173 2685.20167126 1355.64548115 5212.82589888
 2622.93551242 5432.80882609  549.75367559 5564.46204289 5567.77900102]
total_rewards_mean           3989.3218249109727
total_rewards_std            1875.1249701918289
total_rewards_max            5567.7790010178915
total_rewards_min            549.7536755945221
Number of train steps total  420000
Number of env steps total    2102000
Number of rollouts total     0
Train Time (s)               30.950405173934996
(Previous) Eval Time (s)     22.63210081588477
Sample Time (s)              19.101515369024128
Epoch Time (s)               72.68402135884389
Total Train Time (s)         26377.363594224676
Epoch                        419
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:35:20.316095 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #419 | Epoch Duration: 71.89935278892517
2020-01-11 01:35:20.316300 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #419 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043430917
Z variance train             0.04139094
KL Divergence                5.6135054
KL Loss                      0.5613505
QF Loss                      1758.8054
VF Loss                      557.9828
Policy Loss                  -2707.2605
Q Predictions Mean           2704.2139
Q Predictions Std            245.44081
Q Predictions Max            2869.2363
Q Predictions Min            515.84375
V Predictions Mean           2700.7588
V Predictions Std            246.17903
V Predictions Max            2865.6035
V Predictions Min            525.7895
Log Pis Mean                 -4.212721
Log Pis Std                  5.512172
Log Pis Max                  19.003714
Log Pis Min                  -13.23705
Policy mu Mean               0.28490874
Policy mu Std                0.71651024
Policy mu Max                2.962205
Policy mu Min                -2.7097764
Policy log std Mean          -0.29856515
Policy log std Std           0.13922241
Policy log std Max           -0.07429921
Policy log std Min           -1.406203
Z mean eval                  0.043592155
Z variance eval              0.039877586
total_rewards                [4527.22943576 2549.68059859 5513.87534695 5525.55218999 2705.96169399
 5489.27885633 5315.44509634 3443.54969774 5300.33758166 1387.85174005]
total_rewards_mean           4175.876223740445
total_rewards_std            1453.8884613937375
total_rewards_max            5525.5521899934
total_rewards_min            1387.8517400455307
Number of train steps total  421000
Number of env steps total    2107000
Number of rollouts total     0
Train Time (s)               31.74677978316322
(Previous) Eval Time (s)     21.847139528021216
Sample Time (s)              18.865784518420696
Epoch Time (s)               72.45970382960513
Total Train Time (s)         26451.327056468
Epoch                        420
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:36:34.286597 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #420 | Epoch Duration: 73.97012233734131
2020-01-11 01:36:34.286902 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #420 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043540873
Z variance train             0.039891966
KL Divergence                5.697623
KL Loss                      0.5697623
QF Loss                      1250.5916
VF Loss                      270.58368
Policy Loss                  -2687.8103
Q Predictions Mean           2688.7922
Q Predictions Std            387.30533
Q Predictions Max            2862.1235
Q Predictions Min            35.5024
V Predictions Mean           2688.5635
V Predictions Std            385.91934
V Predictions Max            2869.3516
V Predictions Min            36.680878
Log Pis Mean                 -4.6692176
Log Pis Std                  4.4966125
Log Pis Max                  15.08288
Log Pis Min                  -13.433646
Policy mu Mean               0.31919932
Policy mu Std                0.68436104
Policy mu Max                2.5184917
Policy mu Min                -2.4847474
Policy log std Mean          -0.29189333
Policy log std Std           0.1282337
Policy log std Max           -0.06677063
Policy log std Min           -1.2591367
Z mean eval                  0.046723317
Z variance eval              0.04183986
total_rewards                [2171.52830997 4849.42849446 5142.09725285 5486.86825656 5547.59686962
 1589.97235428 5452.62851501 5463.62059372 1574.35574428 1457.21850608]
total_rewards_mean           3873.5314896827185
total_rewards_std            1795.1364835265524
total_rewards_max            5547.596869620837
total_rewards_min            1457.218506083995
Number of train steps total  422000
Number of env steps total    2112000
Number of rollouts total     0
Train Time (s)               30.391362885944545
(Previous) Eval Time (s)     23.357230693101883
Sample Time (s)              19.12789043271914
Epoch Time (s)               72.87648401176557
Total Train Time (s)         26522.061935325153
Epoch                        421
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:37:45.023697 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #421 | Epoch Duration: 70.73658776283264
2020-01-11 01:37:45.023881 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #421 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04682776
Z variance train             0.041852057
KL Divergence                5.5826263
KL Loss                      0.55826265
QF Loss                      1481.232
VF Loss                      605.0339
Policy Loss                  -2658.297
Q Predictions Mean           2653.583
Q Predictions Std            433.84396
Q Predictions Max            2869.1267
Q Predictions Min            24.15924
V Predictions Mean           2646.106
V Predictions Std            433.64133
V Predictions Max            2871.814
V Predictions Min            31.871462
Log Pis Mean                 -4.6871576
Log Pis Std                  5.280843
Log Pis Max                  21.417965
Log Pis Min                  -13.631061
Policy mu Mean               0.32920286
Policy mu Std                0.67943776
Policy mu Max                3.17503
Policy mu Min                -2.5303824
Policy log std Mean          -0.29029083
Policy log std Std           0.13234203
Policy log std Max           -0.037860125
Policy log std Min           -1.0036993
Z mean eval                  0.04372992
Z variance eval              0.041089624
total_rewards                [5504.13871677 2037.59949137 3989.1409012  5576.12208957 5403.53019362
 1820.2636686  3993.48081464 5228.95956909 4847.56688518 1219.33754464]
total_rewards_mean           3962.013987469733
total_rewards_std            1589.505688632431
total_rewards_max            5576.122089571349
total_rewards_min            1219.3375446410632
Number of train steps total  423000
Number of env steps total    2117000
Number of rollouts total     0
Train Time (s)               32.31311529641971
(Previous) Eval Time (s)     21.217063821852207
Sample Time (s)              19.234849297441542
Epoch Time (s)               72.76502841571346
Total Train Time (s)         26595.24172357237
Epoch                        422
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:38:58.212306 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #422 | Epoch Duration: 73.18824934959412
2020-01-11 01:38:58.212637 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #422 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043809306
Z variance train             0.04109578
KL Divergence                5.646761
KL Loss                      0.5646761
QF Loss                      2471.8916
VF Loss                      911.655
Policy Loss                  -2655.614
Q Predictions Mean           2655.9404
Q Predictions Std            401.57925
Q Predictions Max            2854.9753
Q Predictions Min            24.561996
V Predictions Mean           2661.4045
V Predictions Std            407.77753
V Predictions Max            2870.6614
V Predictions Min            33.651333
Log Pis Mean                 -4.1023135
Log Pis Std                  5.898494
Log Pis Max                  27.13126
Log Pis Min                  -17.179611
Policy mu Mean               0.3090695
Policy mu Std                0.70621985
Policy mu Max                2.7770646
Policy mu Min                -3.5586193
Policy log std Mean          -0.30422187
Policy log std Std           0.14259496
Policy log std Max           -0.065792456
Policy log std Min           -1.1821916
Z mean eval                  0.044340197
Z variance eval              0.040419523
total_rewards                [5609.37309662 5555.99617899 1738.20966321 4192.94485849 2374.52038071
 5411.88158718 5533.85217535 3073.24473242 5574.58332024 4447.26585908]
total_rewards_mean           4351.187185228306
total_rewards_std            1394.8955351683742
total_rewards_max            5609.373096623866
total_rewards_min            1738.2096632078697
Number of train steps total  424000
Number of env steps total    2122000
Number of rollouts total     0
Train Time (s)               33.01512590330094
(Previous) Eval Time (s)     21.639954532962292
Sample Time (s)              19.60822468297556
Epoch Time (s)               74.2633051192388
Total Train Time (s)         26670.74270252837
Epoch                        423
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:40:13.718304 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #423 | Epoch Duration: 75.5053915977478
2020-01-11 01:40:13.718605 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #423 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04417568
Z variance train             0.04042158
KL Divergence                5.6904645
KL Loss                      0.56904644
QF Loss                      1408.1282
VF Loss                      495.43622
Policy Loss                  -2639.638
Q Predictions Mean           2639.2686
Q Predictions Std            462.1458
Q Predictions Max            2868.8066
Q Predictions Min            16.838217
V Predictions Mean           2645.211
V Predictions Std            459.75854
V Predictions Max            2869.3743
V Predictions Min            20.599285
Log Pis Mean                 -4.4039454
Log Pis Std                  5.042459
Log Pis Max                  23.864937
Log Pis Min                  -14.70997
Policy mu Mean               0.3526725
Policy mu Std                0.69065624
Policy mu Max                3.4532192
Policy mu Min                -2.8615808
Policy log std Mean          -0.3064436
Policy log std Std           0.13318017
Policy log std Max           -0.035809547
Policy log std Min           -1.0841382
Z mean eval                  0.045857932
Z variance eval              0.041038856
total_rewards                [5424.61233571 3323.39453679 5404.5297809  5509.01378874 4350.97286859
 2390.07657846 5493.40200848 2609.32051527 5416.34062825 1713.14966547]
total_rewards_mean           4163.481270665334
total_rewards_std            1434.7424896120815
total_rewards_max            5509.013788737969
total_rewards_min            1713.149665472454
Number of train steps total  425000
Number of env steps total    2127000
Number of rollouts total     0
Train Time (s)               30.94472621427849
(Previous) Eval Time (s)     22.881729411892593
Sample Time (s)              20.308580214623362
Epoch Time (s)               74.13503584079444
Total Train Time (s)         26744.5225258898
Epoch                        424
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:41:27.503907 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #424 | Epoch Duration: 73.78501415252686
2020-01-11 01:41:27.504193 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #424 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046041176
Z variance train             0.04103599
KL Divergence                5.643731
KL Loss                      0.56437314
QF Loss                      1454.9105
VF Loss                      366.46912
Policy Loss                  -2688.4534
Q Predictions Mean           2686.1353
Q Predictions Std            418.3432
Q Predictions Max            2874.456
Q Predictions Min            22.909826
V Predictions Mean           2687.9648
V Predictions Std            422.65372
V Predictions Max            2879.2695
V Predictions Min            30.205835
Log Pis Mean                 -5.3970485
Log Pis Std                  4.4148784
Log Pis Max                  16.648287
Log Pis Min                  -15.41066
Policy mu Mean               0.2775446
Policy mu Std                0.6738796
Policy mu Max                2.5412974
Policy mu Min                -2.8529747
Policy log std Mean          -0.29346967
Policy log std Std           0.1342673
Policy log std Max           0.00245744
Policy log std Min           -1.2291335
Z mean eval                  0.046485383
Z variance eval              0.039279543
total_rewards                [5418.4459166  3758.88704206 5362.29722646 5418.62459849 1995.57365599
  864.21208917 5249.34208383 5226.19459083 5405.78491565 3303.72166399]
total_rewards_mean           4200.308378307542
total_rewards_std            1578.4034229189456
total_rewards_max            5418.624598492829
total_rewards_min            864.2120891708834
Number of train steps total  426000
Number of env steps total    2132000
Number of rollouts total     0
Train Time (s)               31.853353136219084
(Previous) Eval Time (s)     22.531362389679998
Sample Time (s)              19.163989991880953
Epoch Time (s)               73.54870551778004
Total Train Time (s)         26818.215646188706
Epoch                        425
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:42:41.203738 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #425 | Epoch Duration: 73.6992928981781
2020-01-11 01:42:41.204112 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #425 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04649927
Z variance train             0.039285142
KL Divergence                5.7313604
KL Loss                      0.57313603
QF Loss                      1359.0673
VF Loss                      788.6483
Policy Loss                  -2699.2642
Q Predictions Mean           2695.029
Q Predictions Std            308.98636
Q Predictions Max            2875.9822
Q Predictions Min            310.0366
V Predictions Mean           2718.453
V Predictions Std            315.30084
V Predictions Max            2902.7996
V Predictions Min            333.59552
Log Pis Mean                 -4.81444
Log Pis Std                  4.737952
Log Pis Max                  19.676025
Log Pis Min                  -14.172894
Policy mu Mean               0.27403182
Policy mu Std                0.70631737
Policy mu Max                2.5816326
Policy mu Min                -3.0730171
Policy log std Mean          -0.29782936
Policy log std Std           0.1336998
Policy log std Max           -0.0730382
Policy log std Min           -1.1530995
Z mean eval                  0.045337737
Z variance eval              0.040182587
total_rewards                [1019.81759502 1835.33387547 5461.57543232 5537.14120918 4234.80982593
 5451.05232047 1963.61578635  899.51602228 5366.67819936 3031.83514431]
total_rewards_mean           3480.1375410695437
total_rewards_std            1846.3316391737199
total_rewards_max            5537.141209180795
total_rewards_min            899.51602227748
Number of train steps total  427000
Number of env steps total    2137000
Number of rollouts total     0
Train Time (s)               32.98511708108708
(Previous) Eval Time (s)     22.68159282533452
Sample Time (s)              19.623905597254634
Epoch Time (s)               75.29061550367624
Total Train Time (s)         26889.17472037999
Epoch                        426
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:43:52.167734 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #426 | Epoch Duration: 70.96336722373962
2020-01-11 01:43:52.168051 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #426 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04577478
Z variance train             0.04017601
KL Divergence                5.681967
KL Loss                      0.5681967
QF Loss                      1756.1028
VF Loss                      759.3158
Policy Loss                  -2679.2693
Q Predictions Mean           2675.9478
Q Predictions Std            431.58984
Q Predictions Max            2891.5574
Q Predictions Min            27.449764
V Predictions Mean           2661.6309
V Predictions Std            424.85764
V Predictions Max            2883.2795
V Predictions Min            37.848827
Log Pis Mean                 -4.5516515
Log Pis Std                  5.600805
Log Pis Max                  31.610743
Log Pis Min                  -14.561569
Policy mu Mean               0.29781732
Policy mu Std                0.7009593
Policy mu Max                2.9026644
Policy mu Min                -3.6644204
Policy log std Mean          -0.29189622
Policy log std Std           0.13363437
Policy log std Max           0.016407795
Policy log std Min           -1.3800135
Z mean eval                  0.045764506
Z variance eval              0.037477795
total_rewards                [5046.17161116 5384.7698863  5277.51695078 1630.67407613 4092.47959155
 5419.31238297 5470.49903449 5512.5394309  5477.36983507 5270.27715684]
total_rewards_mean           4858.160995618206
total_rewards_std            1147.2917400379179
total_rewards_max            5512.539430899369
total_rewards_min            1630.6740761267017
Number of train steps total  428000
Number of env steps total    2142000
Number of rollouts total     0
Train Time (s)               33.3280812590383
(Previous) Eval Time (s)     18.354033433366567
Sample Time (s)              18.8635056912899
Epoch Time (s)               70.54562038369477
Total Train Time (s)         26968.60812406754
Epoch                        427
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:45:11.605788 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #427 | Epoch Duration: 79.43753361701965
2020-01-11 01:45:11.605997 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #427 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045560528
Z variance train             0.03747429
KL Divergence                5.8517733
KL Loss                      0.58517736
QF Loss                      1155.9701
VF Loss                      364.16473
Policy Loss                  -2659.181
Q Predictions Mean           2659.602
Q Predictions Std            432.7617
Q Predictions Max            2866.3386
Q Predictions Min            22.458223
V Predictions Mean           2662.9126
V Predictions Std            427.38205
V Predictions Max            2864.7327
V Predictions Min            30.473547
Log Pis Mean                 -4.0377064
Log Pis Std                  5.9554935
Log Pis Max                  38.91307
Log Pis Min                  -17.072983
Policy mu Mean               0.32323456
Policy mu Std                0.7299836
Policy mu Max                2.8238642
Policy mu Min                -3.1476083
Policy log std Mean          -0.3074595
Policy log std Std           0.13936253
Policy log std Max           -0.07890993
Policy log std Min           -1.0916457
Z mean eval                  0.04259661
Z variance eval              0.03706137
total_rewards                [5430.58168256 2733.22754768 4574.20195707 5429.07600402 4235.38735238
 5647.53806124 5306.99561075 5646.63292442 2298.70268428 5133.01688008]
total_rewards_mean           4643.536070447503
total_rewards_std            1151.0613345844786
total_rewards_max            5647.538061238707
total_rewards_min            2298.7026842797177
Number of train steps total  429000
Number of env steps total    2147000
Number of rollouts total     0
Train Time (s)               30.20048509677872
(Previous) Eval Time (s)     27.24560977704823
Sample Time (s)              19.542859853245318
Epoch Time (s)               76.98895472707227
Total Train Time (s)         27043.36866502557
Epoch                        428
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:46:26.368803 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #428 | Epoch Duration: 74.76266551017761
2020-01-11 01:46:26.368957 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #428 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.042976327
Z variance train             0.03706784
KL Divergence                5.8831997
KL Loss                      0.58831996
QF Loss                      1230.6348
VF Loss                      366.2374
Policy Loss                  -2677.2021
Q Predictions Mean           2673.0117
Q Predictions Std            419.45813
Q Predictions Max            2865.7576
Q Predictions Min            15.496827
V Predictions Mean           2670.6313
V Predictions Std            423.24686
V Predictions Max            2879.6392
V Predictions Min            24.609926
Log Pis Mean                 -3.9495916
Log Pis Std                  5.1689825
Log Pis Max                  28.528822
Log Pis Min                  -13.228877
Policy mu Mean               0.34620574
Policy mu Std                0.7192203
Policy mu Max                2.624022
Policy mu Min                -3.127211
Policy log std Mean          -0.30763602
Policy log std Std           0.13438426
Policy log std Max           -0.03511651
Policy log std Min           -0.92029923
Z mean eval                  0.043967884
Z variance eval              0.038746566
total_rewards                [5264.53542779 5229.56373089 2968.16992388 2064.86265745 3767.61135686
 2464.46926746 2661.23983784  951.88375908 4296.57561443  865.36867294]
total_rewards_mean           3053.4280248616187
total_rewards_std            1495.63841784881
total_rewards_max            5264.5354277862825
total_rewards_min            865.3686729380877
Number of train steps total  430000
Number of env steps total    2152000
Number of rollouts total     0
Train Time (s)               29.110376083292067
(Previous) Eval Time (s)     25.01902747992426
Sample Time (s)              20.073942011222243
Epoch Time (s)               74.20334557443857
Total Train Time (s)         27108.692749896087
Epoch                        429
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:47:31.695963 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #429 | Epoch Duration: 65.32688689231873
2020-01-11 01:47:31.696135 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #429 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04385333
Z variance train             0.038749386
KL Divergence                5.7810264
KL Loss                      0.57810265
QF Loss                      1358.7168
VF Loss                      313.4115
Policy Loss                  -2680.289
Q Predictions Mean           2676.3108
Q Predictions Std            406.33792
Q Predictions Max            2856.2913
Q Predictions Min            19.90255
V Predictions Mean           2686.17
V Predictions Std            405.28687
V Predictions Max            2867.116
V Predictions Min            26.794756
Log Pis Mean                 -4.904213
Log Pis Std                  4.7972627
Log Pis Max                  20.75561
Log Pis Min                  -14.402569
Policy mu Mean               0.2924131
Policy mu Std                0.6765755
Policy mu Max                2.563503
Policy mu Min                -2.690346
Policy log std Mean          -0.28643227
Policy log std Std           0.12695082
Policy log std Max           -0.059175216
Policy log std Min           -1.0856805
Z mean eval                  0.045027632
Z variance eval              0.037988454
total_rewards                [3273.80031447 1741.15468594 2246.0003972  5656.57750746 5494.19695537
 5515.53781529 3891.73175268 5427.79083762 5565.18267937 1078.97107126]
total_rewards_mean           3989.0944016655035
total_rewards_std            1703.270893982564
total_rewards_max            5656.577507458232
total_rewards_min            1078.9710712607505
Number of train steps total  431000
Number of env steps total    2157000
Number of rollouts total     0
Train Time (s)               32.47724931174889
(Previous) Eval Time (s)     16.142258980777115
Sample Time (s)              19.362964790314436
Epoch Time (s)               67.98247308284044
Total Train Time (s)         27181.952495981008
Epoch                        430
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:48:44.958571 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #430 | Epoch Duration: 73.26230335235596
2020-01-11 01:48:44.958770 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #430 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04477916
Z variance train             0.038008187
KL Divergence                5.8250513
KL Loss                      0.58250517
QF Loss                      1684.2582
VF Loss                      601.4925
Policy Loss                  -2685.3958
Q Predictions Mean           2689.8484
Q Predictions Std            407.2555
Q Predictions Max            2864.4775
Q Predictions Min            16.098598
V Predictions Mean           2703.7366
V Predictions Std            407.22968
V Predictions Max            2896.8481
V Predictions Min            27.222858
Log Pis Mean                 -4.6918516
Log Pis Std                  4.857489
Log Pis Max                  16.356607
Log Pis Min                  -14.671423
Policy mu Mean               0.3479942
Policy mu Std                0.6618257
Policy mu Max                2.775735
Policy mu Min                -2.8038392
Policy log std Mean          -0.28919202
Policy log std Std           0.12949288
Policy log std Max           0.02774027
Policy log std Min           -1.04115
Z mean eval                  0.043659173
Z variance eval              0.037959762
total_rewards                [1656.67563208 4277.05827578 1568.64498049 4095.3671754  1610.79222725
 2630.81416936 3972.2755813  5588.4635351  3568.58607207  834.51526535]
total_rewards_mean           2980.3192914177275
total_rewards_std            1463.0244456057126
total_rewards_max            5588.463535095467
total_rewards_min            834.5152653529117
Number of train steps total  432000
Number of env steps total    2162000
Number of rollouts total     0
Train Time (s)               30.86424561869353
(Previous) Eval Time (s)     21.421785053331405
Sample Time (s)              19.264269928913563
Epoch Time (s)               71.5503006009385
Total Train Time (s)         27247.4558358714
Epoch                        431
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:49:50.467299 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #431 | Epoch Duration: 65.50837779045105
2020-01-11 01:49:50.467523 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #431 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043394197
Z variance train             0.037959635
KL Divergence                5.823798
KL Loss                      0.5823798
QF Loss                      1229.4198
VF Loss                      673.05457
Policy Loss                  -2680.053
Q Predictions Mean           2674.983
Q Predictions Std            370.28503
Q Predictions Max            2874.3367
Q Predictions Min            21.297749
V Predictions Mean           2687.3591
V Predictions Std            374.2401
V Predictions Max            2887.2087
V Predictions Min            28.193502
Log Pis Mean                 -4.1021132
Log Pis Std                  5.701672
Log Pis Max                  17.435051
Log Pis Min                  -14.124586
Policy mu Mean               0.32003716
Policy mu Std                0.71114975
Policy mu Max                2.8762941
Policy mu Min                -2.7081003
Policy log std Mean          -0.30509573
Policy log std Std           0.13457552
Policy log std Max           -0.07755613
Policy log std Min           -1.2097957
Z mean eval                  0.044548634
Z variance eval              0.03903628
total_rewards                [3638.3737544  5616.83960657 3201.06119903 5341.86293687 1574.17413454
 5488.4562797  3058.47309611 5550.15893681 5477.7486778  5581.79777723]
total_rewards_mean           4452.894639905656
total_rewards_std            1385.934049092746
total_rewards_max            5616.839606568414
total_rewards_min            1574.1741345442176
Number of train steps total  433000
Number of env steps total    2167000
Number of rollouts total     0
Train Time (s)               33.911926181055605
(Previous) Eval Time (s)     15.379545016214252
Sample Time (s)              18.93016953393817
Epoch Time (s)               68.22164073120803
Total Train Time (s)         27324.76808274025
Epoch                        432
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:51:07.786541 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #432 | Epoch Duration: 77.31881284713745
2020-01-11 01:51:07.786836 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #432 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04459287
Z variance train             0.03903547
KL Divergence                5.7440186
KL Loss                      0.57440186
QF Loss                      1155.9353
VF Loss                      366.37427
Policy Loss                  -2679.5261
Q Predictions Mean           2679.6465
Q Predictions Std            421.67056
Q Predictions Max            2855.6755
Q Predictions Min            19.95137
V Predictions Mean           2686.3833
V Predictions Std            420.7849
V Predictions Max            2875.0696
V Predictions Min            31.512115
Log Pis Mean                 -4.3156447
Log Pis Std                  5.142363
Log Pis Max                  18.350105
Log Pis Min                  -15.178669
Policy mu Mean               0.3722285
Policy mu Std                0.6720854
Policy mu Max                3.197177
Policy mu Min                -2.6809535
Policy log std Mean          -0.2983652
Policy log std Std           0.13261414
Policy log std Max           -0.014107324
Policy log std Min           -0.8818927
Z mean eval                  0.046010263
Z variance eval              0.038378056
total_rewards                [3093.58522917  876.30553924 5504.52624828 5433.65325546  944.4394663
 5332.63753508 5621.65450377 2469.16162443 2809.08323457 5360.56876759]
total_rewards_mean           3744.5615403909733
total_rewards_std            1833.0455584462009
total_rewards_max            5621.654503772775
total_rewards_min            876.3055392403114
Number of train steps total  434000
Number of env steps total    2172000
Number of rollouts total     0
Train Time (s)               31.66048562992364
(Previous) Eval Time (s)     24.47640210390091
Sample Time (s)              19.578589724376798
Epoch Time (s)               75.71547745820135
Total Train Time (s)         27396.143656700384
Epoch                        433
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:52:19.165286 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #433 | Epoch Duration: 71.37825584411621
2020-01-11 01:52:19.165458 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #433 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045920026
Z variance train             0.038390655
KL Divergence                5.776152
KL Loss                      0.5776152
QF Loss                      1897.3164
VF Loss                      557.6889
Policy Loss                  -2678.5947
Q Predictions Mean           2673.9744
Q Predictions Std            402.6046
Q Predictions Max            2867.9045
Q Predictions Min            23.873222
V Predictions Mean           2679.6396
V Predictions Std            404.1093
V Predictions Max            2871.7454
V Predictions Min            33.68164
Log Pis Mean                 -3.909542
Log Pis Std                  5.1724358
Log Pis Max                  25.937462
Log Pis Min                  -13.222872
Policy mu Mean               0.27310956
Policy mu Std                0.73168707
Policy mu Max                3.2563202
Policy mu Min                -2.9748726
Policy log std Mean          -0.3016973
Policy log std Std           0.14043829
Policy log std Max           0.12859294
Policy log std Min           -0.9776196
Z mean eval                  0.041313548
Z variance eval              0.037533253
total_rewards                [5371.87147372 1509.32980361 5325.28027467 1101.80508859 5503.10307288
 5346.8432059  1315.49911935 5438.62016583 1051.05513932 5482.66252759]
total_rewards_mean           3744.606987146433
total_rewards_std            2045.3155599860158
total_rewards_max            5503.103072884149
total_rewards_min            1051.0551393158814
Number of train steps total  435000
Number of env steps total    2177000
Number of rollouts total     0
Train Time (s)               31.737476135138422
(Previous) Eval Time (s)     20.138895095326006
Sample Time (s)              18.911423903889954
Epoch Time (s)               70.78779513435438
Total Train Time (s)         27467.240428884048
Epoch                        434
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:53:30.267023 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #434 | Epoch Duration: 71.10142302513123
2020-01-11 01:53:30.267275 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #434 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04145922
Z variance train             0.03753636
KL Divergence                5.8326354
KL Loss                      0.5832636
QF Loss                      1592.5388
VF Loss                      592.23956
Policy Loss                  -2634.9988
Q Predictions Mean           2631.857
Q Predictions Std            497.2904
Q Predictions Max            2862.3442
Q Predictions Min            20.457241
V Predictions Mean           2626.9375
V Predictions Std            496.73306
V Predictions Max            2867.091
V Predictions Min            31.971245
Log Pis Mean                 -4.0761814
Log Pis Std                  5.2719097
Log Pis Max                  20.745451
Log Pis Min                  -13.115685
Policy mu Mean               0.30942968
Policy mu Std                0.6993496
Policy mu Max                2.8474436
Policy mu Min                -3.3390534
Policy log std Mean          -0.29738927
Policy log std Std           0.13692042
Policy log std Max           -0.039104223
Policy log std Min           -1.1363055
Z mean eval                  0.039344374
Z variance eval              0.037374545
total_rewards                [5454.33525413 4093.64975109 5476.16548856 5443.58557445 5532.55024516
 5326.48253722 5515.16063251 5407.11092343 5498.99772792 5574.57512431]
total_rewards_mean           5332.261325880288
total_rewards_std            418.0768879513306
total_rewards_max            5574.575124312998
total_rewards_min            4093.6497510944864
Number of train steps total  436000
Number of env steps total    2182000
Number of rollouts total     0
Train Time (s)               34.72763691097498
(Previous) Eval Time (s)     20.45219877921045
Sample Time (s)              18.96974050393328
Epoch Time (s)               74.14957619411871
Total Train Time (s)         27550.396351195406
Epoch                        435
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:54:53.428168 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #435 | Epoch Duration: 83.16069173812866
2020-01-11 01:54:53.428406 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #435 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03922965
Z variance train             0.037377514
KL Divergence                5.8634424
KL Loss                      0.58634424
QF Loss                      1704.2687
VF Loss                      350.85086
Policy Loss                  -2659.0146
Q Predictions Mean           2659.06
Q Predictions Std            446.68658
Q Predictions Max            2881.4097
Q Predictions Min            20.261303
V Predictions Mean           2661.0933
V Predictions Std            442.1282
V Predictions Max            2867.1235
V Predictions Min            30.629456
Log Pis Mean                 -4.8004837
Log Pis Std                  5.6037006
Log Pis Max                  28.611431
Log Pis Min                  -16.389622
Policy mu Mean               0.27329153
Policy mu Std                0.7046481
Policy mu Max                2.8686292
Policy mu Min                -2.897065
Policy log std Mean          -0.30666474
Policy log std Std           0.14065772
Policy log std Max           -0.08743893
Policy log std Min           -1.1494143
Z mean eval                  0.04032287
Z variance eval              0.037714664
total_rewards                [2647.97854917 5652.86927339 2153.56481833 5598.70146585 5534.81179994
 3424.85489543 5345.14391259 5351.99653567  698.34167861 5621.00758024]
total_rewards_mean           4202.9270509212265
total_rewards_std            1731.0596001422073
total_rewards_max            5652.869273387007
total_rewards_min            698.3416786141432
Number of train steps total  437000
Number of env steps total    2187000
Number of rollouts total     0
Train Time (s)               32.54325381433591
(Previous) Eval Time (s)     29.462990314234048
Sample Time (s)              19.55294719617814
Epoch Time (s)               81.5591913247481
Total Train Time (s)         27625.143799739424
Epoch                        436
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:56:08.178241 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #436 | Epoch Duration: 74.74967169761658
2020-01-11 01:56:08.178409 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #436 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040374275
Z variance train             0.03770848
KL Divergence                5.838052
KL Loss                      0.5838052
QF Loss                      2271.6523
VF Loss                      887.8236
Policy Loss                  -2676.7598
Q Predictions Mean           2671.361
Q Predictions Std            370.86993
Q Predictions Max            2871.165
Q Predictions Min            22.76883
V Predictions Mean           2676.469
V Predictions Std            368.74295
V Predictions Max            2879.7805
V Predictions Min            31.040588
Log Pis Mean                 -4.0594053
Log Pis Std                  5.6851625
Log Pis Max                  21.02102
Log Pis Min                  -14.220173
Policy mu Mean               0.31139112
Policy mu Std                0.71434337
Policy mu Max                4.004871
Policy mu Min                -3.0108213
Policy log std Mean          -0.30914244
Policy log std Std           0.14021383
Policy log std Max           -0.0432524
Policy log std Min           -0.9519061
Z mean eval                  0.04040339
Z variance eval              0.03919982
total_rewards                [5535.79900692 4735.77033165 2867.65580696 5586.98568131 1552.57098417
 3651.34411924 1338.21902204 4837.74839823 5252.42733686 3989.01455415]
total_rewards_mean           3934.7535241534993
total_rewards_std            1487.4561320204573
total_rewards_max            5586.985681312022
total_rewards_min            1338.2190220448765
Number of train steps total  438000
Number of env steps total    2192000
Number of rollouts total     0
Train Time (s)               31.039542351849377
(Previous) Eval Time (s)     22.653153356164694
Sample Time (s)              19.22925917711109
Epoch Time (s)               72.92195488512516
Total Train Time (s)         27697.351120823994
Epoch                        437
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:57:20.389370 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #437 | Epoch Duration: 72.21084237098694
2020-01-11 01:57:20.389566 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #437 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040686384
Z variance train             0.03919476
KL Divergence                5.7593865
KL Loss                      0.57593864
QF Loss                      1540.9143
VF Loss                      405.56702
Policy Loss                  -2741.5679
Q Predictions Mean           2747.1885
Q Predictions Std            278.7419
Q Predictions Max            2913.3809
Q Predictions Min            436.2447
V Predictions Mean           2747.3945
V Predictions Std            279.88968
V Predictions Max            2887.994
V Predictions Min            407.15457
Log Pis Mean                 -5.4738135
Log Pis Std                  3.8222482
Log Pis Max                  14.14314
Log Pis Min                  -15.130704
Policy mu Mean               0.35887688
Policy mu Std                0.63098365
Policy mu Max                2.4843972
Policy mu Min                -2.4286106
Policy log std Mean          -0.2912571
Policy log std Std           0.124896735
Policy log std Max           -0.06286578
Policy log std Min           -0.92073077
Z mean eval                  0.04026388
Z variance eval              0.037558008
total_rewards                [4700.02952146 5508.20580958 2643.17773878 4228.96244668 1676.84815859
 4970.38368599 5448.30835688 5335.82983191 4053.55061625 5547.15579945]
total_rewards_mean           4411.245196556349
total_rewards_std            1248.3655945896194
total_rewards_max            5547.155799446907
total_rewards_min            1676.848158588776
Number of train steps total  439000
Number of env steps total    2197000
Number of rollouts total     0
Train Time (s)               32.5209794100374
(Previous) Eval Time (s)     21.941640825010836
Sample Time (s)              20.288174519315362
Epoch Time (s)               74.7507947543636
Total Train Time (s)         27773.72728382889
Epoch                        438
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:58:36.768505 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #438 | Epoch Duration: 76.37878847122192
2020-01-11 01:58:36.768706 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #438 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04043279
Z variance train             0.03756277
KL Divergence                5.88027
KL Loss                      0.588027
QF Loss                      718.41284
VF Loss                      270.77325
Policy Loss                  -2711.4773
Q Predictions Mean           2710.945
Q Predictions Std            302.74454
Q Predictions Max            2879.298
Q Predictions Min            433.31577
V Predictions Mean           2710.8213
V Predictions Std            305.84158
V Predictions Max            2883.011
V Predictions Min            413.74512
Log Pis Mean                 -4.2639337
Log Pis Std                  4.693018
Log Pis Max                  13.195558
Log Pis Min                  -18.089134
Policy mu Mean               0.33849978
Policy mu Std                0.70655835
Policy mu Max                2.6739213
Policy mu Min                -2.4020677
Policy log std Mean          -0.3154147
Policy log std Std           0.13706343
Policy log std Max           -0.040326744
Policy log std Min           -1.1992533
Z mean eval                  0.040455204
Z variance eval              0.037773363
total_rewards                [5452.08489459 3902.89375996 5459.83847091 5399.66659624 2692.61693442
 5221.71022119 5110.84154252 5364.66301156 2487.19379219 5275.07720706]
total_rewards_mean           4636.6586430644375
total_rewards_std            1112.0853270156374
total_rewards_max            5459.838470909059
total_rewards_min            2487.193792191318
Number of train steps total  440000
Number of env steps total    2202000
Number of rollouts total     0
Train Time (s)               29.275898728054017
(Previous) Eval Time (s)     23.569327536970377
Sample Time (s)              18.846061777789146
Epoch Time (s)               71.69128804281354
Total Train Time (s)         27847.315821312368
Epoch                        439
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:59:50.363440 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #439 | Epoch Duration: 73.59456205368042
2020-01-11 01:59:50.363726 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #439 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040556468
Z variance train             0.037768424
KL Divergence                5.8676195
KL Loss                      0.58676195
QF Loss                      1213.9783
VF Loss                      437.33173
Policy Loss                  -2660.4177
Q Predictions Mean           2659.1016
Q Predictions Std            466.77188
Q Predictions Max            2883.3914
Q Predictions Min            21.176931
V Predictions Mean           2654.2825
V Predictions Std            465.01263
V Predictions Max            2873.701
V Predictions Min            31.278898
Log Pis Mean                 -3.8998182
Log Pis Std                  5.7384686
Log Pis Max                  23.74785
Log Pis Min                  -14.724319
Policy mu Mean               0.34378308
Policy mu Std                0.7117651
Policy mu Max                2.9958105
Policy mu Min                -3.0613031
Policy log std Mean          -0.30557352
Policy log std Std           0.13767037
Policy log std Max           -0.07229484
Policy log std Min           -0.9736343
Z mean eval                  0.041212253
Z variance eval              0.03801363
total_rewards                [5382.22746951  676.8071744  4468.06633122 5450.00900335 3296.99160138
 5416.65909416 5483.92181899 2795.1412802  5455.32604224 5539.83950188]
total_rewards_mean           4396.49893173326
total_rewards_std            1560.371538546804
total_rewards_max            5539.83950187888
total_rewards_min            676.807174400025
Number of train steps total  441000
Number of env steps total    2207000
Number of rollouts total     0
Train Time (s)               32.67906639305875
(Previous) Eval Time (s)     25.47228936292231
Sample Time (s)              19.41588995512575
Epoch Time (s)               77.5672457111068
Total Train Time (s)         27923.705667139962
Epoch                        440
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:01:06.756385 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #440 | Epoch Duration: 76.39245653152466
2020-01-11 02:01:06.756573 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #440 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.041116357
Z variance train             0.03801609
KL Divergence                5.869359
KL Loss                      0.58693594
QF Loss                      1054.1354
VF Loss                      902.0743
Policy Loss                  -2703.84
Q Predictions Mean           2698.0234
Q Predictions Std            398.92917
Q Predictions Max            2868.008
Q Predictions Min            24.789547
V Predictions Mean           2702.3198
V Predictions Std            392.3654
V Predictions Max            2877.986
V Predictions Min            34.397903
Log Pis Mean                 -5.0446615
Log Pis Std                  5.084833
Log Pis Max                  23.798498
Log Pis Min                  -13.248677
Policy mu Mean               0.32703218
Policy mu Std                0.6548541
Policy mu Max                2.725773
Policy mu Min                -2.9639003
Policy log std Mean          -0.29386437
Policy log std Std           0.12366625
Policy log std Max           0.018322356
Policy log std Min           -0.950799
Z mean eval                  0.040819444
Z variance eval              0.036728837
total_rewards                [5462.9186558  5313.95153465 1351.87487048 5498.87088585 5422.25629468
 5503.33544066 5134.82709249 5639.83712971 5434.09688945 5542.82504614]
total_rewards_mean           5030.479383992072
total_rewards_std            1233.0277540539957
total_rewards_max            5639.837129709851
total_rewards_min            1351.8748704826241
Number of train steps total  442000
Number of env steps total    2212000
Number of rollouts total     0
Train Time (s)               30.52558677876368
(Previous) Eval Time (s)     24.297194506041706
Sample Time (s)              20.88728430774063
Epoch Time (s)               75.71006559254602
Total Train Time (s)         28002.244176926557
Epoch                        441
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:02:25.299430 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #441 | Epoch Duration: 78.54272794723511
2020-01-11 02:02:25.299620 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #441 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040936034
Z variance train             0.03674233
KL Divergence                5.94108
KL Loss                      0.59410805
QF Loss                      3690.9136
VF Loss                      724.69507
Policy Loss                  -2636.2292
Q Predictions Mean           2633.5024
Q Predictions Std            538.40753
Q Predictions Max            2888.0493
Q Predictions Min            21.80093
V Predictions Mean           2637.9624
V Predictions Std            543.9059
V Predictions Max            2898.3127
V Predictions Min            30.099163
Log Pis Mean                 -4.024988
Log Pis Std                  5.3969755
Log Pis Max                  17.941956
Log Pis Min                  -14.2012415
Policy mu Mean               0.35905182
Policy mu Std                0.699
Policy mu Max                2.614656
Policy mu Min                -3.168426
Policy log std Mean          -0.29467222
Policy log std Std           0.13821152
Policy log std Max           0.033678025
Policy log std Min           -1.2154826
Z mean eval                  0.041261144
Z variance eval              0.036923233
total_rewards                [1867.20714214 1971.91528305 5670.62986716 5036.61685815 2870.13898256
 5672.81268505 3687.57358856 5622.26183024 5691.20468168 5591.85230426]
total_rewards_mean           4368.221322285361
total_rewards_std            1528.7263056463808
total_rewards_max            5691.204681677811
total_rewards_min            1867.2071421420417
Number of train steps total  443000
Number of env steps total    2217000
Number of rollouts total     0
Train Time (s)               32.67703753570095
(Previous) Eval Time (s)     27.12950651999563
Sample Time (s)              19.01129008922726
Epoch Time (s)               78.81783414492384
Total Train Time (s)         28076.768991210498
Epoch                        442
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:03:39.827613 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #442 | Epoch Duration: 74.52784895896912
2020-01-11 02:03:39.827810 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #442 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04092248
Z variance train             0.03692283
KL Divergence                5.9211645
KL Loss                      0.5921165
QF Loss                      1404.3801
VF Loss                      407.41943
Policy Loss                  -2677.4265
Q Predictions Mean           2676.5098
Q Predictions Std            425.31543
Q Predictions Max            2876.7188
Q Predictions Min            22.898026
V Predictions Mean           2688.4795
V Predictions Std            427.33344
V Predictions Max            2894.6484
V Predictions Min            30.916227
Log Pis Mean                 -4.580988
Log Pis Std                  5.1434374
Log Pis Max                  20.686726
Log Pis Min                  -14.460699
Policy mu Mean               0.34683913
Policy mu Std                0.6758745
Policy mu Max                2.8105524
Policy mu Min                -3.025548
Policy log std Mean          -0.291291
Policy log std Std           0.12513481
Policy log std Max           -0.021927252
Policy log std Min           -1.138897
Z mean eval                  0.039096616
Z variance eval              0.037220754
total_rewards                [5258.65338523 4621.65073336 5319.05374195 4103.97248161 3682.57745672
 2298.08391612  670.21242317 5434.39102615 3135.17070997 5541.72487628]
total_rewards_mean           4006.5490750569325
total_rewards_std            1516.1802587747102
total_rewards_max            5541.724876281853
total_rewards_min            670.2124231671896
Number of train steps total  444000
Number of env steps total    2222000
Number of rollouts total     0
Train Time (s)               32.12047502072528
(Previous) Eval Time (s)     22.83920949837193
Sample Time (s)              19.17014964716509
Epoch Time (s)               74.1298341662623
Total Train Time (s)         28150.617846725043
Epoch                        443
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:04:53.684948 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #443 | Epoch Duration: 73.85696220397949
2020-01-11 02:04:53.685272 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #443 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039202
Z variance train             0.03722503
KL Divergence                5.8806686
KL Loss                      0.5880669
QF Loss                      2094.415
VF Loss                      367.003
Policy Loss                  -2709.0598
Q Predictions Mean           2705.626
Q Predictions Std            360.87454
Q Predictions Max            2869.9104
Q Predictions Min            19.064297
V Predictions Mean           2707.7983
V Predictions Std            366.1135
V Predictions Max            2883.422
V Predictions Min            24.10067
Log Pis Mean                 -4.891106
Log Pis Std                  5.0423894
Log Pis Max                  23.257872
Log Pis Min                  -14.666994
Policy mu Mean               0.3025261
Policy mu Std                0.68515426
Policy mu Max                3.0476646
Policy mu Min                -2.6088548
Policy log std Mean          -0.2915894
Policy log std Std           0.13174237
Policy log std Max           -0.056060024
Policy log std Min           -0.89025676
Z mean eval                  0.039016113
Z variance eval              0.038209222
total_rewards                [5527.63780072 5610.93813047 5587.65140987 5600.48418025 1734.98601268
 5509.64729302 5622.20662163 2924.76265832 4170.76882812 5418.55544277]
total_rewards_mean           4770.763837784681
total_rewards_std            1315.6249882717946
total_rewards_max            5622.206621629997
total_rewards_min            1734.9860126828362
Number of train steps total  445000
Number of env steps total    2227000
Number of rollouts total     0
Train Time (s)               29.602154219988734
(Previous) Eval Time (s)     22.566007198765874
Sample Time (s)              19.29946392867714
Epoch Time (s)               71.46762534743175
Total Train Time (s)         28225.36728847772
Epoch                        444
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:06:08.438077 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #444 | Epoch Duration: 74.75257301330566
2020-01-11 02:06:08.438286 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #444 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039055966
Z variance train             0.038200293
KL Divergence                5.8161573
KL Loss                      0.58161575
QF Loss                      1375.4321
VF Loss                      658.4811
Policy Loss                  -2662.2263
Q Predictions Mean           2660.0664
Q Predictions Std            465.28342
Q Predictions Max            2887.541
Q Predictions Min            23.311113
V Predictions Mean           2655.2754
V Predictions Std            470.03702
V Predictions Max            2877.9292
V Predictions Min            29.542955
Log Pis Mean                 -4.939447
Log Pis Std                  5.237638
Log Pis Max                  20.165148
Log Pis Min                  -15.27021
Policy mu Mean               0.33231828
Policy mu Std                0.66784686
Policy mu Max                2.9112103
Policy mu Min                -2.6106515
Policy log std Mean          -0.29619038
Policy log std Std           0.12699336
Policy log std Max           -0.05009649
Policy log std Min           -1.2589538
Z mean eval                  0.03604649
Z variance eval              0.037324905
total_rewards                [5506.40432643 5457.9247687  5585.17409765 3997.47512396 5412.23066618
 5450.95745255 5524.34246319 5440.32823402 5371.94735829 5476.64622484]
total_rewards_mean           5322.343071580339
total_rewards_std            445.22263069337544
total_rewards_max            5585.1740976513665
total_rewards_min            3997.4751239597786
Number of train steps total  446000
Number of env steps total    2232000
Number of rollouts total     0
Train Time (s)               29.014061300083995
(Previous) Eval Time (s)     25.850680063012987
Sample Time (s)              18.8558100592345
Epoch Time (s)               73.72055142233148
Total Train Time (s)         28301.205820405856
Epoch                        445
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:07:24.284000 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #445 | Epoch Duration: 75.84552216529846
2020-01-11 02:07:24.284306 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #445 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036217067
Z variance train             0.037324354
KL Divergence                5.8749733
KL Loss                      0.58749735
QF Loss                      1728.767
VF Loss                      423.043
Policy Loss                  -2620.4749
Q Predictions Mean           2612.6826
Q Predictions Std            582.16077
Q Predictions Max            2877.306
Q Predictions Min            19.81858
V Predictions Mean           2609.6987
V Predictions Std            581.3702
V Predictions Max            2882.757
V Predictions Min            32.966686
Log Pis Mean                 -4.809939
Log Pis Std                  5.667042
Log Pis Max                  38.03887
Log Pis Min                  -15.848378
Policy mu Mean               0.28255466
Policy mu Std                0.678363
Policy mu Max                3.4969447
Policy mu Min                -3.921978
Policy log std Mean          -0.29234818
Policy log std Std           0.13279326
Policy log std Max           -0.01519011
Policy log std Min           -1.1120824
Z mean eval                  0.034954306
Z variance eval              0.03541947
total_rewards                [4476.6821729  5613.55001529 1602.13329688 5585.00059295 5728.31208318
 5651.309637   5196.64485417 3111.98073768 1425.19053238 5594.21519028]
total_rewards_mean           4398.501911270297
total_rewards_std            1631.2667647375056
total_rewards_max            5728.3120831815
total_rewards_min            1425.190532376396
Number of train steps total  447000
Number of env steps total    2237000
Number of rollouts total     0
Train Time (s)               31.671634710859507
(Previous) Eval Time (s)     27.975348089821637
Sample Time (s)              19.20930166123435
Epoch Time (s)               78.8562844619155
Total Train Time (s)         28375.725530368276
Epoch                        446
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:08:38.805218 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #446 | Epoch Duration: 74.52070689201355
2020-01-11 02:08:38.805370 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #446 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03489929
Z variance train             0.035423934
KL Divergence                6.007922
KL Loss                      0.6007922
QF Loss                      1208.0774
VF Loss                      331.8092
Policy Loss                  -2695.5955
Q Predictions Mean           2693.0557
Q Predictions Std            428.2015
Q Predictions Max            2890.9236
Q Predictions Min            19.964745
V Predictions Mean           2697.2441
V Predictions Std            433.63812
V Predictions Max            2890.767
V Predictions Min            23.21469
Log Pis Mean                 -5.0120187
Log Pis Std                  4.6741924
Log Pis Max                  22.184643
Log Pis Min                  -13.714876
Policy mu Mean               0.36333525
Policy mu Std                0.64619726
Policy mu Max                2.7819614
Policy mu Min                -2.4101481
Policy log std Mean          -0.29517427
Policy log std Std           0.1277841
Policy log std Max           -0.032690838
Policy log std Min           -1.0986135
Z mean eval                  0.036635734
Z variance eval              0.03648787
total_rewards                [5361.93603395 5453.48486342 5562.16491534 3695.53632998 5471.2645082
 5528.09487143 5604.68253266 5503.36657779 1740.18739307 5553.16835413]
total_rewards_mean           4947.388637997495
total_rewards_std            1199.124192298559
total_rewards_max            5604.682532662396
total_rewards_min            1740.1873930673953
Number of train steps total  448000
Number of env steps total    2242000
Number of rollouts total     0
Train Time (s)               31.002454278990626
(Previous) Eval Time (s)     23.63948119431734
Sample Time (s)              18.87198798172176
Epoch Time (s)               73.51392345502973
Total Train Time (s)         28452.09310613619
Epoch                        447
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:09:55.180319 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #447 | Epoch Duration: 76.37478566169739
2020-01-11 02:09:55.180640 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #447 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036487296
Z variance train             0.036493678
KL Divergence                5.959995
KL Loss                      0.5959995
QF Loss                      1542.0701
VF Loss                      435.04495
Policy Loss                  -2651.8845
Q Predictions Mean           2650.544
Q Predictions Std            451.1947
Q Predictions Max            2886.0579
Q Predictions Min            25.936508
V Predictions Mean           2652.6465
V Predictions Std            449.1079
V Predictions Max            2886.6633
V Predictions Min            35.0873
Log Pis Mean                 -3.5338595
Log Pis Std                  5.453296
Log Pis Max                  25.431295
Log Pis Min                  -13.57851
Policy mu Mean               0.31961703
Policy mu Std                0.7179729
Policy mu Max                2.8359392
Policy mu Min                -2.8370411
Policy log std Mean          -0.31679922
Policy log std Std           0.13567293
Policy log std Max           0.03806986
Policy log std Min           -1.0955998
Z mean eval                  0.033965804
Z variance eval              0.036794815
total_rewards                [4533.41638045 1733.98305759  475.82820702 5559.7711667  5429.18877569
 5523.2502551  5605.67532463 5532.86128737 5512.77728594 5522.01384715]
total_rewards_mean           4542.876558762701
total_rewards_std            1766.9363116701036
total_rewards_max            5605.675324627483
total_rewards_min            475.8282070189708
Number of train steps total  449000
Number of env steps total    2247000
Number of rollouts total     0
Train Time (s)               30.51133255288005
(Previous) Eval Time (s)     26.500001289881766
Sample Time (s)              20.017498542554677
Epoch Time (s)               77.02883238531649
Total Train Time (s)         28527.117093477398
Epoch                        448
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:11:10.208792 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #448 | Epoch Duration: 75.02791142463684
2020-01-11 02:11:10.209028 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #448 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03408766
Z variance train             0.036797523
KL Divergence                5.9698243
KL Loss                      0.5969824
QF Loss                      1482.5947
VF Loss                      533.2509
Policy Loss                  -2683.274
Q Predictions Mean           2676.0625
Q Predictions Std            423.5562
Q Predictions Max            2882.2588
Q Predictions Min            22.68348
V Predictions Mean           2672.2078
V Predictions Std            423.01767
V Predictions Max            2873.8994
V Predictions Min            35.55115
Log Pis Mean                 -4.2155685
Log Pis Std                  5.5353527
Log Pis Max                  21.996067
Log Pis Min                  -13.582539
Policy mu Mean               0.3365356
Policy mu Std                0.6947056
Policy mu Max                3.1356926
Policy mu Min                -2.6331198
Policy log std Mean          -0.3093494
Policy log std Std           0.13308537
Policy log std Max           -0.05269251
Policy log std Min           -1.1825926
Z mean eval                  0.035985645
Z variance eval              0.036368586
total_rewards                [5589.9737818  5486.73931288 5428.65589774 5461.93060554 5519.10825722
 5470.83627901 5431.17842805 5484.34517887 5486.10812149 5444.05736094]
total_rewards_mean           5480.293322353649
total_rewards_std            45.21786038398335
total_rewards_max            5589.973781797656
total_rewards_min            5428.655897741126
Number of train steps total  450000
Number of env steps total    2252000
Number of rollouts total     0
Train Time (s)               32.69355080509558
(Previous) Eval Time (s)     24.498765117954463
Sample Time (s)              19.338022225070745
Epoch Time (s)               76.53033814812079
Total Train Time (s)         28609.814326154068
Epoch                        449
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:12:32.911217 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #449 | Epoch Duration: 82.70200967788696
2020-01-11 02:12:32.911458 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #449 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035907004
Z variance train             0.036366917
KL Divergence                6.0030813
KL Loss                      0.6003081
QF Loss                      1228.506
VF Loss                      619.72925
Policy Loss                  -2704.7678
Q Predictions Mean           2699.5496
Q Predictions Std            368.24628
Q Predictions Max            2909.6335
Q Predictions Min            26.38171
V Predictions Mean           2691.742
V Predictions Std            363.85254
V Predictions Max            2903.7922
V Predictions Min            36.146
Log Pis Mean                 -3.6576793
Log Pis Std                  5.9729085
Log Pis Max                  38.949535
Log Pis Min                  -14.832974
Policy mu Mean               0.3169017
Policy mu Std                0.7403628
Policy mu Max                3.9366148
Policy mu Min                -3.8706605
Policy log std Mean          -0.32174903
Policy log std Std           0.14278027
Policy log std Max           0.6140765
Policy log std Min           -1.1738224
Z mean eval                  0.03693352
Z variance eval              0.03577597
total_rewards                [1344.79015733 2403.71982455 1320.72640843 2217.33070207 4194.62035361
 5404.27637535 5605.43248161 5595.73878961 5433.33198056 5536.64602322]
total_rewards_mean           3905.661309634449
total_rewards_std            1772.4292694382113
total_rewards_max            5605.432481611671
total_rewards_min            1320.7264084342369
Number of train steps total  451000
Number of env steps total    2257000
Number of rollouts total     0
Train Time (s)               29.952579519245774
(Previous) Eval Time (s)     30.67010228894651
Sample Time (s)              20.597624704707414
Epoch Time (s)               81.2203065128997
Total Train Time (s)         28682.07268084027
Epoch                        450
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:13:45.173327 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #450 | Epoch Duration: 72.26169228553772
2020-01-11 02:13:45.173531 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #450 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036807902
Z variance train             0.0357802
KL Divergence                6.0392013
KL Loss                      0.60392016
QF Loss                      2212.9172
VF Loss                      526.31177
Policy Loss                  -2687.2224
Q Predictions Mean           2680.9233
Q Predictions Std            422.29062
Q Predictions Max            2887.902
Q Predictions Min            20.738163
V Predictions Mean           2692.9697
V Predictions Std            425.5076
V Predictions Max            2912.9734
V Predictions Min            32.281033
Log Pis Mean                 -4.0873604
Log Pis Std                  5.6702614
Log Pis Max                  27.360462
Log Pis Min                  -13.4257965
Policy mu Mean               0.27405256
Policy mu Std                0.7405927
Policy mu Max                3.2430308
Policy mu Min                -2.8510163
Policy log std Mean          -0.30761433
Policy log std Std           0.13874978
Policy log std Max           -0.0019288063
Policy log std Min           -1.2032511
Z mean eval                  0.0392286
Z variance eval              0.036928415
total_rewards                [2619.19577694 5560.93197668 2788.26202707 4989.95870559 2791.46326029
 5615.48359508 5565.02261961 5615.08159206 5585.45521749 5441.85349996]
total_rewards_mean           4657.270827077118
total_rewards_std            1272.4837562393889
total_rewards_max            5615.483595080081
total_rewards_min            2619.1957769420465
Number of train steps total  452000
Number of env steps total    2262000
Number of rollouts total     0
Train Time (s)               32.13547127926722
(Previous) Eval Time (s)     21.71112686302513
Sample Time (s)              18.96144616883248
Epoch Time (s)               72.80804431112483
Total Train Time (s)         28758.054185256828
Epoch                        451
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:15:01.159272 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #451 | Epoch Duration: 75.98559069633484
2020-01-11 02:15:01.159483 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #451 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039083328
Z variance train             0.036942244
KL Divergence                5.9478
KL Loss                      0.59478
QF Loss                      1621.103
VF Loss                      474.18707
Policy Loss                  -2681.3708
Q Predictions Mean           2682.931
Q Predictions Std            438.72327
Q Predictions Max            2897.6794
Q Predictions Min            23.888264
V Predictions Mean           2690.977
V Predictions Std            437.01794
V Predictions Max            2892.0557
V Predictions Min            34.739357
Log Pis Mean                 -3.9963512
Log Pis Std                  5.455356
Log Pis Max                  19.490246
Log Pis Min                  -14.435638
Policy mu Mean               0.3393519
Policy mu Std                0.71189404
Policy mu Max                2.670246
Policy mu Min                -2.548156
Policy log std Mean          -0.30808252
Policy log std Std           0.13967271
Policy log std Max           -0.014002234
Policy log std Min           -1.0794165
Z mean eval                  0.037346397
Z variance eval              0.035459794
total_rewards                [5606.63505443 5476.93074283 1528.50215202 1642.27856837 2450.39615556
 5587.73822539 3228.15082249 2274.08184356 2864.0270001  1042.64357182]
total_rewards_mean           3170.13841365598
total_rewards_std            1675.5945552700864
total_rewards_max            5606.635054433322
total_rewards_min            1042.6435718207113
Number of train steps total  453000
Number of env steps total    2267000
Number of rollouts total     0
Train Time (s)               30.58113359892741
(Previous) Eval Time (s)     24.888344903010875
Sample Time (s)              19.08984888717532
Epoch Time (s)               74.5593273891136
Total Train Time (s)         28825.643531897105
Epoch                        452
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:16:08.752150 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #452 | Epoch Duration: 67.59251546859741
2020-01-11 02:16:08.752335 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #452 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037565034
Z variance train             0.035461683
KL Divergence                6.0395412
KL Loss                      0.60395414
QF Loss                      1628.3708
VF Loss                      774.42285
Policy Loss                  -2666.9666
Q Predictions Mean           2663.1008
Q Predictions Std            480.01846
Q Predictions Max            2883.268
Q Predictions Min            20.251259
V Predictions Mean           2677.435
V Predictions Std            473.96127
V Predictions Max            2892.757
V Predictions Min            32.175686
Log Pis Mean                 -4.7021427
Log Pis Std                  4.9411793
Log Pis Max                  20.409641
Log Pis Min                  -14.385047
Policy mu Mean               0.30600947
Policy mu Std                0.6928396
Policy mu Max                2.8324716
Policy mu Min                -2.595717
Policy log std Mean          -0.2964426
Policy log std Std           0.1306414
Policy log std Max           0.14216128
Policy log std Min           -0.9705618
Z mean eval                  0.037412386
Z variance eval              0.036899626
total_rewards                [5569.94054729 5322.04711422 5459.7564187  1084.22452049 3797.71557746
 5462.0682114  5444.13594365 5398.71484243 5443.39875946 1922.12555077]
total_rewards_mean           4490.412748586577
total_rewards_std            1583.084558242469
total_rewards_max            5569.940547290989
total_rewards_min            1084.224520491903
Number of train steps total  454000
Number of env steps total    2272000
Number of rollouts total     0
Train Time (s)               32.1156439371407
(Previous) Eval Time (s)     17.921263029798865
Sample Time (s)              20.1433735974133
Epoch Time (s)               70.18028056435287
Total Train Time (s)         28902.894082087558
Epoch                        453
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:17:26.005695 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #453 | Epoch Duration: 77.2532069683075
2020-01-11 02:17:26.005895 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #453 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03753737
Z variance train             0.036889926
KL Divergence                5.964521
KL Loss                      0.5964521
QF Loss                      1052.336
VF Loss                      619.44794
Policy Loss                  -2625.8384
Q Predictions Mean           2622.8174
Q Predictions Std            563.2793
Q Predictions Max            2882.5051
Q Predictions Min            18.50939
V Predictions Mean           2612.8926
V Predictions Std            559.2065
V Predictions Max            2867.1443
V Predictions Min            28.94412
Log Pis Mean                 -4.2691455
Log Pis Std                  4.5170603
Log Pis Max                  15.455009
Log Pis Min                  -14.768021
Policy mu Mean               0.33791822
Policy mu Std                0.6841986
Policy mu Max                2.5723362
Policy mu Min                -2.8583276
Policy log std Mean          -0.30472934
Policy log std Std           0.13394812
Policy log std Max           -0.084605776
Policy log std Min           -1.0046022
Z mean eval                  0.038209863
Z variance eval              0.036070473
total_rewards                [5606.92250585 5694.75008152 5665.22468356 5580.0500331  5687.67059421
 5438.05720067 5578.61695395 5646.62684486 5672.59600018 2595.87755149]
total_rewards_mean           5316.639244938514
total_rewards_std            909.797194434875
total_rewards_max            5694.750081517888
total_rewards_min            2595.87755149034
Number of train steps total  455000
Number of env steps total    2277000
Number of rollouts total     0
Train Time (s)               32.38192982971668
(Previous) Eval Time (s)     24.993815581314266
Sample Time (s)              19.23863353487104
Epoch Time (s)               76.61437894590199
Total Train Time (s)         28983.315840557218
Epoch                        454
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:18:46.432649 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #454 | Epoch Duration: 80.42660427093506
2020-01-11 02:18:46.432863 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #454 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.038315207
Z variance train             0.036075357
KL Divergence                5.9942102
KL Loss                      0.599421
QF Loss                      1532.9666
VF Loss                      770.0908
Policy Loss                  -2672.7021
Q Predictions Mean           2669.8794
Q Predictions Std            470.1767
Q Predictions Max            2882.0544
Q Predictions Min            22.097115
V Predictions Mean           2669.6885
V Predictions Std            469.1897
V Predictions Max            2880.6743
V Predictions Min            30.503092
Log Pis Mean                 -3.8221476
Log Pis Std                  5.873418
Log Pis Max                  24.577587
Log Pis Min                  -14.14617
Policy mu Mean               0.30744523
Policy mu Std                0.7401224
Policy mu Max                3.2822506
Policy mu Min                -3.951142
Policy log std Mean          -0.29965675
Policy log std Std           0.13878195
Policy log std Max           0.06316744
Policy log std Min           -1.1241199
Z mean eval                  0.03653703
Z variance eval              0.03700305
total_rewards                [5482.86809052 5474.00689372 5508.97206169 5493.29189274 5454.69174981
 5433.47408118 5574.14274399 5581.42325853 5527.84430504  619.46143561]
total_rewards_mean           5015.017651280896
total_rewards_std            1465.8803930594995
total_rewards_max            5581.42325852514
total_rewards_min            619.4614356083835
Number of train steps total  456000
Number of env steps total    2282000
Number of rollouts total     0
Train Time (s)               30.94588881218806
(Previous) Eval Time (s)     28.80572008434683
Sample Time (s)              20.003696710336953
Epoch Time (s)               79.75530560687184
Total Train Time (s)         29061.0956539372
Epoch                        455
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:20:04.215468 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #455 | Epoch Duration: 77.78245496749878
2020-01-11 02:20:04.215637 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #455 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03614348
Z variance train             0.03701922
KL Divergence                5.90463
KL Loss                      0.59046304
QF Loss                      1106.314
VF Loss                      469.30927
Policy Loss                  -2670.3948
Q Predictions Mean           2670.675
Q Predictions Std            481.7427
Q Predictions Max            2881.8508
Q Predictions Min            14.64863
V Predictions Mean           2673.5708
V Predictions Std            482.34653
V Predictions Max            2889.3882
V Predictions Min            22.495094
Log Pis Mean                 -4.5781627
Log Pis Std                  4.5543733
Log Pis Max                  13.67258
Log Pis Min                  -13.751898
Policy mu Mean               0.32277057
Policy mu Std                0.6873074
Policy mu Max                2.529059
Policy mu Min                -3.2525814
Policy log std Mean          -0.29141897
Policy log std Std           0.12570141
Policy log std Max           -0.064787515
Policy log std Min           -1.0468023
Z mean eval                  0.03941712
Z variance eval              0.036167424
total_rewards                [5463.65685408 5454.74597676 5469.09319417 4548.15375182 5390.9242836
 5490.38722854 5419.16269145 5421.71155065 5431.53107142 5453.30976933]
total_rewards_mean           5354.267637179973
total_rewards_std            270.0884460383887
total_rewards_max            5490.387228535858
total_rewards_min            4548.153751815366
Number of train steps total  457000
Number of env steps total    2287000
Number of rollouts total     0
Train Time (s)               32.48659309698269
(Previous) Eval Time (s)     26.832511555869132
Sample Time (s)              19.51705246279016
Epoch Time (s)               78.83615711564198
Total Train Time (s)         29142.719329325482
Epoch                        456
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:21:25.846271 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #456 | Epoch Duration: 81.63047480583191
2020-01-11 02:21:25.846547 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #456 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039954416
Z variance train             0.036156368
KL Divergence                5.992076
KL Loss                      0.5992076
QF Loss                      1191.7029
VF Loss                      450.8928
Policy Loss                  -2732.1182
Q Predictions Mean           2729.1816
Q Predictions Std            293.00183
Q Predictions Max            2883.0874
Q Predictions Min            29.066883
V Predictions Mean           2721.5098
V Predictions Std            292.88617
V Predictions Max            2877.7876
V Predictions Min            35.727787
Log Pis Mean                 -5.0365667
Log Pis Std                  5.198951
Log Pis Max                  22.856228
Log Pis Min                  -13.83916
Policy mu Mean               0.31771255
Policy mu Std                0.6692602
Policy mu Max                3.5518842
Policy mu Min                -3.1646028
Policy log std Mean          -0.2982183
Policy log std Std           0.13375317
Policy log std Max           -0.064127915
Policy log std Min           -1.5000801
Z mean eval                  0.038359445
Z variance eval              0.036688343
total_rewards                [5463.09713665 5500.8254013  3643.19489661 5633.91802526 4419.26907738
 5386.97059191 5444.00701583 1141.39430837 5641.07699339 5552.62639691]
total_rewards_mean           4782.637984361794
total_rewards_std            1361.063743422188
total_rewards_max            5641.076993390808
total_rewards_min            1141.394308366638
Number of train steps total  458000
Number of env steps total    2292000
Number of rollouts total     0
Train Time (s)               31.04471500404179
(Previous) Eval Time (s)     29.626510506961495
Sample Time (s)              20.165446259081364
Epoch Time (s)               80.83667177008465
Total Train Time (s)         29218.75108148018
Epoch                        457
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:22:41.880089 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #457 | Epoch Duration: 76.03333020210266
2020-01-11 02:22:41.880254 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #457 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03800014
Z variance train             0.03667984
KL Divergence                5.9336977
KL Loss                      0.5933698
QF Loss                      1315.6409
VF Loss                      432.21082
Policy Loss                  -2716.1042
Q Predictions Mean           2716.602
Q Predictions Std            351.25446
Q Predictions Max            2888.0886
Q Predictions Min            26.355333
V Predictions Mean           2726.2324
V Predictions Std            351.6582
V Predictions Max            2915.4941
V Predictions Min            32.743633
Log Pis Mean                 -4.986125
Log Pis Std                  4.996598
Log Pis Max                  26.788445
Log Pis Min                  -14.530391
Policy mu Mean               0.3077432
Policy mu Std                0.6833027
Policy mu Max                2.979209
Policy mu Min                -3.087303
Policy log std Mean          -0.3004017
Policy log std Std           0.13372962
Policy log std Max           0.104033634
Policy log std Min           -1.155752
Z mean eval                  0.036749814
Z variance eval              0.039185736
total_rewards                [4010.53170224 4897.76318132 5521.69860825 2118.98967643 5398.45728919
 5509.67402863 5590.04268719 5390.0900022  5162.73901876 5640.23730951]
total_rewards_mean           4924.022350372755
total_rewards_std            1042.0848324065967
total_rewards_max            5640.237309513577
total_rewards_min            2118.989676430165
Number of train steps total  459000
Number of env steps total    2297000
Number of rollouts total     0
Train Time (s)               32.09087324002758
(Previous) Eval Time (s)     24.822818947024643
Sample Time (s)              19.316340868826956
Epoch Time (s)               76.23003305587918
Total Train Time (s)         29295.84064566437
Epoch                        458
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:23:58.972853 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #458 | Epoch Duration: 77.09248280525208
2020-01-11 02:23:58.973021 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #458 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03724483
Z variance train             0.03917858
KL Divergence                5.7617025
KL Loss                      0.57617027
QF Loss                      1706.1426
VF Loss                      390.3004
Policy Loss                  -2714.3608
Q Predictions Mean           2710.5312
Q Predictions Std            306.9534
Q Predictions Max            2891.5586
Q Predictions Min            579.023
V Predictions Mean           2707.7075
V Predictions Std            302.15567
V Predictions Max            2876.171
V Predictions Min            582.74365
Log Pis Mean                 -3.681698
Log Pis Std                  5.919974
Log Pis Max                  20.924805
Log Pis Min                  -12.660707
Policy mu Mean               0.33052474
Policy mu Std                0.7293474
Policy mu Max                3.3237925
Policy mu Min                -3.2642934
Policy log std Mean          -0.3105672
Policy log std Std           0.14285164
Policy log std Max           -0.03817755
Policy log std Min           -1.359668
Z mean eval                  0.03879019
Z variance eval              0.03946503
total_rewards                [5529.69761698 4046.56028711 4658.82962223 1668.05418655 5568.31030131
 5677.33848515 5344.61749064 1456.97805833 5665.11830638 5692.37590674]
total_rewards_mean           4530.788026143225
total_rewards_std            1567.8515456410696
total_rewards_max            5692.37590674499
total_rewards_min            1456.9780583252739
Number of train steps total  460000
Number of env steps total    2302000
Number of rollouts total     0
Train Time (s)               30.884610986337066
(Previous) Eval Time (s)     25.684953475371003
Sample Time (s)              20.030091276858002
Epoch Time (s)               76.59965573856607
Total Train Time (s)         29371.26844836073
Epoch                        459
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:25:14.404929 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #459 | Epoch Duration: 75.4317786693573
2020-01-11 02:25:14.405132 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #459 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039028157
Z variance train             0.03946594
KL Divergence                5.7417054
KL Loss                      0.57417053
QF Loss                      1207.0981
VF Loss                      285.92957
Policy Loss                  -2709.3735
Q Predictions Mean           2705.2712
Q Predictions Std            379.33768
Q Predictions Max            2893.8662
Q Predictions Min            26.24677
V Predictions Mean           2708.1118
V Predictions Std            381.13803
V Predictions Max            2890.8193
V Predictions Min            35.73666
Log Pis Mean                 -4.7169247
Log Pis Std                  5.7779202
Log Pis Max                  26.017136
Log Pis Min                  -13.479579
Policy mu Mean               0.3372348
Policy mu Std                0.6904802
Policy mu Max                2.8543773
Policy mu Min                -2.6911187
Policy log std Mean          -0.29480135
Policy log std Std           0.13153294
Policy log std Max           -0.040716887
Policy log std Min           -1.119382
Z mean eval                  0.038676005
Z variance eval              0.03804005
total_rewards                [5590.30614038 5617.57333192 3945.65261061 2962.12281892 2930.14260441
 2799.09218537 4038.30525994 1054.79144525 5504.2935802  5115.39784468]
total_rewards_mean           3955.7677821684856
total_rewards_std            1448.2990565640257
total_rewards_max            5617.573331917063
total_rewards_min            1054.7914452534906
Number of train steps total  461000
Number of env steps total    2307000
Number of rollouts total     0
Train Time (s)               30.03463320666924
(Previous) Eval Time (s)     24.51674216799438
Sample Time (s)              19.26837542327121
Epoch Time (s)               73.81975079793483
Total Train Time (s)         29441.07468092488
Epoch                        460
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:26:24.217671 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #460 | Epoch Duration: 69.81236505508423
2020-01-11 02:26:24.217931 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #460 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039031718
Z variance train             0.038047172
KL Divergence                5.837001
KL Loss                      0.5837001
QF Loss                      1920.1246
VF Loss                      515.32825
Policy Loss                  -2686.5847
Q Predictions Mean           2676.226
Q Predictions Std            463.28082
Q Predictions Max            2886.71
Q Predictions Min            22.594332
V Predictions Mean           2675.6274
V Predictions Std            461.80795
V Predictions Max            2895.797
V Predictions Min            30.247936
Log Pis Mean                 -4.604992
Log Pis Std                  5.27465
Log Pis Max                  21.376019
Log Pis Min                  -19.199944
Policy mu Mean               0.2938483
Policy mu Std                0.70366085
Policy mu Max                2.6134362
Policy mu Min                -2.9380841
Policy log std Mean          -0.3043513
Policy log std Std           0.13691495
Policy log std Max           -0.02368813
Policy log std Min           -1.1991943
Z mean eval                  0.037053175
Z variance eval              0.037402853
total_rewards                [5593.011241   1565.05461681 5629.88935622 5496.84789102 5445.9900024
 5419.4418291  5319.26963301 2720.63752286 4965.43275539 3264.68281774]
total_rewards_mean           4542.0257665552
total_rewards_std            1392.1749929087218
total_rewards_max            5629.889356224959
total_rewards_min            1565.054616809849
Number of train steps total  462000
Number of env steps total    2312000
Number of rollouts total     0
Train Time (s)               29.65402132831514
(Previous) Eval Time (s)     20.509049104060978
Sample Time (s)              19.888629043009132
Epoch Time (s)               70.05169947538525
Total Train Time (s)         29515.20876337355
Epoch                        461
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:27:38.355020 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #461 | Epoch Duration: 74.13689756393433
2020-01-11 02:27:38.355203 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #461 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036955245
Z variance train             0.03740427
KL Divergence                5.8727074
KL Loss                      0.58727074
QF Loss                      1336.5034
VF Loss                      473.46957
Policy Loss                  -2728.1199
Q Predictions Mean           2722.3374
Q Predictions Std            332.81174
Q Predictions Max            2895.7886
Q Predictions Min            29.49162
V Predictions Mean           2728.9697
V Predictions Std            331.79398
V Predictions Max            2894.116
V Predictions Min            33.72999
Log Pis Mean                 -4.27125
Log Pis Std                  4.887315
Log Pis Max                  26.056873
Log Pis Min                  -15.934809
Policy mu Mean               0.3676183
Policy mu Std                0.6789589
Policy mu Max                2.837531
Policy mu Min                -2.612484
Policy log std Mean          -0.30219454
Policy log std Std           0.12756453
Policy log std Max           -0.046731457
Policy log std Min           -1.0996953
Z mean eval                  0.036687676
Z variance eval              0.037324477
total_rewards                [5465.78925797 3005.57850233 5581.36558769 5621.89483073 1381.51887176
 5657.83919903 3403.96629209 5713.93336675 2357.15965074 2689.20970195]
total_rewards_mean           4087.8255261052195
total_rewards_std            1597.0702117098099
total_rewards_max            5713.933366753063
total_rewards_min            1381.5188717645722
Number of train steps total  463000
Number of env steps total    2317000
Number of rollouts total     0
Train Time (s)               31.42984202504158
(Previous) Eval Time (s)     24.593971396330744
Sample Time (s)              19.354484104551375
Epoch Time (s)               75.3782975259237
Total Train Time (s)         29588.110714273527
Epoch                        462
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:28:51.264534 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #462 | Epoch Duration: 72.90916562080383
2020-01-11 02:28:51.264810 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #462 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036456805
Z variance train             0.037331898
KL Divergence                5.918188
KL Loss                      0.5918188
QF Loss                      1386.4143
VF Loss                      441.4601
Policy Loss                  -2717.8054
Q Predictions Mean           2716.1875
Q Predictions Std            390.2616
Q Predictions Max            2904.359
Q Predictions Min            22.299318
V Predictions Mean           2726.8918
V Predictions Std            393.59842
V Predictions Max            2907.151
V Predictions Min            33.328136
Log Pis Mean                 -5.2808957
Log Pis Std                  5.1765532
Log Pis Max                  33.578697
Log Pis Min                  -13.08322
Policy mu Mean               0.33951393
Policy mu Std                0.6457582
Policy mu Max                2.8648217
Policy mu Min                -3.130644
Policy log std Mean          -0.29181468
Policy log std Std           0.12983224
Policy log std Max           -0.046708502
Policy log std Min           -1.1730144
Z mean eval                  0.037359573
Z variance eval              0.037729867
total_rewards                [2312.08972836 5292.08326174 5455.34433424 5445.77169901 1165.63681023
 5585.11298392 5270.00758863 4373.59230523 5438.07318159 4261.08161811]
total_rewards_mean           4459.879351106695
total_rewards_std            1450.7521992892541
total_rewards_max            5585.112983920706
total_rewards_min            1165.6368102285492
Number of train steps total  464000
Number of env steps total    2322000
Number of rollouts total     0
Train Time (s)               33.54833262087777
(Previous) Eval Time (s)     22.124478850048035
Sample Time (s)              19.82067421497777
Epoch Time (s)               75.49348568590358
Total Train Time (s)         29666.27824275894
Epoch                        463
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:30:09.434851 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #463 | Epoch Duration: 78.16984558105469
2020-01-11 02:30:09.435001 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #463 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03751804
Z variance train             0.037733056
KL Divergence                5.9193935
KL Loss                      0.5919394
QF Loss                      2092.1172
VF Loss                      518.46655
Policy Loss                  -2716.287
Q Predictions Mean           2713.419
Q Predictions Std            313.5183
Q Predictions Max            2905.7773
Q Predictions Min            78.60829
V Predictions Mean           2706.878
V Predictions Std            310.66718
V Predictions Max            2878.4358
V Predictions Min            95.3158
Log Pis Mean                 -3.7692146
Log Pis Std                  5.2769556
Log Pis Max                  17.28674
Log Pis Min                  -14.314757
Policy mu Mean               0.3573268
Policy mu Std                0.7279534
Policy mu Max                2.5549397
Policy mu Min                -2.5985346
Policy log std Mean          -0.3209675
Policy log std Std           0.13047129
Policy log std Max           -0.077562705
Policy log std Min           -0.9652255
Z mean eval                  0.03463756
Z variance eval              0.03751068
total_rewards                [5686.89755708 1582.29149385 5615.86086326 5687.85245311  881.86385924
 2622.09730429 1222.06193101 2263.58308154 1855.15546589 4337.37070699]
total_rewards_mean           3175.503471624217
total_rewards_std            1855.276106113304
total_rewards_max            5687.852453105292
total_rewards_min            881.8638592353897
Number of train steps total  465000
Number of env steps total    2327000
Number of rollouts total     0
Train Time (s)               33.17140446975827
(Previous) Eval Time (s)     24.800490263383836
Sample Time (s)              19.813326424453408
Epoch Time (s)               77.78522115759552
Total Train Time (s)         29736.46636171546
Epoch                        464
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:31:19.631445 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #464 | Epoch Duration: 70.19628882408142
2020-01-11 02:31:19.631765 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #464 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03447897
Z variance train             0.037508864
KL Divergence                5.9224815
KL Loss                      0.59224814
QF Loss                      1697.8049
VF Loss                      327.48154
Policy Loss                  -2685.593
Q Predictions Mean           2681.7803
Q Predictions Std            423.50012
Q Predictions Max            2881.0767
Q Predictions Min            31.431433
V Predictions Mean           2696.0918
V Predictions Std            421.096
V Predictions Max            2897.848
V Predictions Min            40.55778
Log Pis Mean                 -4.4017444
Log Pis Std                  4.8976707
Log Pis Max                  16.355083
Log Pis Min                  -14.315931
Policy mu Mean               0.3064344
Policy mu Std                0.70296514
Policy mu Max                2.874003
Policy mu Min                -2.5394447
Policy log std Mean          -0.29963112
Policy log std Std           0.12466162
Policy log std Max           -0.00083292276
Policy log std Min           -0.95282686
Z mean eval                  0.036222782
Z variance eval              0.038504686
total_rewards                [4086.42997148 3806.58921389 2513.06971659 5527.44191444 5374.07654818
 3809.70652848 5843.28488903 4948.73197989 5683.43838633 5797.93511076]
total_rewards_mean           4739.07042590598
total_rewards_std            1068.423716404703
total_rewards_max            5843.284889025469
total_rewards_min            2513.0697165883234
Number of train steps total  466000
Number of env steps total    2332000
Number of rollouts total     0
Train Time (s)               29.737962454091758
(Previous) Eval Time (s)     17.211181041784585
Sample Time (s)              19.291240551043302
Epoch Time (s)               66.24038404691964
Total Train Time (s)         29809.983186090365
Epoch                        465
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:32:33.152426 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #465 | Epoch Duration: 73.5204119682312
2020-01-11 02:32:33.152614 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #465 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036382057
Z variance train             0.03851243
KL Divergence                5.874361
KL Loss                      0.58743614
QF Loss                      1460.387
VF Loss                      557.30786
Policy Loss                  -2737.8586
Q Predictions Mean           2730.2666
Q Predictions Std            338.62524
Q Predictions Max            2898.0942
Q Predictions Min            23.74593
V Predictions Mean           2736.468
V Predictions Std            334.34833
V Predictions Max            2895.1375
V Predictions Min            32.99009
Log Pis Mean                 -4.2196703
Log Pis Std                  4.932835
Log Pis Max                  22.998394
Log Pis Min                  -15.502653
Policy mu Mean               0.33107173
Policy mu Std                0.7050841
Policy mu Max                3.1841805
Policy mu Min                -3.604476
Policy log std Mean          -0.29594544
Policy log std Std           0.12639086
Policy log std Max           -0.032618314
Policy log std Min           -1.0601894
Z mean eval                  0.037676338
Z variance eval              0.03698113
total_rewards                [5504.31505608 1451.38575927 3742.3318327  1374.72303094 2793.21180265
 4995.20686139 4002.67220618 3066.42646363 5275.47808685 4927.11449698]
total_rewards_mean           3713.286559667028
total_rewards_std            1438.7338598685915
total_rewards_max            5504.3150560810045
total_rewards_min            1374.7230309371594
Number of train steps total  467000
Number of env steps total    2337000
Number of rollouts total     0
Train Time (s)               30.589541363995522
(Previous) Eval Time (s)     24.490921646356583
Sample Time (s)              19.65240973001346
Epoch Time (s)               74.73287274036556
Total Train Time (s)         29880.849360465072
Epoch                        466
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:33:44.025853 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #466 | Epoch Duration: 70.87306356430054
2020-01-11 02:33:44.026153 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #466 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037692953
Z variance train             0.036979456
KL Divergence                5.9672027
KL Loss                      0.5967203
QF Loss                      761.9048
VF Loss                      256.13998
Policy Loss                  -2711.3308
Q Predictions Mean           2709.3467
Q Predictions Std            406.19855
Q Predictions Max            2892.0962
Q Predictions Min            20.662542
V Predictions Mean           2708.9272
V Predictions Std            408.08557
V Predictions Max            2897.8987
V Predictions Min            30.09396
Log Pis Mean                 -4.7907267
Log Pis Std                  4.761014
Log Pis Max                  21.355953
Log Pis Min                  -15.462413
Policy mu Mean               0.34395003
Policy mu Std                0.67120534
Policy mu Max                2.8407433
Policy mu Min                -2.8819046
Policy log std Mean          -0.29445785
Policy log std Std           0.12479767
Policy log std Max           -0.03505481
Policy log std Min           -0.936181
Z mean eval                  0.031346075
Z variance eval              0.03649946
total_rewards                [5506.97450381 5409.51220697 2293.86708549 5454.34537356 3188.27646608
 1553.92930126 3917.8798445  1685.90072982 5503.66047041 1903.75128787]
total_rewards_mean           3641.809726977625
total_rewards_std            1632.7863813659915
total_rewards_max            5506.974503812189
total_rewards_min            1553.9293012625033
Number of train steps total  468000
Number of env steps total    2342000
Number of rollouts total     0
Train Time (s)               31.40740526514128
(Previous) Eval Time (s)     20.63075556186959
Sample Time (s)              19.518051190301776
Epoch Time (s)               71.55621201731265
Total Train Time (s)         29951.26376140816
Epoch                        467
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:34:54.447605 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #467 | Epoch Duration: 70.421217918396
2020-01-11 02:34:54.447922 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #467 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031026363
Z variance train             0.036493037
KL Divergence                6.015515
KL Loss                      0.6015515
QF Loss                      1495.7227
VF Loss                      674.02136
Policy Loss                  -2699.572
Q Predictions Mean           2695.473
Q Predictions Std            423.10657
Q Predictions Max            2891.563
Q Predictions Min            20.831928
V Predictions Mean           2718.739
V Predictions Std            425.12042
V Predictions Max            2920.8477
V Predictions Min            31.123148
Log Pis Mean                 -4.2876554
Log Pis Std                  5.11123
Log Pis Max                  18.655867
Log Pis Min                  -17.390965
Policy mu Mean               0.3196237
Policy mu Std                0.73489183
Policy mu Max                2.8394294
Policy mu Min                -3.4493513
Policy log std Mean          -0.3053522
Policy log std Std           0.12930126
Policy log std Max           0.0028851181
Policy log std Min           -1.0101919
Z mean eval                  0.03309378
Z variance eval              0.035895433
total_rewards                [1523.34710942 1805.2335297  5436.44864136 5541.74581776 3042.7291746
 2605.09549146 5548.77271603 5464.81670406 1360.38078159 5602.09782408]
total_rewards_mean           3793.0667790071448
total_rewards_std            1786.162889144044
total_rewards_max            5602.09782408386
total_rewards_min            1360.3807815879861
Number of train steps total  469000
Number of env steps total    2347000
Number of rollouts total     0
Train Time (s)               30.311223477125168
(Previous) Eval Time (s)     19.495444741100073
Sample Time (s)              20.06239968771115
Epoch Time (s)               69.86906790593639
Total Train Time (s)         30021.72070159344
Epoch                        468
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:36:04.908491 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #468 | Epoch Duration: 70.46035480499268
2020-01-11 02:36:04.908692 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #468 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03338865
Z variance train             0.035897616
KL Divergence                6.0002155
KL Loss                      0.60002154
QF Loss                      1040.8475
VF Loss                      298.43555
Policy Loss                  -2715.0093
Q Predictions Mean           2709.79
Q Predictions Std            394.94812
Q Predictions Max            2923.8801
Q Predictions Min            19.026377
V Predictions Mean           2710.6973
V Predictions Std            392.3389
V Predictions Max            2923.0894
V Predictions Min            27.652824
Log Pis Mean                 -4.2471266
Log Pis Std                  4.7311883
Log Pis Max                  18.440548
Log Pis Min                  -13.983469
Policy mu Mean               0.3483645
Policy mu Std                0.6980789
Policy mu Max                2.5214245
Policy mu Min                -2.6793838
Policy log std Mean          -0.31495744
Policy log std Std           0.1427288
Policy log std Max           -0.051385373
Policy log std Min           -1.1200433
Z mean eval                  0.03399126
Z variance eval              0.03704943
total_rewards                [5549.53633229 3713.44413654 5410.9948347  4235.10168495 4799.00850029
 5565.32454843 5458.93112352 1390.2946435  5555.47722773 5601.24457503]
total_rewards_mean           4727.935760698403
total_rewards_std            1274.4270402090078
total_rewards_max            5601.2445750313755
total_rewards_min            1390.2946435027557
Number of train steps total  470000
Number of env steps total    2352000
Number of rollouts total     0
Train Time (s)               31.501400297041982
(Previous) Eval Time (s)     20.086389504838735
Sample Time (s)              18.81380237126723
Epoch Time (s)               70.40159217314795
Total Train Time (s)         30098.358128516935
Epoch                        469
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:37:21.552412 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #469 | Epoch Duration: 76.64354872703552
2020-01-11 02:37:21.552709 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #469 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03394275
Z variance train             0.03705004
KL Divergence                5.9239483
KL Loss                      0.5923948
QF Loss                      2333.9644
VF Loss                      741.97107
Policy Loss                  -2745.837
Q Predictions Mean           2745.8755
Q Predictions Std            275.80154
Q Predictions Max            2899.2441
Q Predictions Min            34.86496
V Predictions Mean           2749.2725
V Predictions Std            276.5105
V Predictions Max            2918.3462
V Predictions Min            45.04825
Log Pis Mean                 -4.0905437
Log Pis Std                  5.6832995
Log Pis Max                  25.05382
Log Pis Min                  -14.0344925
Policy mu Mean               0.3085554
Policy mu Std                0.72906214
Policy mu Max                3.1796246
Policy mu Min                -3.1652782
Policy log std Mean          -0.312976
Policy log std Std           0.13744853
Policy log std Max           -0.066947676
Policy log std Min           -1.2341154
Z mean eval                  0.037303902
Z variance eval              0.03628975
total_rewards                [1732.83365385 3561.01560773  774.36987237 5472.16247978 5303.78509142
 5531.20581612 1011.25783447 5572.08094887 5376.763089   5489.06196423]
total_rewards_mean           3982.4536357835723
total_rewards_std            1935.5327708467476
total_rewards_max            5572.080948870471
total_rewards_min            774.3698723712653
Number of train steps total  471000
Number of env steps total    2357000
Number of rollouts total     0
Train Time (s)               32.01471980381757
(Previous) Eval Time (s)     26.328025424852967
Sample Time (s)              19.10328495502472
Epoch Time (s)               77.44603018369526
Total Train Time (s)         30171.201039578766
Epoch                        470
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:38:34.402358 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #470 | Epoch Duration: 72.84942269325256
2020-01-11 02:38:34.402625 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #470 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03688187
Z variance train             0.036308303
KL Divergence                5.9744563
KL Loss                      0.59744567
QF Loss                      1987.1218
VF Loss                      928.5196
Policy Loss                  -2709.199
Q Predictions Mean           2710.1724
Q Predictions Std            389.88388
Q Predictions Max            2907.673
Q Predictions Min            219.01527
V Predictions Mean           2720.019
V Predictions Std            384.2773
V Predictions Max            2916.0176
V Predictions Min            235.45892
Log Pis Mean                 -4.43405
Log Pis Std                  5.4656544
Log Pis Max                  21.764849
Log Pis Min                  -16.791637
Policy mu Mean               0.32431424
Policy mu Std                0.7124758
Policy mu Max                2.6270456
Policy mu Min                -2.6693158
Policy log std Mean          -0.30574366
Policy log std Std           0.13498855
Policy log std Max           0.14863275
Policy log std Min           -0.9388198
Z mean eval                  0.035768982
Z variance eval              0.036283173
total_rewards                [5381.83663085 2355.19471308 5578.27939137 5596.37871651 1222.95122395
 4725.64315837 3366.22587293 5738.65580437 5616.08558594 5335.36974016]
total_rewards_mean           4491.662083752877
total_rewards_std            1526.2708873630252
total_rewards_max            5738.655804369517
total_rewards_min            1222.9512239477956
Number of train steps total  472000
Number of env steps total    2362000
Number of rollouts total     0
Train Time (s)               31.428330074064434
(Previous) Eval Time (s)     21.73115633195266
Sample Time (s)              20.237783506512642
Epoch Time (s)               73.39726991252974
Total Train Time (s)         30247.19989164034
Epoch                        471
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:39:50.405210 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #471 | Epoch Duration: 76.00238990783691
2020-01-11 02:39:50.405392 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #471 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03560672
Z variance train             0.036281783
KL Divergence                5.9926004
KL Loss                      0.59926003
QF Loss                      2166.4792
VF Loss                      369.6776
Policy Loss                  -2601.9714
Q Predictions Mean           2599.3584
Q Predictions Std            641.9522
Q Predictions Max            2923.739
Q Predictions Min            21.276234
V Predictions Mean           2600.5493
V Predictions Std            640.8295
V Predictions Max            2919.8315
V Predictions Min            31.779057
Log Pis Mean                 -4.752788
Log Pis Std                  5.5139666
Log Pis Max                  30.978086
Log Pis Min                  -14.425747
Policy mu Mean               0.30642065
Policy mu Std                0.69030654
Policy mu Max                2.7117743
Policy mu Min                -3.2489507
Policy log std Mean          -0.29177824
Policy log std Std           0.13053356
Policy log std Max           0.154066
Policy log std Min           -1.0299411
Z mean eval                  0.033390477
Z variance eval              0.03690773
total_rewards                [3846.38262087 3133.89334146 5494.23130634 5538.31244782 1838.04399622
 5552.37669076 3140.16776796 5509.19768428 5475.75835583 5411.12501097]
total_rewards_mean           4493.948922252995
total_rewards_std            1311.6046980834033
total_rewards_max            5552.376690755581
total_rewards_min            1838.043996220888
Number of train steps total  473000
Number of env steps total    2367000
Number of rollouts total     0
Train Time (s)               28.453983685933053
(Previous) Eval Time (s)     24.335908436216414
Sample Time (s)              20.03539204504341
Epoch Time (s)               72.82528416719288
Total Train Time (s)         30320.981333252043
Epoch                        472
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:41:04.194924 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #472 | Epoch Duration: 73.78935384750366
2020-01-11 02:41:04.195236 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #472 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032996558
Z variance train             0.03692033
KL Divergence                5.9415817
KL Loss                      0.5941582
QF Loss                      1886.7749
VF Loss                      392.91983
Policy Loss                  -2672.8489
Q Predictions Mean           2666.7305
Q Predictions Std            506.01544
Q Predictions Max            2897.5164
Q Predictions Min            21.414982
V Predictions Mean           2681.5034
V Predictions Std            507.32593
V Predictions Max            2914.4795
V Predictions Min            28.726936
Log Pis Mean                 -4.163163
Log Pis Std                  4.9918585
Log Pis Max                  16.047276
Log Pis Min                  -12.739212
Policy mu Mean               0.34924585
Policy mu Std                0.6748549
Policy mu Max                2.8930862
Policy mu Min                -2.5943317
Policy log std Mean          -0.3045716
Policy log std Std           0.13406274
Policy log std Max           -0.04794503
Policy log std Min           -1.033561
Z mean eval                  0.035924144
Z variance eval              0.03612288
total_rewards                [3161.46694063 3099.82273522 5597.54908412 5646.25939593 5117.28820716
 5498.34093822 5502.9247598  2754.68341418 3508.32094089 2654.37469519]
total_rewards_mean           4254.10311113476
total_rewards_std            1244.4081508616246
total_rewards_max            5646.259395934047
total_rewards_min            2654.374695192613
Number of train steps total  474000
Number of env steps total    2372000
Number of rollouts total     0
Train Time (s)               32.20330407191068
(Previous) Eval Time (s)     25.299604495987296
Sample Time (s)              19.993851841893047
Epoch Time (s)               77.49676040979102
Total Train Time (s)         30396.29530081246
Epoch                        473
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:42:19.512984 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #473 | Epoch Duration: 75.3175299167633
2020-01-11 02:42:19.513180 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #473 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03594558
Z variance train             0.036121853
KL Divergence                6.005596
KL Loss                      0.60055965
QF Loss                      959.5713
VF Loss                      550.29913
Policy Loss                  -2727.3943
Q Predictions Mean           2721.4746
Q Predictions Std            357.1439
Q Predictions Max            2902.3364
Q Predictions Min            30.867956
V Predictions Mean           2721.8066
V Predictions Std            357.54297
V Predictions Max            2907.4363
V Predictions Min            37.63821
Log Pis Mean                 -4.647414
Log Pis Std                  5.058338
Log Pis Max                  27.748787
Log Pis Min                  -16.679964
Policy mu Mean               0.31855172
Policy mu Std                0.6879926
Policy mu Max                3.3091502
Policy mu Min                -3.3383858
Policy log std Mean          -0.2993834
Policy log std Std           0.13722377
Policy log std Max           -0.014867768
Policy log std Min           -1.0641716
Z mean eval                  0.03713051
Z variance eval              0.03564293
total_rewards                [5414.98331328 5301.46393219 5415.3278008  5436.39788326 5500.75315016
 5430.06927771 2251.9707189  5281.42069576 5423.12431248 5434.22362559]
total_rewards_mean           5088.973471014497
total_rewards_std            947.6829291251132
total_rewards_max            5500.753150157345
total_rewards_min            2251.970718900166
Number of train steps total  475000
Number of env steps total    2377000
Number of rollouts total     0
Train Time (s)               31.23417479498312
(Previous) Eval Time (s)     23.120074230711907
Sample Time (s)              19.023327187635005
Epoch Time (s)               73.37757621333003
Total Train Time (s)         30474.551279626787
Epoch                        474
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:43:37.773888 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #474 | Epoch Duration: 78.26055335998535
2020-01-11 02:43:37.774102 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #474 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037114955
Z variance train             0.03564643
KL Divergence                6.0282593
KL Loss                      0.60282594
QF Loss                      2487.93
VF Loss                      420.05698
Policy Loss                  -2738.634
Q Predictions Mean           2733.457
Q Predictions Std            301.2858
Q Predictions Max            2910.3274
Q Predictions Min            28.790705
V Predictions Mean           2744.6875
V Predictions Std            304.15775
V Predictions Max            2934.8567
V Predictions Min            38.92727
Log Pis Mean                 -4.1061654
Log Pis Std                  4.841161
Log Pis Max                  21.054358
Log Pis Min                  -15.3761425
Policy mu Mean               0.35576522
Policy mu Std                0.7035019
Policy mu Max                2.6000412
Policy mu Min                -2.5595236
Policy log std Mean          -0.31988874
Policy log std Std           0.13730301
Policy log std Max           -0.06730181
Policy log std Min           -1.143746
Z mean eval                  0.037327386
Z variance eval              0.035130106
total_rewards                [5475.05537061 3941.74680898 5482.88592774 5581.40446783 5213.92505252
  403.7015655  5342.7043589  5540.61032731 5475.74357357 5433.92465673]
total_rewards_mean           4789.170210968932
total_rewards_std            1531.938216201517
total_rewards_max            5581.40446782546
total_rewards_min            403.7015655048847
Number of train steps total  476000
Number of env steps total    2382000
Number of rollouts total     0
Train Time (s)               31.01231661112979
(Previous) Eval Time (s)     28.002759478986263
Sample Time (s)              19.833444648887962
Epoch Time (s)               78.84852073900402
Total Train Time (s)         30551.130766639486
Epoch                        475
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:44:54.356864 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #475 | Epoch Duration: 76.5826063156128
2020-01-11 02:44:54.357025 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #475 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03732194
Z variance train             0.03512042
KL Divergence                6.0676317
KL Loss                      0.6067632
QF Loss                      1939.7346
VF Loss                      426.46185
Policy Loss                  -2735.8506
Q Predictions Mean           2737.143
Q Predictions Std            313.169
Q Predictions Max            2905.6345
Q Predictions Min            24.128742
V Predictions Mean           2730.1743
V Predictions Std            316.7001
V Predictions Max            2910.0913
V Predictions Min            35.385777
Log Pis Mean                 -3.7956991
Log Pis Std                  5.50396
Log Pis Max                  23.36824
Log Pis Min                  -16.7142
Policy mu Mean               0.35897395
Policy mu Std                0.7127179
Policy mu Max                3.053513
Policy mu Min                -3.1655722
Policy log std Mean          -0.31634802
Policy log std Std           0.13219625
Policy log std Max           0.017839357
Policy log std Min           -1.2561436
Z mean eval                  0.03711876
Z variance eval              0.03561674
total_rewards                [5352.61536183 5539.83444923 5574.27998855 5547.8655397  5450.93484371
 5549.82667208 5459.6256459  5361.34920197 5488.43169442 5607.47128216]
total_rewards_mean           5493.223467955889
total_rewards_std            82.51457380176159
total_rewards_max            5607.4712821633575
total_rewards_min            5352.6153618333365
Number of train steps total  477000
Number of env steps total    2387000
Number of rollouts total     0
Train Time (s)               30.080233500804752
(Previous) Eval Time (s)     25.736497839912772
Sample Time (s)              19.20473642833531
Epoch Time (s)               75.02146776905283
Total Train Time (s)         30630.18962248601
Epoch                        476
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:46:13.420542 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #476 | Epoch Duration: 79.06336832046509
2020-01-11 02:46:13.420758 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #476 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036846325
Z variance train             0.03561736
KL Divergence                6.0152826
KL Loss                      0.6015283
QF Loss                      2209.2512
VF Loss                      629.881
Policy Loss                  -2730.4617
Q Predictions Mean           2732.269
Q Predictions Std            388.45917
Q Predictions Max            2927.9736
Q Predictions Min            22.384275
V Predictions Mean           2746.5427
V Predictions Std            391.29117
V Predictions Max            2947.797
V Predictions Min            31.725595
Log Pis Mean                 -4.137735
Log Pis Std                  4.909922
Log Pis Max                  16.962835
Log Pis Min                  -13.603334
Policy mu Mean               0.32690912
Policy mu Std                0.6942258
Policy mu Max                2.5613859
Policy mu Min                -2.5270824
Policy log std Mean          -0.31394663
Policy log std Std           0.13875
Policy log std Max           -0.08229078
Policy log std Min           -1.2162322
Z mean eval                  0.036087293
Z variance eval              0.036586888
total_rewards                [4186.41375562 5457.86911014 5398.20374521 5577.74203232 5661.33601064
 2940.6718853  5476.42608895 5540.77334393 5603.79641028 5590.27548742]
total_rewards_mean           5143.350786980785
total_rewards_std            840.7755219556426
total_rewards_max            5661.336010639975
total_rewards_min            2940.6718853037432
Number of train steps total  478000
Number of env steps total    2392000
Number of rollouts total     0
Train Time (s)               31.76061797887087
(Previous) Eval Time (s)     29.77810158394277
Sample Time (s)              19.261293671559542
Epoch Time (s)               80.80001323437318
Total Train Time (s)         30708.43220079923
Epoch                        477
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:47:31.670960 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #477 | Epoch Duration: 78.25000715255737
2020-01-11 02:47:31.671247 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #477 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036150355
Z variance train             0.036585845
KL Divergence                5.9595356
KL Loss                      0.5959536
QF Loss                      1086.7727
VF Loss                      503.21286
Policy Loss                  -2713.718
Q Predictions Mean           2706.2017
Q Predictions Std            416.4503
Q Predictions Max            2895.438
Q Predictions Min            17.901802
V Predictions Mean           2702.0012
V Predictions Std            416.0115
V Predictions Max            2898.0134
V Predictions Min            29.969011
Log Pis Mean                 -4.2766795
Log Pis Std                  4.8691745
Log Pis Max                  18.133137
Log Pis Min                  -18.962591
Policy mu Mean               0.3292651
Policy mu Std                0.71209544
Policy mu Max                2.7637153
Policy mu Min                -3.0353878
Policy log std Mean          -0.3003439
Policy log std Std           0.1299981
Policy log std Max           -0.009397902
Policy log std Min           -0.99166757
Z mean eval                  0.037535798
Z variance eval              0.03538452
total_rewards                [5490.0576767  5512.10901339 5378.60856344 3159.13409569 5415.57443044
 5540.7210044  5534.12390381 5340.47798951 5493.52673192 5538.55441361]
total_rewards_mean           5240.288782290918
total_rewards_std            696.9262020075137
total_rewards_max            5540.721004403947
total_rewards_min            3159.1340956879735
Number of train steps total  479000
Number of env steps total    2397000
Number of rollouts total     0
Train Time (s)               32.09638545010239
(Previous) Eval Time (s)     27.227768673095852
Sample Time (s)              19.71371013438329
Epoch Time (s)               79.03786425758153
Total Train Time (s)         30788.693881744053
Epoch                        478
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:48:51.935553 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #478 | Epoch Duration: 80.26406025886536
2020-01-11 02:48:51.935709 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #478 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03762486
Z variance train             0.035384595
KL Divergence                6.02826
KL Loss                      0.60282606
QF Loss                      1366.6941
VF Loss                      659.9212
Policy Loss                  -2683.0378
Q Predictions Mean           2678.6719
Q Predictions Std            509.403
Q Predictions Max            2908.3198
Q Predictions Min            22.319458
V Predictions Mean           2679.237
V Predictions Std            507.2268
V Predictions Max            2901.4397
V Predictions Min            30.805017
Log Pis Mean                 -4.895649
Log Pis Std                  5.1042786
Log Pis Max                  26.708273
Log Pis Min                  -17.316631
Policy mu Mean               0.30657846
Policy mu Std                0.68506676
Policy mu Max                3.345655
Policy mu Min                -3.7754638
Policy log std Mean          -0.30030417
Policy log std Std           0.13425453
Policy log std Max           -0.007863916
Policy log std Min           -1.2325783
Z mean eval                  0.03871145
Z variance eval              0.036250886
total_rewards                [5729.72170944 5632.73553308 5510.43311322 5657.69303073 5496.68143605
 4573.68927479 2219.68593606 5691.91259848 5562.59100802 5478.50335197]
total_rewards_mean           5155.36469918472
total_rewards_std            1027.9768936035496
total_rewards_max            5729.721709439554
total_rewards_min            2219.6859360612384
Number of train steps total  480000
Number of env steps total    2402000
Number of rollouts total     0
Train Time (s)               29.461386275012046
(Previous) Eval Time (s)     28.45366272702813
Sample Time (s)              19.3025148534216
Epoch Time (s)               77.21756385546178
Total Train Time (s)         30865.018540795892
Epoch                        479
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:50:08.269562 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #479 | Epoch Duration: 76.33363962173462
2020-01-11 02:50:08.269858 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #479 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.038602944
Z variance train             0.036250256
KL Divergence                5.9830256
KL Loss                      0.59830254
QF Loss                      2926.0312
VF Loss                      782.0966
Policy Loss                  -2726.1226
Q Predictions Mean           2730.542
Q Predictions Std            365.11713
Q Predictions Max            2910.6235
Q Predictions Min            27.229721
V Predictions Mean           2725.1428
V Predictions Std            369.23706
V Predictions Max            2911.0984
V Predictions Min            37.75028
Log Pis Mean                 -4.6195183
Log Pis Std                  5.599109
Log Pis Max                  20.930803
Log Pis Min                  -15.4980135
Policy mu Mean               0.24418004
Policy mu Std                0.72893643
Policy mu Max                3.0666087
Policy mu Min                -4.066982
Policy log std Mean          -0.312987
Policy log std Std           0.13182795
Policy log std Max           0.010569915
Policy log std Min           -1.19043
Z mean eval                  0.03636504
Z variance eval              0.03600625
total_rewards                [5564.3166417  5420.31480675 5651.72677398 5500.17957416 5513.77024462
 1168.55944314 5365.29414257 1790.2159418  5435.21294923 5426.44323881]
total_rewards_mean           4683.603375677287
total_rewards_std            1609.9779882755295
total_rewards_max            5651.726773981297
total_rewards_min            1168.5594431424909
Number of train steps total  481000
Number of env steps total    2407000
Number of rollouts total     0
Train Time (s)               29.857517438940704
(Previous) Eval Time (s)     27.56938197510317
Sample Time (s)              19.845366931986064
Epoch Time (s)               77.27226634602994
Total Train Time (s)         30939.970234921668
Epoch                        480
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:51:23.226355 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #480 | Epoch Duration: 74.95623540878296
2020-01-11 02:51:23.226583 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #480 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036705337
Z variance train             0.036011428
KL Divergence                6.0082073
KL Loss                      0.6008207
QF Loss                      1141.4257
VF Loss                      544.36694
Policy Loss                  -2717.5107
Q Predictions Mean           2715.46
Q Predictions Std            468.9845
Q Predictions Max            2923.0952
Q Predictions Min            21.809067
V Predictions Mean           2707.651
V Predictions Std            473.32196
V Predictions Max            2919.6711
V Predictions Min            31.871666
Log Pis Mean                 -4.553033
Log Pis Std                  4.6667523
Log Pis Max                  13.217104
Log Pis Min                  -14.84268
Policy mu Mean               0.3047463
Policy mu Std                0.69532216
Policy mu Max                2.6645103
Policy mu Min                -3.086676
Policy log std Mean          -0.30966926
Policy log std Std           0.13800117
Policy log std Max           0.08125447
Policy log std Min           -1.2948809
Z mean eval                  0.041280843
Z variance eval              0.037012372
total_rewards                [4971.29482591 4432.6419229  5225.28094976 1275.05395098 5257.68179584
 3794.57240383 2283.3663503  5168.31920368 5129.2376214  2626.91433314]
total_rewards_mean           4016.436335775606
total_rewards_std            1383.8656805064766
total_rewards_max            5257.68179584282
total_rewards_min            1275.0539509809787
Number of train steps total  482000
Number of env steps total    2412000
Number of rollouts total     0
Train Time (s)               32.954261530190706
(Previous) Eval Time (s)     25.253041389863938
Sample Time (s)              19.914213862270117
Epoch Time (s)               78.12151678232476
Total Train Time (s)         31016.071686711162
Epoch                        481
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:52:39.335087 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #481 | Epoch Duration: 76.10830330848694
2020-01-11 02:52:39.335385 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #481 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.041549683
Z variance train             0.037010632
KL Divergence                5.9357524
KL Loss                      0.59357524
QF Loss                      1509.7557
VF Loss                      552.4067
Policy Loss                  -2711.2625
Q Predictions Mean           2709.0283
Q Predictions Std            401.24905
Q Predictions Max            2923.0776
Q Predictions Min            15.749563
V Predictions Mean           2707.9883
V Predictions Std            398.0269
V Predictions Max            2921.7864
V Predictions Min            29.107414
Log Pis Mean                 -3.8472862
Log Pis Std                  5.8906817
Log Pis Max                  38.685555
Log Pis Min                  -14.103808
Policy mu Mean               0.2798294
Policy mu Std                0.7551509
Policy mu Max                3.271802
Policy mu Min                -3.6394227
Policy log std Mean          -0.3081035
Policy log std Std           0.13450307
Policy log std Max           -0.019942246
Policy log std Min           -1.0509138
Z mean eval                  0.04184975
Z variance eval              0.036473252
total_rewards                [1039.46333479 5511.66497268 5620.38932765 2906.92106287 1681.56279585
 1190.94672864 5576.60785579 3897.31524328 5568.91100054 2338.94784058]
total_rewards_mean           3533.27301626771
total_rewards_std            1835.0693322950979
total_rewards_max            5620.389327650182
total_rewards_min            1039.4633347904798
Number of train steps total  483000
Number of env steps total    2417000
Number of rollouts total     0
Train Time (s)               32.29400617396459
(Previous) Eval Time (s)     23.23946291487664
Sample Time (s)              20.16702971374616
Epoch Time (s)               75.70049880258739
Total Train Time (s)         31087.818566557486
Epoch                        482
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:53:51.089153 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #482 | Epoch Duration: 71.75354051589966
2020-01-11 02:53:51.089435 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #482 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04160794
Z variance train             0.036457304
KL Divergence                5.9583626
KL Loss                      0.5958363
QF Loss                      1529.0161
VF Loss                      414.20285
Policy Loss                  -2707.5532
Q Predictions Mean           2704.5042
Q Predictions Std            434.74823
Q Predictions Max            2913.7112
Q Predictions Min            23.812716
V Predictions Mean           2721.6504
V Predictions Std            439.78406
V Predictions Max            2934.569
V Predictions Min            30.324097
Log Pis Mean                 -4.236246
Log Pis Std                  5.1775246
Log Pis Max                  23.808502
Log Pis Min                  -16.310658
Policy mu Mean               0.36111754
Policy mu Std                0.6846224
Policy mu Max                2.7343135
Policy mu Min                -3.75817
Policy log std Mean          -0.30140284
Policy log std Std           0.13561243
Policy log std Max           0.02339881
Policy log std Min           -1.0193332
Z mean eval                  0.04116934
Z variance eval              0.03707185
total_rewards                [2117.84326562 2489.37380001 4440.6087796  5766.99156197 5718.96775309
 4764.22775698 4770.37937204 4444.93430666 1250.76024179 5658.84010508]
total_rewards_mean           4142.292694282494
total_rewards_std            1535.5404102222133
total_rewards_max            5766.991561967872
total_rewards_min            1250.7602417932815
Number of train steps total  484000
Number of env steps total    2422000
Number of rollouts total     0
Train Time (s)               31.406257866881788
(Previous) Eval Time (s)     19.292165184859186
Sample Time (s)              19.59489080356434
Epoch Time (s)               70.29331385530531
Total Train Time (s)         31161.119627477136
Epoch                        483
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:55:04.397741 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #483 | Epoch Duration: 73.30806994438171
2020-01-11 02:55:04.398031 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #483 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040907927
Z variance train             0.037068006
KL Divergence                5.901831
KL Loss                      0.59018314
QF Loss                      928.97424
VF Loss                      331.56873
Policy Loss                  -2749.4978
Q Predictions Mean           2745.1855
Q Predictions Std            347.1449
Q Predictions Max            2910.8264
Q Predictions Min            24.905947
V Predictions Mean           2759.339
V Predictions Std            349.25146
V Predictions Max            2922.6917
V Predictions Min            35.47615
Log Pis Mean                 -4.5865307
Log Pis Std                  4.8047543
Log Pis Max                  17.904305
Log Pis Min                  -13.96867
Policy mu Mean               0.35579896
Policy mu Std                0.66890305
Policy mu Max                2.695564
Policy mu Min                -2.4387002
Policy log std Mean          -0.29617187
Policy log std Std           0.13420177
Policy log std Max           -0.038202554
Policy log std Min           -0.96503896
Z mean eval                  0.040479902
Z variance eval              0.03793333
total_rewards                [5632.41265461 3091.31402344 5486.70608234 5574.40206786 5574.75394582
 5488.39657907 5479.21783585 5621.56478241 2025.15610148 5539.35090292]
total_rewards_mean           4951.327497581298
total_rewards_std            1221.1314339872051
total_rewards_max            5632.4126546126945
total_rewards_min            2025.1561014782244
Number of train steps total  485000
Number of env steps total    2427000
Number of rollouts total     0
Train Time (s)               31.817463683430105
(Previous) Eval Time (s)     22.306617283727974
Sample Time (s)              19.49273769231513
Epoch Time (s)               73.61681865947321
Total Train Time (s)         31238.56363551505
Epoch                        484
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:56:21.848575 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #484 | Epoch Duration: 77.45032739639282
2020-01-11 02:56:21.848800 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #484 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040282693
Z variance train             0.03794384
KL Divergence                5.8194947
KL Loss                      0.5819495
QF Loss                      1334.3767
VF Loss                      893.1137
Policy Loss                  -2712.007
Q Predictions Mean           2713.3901
Q Predictions Std            442.48026
Q Predictions Max            2908.585
Q Predictions Min            23.856657
V Predictions Mean           2713.2808
V Predictions Std            442.1408
V Predictions Max            2909.3252
V Predictions Min            29.620306
Log Pis Mean                 -3.7667255
Log Pis Std                  5.730466
Log Pis Max                  23.37125
Log Pis Min                  -12.767569
Policy mu Mean               0.28044683
Policy mu Std                0.7353079
Policy mu Max                3.1705027
Policy mu Min                -3.1882014
Policy log std Mean          -0.31065547
Policy log std Std           0.1427117
Policy log std Max           0.04703866
Policy log std Min           -1.3631735
Z mean eval                  0.041167002
Z variance eval              0.037803184
total_rewards                [5699.93629741 5661.56471442 5699.06235941 5559.56020305 5534.75102672
 5517.57787104 5589.02117789 5729.40713953 5589.3757672  5594.31427066]
total_rewards_mean           5617.4570827331645
total_rewards_std            70.88123055214811
total_rewards_max            5729.407139525413
total_rewards_min            5517.577871041696
Number of train steps total  486000
Number of env steps total    2432000
Number of rollouts total     0
Train Time (s)               33.04167764959857
(Previous) Eval Time (s)     26.139790375716984
Sample Time (s)              20.184817366767675
Epoch Time (s)               79.36628539208323
Total Train Time (s)         31321.849368033
Epoch                        485
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:57:45.136966 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #485 | Epoch Duration: 83.28799390792847
2020-01-11 02:57:45.137119 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #485 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04103646
Z variance train             0.03780017
KL Divergence                5.842179
KL Loss                      0.5842179
QF Loss                      1259.8135
VF Loss                      381.04068
Policy Loss                  -2680.074
Q Predictions Mean           2676.3281
Q Predictions Std            485.87982
Q Predictions Max            2912.008
Q Predictions Min            20.214014
V Predictions Mean           2681.002
V Predictions Std            487.7801
V Predictions Max            2914.0037
V Predictions Min            33.130196
Log Pis Mean                 -4.279606
Log Pis Std                  5.374944
Log Pis Max                  20.978523
Log Pis Min                  -13.400396
Policy mu Mean               0.34563798
Policy mu Std                0.6917085
Policy mu Max                3.1077669
Policy mu Min                -3.1683304
Policy log std Mean          -0.31799945
Policy log std Std           0.13979982
Policy log std Max           0.14596659
Policy log std Min           -0.9933375
Z mean eval                  0.038744032
Z variance eval              0.038112517
total_rewards                [2751.65910062 5691.58605869 4418.06966921 5542.04775198  724.33270455
 5607.78485014 5628.77811015 2418.57354142 5629.18165124 5521.06510991]
total_rewards_mean           4393.307854791635
total_rewards_std            1698.8899104556967
total_rewards_max            5691.586058690151
total_rewards_min            724.3327045493411
Number of train steps total  487000
Number of env steps total    2437000
Number of rollouts total     0
Train Time (s)               31.593985029961914
(Previous) Eval Time (s)     30.06113355886191
Sample Time (s)              19.770034471526742
Epoch Time (s)               81.42515306035057
Total Train Time (s)         31396.990445259493
Epoch                        486
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:59:00.282252 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #486 | Epoch Duration: 75.14501404762268
2020-01-11 02:59:00.282453 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #486 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.038641714
Z variance train             0.038120415
KL Divergence                5.8136535
KL Loss                      0.58136535
QF Loss                      1502.8423
VF Loss                      453.11554
Policy Loss                  -2743.5713
Q Predictions Mean           2739.4224
Q Predictions Std            311.31653
Q Predictions Max            2904.1475
Q Predictions Min            286.2601
V Predictions Mean           2744.7302
V Predictions Std            307.5333
V Predictions Max            2907.6733
V Predictions Min            284.55228
Log Pis Mean                 -4.163316
Log Pis Std                  6.2844954
Log Pis Max                  38.743538
Log Pis Min                  -15.191955
Policy mu Mean               0.36788586
Policy mu Std                0.6884985
Policy mu Max                3.1761496
Policy mu Min                -3.9373555
Policy log std Mean          -0.3107889
Policy log std Std           0.13818815
Policy log std Max           0.056685716
Policy log std Min           -1.3646119
Z mean eval                  0.04033474
Z variance eval              0.038151685
total_rewards                [5516.36733106 5485.39636966 4552.21414396 5545.54649581 5349.63280522
 5541.28082301 5237.90460968 5505.01774624 5475.64355786 5575.96042797]
total_rewards_mean           5378.496431046678
total_rewards_std            291.99645356919876
total_rewards_max            5575.960427974569
total_rewards_min            4552.214143955553
Number of train steps total  488000
Number of env steps total    2442000
Number of rollouts total     0
Train Time (s)               29.49036880629137
(Previous) Eval Time (s)     23.780649254098535
Sample Time (s)              19.735813598614186
Epoch Time (s)               73.00683165900409
Total Train Time (s)         31474.84763625916
Epoch                        487
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:00:18.143737 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #487 | Epoch Duration: 77.86113691329956
2020-01-11 03:00:18.143961 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #487 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040650103
Z variance train             0.03813371
KL Divergence                5.801001
KL Loss                      0.5801001
QF Loss                      1780.9802
VF Loss                      708.64996
Policy Loss                  -2730.1365
Q Predictions Mean           2724.3535
Q Predictions Std            417.6548
Q Predictions Max            2932.0525
Q Predictions Min            17.385746
V Predictions Mean           2725.5703
V Predictions Std            419.56268
V Predictions Max            2922.487
V Predictions Min            20.692547
Log Pis Mean                 -4.6541357
Log Pis Std                  4.953452
Log Pis Max                  17.753294
Log Pis Min                  -15.104097
Policy mu Mean               0.28919804
Policy mu Std                0.690829
Policy mu Max                2.774557
Policy mu Min                -2.4655404
Policy log std Mean          -0.3013203
Policy log std Std           0.13569675
Policy log std Max           0.0064121857
Policy log std Min           -1.1664548
Z mean eval                  0.045181394
Z variance eval              0.037095647
total_rewards                [5615.15397181 5600.2826652  3756.75298926 5574.5048604  5167.71355888
 5512.07933555 1181.0536887  5416.00349919 5612.15512897 3654.86421996]
total_rewards_mean           4709.0563917908685
total_rewards_std            1378.4004466134222
total_rewards_max            5615.153971805134
total_rewards_min            1181.0536886984391
Number of train steps total  489000
Number of env steps total    2447000
Number of rollouts total     0
Train Time (s)               31.86805485188961
(Previous) Eval Time (s)     28.634595266077667
Sample Time (s)              19.96292294980958
Epoch Time (s)               80.46557306777686
Total Train Time (s)         31551.258406898938
Epoch                        488
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:01:34.560974 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #488 | Epoch Duration: 76.4168381690979
2020-01-11 03:01:34.561219 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #488 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045116957
Z variance train             0.03709206
KL Divergence                5.8585887
KL Loss                      0.5858589
QF Loss                      1194.5063
VF Loss                      603.6268
Policy Loss                  -2709.3909
Q Predictions Mean           2706.4521
Q Predictions Std            488.93564
Q Predictions Max            2923.6611
Q Predictions Min            22.507978
V Predictions Mean           2697.7183
V Predictions Std            492.27695
V Predictions Max            2921.326
V Predictions Min            32.39066
Log Pis Mean                 -4.7757893
Log Pis Std                  5.136963
Log Pis Max                  35.831463
Log Pis Min                  -14.200153
Policy mu Mean               0.32079247
Policy mu Std                0.65683866
Policy mu Max                3.1455977
Policy mu Min                -3.6631567
Policy log std Mean          -0.29220837
Policy log std Std           0.13133532
Policy log std Max           0.010835625
Policy log std Min           -1.0073868
Z mean eval                  0.046631455
Z variance eval              0.035114802
total_rewards                [ 762.03180033 5546.3631692  4844.51756409 5660.05680144 1989.30688405
 5669.20691025 5702.72571578 5617.09249849 3067.11223606 5684.32694588]
total_rewards_mean           4454.274052557957
total_rewards_std            1741.5988296175985
total_rewards_max            5702.725715777084
total_rewards_min            762.0318003331965
Number of train steps total  490000
Number of env steps total    2452000
Number of rollouts total     0
Train Time (s)               32.36793262604624
(Previous) Eval Time (s)     24.585522880777717
Sample Time (s)              19.792562746442854
Epoch Time (s)               76.74601825326681
Total Train Time (s)         31626.155765139963
Epoch                        489
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:02:49.466154 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #489 | Epoch Duration: 74.9047360420227
2020-01-11 03:02:49.466422 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #489 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046631224
Z variance train             0.035113987
KL Divergence                6.007309
KL Loss                      0.6007309
QF Loss                      1413.467
VF Loss                      395.09885
Policy Loss                  -2759.228
Q Predictions Mean           2759.6123
Q Predictions Std            296.84872
Q Predictions Max            2951.959
Q Predictions Min            29.826975
V Predictions Mean           2753.2065
V Predictions Std            296.09375
V Predictions Max            2931.9504
V Predictions Min            33.75459
Log Pis Mean                 -4.5704265
Log Pis Std                  5.5068264
Log Pis Max                  21.927584
Log Pis Min                  -14.800752
Policy mu Mean               0.3127924
Policy mu Std                0.69426
Policy mu Max                4.3044243
Policy mu Min                -3.0631466
Policy log std Mean          -0.30154097
Policy log std Std           0.12751144
Policy log std Max           -0.07486793
Policy log std Min           -0.9605763
Z mean eval                  0.046030324
Z variance eval              0.037385613
total_rewards                [ 989.61433794 5482.71727852 5509.38055267 5541.96172828 5456.55443228
 5460.59958933 5502.57732157 5549.40029388 5522.09395745 5572.18062402]
total_rewards_mean           5058.708011594905
total_rewards_std            1356.831796167167
total_rewards_max            5572.180624024679
total_rewards_min            989.6143379352325
Number of train steps total  491000
Number of env steps total    2457000
Number of rollouts total     0
Train Time (s)               31.79750581085682
(Previous) Eval Time (s)     22.743915356695652
Sample Time (s)              19.416956163942814
Epoch Time (s)               73.95837733149529
Total Train Time (s)         31704.33221264975
Epoch                        490
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:04:07.675273 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #490 | Epoch Duration: 78.20862221717834
2020-01-11 03:04:07.675574 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #490 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04610359
Z variance train             0.037400924
KL Divergence                5.852235
KL Loss                      0.5852235
QF Loss                      1830.8916
VF Loss                      899.1086
Policy Loss                  -2714.148
Q Predictions Mean           2710.8687
Q Predictions Std            441.619
Q Predictions Max            2941.127
Q Predictions Min            21.840445
V Predictions Mean           2720.5222
V Predictions Std            433.80875
V Predictions Max            2930.178
V Predictions Min            32.306805
Log Pis Mean                 -4.4665613
Log Pis Std                  5.122477
Log Pis Max                  21.015741
Log Pis Min                  -16.124859
Policy mu Mean               0.2694839
Policy mu Std                0.704626
Policy mu Max                2.9947355
Policy mu Min                -3.1926374
Policy log std Mean          -0.3166508
Policy log std Std           0.13448045
Policy log std Max           -0.03415961
Policy log std Min           -1.5550392
Z mean eval                  0.0442466
Z variance eval              0.0367988
total_rewards                [2433.23570771 5526.93423898 5569.92790083 5537.91235036 5417.01907996
  247.30118922 1532.36109931 5542.64003051 5659.45570319 3306.7887195 ]
total_rewards_mean           4077.3576019567167
total_rewards_std            1932.622340209269
total_rewards_max            5659.455703188111
total_rewards_min            247.30118921880168
Number of train steps total  492000
Number of env steps total    2462000
Number of rollouts total     0
Train Time (s)               30.009207881055772
(Previous) Eval Time (s)     26.993801242671907
Sample Time (s)              20.395893364213407
Epoch Time (s)               77.39890248794109
Total Train Time (s)         31776.944143049885
Epoch                        491
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:05:20.268338 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #491 | Epoch Duration: 72.59247875213623
2020-01-11 03:05:20.268638 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #491 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.044193957
Z variance train             0.036795232
KL Divergence                5.8833914
KL Loss                      0.58833915
QF Loss                      1337.4957
VF Loss                      548.76587
Policy Loss                  -2768.8662
Q Predictions Mean           2765.7961
Q Predictions Std            300.8679
Q Predictions Max            2944.9465
Q Predictions Min            25.979183
V Predictions Mean           2769.1309
V Predictions Std            300.44562
V Predictions Max            2949.19
V Predictions Min            33.421017
Log Pis Mean                 -4.9647083
Log Pis Std                  4.666768
Log Pis Max                  15.706306
Log Pis Min                  -16.262669
Policy mu Mean               0.30934262
Policy mu Std                0.6755263
Policy mu Max                2.7015011
Policy mu Min                -2.7026312
Policy log std Mean          -0.298696
Policy log std Std           0.12594482
Policy log std Max           0.04976538
Policy log std Min           -1.0664815
Z mean eval                  0.045412496
Z variance eval              0.036677487
total_rewards                [5528.20001432 5423.41296109 5486.27520689 3613.98421735 5532.38671903
 5470.78739619 5230.91947737 3527.87822971 5463.7364335  5497.27215846]
total_rewards_mean           5077.485281389197
total_rewards_std            757.8661630499538
total_rewards_max            5532.386719030025
total_rewards_min            3527.8782297055727
Number of train steps total  493000
Number of env steps total    2467000
Number of rollouts total     0
Train Time (s)               32.21600359631702
(Previous) Eval Time (s)     22.18698224099353
Sample Time (s)              19.366404846310616
Epoch Time (s)               73.76939068362117
Total Train Time (s)         31855.891621650197
Epoch                        492
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:06:39.221648 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #492 | Epoch Duration: 78.95280718803406
2020-01-11 03:06:39.221936 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #492 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045898948
Z variance train             0.036684036
KL Divergence                5.8808002
KL Loss                      0.58808005
QF Loss                      1747.2341
VF Loss                      1157.225
Policy Loss                  -2726.3303
Q Predictions Mean           2722.4111
Q Predictions Std            448.7461
Q Predictions Max            2927.4983
Q Predictions Min            26.179602
V Predictions Mean           2708.9165
V Predictions Std            449.10214
V Predictions Max            2938.19
V Predictions Min            35.914684
Log Pis Mean                 -4.8028393
Log Pis Std                  5.859808
Log Pis Max                  44.75468
Log Pis Min                  -14.1545925
Policy mu Mean               0.29332355
Policy mu Std                0.6955156
Policy mu Max                4.879919
Policy mu Min                -3.2955952
Policy log std Mean          -0.29594544
Policy log std Std           0.13897258
Policy log std Max           0.040679857
Policy log std Min           -1.1429486
Z mean eval                  0.04336967
Z variance eval              0.03499118
total_rewards                [5429.80788757 5011.15614028 5496.43051916 5485.08830264 2763.61053241
 5483.84705166 5425.77485114 2693.6317     5421.00016855 2320.59207329]
total_rewards_mean           4553.093922669703
total_rewards_std            1294.6812557823193
total_rewards_max            5496.430519161263
total_rewards_min            2320.5920732861205
Number of train steps total  494000
Number of env steps total    2472000
Number of rollouts total     0
Train Time (s)               28.821756469085813
(Previous) Eval Time (s)     27.37008803198114
Sample Time (s)              19.1509073455818
Epoch Time (s)               75.34275184664875
Total Train Time (s)         31928.63942333823
Epoch                        493
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:07:51.973817 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #493 | Epoch Duration: 72.75162935256958
2020-01-11 03:07:51.974071 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #493 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04317501
Z variance train             0.03499817
KL Divergence                5.9906187
KL Loss                      0.5990619
QF Loss                      2222.6294
VF Loss                      561.6264
Policy Loss                  -2723.285
Q Predictions Mean           2722.247
Q Predictions Std            422.65274
Q Predictions Max            2916.166
Q Predictions Min            26.105988
V Predictions Mean           2729.3772
V Predictions Std            421.52127
V Predictions Max            2934.4634
V Predictions Min            35.42201
Log Pis Mean                 -4.541625
Log Pis Std                  5.9171147
Log Pis Max                  26.775564
Log Pis Min                  -14.822134
Policy mu Mean               0.286439
Policy mu Std                0.7050682
Policy mu Max                3.305591
Policy mu Min                -3.2473683
Policy log std Mean          -0.29464963
Policy log std Std           0.1334746
Policy log std Max           -0.010133624
Policy log std Min           -1.1603467
Z mean eval                  0.047232926
Z variance eval              0.035093687
total_rewards                [1816.52090724 1047.75428653 2000.32250705 3009.04804659 5133.88062618
 4600.67717946 5562.02917152 5641.36117765 5555.68823081 1503.20933926]
total_rewards_mean           3587.0491472306867
total_rewards_std            1794.2512910559449
total_rewards_max            5641.361177653052
total_rewards_min            1047.7542865250402
Number of train steps total  495000
Number of env steps total    2477000
Number of rollouts total     0
Train Time (s)               32.535681072156876
(Previous) Eval Time (s)     24.77866714214906
Sample Time (s)              19.029133828822523
Epoch Time (s)               76.34348204312846
Total Train Time (s)         31998.59157267306
Epoch                        494
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:09:01.932286 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #494 | Epoch Duration: 69.9580352306366
2020-01-11 03:09:01.932565 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #494 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.047272086
Z variance train             0.035099138
KL Divergence                5.9797735
KL Loss                      0.59797734
QF Loss                      1486.8052
VF Loss                      414.2725
Policy Loss                  -2705.1877
Q Predictions Mean           2702.859
Q Predictions Std            493.5922
Q Predictions Max            2924.065
Q Predictions Min            18.186659
V Predictions Mean           2698.7273
V Predictions Std            490.0307
V Predictions Max            2929.4714
V Predictions Min            24.290445
Log Pis Mean                 -4.2136526
Log Pis Std                  4.6065536
Log Pis Max                  19.170212
Log Pis Min                  -13.416446
Policy mu Mean               0.33820057
Policy mu Std                0.6886091
Policy mu Max                2.5837612
Policy mu Min                -2.9549856
Policy log std Mean          -0.30523193
Policy log std Std           0.13136014
Policy log std Max           -0.0043094456
Policy log std Min           -1.3542631
Z mean eval                  0.04725466
Z variance eval              0.035808552
total_rewards                [5580.4419328  5454.41122483 5595.45498462 5611.49052375 5620.49495107
 5569.65302648 5539.8052017  5521.72694541 5596.92007969 3041.87767429]
total_rewards_mean           5313.227654463852
total_rewards_std            758.5801146183044
total_rewards_max            5620.494951070175
total_rewards_min            3041.877674291408
Number of train steps total  496000
Number of env steps total    2482000
Number of rollouts total     0
Train Time (s)               32.94226002506912
(Previous) Eval Time (s)     18.392918994184583
Sample Time (s)              19.731580194551498
Epoch Time (s)               71.0667592138052
Total Train Time (s)         32080.19765431527
Epoch                        495
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:10:23.546114 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #495 | Epoch Duration: 81.61332559585571
2020-01-11 03:10:23.546409 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #495 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.047338083
Z variance train             0.035788428
KL Divergence                5.944559
KL Loss                      0.5944559
QF Loss                      1264.7622
VF Loss                      609.0159
Policy Loss                  -2721.4548
Q Predictions Mean           2716.483
Q Predictions Std            452.75818
Q Predictions Max            2934.1394
Q Predictions Min            20.670332
V Predictions Mean           2721.9568
V Predictions Std            457.31024
V Predictions Max            2948.9219
V Predictions Min            34.019497
Log Pis Mean                 -3.839324
Log Pis Std                  5.9831305
Log Pis Max                  24.905828
Log Pis Min                  -17.72991
Policy mu Mean               0.31509706
Policy mu Std                0.7326799
Policy mu Max                2.9885936
Policy mu Min                -3.1534128
Policy log std Mean          -0.31511128
Policy log std Std           0.13304998
Policy log std Max           -0.04047288
Policy log std Min           -1.1253307
Z mean eval                  0.043357544
Z variance eval              0.034319572
total_rewards                [5659.33194628 5652.01710534 5569.38026818 5540.61665092 5601.40982374
 5588.40623264 3517.02917827 3516.24486119 2765.2950258  5591.66234961]
total_rewards_mean           4900.139344196868
total_rewards_std            1087.6213388275926
total_rewards_max            5659.33194628181
total_rewards_min            2765.2950258017463
Number of train steps total  497000
Number of env steps total    2487000
Number of rollouts total     0
Train Time (s)               29.343972472008318
(Previous) Eval Time (s)     28.939154313877225
Sample Time (s)              20.25920268986374
Epoch Time (s)               78.54232947574928
Total Train Time (s)         32156.915460674092
Epoch                        496
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:11:40.271190 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #496 | Epoch Duration: 76.72454261779785
2020-01-11 03:11:40.271485 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #496 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043304436
Z variance train             0.03432818
KL Divergence                6.040364
KL Loss                      0.6040364
QF Loss                      1482.0188
VF Loss                      576.5177
Policy Loss                  -2729.8938
Q Predictions Mean           2723.4585
Q Predictions Std            445.391
Q Predictions Max            2915.0703
Q Predictions Min            21.519392
V Predictions Mean           2733.5972
V Predictions Std            443.81277
V Predictions Max            2925.8188
V Predictions Min            30.38075
Log Pis Mean                 -4.8476076
Log Pis Std                  5.45749
Log Pis Max                  28.257437
Log Pis Min                  -15.113647
Policy mu Mean               0.22755516
Policy mu Std                0.7158712
Policy mu Max                2.7289078
Policy mu Min                -3.1779883
Policy log std Mean          -0.30380845
Policy log std Std           0.13370985
Policy log std Max           -0.07175194
Policy log std Min           -1.090986
Z mean eval                  0.04279068
Z variance eval              0.034116227
total_rewards                [5591.40146412 4497.13936783 1184.38328974 5577.01347546 4101.70087606
 2940.19093154  771.30928848 2341.29625894 5605.77157152 5636.89987875]
total_rewards_mean           3824.7106402442905
total_rewards_std            1801.5086796773926
total_rewards_max            5636.899878753611
total_rewards_min            771.309288478256
Number of train steps total  498000
Number of env steps total    2492000
Number of rollouts total     0
Train Time (s)               31.946435179095715
(Previous) Eval Time (s)     27.121050361078233
Sample Time (s)              19.91284481342882
Epoch Time (s)               78.98033035360277
Total Train Time (s)         32229.161813613027
Epoch                        497
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:12:52.541479 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #497 | Epoch Duration: 72.26977372169495
2020-01-11 03:12:52.541730 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #497 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04257941
Z variance train             0.03411479
KL Divergence                6.0479755
KL Loss                      0.60479754
QF Loss                      1263.2202
VF Loss                      442.7076
Policy Loss                  -2752.1594
Q Predictions Mean           2753.5166
Q Predictions Std            358.14413
Q Predictions Max            2928.475
Q Predictions Min            26.525108
V Predictions Mean           2758.2466
V Predictions Std            361.76495
V Predictions Max            2942.6138
V Predictions Min            36.37277
Log Pis Mean                 -4.771398
Log Pis Std                  4.9071155
Log Pis Max                  20.35107
Log Pis Min                  -16.427242
Policy mu Mean               0.2544836
Policy mu Std                0.71694416
Policy mu Max                2.782845
Policy mu Min                -2.716321
Policy log std Mean          -0.30845872
Policy log std Std           0.12752555
Policy log std Max           0.09519616
Policy log std Min           -1.0698482
Z mean eval                  0.04605601
Z variance eval              0.035068322
total_rewards                [5276.09729498 5375.7889994  5294.21559537 5398.67820677 5319.44715688
 5612.52554067 5268.34487533 5351.70700091 5247.24842419 5355.24857102]
total_rewards_mean           5349.9301665519615
total_rewards_std            99.35650151726391
total_rewards_max            5612.525540665871
total_rewards_min            5247.248424190533
Number of train steps total  499000
Number of env steps total    2497000
Number of rollouts total     0
Train Time (s)               32.03306670486927
(Previous) Eval Time (s)     20.410178993828595
Sample Time (s)              20.241992361843586
Epoch Time (s)               72.68523806054145
Total Train Time (s)         32312.41825700784
Epoch                        498
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:14:15.801561 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #498 | Epoch Duration: 83.2596492767334
2020-01-11 03:14:15.801772 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #498 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045883548
Z variance train             0.03507176
KL Divergence                5.9914875
KL Loss                      0.59914875
QF Loss                      951.3255
VF Loss                      591.7318
Policy Loss                  -2731.6458
Q Predictions Mean           2728.81
Q Predictions Std            447.19397
Q Predictions Max            2925.925
Q Predictions Min            13.662062
V Predictions Mean           2734.9531
V Predictions Std            450.9166
V Predictions Max            2945.3542
V Predictions Min            25.970102
Log Pis Mean                 -4.4203415
Log Pis Std                  5.3333316
Log Pis Max                  19.187576
Log Pis Min                  -15.170809
Policy mu Mean               0.24865809
Policy mu Std                0.7197956
Policy mu Max                3.4841042
Policy mu Min                -3.2808492
Policy log std Mean          -0.2932106
Policy log std Std           0.12427328
Policy log std Max           0.060363054
Policy log std Min           -0.9647664
Z mean eval                  0.044976037
Z variance eval              0.03351447
total_rewards                [4495.71573139 5257.53619692 3971.00791305 5597.13718934  873.26604807
 5624.30568624 3825.55409008 4841.60576016 5720.71887319 3269.47006814]
total_rewards_mean           4347.631755658143
total_rewards_std            1407.780308201846
total_rewards_max            5720.718873187191
total_rewards_min            873.266048068031
Number of train steps total  500000
Number of env steps total    2502000
Number of rollouts total     0
Train Time (s)               31.172312955837697
(Previous) Eval Time (s)     30.984246184118092
Sample Time (s)              20.008403926622123
Epoch Time (s)               82.16496306657791
Total Train Time (s)         32386.870821377262
Epoch                        499
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:15:30.258902 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #499 | Epoch Duration: 74.45696711540222
2020-01-11 03:15:30.259152 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #499 | Started Training: True
2020-01-11 03:15:31.247258 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Variant:
2020-01-11 03:15:31.247680 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] {
  "env_name": "Ant-v2",
  "n_train_tasks": 1,
  "n_eval_tasks": 1,
  "latent_size": 5,
  "net_size": 300,
  "path_to_weights": null,
  "env_params": {
    "n_tasks": 2,
    "randomize_tasks": true
  },
  "algo_params": {
    "meta_batch": 1,
    "num_iterations": 500,
    "num_initial_steps": 2000,
    "num_tasks_sample": 5,
    "num_steps_prior": 400,
    "num_steps_posterior": 0,
    "num_extra_rl_steps_posterior": 600,
    "num_train_steps_per_itr": 1000,
    "num_evals": 2,
    "num_steps_per_eval": 600,
    "batch_size": 256,
    "embedding_batch_size": 20,
    "embedding_mini_batch_size": 20,
    "max_path_length": 200,
    "discount": 0.99,
    "soft_target_tau": 0.005,
    "policy_lr": 0.0003,
    "qf_lr": 0.0003,
    "vf_lr": 0.0003,
    "context_lr": 0.0003,
    "reward_scale": 5.0,
    "sparse_rewards": false,
    "kl_lambda": 0.1,
    "use_information_bottleneck": true,
    "use_next_obs_in_context": false,
    "update_post_train": 1,
    "num_exp_traj_eval": 2,
    "recurrent": true,
    "dump_eval_paths": false
  },
  "util_params": {
    "base_log_dir": "./test/train1000/H-20",
    "use_gpu": true,
    "gpu_id": 0,
    "debug": false,
    "docker": false,
    "num_iterations": 3000
  }
}
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0007111436
Z variance train             0.69280326
KL Divergence                0.1495356
KL Loss                      0.01495356
QF Loss                      69.50569
VF Loss                      29.639257
Policy Loss                  -5.4038105
Q Predictions Mean           0.0033121614
Q Predictions Std            0.0017587668
Q Predictions Max            0.008227947
Q Predictions Min            -0.0015977039
V Predictions Mean           -0.00029463152
V Predictions Std            0.0020243167
V Predictions Max            0.004122844
V Predictions Min            -0.006428632
Log Pis Mean                 -5.422134
Log Pis Std                  0.6595036
Log Pis Max                  -3.5287657
Log Pis Min                  -7.012924
Policy mu Mean               0.0015601738
Policy mu Std                0.001667595
Policy mu Max                0.0055234022
Policy mu Min                -0.0032934812
Policy log std Mean          0.00043443142
Policy log std Std           0.0017997469
Policy log std Max           0.005979537
Policy log std Min           -0.0037199063
Z mean eval                  0.18768252
Z variance eval              0.14730497
total_rewards                [  14.00028753  -31.55095684 -226.86372544   -3.98702791   53.89787073
  -74.96443857  -12.16322149  -30.99285471   12.30646493  -53.08923595]
total_rewards_mean           -35.34068377127018
total_rewards_std            72.65531124277545
total_rewards_max            53.897870730937704
total_rewards_min            -226.8637254375447
Number of train steps total  1000
Number of env steps total    7000
Number of rollouts total     0
Train Time (s)               30.07871193718165
(Previous) Eval Time (s)     0
Sample Time (s)              22.95115672517568
Epoch Time (s)               53.02986866235733
Total Train Time (s)         57.862271438818425
Epoch                        0
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:16:29.199706 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #0 | Epoch Duration: 57.8650336265564
2020-01-11 03:16:29.199895 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #0 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.18722084
Z variance train             0.14853871
KL Divergence                2.7861366
KL Loss                      0.27861366
QF Loss                      48.19011
VF Loss                      4.1835685
Policy Loss                  -9.512016
Q Predictions Mean           3.6318457
Q Predictions Std            8.760866
Q Predictions Max            29.975864
Q Predictions Min            -23.36469
V Predictions Mean           10.310211
V Predictions Std            8.521749
V Predictions Max            34.14213
V Predictions Min            -13.94922
Log Pis Mean                 -5.2847686
Log Pis Std                  0.5802789
Log Pis Max                  -3.918102
Log Pis Min                  -7.654071
Policy mu Mean               -0.0133898165
Policy mu Std                0.14630279
Policy mu Max                0.44273037
Policy mu Min                -0.55860287
Policy log std Mean          -0.2799964
Policy log std Std           0.029475626
Policy log std Max           -0.19588062
Policy log std Min           -0.41837108
Z mean eval                  0.14425269
Z variance eval              0.03420157
total_rewards                [ 47.96509837  14.07117867 173.66179988  16.13680027  52.80957115
  87.54043317 306.37415648 238.40122172 280.50058111 447.02988885]
total_rewards_mean           166.4490729658226
total_rewards_std            139.833210977617
total_rewards_max            447.0298888459089
total_rewards_min            14.07117867156966
Number of train steps total  2000
Number of env steps total    12000
Number of rollouts total     0
Train Time (s)               29.249305265024304
(Previous) Eval Time (s)     4.8348440788686275
Sample Time (s)              15.75704830000177
Epoch Time (s)               49.8411976438947
Total Train Time (s)         116.66827899916098
Epoch                        1
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:17:28.007307 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #1 | Epoch Duration: 58.80724906921387
2020-01-11 03:17:28.007495 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #1 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.13958915
Z variance train             0.034409728
KL Divergence                6.1003313
KL Loss                      0.61003315
QF Loss                      82.67131
VF Loss                      11.706245
Policy Loss                  -22.653818
Q Predictions Mean           17.357052
Q Predictions Std            15.013961
Q Predictions Max            57.756996
Q Predictions Min            -32.1553
V Predictions Mean           24.27089
V Predictions Std            14.021844
V Predictions Max            62.20539
V Predictions Min            -22.829952
Log Pis Mean                 -3.7396107
Log Pis Std                  1.285501
Log Pis Max                  -0.8504703
Log Pis Min                  -9.2934
Policy mu Mean               0.011537545
Policy mu Std                0.21715458
Policy mu Max                0.6880044
Policy mu Min                -0.74749595
Policy log std Mean          -0.6653442
Policy log std Std           0.106234394
Policy log std Max           -0.34577504
Policy log std Min           -1.0635878
Z mean eval                  0.20194706
Z variance eval              0.019815784
total_rewards                [298.66488095 377.97489911 188.71140318 377.27829558 287.60327572
 358.84028923   8.82174145   3.23773512 289.1894981  327.9222451 ]
total_rewards_mean           251.82442635314933
total_rewards_std            133.63947488151322
total_rewards_max            377.97489910669213
total_rewards_min            3.2377351183449252
Number of train steps total  3000
Number of env steps total    17000
Number of rollouts total     0
Train Time (s)               27.1356070949696
(Previous) Eval Time (s)     13.800593433901668
Sample Time (s)              18.643156186211854
Epoch Time (s)               59.57935671508312
Total Train Time (s)         185.00775074306875
Epoch                        2
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:18:36.347122 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #2 | Epoch Duration: 68.33947658538818
2020-01-11 03:18:36.347303 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #2 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.19896053
Z variance train             0.020200843
KL Divergence                7.5326552
KL Loss                      0.75326556
QF Loss                      112.58616
VF Loss                      12.693346
Policy Loss                  -43.681957
Q Predictions Mean           40.023003
Q Predictions Std            15.565252
Q Predictions Max            73.52837
Q Predictions Min            -27.113647
V Predictions Mean           42.693695
V Predictions Std            14.684568
V Predictions Max            75.33157
V Predictions Min            -23.203854
Log Pis Mean                 -3.0951161
Log Pis Std                  1.4846718
Log Pis Max                  -0.2341809
Log Pis Min                  -7.691781
Policy mu Mean               0.004568341
Policy mu Std                0.21790825
Policy mu Max                0.9716887
Policy mu Min                -0.69259274
Policy log std Mean          -0.7961521
Policy log std Std           0.11852843
Policy log std Max           -0.43446904
Policy log std Min           -1.1741184
Z mean eval                  0.21762693
Z variance eval              0.013804589
total_rewards                [214.6942854  210.90843858 276.89681978 236.76517041 179.246178
 204.07881529   7.22038409 235.86616231  58.24339253 200.87165342]
total_rewards_mean           182.4791299818242
total_rewards_std            79.70151890255684
total_rewards_max            276.8968197817103
total_rewards_min            7.220384091456773
Number of train steps total  4000
Number of env steps total    22000
Number of rollouts total     0
Train Time (s)               28.182227700948715
(Previous) Eval Time (s)     22.56042685592547
Sample Time (s)              18.19216518336907
Epoch Time (s)               68.93481974024326
Total Train Time (s)         251.7596828932874
Epoch                        3
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:19:43.099507 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #3 | Epoch Duration: 66.75206208229065
2020-01-11 03:19:43.099696 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #3 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.22463217
Z variance train             0.014188205
KL Divergence                8.463063
KL Loss                      0.8463063
QF Loss                      108.58185
VF Loss                      18.436272
Policy Loss                  -57.473396
Q Predictions Mean           52.912117
Q Predictions Std            20.455147
Q Predictions Max            103.359474
Q Predictions Min            -21.327036
V Predictions Mean           58.025932
V Predictions Std            19.029228
V Predictions Max            98.53959
V Predictions Min            -13.60782
Log Pis Mean                 -3.2443657
Log Pis Std                  1.5840989
Log Pis Max                  -0.16876617
Log Pis Min                  -9.885862
Policy mu Mean               0.022113647
Policy mu Std                0.2537919
Policy mu Max                0.8153246
Policy mu Min                -0.78958535
Policy log std Mean          -0.7594018
Policy log std Std           0.108144365
Policy log std Max           -0.4079075
Policy log std Min           -1.0856087
Z mean eval                  0.29892033
Z variance eval              0.013701287
total_rewards                [158.95969706 181.3274048  127.98129476  29.31454848 306.65043237
 158.20926517  67.59949787  41.93972695  75.63325891  53.91713384]
total_rewards_mean           120.15322602031384
total_rewards_std            80.64684097378489
total_rewards_max            306.6504323699024
total_rewards_min            29.314548476198578
Number of train steps total  5000
Number of env steps total    27000
Number of rollouts total     0
Train Time (s)               26.87611459195614
(Previous) Eval Time (s)     20.377358423080295
Sample Time (s)              17.928523713257164
Epoch Time (s)               65.1819967282936
Total Train Time (s)         310.9865999035537
Epoch                        4
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:20:42.330258 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #4 | Epoch Duration: 59.23035669326782
2020-01-11 03:20:42.330550 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #4 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.30578932
Z variance train             0.01215495
KL Divergence                9.109398
KL Loss                      0.9109398
QF Loss                      145.23572
VF Loss                      16.488611
Policy Loss                  -74.223434
Q Predictions Mean           70.19043
Q Predictions Std            20.767406
Q Predictions Max            113.55323
Q Predictions Min            -23.025692
V Predictions Mean           73.45296
V Predictions Std            19.39197
V Predictions Max            124.43048
V Predictions Min            -11.286664
Log Pis Mean                 -3.0350795
Log Pis Std                  1.5637962
Log Pis Max                  0.96182406
Log Pis Min                  -8.495542
Policy mu Mean               0.03747923
Policy mu Std                0.2613341
Policy mu Max                0.97027767
Policy mu Min                -0.8806474
Policy log std Mean          -0.77577466
Policy log std Std           0.10570175
Policy log std Max           -0.4187682
Policy log std Min           -1.0943424
Z mean eval                  0.32748044
Z variance eval              0.01574593
total_rewards                [ 94.05598754 113.63772341  70.84445821  34.73149022  93.14444108
  39.46521679  76.11159621 217.92909419  28.35957557  90.81832159]
total_rewards_mean           85.90979048123187
total_rewards_std            51.72237631353141
total_rewards_max            217.92909418665312
total_rewards_min            28.359575567968875
Number of train steps total  6000
Number of env steps total    32000
Number of rollouts total     0
Train Time (s)               28.468368031084538
(Previous) Eval Time (s)     14.425354977604002
Sample Time (s)              18.173614399507642
Epoch Time (s)               61.06733740819618
Total Train Time (s)         380.7155390540138
Epoch                        5
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:21:52.058852 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #5 | Epoch Duration: 69.72808051109314
2020-01-11 03:21:52.059046 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #5 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.32936147
Z variance train             0.015748452
KL Divergence                8.420627
KL Loss                      0.84206265
QF Loss                      154.15768
VF Loss                      27.507387
Policy Loss                  -94.3253
Q Predictions Mean           90.96997
Q Predictions Std            22.255493
Q Predictions Max            139.42342
Q Predictions Min            -30.076017
V Predictions Mean           93.16261
V Predictions Std            21.139242
V Predictions Max            146.12671
V Predictions Min            -24.818361
Log Pis Mean                 -3.6114368
Log Pis Std                  1.4335512
Log Pis Max                  -0.3939123
Log Pis Min                  -9.466815
Policy mu Mean               0.06584862
Policy mu Std                0.27868098
Policy mu Max                0.99131376
Policy mu Min                -0.95145416
Policy log std Mean          -0.6747285
Policy log std Std           0.11750259
Policy log std Max           -0.34635544
Policy log std Min           -1.0904018
Z mean eval                  0.26609927
Z variance eval              0.012010933
total_rewards                [ -4.80026783  15.38829441  89.6193241   -0.10354879 -28.39134502
 -20.50840603  96.33554517 -15.08998181  -1.31664611  45.35398492]
total_rewards_mean           17.64869530236571
total_rewards_std            42.39143451487798
total_rewards_max            96.33554517308197
total_rewards_min            -28.391345020852953
Number of train steps total  7000
Number of env steps total    37000
Number of rollouts total     0
Train Time (s)               24.82856333302334
(Previous) Eval Time (s)     23.0858018361032
Sample Time (s)              17.834485481493175
Epoch Time (s)               65.74885065061972
Total Train Time (s)         439.63256664481014
Epoch                        6
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:22:50.980352 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #6 | Epoch Duration: 58.921141386032104
2020-01-11 03:22:50.980633 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #6 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.35418946
Z variance train             0.01135229
KL Divergence                9.546211
KL Loss                      0.95462114
QF Loss                      227.18376
VF Loss                      40.33774
Policy Loss                  -97.3167
Q Predictions Mean           93.209366
Q Predictions Std            23.542912
Q Predictions Max            150.00052
Q Predictions Min            -8.637249
V Predictions Mean           95.42553
V Predictions Std            22.818138
V Predictions Max            159.47981
V Predictions Min            -2.2414496
Log Pis Mean                 -3.9486437
Log Pis Std                  1.4011819
Log Pis Max                  -1.178171
Log Pis Min                  -9.871375
Policy mu Mean               0.004853488
Policy mu Std                0.28635484
Policy mu Max                1.107944
Policy mu Min                -0.9432404
Policy log std Mean          -0.59874105
Policy log std Std           0.112378635
Policy log std Max           -0.29864386
Policy log std Min           -0.95232606
Z mean eval                  0.51611984
Z variance eval              0.017133329
total_rewards                [ 58.9230366   64.91746744 -90.18703978 -16.93030133 123.43967777
  11.64982738  83.68769434  -9.44510361 -13.04985555  76.53903657]
total_rewards_mean           28.954443983386994
total_rewards_std            60.18087432431614
total_rewards_max            123.43967777435226
total_rewards_min            -90.18703977741289
Number of train steps total  8000
Number of env steps total    42000
Number of rollouts total     0
Train Time (s)               28.159306711982936
(Previous) Eval Time (s)     16.257794691249728
Sample Time (s)              18.320272703655064
Epoch Time (s)               62.73737410688773
Total Train Time (s)         507.13103967299685
Epoch                        7
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:23:58.475731 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #7 | Epoch Duration: 67.49489831924438
2020-01-11 03:23:58.475889 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #7 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.5034417
Z variance train             0.01786727
KL Divergence                8.807041
KL Loss                      0.8807041
QF Loss                      188.02
VF Loss                      32.8407
Policy Loss                  -114.19888
Q Predictions Mean           110.690475
Q Predictions Std            27.263206
Q Predictions Max            155.89728
Q Predictions Min            -12.47857
V Predictions Mean           117.06068
V Predictions Std            25.54699
V Predictions Max            161.93475
V Predictions Min            -16.065434
Log Pis Mean                 -3.2456832
Log Pis Std                  1.631841
Log Pis Max                  3.5598595
Log Pis Min                  -7.593236
Policy mu Mean               0.009642176
Policy mu Std                0.32874343
Policy mu Max                1.0842344
Policy mu Min                -1.0483272
Policy log std Mean          -0.70162904
Policy log std Std           0.14981861
Policy log std Max           -0.34593722
Policy log std Min           -1.2650514
Z mean eval                  0.54885375
Z variance eval              0.0142388595
total_rewards                [  7.91550698  66.6498799  114.08832991 -40.2615703   27.21515304
 -68.30886235  -1.09655134  94.3517987   60.57018587  43.85456066]
total_rewards_mean           30.497843106939683
total_rewards_std            54.53715975819693
total_rewards_max            114.08832991479257
total_rewards_min            -68.30886234863344
Number of train steps total  9000
Number of env steps total    47000
Number of rollouts total     0
Train Time (s)               26.61880941130221
(Previous) Eval Time (s)     21.01503843208775
Sample Time (s)              18.567066584248096
Epoch Time (s)               66.20091442763805
Total Train Time (s)         569.4529223539867
Epoch                        8
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:25:00.801203 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #8 | Epoch Duration: 62.32512378692627
2020-01-11 03:25:00.801480 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #8 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.20044012
Z variance train             0.02119305
KL Divergence                7.3962517
KL Loss                      0.73962516
QF Loss                      244.30061
VF Loss                      20.876696
Policy Loss                  -115.610054
Q Predictions Mean           112.66367
Q Predictions Std            22.676142
Q Predictions Max            162.06639
Q Predictions Min            -36.56254
V Predictions Mean           117.426216
V Predictions Std            22.78295
V Predictions Max            165.24786
V Predictions Min            -20.412582
Log Pis Mean                 -3.3146615
Log Pis Std                  1.5929854
Log Pis Max                  1.8636954
Log Pis Min                  -8.249573
Policy mu Mean               0.027097441
Policy mu Std                0.3258119
Policy mu Max                1.1779407
Policy mu Min                -1.0195366
Policy log std Mean          -0.7119627
Policy log std Std           0.12863982
Policy log std Max           -0.36608803
Policy log std Min           -1.3362197
Z mean eval                  0.5433329
Z variance eval              0.016662344
total_rewards                [  1.36539742 -39.78129557 -15.20043885  21.16950838 122.70415198
 -12.7601363  105.49676608 103.44073389  77.14992112 146.28225743]
total_rewards_mean           50.98668655740536
total_rewards_std            63.77028100337434
total_rewards_max            146.28225742810832
total_rewards_min            -39.781295574254635
Number of train steps total  10000
Number of env steps total    52000
Number of rollouts total     0
Train Time (s)               29.525174090173095
(Previous) Eval Time (s)     17.13894143514335
Sample Time (s)              18.02102380571887
Epoch Time (s)               64.68513933103532
Total Train Time (s)         640.6399309765548
Epoch                        9
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:26:11.989899 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #9 | Epoch Duration: 71.1881856918335
2020-01-11 03:26:11.990209 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #9 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.54553485
Z variance train             0.015634373
KL Divergence                9.232988
KL Loss                      0.92329884
QF Loss                      214.75227
VF Loss                      21.24357
Policy Loss                  -143.40146
Q Predictions Mean           139.8292
Q Predictions Std            25.807838
Q Predictions Max            187.6023
Q Predictions Min            -26.11967
V Predictions Mean           143.36987
V Predictions Std            25.044538
V Predictions Max            192.82747
V Predictions Min            -53.040443
Log Pis Mean                 -3.2694788
Log Pis Std                  1.7068185
Log Pis Max                  4.738654
Log Pis Min                  -8.930595
Policy mu Mean               0.06982015
Policy mu Std                0.32872978
Policy mu Max                1.4110968
Policy mu Min                -1.2271042
Policy log std Mean          -0.70314467
Policy log std Std           0.1436817
Policy log std Max           -0.39803433
Policy log std Min           -1.5892609
Z mean eval                  0.57717735
Z variance eval              0.02215753
total_rewards                [ 70.66703855 113.96616177   5.55028387  49.15753449  76.52246067
  36.44158213  27.94920307  58.83616892  44.8505133   74.12351887]
total_rewards_mean           55.80644656555906
total_rewards_std            28.66737456889748
total_rewards_max            113.96616177424664
total_rewards_min            5.550283874486045
Number of train steps total  11000
Number of env steps total    57000
Number of rollouts total     0
Train Time (s)               26.18080514203757
(Previous) Eval Time (s)     23.641721657011658
Sample Time (s)              18.85543723590672
Epoch Time (s)               68.67796403495595
Total Train Time (s)         711.0938390330411
Epoch                        10
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:27:22.443437 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #10 | Epoch Duration: 70.45301127433777
2020-01-11 03:27:22.443648 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #10 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.5812179
Z variance train             0.023214545
KL Divergence                8.728807
KL Loss                      0.87288076
QF Loss                      201.6477
VF Loss                      44.7297
Policy Loss                  -153.33871
Q Predictions Mean           148.3994
Q Predictions Std            29.909353
Q Predictions Max            220.3124
Q Predictions Min            -5.4840345
V Predictions Mean           152.16708
V Predictions Std            23.96081
V Predictions Max            226.97108
V Predictions Min            12.218166
Log Pis Mean                 -3.235735
Log Pis Std                  1.7110013
Log Pis Max                  4.1791124
Log Pis Min                  -8.300232
Policy mu Mean               0.055269033
Policy mu Std                0.33789483
Policy mu Max                1.3588798
Policy mu Min                -1.2473369
Policy log std Mean          -0.7119409
Policy log std Std           0.14773114
Policy log std Max           -0.38511634
Policy log std Min           -1.3798723
Z mean eval                  0.60608304
Z variance eval              0.013422793
total_rewards                [143.68586168  58.03274245  60.87477969  33.3288478    4.77619137
  25.11201399  17.61253695 250.35080818   5.57475357 119.56483374]
total_rewards_mean           71.89133694159321
total_rewards_std            74.23766892714623
total_rewards_max            250.3508081787017
total_rewards_min            4.776191366281468
Number of train steps total  12000
Number of env steps total    62000
Number of rollouts total     0
Train Time (s)               26.675670464988798
(Previous) Eval Time (s)     25.416499115061015
Sample Time (s)              18.177351393271238
Epoch Time (s)               70.26952097332105
Total Train Time (s)         770.2186742620543
Epoch                        11
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:28:21.569574 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #11 | Epoch Duration: 59.125765800476074
2020-01-11 03:28:21.569783 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #11 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6069572
Z variance train             0.013817665
KL Divergence                10.12755
KL Loss                      1.012755
QF Loss                      237.9425
VF Loss                      32.709206
Policy Loss                  -167.34221
Q Predictions Mean           162.30997
Q Predictions Std            28.307238
Q Predictions Max            209.97751
Q Predictions Min            -18.696152
V Predictions Mean           166.75073
V Predictions Std            26.508955
V Predictions Max            211.31908
V Predictions Min            -54.912685
Log Pis Mean                 -3.3113174
Log Pis Std                  1.7729657
Log Pis Max                  3.2222211
Log Pis Min                  -8.4787445
Policy mu Mean               0.037758883
Policy mu Std                0.3474832
Policy mu Max                1.1453158
Policy mu Min                -1.4719917
Policy log std Mean          -0.6538307
Policy log std Std           0.14762701
Policy log std Max           -0.33877504
Policy log std Min           -1.4539844
Z mean eval                  0.654648
Z variance eval              0.0107842265
total_rewards                [ 130.99459617   37.07599952  -54.94227907   91.06887775 -187.55035145
   13.85582252    2.34506808  -49.56595881   43.00519135   29.83689445]
total_rewards_mean           5.612386050482222
total_rewards_std            83.72604626829403
total_rewards_max            130.99459616947462
total_rewards_min            -187.55035145496333
Number of train steps total  13000
Number of env steps total    67000
Number of rollouts total     0
Train Time (s)               29.566403006669134
(Previous) Eval Time (s)     14.272446635179222
Sample Time (s)              18.81917978776619
Epoch Time (s)               62.658029429614544
Total Train Time (s)         840.1090457998216
Epoch                        12
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:29:31.462241 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #12 | Epoch Duration: 69.89228010177612
2020-01-11 03:29:31.462493 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #12 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6484249
Z variance train             0.010893333
KL Divergence                11.196309
KL Loss                      1.1196309
QF Loss                      214.59839
VF Loss                      62.04062
Policy Loss                  -173.96155
Q Predictions Mean           171.7445
Q Predictions Std            28.09185
Q Predictions Max            223.21835
Q Predictions Min            11.70386
V Predictions Mean           179.85933
V Predictions Std            24.175901
V Predictions Max            229.71165
V Predictions Min            61.383648
Log Pis Mean                 -3.0406108
Log Pis Std                  1.6995105
Log Pis Max                  3.2174013
Log Pis Min                  -7.761197
Policy mu Mean               0.021149555
Policy mu Std                0.36804366
Policy mu Max                1.3824763
Policy mu Min                -1.5050123
Policy log std Mean          -0.67290133
Policy log std Std           0.14514771
Policy log std Max           -0.4122878
Policy log std Min           -1.5782896
Z mean eval                  0.6505477
Z variance eval              0.0089729
total_rewards                [-30.21452651 -41.69801503 118.36332107  39.95807862 229.84921408
 -46.67255674 197.73300803  -4.79803572  62.22236033 108.23096024]
total_rewards_mean           63.29738083760706
total_rewards_std            93.7595312164279
total_rewards_max            229.84921407889644
total_rewards_min            -46.67255674008302
Number of train steps total  14000
Number of env steps total    72000
Number of rollouts total     0
Train Time (s)               26.44997218903154
(Previous) Eval Time (s)     21.50635995203629
Sample Time (s)              18.171491474844515
Epoch Time (s)               66.12782361591235
Total Train Time (s)         909.4373334730044
Epoch                        13
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:30:40.792237 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #13 | Epoch Duration: 69.32953691482544
2020-01-11 03:30:40.792474 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #13 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.35296655
Z variance train             0.021226514
KL Divergence                7.8010893
KL Loss                      0.7801089
QF Loss                      265.97226
VF Loss                      37.18196
Policy Loss                  -164.77693
Q Predictions Mean           161.66232
Q Predictions Std            30.790628
Q Predictions Max            203.54988
Q Predictions Min            -3.23198
V Predictions Mean           165.60953
V Predictions Std            27.078503
V Predictions Max            208.47821
V Predictions Min            3.9660437
Log Pis Mean                 -3.1487572
Log Pis Std                  1.8365537
Log Pis Max                  3.7875195
Log Pis Min                  -9.948297
Policy mu Mean               0.050780382
Policy mu Std                0.34758723
Policy mu Max                1.1877016
Policy mu Min                -1.5764284
Policy log std Mean          -0.691293
Policy log std Std           0.14364557
Policy log std Max           -0.3624735
Policy log std Min           -1.5587778
Z mean eval                  0.67162335
Z variance eval              0.010211244
total_rewards                [ 46.43514769 184.18421549  13.28445187 125.7873351    2.04232179
 218.97361196 151.4899056  156.17309448 183.04691048   8.44064705]
total_rewards_mean           108.98576415127334
total_rewards_std            78.84812448153275
total_rewards_max            218.97361195664305
total_rewards_min            2.04232179123409
Number of train steps total  15000
Number of env steps total    77000
Number of rollouts total     0
Train Time (s)               29.366876787040383
(Previous) Eval Time (s)     24.707781281787902
Sample Time (s)              18.52231630962342
Epoch Time (s)               72.5969743784517
Total Train Time (s)         979.6874375357293
Epoch                        14
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:31:51.042574 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #14 | Epoch Duration: 70.24991536140442
2020-01-11 03:31:51.042787 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #14 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6690649
Z variance train             0.010235261
KL Divergence                11.790938
KL Loss                      1.1790938
QF Loss                      304.55713
VF Loss                      36.62172
Policy Loss                  -193.53809
Q Predictions Mean           191.94504
Q Predictions Std            25.46615
Q Predictions Max            255.48216
Q Predictions Min            13.120646
V Predictions Mean           192.58087
V Predictions Std            25.380335
V Predictions Max            270.90552
V Predictions Min            36.681244
Log Pis Mean                 -2.9276276
Log Pis Std                  1.7975532
Log Pis Max                  4.4996424
Log Pis Min                  -8.409382
Policy mu Mean               0.05749204
Policy mu Std                0.3699249
Policy mu Max                1.5180372
Policy mu Min                -1.5089194
Policy log std Mean          -0.71429354
Policy log std Std           0.13474534
Policy log std Max           -0.42689556
Policy log std Min           -1.6738021
Z mean eval                  0.6902353
Z variance eval              0.014196296
total_rewards                [-31.85465628 117.06543695 100.57184375 108.06075617 168.86524871
  49.06330367  97.62048149  88.91188785  39.59237926  23.25849689]
total_rewards_mean           76.11551784575391
total_rewards_std            53.8900865028662
total_rewards_max            168.86524871050403
total_rewards_min            -31.854656276321684
Number of train steps total  16000
Number of env steps total    82000
Number of rollouts total     0
Train Time (s)               27.95773120317608
(Previous) Eval Time (s)     22.360426841769367
Sample Time (s)              19.1163699189201
Epoch Time (s)               69.43452796386555
Total Train Time (s)         1048.5641627577133
Epoch                        15
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:32:59.922619 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #15 | Epoch Duration: 68.87966132164001
2020-01-11 03:32:59.922816 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #15 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6923238
Z variance train             0.014213341
KL Divergence                11.64362
KL Loss                      1.164362
QF Loss                      172.50627
VF Loss                      44.48893
Policy Loss                  -205.8193
Q Predictions Mean           200.77193
Q Predictions Std            23.84222
Q Predictions Max            282.10364
Q Predictions Min            29.684013
V Predictions Mean           203.37166
V Predictions Std            19.13233
V Predictions Max            272.70828
V Predictions Min            129.88678
Log Pis Mean                 -3.3298812
Log Pis Std                  1.7665997
Log Pis Max                  2.6907642
Log Pis Min                  -9.186504
Policy mu Mean               0.08369846
Policy mu Std                0.34483203
Policy mu Max                1.4590036
Policy mu Min                -1.2146711
Policy log std Mean          -0.7027419
Policy log std Std           0.12603186
Policy log std Max           -0.40591824
Policy log std Min           -1.5213488
Z mean eval                  0.6945084
Z variance eval              0.01150859
total_rewards                [182.3608812   94.46364337 143.47784022  19.90357579 177.09730596
 116.50978876 240.9201372   20.79882263 127.15831342 101.24064704]
total_rewards_mean           122.39309555864193
total_rewards_std            65.72078129545694
total_rewards_max            240.92013720077537
total_rewards_min            19.903575786521003
Number of train steps total  17000
Number of env steps total    87000
Number of rollouts total     0
Train Time (s)               24.828399889171124
(Previous) Eval Time (s)     21.805228765122592
Sample Time (s)              18.85377375688404
Epoch Time (s)               65.48740241117775
Total Train Time (s)         1113.607843842823
Epoch                        16
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:34:04.964926 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #16 | Epoch Duration: 65.04195523262024
2020-01-11 03:34:04.965119 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #16 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.69392526
Z variance train             0.01152909
KL Divergence                12.443283
KL Loss                      1.2443284
QF Loss                      233.98004
VF Loss                      35.488136
Policy Loss                  -208.77776
Q Predictions Mean           206.01566
Q Predictions Std            32.38121
Q Predictions Max            259.89194
Q Predictions Min            -30.990711
V Predictions Mean           208.38412
V Predictions Std            32.25189
V Predictions Max            265.0374
V Predictions Min            -110.498055
Log Pis Mean                 -3.2332573
Log Pis Std                  1.7271649
Log Pis Max                  3.2953906
Log Pis Min                  -8.970548
Policy mu Mean               0.053399127
Policy mu Std                0.33935666
Policy mu Max                1.4635673
Policy mu Min                -1.7957724
Policy log std Mean          -0.7222102
Policy log std Std           0.1412551
Policy log std Max           -0.26181477
Policy log std Min           -1.6006993
Z mean eval                  0.71026254
Z variance eval              0.009848932
total_rewards                [210.34923685  83.13503295  65.24515202 101.6459953  330.45727328
 322.16998538 277.20218544  32.565091   382.91847755 226.27780952]
total_rewards_mean           203.19662392951662
total_rewards_std            118.98892673180261
total_rewards_max            382.9184775499112
total_rewards_min            32.565090999306676
Number of train steps total  18000
Number of env steps total    92000
Number of rollouts total     0
Train Time (s)               28.449849078897387
(Previous) Eval Time (s)     21.359467243310064
Sample Time (s)              18.08360978960991
Epoch Time (s)               67.89292611181736
Total Train Time (s)         1180.1226809867658
Epoch                        17
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:35:11.481671 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #17 | Epoch Duration: 66.51638913154602
2020-01-11 03:35:11.481889 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #17 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7109053
Z variance train             0.009838758
KL Divergence                12.4456415
KL Loss                      1.2445642
QF Loss                      185.30629
VF Loss                      28.986546
Policy Loss                  -222.26201
Q Predictions Mean           219.27486
Q Predictions Std            27.078827
Q Predictions Max            273.61908
Q Predictions Min            -48.352512
V Predictions Mean           220.71852
V Predictions Std            26.383245
V Predictions Max            271.82047
V Predictions Min            -61.301167
Log Pis Mean                 -3.0656972
Log Pis Std                  2.0124834
Log Pis Max                  14.894779
Log Pis Min                  -10.005009
Policy mu Mean               0.03598152
Policy mu Std                0.33536142
Policy mu Max                2.2286584
Policy mu Min                -2.5230548
Policy log std Mean          -0.7267268
Policy log std Std           0.13806933
Policy log std Max           -0.39144304
Policy log std Min           -1.6582252
Z mean eval                  0.7193595
Z variance eval              0.010459467
total_rewards                [ 36.96947051  78.54057899  37.7533013    4.54891089  16.20566784
  24.83375482 143.87058763  79.88123891  56.15764637  34.87728003]
total_rewards_mean           51.36384372968655
total_rewards_std            38.6369350389794
total_rewards_max            143.87058762832316
total_rewards_min            4.548910894629974
Number of train steps total  19000
Number of env steps total    97000
Number of rollouts total     0
Train Time (s)               26.770887195132673
(Previous) Eval Time (s)     19.98260773019865
Sample Time (s)              19.801727114245296
Epoch Time (s)               66.55522203957662
Total Train Time (s)         1246.276926830411
Epoch                        18
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:36:17.637471 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #18 | Epoch Duration: 66.15541195869446
2020-01-11 03:36:17.637665 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #18 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.72472054
Z variance train             0.010450283
KL Divergence                12.833864
KL Loss                      1.2833865
QF Loss                      236.22527
VF Loss                      76.334435
Policy Loss                  -232.2547
Q Predictions Mean           225.35959
Q Predictions Std            25.552698
Q Predictions Max            288.91867
Q Predictions Min            1.5154634
V Predictions Mean           226.27019
V Predictions Std            23.444933
V Predictions Max            292.5475
V Predictions Min            61.232388
Log Pis Mean                 -3.01473
Log Pis Std                  1.8805358
Log Pis Max                  8.33905
Log Pis Min                  -8.687319
Policy mu Mean               0.014879188
Policy mu Std                0.36196807
Policy mu Max                2.1950548
Policy mu Min                -1.2122825
Policy log std Mean          -0.73605955
Policy log std Std           0.14597315
Policy log std Max           -0.3454131
Policy log std Min           -1.6585814
Z mean eval                  0.7293374
Z variance eval              0.012279026
total_rewards                [ 67.81308932 167.01725478  91.08097111 172.92004223 306.58120793
 301.67379042 237.41620852  74.06614161 331.83282391  63.52524691]
total_rewards_mean           181.39267767248933
total_rewards_std            101.31992397526702
total_rewards_max            331.8328239101088
total_rewards_min            63.52524691370002
Number of train steps total  20000
Number of env steps total    102000
Number of rollouts total     0
Train Time (s)               27.8594450391829
(Previous) Eval Time (s)     19.582483114674687
Sample Time (s)              17.964899419806898
Epoch Time (s)               65.40682757366449
Total Train Time (s)         1317.667057198938
Epoch                        19
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:37:29.028680 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #19 | Epoch Duration: 71.39084911346436
2020-01-11 03:37:29.028903 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #19 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.72803175
Z variance train             0.012268839
KL Divergence                12.727528
KL Loss                      1.2727528
QF Loss                      156.61862
VF Loss                      48.11882
Policy Loss                  -233.22481
Q Predictions Mean           230.65811
Q Predictions Std            30.903418
Q Predictions Max            297.40674
Q Predictions Min            -9.352205
V Predictions Mean           234.67012
V Predictions Std            27.117731
V Predictions Max            295.58344
V Predictions Min            19.175674
Log Pis Mean                 -2.9144242
Log Pis Std                  1.8515092
Log Pis Max                  3.3475566
Log Pis Min                  -9.624564
Policy mu Mean               0.034603864
Policy mu Std                0.33342487
Policy mu Max                1.5425142
Policy mu Min                -1.402113
Policy log std Mean          -0.768944
Policy log std Std           0.12126361
Policy log std Max           -0.39748865
Policy log std Min           -1.3821671
Z mean eval                  0.748752
Z variance eval              0.014075378
total_rewards                [285.8004526  105.27294428  55.68544619  11.9612765  141.99221693
 279.19107335 128.92930601 162.64663554 333.29914618 228.10933157]
total_rewards_mean           173.28878291584675
total_rewards_std            100.01326752960613
total_rewards_max            333.29914618485793
total_rewards_min            11.961276501660977
Number of train steps total  21000
Number of env steps total    107000
Number of rollouts total     0
Train Time (s)               28.32223001914099
(Previous) Eval Time (s)     25.566187248099595
Sample Time (s)              18.014545517973602
Epoch Time (s)               71.90296278521419
Total Train Time (s)         1387.1957493536174
Epoch                        20
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:38:38.558104 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #20 | Epoch Duration: 69.52903413772583
2020-01-11 03:38:38.558303 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #20 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7451602
Z variance train             0.014067242
KL Divergence                12.673101
KL Loss                      1.2673101
QF Loss                      197.9515
VF Loss                      79.746666
Policy Loss                  -234.4805
Q Predictions Mean           231.6966
Q Predictions Std            37.157845
Q Predictions Max            283.7031
Q Predictions Min            -17.691284
V Predictions Mean           237.48476
V Predictions Std            31.311888
V Predictions Max            285.87686
V Predictions Min            27.934252
Log Pis Mean                 -2.8665183
Log Pis Std                  1.8115149
Log Pis Max                  3.5061545
Log Pis Min                  -8.313202
Policy mu Mean               -0.0006065613
Policy mu Std                0.3210416
Policy mu Max                1.1892976
Policy mu Min                -1.2198368
Policy log std Mean          -0.7571856
Policy log std Std           0.15314043
Policy log std Max           -0.41159606
Policy log std Min           -1.6240695
Z mean eval                  0.7580375
Z variance eval              0.018518653
total_rewards                [162.82046148  16.65744174 116.85255595 374.35972847 305.90886798
  90.7011549   92.67959118  87.07266002 416.6362295   90.09157319]
total_rewards_mean           175.37802644076106
total_rewards_std            131.41290143529054
total_rewards_max            416.6362294975662
total_rewards_min            16.657441738619212
Number of train steps total  22000
Number of env steps total    112000
Number of rollouts total     0
Train Time (s)               28.588295630179346
(Previous) Eval Time (s)     23.19198343111202
Sample Time (s)              18.85999903595075
Epoch Time (s)               70.64027809724212
Total Train Time (s)         1460.0477204890922
Epoch                        21
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:39:51.412863 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #21 | Epoch Duration: 72.85439991950989
2020-01-11 03:39:51.413147 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #21 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7606193
Z variance train             0.018565113
KL Divergence                13.043941
KL Loss                      1.3043941
QF Loss                      165.19003
VF Loss                      52.61403
Policy Loss                  -249.91528
Q Predictions Mean           247.29309
Q Predictions Std            31.09944
Q Predictions Max            306.60385
Q Predictions Min            -12.391284
V Predictions Mean           248.25667
V Predictions Std            29.070091
V Predictions Max            305.3214
V Predictions Min            -3.0749936
Log Pis Mean                 -3.1697474
Log Pis Std                  1.5416833
Log Pis Max                  1.9370449
Log Pis Min                  -7.5658283
Policy mu Mean               0.045888465
Policy mu Std                0.32297447
Policy mu Max                1.0278764
Policy mu Min                -1.7198079
Policy log std Mean          -0.72098887
Policy log std Std           0.12221545
Policy log std Max           -0.35186893
Policy log std Min           -1.5748951
Z mean eval                  0.76344836
Z variance eval              0.015128831
total_rewards                [204.31602316 103.05691785 -30.92436493 131.02246692 123.66251747
 362.1187438   23.90046009  80.51399952  76.87177353 369.18851955]
total_rewards_mean           144.37270569574645
total_rewards_std            125.59448984770096
total_rewards_max            369.1885195498377
total_rewards_min            -30.924364930484234
Number of train steps total  23000
Number of env steps total    117000
Number of rollouts total     0
Train Time (s)               28.244730638805777
(Previous) Eval Time (s)     25.40576889924705
Sample Time (s)              18.55090286117047
Epoch Time (s)               72.2014023992233
Total Train Time (s)         1528.1538036484271
Epoch                        22
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:40:59.520135 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #22 | Epoch Duration: 68.10676980018616
2020-01-11 03:40:59.520353 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #22 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.75995666
Z variance train             0.015054673
KL Divergence                13.184206
KL Loss                      1.3184206
QF Loss                      405.34247
VF Loss                      61.547997
Policy Loss                  -249.15596
Q Predictions Mean           246.17238
Q Predictions Std            29.106161
Q Predictions Max            298.52466
Q Predictions Min            -20.918173
V Predictions Mean           252.4101
V Predictions Std            26.064615
V Predictions Max            298.70825
V Predictions Min            18.406628
Log Pis Mean                 -2.906857
Log Pis Std                  1.6232436
Log Pis Max                  1.7773979
Log Pis Min                  -7.7317166
Policy mu Mean               0.0069695185
Policy mu Std                0.32273653
Policy mu Max                1.0825757
Policy mu Min                -1.2719525
Policy log std Mean          -0.75098616
Policy log std Std           0.13049361
Policy log std Max           -0.4243511
Policy log std Min           -1.7053806
Z mean eval                  0.739631
Z variance eval              0.014698912
total_rewards                [355.36089997 116.94542552  55.27625328 188.52924141 158.3982388
 189.37969432  81.93391652  82.57953375  95.67789694 275.31604009]
total_rewards_mean           159.93971405959084
total_rewards_std            90.65849001968445
total_rewards_max            355.3608999741153
total_rewards_min            55.27625328107531
Number of train steps total  24000
Number of env steps total    122000
Number of rollouts total     0
Train Time (s)               27.786528019234538
(Previous) Eval Time (s)     21.310829661786556
Sample Time (s)              18.693867267575115
Epoch Time (s)               67.79122494859621
Total Train Time (s)         1599.1637954819016
Epoch                        23
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:42:10.531927 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #23 | Epoch Duration: 71.0114016532898
2020-01-11 03:42:10.532124 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #23 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.74161875
Z variance train             0.0146800475
KL Divergence                12.693905
KL Loss                      1.2693905
QF Loss                      174.94424
VF Loss                      58.60338
Policy Loss                  -256.6574
Q Predictions Mean           252.08908
Q Predictions Std            29.561289
Q Predictions Max            306.6537
Q Predictions Min            -9.410652
V Predictions Mean           258.20245
V Predictions Std            30.1722
V Predictions Max            316.4161
V Predictions Min            24.670963
Log Pis Mean                 -2.7622693
Log Pis Std                  1.520641
Log Pis Max                  3.8383126
Log Pis Min                  -8.559996
Policy mu Mean               0.011537492
Policy mu Std                0.3416359
Policy mu Max                2.1310303
Policy mu Min                -1.5964568
Policy log std Mean          -0.7411953
Policy log std Std           0.12994018
Policy log std Max           -0.39049596
Policy log std Min           -1.4497437
Z mean eval                  0.7485394
Z variance eval              0.015585186
total_rewards                [265.27969066 306.96841571 121.91733363  80.50578446  80.94463564
   9.01189208  23.67835925  29.26754493 334.01247403 151.65401159]
total_rewards_mean           140.32401419871317
total_rewards_std            114.74032623584272
total_rewards_max            334.0124740324415
total_rewards_min            9.011892082345208
Number of train steps total  25000
Number of env steps total    127000
Number of rollouts total     0
Train Time (s)               28.629480347968638
(Previous) Eval Time (s)     24.530726076103747
Sample Time (s)              17.757304337807
Epoch Time (s)               70.91751076187938
Total Train Time (s)         1664.2884180345573
Epoch                        24
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:43:15.656841 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #24 | Epoch Duration: 65.12452387809753
2020-01-11 03:43:15.657148 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #24 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.75126064
Z variance train             0.015575742
KL Divergence                13.6505575
KL Loss                      1.3650558
QF Loss                      352.50134
VF Loss                      47.772385
Policy Loss                  -253.19876
Q Predictions Mean           250.65405
Q Predictions Std            42.312073
Q Predictions Max            321.40988
Q Predictions Min            -29.354832
V Predictions Mean           249.70818
V Predictions Std            40.526394
V Predictions Max            315.51523
V Predictions Min            -30.268946
Log Pis Mean                 -2.5805027
Log Pis Std                  1.828088
Log Pis Max                  8.943451
Log Pis Min                  -7.941637
Policy mu Mean               0.025180906
Policy mu Std                0.33519953
Policy mu Max                2.126047
Policy mu Min                -1.7749556
Policy log std Mean          -0.779299
Policy log std Std           0.13995592
Policy log std Max           -0.4512185
Policy log std Min           -1.6189661
Z mean eval                  0.7652315
Z variance eval              0.013945426
total_rewards                [150.62512464 177.06131979 158.53774804 111.8102991  150.49759813
 269.53489721 212.73601121 461.0063713  116.69506522 203.72082234]
total_rewards_mean           201.22252569923592
total_rewards_std            97.45323781014369
total_rewards_max            461.0063712975957
total_rewards_min            111.81029910050478
Number of train steps total  26000
Number of env steps total    132000
Number of rollouts total     0
Train Time (s)               30.10825598007068
(Previous) Eval Time (s)     18.737423228099942
Sample Time (s)              18.657793413382024
Epoch Time (s)               67.50347262155265
Total Train Time (s)         1737.755612990819
Epoch                        25
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:44:29.126075 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #25 | Epoch Duration: 73.46868205070496
2020-01-11 03:44:29.126333 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #25 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7671998
Z variance train             0.013943056
KL Divergence                14.452051
KL Loss                      1.4452051
QF Loss                      125.30353
VF Loss                      57.41455
Policy Loss                  -268.5525
Q Predictions Mean           264.02426
Q Predictions Std            40.324284
Q Predictions Max            338.7571
Q Predictions Min            -6.264393
V Predictions Mean           265.84335
V Predictions Std            34.314533
V Predictions Max            328.62518
V Predictions Min            13.52258
Log Pis Mean                 -3.0505385
Log Pis Std                  2.0271177
Log Pis Max                  10.56304
Log Pis Min                  -10.020205
Policy mu Mean               0.034904655
Policy mu Std                0.34602568
Policy mu Max                1.8879055
Policy mu Min                -2.4926836
Policy log std Mean          -0.7365954
Policy log std Std           0.14738698
Policy log std Max           -0.41419873
Policy log std Min           -1.8539121
Z mean eval                  0.7759563
Z variance eval              0.01866042
total_rewards                [219.72985544 -71.74920805 213.28855865 181.63845249 189.12837537
 149.45783177 277.15021392 242.33216753 238.33432962 200.72515692]
total_rewards_mean           184.00357336583482
total_rewards_std            91.69443408659173
total_rewards_max            277.1502139195471
total_rewards_min            -71.74920804843367
Number of train steps total  27000
Number of env steps total    137000
Number of rollouts total     0
Train Time (s)               26.763115728273988
(Previous) Eval Time (s)     24.702343795914203
Sample Time (s)              18.184475107118487
Epoch Time (s)               69.64993463130668
Total Train Time (s)         1810.9634965872392
Epoch                        26
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:45:42.334294 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #26 | Epoch Duration: 73.20777440071106
2020-01-11 03:45:42.334494 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #26 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.77781254
Z variance train             0.018764269
KL Divergence                14.789951
KL Loss                      1.4789952
QF Loss                      154.86755
VF Loss                      44.472855
Policy Loss                  -277.54874
Q Predictions Mean           274.6021
Q Predictions Std            31.11767
Q Predictions Max            328.51895
Q Predictions Min            -5.77285
V Predictions Mean           274.04694
V Predictions Std            29.622057
V Predictions Max            333.7296
V Predictions Min            -3.580032
Log Pis Mean                 -2.8420212
Log Pis Std                  1.8740761
Log Pis Max                  5.676107
Log Pis Min                  -9.852439
Policy mu Mean               0.054800574
Policy mu Std                0.34094942
Policy mu Max                1.7994422
Policy mu Min                -1.8188704
Policy log std Mean          -0.754624
Policy log std Std           0.15707599
Policy log std Max           -0.42197204
Policy log std Min           -1.8445907
Z mean eval                  0.784774
Z variance eval              0.017804269
total_rewards                [228.70116868 274.25057621 246.35571382 158.96786416  65.51500837
  98.11993687 308.11686734 327.4726165  250.30073903  95.66983938]
total_rewards_mean           205.34703303638517
total_rewards_std            89.27637865956473
total_rewards_max            327.4726164986696
total_rewards_min            65.51500836871367
Number of train steps total  28000
Number of env steps total    142000
Number of rollouts total     0
Train Time (s)               27.873672848101705
(Previous) Eval Time (s)     28.259893426205963
Sample Time (s)              18.32898649573326
Epoch Time (s)               74.46255277004093
Total Train Time (s)         1882.463045461569
Epoch                        27
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:46:53.833984 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #27 | Epoch Duration: 71.49934959411621
2020-01-11 03:46:53.834137 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #27 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7850268
Z variance train             0.01778864
KL Divergence                15.229598
KL Loss                      1.5229598
QF Loss                      388.01218
VF Loss                      97.185844
Policy Loss                  -282.4482
Q Predictions Mean           278.28503
Q Predictions Std            32.75839
Q Predictions Max            330.7655
Q Predictions Min            8.865522
V Predictions Mean           280.69135
V Predictions Std            28.489902
V Predictions Max            334.3245
V Predictions Min            35.119953
Log Pis Mean                 -2.7555573
Log Pis Std                  1.7200489
Log Pis Max                  3.9272196
Log Pis Min                  -7.513995
Policy mu Mean               0.047942042
Policy mu Std                0.3584079
Policy mu Max                1.8640476
Policy mu Min                -1.2806234
Policy log std Mean          -0.7513478
Policy log std Std           0.1265368
Policy log std Max           -0.44503015
Policy log std Min           -1.3245828
Z mean eval                  0.7786517
Z variance eval              0.015273402
total_rewards                [322.65398276 162.57982948 256.54174474  19.74189226 185.41627771
 226.20205376  89.72408786 218.85954913 140.48663003 146.06524545]
total_rewards_mean           176.82712931699945
total_rewards_std            81.62774927495961
total_rewards_max            322.6539827591292
total_rewards_min            19.741892260041293
Number of train steps total  29000
Number of env steps total    147000
Number of rollouts total     0
Train Time (s)               26.68394313706085
(Previous) Eval Time (s)     25.296388660091907
Sample Time (s)              17.699599695857614
Epoch Time (s)               69.67993149301037
Total Train Time (s)         1952.1252978867851
Epoch                        28
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:48:03.498622 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #28 | Epoch Duration: 69.66435146331787
2020-01-11 03:48:03.498816 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #28 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7809794
Z variance train             0.015278704
KL Divergence                14.738406
KL Loss                      1.4738406
QF Loss                      136.45888
VF Loss                      47.273197
Policy Loss                  -288.73328
Q Predictions Mean           283.6267
Q Predictions Std            33.44206
Q Predictions Max            340.58917
Q Predictions Min            -38.949596
V Predictions Mean           285.34955
V Predictions Std            27.578405
V Predictions Max            350.3904
V Predictions Min            59.84125
Log Pis Mean                 -2.9582672
Log Pis Std                  1.5484574
Log Pis Max                  2.5507705
Log Pis Min                  -8.625285
Policy mu Mean               0.046379216
Policy mu Std                0.3209607
Policy mu Max                1.1426018
Policy mu Min                -1.4782823
Policy log std Mean          -0.7394495
Policy log std Std           0.13637923
Policy log std Max           -0.36781466
Policy log std Min           -1.6526048
Z mean eval                  0.7699901
Z variance eval              0.013746428
total_rewards                [246.66360295 198.01772681 188.41250238 451.02907144 426.07026893
 250.1201469  341.91748431 261.45930937 460.02969632 333.17969841]
total_rewards_mean           315.6899507821487
total_rewards_std            97.14912694136119
total_rewards_max            460.0296963193616
total_rewards_min            188.41250237533598
Number of train steps total  30000
Number of env steps total    152000
Number of rollouts total     0
Train Time (s)               25.926625015679747
(Previous) Eval Time (s)     25.28052101098001
Sample Time (s)              19.019168213009834
Epoch Time (s)               70.22631423966959
Total Train Time (s)         2021.0735512236133
Epoch                        29
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:49:12.448410 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #29 | Epoch Duration: 68.94942569732666
2020-01-11 03:49:12.448651 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #29 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7658783
Z variance train             0.0137972785
KL Divergence                14.860693
KL Loss                      1.4860693
QF Loss                      162.3968
VF Loss                      31.86914
Policy Loss                  -281.66705
Q Predictions Mean           279.57898
Q Predictions Std            33.1799
Q Predictions Max            343.11212
Q Predictions Min            -19.590673
V Predictions Mean           283.51834
V Predictions Std            32.1938
V Predictions Max            343.18594
V Predictions Min            -24.702333
Log Pis Mean                 -2.9646575
Log Pis Std                  1.7400949
Log Pis Max                  7.8213367
Log Pis Min                  -9.93593
Policy mu Mean               0.053396158
Policy mu Std                0.3204567
Policy mu Max                1.7102147
Policy mu Min                -1.6427199
Policy log std Mean          -0.7392926
Policy log std Std           0.13603288
Policy log std Max           -0.23520611
Policy log std Min           -1.6357927
Z mean eval                  0.7738697
Z variance eval              0.02026751
total_rewards                [ 54.55975132 433.86749084 535.2733309  184.46343164 213.97248889
 141.55532036 165.39954972 394.88310947 367.85811088 254.94852482]
total_rewards_mean           274.67811088467937
total_rewards_std            143.77467525012491
total_rewards_max            535.2733308981489
total_rewards_min            54.55975131777895
Number of train steps total  31000
Number of env steps total    157000
Number of rollouts total     0
Train Time (s)               24.487768333870918
(Previous) Eval Time (s)     24.003323103301227
Sample Time (s)              18.0525656118989
Epoch Time (s)               66.54365704907104
Total Train Time (s)         2084.4483446185477
Epoch                        30
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:50:15.823069 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #30 | Epoch Duration: 63.37422823905945
2020-01-11 03:50:15.823254 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #30 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.77263224
Z variance train             0.020372901
KL Divergence                14.40239
KL Loss                      1.440239
QF Loss                      117.51446
VF Loss                      68.321045
Policy Loss                  -293.63455
Q Predictions Mean           290.57843
Q Predictions Std            39.236668
Q Predictions Max            341.0071
Q Predictions Min            -13.509363
V Predictions Mean           291.88507
V Predictions Std            37.814137
V Predictions Max            343.72836
V Predictions Min            -41.970776
Log Pis Mean                 -2.8492913
Log Pis Std                  1.6587346
Log Pis Max                  4.0810885
Log Pis Min                  -7.394895
Policy mu Mean               0.094547614
Policy mu Std                0.34680784
Policy mu Max                2.4639869
Policy mu Min                -2.2069185
Policy log std Mean          -0.74679935
Policy log std Std           0.15543489
Policy log std Max           0.01631555
Policy log std Min           -1.7076864
Z mean eval                  0.7985636
Z variance eval              0.016128482
total_rewards                [239.64708349 226.44496784 334.24396764 516.68411483 320.11940186
 353.46401003 478.51475961 209.23942832 201.41039963 239.91803593]
total_rewards_mean           311.9686169178049
total_rewards_std            106.03911424414076
total_rewards_max            516.6841148295854
total_rewards_min            201.41039962678082
Number of train steps total  32000
Number of env steps total    162000
Number of rollouts total     0
Train Time (s)               26.230613856576383
(Previous) Eval Time (s)     20.83361671678722
Sample Time (s)              19.155642635654658
Epoch Time (s)               66.21987320901826
Total Train Time (s)         2156.641087961849
Epoch                        31
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:51:28.018149 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #31 | Epoch Duration: 72.19473576545715
2020-01-11 03:51:28.018358 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #31 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.796374
Z variance train             0.016122315
KL Divergence                15.027939
KL Loss                      1.5027939
QF Loss                      156.96738
VF Loss                      50.340324
Policy Loss                  -297.0927
Q Predictions Mean           295.10446
Q Predictions Std            21.458134
Q Predictions Max            363.33072
Q Predictions Min            226.10008
V Predictions Mean           302.11597
V Predictions Std            22.42754
V Predictions Max            367.20236
V Predictions Min            220.77332
Log Pis Mean                 -2.9117777
Log Pis Std                  1.6610363
Log Pis Max                  2.6073208
Log Pis Min                  -9.355399
Policy mu Mean               0.02291039
Policy mu Std                0.31791502
Policy mu Max                1.1057758
Policy mu Min                -1.0338318
Policy log std Mean          -0.77831364
Policy log std Std           0.1477217
Policy log std Max           -0.33850408
Policy log std Min           -1.5744648
Z mean eval                  0.81349814
Z variance eval              0.014644829
total_rewards                [256.97508517 231.03154218 180.60297095 186.67219733 372.56212197
 397.95959293 150.22484902 155.50275539 181.3563338   28.33417146]
total_rewards_mean           214.122162019577
total_rewards_std            102.96049590941092
total_rewards_max            397.9595929273419
total_rewards_min            28.334171461525862
Number of train steps total  33000
Number of env steps total    167000
Number of rollouts total     0
Train Time (s)               27.5904444437474
(Previous) Eval Time (s)     26.80814232910052
Sample Time (s)              19.245804839767516
Epoch Time (s)               73.64439161261544
Total Train Time (s)         2229.246109861415
Epoch                        32
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:52:40.626941 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #32 | Epoch Duration: 72.60826778411865
2020-01-11 03:52:40.627391 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #32 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.81126225
Z variance train             0.014692453
KL Divergence                14.8645
KL Loss                      1.4864501
QF Loss                      94.33034
VF Loss                      54.623405
Policy Loss                  -301.4431
Q Predictions Mean           300.48248
Q Predictions Std            33.928215
Q Predictions Max            358.8151
Q Predictions Min            -13.603962
V Predictions Mean           306.88742
V Predictions Std            29.111578
V Predictions Max            366.88916
V Predictions Min            56.27022
Log Pis Mean                 -3.159423
Log Pis Std                  1.6764936
Log Pis Max                  5.0393066
Log Pis Min                  -9.460457
Policy mu Mean               0.061121017
Policy mu Std                0.29598722
Policy mu Max                1.3468851
Policy mu Min                -1.4158834
Policy log std Mean          -0.75133514
Policy log std Std           0.12773114
Policy log std Max           -0.3566537
Policy log std Min           -1.4091214
Z mean eval                  0.79580534
Z variance eval              0.0118832365
total_rewards                [316.34061312  44.72056029 200.31792138  47.01018111 295.43119991
 539.78931339 536.00526097 177.71493012 231.0851563  413.63402648]
total_rewards_mean           280.20491630463926
total_rewards_std            167.7171362089707
total_rewards_max            539.7893133924937
total_rewards_min            44.720560286652955
Number of train steps total  34000
Number of env steps total    172000
Number of rollouts total     0
Train Time (s)               25.725533698685467
(Previous) Eval Time (s)     25.771705746185035
Sample Time (s)              18.984671857208014
Epoch Time (s)               70.48191130207852
Total Train Time (s)         2296.080437990371
Epoch                        33
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:53:47.461712 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #33 | Epoch Duration: 66.83406281471252
2020-01-11 03:53:47.461944 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #33 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.79991406
Z variance train             0.011840081
KL Divergence                15.390139
KL Loss                      1.5390139
QF Loss                      302.37915
VF Loss                      94.49457
Policy Loss                  -308.41412
Q Predictions Mean           303.8765
Q Predictions Std            34.93788
Q Predictions Max            391.10727
Q Predictions Min            -2.4655972
V Predictions Mean           301.9819
V Predictions Std            34.58567
V Predictions Max            394.09283
V Predictions Min            15.07126
Log Pis Mean                 -2.829511
Log Pis Std                  1.5562015
Log Pis Max                  6.277613
Log Pis Min                  -8.520113
Policy mu Mean               0.029291047
Policy mu Std                0.328224
Policy mu Max                1.155629
Policy mu Min                -3.037689
Policy log std Mean          -0.7708024
Policy log std Std           0.13806044
Policy log std Max           -0.3984789
Policy log std Min           -1.7296336
Z mean eval                  0.7997624
Z variance eval              0.011469017
total_rewards                [613.62049689 204.33169356 474.81927735 102.48343758 217.87224871
 273.01423844 322.80671268 285.76910522 284.26520713 276.52315761]
total_rewards_mean           305.55055751748057
total_rewards_std            136.29795868105407
total_rewards_max            613.6204968937537
total_rewards_min            102.48343758005977
Number of train steps total  35000
Number of env steps total    177000
Number of rollouts total     0
Train Time (s)               27.72141413995996
(Previous) Eval Time (s)     22.123562355991453
Sample Time (s)              18.45872044097632
Epoch Time (s)               68.30369693692774
Total Train Time (s)         2365.585138650611
Epoch                        34
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:54:56.969721 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #34 | Epoch Duration: 69.50745248794556
2020-01-11 03:54:56.970142 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #34 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7988483
Z variance train             0.01149949
KL Divergence                15.380762
KL Loss                      1.5380763
QF Loss                      162.1677
VF Loss                      38.29681
Policy Loss                  -308.3271
Q Predictions Mean           305.653
Q Predictions Std            38.80897
Q Predictions Max            373.50406
Q Predictions Min            0.24111721
V Predictions Mean           307.42456
V Predictions Std            35.298454
V Predictions Max            369.7358
V Predictions Min            -9.853882
Log Pis Mean                 -2.759622
Log Pis Std                  1.9448377
Log Pis Max                  8.825727
Log Pis Min                  -8.228796
Policy mu Mean               0.051096562
Policy mu Std                0.32848912
Policy mu Max                1.6467946
Policy mu Min                -1.8291388
Policy log std Mean          -0.7750391
Policy log std Std           0.142983
Policy log std Max           -0.37977204
Policy log std Min           -1.8589388
Z mean eval                  0.7863915
Z variance eval              0.014677035
total_rewards                [ 45.42789095  57.74303645 129.28560598 295.98736002 309.27049057
 133.33979033 294.45675153 347.4381112  188.12374443 222.39329683]
total_rewards_mean           202.34660782963434
total_rewards_std            102.94407078328433
total_rewards_max            347.4381112027812
total_rewards_min            45.42789094730747
Number of train steps total  36000
Number of env steps total    182000
Number of rollouts total     0
Train Time (s)               28.903704093769193
(Previous) Eval Time (s)     23.326994626782835
Sample Time (s)              18.512391277123243
Epoch Time (s)               70.74308999767527
Total Train Time (s)         2431.3872176506557
Epoch                        35
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:56:02.774772 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #35 | Epoch Duration: 65.8043463230133
2020-01-11 03:56:02.775109 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #35 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7817628
Z variance train             0.014581867
KL Divergence                15.103876
KL Loss                      1.5103877
QF Loss                      163.1334
VF Loss                      58.873985
Policy Loss                  -310.9073
Q Predictions Mean           307.81152
Q Predictions Std            34.372643
Q Predictions Max            394.34625
Q Predictions Min            -1.195832
V Predictions Mean           316.51532
V Predictions Std            31.102024
V Predictions Max            399.46677
V Predictions Min            28.62391
Log Pis Mean                 -3.081427
Log Pis Std                  1.8621163
Log Pis Max                  6.7654676
Log Pis Min                  -10.327641
Policy mu Mean               0.06354298
Policy mu Std                0.31919622
Policy mu Max                1.2899609
Policy mu Min                -1.4253762
Policy log std Mean          -0.7758134
Policy log std Std           0.13305938
Policy log std Max           -0.4254352
Policy log std Min           -1.9822227
Z mean eval                  0.8120845
Z variance eval              0.01190261
total_rewards                [562.957137   574.08100413 228.13345458 232.80350897 242.24291575
 256.71578652   7.82587268  95.4400667  178.3115125  229.17575981]
total_rewards_mean           260.7687018640612
total_rewards_std            170.52862687615837
total_rewards_max            574.0810041313963
total_rewards_min            7.825872676862154
Number of train steps total  37000
Number of env steps total    187000
Number of rollouts total     0
Train Time (s)               30.29506926704198
(Previous) Eval Time (s)     18.387960937805474
Sample Time (s)              19.088959247339517
Epoch Time (s)               67.77198945218697
Total Train Time (s)         2501.7840570546687
Epoch                        36
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:57:13.171645 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #36 | Epoch Duration: 70.39615535736084
2020-01-11 03:57:13.172011 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #36 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.81133974
Z variance train             0.011868821
KL Divergence                15.486149
KL Loss                      1.5486149
QF Loss                      130.61353
VF Loss                      41.77863
Policy Loss                  -316.76913
Q Predictions Mean           311.59702
Q Predictions Std            44.480675
Q Predictions Max            369.1749
Q Predictions Min            -24.94041
V Predictions Mean           317.10315
V Predictions Std            34.655445
V Predictions Max            377.9884
V Predictions Min            22.854246
Log Pis Mean                 -2.9062238
Log Pis Std                  1.7159638
Log Pis Max                  6.569688
Log Pis Min                  -7.122958
Policy mu Mean               0.044092387
Policy mu Std                0.31266814
Policy mu Max                1.1552476
Policy mu Min                -1.6050397
Policy log std Mean          -0.76144445
Policy log std Std           0.15449
Policy log std Max           -0.3784804
Policy log std Min           -1.9403936
Z mean eval                  0.7899966
Z variance eval              0.015322109
total_rewards                [ 71.78107232  52.17822558 259.90110502 195.36848702 260.41572054
 248.18817227 537.55232662 126.55112909 344.49930133 425.06950693]
total_rewards_mean           252.15050467329792
total_rewards_std            145.4472455712616
total_rewards_max            537.5523266249579
total_rewards_min            52.17822558209087
Number of train steps total  38000
Number of env steps total    192000
Number of rollouts total     0
Train Time (s)               26.654523170087487
(Previous) Eval Time (s)     21.01183094503358
Sample Time (s)              18.40460590366274
Epoch Time (s)               66.07096001878381
Total Train Time (s)         2568.8169862418436
Epoch                        37
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:58:20.205346 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #37 | Epoch Duration: 67.033123254776
2020-01-11 03:58:20.205581 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #37 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7898148
Z variance train             0.015410727
KL Divergence                15.478196
KL Loss                      1.5478196
QF Loss                      109.59188
VF Loss                      82.6082
Policy Loss                  -319.04422
Q Predictions Mean           316.33594
Q Predictions Std            34.28622
Q Predictions Max            396.79272
Q Predictions Min            31.516495
V Predictions Mean           324.83624
V Predictions Std            29.43903
V Predictions Max            402.11508
V Predictions Min            112.826454
Log Pis Mean                 -2.7948074
Log Pis Std                  1.7569478
Log Pis Max                  4.8748126
Log Pis Min                  -7.731574
Policy mu Mean               0.05564673
Policy mu Std                0.32502094
Policy mu Max                2.196056
Policy mu Min                -1.7143375
Policy log std Mean          -0.7788903
Policy log std Std           0.14874274
Policy log std Max           -0.37732953
Policy log std Min           -1.9650885
Z mean eval                  0.7974572
Z variance eval              0.016433844
total_rewards                [536.71314164 373.74217949 197.56421407 628.89521622 279.18873869
 455.13693211 192.76406104 315.65564778 375.76890744 216.61326418]
total_rewards_mean           357.20423026537543
total_rewards_std            140.12581190152017
total_rewards_max            628.8952162185373
total_rewards_min            192.76406104015865
Number of train steps total  39000
Number of env steps total    197000
Number of rollouts total     0
Train Time (s)               25.172023478895426
(Previous) Eval Time (s)     21.97370264073834
Sample Time (s)              17.87066791485995
Epoch Time (s)               65.01639403449371
Total Train Time (s)         2637.585715209134
Epoch                        38
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:59:28.975094 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #38 | Epoch Duration: 68.76926612854004
2020-01-11 03:59:28.975346 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #38 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7983228
Z variance train             0.016434748
KL Divergence                15.439045
KL Loss                      1.5439045
QF Loss                      166.85406
VF Loss                      35.512405
Policy Loss                  -322.5543
Q Predictions Mean           317.89627
Q Predictions Std            37.074757
Q Predictions Max            396.14148
Q Predictions Min            -5.249235
V Predictions Mean           319.91785
V Predictions Std            33.430374
V Predictions Max            393.24738
V Predictions Min            0.78805536
Log Pis Mean                 -2.8286085
Log Pis Std                  1.6550952
Log Pis Max                  1.6653223
Log Pis Min                  -9.006538
Policy mu Mean               0.044833552
Policy mu Std                0.3074588
Policy mu Max                1.9553895
Policy mu Min                -1.6371406
Policy log std Mean          -0.8154963
Policy log std Std           0.14278194
Policy log std Max           -0.48251134
Policy log std Min           -1.5990126
Z mean eval                  0.8081606
Z variance eval              0.014622383
total_rewards                [345.06697124  47.19311089 174.00043865 483.69279695 633.43899052
 166.92123444 500.33033638 171.31981944  64.10140449 241.50263285]
total_rewards_mean           282.7567735846487
total_rewards_std            189.0080526671105
total_rewards_max            633.4389905222487
total_rewards_min            47.1931108947941
Number of train steps total  40000
Number of env steps total    202000
Number of rollouts total     0
Train Time (s)               28.036943424958736
(Previous) Eval Time (s)     25.726241477765143
Sample Time (s)              19.01010990748182
Epoch Time (s)               72.7732948102057
Total Train Time (s)         2700.247945719864
Epoch                        39
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:00:31.637588 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #39 | Epoch Duration: 62.66209578514099
2020-01-11 04:00:31.637748 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #39 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8079885
Z variance train             0.014617458
KL Divergence                16.042326
KL Loss                      1.6042327
QF Loss                      167.35788
VF Loss                      57.86468
Policy Loss                  -326.64975
Q Predictions Mean           325.07526
Q Predictions Std            29.81944
Q Predictions Max            398.6382
Q Predictions Min            8.82721
V Predictions Mean           328.19287
V Predictions Std            29.824434
V Predictions Max            396.4111
V Predictions Min            14.335817
Log Pis Mean                 -2.7607412
Log Pis Std                  1.6911871
Log Pis Max                  7.8218927
Log Pis Min                  -9.400939
Policy mu Mean               0.021489475
Policy mu Std                0.30881
Policy mu Max                1.4851677
Policy mu Min                -1.5512114
Policy log std Mean          -0.8194401
Policy log std Std           0.15004666
Policy log std Max           -0.3715225
Policy log std Min           -1.8778483
Z mean eval                  0.8223106
Z variance eval              0.018016908
total_rewards                [540.41390684 431.21243277 348.37967472 293.56634132 249.90750478
 175.3651696  482.62280222 451.98019292 114.454731   140.48736145]
total_rewards_mean           322.8390117627205
total_rewards_std            143.7166740810801
total_rewards_max            540.4139068448112
total_rewards_min            114.45473099683792
Number of train steps total  41000
Number of env steps total    207000
Number of rollouts total     0
Train Time (s)               29.03519000299275
(Previous) Eval Time (s)     15.614734085276723
Sample Time (s)              19.301058046519756
Epoch Time (s)               63.95098213478923
Total Train Time (s)         2773.10077460343
Epoch                        40
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:01:44.491513 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #40 | Epoch Duration: 72.85361576080322
2020-01-11 04:01:44.491708 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #40 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8193482
Z variance train             0.017992038
KL Divergence                16.006649
KL Loss                      1.600665
QF Loss                      161.56693
VF Loss                      24.728008
Policy Loss                  -336.85867
Q Predictions Mean           334.33038
Q Predictions Std            43.966064
Q Predictions Max            403.11295
Q Predictions Min            -8.226973
V Predictions Mean           335.48346
V Predictions Std            42.162888
V Predictions Max            405.11862
V Predictions Min            10.233463
Log Pis Mean                 -2.8226914
Log Pis Std                  1.8026079
Log Pis Max                  6.9778595
Log Pis Min                  -7.835019
Policy mu Mean               -0.0381509
Policy mu Std                0.3290929
Policy mu Max                1.9216088
Policy mu Min                -2.406027
Policy log std Mean          -0.7865526
Policy log std Std           0.14197198
Policy log std Max           -0.40670907
Policy log std Min           -1.8371272
Z mean eval                  0.80505645
Z variance eval              0.019476179
total_rewards                [283.9381733  373.83402489 310.91622822 296.18495913   6.59562442
 249.87479839 272.39814875 273.40140045 187.59148502 161.18304408]
total_rewards_mean           241.5917886645015
total_rewards_std            96.79969276625931
total_rewards_max            373.83402488904153
total_rewards_min            6.595624421566688
Number of train steps total  42000
Number of env steps total    212000
Number of rollouts total     0
Train Time (s)               28.013907020911574
(Previous) Eval Time (s)     24.51706035900861
Sample Time (s)              18.56665640231222
Epoch Time (s)               71.0976237822324
Total Train Time (s)         2843.3488158369437
Epoch                        41
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:02:54.741840 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #41 | Epoch Duration: 70.2499487400055
2020-01-11 04:02:54.742063 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #41 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.80466795
Z variance train             0.01948788
KL Divergence                15.912004
KL Loss                      1.5912005
QF Loss                      144.39706
VF Loss                      42.652977
Policy Loss                  -333.73587
Q Predictions Mean           330.41544
Q Predictions Std            40.99793
Q Predictions Max            417.51883
Q Predictions Min            -29.792728
V Predictions Mean           333.12418
V Predictions Std            35.858604
V Predictions Max            412.97647
V Predictions Min            11.747393
Log Pis Mean                 -2.883854
Log Pis Std                  1.4496377
Log Pis Max                  0.33044976
Log Pis Min                  -8.31875
Policy mu Mean               0.0137185
Policy mu Std                0.30322617
Policy mu Max                1.9117794
Policy mu Min                -1.1377403
Policy log std Mean          -0.77417314
Policy log std Std           0.13503987
Policy log std Max           -0.43046707
Policy log std Min           -1.5060688
Z mean eval                  0.80447114
Z variance eval              0.014865798
total_rewards                [408.62420141 368.68903947 264.63955903 511.62359111 365.47792879
 313.99455755  58.54559514 563.18343605 440.2217012  320.11120427]
total_rewards_mean           361.51108140318837
total_rewards_std            132.97808785098442
total_rewards_max            563.1834360542979
total_rewards_min            58.54559514307448
Number of train steps total  43000
Number of env steps total    217000
Number of rollouts total     0
Train Time (s)               28.422670356929302
(Previous) Eval Time (s)     23.66909060627222
Sample Time (s)              18.180722386110574
Epoch Time (s)               70.2724833493121
Total Train Time (s)         2914.514129581861
Epoch                        42
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:04:05.910801 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #42 | Epoch Duration: 71.16855001449585
2020-01-11 04:04:05.911068 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #42 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8047541
Z variance train             0.014865035
KL Divergence                16.736244
KL Loss                      1.6736244
QF Loss                      127.78496
VF Loss                      40.17981
Policy Loss                  -326.85928
Q Predictions Mean           323.7555
Q Predictions Std            56.507496
Q Predictions Max            413.1879
Q Predictions Min            -17.320232
V Predictions Mean           325.77597
V Predictions Std            55.91823
V Predictions Max            410.69055
V Predictions Min            -15.517127
Log Pis Mean                 -2.7433496
Log Pis Std                  1.90336
Log Pis Max                  7.45051
Log Pis Min                  -9.23304
Policy mu Mean               0.03163413
Policy mu Std                0.33421305
Policy mu Max                1.7226882
Policy mu Min                -1.506763
Policy log std Mean          -0.7825661
Policy log std Std           0.15049206
Policy log std Max           -0.280898
Policy log std Min           -1.477716
Z mean eval                  0.81466657
Z variance eval              0.013608192
total_rewards                [ 49.79803576 209.27814045 218.2297276  153.68945515 166.1919987
  88.33252521 381.57950853 417.77242348 180.57350969 253.06679913]
total_rewards_mean           211.85121236984727
total_rewards_std            109.96418374024914
total_rewards_max            417.77242348311506
total_rewards_min            49.798035762160204
Number of train steps total  44000
Number of env steps total    222000
Number of rollouts total     0
Train Time (s)               29.331219749059528
(Previous) Eval Time (s)     24.564867781940848
Sample Time (s)              18.967769879847765
Epoch Time (s)               72.86385741084814
Total Train Time (s)         2984.001841260586
Epoch                        43
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:05:15.397010 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #43 | Epoch Duration: 69.48574686050415
2020-01-11 04:05:15.397159 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #43 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8160682
Z variance train             0.013625774
KL Divergence                16.32885
KL Loss                      1.632885
QF Loss                      255.94595
VF Loss                      44.688625
Policy Loss                  -342.26056
Q Predictions Mean           337.87164
Q Predictions Std            41.254486
Q Predictions Max            411.46725
Q Predictions Min            -0.6582997
V Predictions Mean           338.075
V Predictions Std            39.200317
V Predictions Max            405.34903
V Predictions Min            28.975967
Log Pis Mean                 -2.9625201
Log Pis Std                  1.7323954
Log Pis Max                  6.698341
Log Pis Min                  -7.926832
Policy mu Mean               0.017039597
Policy mu Std                0.3164579
Policy mu Max                1.5591819
Policy mu Min                -1.4768586
Policy log std Mean          -0.7645022
Policy log std Std           0.15865351
Policy log std Max           -0.43566164
Policy log std Min           -1.8523582
Z mean eval                  0.80745
Z variance eval              0.0133001935
total_rewards                [354.11550925 228.64433135 538.22651482 277.80450944 189.3347526
 353.43339702 258.86359118 237.88790688 217.86319425 306.07016222]
total_rewards_mean           296.2243869019182
total_rewards_std            96.20676809973236
total_rewards_max            538.2265148209417
total_rewards_min            189.33475259994094
Number of train steps total  45000
Number of env steps total    227000
Number of rollouts total     0
Train Time (s)               27.89505500625819
(Previous) Eval Time (s)     21.186477091163397
Sample Time (s)              17.728863310534507
Epoch Time (s)               66.8103954079561
Total Train Time (s)         3054.738431226928
Epoch                        44
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:06:26.136825 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #44 | Epoch Duration: 70.73952651023865
2020-01-11 04:06:26.137029 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #44 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.80768555
Z variance train             0.013281028
KL Divergence                15.95775
KL Loss                      1.595775
QF Loss                      149.64413
VF Loss                      26.272923
Policy Loss                  -344.98923
Q Predictions Mean           342.93982
Q Predictions Std            25.082594
Q Predictions Max            409.33603
Q Predictions Min            258.07874
V Predictions Mean           346.7558
V Predictions Std            25.051443
V Predictions Max            403.9058
V Predictions Min            278.45062
Log Pis Mean                 -2.9411578
Log Pis Std                  1.6731529
Log Pis Max                  3.4907334
Log Pis Min                  -9.002154
Policy mu Mean               0.028811894
Policy mu Std                0.31374604
Policy mu Max                1.1324953
Policy mu Min                -1.0065082
Policy log std Mean          -0.7649702
Policy log std Std           0.13746597
Policy log std Max           -0.3206239
Policy log std Min           -1.6561513
Z mean eval                  0.8091407
Z variance eval              0.012542789
total_rewards                [241.74422359 550.88150603 339.62393306 359.95970935 367.1793015
 414.01205891 330.05686164 595.56996895 487.79204563 197.60972812]
total_rewards_mean           388.4429336768436
total_rewards_std            120.33512079738715
total_rewards_max            595.5699689460167
total_rewards_min            197.60972811652198
Number of train steps total  46000
Number of env steps total    232000
Number of rollouts total     0
Train Time (s)               26.81837469385937
(Previous) Eval Time (s)     25.115316424984485
Sample Time (s)              18.93168356223032
Epoch Time (s)               70.86537468107417
Total Train Time (s)         3127.171344930306
Epoch                        45
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:07:38.569058 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #45 | Epoch Duration: 72.43187808990479
2020-01-11 04:07:38.569259 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #45 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.80856675
Z variance train             0.0125403255
KL Divergence                16.21865
KL Loss                      1.6218652
QF Loss                      139.58688
VF Loss                      28.012146
Policy Loss                  -350.12186
Q Predictions Mean           348.65607
Q Predictions Std            26.126358
Q Predictions Max            416.1751
Q Predictions Min            244.68503
V Predictions Mean           352.50037
V Predictions Std            26.278131
V Predictions Max            417.64362
V Predictions Min            222.86711
Log Pis Mean                 -2.8541505
Log Pis Std                  1.716267
Log Pis Max                  1.8113286
Log Pis Min                  -8.604999
Policy mu Mean               0.023205679
Policy mu Std                0.31586716
Policy mu Max                1.2589817
Policy mu Min                -1.6372228
Policy log std Mean          -0.7945501
Policy log std Std           0.15248863
Policy log std Max           -0.37793043
Policy log std Min           -1.863426
Z mean eval                  0.8111132
Z variance eval              0.010555501
total_rewards                [249.56712657 152.07501166 194.50436514 228.89942055 291.49648855
 573.4394406  309.79550791 660.84034873 744.46120664  97.68934437]
total_rewards_mean           350.2768260728431
total_rewards_std            214.23137447338863
total_rewards_max            744.4612066404208
total_rewards_min            97.68934437385919
Number of train steps total  47000
Number of env steps total    237000
Number of rollouts total     0
Train Time (s)               28.66368319839239
(Previous) Eval Time (s)     26.681495619937778
Sample Time (s)              18.397144082468003
Epoch Time (s)               73.74232290079817
Total Train Time (s)         3196.7352440180257
Epoch                        46
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:08:48.136468 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #46 | Epoch Duration: 69.5670690536499
2020-01-11 04:08:48.136682 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #46 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8118909
Z variance train             0.010583001
KL Divergence                15.769209
KL Loss                      1.5769209
QF Loss                      117.72101
VF Loss                      78.06004
Policy Loss                  -342.88007
Q Predictions Mean           339.09918
Q Predictions Std            46.152805
Q Predictions Max            404.5696
Q Predictions Min            -15.46731
V Predictions Mean           340.13678
V Predictions Std            43.8095
V Predictions Max            400.7169
V Predictions Min            11.976256
Log Pis Mean                 -2.7085493
Log Pis Std                  1.9521893
Log Pis Max                  8.936626
Log Pis Min                  -10.183688
Policy mu Mean               0.020117454
Policy mu Std                0.33511204
Policy mu Max                1.3021035
Policy mu Min                -1.915746
Policy log std Mean          -0.8023311
Policy log std Std           0.16438335
Policy log std Max           -0.39728487
Policy log std Min           -1.9137367
Z mean eval                  0.82143945
Z variance eval              0.01807115
total_rewards                [615.19150152 135.12793738 633.09307315 159.1462093  119.19813569
 276.27779596 303.39894628 499.77617544 246.71191014 657.1564983 ]
total_rewards_mean           364.5078183158213
total_rewards_std            204.76356955480554
total_rewards_max            657.15649830361
total_rewards_min            119.19813568984974
Number of train steps total  48000
Number of env steps total    242000
Number of rollouts total     0
Train Time (s)               25.682717863004655
(Previous) Eval Time (s)     22.50592914223671
Sample Time (s)              17.555466641671956
Epoch Time (s)               65.74411364691332
Total Train Time (s)         3265.559481624514
Epoch                        47
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:09:56.960741 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #47 | Epoch Duration: 68.82388639450073
2020-01-11 04:09:56.960947 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #47 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8214429
Z variance train             0.018125918
KL Divergence                15.560294
KL Loss                      1.5560294
QF Loss                      179.20407
VF Loss                      63.21602
Policy Loss                  -351.1158
Q Predictions Mean           348.93915
Q Predictions Std            48.579987
Q Predictions Max            417.58456
Q Predictions Min            -30.448668
V Predictions Mean           349.12338
V Predictions Std            44.253365
V Predictions Max            418.45035
V Predictions Min            18.444342
Log Pis Mean                 -2.6299314
Log Pis Std                  2.077522
Log Pis Max                  7.7849517
Log Pis Min                  -8.790115
Policy mu Mean               0.053459365
Policy mu Std                0.35244325
Policy mu Max                1.4417102
Policy mu Min                -1.3777083
Policy log std Mean          -0.80529803
Policy log std Std           0.17368759
Policy log std Max           -0.3838036
Policy log std Min           -2.0088515
Z mean eval                  0.81672823
Z variance eval              0.017194733
total_rewards                [727.83264865 258.0930308  304.6647673  339.52254177 236.49704929
 199.44752781 662.90212461 265.94563619 302.68272629 317.99428068]
total_rewards_mean           361.55823333928436
total_rewards_std            171.99379845557598
total_rewards_max            727.8326486489648
total_rewards_min            199.44752780897386
Number of train steps total  49000
Number of env steps total    247000
Number of rollouts total     0
Train Time (s)               26.925372815225273
(Previous) Eval Time (s)     25.58542653499171
Sample Time (s)              18.476802026387304
Epoch Time (s)               70.98760137660429
Total Train Time (s)         3338.6976445335895
Epoch                        48
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:11:10.101632 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #48 | Epoch Duration: 73.14047741889954
2020-01-11 04:11:10.101902 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #48 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8158151
Z variance train             0.017109035
KL Divergence                15.817215
KL Loss                      1.5817215
QF Loss                      110.25838
VF Loss                      20.09011
Policy Loss                  -355.70767
Q Predictions Mean           352.1467
Q Predictions Std            33.769714
Q Predictions Max            432.2449
Q Predictions Min            37.913918
V Predictions Mean           357.67252
V Predictions Std            31.377342
V Predictions Max            435.64667
V Predictions Min            102.11248
Log Pis Mean                 -2.9049096
Log Pis Std                  1.5759073
Log Pis Max                  1.6533121
Log Pis Min                  -7.8071785
Policy mu Mean               0.029004619
Policy mu Std                0.32637748
Policy mu Max                1.058201
Policy mu Min                -1.1328586
Policy log std Mean          -0.79439384
Policy log std Std           0.14301819
Policy log std Max           -0.4222151
Policy log std Min           -1.5190759
Z mean eval                  0.81187755
Z variance eval              0.012928223
total_rewards                [210.47871588 396.48877058 597.46306046 430.42108332 512.4578254
 530.48121644 458.78676676 391.11437051 417.79445135 691.92866502]
total_rewards_mean           463.74149257157006
total_rewards_std            124.08219305123683
total_rewards_max            691.9286650189233
total_rewards_min            210.47871587896597
Number of train steps total  50000
Number of env steps total    252000
Number of rollouts total     0
Train Time (s)               30.39946267893538
(Previous) Eval Time (s)     27.738010487053543
Sample Time (s)              19.733163479249924
Epoch Time (s)               77.87063664523885
Total Train Time (s)         3415.9294491847977
Epoch                        49
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:12:27.334150 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #49 | Epoch Duration: 77.2320442199707
2020-01-11 04:12:27.334364 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #49 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8113245
Z variance train             0.012908128
KL Divergence                15.4984045
KL Loss                      1.5498405
QF Loss                      194.04723
VF Loss                      31.30147
Policy Loss                  -360.51608
Q Predictions Mean           357.312
Q Predictions Std            40.16957
Q Predictions Max            431.6584
Q Predictions Min            13.899
V Predictions Mean           357.53558
V Predictions Std            38.863045
V Predictions Max            428.07556
V Predictions Min            23.052252
Log Pis Mean                 -2.7640061
Log Pis Std                  1.8062696
Log Pis Max                  4.8727636
Log Pis Min                  -8.365217
Policy mu Mean               0.08199888
Policy mu Std                0.3201614
Policy mu Max                1.2813345
Policy mu Min                -1.3649118
Policy log std Mean          -0.81012154
Policy log std Std           0.16022435
Policy log std Max           -0.42266536
Policy log std Min           -1.7561952
Z mean eval                  0.8316635
Z variance eval              0.012104737
total_rewards                [ 54.0296543  491.79148091 708.82644542 289.20677933 664.72353513
 811.45767175 258.83968129 550.36202224 107.6636794  450.38516043]
total_rewards_mean           438.7286110190477
total_rewards_std            243.0393264122654
total_rewards_max            811.4576717460009
total_rewards_min            54.029654295447585
Number of train steps total  51000
Number of env steps total    257000
Number of rollouts total     0
Train Time (s)               28.772571854293346
(Previous) Eval Time (s)     27.09911274118349
Sample Time (s)              18.30313781509176
Epoch Time (s)               74.1748224105686
Total Train Time (s)         3485.8598514515907
Epoch                        50
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:13:37.266541 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #50 | Epoch Duration: 69.93200588226318
2020-01-11 04:13:37.266770 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #50 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8266894
Z variance train             0.012080883
KL Divergence                15.675956
KL Loss                      1.5675956
QF Loss                      188.996
VF Loss                      31.42228
Policy Loss                  -360.41672
Q Predictions Mean           357.58374
Q Predictions Std            32.11384
Q Predictions Max            426.88705
Q Predictions Min            200.05238
V Predictions Mean           363.2622
V Predictions Std            30.579529
V Predictions Max            434.6431
V Predictions Min            271.17343
Log Pis Mean                 -2.8963144
Log Pis Std                  1.7817934
Log Pis Max                  5.642202
Log Pis Min                  -9.486546
Policy mu Mean               0.057754714
Policy mu Std                0.33287537
Policy mu Max                1.3287252
Policy mu Min                -1.0251387
Policy log std Mean          -0.78318745
Policy log std Std           0.17157407
Policy log std Max           -0.36391857
Policy log std Min           -1.9735897
Z mean eval                  0.81960773
Z variance eval              0.014349001
total_rewards                [178.29719185 140.63071294   8.16026862 129.70734493 264.18297455
 630.19615637 352.05349031 234.65925999 530.82445788 441.35391988]
total_rewards_mean           291.00657773188294
total_rewards_std            185.50567217332545
total_rewards_max            630.1961563668647
total_rewards_min            8.160268622085578
Number of train steps total  52000
Number of env steps total    262000
Number of rollouts total     0
Train Time (s)               27.097180482931435
(Previous) Eval Time (s)     22.8559861429967
Sample Time (s)              18.228359398897737
Epoch Time (s)               68.18152602482587
Total Train Time (s)         3551.5646804757416
Epoch                        51
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:14:42.975483 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #51 | Epoch Duration: 65.70852708816528
2020-01-11 04:14:42.975715 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #51 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.81719697
Z variance train             0.014450093
KL Divergence                15.140713
KL Loss                      1.5140713
QF Loss                      279.7078
VF Loss                      54.09053
Policy Loss                  -364.2611
Q Predictions Mean           362.17166
Q Predictions Std            45.573833
Q Predictions Max            476.99286
Q Predictions Min            -20.259342
V Predictions Mean           370.0345
V Predictions Std            38.979935
V Predictions Max            485.88107
V Predictions Min            21.019634
Log Pis Mean                 -2.679289
Log Pis Std                  1.8405964
Log Pis Max                  5.0956354
Log Pis Min                  -8.898292
Policy mu Mean               0.06348329
Policy mu Std                0.33507285
Policy mu Max                1.2487913
Policy mu Min                -2.2944024
Policy log std Mean          -0.7961225
Policy log std Std           0.14486061
Policy log std Max           -0.392954
Policy log std Min           -1.5724276
Z mean eval                  0.8213089
Z variance eval              0.011591291
total_rewards                [610.01486088 176.98900544 625.56804753 396.62098791  54.49295519
 321.32888739 384.81939572 374.14092264 283.07823274  89.70129437]
total_rewards_mean           331.6754589805428
total_rewards_std            182.8850647793886
total_rewards_max            625.5680475260699
total_rewards_min            54.492955187967546
Number of train steps total  53000
Number of env steps total    267000
Number of rollouts total     0
Train Time (s)               26.443884385749698
(Previous) Eval Time (s)     20.38270544121042
Sample Time (s)              18.224346722941846
Epoch Time (s)               65.05093654990196
Total Train Time (s)         3616.714787494391
Epoch                        52
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:15:48.122921 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #52 | Epoch Duration: 65.14703702926636
2020-01-11 04:15:48.123073 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #52 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.82217824
Z variance train             0.011541474
KL Divergence                15.766862
KL Loss                      1.5766863
QF Loss                      384.86478
VF Loss                      89.37344
Policy Loss                  -368.6933
Q Predictions Mean           362.84222
Q Predictions Std            45.695724
Q Predictions Max            455.681
Q Predictions Min            -56.865784
V Predictions Mean           369.2723
V Predictions Std            30.01864
V Predictions Max            460.087
V Predictions Min            262.13165
Log Pis Mean                 -2.636076
Log Pis Std                  1.8560567
Log Pis Max                  8.459513
Log Pis Min                  -10.605503
Policy mu Mean               0.077479325
Policy mu Std                0.34189698
Policy mu Max                1.4084789
Policy mu Min                -1.0579523
Policy log std Mean          -0.7975232
Policy log std Std           0.16050014
Policy log std Max           -0.40379748
Policy log std Min           -2.2999294
Z mean eval                  0.8234863
Z variance eval              0.010827424
total_rewards                [362.69668146 791.50071402 108.53654518 355.3558383  270.0546105
 280.56813654 537.0329339  244.24199729 638.06402947 527.73382066]
total_rewards_mean           411.5785307318205
total_rewards_std            196.83661633210136
total_rewards_max            791.500714018416
total_rewards_min            108.53654517903833
Number of train steps total  54000
Number of env steps total    272000
Number of rollouts total     0
Train Time (s)               29.874001041986048
(Previous) Eval Time (s)     20.478517852257937
Sample Time (s)              19.172903404105455
Epoch Time (s)               69.52542229834944
Total Train Time (s)         3687.3005087384954
Epoch                        53
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:16:58.709989 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #53 | Epoch Duration: 70.58679699897766
2020-01-11 04:16:58.710180 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #53 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8229575
Z variance train             0.010826922
KL Divergence                15.964656
KL Loss                      1.5964656
QF Loss                      171.93033
VF Loss                      94.37228
Policy Loss                  -372.12515
Q Predictions Mean           369.00922
Q Predictions Std            42.976505
Q Predictions Max            445.91312
Q Predictions Min            -4.534584
V Predictions Mean           380.12738
V Predictions Std            39.41678
V Predictions Max            459.49484
V Predictions Min            -7.5415864
Log Pis Mean                 -2.6565177
Log Pis Std                  1.7526478
Log Pis Max                  5.7456512
Log Pis Min                  -7.8003125
Policy mu Mean               0.020326216
Policy mu Std                0.32380596
Policy mu Max                1.4918844
Policy mu Min                -1.3271695
Policy log std Mean          -0.8066346
Policy log std Std           0.14453734
Policy log std Max           -0.3550755
Policy log std Min           -2.0086493
Z mean eval                  0.8141901
Z variance eval              0.010475473
total_rewards                [318.99647745 374.33723022 322.41768702 793.45745503 411.06814331
 674.67842136 331.97921791 783.06794305 333.26549971 335.11271918]
total_rewards_mean           467.8380794240367
total_rewards_std            189.11117098407422
total_rewards_max            793.4574550261502
total_rewards_min            318.9964774529009
Number of train steps total  55000
Number of env steps total    277000
Number of rollouts total     0
Train Time (s)               29.574626437854022
(Previous) Eval Time (s)     21.53958335891366
Sample Time (s)              17.532171356026083
Epoch Time (s)               68.64638115279377
Total Train Time (s)         3762.1726420549676
Epoch                        54
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:18:13.586371 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #54 | Epoch Duration: 74.87602186203003
2020-01-11 04:18:13.586678 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #54 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.815654
Z variance train             0.010481994
KL Divergence                15.876492
KL Loss                      1.5876492
QF Loss                      183.3064
VF Loss                      113.64712
Policy Loss                  -370.25305
Q Predictions Mean           366.13324
Q Predictions Std            55.75505
Q Predictions Max            425.95453
Q Predictions Min            -37.47028
V Predictions Mean           361.41504
V Predictions Std            51.241642
V Predictions Max            423.9448
V Predictions Min            0.11735469
Log Pis Mean                 -2.6045291
Log Pis Std                  1.8372096
Log Pis Max                  7.5218086
Log Pis Min                  -10.328311
Policy mu Mean               0.036826774
Policy mu Std                0.3533193
Policy mu Max                1.7458032
Policy mu Min                -2.0753982
Policy log std Mean          -0.8012195
Policy log std Std           0.14225343
Policy log std Max           -0.4298404
Policy log std Min           -1.4865692
Z mean eval                  0.81977236
Z variance eval              0.010752186
total_rewards                [ 35.11648474 626.15006835  23.90444815 366.3985364  756.82788181
 527.3074976  489.49354924 115.14830195  67.4880357  356.52938523]
total_rewards_mean           336.43641891671894
total_rewards_std            251.31539733443165
total_rewards_max            756.8278818107461
total_rewards_min            23.904448149459267
Number of train steps total  56000
Number of env steps total    282000
Number of rollouts total     0
Train Time (s)               31.736543694045395
(Previous) Eval Time (s)     27.768924822099507
Sample Time (s)              17.94925923086703
Epoch Time (s)               77.45472774701193
Total Train Time (s)         3828.825454398524
Epoch                        55
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:19:20.238393 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #55 | Epoch Duration: 66.65149855613708
2020-01-11 04:19:20.238604 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #55 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8218919
Z variance train             0.010781242
KL Divergence                15.723259
KL Loss                      1.572326
QF Loss                      126.047745
VF Loss                      24.756767
Policy Loss                  -383.44342
Q Predictions Mean           379.53662
Q Predictions Std            47.893337
Q Predictions Max            460.86032
Q Predictions Min            19.332478
V Predictions Mean           381.24426
V Predictions Std            45.99956
V Predictions Max            459.09232
V Predictions Min            13.815419
Log Pis Mean                 -2.5722017
Log Pis Std                  1.963226
Log Pis Max                  10.714093
Log Pis Min                  -8.676916
Policy mu Mean               0.05173993
Policy mu Std                0.3470544
Policy mu Max                1.7817911
Policy mu Min                -3.2501433
Policy log std Mean          -0.8172071
Policy log std Std           0.15480001
Policy log std Max           -0.33378327
Policy log std Min           -1.9699277
Z mean eval                  0.82508194
Z variance eval              0.012128641
total_rewards                [138.78504026 309.71567463 597.90323074 490.88451951 420.25055564
 234.08755351 514.55974122 251.22572041 503.12331095 254.10954605]
total_rewards_mean           371.46448929284327
total_rewards_std            145.182861524131
total_rewards_max            597.9032307412066
total_rewards_min            138.78504026430122
Number of train steps total  57000
Number of env steps total    287000
Number of rollouts total     0
Train Time (s)               28.267299289349467
(Previous) Eval Time (s)     16.9654313409701
Sample Time (s)              18.250169344246387
Epoch Time (s)               63.48289997456595
Total Train Time (s)         3900.562148041092
Epoch                        56
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:20:31.978281 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #56 | Epoch Duration: 71.73953056335449
2020-01-11 04:20:31.978537 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #56 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8294733
Z variance train             0.012168719
KL Divergence                15.378234
KL Loss                      1.5378234
QF Loss                      270.92993
VF Loss                      79.93054
Policy Loss                  -384.49094
Q Predictions Mean           380.00385
Q Predictions Std            46.406197
Q Predictions Max            456.5685
Q Predictions Min            -36.683548
V Predictions Mean           377.65118
V Predictions Std            37.77099
V Predictions Max            452.91803
V Predictions Min            13.330762
Log Pis Mean                 -2.7456024
Log Pis Std                  1.8595928
Log Pis Max                  5.9009466
Log Pis Min                  -9.40719
Policy mu Mean               0.07588927
Policy mu Std                0.32940856
Policy mu Max                1.1787354
Policy mu Min                -0.97790885
Policy log std Mean          -0.80016506
Policy log std Std           0.15999217
Policy log std Max           -0.42780262
Policy log std Min           -1.9731579
Z mean eval                  0.82338274
Z variance eval              0.009714234
total_rewards                [241.05433968 570.66894708 324.22649419 822.41786896 372.81451113
 807.97763614 477.20305533 454.689322   739.25941305 326.79786035]
total_rewards_mean           513.7109447907636
total_rewards_std            201.45963408558333
total_rewards_max            822.4178689585283
total_rewards_min            241.0543396788887
Number of train steps total  58000
Number of env steps total    292000
Number of rollouts total     0
Train Time (s)               29.339919089805335
(Previous) Eval Time (s)     25.22174333734438
Sample Time (s)              17.490504308138043
Epoch Time (s)               72.05216673528776
Total Train Time (s)         3970.7330453707837
Epoch                        57
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:21:42.152279 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #57 | Epoch Duration: 70.17351388931274
2020-01-11 04:21:42.152613 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #57 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8244692
Z variance train             0.009706795
KL Divergence                15.951052
KL Loss                      1.5951052
QF Loss                      223.91428
VF Loss                      25.050236
Policy Loss                  -376.42566
Q Predictions Mean           373.89185
Q Predictions Std            49.037125
Q Predictions Max            450.82178
Q Predictions Min            -23.850327
V Predictions Mean           374.55676
V Predictions Std            48.026653
V Predictions Max            455.68216
V Predictions Min            53.922993
Log Pis Mean                 -2.2123842
Log Pis Std                  1.8962841
Log Pis Max                  7.1404395
Log Pis Min                  -8.239906
Policy mu Mean               0.10076999
Policy mu Std                0.339512
Policy mu Max                2.1643429
Policy mu Min                -1.3728828
Policy log std Mean          -0.8335068
Policy log std Std           0.17080231
Policy log std Max           -0.39104778
Policy log std Min           -1.9118208
Z mean eval                  0.82513255
Z variance eval              0.012572715
total_rewards                [368.90885452 647.00137676 213.67339957 647.22561074 439.62405042
  27.00261417 239.37965872 630.17013486 102.07657917 188.90391246]
total_rewards_mean           350.3966191399728
total_rewards_std            220.4549190266164
total_rewards_max            647.2256107417542
total_rewards_min            27.00261416723076
Number of train steps total  59000
Number of env steps total    297000
Number of rollouts total     0
Train Time (s)               29.598319325130433
(Previous) Eval Time (s)     23.342791280709207
Sample Time (s)              18.021445692982525
Epoch Time (s)               70.96255629882216
Total Train Time (s)         4043.0587264583446
Epoch                        58
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:22:54.479468 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #58 | Epoch Duration: 72.32659435272217
2020-01-11 04:22:54.479747 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #58 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.83060616
Z variance train             0.012618229
KL Divergence                15.955157
KL Loss                      1.5955157
QF Loss                      164.91211
VF Loss                      21.745995
Policy Loss                  -385.51056
Q Predictions Mean           385.2481
Q Predictions Std            41.117558
Q Predictions Max            464.0515
Q Predictions Min            96.103485
V Predictions Mean           388.07242
V Predictions Std            39.4396
V Predictions Max            455.17737
V Predictions Min            168.94597
Log Pis Mean                 -2.479903
Log Pis Std                  1.8069555
Log Pis Max                  8.388687
Log Pis Min                  -8.564295
Policy mu Mean               0.07150719
Policy mu Std                0.3476705
Policy mu Max                1.4615638
Policy mu Min                -2.1107488
Policy log std Mean          -0.8306477
Policy log std Std           0.15899397
Policy log std Max           -0.36675587
Policy log std Min           -2.3543298
Z mean eval                  0.8515193
Z variance eval              0.0073999176
total_rewards                [446.34936356 681.64850662 463.22828551 575.02116167 332.25897189
 743.52583015 277.85298072  38.4007201  435.65237003 313.82429598]
total_rewards_mean           430.7762486232876
total_rewards_std            195.85778334756935
total_rewards_max            743.5258301542261
total_rewards_min            38.400720102281
Number of train steps total  60000
Number of env steps total    302000
Number of rollouts total     0
Train Time (s)               29.125379905104637
(Previous) Eval Time (s)     24.706534212920815
Sample Time (s)              18.00436883419752
Epoch Time (s)               71.83628295222297
Total Train Time (s)         4114.679358037654
Epoch                        59
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:24:06.102246 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #59 | Epoch Duration: 71.62226223945618
2020-01-11 04:24:06.102476 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #59 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8519375
Z variance train             0.0073975213
KL Divergence                16.874706
KL Loss                      1.6874707
QF Loss                      491.11786
VF Loss                      63.360203
Policy Loss                  -390.0825
Q Predictions Mean           387.7329
Q Predictions Std            47.7412
Q Predictions Max            468.43832
Q Predictions Min            12.584836
V Predictions Mean           392.90988
V Predictions Std            41.76241
V Predictions Max            464.64505
V Predictions Min            47.81738
Log Pis Mean                 -2.4641416
Log Pis Std                  1.9516811
Log Pis Max                  5.515826
Log Pis Min                  -8.703466
Policy mu Mean               0.03110159
Policy mu Std                0.35070953
Policy mu Max                1.3209782
Policy mu Min                -1.5677104
Policy log std Mean          -0.80660903
Policy log std Std           0.15912214
Policy log std Max           -0.44339174
Policy log std Min           -1.8821325
Z mean eval                  0.8298019
Z variance eval              0.0067842766
total_rewards                [145.47391992 236.96418196  23.79040821 388.04411419 242.18835832
 461.91728669 589.17210775 194.26041394 410.90625942 517.75727711]
total_rewards_mean           321.0474327505891
total_rewards_std            170.74676450189156
total_rewards_max            589.1721077499247
total_rewards_min            23.790408213911903
Number of train steps total  61000
Number of env steps total    307000
Number of rollouts total     0
Train Time (s)               27.45120234414935
(Previous) Eval Time (s)     24.492237322963774
Sample Time (s)              18.861433901824057
Epoch Time (s)               70.80487356893718
Total Train Time (s)         4181.514639220666
Epoch                        60
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:25:12.938419 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #60 | Epoch Duration: 66.83575654029846
2020-01-11 04:25:12.938655 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #60 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8285214
Z variance train             0.006796471
KL Divergence                16.569044
KL Loss                      1.6569045
QF Loss                      218.9649
VF Loss                      51.164642
Policy Loss                  -387.95618
Q Predictions Mean           386.92865
Q Predictions Std            52.132378
Q Predictions Max            471.78928
Q Predictions Min            11.795907
V Predictions Mean           393.12357
V Predictions Std            53.811855
V Predictions Max            470.24222
V Predictions Min            -35.636135
Log Pis Mean                 -2.5605555
Log Pis Std                  1.7180625
Log Pis Max                  3.1372554
Log Pis Min                  -8.488198
Policy mu Mean               0.07915558
Policy mu Std                0.32531354
Policy mu Max                1.3710002
Policy mu Min                -1.2180191
Policy log std Mean          -0.8120457
Policy log std Std           0.15938206
Policy log std Max           -0.36883348
Policy log std Min           -2.1072457
Z mean eval                  0.8429557
Z variance eval              0.009306221
total_rewards                [310.23113309 486.92933728 394.23421628 327.88200602 181.95402881
 494.47216091 282.94824833 583.34448551 348.64386904 392.78978036]
total_rewards_mean           380.3429265631209
total_rewards_std            111.11264115105168
total_rewards_max            583.3444855134767
total_rewards_min            181.95402880533055
Number of train steps total  62000
Number of env steps total    312000
Number of rollouts total     0
Train Time (s)               30.152096850331873
(Previous) Eval Time (s)     20.522795835975558
Sample Time (s)              18.20627854531631
Epoch Time (s)               68.88117123162374
Total Train Time (s)         4257.134144000243
Epoch                        61
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:26:28.558172 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #61 | Epoch Duration: 75.6193528175354
2020-01-11 04:26:28.558368 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #61 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8393904
Z variance train             0.009258442
KL Divergence                16.728
KL Loss                      1.6728001
QF Loss                      280.4834
VF Loss                      68.614395
Policy Loss                  -393.39825
Q Predictions Mean           388.95282
Q Predictions Std            43.047195
Q Predictions Max            481.51376
Q Predictions Min            117.65945
V Predictions Mean           390.44415
V Predictions Std            42.21963
V Predictions Max            484.89893
V Predictions Min            175.50656
Log Pis Mean                 -2.3964663
Log Pis Std                  1.745255
Log Pis Max                  2.4782515
Log Pis Min                  -7.710405
Policy mu Mean               0.052155495
Policy mu Std                0.3777953
Policy mu Max                1.4375519
Policy mu Min                -1.2046444
Policy log std Mean          -0.8221817
Policy log std Std           0.15371157
Policy log std Max           -0.38313463
Policy log std Min           -1.6672883
Z mean eval                  0.82505625
Z variance eval              0.007879742
total_rewards                [ 75.01757223 710.20462102 491.75435451  19.50058944 444.48991626
 250.14153921 163.2977258  486.6860986   70.50135462 282.29139996]
total_rewards_mean           299.3885171650187
total_rewards_std            215.45683385234153
total_rewards_max            710.2046210225742
total_rewards_min            19.500589443738917
Number of train steps total  63000
Number of env steps total    317000
Number of rollouts total     0
Train Time (s)               28.376864572055638
(Previous) Eval Time (s)     27.260662491898984
Sample Time (s)              19.015454946551472
Epoch Time (s)               74.6529820105061
Total Train Time (s)         4320.871291828342
Epoch                        62
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:27:32.298866 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #62 | Epoch Duration: 63.74034285545349
2020-01-11 04:27:32.299156 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #62 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.82351047
Z variance train             0.007921049
KL Divergence                16.949303
KL Loss                      1.6949303
QF Loss                      316.5742
VF Loss                      54.854122
Policy Loss                  -393.5977
Q Predictions Mean           391.0834
Q Predictions Std            53.379986
Q Predictions Max            495.21957
Q Predictions Min            -26.315838
V Predictions Mean           397.92188
V Predictions Std            50.14628
V Predictions Max            493.50244
V Predictions Min            6.9701204
Log Pis Mean                 -2.1641374
Log Pis Std                  1.6734922
Log Pis Max                  3.8049052
Log Pis Min                  -9.059922
Policy mu Mean               0.04013084
Policy mu Std                0.35459864
Policy mu Max                1.3729464
Policy mu Min                -1.2819135
Policy log std Mean          -0.82703316
Policy log std Std           0.16481116
Policy log std Max           -0.403619
Policy log std Min           -1.8935874
Z mean eval                  0.83482087
Z variance eval              0.008805775
total_rewards                [134.51839008 733.82610973 792.7636523  160.06558347 324.42939184
 383.23740833 441.94114436 813.13090426 204.03831279 371.4852417 ]
total_rewards_mean           435.94361388639254
total_rewards_std            244.63746912245415
total_rewards_max            813.1309042602071
total_rewards_min            134.5183900783568
Number of train steps total  64000
Number of env steps total    322000
Number of rollouts total     0
Train Time (s)               29.68661061488092
(Previous) Eval Time (s)     16.347669503185898
Sample Time (s)              18.31430963613093
Epoch Time (s)               64.34858975419775
Total Train Time (s)         4392.12222475186
Epoch                        63
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:28:43.560425 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #63 | Epoch Duration: 71.26103830337524
2020-01-11 04:28:43.560728 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #63 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8354723
Z variance train             0.008811386
KL Divergence                17.294899
KL Loss                      1.7294899
QF Loss                      200.36882
VF Loss                      32.01487
Policy Loss                  -399.8387
Q Predictions Mean           394.98193
Q Predictions Std            59.56516
Q Predictions Max            476.77304
Q Predictions Min            15.22739
V Predictions Mean           402.25146
V Predictions Std            56.10442
V Predictions Max            476.51404
V Predictions Min            -18.084686
Log Pis Mean                 -2.395779
Log Pis Std                  1.845495
Log Pis Max                  5.079619
Log Pis Min                  -8.5970335
Policy mu Mean               0.007030852
Policy mu Std                0.37304667
Policy mu Max                2.455512
Policy mu Min                -1.723046
Policy log std Mean          -0.81091845
Policy log std Std           0.1651433
Policy log std Max           0.35296315
Policy log std Min           -1.5760994
Z mean eval                  0.8534643
Z variance eval              0.008191782
total_rewards                [942.21624566 238.3128602  151.27414029 883.57704243 605.62533239
 982.76759642 419.90659125 704.75183705 664.3989789  217.06366444]
total_rewards_mean           580.9894289031824
total_rewards_std            294.41859485581847
total_rewards_max            982.7675964203404
total_rewards_min            151.2741402878324
Number of train steps total  65000
Number of env steps total    327000
Number of rollouts total     0
Train Time (s)               29.27872125338763
(Previous) Eval Time (s)     23.259806677233428
Sample Time (s)              19.211734858341515
Epoch Time (s)               71.75026278896257
Total Train Time (s)         4465.017082509585
Epoch                        64
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:29:56.449242 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #64 | Epoch Duration: 72.88828229904175
2020-01-11 04:29:56.449494 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #64 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8517602
Z variance train             0.008179852
KL Divergence                17.242907
KL Loss                      1.7242907
QF Loss                      175.18745
VF Loss                      35.014107
Policy Loss                  -403.177
Q Predictions Mean           401.53238
Q Predictions Std            55.300526
Q Predictions Max            485.26593
Q Predictions Min            0.5503644
V Predictions Mean           401.7685
V Predictions Std            55.24972
V Predictions Max            485.13684
V Predictions Min            -27.65972
Log Pis Mean                 -2.7480278
Log Pis Std                  1.795467
Log Pis Max                  3.8670526
Log Pis Min                  -8.811529
Policy mu Mean               0.030107556
Policy mu Std                0.3484083
Policy mu Max                1.1884176
Policy mu Min                -1.6760955
Policy log std Mean          -0.79382217
Policy log std Std           0.16412227
Policy log std Max           -0.21749607
Policy log std Min           -1.788944
Z mean eval                  0.8539375
Z variance eval              0.013584213
total_rewards                [301.89907963 172.94177789 363.24891493 920.04243867 153.87203233
 336.84554515 720.84099284 792.78203643  20.65868762 349.25387236]
total_rewards_mean           413.23853778483783
total_rewards_std            282.7508711693058
total_rewards_max            920.0424386746483
total_rewards_min            20.65868762059067
Number of train steps total  66000
Number of env steps total    332000
Number of rollouts total     0
Train Time (s)               28.188089677132666
(Previous) Eval Time (s)     24.397499246988446
Sample Time (s)              17.994373274967074
Epoch Time (s)               70.57996219908819
Total Train Time (s)         4535.437931260094
Epoch                        65
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:31:06.871663 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #65 | Epoch Duration: 70.42195153236389
2020-01-11 04:31:06.871879 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #65 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.85547066
Z variance train             0.013652215
KL Divergence                16.984009
KL Loss                      1.6984009
QF Loss                      211.30432
VF Loss                      121.861725
Policy Loss                  -408.81824
Q Predictions Mean           405.6739
Q Predictions Std            57.07861
Q Predictions Max            481.3181
Q Predictions Min            -37.072903
V Predictions Mean           409.67725
V Predictions Std            51.62461
V Predictions Max            487.72217
V Predictions Min            -8.63447
Log Pis Mean                 -2.4191892
Log Pis Std                  1.7235364
Log Pis Max                  4.3656664
Log Pis Min                  -8.044631
Policy mu Mean               0.05874502
Policy mu Std                0.36997
Policy mu Max                1.3620276
Policy mu Min                -2.300598
Policy log std Mean          -0.82116
Policy log std Std           0.17130487
Policy log std Max           -0.067070425
Policy log std Min           -1.8818092
Z mean eval                  0.83851415
Z variance eval              0.011162552
total_rewards                [ 156.84360039  659.98323137  630.26815312  470.95069455  356.72436309
  231.69618392  746.93331124 1039.75321391   10.78813207  112.49286037]
total_rewards_mean           441.6433744034297
total_rewards_std            310.06839862030796
total_rewards_max            1039.753213910388
total_rewards_min            10.788132072212498
Number of train steps total  67000
Number of env steps total    337000
Number of rollouts total     0
Train Time (s)               28.72139036701992
(Previous) Eval Time (s)     24.239208452403545
Sample Time (s)              18.27974511915818
Epoch Time (s)               71.24034393858165
Total Train Time (s)         4602.759003023617
Epoch                        66
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:32:14.194480 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #66 | Epoch Duration: 67.32242774963379
2020-01-11 04:32:14.194728 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #66 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8368112
Z variance train             0.0111677265
KL Divergence                17.003735
KL Loss                      1.7003735
QF Loss                      128.47092
VF Loss                      88.440125
Policy Loss                  -405.85986
Q Predictions Mean           402.5008
Q Predictions Std            53.96933
Q Predictions Max            505.89307
Q Predictions Min            25.360115
V Predictions Mean           407.6702
V Predictions Std            54.582314
V Predictions Max            512.01117
V Predictions Min            29.2672
Log Pis Mean                 -2.5501022
Log Pis Std                  2.0528276
Log Pis Max                  6.2108912
Log Pis Min                  -9.508582
Policy mu Mean               0.09444634
Policy mu Std                0.3471666
Policy mu Max                1.7570431
Policy mu Min                -1.3920761
Policy log std Mean          -0.8303436
Policy log std Std           0.19086693
Policy log std Max           -0.4046596
Policy log std Min           -2.168085
Z mean eval                  0.8468239
Z variance eval              0.014052736
total_rewards                [206.0162676  300.64497409 246.88024859 134.7018364  434.40840451
 279.11470379 186.9647246  378.42580129 213.3208934  368.96813043]
total_rewards_mean           274.9445984704198
total_rewards_std            90.77449118231199
total_rewards_max            434.4084045055824
total_rewards_min            134.70183640474255
Number of train steps total  68000
Number of env steps total    342000
Number of rollouts total     0
Train Time (s)               28.462805191986263
(Previous) Eval Time (s)     20.321001078933477
Sample Time (s)              18.033664270769805
Epoch Time (s)               66.81747054168954
Total Train Time (s)         4672.0001046145335
Epoch                        67
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:33:23.438713 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #67 | Epoch Duration: 69.24377584457397
2020-01-11 04:33:23.439017 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #67 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8441876
Z variance train             0.014046376
KL Divergence                16.573364
KL Loss                      1.6573365
QF Loss                      825.82983
VF Loss                      56.095135
Policy Loss                  -412.98703
Q Predictions Mean           408.39594
Q Predictions Std            53.239212
Q Predictions Max            495.04453
Q Predictions Min            -29.534798
V Predictions Mean           411.37146
V Predictions Std            45.800312
V Predictions Max            492.74963
V Predictions Min            25.5616
Log Pis Mean                 -2.4290934
Log Pis Std                  1.817199
Log Pis Max                  7.674161
Log Pis Min                  -7.655017
Policy mu Mean               0.08161472
Policy mu Std                0.3548014
Policy mu Max                1.368913
Policy mu Min                -1.4664874
Policy log std Mean          -0.83379173
Policy log std Std           0.18394679
Policy log std Max           -0.43712375
Policy log std Min           -2.372582
Z mean eval                  0.84082824
Z variance eval              0.009663815
total_rewards                [ 100.09202181  867.10392418  464.11840652  497.0091961   995.99720724
  676.68554305  285.98172585  148.53473851 1099.36735219  398.43203945]
total_rewards_mean           553.3322154887093
total_rewards_std            329.1906437965655
total_rewards_max            1099.3673521916558
total_rewards_min            100.09202181104159
Number of train steps total  69000
Number of env steps total    347000
Number of rollouts total     0
Train Time (s)               29.701967519242316
(Previous) Eval Time (s)     22.74698934983462
Sample Time (s)              18.057226441334933
Epoch Time (s)               70.50618331041187
Total Train Time (s)         4745.17149411561
Epoch                        68
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:34:36.612384 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #68 | Epoch Duration: 73.17313194274902
2020-01-11 04:34:36.612664 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #68 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.83975136
Z variance train             0.009660794
KL Divergence                17.289356
KL Loss                      1.7289356
QF Loss                      553.2752
VF Loss                      322.8106
Policy Loss                  -410.4813
Q Predictions Mean           406.88318
Q Predictions Std            64.020004
Q Predictions Max            518.00745
Q Predictions Min            -3.736102
V Predictions Mean           413.0754
V Predictions Std            55.962517
V Predictions Max            515.7039
V Predictions Min            26.253078
Log Pis Mean                 -2.3719845
Log Pis Std                  1.9176445
Log Pis Max                  7.737073
Log Pis Min                  -7.9933333
Policy mu Mean               0.031534966
Policy mu Std                0.3638374
Policy mu Max                1.2620324
Policy mu Min                -1.8897243
Policy log std Mean          -0.8413021
Policy log std Std           0.17741968
Policy log std Max           -0.44679552
Policy log std Min           -2.329609
Z mean eval                  0.85174286
Z variance eval              0.010183555
total_rewards                [ 446.58068763  540.71577102 1194.8908828  1086.38510411  344.77164732
   12.25340649  586.66805572  459.05239894   86.52423712 1190.66922875]
total_rewards_mean           594.8511419898808
total_rewards_std            407.48394616182327
total_rewards_max            1194.8908827996436
total_rewards_min            12.253406487156498
Number of train steps total  70000
Number of env steps total    352000
Number of rollouts total     0
Train Time (s)               26.36977033223957
(Previous) Eval Time (s)     25.413659621030092
Sample Time (s)              18.025646137539297
Epoch Time (s)               69.80907609080896
Total Train Time (s)         4810.447018534876
Epoch                        69
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:35:41.890007 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #69 | Epoch Duration: 65.27708673477173
2020-01-11 04:35:41.890349 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #69 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8516408
Z variance train             0.010175725
KL Divergence                15.792585
KL Loss                      1.5792586
QF Loss                      236.08167
VF Loss                      268.08154
Policy Loss                  -417.18613
Q Predictions Mean           414.6903
Q Predictions Std            55.270428
Q Predictions Max            511.88654
Q Predictions Min            6.821334
V Predictions Mean           413.49124
V Predictions Std            51.376465
V Predictions Max            502.63312
V Predictions Min            90.6395
Log Pis Mean                 -2.6766286
Log Pis Std                  1.9603842
Log Pis Max                  10.04716
Log Pis Min                  -9.2784605
Policy mu Mean               0.02980247
Policy mu Std                0.35822383
Policy mu Max                1.5350894
Policy mu Min                -1.1630728
Policy log std Mean          -0.821041
Policy log std Std           0.18904957
Policy log std Max           -0.4134515
Policy log std Min           -2.2575736
Z mean eval                  0.875069
Z variance eval              0.010857786
total_rewards                [ 103.86579954 1097.51041926  430.36174349  874.41344021  213.28488153
  296.73801961  277.73670313  296.79760723  253.87202244  743.80851735]
total_rewards_mean           458.83891537900973
total_rewards_std            312.45292763228196
total_rewards_max            1097.5104192552903
total_rewards_min            103.86579954203171
Number of train steps total  71000
Number of env steps total    357000
Number of rollouts total     0
Train Time (s)               25.175520881079137
(Previous) Eval Time (s)     20.881400536745787
Sample Time (s)              17.8567828675732
Epoch Time (s)               63.913704285398126
Total Train Time (s)         4878.051630072296
Epoch                        70
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:36:49.499545 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #70 | Epoch Duration: 67.6089117527008
2020-01-11 04:36:49.499882 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #70 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.86877596
Z variance train             0.010877983
KL Divergence                16.63936
KL Loss                      1.663936
QF Loss                      358.44333
VF Loss                      118.60812
Policy Loss                  -425.98532
Q Predictions Mean           423.19324
Q Predictions Std            49.89845
Q Predictions Max            515.0443
Q Predictions Min            25.544865
V Predictions Mean           432.2786
V Predictions Std            49.734688
V Predictions Max            522.12006
V Predictions Min            14.270392
Log Pis Mean                 -2.4258356
Log Pis Std                  1.8317683
Log Pis Max                  6.922211
Log Pis Min                  -7.982917
Policy mu Mean               0.09911648
Policy mu Std                0.36085728
Policy mu Max                2.419844
Policy mu Min                -1.067773
Policy log std Mean          -0.80934966
Policy log std Std           0.17855637
Policy log std Max           -0.3976169
Policy log std Min           -1.6673486
Z mean eval                  0.8610252
Z variance eval              0.010639413
total_rewards                [112.22701103 295.52550857 818.0740548  252.47572436 197.63967664
 437.74874333 376.7981158  840.16227986 425.4320337   11.49592369]
total_rewards_mean           376.7579071769693
total_rewards_std            259.44433405501235
total_rewards_max            840.1622798553227
total_rewards_min            11.495923685090949
Number of train steps total  72000
Number of env steps total    362000
Number of rollouts total     0
Train Time (s)               31.221636600326747
(Previous) Eval Time (s)     24.576305048074573
Sample Time (s)              18.772111660800874
Epoch Time (s)               74.5700533092022
Total Train Time (s)         4945.698341366369
Epoch                        71
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:37:57.142938 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #71 | Epoch Duration: 67.64282417297363
2020-01-11 04:37:57.143087 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #71 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.85944575
Z variance train             0.010635066
KL Divergence                16.81318
KL Loss                      1.6813182
QF Loss                      168.88153
VF Loss                      37.635365
Policy Loss                  -430.04987
Q Predictions Mean           428.30774
Q Predictions Std            58.378113
Q Predictions Max            519.06696
Q Predictions Min            -22.471199
V Predictions Mean           431.38818
V Predictions Std            56.903416
V Predictions Max            512.8858
V Predictions Min            41.714676
Log Pis Mean                 -2.6603408
Log Pis Std                  1.9885412
Log Pis Max                  11.460071
Log Pis Min                  -10.7600765
Policy mu Mean               0.04871077
Policy mu Std                0.37712482
Policy mu Max                2.913679
Policy mu Min                -2.2351704
Policy log std Mean          -0.7969511
Policy log std Std           0.17499743
Policy log std Max           -0.397489
Policy log std Min           -2.01026
Z mean eval                  0.87266237
Z variance eval              0.0125981
total_rewards                [215.16153248 179.33238021 992.96822315 512.91597725 893.28552246
 183.10588717 427.36084448 669.4791428  334.97903146 707.82427761]
total_rewards_mean           511.6412819076796
total_rewards_std            280.2334437806979
total_rewards_max            992.9682231518893
total_rewards_min            179.33238020564988
Number of train steps total  73000
Number of env steps total    367000
Number of rollouts total     0
Train Time (s)               29.546486858278513
(Previous) Eval Time (s)     17.648739993106574
Sample Time (s)              17.89322559442371
Epoch Time (s)               65.0884524458088
Total Train Time (s)         5017.6182788587175
Epoch                        72
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:39:09.077135 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #72 | Epoch Duration: 71.93387818336487
2020-01-11 04:39:09.077457 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #72 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8744956
Z variance train             0.012673335
KL Divergence                16.848217
KL Loss                      1.6848217
QF Loss                      416.09586
VF Loss                      76.381294
Policy Loss                  -434.5811
Q Predictions Mean           431.69977
Q Predictions Std            55.52825
Q Predictions Max            533.0361
Q Predictions Min            29.705553
V Predictions Mean           428.64734
V Predictions Std            53.933575
V Predictions Max            522.42535
V Predictions Min            3.5056965
Log Pis Mean                 -2.2849455
Log Pis Std                  1.8358706
Log Pis Max                  5.665387
Log Pis Min                  -7.1369405
Policy mu Mean               0.055713966
Policy mu Std                0.3673371
Policy mu Max                1.2504508
Policy mu Min                -1.5459917
Policy log std Mean          -0.84322715
Policy log std Std           0.17575192
Policy log std Max           -0.3724923
Policy log std Min           -2.120945
Z mean eval                  0.90165645
Z variance eval              0.008477689
total_rewards                [427.92560381 665.79542889 888.3970435  259.34490921 307.25747806
 367.13813038 441.68314209 290.88523703 586.50985815 368.18389057]
total_rewards_mean           460.3120721705013
total_rewards_std            187.74714411318485
total_rewards_max            888.397043504485
total_rewards_min            259.3449092138384
Number of train steps total  74000
Number of env steps total    372000
Number of rollouts total     0
Train Time (s)               26.531149704940617
(Previous) Eval Time (s)     24.49380048410967
Sample Time (s)              17.54757996229455
Epoch Time (s)               68.57253015134484
Total Train Time (s)         5087.204788014293
Epoch                        73
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:40:18.654419 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #73 | Epoch Duration: 69.57671070098877
2020-01-11 04:40:18.654659 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #73 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89845675
Z variance train             0.0084323315
KL Divergence                17.096127
KL Loss                      1.7096127
QF Loss                      125.44207
VF Loss                      31.024075
Policy Loss                  -427.49246
Q Predictions Mean           424.15033
Q Predictions Std            51.053448
Q Predictions Max            526.397
Q Predictions Min            88.32458
V Predictions Mean           430.10608
V Predictions Std            47.146706
V Predictions Max            532.7788
V Predictions Min            269.35886
Log Pis Mean                 -2.2575445
Log Pis Std                  1.8603485
Log Pis Max                  5.3433127
Log Pis Min                  -7.189107
Policy mu Mean               0.060424335
Policy mu Std                0.36292365
Policy mu Max                1.3975424
Policy mu Min                -1.7881044
Policy log std Mean          -0.8450152
Policy log std Std           0.1811259
Policy log std Max           -0.3101557
Policy log std Min           -1.8915792
Z mean eval                  0.84945667
Z variance eval              0.009644638
total_rewards                [ 274.79973208 1247.05694114  143.31341709  154.56915758  442.96797453
  995.97069091  845.876161    753.03605467  119.38461755  290.64307794]
total_rewards_mean           526.761782447999
total_rewards_std            383.37848418562885
total_rewards_max            1247.0569411449849
total_rewards_min            119.38461754927896
Number of train steps total  75000
Number of env steps total    377000
Number of rollouts total     0
Train Time (s)               27.566517051309347
(Previous) Eval Time (s)     25.497675474733114
Sample Time (s)              18.488395570311695
Epoch Time (s)               71.55258809635416
Total Train Time (s)         5160.319834402762
Epoch                        74
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:41:31.772361 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #74 | Epoch Duration: 73.11750221252441
2020-01-11 04:41:31.772595 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #74 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8492104
Z variance train             0.009642283
KL Divergence                17.04586
KL Loss                      1.704586
QF Loss                      201.81566
VF Loss                      149.92984
Policy Loss                  -438.33066
Q Predictions Mean           434.3266
Q Predictions Std            57.603077
Q Predictions Max            526.42834
Q Predictions Min            10.857303
V Predictions Mean           439.6697
V Predictions Std            53.636997
V Predictions Max            534.58563
V Predictions Min            5.057658
Log Pis Mean                 -1.9489195
Log Pis Std                  1.9028152
Log Pis Max                  8.679107
Log Pis Min                  -8.247655
Policy mu Mean               0.13461742
Policy mu Std                0.38048416
Policy mu Max                2.0154834
Policy mu Min                -1.0894544
Policy log std Mean          -0.8574904
Policy log std Std           0.17850843
Policy log std Max           -0.38698658
Policy log std Min           -2.2637224
Z mean eval                  0.86273134
Z variance eval              0.0083673345
total_rewards                [ 508.42059677  149.97036833  435.6727781   902.78429328  144.86803548
  267.76429015  441.35780658  520.96299147 1185.88748589  364.31756558]
total_rewards_mean           492.20062116139604
total_rewards_std            310.0223188905692
total_rewards_max            1185.8874858859676
total_rewards_min            144.86803547922176
Number of train steps total  76000
Number of env steps total    382000
Number of rollouts total     0
Train Time (s)               28.245735192205757
(Previous) Eval Time (s)     27.062303002923727
Sample Time (s)              17.81864973437041
Epoch Time (s)               73.1266879294999
Total Train Time (s)         5231.063923754264
Epoch                        75
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:42:42.516142 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #75 | Epoch Duration: 70.74337339401245
2020-01-11 04:42:42.516374 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #75 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8619796
Z variance train             0.008373566
KL Divergence                16.829872
KL Loss                      1.6829872
QF Loss                      191.9412
VF Loss                      43.163147
Policy Loss                  -423.99747
Q Predictions Mean           419.90912
Q Predictions Std            70.27014
Q Predictions Max            526.99756
Q Predictions Min            -3.9518807
V Predictions Mean           426.1836
V Predictions Std            71.94922
V Predictions Max            526.5449
V Predictions Min            -12.281841
Log Pis Mean                 -2.4959111
Log Pis Std                  1.8525425
Log Pis Max                  4.459488
Log Pis Min                  -8.447972
Policy mu Mean               0.08325386
Policy mu Std                0.35506862
Policy mu Max                1.8182597
Policy mu Min                -1.3392097
Policy log std Mean          -0.848264
Policy log std Std           0.18281245
Policy log std Max           -0.06951004
Policy log std Min           -2.0138073
Z mean eval                  0.85716885
Z variance eval              0.009443477
total_rewards                [ 304.97090297 1221.6446047    87.49214106  841.59848379  384.52767816
  166.8297687   485.38148895   53.01830923  983.95041525  603.6730395 ]
total_rewards_mean           513.3086832311905
total_rewards_std            375.92379918340026
total_rewards_max            1221.6446046968692
total_rewards_min            53.018309225123375
Number of train steps total  77000
Number of env steps total    387000
Number of rollouts total     0
Train Time (s)               25.47545846598223
(Previous) Eval Time (s)     24.678714827168733
Sample Time (s)              18.128396009560674
Epoch Time (s)               68.28256930271164
Total Train Time (s)         5295.629320138134
Epoch                        76
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:43:47.083542 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #76 | Epoch Duration: 64.56704306602478
2020-01-11 04:43:47.083712 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #76 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.854722
Z variance train             0.009425341
KL Divergence                17.15297
KL Loss                      1.715297
QF Loss                      181.87695
VF Loss                      21.330187
Policy Loss                  -443.3067
Q Predictions Mean           439.2075
Q Predictions Std            47.36776
Q Predictions Max            520.71716
Q Predictions Min            259.37607
V Predictions Mean           443.55145
V Predictions Std            46.770325
V Predictions Max            526.11176
V Predictions Min            277.72824
Log Pis Mean                 -2.3790102
Log Pis Std                  1.6983881
Log Pis Max                  2.254385
Log Pis Min                  -8.736387
Policy mu Mean               0.049428105
Policy mu Std                0.35566762
Policy mu Max                1.1785556
Policy mu Min                -1.7098535
Policy log std Mean          -0.848078
Policy log std Std           0.1674599
Policy log std Max           -0.40492204
Policy log std Min           -1.4296153
Z mean eval                  0.8648082
Z variance eval              0.007964576
total_rewards                [1063.92091403  360.90229658  183.07833852  221.41740861  372.07232397
  571.97894391  367.62643177  570.77396771 1123.61157037  403.43462874]
total_rewards_mean           523.881682421695
total_rewards_std            308.54394450703865
total_rewards_max            1123.6115703720798
total_rewards_min            183.07833852425176
Number of train steps total  78000
Number of env steps total    392000
Number of rollouts total     0
Train Time (s)               25.81782181886956
(Previous) Eval Time (s)     20.962886189110577
Sample Time (s)              17.889411052688956
Epoch Time (s)               64.6701190606691
Total Train Time (s)         5365.589900386054
Epoch                        77
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:44:57.047228 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #77 | Epoch Duration: 69.963303565979
2020-01-11 04:44:57.047518 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #77 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.86391944
Z variance train             0.007964113
KL Divergence                17.89368
KL Loss                      1.789368
QF Loss                      192.72893
VF Loss                      95.149536
Policy Loss                  -444.94608
Q Predictions Mean           441.27115
Q Predictions Std            59.05033
Q Predictions Max            553.9316
Q Predictions Min            48.16522
V Predictions Mean           440.28625
V Predictions Std            59.905674
V Predictions Max            551.38556
V Predictions Min            11.91044
Log Pis Mean                 -2.2350185
Log Pis Std                  1.8498296
Log Pis Max                  8.144057
Log Pis Min                  -8.8538265
Policy mu Mean               0.07382614
Policy mu Std                0.36646047
Policy mu Max                1.9363172
Policy mu Min                -1.131041
Policy log std Mean          -0.84392715
Policy log std Std           0.16694668
Policy log std Max           -0.39685184
Policy log std Min           -1.7520131
Z mean eval                  0.88922757
Z variance eval              0.012825638
total_rewards                [ 667.57136108  607.22473132  158.64199993  659.28165511  313.16575434
 1198.54966013  487.73154816 1279.53734341 1045.39055474  133.09738907]
total_rewards_mean           655.0191997287395
total_rewards_std            387.80661957788516
total_rewards_max            1279.5373434097833
total_rewards_min            133.0973890744845
Number of train steps total  79000
Number of env steps total    397000
Number of rollouts total     0
Train Time (s)               29.12621673103422
(Previous) Eval Time (s)     26.25577829219401
Sample Time (s)              18.207861001137644
Epoch Time (s)               73.58985602436587
Total Train Time (s)         5439.657263092231
Epoch                        78
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:46:11.118646 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #78 | Epoch Duration: 74.07076096534729
2020-01-11 04:46:11.119093 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #78 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8811839
Z variance train             0.012742428
KL Divergence                15.966177
KL Loss                      1.5966177
QF Loss                      369.10712
VF Loss                      86.50034
Policy Loss                  -445.7383
Q Predictions Mean           442.85388
Q Predictions Std            58.42456
Q Predictions Max            550.65466
Q Predictions Min            217.09685
V Predictions Mean           450.5399
V Predictions Std            56.436455
V Predictions Max            542.1175
V Predictions Min            232.0763
Log Pis Mean                 -2.2513807
Log Pis Std                  1.9754605
Log Pis Max                  6.239049
Log Pis Min                  -10.544867
Policy mu Mean               0.04016282
Policy mu Std                0.38580635
Policy mu Max                1.4558257
Policy mu Min                -1.1502542
Policy log std Mean          -0.87321347
Policy log std Std           0.19835667
Policy log std Max           -0.3758534
Policy log std Min           -2.108231
Z mean eval                  0.90974426
Z variance eval              0.01159615
total_rewards                [ 431.76312648  278.02589813  840.76132977  623.49130624  481.94158819
  297.03928966  525.9386442   202.69162373 1134.60380314  314.25571748]
total_rewards_mean           513.0512327028018
total_rewards_std            274.11694185753765
total_rewards_max            1134.6038031431822
total_rewards_min            202.6916237327428
Number of train steps total  80000
Number of env steps total    402000
Number of rollouts total     0
Train Time (s)               29.019479902926832
(Previous) Eval Time (s)     26.73637876380235
Sample Time (s)              18.116218315903097
Epoch Time (s)               73.87207698263228
Total Train Time (s)         5511.4137733038515
Epoch                        79
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:47:22.876319 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #79 | Epoch Duration: 71.75696611404419
2020-01-11 04:47:22.876567 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #79 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9040292
Z variance train             0.011685118
KL Divergence                16.225798
KL Loss                      1.6225798
QF Loss                      251.62955
VF Loss                      42.43947
Policy Loss                  -450.9991
Q Predictions Mean           448.0122
Q Predictions Std            56.58887
Q Predictions Max            535.96185
Q Predictions Min            214.18678
V Predictions Mean           454.43365
V Predictions Std            56.636303
V Predictions Max            535.30396
V Predictions Min            142.31627
Log Pis Mean                 -2.0942025
Log Pis Std                  1.9565873
Log Pis Max                  3.3991585
Log Pis Min                  -11.731694
Policy mu Mean               0.073094085
Policy mu Std                0.38739422
Policy mu Max                1.3174396
Policy mu Min                -1.1157053
Policy log std Mean          -0.8526318
Policy log std Std           0.19408534
Policy log std Max           -0.3792996
Policy log std Min           -1.8399961
Z mean eval                  0.8834025
Z variance eval              0.013711542
total_rewards                [614.74823057 750.64179949 400.27315586 694.73278344 686.9075298
 537.90059862 186.03693215  56.34266116 464.46453075 674.27578618]
total_rewards_mean           506.63240080307577
total_rewards_std            220.64116176092298
total_rewards_max            750.6417994948641
total_rewards_min            56.342661159907
Number of train steps total  81000
Number of env steps total    407000
Number of rollouts total     0
Train Time (s)               27.825790111906826
(Previous) Eval Time (s)     24.620958198793232
Sample Time (s)              18.255790230818093
Epoch Time (s)               70.70253854151815
Total Train Time (s)         5576.860112561844
Epoch                        80
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:48:28.322614 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #80 | Epoch Duration: 65.44581937789917
2020-01-11 04:48:28.322853 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #80 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8833731
Z variance train             0.01373761
KL Divergence                15.903759
KL Loss                      1.5903759
QF Loss                      324.50745
VF Loss                      29.568558
Policy Loss                  -464.4799
Q Predictions Mean           461.19595
Q Predictions Std            50.9667
Q Predictions Max            559.7302
Q Predictions Min            283.34222
V Predictions Mean           466.5335
V Predictions Std            50.226368
V Predictions Max            557.3526
V Predictions Min            294.02017
Log Pis Mean                 -1.7819204
Log Pis Std                  1.9025948
Log Pis Max                  3.5249252
Log Pis Min                  -8.458919
Policy mu Mean               0.109536834
Policy mu Std                0.39904493
Policy mu Max                1.4544164
Policy mu Min                -1.3747395
Policy log std Mean          -0.8739649
Policy log std Std           0.18586002
Policy log std Max           -0.33763626
Policy log std Min           -1.8437177
Z mean eval                  0.9006885
Z variance eval              0.012483658
total_rewards                [110.99123128  23.10657991 381.17679645 364.84023542 398.67100392
 447.66019614 422.0548361  126.28716951 503.6177394  861.29316546]
total_rewards_mean           363.9698953599858
total_rewards_std            227.0220179751767
total_rewards_max            861.2931654641694
total_rewards_min            23.106579911221242
Number of train steps total  82000
Number of env steps total    412000
Number of rollouts total     0
Train Time (s)               30.366204699035734
(Previous) Eval Time (s)     19.36390263494104
Sample Time (s)              18.141428847797215
Epoch Time (s)               67.87153618177399
Total Train Time (s)         5647.361463692971
Epoch                        81
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:49:38.827229 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #81 | Epoch Duration: 70.50420641899109
2020-01-11 04:49:38.827517 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #81 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9026538
Z variance train             0.012428687
KL Divergence                16.249985
KL Loss                      1.6249985
QF Loss                      281.86002
VF Loss                      27.162075
Policy Loss                  -454.73895
Q Predictions Mean           453.3988
Q Predictions Std            60.783203
Q Predictions Max            578.1537
Q Predictions Min            279.47076
V Predictions Mean           455.8061
V Predictions Std            59.71038
V Predictions Max            575.1079
V Predictions Min            279.30923
Log Pis Mean                 -2.2376766
Log Pis Std                  1.9015914
Log Pis Max                  4.506604
Log Pis Min                  -8.472146
Policy mu Mean               0.087317124
Policy mu Std                0.36840415
Policy mu Max                1.1849056
Policy mu Min                -1.2683777
Policy log std Mean          -0.8414929
Policy log std Std           0.2138206
Policy log std Max           -0.34404635
Policy log std Min           -2.0555825
Z mean eval                  0.9025505
Z variance eval              0.009696717
total_rewards                [ 586.87003542 1148.18197421 1201.79931242  960.27925155  220.70515883
 1082.58940376  597.92621038 1155.13576747  269.56452162 1268.63354428]
total_rewards_mean           849.1685179925335
total_rewards_std            375.8969902441001
total_rewards_max            1268.633544279458
total_rewards_min            220.7051588300596
Number of train steps total  83000
Number of env steps total    417000
Number of rollouts total     0
Train Time (s)               29.295200848020613
(Previous) Eval Time (s)     21.99627081817016
Sample Time (s)              18.829626403283328
Epoch Time (s)               70.1210980694741
Total Train Time (s)         5719.625093003735
Epoch                        82
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:50:51.093976 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #82 | Epoch Duration: 72.26613235473633
2020-01-11 04:50:51.094361 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #82 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89982873
Z variance train             0.009691484
KL Divergence                17.160618
KL Loss                      1.7160618
QF Loss                      253.74275
VF Loss                      44.91256
Policy Loss                  -457.94745
Q Predictions Mean           455.5437
Q Predictions Std            67.04488
Q Predictions Max            556.33185
Q Predictions Min            9.926513
V Predictions Mean           454.57892
V Predictions Std            67.315765
V Predictions Max            545.6175
V Predictions Min            27.088644
Log Pis Mean                 -1.840441
Log Pis Std                  1.6549108
Log Pis Max                  4.809725
Log Pis Min                  -7.0056896
Policy mu Mean               0.110546544
Policy mu Std                0.38209772
Policy mu Max                1.4448639
Policy mu Min                -0.9225507
Policy log std Mean          -0.8849955
Policy log std Std           0.19113588
Policy log std Max           -0.42737123
Policy log std Min           -1.9273899
Z mean eval                  0.90514964
Z variance eval              0.0103235515
total_rewards                [ 306.94880887  631.57777785  726.26075403 1111.19639948   80.02162875
  155.31803594  381.96364822 1104.17747244  303.98814153  228.41827961]
total_rewards_mean           502.9870946721624
total_rewards_std            355.74920673817775
total_rewards_max            1111.1963994841044
total_rewards_min            80.02162875491024
Number of train steps total  84000
Number of env steps total    422000
Number of rollouts total     0
Train Time (s)               29.23836149321869
(Previous) Eval Time (s)     24.14093925943598
Sample Time (s)              18.684030572883785
Epoch Time (s)               72.06333132553846
Total Train Time (s)         5785.505091770552
Epoch                        83
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:51:56.974259 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #83 | Epoch Duration: 65.87968420982361
2020-01-11 04:51:56.974477 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #83 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90323126
Z variance train             0.010347493
KL Divergence                16.776651
KL Loss                      1.6776651
QF Loss                      320.80322
VF Loss                      47.909958
Policy Loss                  -458.73944
Q Predictions Mean           456.70193
Q Predictions Std            72.80827
Q Predictions Max            617.7209
Q Predictions Min            -6.78412
V Predictions Mean           460.7031
V Predictions Std            74.52164
V Predictions Max            614.05145
V Predictions Min            -3.4085107
Log Pis Mean                 -2.0315218
Log Pis Std                  1.6838819
Log Pis Max                  2.6819592
Log Pis Min                  -9.690501
Policy mu Mean               -0.0180435
Policy mu Std                0.39147934
Policy mu Max                1.4155022
Policy mu Min                -1.2754046
Policy log std Mean          -0.84819394
Policy log std Std           0.19703184
Policy log std Max           0.2512148
Policy log std Min           -1.4471748
Z mean eval                  0.91897166
Z variance eval              0.006199686
total_rewards                [ 987.93121195  118.06750999  187.48187108  415.67113326   38.62591939
 1211.58477106  367.89354454 1065.8432061   582.71698111  189.81758228]
total_rewards_mean           516.5633730763448
total_rewards_std            405.6956481470694
total_rewards_max            1211.584771056713
total_rewards_min            38.625919394011376
Number of train steps total  85000
Number of env steps total    427000
Number of rollouts total     0
Train Time (s)               25.955029351171106
(Previous) Eval Time (s)     17.956975222099572
Sample Time (s)              18.23685678699985
Epoch Time (s)               62.14886136027053
Total Train Time (s)         5851.056542440318
Epoch                        84
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:53:02.529510 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #84 | Epoch Duration: 65.55485701560974
2020-01-11 04:53:02.529746 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #84 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9178213
Z variance train             0.00619878
KL Divergence                17.184883
KL Loss                      1.7184883
QF Loss                      577.52
VF Loss                      83.589806
Policy Loss                  -460.991
Q Predictions Mean           455.26624
Q Predictions Std            85.81974
Q Predictions Max            571.4563
Q Predictions Min            -75.254875
V Predictions Mean           459.42706
V Predictions Std            79.97525
V Predictions Max            569.4476
V Predictions Min            18.154758
Log Pis Mean                 -1.9205747
Log Pis Std                  2.2508512
Log Pis Max                  9.621165
Log Pis Min                  -8.97917
Policy mu Mean               0.07638605
Policy mu Std                0.41982308
Policy mu Max                1.961801
Policy mu Min                -1.5184747
Policy log std Mean          -0.8611712
Policy log std Std           0.23078708
Policy log std Max           -0.34424883
Policy log std Min           -2.3094468
Z mean eval                  0.9334629
Z variance eval              0.00734737
total_rewards                [148.11155441 233.65799319 184.37627435 879.64946506 101.54358612
 504.18986421 407.14978792 131.96828084 639.64422074 379.18019442]
total_rewards_mean           360.9471221263981
total_rewards_std            241.26957485652764
total_rewards_max            879.6494650618624
total_rewards_min            101.54358612353448
Number of train steps total  86000
Number of env steps total    432000
Number of rollouts total     0
Train Time (s)               29.133178636897355
(Previous) Eval Time (s)     21.362665604799986
Sample Time (s)              17.63824003515765
Epoch Time (s)               68.13408427685499
Total Train Time (s)         5920.1637005591765
Epoch                        85
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:54:11.635609 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #85 | Epoch Duration: 69.10569906234741
2020-01-11 04:54:11.635841 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #85 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93276435
Z variance train             0.007302965
KL Divergence                17.34316
KL Loss                      1.7343161
QF Loss                      212.94394
VF Loss                      154.04158
Policy Loss                  -480.51068
Q Predictions Mean           476.89587
Q Predictions Std            75.61508
Q Predictions Max            591.67316
Q Predictions Min            -1.7431338
V Predictions Mean           476.4356
V Predictions Std            69.90902
V Predictions Max            592.3153
V Predictions Min            86.05953
Log Pis Mean                 -1.7114418
Log Pis Std                  2.0624304
Log Pis Max                  11.328944
Log Pis Min                  -9.031583
Policy mu Mean               0.04747865
Policy mu Std                0.4126232
Policy mu Max                2.78327
Policy mu Min                -1.743125
Policy log std Mean          -0.8798177
Policy log std Std           0.20818955
Policy log std Max           -0.2522965
Policy log std Min           -1.8112411
Z mean eval                  0.89300555
Z variance eval              0.008531142
total_rewards                [ 210.26877015  732.29502326 1462.97179421  468.15314424 1461.87454177
 1146.57785942  177.18273732  716.44324995   66.72193675  467.57437686]
total_rewards_mean           691.0063433917622
total_rewards_std            488.313972658534
total_rewards_max            1462.9717942097695
total_rewards_min            66.72193675411708
Number of train steps total  87000
Number of env steps total    437000
Number of rollouts total     0
Train Time (s)               26.499555798247457
(Previous) Eval Time (s)     22.333968597929925
Sample Time (s)              18.211380708497018
Epoch Time (s)               67.0449051046744
Total Train Time (s)         5990.744422904681
Epoch                        86
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:55:22.220023 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #86 | Epoch Duration: 70.5839536190033
2020-01-11 04:55:22.220330 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #86 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89293754
Z variance train             0.0085148625
KL Divergence                17.389822
KL Loss                      1.7389822
QF Loss                      256.98694
VF Loss                      109.39192
Policy Loss                  -483.8801
Q Predictions Mean           480.27643
Q Predictions Std            73.41438
Q Predictions Max            586.5225
Q Predictions Min            40.14512
V Predictions Mean           482.69467
V Predictions Std            76.100624
V Predictions Max            585.44666
V Predictions Min            -17.694658
Log Pis Mean                 -2.1331635
Log Pis Std                  1.9013506
Log Pis Max                  2.372901
Log Pis Min                  -8.337246
Policy mu Mean               0.070909455
Policy mu Std                0.39352974
Policy mu Max                1.6094208
Policy mu Min                -1.4642345
Policy log std Mean          -0.87087107
Policy log std Std           0.19539982
Policy log std Max           -0.24049857
Policy log std Min           -1.6992462
Z mean eval                  0.89754355
Z variance eval              0.01025573
total_rewards                [708.57037109 837.38704972  99.73982868 684.18865596 295.49970089
 236.76222723 309.01399264  91.45417895 222.30358953 121.27778029]
total_rewards_mean           360.6197374981506
total_rewards_std            263.10499184616464
total_rewards_max            837.3870497234502
total_rewards_min            91.4541789469804
Number of train steps total  88000
Number of env steps total    442000
Number of rollouts total     0
Train Time (s)               28.818040571641177
(Previous) Eval Time (s)     25.87273733690381
Sample Time (s)              17.95398585917428
Epoch Time (s)               72.64476376771927
Total Train Time (s)         6057.90303584747
Epoch                        87
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:56:29.378001 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #87 | Epoch Duration: 67.15750861167908
2020-01-11 04:56:29.378156 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #87 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8972801
Z variance train             0.010277376
KL Divergence                18.054447
KL Loss                      1.8054447
QF Loss                      269.6501
VF Loss                      88.12098
Policy Loss                  -492.2021
Q Predictions Mean           489.50854
Q Predictions Std            66.09299
Q Predictions Max            609.55096
Q Predictions Min            279.7827
V Predictions Mean           492.22397
V Predictions Std            65.884766
V Predictions Max            609.0162
V Predictions Min            301.29355
Log Pis Mean                 -2.0014515
Log Pis Std                  2.087426
Log Pis Max                  8.848779
Log Pis Min                  -7.468706
Policy mu Mean               0.048163682
Policy mu Std                0.4039579
Policy mu Max                1.2509172
Policy mu Min                -1.3989217
Policy log std Mean          -0.84425026
Policy log std Std           0.22469379
Policy log std Max           -0.28560334
Policy log std Min           -2.3912401
Z mean eval                  0.8847739
Z variance eval              0.007933907
total_rewards                [ 285.98101534  103.71490822  914.63836912   10.75266022  183.16059107
   52.09028476  135.1871068   433.39926096 1496.24896844 1122.91706626]
total_rewards_mean           473.80902311740994
total_rewards_std            492.579574465438
total_rewards_max            1496.2489684425777
total_rewards_min            10.752660216676613
Number of train steps total  89000
Number of env steps total    447000
Number of rollouts total     0
Train Time (s)               28.633769399952143
(Previous) Eval Time (s)     20.38518377300352
Sample Time (s)              18.25331967556849
Epoch Time (s)               67.27227284852415
Total Train Time (s)         6127.735314706806
Epoch                        88
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:57:39.215390 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #88 | Epoch Duration: 69.83706784248352
2020-01-11 04:57:39.215680 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #88 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8846471
Z variance train             0.007912212
KL Divergence                18.269672
KL Loss                      1.8269672
QF Loss                      233.30402
VF Loss                      73.07487
Policy Loss                  -479.98953
Q Predictions Mean           478.0838
Q Predictions Std            76.85981
Q Predictions Max            594.4571
Q Predictions Min            -12.315158
V Predictions Mean           484.29358
V Predictions Std            75.52486
V Predictions Max            599.62915
V Predictions Min            11.912041
Log Pis Mean                 -1.9916635
Log Pis Std                  2.0558898
Log Pis Max                  11.38641
Log Pis Min                  -8.062626
Policy mu Mean               0.04366938
Policy mu Std                0.40903455
Policy mu Max                2.15427
Policy mu Min                -2.1585953
Policy log std Mean          -0.87204635
Policy log std Std           0.20895275
Policy log std Max           -0.27306196
Policy log std Min           -2.2204509
Z mean eval                  0.8870834
Z variance eval              0.0068728095
total_rewards                [  54.0559803   519.96249784 1517.78691471  771.55895468  421.35370636
  165.45432078  244.67435184  370.43430986   71.919989   1348.57880055]
total_rewards_mean           548.5779825912756
total_rewards_std            488.7457230441332
total_rewards_max            1517.7869147093172
total_rewards_min            54.05598029900706
Number of train steps total  90000
Number of env steps total    452000
Number of rollouts total     0
Train Time (s)               28.23309324402362
(Previous) Eval Time (s)     22.94962474424392
Sample Time (s)              18.04565510293469
Epoch Time (s)               69.22837309120223
Total Train Time (s)         6193.647983376402
Epoch                        89
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:58:45.126685 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #89 | Epoch Duration: 65.91076302528381
2020-01-11 04:58:45.126839 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #89 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8877093
Z variance train             0.0068745934
KL Divergence                18.34193
KL Loss                      1.8341931
QF Loss                      171.38467
VF Loss                      216.57437
Policy Loss                  -490.93222
Q Predictions Mean           486.89603
Q Predictions Std            74.73307
Q Predictions Max            601.9922
Q Predictions Min            -12.439505
V Predictions Mean           488.7293
V Predictions Std            68.60335
V Predictions Max            594.7116
V Predictions Min            260.03757
Log Pis Mean                 -2.1914973
Log Pis Std                  2.0944068
Log Pis Max                  4.030856
Log Pis Min                  -8.535101
Policy mu Mean               0.045841657
Policy mu Std                0.4110616
Policy mu Max                2.8978827
Policy mu Min                -1.3687036
Policy log std Mean          -0.85840344
Policy log std Std           0.2156091
Policy log std Max           -0.28884676
Policy log std Min           -1.9897163
Z mean eval                  0.91662425
Z variance eval              0.010734266
total_rewards                [455.98758735 384.98861594  52.34462864 124.53144065 909.22975152
  57.39330634 367.54448442 426.54107371 115.6078139  780.89698501]
total_rewards_mean           367.5065687490085
total_rewards_std            281.77338579491914
total_rewards_max            909.2297515189948
total_rewards_min            52.34462864078665
Number of train steps total  91000
Number of env steps total    457000
Number of rollouts total     0
Train Time (s)               29.554285410791636
(Previous) Eval Time (s)     19.631756325252354
Sample Time (s)              18.251148050650954
Epoch Time (s)               67.43718978669494
Total Train Time (s)         6259.381939907093
Epoch                        90
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:59:50.863539 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #90 | Epoch Duration: 65.73654747009277
2020-01-11 04:59:50.863758 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #90 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9177659
Z variance train             0.010599058
KL Divergence                18.110287
KL Loss                      1.8110287
QF Loss                      193.90836
VF Loss                      48.58844
Policy Loss                  -502.3267
Q Predictions Mean           499.4413
Q Predictions Std            65.27203
Q Predictions Max            603.5955
Q Predictions Min            307.42026
V Predictions Mean           505.37048
V Predictions Std            64.68487
V Predictions Max            614.42487
V Predictions Min            310.98553
Log Pis Mean                 -2.0507026
Log Pis Std                  2.1493714
Log Pis Max                  7.3512197
Log Pis Min                  -12.869061
Policy mu Mean               0.08987801
Policy mu Std                0.39834833
Policy mu Max                1.44141
Policy mu Min                -1.2959312
Policy log std Mean          -0.86183524
Policy log std Std           0.20270754
Policy log std Max           -0.24611598
Policy log std Min           -2.0127895
Z mean eval                  0.88944197
Z variance eval              0.0063047213
total_rewards                [1115.81110168 1085.48487105  445.79657595   84.88103355  399.04564603
  257.14468393   84.37815749  515.1365728  1132.38755058  363.04755986]
total_rewards_mean           548.3113752917557
total_rewards_std            391.75870478718275
total_rewards_max            1132.387550578258
total_rewards_min            84.37815748565238
Number of train steps total  92000
Number of env steps total    462000
Number of rollouts total     0
Train Time (s)               27.4229132020846
(Previous) Eval Time (s)     17.930801848880947
Sample Time (s)              17.897048613522202
Epoch Time (s)               63.25076366448775
Total Train Time (s)         6328.080064993817
Epoch                        91
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:00:59.563198 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #91 | Epoch Duration: 68.69926762580872
2020-01-11 05:00:59.563389 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #91 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8892003
Z variance train             0.0062986994
KL Divergence                18.970448
KL Loss                      1.8970448
QF Loss                      237.7117
VF Loss                      36.76718
Policy Loss                  -499.32098
Q Predictions Mean           497.1927
Q Predictions Std            65.47815
Q Predictions Max            602.02423
Q Predictions Min            296.51855
V Predictions Mean           500.4242
V Predictions Std            65.521965
V Predictions Max            603.37885
V Predictions Min            299.30966
Log Pis Mean                 -1.9147346
Log Pis Std                  2.180499
Log Pis Max                  2.599475
Log Pis Min                  -12.513306
Policy mu Mean               0.014839868
Policy mu Std                0.42083845
Policy mu Max                1.4306606
Policy mu Min                -1.2667437
Policy log std Mean          -0.8684852
Policy log std Std           0.20337415
Policy log std Max           -0.3027559
Policy log std Min           -1.671807
Z mean eval                  0.9113016
Z variance eval              0.006300895
total_rewards                [1318.00537961 1440.98750318 1086.13193845 1236.61491244  793.45831334
  189.9249415   358.12492377  167.58484675  238.831483    415.24394141]
total_rewards_mean           724.4908183456621
total_rewards_std            482.1894300139166
total_rewards_max            1440.9875031817535
total_rewards_min            167.58484675258237
Number of train steps total  93000
Number of env steps total    467000
Number of rollouts total     0
Train Time (s)               28.448352068196982
(Previous) Eval Time (s)     23.379019473213702
Sample Time (s)              18.66235516499728
Epoch Time (s)               70.48972670640796
Total Train Time (s)         6399.757570562884
Epoch                        92
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:02:11.243422 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #92 | Epoch Duration: 71.67986750602722
2020-01-11 05:02:11.243701 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #92 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91219074
Z variance train             0.0062771305
KL Divergence                19.43486
KL Loss                      1.9434861
QF Loss                      386.51633
VF Loss                      105.53774
Policy Loss                  -482.93738
Q Predictions Mean           479.21487
Q Predictions Std            102.071754
Q Predictions Max            615.1769
Q Predictions Min            24.755444
V Predictions Mean           486.96387
V Predictions Std            104.058876
V Predictions Max            621.4715
V Predictions Min            -7.811308
Log Pis Mean                 -1.715427
Log Pis Std                  2.3907008
Log Pis Max                  8.789402
Log Pis Min                  -7.67487
Policy mu Mean               0.08134042
Policy mu Std                0.4212352
Policy mu Max                1.5517304
Policy mu Min                -2.4150648
Policy log std Mean          -0.88528055
Policy log std Std           0.2612167
Policy log std Max           -0.089518845
Policy log std Min           -2.5376537
Z mean eval                  0.9056331
Z variance eval              0.0068972083
total_rewards                [ 698.89071246  656.08813038  453.98250012  433.77446595 -178.12716543
   13.0944061   -31.91643725  311.91519515   74.71559452  267.03810467]
total_rewards_mean           269.9455506661457
total_rewards_std            281.34614359393646
total_rewards_max            698.8907124645934
total_rewards_min            -178.1271654289865
Number of train steps total  94000
Number of env steps total    472000
Number of rollouts total     0
Train Time (s)               25.40580704435706
(Previous) Eval Time (s)     24.568839707877487
Sample Time (s)              18.40154157113284
Epoch Time (s)               68.37618832336739
Total Train Time (s)         6468.328667748719
Epoch                        93
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:03:19.817370 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #93 | Epoch Duration: 68.57345342636108
2020-01-11 05:03:19.817564 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #93 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9057374
Z variance train             0.0068964697
KL Divergence                19.525084
KL Loss                      1.9525083
QF Loss                      237.93059
VF Loss                      126.02294
Policy Loss                  -493.3954
Q Predictions Mean           490.59827
Q Predictions Std            88.61154
Q Predictions Max            631.1925
Q Predictions Min            -32.63671
V Predictions Mean           493.65378
V Predictions Std            81.59534
V Predictions Max            631.7113
V Predictions Min            16.93399
Log Pis Mean                 -2.1137276
Log Pis Std                  2.2702
Log Pis Max                  8.194191
Log Pis Min                  -12.692665
Policy mu Mean               0.07677892
Policy mu Std                0.41471082
Policy mu Max                1.5696093
Policy mu Min                -1.3577975
Policy log std Mean          -0.84690833
Policy log std Std           0.22169943
Policy log std Max           -0.31154573
Policy log std Min           -2.119537
Z mean eval                  0.89785194
Z variance eval              0.01152737
total_rewards                [ 335.81589778  212.51217276 1102.44388957  272.52269952  179.51947171
    1.54531047  618.27947395 1040.05871796  394.88712869  225.67158187]
total_rewards_mean           438.3256344288716
total_rewards_std            350.6245933898691
total_rewards_max            1102.4438895706437
total_rewards_min            1.5453104730182687
Number of train steps total  95000
Number of env steps total    477000
Number of rollouts total     0
Train Time (s)               27.5991197838448
(Previous) Eval Time (s)     24.765818940009922
Sample Time (s)              18.823250792454928
Epoch Time (s)               71.18818951630965
Total Train Time (s)         6538.087598172948
Epoch                        94
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:04:29.578575 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #94 | Epoch Duration: 69.7608437538147
2020-01-11 05:04:29.578879 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #94 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9007139
Z variance train             0.0114909215
KL Divergence                17.698414
KL Loss                      1.7698414
QF Loss                      322.78326
VF Loss                      65.643036
Policy Loss                  -504.89322
Q Predictions Mean           502.8559
Q Predictions Std            81.10711
Q Predictions Max            658.49817
Q Predictions Min            291.4068
V Predictions Mean           508.01862
V Predictions Std            79.07506
V Predictions Max            653.9051
V Predictions Min            307.80606
Log Pis Mean                 -1.7897561
Log Pis Std                  1.9429353
Log Pis Max                  7.565667
Log Pis Min                  -8.576189
Policy mu Mean               0.13285075
Policy mu Std                0.41623408
Policy mu Max                1.5596377
Policy mu Min                -1.1109052
Policy log std Mean          -0.8710474
Policy log std Std           0.21070729
Policy log std Max           -0.29001224
Policy log std Min           -1.8853605
Z mean eval                  0.93662757
Z variance eval              0.011960267
total_rewards                [1461.7694244   719.88378985  209.93637079  349.01276667  243.23739139
 1624.32649159  942.30307002   42.94961311 1372.18889421  769.91954249]
total_rewards_mean           773.5527354510043
total_rewards_std            538.5263740088138
total_rewards_max            1624.32649159495
total_rewards_min            42.94961310740236
Number of train steps total  96000
Number of env steps total    482000
Number of rollouts total     0
Train Time (s)               30.860288931056857
(Previous) Eval Time (s)     23.33815606124699
Sample Time (s)              19.36579220322892
Epoch Time (s)               73.56423719553277
Total Train Time (s)         6614.018606635742
Epoch                        95
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:05:45.509016 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #95 | Epoch Duration: 75.9299144744873
2020-01-11 05:05:45.509168 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #95 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93688357
Z variance train             0.011967393
KL Divergence                16.977098
KL Loss                      1.6977099
QF Loss                      760.291
VF Loss                      132.15764
Policy Loss                  -502.21213
Q Predictions Mean           500.3396
Q Predictions Std            101.759125
Q Predictions Max            634.07776
Q Predictions Min            -29.80446
V Predictions Mean           495.34683
V Predictions Std            99.49116
V Predictions Max            627.2562
V Predictions Min            -3.5114155
Log Pis Mean                 -1.8242346
Log Pis Std                  2.1431136
Log Pis Max                  7.2286444
Log Pis Min                  -7.4501247
Policy mu Mean               0.047625583
Policy mu Std                0.41631305
Policy mu Max                1.8153497
Policy mu Min                -1.4379361
Policy log std Mean          -0.8868216
Policy log std Std           0.23737128
Policy log std Max           -0.3266527
Policy log std Min           -2.2010956
Z mean eval                  0.905454
Z variance eval              0.0088762045
total_rewards                [ 540.64777711  473.95837893 1455.14195925 1656.21055608  660.2323245
  926.44924629  381.24414031  341.21228212   51.81095289  143.9931654 ]
total_rewards_mean           663.09007828831
total_rewards_std            505.9574906075624
total_rewards_max            1656.2105560768464
total_rewards_min            51.81095288642811
Number of train steps total  97000
Number of env steps total    487000
Number of rollouts total     0
Train Time (s)               28.920072271022946
(Previous) Eval Time (s)     25.703523639123887
Sample Time (s)              17.563963770400733
Epoch Time (s)               72.18755968054757
Total Train Time (s)         6686.594522649888
Epoch                        96
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:06:58.089220 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #96 | Epoch Duration: 72.57988023757935
2020-01-11 05:06:58.089572 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #96 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90561354
Z variance train             0.008880566
KL Divergence                16.682642
KL Loss                      1.6682643
QF Loss                      318.3013
VF Loss                      37.02369
Policy Loss                  -513.06726
Q Predictions Mean           511.49243
Q Predictions Std            92.46176
Q Predictions Max            651.31006
Q Predictions Min            9.766531
V Predictions Mean           512.67004
V Predictions Std            93.33987
V Predictions Max            651.3563
V Predictions Min            -6.329755
Log Pis Mean                 -1.6890821
Log Pis Std                  2.0293374
Log Pis Max                  5.301417
Log Pis Min                  -7.1690903
Policy mu Mean               0.070195615
Policy mu Std                0.43034208
Policy mu Max                1.8652425
Policy mu Min                -1.6901947
Policy log std Mean          -0.8578613
Policy log std Std           0.23587285
Policy log std Max           0.28897074
Policy log std Min           -1.9726245
Z mean eval                  0.9428237
Z variance eval              0.010647838
total_rewards                [ 882.57760025  253.91288126  298.36029069   84.71204379   80.51720021
  431.52900384 1274.82953655   70.62816093  856.08136138  586.65915289]
total_rewards_mean           481.9807231780307
total_rewards_std            389.4199576332249
total_rewards_max            1274.8295365469057
total_rewards_min            70.62816092969646
Number of train steps total  98000
Number of env steps total    492000
Number of rollouts total     0
Train Time (s)               29.111507419962436
(Previous) Eval Time (s)     26.095522550866008
Sample Time (s)              18.251847735140473
Epoch Time (s)               73.45887770596892
Total Train Time (s)         6758.267804927193
Epoch                        97
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:08:09.762664 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #97 | Epoch Duration: 71.67285776138306
2020-01-11 05:08:09.762876 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #97 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9442105
Z variance train             0.010630313
KL Divergence                16.696247
KL Loss                      1.6696247
QF Loss                      206.35913
VF Loss                      30.941462
Policy Loss                  -522.108
Q Predictions Mean           519.71783
Q Predictions Std            76.37246
Q Predictions Max            663.9742
Q Predictions Min            293.34735
V Predictions Mean           523.8466
V Predictions Std            75.08536
V Predictions Max            655.66705
V Predictions Min            305.08087
Log Pis Mean                 -1.9483061
Log Pis Std                  1.9345322
Log Pis Max                  3.6533742
Log Pis Min                  -10.318398
Policy mu Mean               0.053976353
Policy mu Std                0.43597484
Policy mu Max                1.5487082
Policy mu Min                -1.655339
Policy log std Mean          -0.82376283
Policy log std Std           0.21410835
Policy log std Max           -0.19745076
Policy log std Min           -1.6112531
Z mean eval                  0.9228816
Z variance eval              0.008249254
total_rewards                [1125.30742343  216.17455967 1606.47092639  531.05072773  170.13296593
  578.68486883  939.64562411  265.54513782 1560.06524277   23.49006381]
total_rewards_mean           701.6567540480639
total_rewards_std            548.1071804541584
total_rewards_max            1606.4709263925897
total_rewards_min            23.49006380554987
Number of train steps total  99000
Number of env steps total    497000
Number of rollouts total     0
Train Time (s)               27.755437857005745
(Previous) Eval Time (s)     24.309221672359854
Sample Time (s)              17.798044360242784
Epoch Time (s)               69.86270388960838
Total Train Time (s)         6822.010434662923
Epoch                        98
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:09:13.506139 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #98 | Epoch Duration: 63.74311375617981
2020-01-11 05:09:13.506343 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #98 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9234649
Z variance train             0.00824218
KL Divergence                16.99391
KL Loss                      1.699391
QF Loss                      274.4343
VF Loss                      91.39545
Policy Loss                  -525.0156
Q Predictions Mean           522.05994
Q Predictions Std            92.59448
Q Predictions Max            637.14197
Q Predictions Min            -39.99301
V Predictions Mean           527.34467
V Predictions Std            87.05605
V Predictions Max            633.77167
V Predictions Min            -2.2198257
Log Pis Mean                 -1.9091476
Log Pis Std                  2.284147
Log Pis Max                  11.390927
Log Pis Min                  -13.559205
Policy mu Mean               0.0025878875
Policy mu Std                0.41426212
Policy mu Max                1.3333538
Policy mu Min                -1.8108767
Policy log std Mean          -0.88368845
Policy log std Std           0.21527727
Policy log std Max           -0.32223663
Policy log std Min           -2.4940262
Z mean eval                  0.9221649
Z variance eval              0.010485623
total_rewards                [ -12.69384207   19.95412632  -73.61949518  265.83454441  133.18005168
  179.86679337 1498.25134646  609.37125064  677.08518015  463.0540157 ]
total_rewards_mean           376.0283971467949
total_rewards_std            447.4054482986671
total_rewards_max            1498.2513464560197
total_rewards_min            -73.61949518051671
Number of train steps total  100000
Number of env steps total    502000
Number of rollouts total     0
Train Time (s)               28.83786243200302
(Previous) Eval Time (s)     18.189358382020146
Sample Time (s)              17.913510717917234
Epoch Time (s)               64.9407315319404
Total Train Time (s)         6892.4540448198095
Epoch                        99
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:10:23.952134 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #99 | Epoch Duration: 70.44566297531128
2020-01-11 05:10:23.952344 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #99 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9217187
Z variance train             0.010440041
KL Divergence                16.61567
KL Loss                      1.661567
QF Loss                      400.36438
VF Loss                      65.689285
Policy Loss                  -526.5787
Q Predictions Mean           521.3028
Q Predictions Std            96.41591
Q Predictions Max            649.63007
Q Predictions Min            -29.513443
V Predictions Mean           524.86066
V Predictions Std            93.21393
V Predictions Max            651.2118
V Predictions Min            -4.9777985
Log Pis Mean                 -1.6687546
Log Pis Std                  2.1531925
Log Pis Max                  5.6738586
Log Pis Min                  -6.987944
Policy mu Mean               0.09685783
Policy mu Std                0.4353304
Policy mu Max                1.5600476
Policy mu Min                -1.2897761
Policy log std Mean          -0.88300073
Policy log std Std           0.22715952
Policy log std Max           -0.23195612
Policy log std Min           -1.8728244
Z mean eval                  0.9265027
Z variance eval              0.0063894144
total_rewards                [ 858.66245426 1188.37252771 1543.10233327  114.93838585 1709.74580543
 1574.46296833  876.49071841 1626.43082839  429.510502    584.12385812]
total_rewards_mean           1050.5840381756648
total_rewards_std            533.6661349121695
total_rewards_max            1709.745805430865
total_rewards_min            114.9383858454425
Number of train steps total  101000
Number of env steps total    507000
Number of rollouts total     0
Train Time (s)               25.852392442058772
(Previous) Eval Time (s)     23.693976424634457
Sample Time (s)              17.40713031310588
Epoch Time (s)               66.95349917979911
Total Train Time (s)         6962.912882679142
Epoch                        100
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:11:34.412395 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #100 | Epoch Duration: 70.45991277694702
2020-01-11 05:11:34.412597 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #100 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9246933
Z variance train             0.006387399
KL Divergence                17.825367
KL Loss                      1.7825367
QF Loss                      798.2456
VF Loss                      51.99299
Policy Loss                  -534.2751
Q Predictions Mean           531.7572
Q Predictions Std            80.09182
Q Predictions Max            668.1297
Q Predictions Min            312.82498
V Predictions Mean           533.17645
V Predictions Std            79.80223
V Predictions Max            663.993
V Predictions Min            309.47998
Log Pis Mean                 -1.5746208
Log Pis Std                  1.9797586
Log Pis Max                  4.109961
Log Pis Min                  -9.486864
Policy mu Mean               0.03110494
Policy mu Std                0.44574216
Policy mu Max                1.6616849
Policy mu Min                -1.6434928
Policy log std Mean          -0.8820347
Policy log std Std           0.2237427
Policy log std Max           -0.14067352
Policy log std Min           -1.4745376
Z mean eval                  0.9319478
Z variance eval              0.0073543303
total_rewards                [1252.90316743 1216.26646775 1619.94302742 1489.08073841  587.6126338
  304.22008113 1581.06820192   44.95542837 1607.24033357  318.3107624 ]
total_rewards_mean           1002.1600842206332
total_rewards_std            589.2010121546733
total_rewards_max            1619.943027419027
total_rewards_min            44.955428367154724
Number of train steps total  102000
Number of env steps total    512000
Number of rollouts total     0
Train Time (s)               29.18674149317667
(Previous) Eval Time (s)     27.20008089626208
Sample Time (s)              17.75314277363941
Epoch Time (s)               74.13996516307816
Total Train Time (s)         7033.686132376082
Epoch                        101
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:12:45.186504 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #101 | Epoch Duration: 70.77375149726868
2020-01-11 05:12:45.186673 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #101 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9313362
Z variance train             0.0073435334
KL Divergence                17.880499
KL Loss                      1.7880499
QF Loss                      273.82507
VF Loss                      52.981216
Policy Loss                  -531.13617
Q Predictions Mean           527.2717
Q Predictions Std            87.608055
Q Predictions Max            657.96344
Q Predictions Min            305.03906
V Predictions Mean           530.53687
V Predictions Std            88.31984
V Predictions Max            656.48773
V Predictions Min            307.77222
Log Pis Mean                 -1.9419544
Log Pis Std                  2.1529524
Log Pis Max                  2.8582006
Log Pis Min                  -10.853488
Policy mu Mean               0.1405366
Policy mu Std                0.44034222
Policy mu Max                1.5635219
Policy mu Min                -1.7372617
Policy log std Mean          -0.8457171
Policy log std Std           0.2107821
Policy log std Max           -0.2669426
Policy log std Min           -1.676594
Z mean eval                  0.91090715
Z variance eval              0.007478288
total_rewards                [ 727.35096465 1450.98613497  721.56422669  -97.50645605 1098.04513958
  284.67849772  120.96001052  993.7023587   979.9078038  1548.34087273]
total_rewards_mean           782.8029553300742
total_rewards_std            517.9920272251637
total_rewards_max            1548.340872730088
total_rewards_min            -97.5064560504042
Number of train steps total  103000
Number of env steps total    517000
Number of rollouts total     0
Train Time (s)               28.538359474856406
(Previous) Eval Time (s)     23.833598298951983
Sample Time (s)              17.839291350450367
Epoch Time (s)               70.21124912425876
Total Train Time (s)         7103.611421211623
Epoch                        102
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:13:55.113059 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #102 | Epoch Duration: 69.92622017860413
2020-01-11 05:13:55.113262 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #102 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9089426
Z variance train             0.0074722967
KL Divergence                17.65146
KL Loss                      1.7651461
QF Loss                      323.5187
VF Loss                      108.858574
Policy Loss                  -532.9915
Q Predictions Mean           530.4663
Q Predictions Std            91.951035
Q Predictions Max            666.5521
Q Predictions Min            256.3717
V Predictions Mean           538.084
V Predictions Std            90.909775
V Predictions Max            665.9169
V Predictions Min            299.8719
Log Pis Mean                 -1.9553893
Log Pis Std                  1.9356816
Log Pis Max                  4.274516
Log Pis Min                  -8.181858
Policy mu Mean               0.071098566
Policy mu Std                0.42678615
Policy mu Max                1.5285197
Policy mu Min                -1.7630622
Policy log std Mean          -0.8328217
Policy log std Std           0.22153625
Policy log std Max           -0.28056914
Policy log std Min           -1.9371855
Z mean eval                  0.94323957
Z variance eval              0.005651037
total_rewards                [ 745.05811646   57.71248903  193.01383426 1052.81579754  732.25975462
 1840.70770001  782.15173674 -117.08642487  763.99466311    6.65009082]
total_rewards_mean           605.7277757713189
total_rewards_std            562.9092478260684
total_rewards_max            1840.7077000054064
total_rewards_min            -117.08642487388741
Number of train steps total  104000
Number of env steps total    522000
Number of rollouts total     0
Train Time (s)               26.311430297326297
(Previous) Eval Time (s)     23.548331582453102
Sample Time (s)              19.448542480822653
Epoch Time (s)               69.30830436060205
Total Train Time (s)         7174.945170136169
Epoch                        103
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:15:06.450599 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #103 | Epoch Duration: 71.33716893196106
2020-01-11 05:15:06.450862 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #103 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9456436
Z variance train             0.00563155
KL Divergence                18.200489
KL Loss                      1.8200489
QF Loss                      258.89798
VF Loss                      548.7111
Policy Loss                  -535.905
Q Predictions Mean           531.2195
Q Predictions Std            109.23093
Q Predictions Max            678.8071
Q Predictions Min            -22.144768
V Predictions Mean           534.9568
V Predictions Std            106.531494
V Predictions Max            685.22064
V Predictions Min            27.477531
Log Pis Mean                 -1.839635
Log Pis Std                  2.0682263
Log Pis Max                  8.329306
Log Pis Min                  -9.040285
Policy mu Mean               0.04804217
Policy mu Std                0.43348682
Policy mu Max                2.129143
Policy mu Min                -2.063205
Policy log std Mean          -0.86717904
Policy log std Std           0.24033666
Policy log std Max           -0.21132433
Policy log std Min           -2.1040478
Z mean eval                  0.9509605
Z variance eval              0.0099251885
total_rewards                [ -14.94437098  -94.83277465  493.73010623  -19.9664555  1573.15966445
  835.00912007 1079.2012047   749.83888503  112.26369334  946.41871721]
total_rewards_mean           565.9877789898529
total_rewards_std            534.535282853877
total_rewards_max            1573.1596644462193
total_rewards_min            -94.83277465316115
Number of train steps total  105000
Number of env steps total    527000
Number of rollouts total     0
Train Time (s)               29.3484818469733
(Previous) Eval Time (s)     25.57682876707986
Sample Time (s)              17.973638800904155
Epoch Time (s)               72.89894941495731
Total Train Time (s)         7246.035560521297
Epoch                        104
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:16:17.544978 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #104 | Epoch Duration: 71.09378170967102
2020-01-11 05:16:17.545389 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #104 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9506505
Z variance train             0.00997875
KL Divergence                17.593203
KL Loss                      1.7593203
QF Loss                      394.25308
VF Loss                      122.285
Policy Loss                  -537.1396
Q Predictions Mean           532.775
Q Predictions Std            117.51915
Q Predictions Max            696.36597
Q Predictions Min            -29.977383
V Predictions Mean           530.6958
V Predictions Std            116.497154
V Predictions Max            686.75543
V Predictions Min            -18.305641
Log Pis Mean                 -1.6802607
Log Pis Std                  2.0464013
Log Pis Max                  4.449562
Log Pis Min                  -7.062427
Policy mu Mean               0.008111075
Policy mu Std                0.44899172
Policy mu Max                1.7564147
Policy mu Min                -1.8301798
Policy log std Mean          -0.8749069
Policy log std Std           0.23340757
Policy log std Max           -0.13692078
Policy log std Min           -1.9243739
Z mean eval                  0.9458065
Z variance eval              0.00739088
total_rewards                [1030.04194024  741.81078068   52.9980295   368.63059168 1458.59216094
  -61.4480189   610.30363318  174.62886075   68.20936072  230.68099083]
total_rewards_mean           467.44483296172893
total_rewards_std            464.4372045490932
total_rewards_max            1458.5921609422655
total_rewards_min            -61.44801890162736
Number of train steps total  106000
Number of env steps total    532000
Number of rollouts total     0
Train Time (s)               30.83392773894593
(Previous) Eval Time (s)     23.771356279030442
Sample Time (s)              18.527797822840512
Epoch Time (s)               73.13308184081689
Total Train Time (s)         7317.371266911272
Epoch                        105
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:17:28.882481 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #105 | Epoch Duration: 71.33684229850769
2020-01-11 05:17:28.882754 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #105 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9474775
Z variance train             0.007391387
KL Divergence                18.038973
KL Loss                      1.8038973
QF Loss                      346.71973
VF Loss                      98.81651
Policy Loss                  -539.8336
Q Predictions Mean           536.6523
Q Predictions Std            100.99715
Q Predictions Max            661.8718
Q Predictions Min            78.81863
V Predictions Mean           545.1063
V Predictions Std            100.422104
V Predictions Max            674.8026
V Predictions Min            12.379625
Log Pis Mean                 -1.6773162
Log Pis Std                  2.0769258
Log Pis Max                  6.2671237
Log Pis Min                  -8.04653
Policy mu Mean               0.06198241
Policy mu Std                0.45783705
Policy mu Max                1.4306692
Policy mu Min                -1.4268115
Policy log std Mean          -0.8509433
Policy log std Std           0.23783992
Policy log std Max           -0.13900283
Policy log std Min           -1.8811239
Z mean eval                  0.9274756
Z variance eval              0.009034363
total_rewards                [ 787.60816385  169.24394727  900.68248665 1554.76665253  390.64279109
   76.42848884  199.39408199  655.65232832 1564.17746233 1747.0594478 ]
total_rewards_mean           804.5655850680089
total_rewards_std            594.2381290187642
total_rewards_max            1747.0594477977527
total_rewards_min            76.42848884233075
Number of train steps total  107000
Number of env steps total    537000
Number of rollouts total     0
Train Time (s)               28.76650984492153
(Previous) Eval Time (s)     21.9748192303814
Sample Time (s)              19.099209067877382
Epoch Time (s)               69.84053814318031
Total Train Time (s)         7387.803015490528
Epoch                        106
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:18:39.318924 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #106 | Epoch Duration: 70.43582081794739
2020-01-11 05:18:39.319364 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #106 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92636174
Z variance train             0.009008432
KL Divergence                17.132687
KL Loss                      1.7132686
QF Loss                      714.8854
VF Loss                      313.5257
Policy Loss                  -536.4504
Q Predictions Mean           532.22217
Q Predictions Std            107.08333
Q Predictions Max            680.3342
Q Predictions Min            -44.91931
V Predictions Mean           540.1336
V Predictions Std            105.03403
V Predictions Max            686.77716
V Predictions Min            20.064234
Log Pis Mean                 -1.7353334
Log Pis Std                  2.0639389
Log Pis Max                  7.5238204
Log Pis Min                  -7.0903177
Policy mu Mean               0.0562478
Policy mu Std                0.44785368
Policy mu Max                1.6351734
Policy mu Min                -1.5075179
Policy log std Mean          -0.8491298
Policy log std Std           0.24542692
Policy log std Max           -0.2207247
Policy log std Min           -2.0503242
Z mean eval                  0.9345024
Z variance eval              0.008168327
total_rewards                [ 796.21668062  959.96474533  159.76007025   67.21583853 1425.22909589
  265.43632188 1802.94413747  644.76807275  311.81709611 1452.29708032]
total_rewards_mean           788.5649139153538
total_rewards_std            578.070314696691
total_rewards_max            1802.9441374665644
total_rewards_min            67.21583852805662
Number of train steps total  108000
Number of env steps total    542000
Number of rollouts total     0
Train Time (s)               27.80497053777799
(Previous) Eval Time (s)     22.5697408108972
Sample Time (s)              18.635151321534067
Epoch Time (s)               69.00986267020926
Total Train Time (s)         7459.351647661999
Epoch                        107
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:19:50.869301 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #107 | Epoch Duration: 71.54964828491211
2020-01-11 05:19:50.869587 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #107 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9356332
Z variance train             0.008163562
KL Divergence                17.632345
KL Loss                      1.7632345
QF Loss                      496.1282
VF Loss                      66.47643
Policy Loss                  -570.6298
Q Predictions Mean           568.3616
Q Predictions Std            89.03212
Q Predictions Max            698.8895
Q Predictions Min            245.97456
V Predictions Mean           572.34454
V Predictions Std            88.56373
V Predictions Max            689.52466
V Predictions Min            228.95636
Log Pis Mean                 -1.5631096
Log Pis Std                  2.2365322
Log Pis Max                  7.1943684
Log Pis Min                  -8.670519
Policy mu Mean               0.10226431
Policy mu Std                0.4789023
Policy mu Max                1.5495156
Policy mu Min                -1.8652332
Policy log std Mean          -0.87709904
Policy log std Std           0.2292549
Policy log std Max           -0.17622912
Policy log std Min           -2.258147
Z mean eval                  0.93591416
Z variance eval              0.009675875
total_rewards                [1565.63553236   40.02724233  231.89762916  859.32523506 1026.38341408
  186.65453621  187.63561893  820.71157214  908.06597689  243.12692937]
total_rewards_mean           606.9463686520609
total_rewards_std            473.4940535022991
total_rewards_max            1565.6355323635169
total_rewards_min            40.02724233287769
Number of train steps total  109000
Number of env steps total    547000
Number of rollouts total     0
Train Time (s)               30.154253859072924
(Previous) Eval Time (s)     25.10922080092132
Sample Time (s)              18.23837898718193
Epoch Time (s)               73.50185364717618
Total Train Time (s)         7535.042568687815
Epoch                        108
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:21:06.560805 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #108 | Epoch Duration: 75.69101691246033
2020-01-11 05:21:06.560966 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #108 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93608224
Z variance train             0.009671235
KL Divergence                17.764137
KL Loss                      1.7764138
QF Loss                      194.7917
VF Loss                      64.84381
Policy Loss                  -556.4995
Q Predictions Mean           555.53955
Q Predictions Std            97.67214
Q Predictions Max            711.8715
Q Predictions Min            305.7707
V Predictions Mean           561.9948
V Predictions Std            98.1311
V Predictions Max            726.71545
V Predictions Min            310.04224
Log Pis Mean                 -1.6498089
Log Pis Std                  1.8926964
Log Pis Max                  3.1932325
Log Pis Min                  -7.8599963
Policy mu Mean               0.007290663
Policy mu Std                0.46618193
Policy mu Max                1.4464076
Policy mu Min                -1.6392533
Policy log std Mean          -0.85117793
Policy log std Std           0.22142354
Policy log std Max           -0.22625408
Policy log std Min           -1.6794343
Z mean eval                  0.9211758
Z variance eval              0.0063700425
total_rewards                [1178.60655304 1367.71059327 1413.83654627 1346.70218043 1544.12296453
  244.89048069 1643.29325411 1286.81365538  544.74965906  153.88966092]
total_rewards_mean           1072.4615547711028
total_rewards_std            518.8035996540342
total_rewards_max            1643.2932541097937
total_rewards_min            153.8896609216666
Number of train steps total  110000
Number of env steps total    552000
Number of rollouts total     0
Train Time (s)               28.16576306009665
(Previous) Eval Time (s)     27.298114887904376
Sample Time (s)              18.19211560720578
Epoch Time (s)               73.6559935552068
Total Train Time (s)         7608.330847520381
Epoch                        109
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:22:19.851714 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #109 | Epoch Duration: 73.29058504104614
2020-01-11 05:22:19.851971 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #109 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9211893
Z variance train             0.006370564
KL Divergence                17.861292
KL Loss                      1.7861292
QF Loss                      381.39624
VF Loss                      60.694958
Policy Loss                  -550.3099
Q Predictions Mean           547.02966
Q Predictions Std            107.51134
Q Predictions Max            694.77026
Q Predictions Min            119.4753
V Predictions Mean           548.9729
V Predictions Std            106.457634
V Predictions Max            705.09534
V Predictions Min            106.38616
Log Pis Mean                 -1.586061
Log Pis Std                  2.108911
Log Pis Max                  3.7704253
Log Pis Min                  -13.572044
Policy mu Mean               0.026321728
Policy mu Std                0.4573756
Policy mu Max                1.4551425
Policy mu Min                -1.8048828
Policy log std Mean          -0.8624879
Policy log std Std           0.21943974
Policy log std Max           -0.30807748
Policy log std Min           -1.9048293
Z mean eval                  0.9253346
Z variance eval              0.0051375898
total_rewards                [ 7.97223290e+02  3.98145625e+02 -1.11344663e+00  3.16377526e+02
  1.10573893e+03  3.22259592e+02  1.44670673e+03  8.36770585e+02
  1.11458466e+03  1.05425708e+02]
total_rewards_mean           644.2119204182914
total_rewards_std            460.1260329169641
total_rewards_max            1446.7067310364218
total_rewards_min            -1.11344662650691
Number of train steps total  111000
Number of env steps total    557000
Number of rollouts total     0
Train Time (s)               27.848459581378847
(Previous) Eval Time (s)     26.932418541051447
Sample Time (s)              19.736338697373867
Epoch Time (s)               74.51721681980416
Total Train Time (s)         7681.01406596601
Epoch                        110
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:23:32.538370 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #110 | Epoch Duration: 72.68617653846741
2020-01-11 05:23:32.538682 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #110 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9233754
Z variance train             0.005137729
KL Divergence                17.927814
KL Loss                      1.7927815
QF Loss                      298.4376
VF Loss                      53.374943
Policy Loss                  -557.88043
Q Predictions Mean           555.7134
Q Predictions Std            104.47747
Q Predictions Max            702.4659
Q Predictions Min            41.38307
V Predictions Mean           559.16974
V Predictions Std            102.044846
V Predictions Max            704.693
V Predictions Min            278.61313
Log Pis Mean                 -1.6755912
Log Pis Std                  2.2006388
Log Pis Max                  6.8382545
Log Pis Min                  -8.163701
Policy mu Mean               0.049754255
Policy mu Std                0.44695705
Policy mu Max                1.7117772
Policy mu Min                -1.6770167
Policy log std Mean          -0.86086357
Policy log std Std           0.24028242
Policy log std Max           -0.27076834
Policy log std Min           -1.8846439
Z mean eval                  0.934618
Z variance eval              0.005353306
total_rewards                [  80.51471877  235.76816394  734.35094287 1503.44025267  651.03471466
  669.76351979  114.79121642  824.74844432  -87.43902626 1693.72812092]
total_rewards_mean           642.0701068093498
total_rewards_std            564.0310142127778
total_rewards_max            1693.7281209237751
total_rewards_min            -87.43902626040912
Number of train steps total  112000
Number of env steps total    562000
Number of rollouts total     0
Train Time (s)               29.725862396880984
(Previous) Eval Time (s)     25.10104104829952
Sample Time (s)              19.19725398812443
Epoch Time (s)               74.02415743330494
Total Train Time (s)         7758.339970597532
Epoch                        111
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:24:49.866738 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #111 | Epoch Duration: 77.32780170440674
2020-01-11 05:24:49.866979 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #111 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93373835
Z variance train             0.0053522643
KL Divergence                17.966564
KL Loss                      1.7966565
QF Loss                      415.03595
VF Loss                      90.33437
Policy Loss                  -567.2175
Q Predictions Mean           563.2324
Q Predictions Std            110.702576
Q Predictions Max            697.09924
Q Predictions Min            -41.999992
V Predictions Mean           573.8457
V Predictions Std            109.30191
V Predictions Max            707.7017
V Predictions Min            36.808857
Log Pis Mean                 -1.8731169
Log Pis Std                  2.227248
Log Pis Max                  8.7775545
Log Pis Min                  -6.7852035
Policy mu Mean               0.016563015
Policy mu Std                0.44016066
Policy mu Max                1.5232313
Policy mu Min                -1.7856113
Policy log std Mean          -0.861519
Policy log std Std           0.24363509
Policy log std Max           -0.16526729
Policy log std Min           -2.1305523
Z mean eval                  0.92993575
Z variance eval              0.011091021
total_rewards                [1868.87674685  531.10801333 1667.89445146  321.74167109  -19.54145183
 1673.37608027  907.15894705  225.5221862  1793.67905816 1640.08354031]
total_rewards_mean           1060.9899242893553
total_rewards_std            706.0237244857826
total_rewards_max            1868.876746850444
total_rewards_min            -19.541451830972047
Number of train steps total  113000
Number of env steps total    567000
Number of rollouts total     0
Train Time (s)               27.85778199089691
(Previous) Eval Time (s)     28.404383037239313
Sample Time (s)              18.84402336133644
Epoch Time (s)               75.10618838947266
Total Train Time (s)         7829.962251307908
Epoch                        112
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:26:01.491755 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #112 | Epoch Duration: 71.62457036972046
2020-01-11 05:26:01.492055 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #112 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9282193
Z variance train             0.011081201
KL Divergence                16.006176
KL Loss                      1.6006176
QF Loss                      354.03253
VF Loss                      88.23481
Policy Loss                  -546.4563
Q Predictions Mean           543.3008
Q Predictions Std            124.87236
Q Predictions Max            707.4615
Q Predictions Min            -42.027477
V Predictions Mean           550.30096
V Predictions Std            123.70221
V Predictions Max            709.3335
V Predictions Min            -11.272998
Log Pis Mean                 -1.6145395
Log Pis Std                  2.3033268
Log Pis Max                  9.009993
Log Pis Min                  -12.723944
Policy mu Mean               0.039035566
Policy mu Std                0.45824483
Policy mu Max                1.9101868
Policy mu Min                -1.8295166
Policy log std Mean          -0.86663175
Policy log std Std           0.22987835
Policy log std Max           -0.15431434
Policy log std Min           -1.9634264
Z mean eval                  0.9161803
Z variance eval              0.007636045
total_rewards                [ 610.82774752  155.80071447 1643.33530171  218.62602825  713.80485178
  782.89045915 1260.21577446  157.24986321  275.61486154  595.4676744 ]
total_rewards_mean           641.3833276471773
total_rewards_std            468.8132231783175
total_rewards_max            1643.33530170607
total_rewards_min            155.8007144674824
Number of train steps total  114000
Number of env steps total    572000
Number of rollouts total     0
Train Time (s)               29.393971015233546
(Previous) Eval Time (s)     24.92244157800451
Sample Time (s)              18.377691863570362
Epoch Time (s)               72.69410445680842
Total Train Time (s)         7894.806881075725
Epoch                        113
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:27:06.339883 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #113 | Epoch Duration: 64.84757542610168
2020-01-11 05:27:06.340148 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #113 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91562384
Z variance train             0.0076542795
KL Divergence                16.927475
KL Loss                      1.6927475
QF Loss                      365.92786
VF Loss                      59.384453
Policy Loss                  -572.1737
Q Predictions Mean           568.54395
Q Predictions Std            112.521416
Q Predictions Max            711.4239
Q Predictions Min            188.7344
V Predictions Mean           569.688
V Predictions Std            115.41657
V Predictions Max            711.0171
V Predictions Min            40.39295
Log Pis Mean                 -1.8047633
Log Pis Std                  2.2897348
Log Pis Max                  5.8924203
Log Pis Min                  -7.435878
Policy mu Mean               0.0531661
Policy mu Std                0.460349
Policy mu Max                1.5776783
Policy mu Min                -1.7546841
Policy log std Mean          -0.84764385
Policy log std Std           0.25891972
Policy log std Max           -0.22153339
Policy log std Min           -2.652592
Z mean eval                  0.9537897
Z variance eval              0.0077698156
total_rewards                [ 869.48111776  -52.54355708  602.4314882  1243.7071344   601.40266744
  872.68789653  289.40103016  597.73274825  340.30294829  455.95759418]
total_rewards_mean           582.0561068145867
total_rewards_std            341.8488570872726
total_rewards_max            1243.7071343975038
total_rewards_min            -52.54355707603433
Number of train steps total  115000
Number of env steps total    577000
Number of rollouts total     0
Train Time (s)               27.15873744804412
(Previous) Eval Time (s)     17.075596934184432
Sample Time (s)              17.938863972667605
Epoch Time (s)               62.17319835489616
Total Train Time (s)         7966.247430819552
Epoch                        114
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:28:17.782195 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #114 | Epoch Duration: 71.44182968139648
2020-01-11 05:28:17.782460 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #114 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9533638
Z variance train             0.0077377246
KL Divergence                16.63058
KL Loss                      1.6630582
QF Loss                      311.76114
VF Loss                      140.95381
Policy Loss                  -572.1971
Q Predictions Mean           570.8267
Q Predictions Std            114.061615
Q Predictions Max            723.68805
Q Predictions Min            305.59128
V Predictions Mean           577.4499
V Predictions Std            113.518074
V Predictions Max            734.57294
V Predictions Min            318.24268
Log Pis Mean                 -1.542867
Log Pis Std                  2.287833
Log Pis Max                  5.411988
Log Pis Min                  -8.755628
Policy mu Mean               0.008277988
Policy mu Std                0.45850083
Policy mu Max                1.5245247
Policy mu Min                -1.6164142
Policy log std Mean          -0.879087
Policy log std Std           0.25145158
Policy log std Max           -0.18966246
Policy log std Min           -2.3329828
Z mean eval                  0.93285215
Z variance eval              0.010292156
total_rewards                [ 637.31652813  936.13993687 1129.01841761   28.05002719  180.50926974
  757.48788045  393.91251291 1020.8736614    13.5984883   -27.35763315]
total_rewards_mean           506.95490894543946
total_rewards_std            423.3936557829409
total_rewards_max            1129.018417610857
total_rewards_min            -27.357633151091747
Number of train steps total  116000
Number of env steps total    582000
Number of rollouts total     0
Train Time (s)               27.177924289833754
(Previous) Eval Time (s)     26.34390235831961
Sample Time (s)              18.49580220831558
Epoch Time (s)               72.01762885646895
Total Train Time (s)         8037.183885743376
Epoch                        115
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:29:28.722369 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #115 | Epoch Duration: 70.93968415260315
2020-01-11 05:29:28.722635 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #115 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93229026
Z variance train             0.010283263
KL Divergence                16.674381
KL Loss                      1.6674381
QF Loss                      536.92737
VF Loss                      132.05301
Policy Loss                  -576.97894
Q Predictions Mean           575.1394
Q Predictions Std            122.7784
Q Predictions Max            751.34534
Q Predictions Min            -69.4539
V Predictions Mean           579.2433
V Predictions Std            115.84004
V Predictions Max            730.6713
V Predictions Min            -9.08072
Log Pis Mean                 -1.5774386
Log Pis Std                  2.2662401
Log Pis Max                  7.689188
Log Pis Min                  -7.1172314
Policy mu Mean               0.03629465
Policy mu Std                0.49120852
Policy mu Max                2.531624
Policy mu Min                -1.7312338
Policy log std Mean          -0.8431407
Policy log std Std           0.24782886
Policy log std Max           -0.0871315
Policy log std Min           -2.6306756
Z mean eval                  0.94343597
Z variance eval              0.006873826
total_rewards                [1602.49712733  358.97492833  -52.00947991  388.45524468  666.79952726
 1594.69384727 1666.59123616  -60.95267191  597.03772727 1649.8898642 ]
total_rewards_mean           841.1977350677267
total_rewards_std            679.8403102978657
total_rewards_max            1666.5912361574847
total_rewards_min            -60.9526719142986
Number of train steps total  117000
Number of env steps total    587000
Number of rollouts total     0
Train Time (s)               29.060352549888194
(Previous) Eval Time (s)     25.265624797903
Sample Time (s)              17.97158039174974
Epoch Time (s)               72.29755773954093
Total Train Time (s)         8108.555500312243
Epoch                        116
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:30:40.096253 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #116 | Epoch Duration: 71.37339973449707
2020-01-11 05:30:40.096538 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #116 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9407573
Z variance train             0.0068937526
KL Divergence                17.99228
KL Loss                      1.799228
QF Loss                      400.43195
VF Loss                      115.97214
Policy Loss                  -574.84143
Q Predictions Mean           571.379
Q Predictions Std            124.56507
Q Predictions Max            733.96606
Q Predictions Min            124.484566
V Predictions Mean           573.31586
V Predictions Std            122.13378
V Predictions Max            735.953
V Predictions Min            159.64833
Log Pis Mean                 -1.8840573
Log Pis Std                  2.1550813
Log Pis Max                  7.1960793
Log Pis Min                  -7.8575335
Policy mu Mean               0.07259525
Policy mu Std                0.46518773
Policy mu Max                2.2190075
Policy mu Min                -1.4040923
Policy log std Mean          -0.8230223
Policy log std Std           0.23280749
Policy log std Max           -0.09776986
Policy log std Min           -1.7668021
Z mean eval                  0.92332065
Z variance eval              0.0044443947
total_rewards                [  49.88695657  161.78167311  473.40392182  625.1317527  1753.69707904
  401.24401318  256.53309779  679.35045107  150.7638645   554.59804125]
total_rewards_mean           510.63908510254385
total_rewards_std            461.5328207458067
total_rewards_max            1753.6970790436537
total_rewards_min            49.88695656890174
Number of train steps total  118000
Number of env steps total    592000
Number of rollouts total     0
Train Time (s)               29.55249900696799
(Previous) Eval Time (s)     24.341188246849924
Sample Time (s)              17.4481344637461
Epoch Time (s)               71.34182171756402
Total Train Time (s)         8177.910752178635
Epoch                        117
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:31:49.455138 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #117 | Epoch Duration: 69.35835123062134
2020-01-11 05:31:49.455436 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #117 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92551214
Z variance train             0.004424981
KL Divergence                18.92207
KL Loss                      1.892207
QF Loss                      298.6646
VF Loss                      115.85767
Policy Loss                  -594.6694
Q Predictions Mean           588.3955
Q Predictions Std            106.39401
Q Predictions Max            733.4352
Q Predictions Min            282.24014
V Predictions Mean           586.7746
V Predictions Std            105.09987
V Predictions Max            718.18414
V Predictions Min            277.93304
Log Pis Mean                 -1.5937026
Log Pis Std                  2.0473685
Log Pis Max                  5.6574802
Log Pis Min                  -8.344028
Policy mu Mean               0.06315845
Policy mu Std                0.46364865
Policy mu Max                1.6655357
Policy mu Min                -1.8443837
Policy log std Mean          -0.86543536
Policy log std Std           0.21423362
Policy log std Max           -0.16028169
Policy log std Min           -1.6414402
Z mean eval                  0.91275537
Z variance eval              0.0048040827
total_rewards                [ 620.22397498  542.60303513  349.65363293 1318.45943407   13.14409393
 1705.522451    108.03928479    6.00810814   63.80864784  609.32685422]
total_rewards_mean           533.6789517023203
total_rewards_std            546.5890121076394
total_rewards_max            1705.5224510006883
total_rewards_min            6.008108139783602
Number of train steps total  119000
Number of env steps total    597000
Number of rollouts total     0
Train Time (s)               26.592080089263618
(Previous) Eval Time (s)     22.357420743908733
Sample Time (s)              17.683137335348874
Epoch Time (s)               66.63263816852123
Total Train Time (s)         8248.548113573343
Epoch                        118
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:33:00.092170 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #118 | Epoch Duration: 70.63651394844055
2020-01-11 05:33:00.092409 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #118 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91496944
Z variance train             0.00480944
KL Divergence                19.255348
KL Loss                      1.9255348
QF Loss                      328.88745
VF Loss                      80.24624
Policy Loss                  -584.7823
Q Predictions Mean           580.8489
Q Predictions Std            116.170074
Q Predictions Max            736.8417
Q Predictions Min            282.6449
V Predictions Mean           580.7568
V Predictions Std            113.77155
V Predictions Max            730.25323
V Predictions Min            277.35403
Log Pis Mean                 -1.7827002
Log Pis Std                  2.2746358
Log Pis Max                  6.7317867
Log Pis Min                  -8.391139
Policy mu Mean               0.05589692
Policy mu Std                0.46951807
Policy mu Max                1.8012033
Policy mu Min                -1.6942004
Policy log std Mean          -0.8433738
Policy log std Std           0.23627877
Policy log std Max           -0.16739535
Policy log std Min           -1.8536198
Z mean eval                  0.9395053
Z variance eval              0.005618044
total_rewards                [7.92962751e+02 1.59718981e+02 1.30173982e+02 8.92861467e+01
 6.76870723e-01 5.07496937e+02 1.73382113e+03 1.20111055e+03
 8.46591742e+02 3.39076850e+02]
total_rewards_mean           580.0915941142248
total_rewards_std            534.0600468959486
total_rewards_max            1733.821128442882
total_rewards_min            0.6768707231070898
Number of train steps total  120000
Number of env steps total    602000
Number of rollouts total     0
Train Time (s)               32.422123988159
(Previous) Eval Time (s)     26.361012667883188
Sample Time (s)              17.44400376966223
Epoch Time (s)               76.22714042570442
Total Train Time (s)         8323.096208659466
Epoch                        119
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:34:14.644528 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #119 | Epoch Duration: 74.55196738243103
2020-01-11 05:34:14.644802 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #119 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9383742
Z variance train             0.00567486
KL Divergence                19.324652
KL Loss                      1.9324652
QF Loss                      287.05954
VF Loss                      97.73711
Policy Loss                  -578.86383
Q Predictions Mean           575.3991
Q Predictions Std            129.45155
Q Predictions Max            739.61957
Q Predictions Min            -44.065582
V Predictions Mean           582.6773
V Predictions Std            128.5334
V Predictions Max            743.0028
V Predictions Min            -4.251669
Log Pis Mean                 -2.0668674
Log Pis Std                  2.0090969
Log Pis Max                  4.4077682
Log Pis Min                  -8.061613
Policy mu Mean               0.04339601
Policy mu Std                0.46051052
Policy mu Max                2.1221783
Policy mu Min                -2.8012545
Policy log std Mean          -0.81090844
Policy log std Std           0.21949492
Policy log std Max           -0.08966583
Policy log std Min           -1.4631684
Z mean eval                  0.9392377
Z variance eval              0.0063231466
total_rewards                [ 361.82852548 1681.29415033  487.87664034 1605.57691569  111.45997177
  681.9167269  1711.33612766 1331.32667584  614.91595821  244.41450166]
total_rewards_mean           883.1946193874892
total_rewards_std            599.1359849536444
total_rewards_max            1711.3361276581288
total_rewards_min            111.45997176709442
Number of train steps total  121000
Number of env steps total    607000
Number of rollouts total     0
Train Time (s)               28.932871445082128
(Previous) Eval Time (s)     24.68553935131058
Sample Time (s)              17.833680057432503
Epoch Time (s)               71.45209085382521
Total Train Time (s)         8393.523124356288
Epoch                        120
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:35:25.074073 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #120 | Epoch Duration: 70.4290554523468
2020-01-11 05:35:25.074306 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #120 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93978167
Z variance train             0.006312574
KL Divergence                19.125546
KL Loss                      1.9125546
QF Loss                      412.12653
VF Loss                      60.414017
Policy Loss                  -584.21594
Q Predictions Mean           580.9603
Q Predictions Std            118.297935
Q Predictions Max            741.43713
Q Predictions Min            268.48798
V Predictions Mean           581.4363
V Predictions Std            117.204956
V Predictions Max            738.0497
V Predictions Min            261.79486
Log Pis Mean                 -1.7907848
Log Pis Std                  2.1331217
Log Pis Max                  4.204361
Log Pis Min                  -9.360911
Policy mu Mean               0.01155327
Policy mu Std                0.47582847
Policy mu Max                1.5303793
Policy mu Min                -1.5980283
Policy log std Mean          -0.8221741
Policy log std Std           0.21486324
Policy log std Max           -0.1379947
Policy log std Min           -1.7666773
Z mean eval                  0.93001926
Z variance eval              0.014714694
total_rewards                [ 362.5348143   958.31427487  267.45553093  658.61443461   96.41467044
 1032.84751597 1609.69387388 -128.1012668  1109.21426843  178.96214747]
total_rewards_mean           614.5950264105654
total_rewards_std            521.9013830417191
total_rewards_max            1609.6938738759623
total_rewards_min            -128.1012667952574
Number of train steps total  122000
Number of env steps total    612000
Number of rollouts total     0
Train Time (s)               27.14835422579199
(Previous) Eval Time (s)     23.662231401074678
Sample Time (s)              17.84651780175045
Epoch Time (s)               68.65710342861712
Total Train Time (s)         8461.68147663027
Epoch                        121
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:36:33.232292 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #121 | Epoch Duration: 68.15779256820679
2020-01-11 05:36:33.232519 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #121 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93251514
Z variance train             0.014671823
KL Divergence                18.034428
KL Loss                      1.8034428
QF Loss                      501.80392
VF Loss                      233.3757
Policy Loss                  -589.69415
Q Predictions Mean           586.8684
Q Predictions Std            126.418106
Q Predictions Max            787.57404
Q Predictions Min            -4.6905065
V Predictions Mean           579.71515
V Predictions Std            124.86651
V Predictions Max            776.0843
V Predictions Min            -2.2315085
Log Pis Mean                 -1.7126689
Log Pis Std                  2.3084404
Log Pis Max                  7.8014393
Log Pis Min                  -7.6947584
Policy mu Mean               0.11122786
Policy mu Std                0.4834446
Policy mu Max                1.6993474
Policy mu Min                -1.9233183
Policy log std Mean          -0.8218816
Policy log std Std           0.25126553
Policy log std Max           -0.24429405
Policy log std Min           -2.3495564
Z mean eval                  0.9338705
Z variance eval              0.0074159494
total_rewards                [ 518.71530997  439.82546137 1350.31154762 1551.24297514 1286.66248667
 1890.8429329  1913.71768832  289.93866584 1709.93354675  595.9927782 ]
total_rewards_mean           1154.7183392778588
total_rewards_std            601.2246601867479
total_rewards_max            1913.7176883182385
total_rewards_min            289.93866583938774
Number of train steps total  123000
Number of env steps total    617000
Number of rollouts total     0
Train Time (s)               29.92198373703286
(Previous) Eval Time (s)     23.162637814879417
Sample Time (s)              17.736866601742804
Epoch Time (s)               70.82148815365508
Total Train Time (s)         8534.061844027601
Epoch                        122
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:37:45.616191 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #122 | Epoch Duration: 72.38353300094604
2020-01-11 05:37:45.616410 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #122 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93293446
Z variance train             0.0074134893
KL Divergence                19.148727
KL Loss                      1.9148728
QF Loss                      352.3419
VF Loss                      56.82625
Policy Loss                  -601.51
Q Predictions Mean           598.95996
Q Predictions Std            119.23402
Q Predictions Max            745.8651
Q Predictions Min            279.31924
V Predictions Mean           603.66003
V Predictions Std            118.598694
V Predictions Max            751.5461
V Predictions Min            255.37276
Log Pis Mean                 -1.5589592
Log Pis Std                  2.1117842
Log Pis Max                  5.5799623
Log Pis Min                  -7.1270285
Policy mu Mean               0.03885386
Policy mu Std                0.47654995
Policy mu Max                1.8606839
Policy mu Min                -1.5619774
Policy log std Mean          -0.8358262
Policy log std Std           0.22709921
Policy log std Max           -0.1614669
Policy log std Min           -1.8453732
Z mean eval                  0.9185494
Z variance eval              0.009443773
total_rewards                [ 271.93353966  118.04975115  882.27410836  110.76591963 1716.56459419
   74.08239101 1918.08877235 1778.36947519 1678.43969723   58.49675643]
total_rewards_mean           860.7065005219904
total_rewards_std            780.0467875672554
total_rewards_max            1918.0887723542278
total_rewards_min            58.49675643406991
Number of train steps total  124000
Number of env steps total    622000
Number of rollouts total     0
Train Time (s)               29.47455327026546
(Previous) Eval Time (s)     24.72436079988256
Sample Time (s)              17.924384823534638
Epoch Time (s)               72.12329889368266
Total Train Time (s)         8603.878644882701
Epoch                        123
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:38:55.435531 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #123 | Epoch Duration: 69.81892824172974
2020-01-11 05:38:55.435817 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #123 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91766226
Z variance train             0.009444478
KL Divergence                19.044281
KL Loss                      1.9044281
QF Loss                      420.94165
VF Loss                      47.634186
Policy Loss                  -587.4625
Q Predictions Mean           585.8115
Q Predictions Std            134.48749
Q Predictions Max            730.6852
Q Predictions Min            -47.56726
V Predictions Mean           588.3467
V Predictions Std            133.55463
V Predictions Max            735.30865
V Predictions Min            -7.051205
Log Pis Mean                 -1.8133187
Log Pis Std                  2.3666909
Log Pis Max                  8.223674
Log Pis Min                  -7.570896
Policy mu Mean               0.043090887
Policy mu Std                0.46301743
Policy mu Max                1.4785199
Policy mu Min                -2.5397434
Policy log std Mean          -0.82477343
Policy log std Std           0.2517493
Policy log std Max           0.44145662
Policy log std Min           -2.0565896
Z mean eval                  0.929797
Z variance eval              0.010721324
total_rewards                [1167.42544852 1663.57846867 1825.06802294  528.7323575   547.90949909
  154.5389332   246.56725463  231.99729975 1658.18817304  502.09088171]
total_rewards_mean           852.6096339034409
total_rewards_std            625.4409120878734
total_rewards_max            1825.068022938739
total_rewards_min            154.53893319535067
Number of train steps total  125000
Number of env steps total    627000
Number of rollouts total     0
Train Time (s)               27.15427488507703
(Previous) Eval Time (s)     22.41965516936034
Sample Time (s)              18.406266757752746
Epoch Time (s)               67.98019681219012
Total Train Time (s)         8673.135308921803
Epoch                        124
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:40:04.700957 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #124 | Epoch Duration: 69.2649154663086
2020-01-11 05:40:04.701164 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #124 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9272634
Z variance train             0.010748374
KL Divergence                18.632656
KL Loss                      1.8632656
QF Loss                      524.6518
VF Loss                      128.64157
Policy Loss                  -588.96014
Q Predictions Mean           586.9171
Q Predictions Std            144.15097
Q Predictions Max            765.19586
Q Predictions Min            -0.586463
V Predictions Mean           591.74194
V Predictions Std            139.79918
V Predictions Max            765.42145
V Predictions Min            80.75149
Log Pis Mean                 -1.6057677
Log Pis Std                  2.2381794
Log Pis Max                  8.917685
Log Pis Min                  -7.148918
Policy mu Mean               0.037810963
Policy mu Std                0.50464386
Policy mu Max                1.933537
Policy mu Min                -1.6187979
Policy log std Mean          -0.8144204
Policy log std Std           0.2506722
Policy log std Max           -0.13655692
Policy log std Min           -2.3056564
Z mean eval                  0.9321602
Z variance eval              0.013728115
total_rewards                [1590.66100769  996.66346737  456.00902291 1321.15298761 1577.76263289
 1790.92371536 1709.5430289  1721.15415515 1637.69762176 1775.42474345]
total_rewards_mean           1457.6992383088827
total_rewards_std            405.4500528990742
total_rewards_max            1790.9237153619679
total_rewards_min            456.0090229131713
Number of train steps total  126000
Number of env steps total    632000
Number of rollouts total     0
Train Time (s)               30.70042227813974
(Previous) Eval Time (s)     23.70405373442918
Sample Time (s)              17.94996698619798
Epoch Time (s)               72.3544429987669
Total Train Time (s)         8749.205912117846
Epoch                        125
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:41:20.766312 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #125 | Epoch Duration: 76.06498742103577
2020-01-11 05:41:20.766502 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #125 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9323524
Z variance train             0.013734673
KL Divergence                18.289227
KL Loss                      1.8289226
QF Loss                      394.44232
VF Loss                      90.56522
Policy Loss                  -584.741
Q Predictions Mean           582.28723
Q Predictions Std            140.697
Q Predictions Max            747.2014
Q Predictions Min            -71.64131
V Predictions Mean           583.5115
V Predictions Std            137.73273
V Predictions Max            753.5011
V Predictions Min            1.9490318
Log Pis Mean                 -1.6476173
Log Pis Std                  2.0764523
Log Pis Max                  7.5368443
Log Pis Min                  -6.8133674
Policy mu Mean               0.102437325
Policy mu Std                0.45170245
Policy mu Max                1.9834675
Policy mu Min                -1.3687713
Policy log std Mean          -0.8581947
Policy log std Std           0.24064074
Policy log std Max           -0.22262546
Policy log std Min           -2.1563585
Z mean eval                  0.930313
Z variance eval              0.01272313
total_rewards                [  82.50057338   96.77479322 1840.26916577  722.89647664  107.27103405
  253.34399556 1501.16850723 1153.92368904  988.55339954  541.91909396]
total_rewards_mean           728.8620728397211
total_rewards_std            595.3648932890351
total_rewards_max            1840.269165772421
total_rewards_min            82.50057337846384
Number of train steps total  127000
Number of env steps total    637000
Number of rollouts total     0
Train Time (s)               28.369376676157117
(Previous) Eval Time (s)     27.414276191033423
Sample Time (s)              18.541628325823694
Epoch Time (s)               74.32528119301423
Total Train Time (s)         8820.435884302016
Epoch                        126
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:42:31.997586 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #126 | Epoch Duration: 71.23093676567078
2020-01-11 05:42:31.997762 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #126 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.928185
Z variance train             0.012692327
KL Divergence                18.358612
KL Loss                      1.8358612
QF Loss                      349.56665
VF Loss                      130.91824
Policy Loss                  -605.8388
Q Predictions Mean           601.458
Q Predictions Std            134.38809
Q Predictions Max            766.88306
Q Predictions Min            -70.76646
V Predictions Mean           602.4508
V Predictions Std            128.71379
V Predictions Max            763.0793
V Predictions Min            -0.47446483
Log Pis Mean                 -1.4604111
Log Pis Std                  2.130357
Log Pis Max                  4.6127567
Log Pis Min                  -8.203983
Policy mu Mean               0.050987177
Policy mu Std                0.47734678
Policy mu Max                1.5213798
Policy mu Min                -1.8028384
Policy log std Mean          -0.85378563
Policy log std Std           0.23925236
Policy log std Max           -0.2787561
Policy log std Min           -1.9103261
Z mean eval                  0.922623
Z variance eval              0.010802831
total_rewards                [ 527.44360748  108.27950348 1143.74344334 1852.29130737 1374.70929929
 1803.93831712 1710.03256058 1885.49891544 1059.20039863  515.05806739]
total_rewards_mean           1198.0195420120401
total_rewards_std            607.2126527167025
total_rewards_max            1885.4989154438736
total_rewards_min            108.27950348286257
Number of train steps total  128000
Number of env steps total    642000
Number of rollouts total     0
Train Time (s)               31.081621384248137
(Previous) Eval Time (s)     24.3195859240368
Sample Time (s)              17.734809149522334
Epoch Time (s)               73.13601645780727
Total Train Time (s)         8891.761330638546
Epoch                        127
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:43:43.326040 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #127 | Epoch Duration: 71.32812404632568
2020-01-11 05:43:43.326224 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #127 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92348033
Z variance train             0.010809407
KL Divergence                17.917023
KL Loss                      1.7917023
QF Loss                      445.812
VF Loss                      98.763245
Policy Loss                  -631.2636
Q Predictions Mean           627.2639
Q Predictions Std            100.20642
Q Predictions Max            752.69165
Q Predictions Min            254.93416
V Predictions Mean           625.6181
V Predictions Std            98.66254
V Predictions Max            740.41895
V Predictions Min            237.06084
Log Pis Mean                 -1.6096487
Log Pis Std                  2.1639252
Log Pis Max                  6.793354
Log Pis Min                  -8.449963
Policy mu Mean               0.0261508
Policy mu Std                0.4741408
Policy mu Max                1.517068
Policy mu Min                -1.6196196
Policy log std Mean          -0.8822725
Policy log std Std           0.23524833
Policy log std Max           -0.27767715
Policy log std Min           -2.448907
Z mean eval                  0.9320487
Z variance eval              0.018525943
total_rewards                [1888.78686047 1862.49799425   99.5790784  1840.61683674 1723.41681381
  320.19780703 1828.58934802  860.06960997  245.46247604 1456.91119725]
total_rewards_mean           1212.6128021973211
total_rewards_std            711.9617817073704
total_rewards_max            1888.7868604681046
total_rewards_min            99.57907839587618
Number of train steps total  129000
Number of env steps total    647000
Number of rollouts total     0
Train Time (s)               26.33798607904464
(Previous) Eval Time (s)     22.511397717054933
Sample Time (s)              17.984405836090446
Epoch Time (s)               66.83378963219002
Total Train Time (s)         8960.60968115693
Epoch                        128
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:44:52.175184 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #128 | Epoch Duration: 68.84881472587585
2020-01-11 05:44:52.175368 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #128 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9325325
Z variance train             0.018584544
KL Divergence                17.267946
KL Loss                      1.7267946
QF Loss                      1954.2333
VF Loss                      105.0964
Policy Loss                  -570.00354
Q Predictions Mean           567.0167
Q Predictions Std            131.49936
Q Predictions Max            735.45233
Q Predictions Min            31.443651
V Predictions Mean           572.9037
V Predictions Std            130.41536
V Predictions Max            742.8759
V Predictions Min            2.3555362
Log Pis Mean                 -1.4757204
Log Pis Std                  2.3463037
Log Pis Max                  7.2162485
Log Pis Min                  -8.57498
Policy mu Mean               -0.0019380865
Policy mu Std                0.50112206
Policy mu Max                1.3944246
Policy mu Min                -1.5521566
Policy log std Mean          -0.87187207
Policy log std Std           0.25397688
Policy log std Max           -0.18504876
Policy log std Min           -2.2483377
Z mean eval                  0.9495449
Z variance eval              0.017732408
total_rewards                [1001.80973102 1962.98049838 1889.45899009 1480.23188023  486.04088029
  923.41274415  182.37223109 1145.1614591  1930.59372811  587.05839683]
total_rewards_mean           1158.912053929565
total_rewards_std            607.6755974194995
total_rewards_max            1962.9804983758152
total_rewards_min            182.37223108684773
Number of train steps total  130000
Number of env steps total    652000
Number of rollouts total     0
Train Time (s)               29.33234988618642
(Previous) Eval Time (s)     24.526102629955858
Sample Time (s)              18.311002573929727
Epoch Time (s)               72.169455090072
Total Train Time (s)         9033.424598601181
Epoch                        129
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:46:04.992128 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #129 | Epoch Duration: 72.81661486625671
2020-01-11 05:46:04.992319 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #129 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9479321
Z variance train             0.01778176
KL Divergence                16.91266
KL Loss                      1.6912661
QF Loss                      311.5598
VF Loss                      54.80452
Policy Loss                  -614.46173
Q Predictions Mean           611.6501
Q Predictions Std            129.83775
Q Predictions Max            769.46954
Q Predictions Min            274.45676
V Predictions Mean           617.7069
V Predictions Std            130.48961
V Predictions Max            767.93384
V Predictions Min            281.38727
Log Pis Mean                 -1.7140651
Log Pis Std                  2.290611
Log Pis Max                  4.587346
Log Pis Min                  -10.829669
Policy mu Mean               0.03296018
Policy mu Std                0.5082161
Policy mu Max                1.5027554
Policy mu Min                -1.6868204
Policy log std Mean          -0.81218404
Policy log std Std           0.23653871
Policy log std Max           -0.13360924
Policy log std Min           -1.6743766
Z mean eval                  0.9438853
Z variance eval              0.01686069
total_rewards                [1569.10451065  296.03607957  234.70024589 1078.58533353 1723.06640993
  604.90967592   30.81194754  420.75549186  558.15020187   29.5783007 ]
total_rewards_mean           654.5698197458734
total_rewards_std            575.2221324387681
total_rewards_max            1723.0664099272144
total_rewards_min            29.57830069830018
Number of train steps total  131000
Number of env steps total    657000
Number of rollouts total     0
Train Time (s)               28.86149015603587
(Previous) Eval Time (s)     25.17295277863741
Sample Time (s)              18.455036654602736
Epoch Time (s)               72.48947958927602
Total Train Time (s)         9108.005001373123
Epoch                        130
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:47:19.576959 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #130 | Epoch Duration: 74.58446455001831
2020-01-11 05:47:19.577247 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #130 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93988484
Z variance train             0.016879803
KL Divergence                16.239616
KL Loss                      1.6239617
QF Loss                      391.141
VF Loss                      67.07724
Policy Loss                  -594.6142
Q Predictions Mean           592.228
Q Predictions Std            147.0053
Q Predictions Max            765.7836
Q Predictions Min            -14.760094
V Predictions Mean           590.80066
V Predictions Std            147.3336
V Predictions Max            759.9931
V Predictions Min            6.0946136
Log Pis Mean                 -1.4341555
Log Pis Std                  2.5201948
Log Pis Max                  8.7747555
Log Pis Min                  -8.553055
Policy mu Mean               -0.018358238
Policy mu Std                0.4934931
Policy mu Max                1.6619216
Policy mu Min                -1.8303086
Policy log std Mean          -0.85910815
Policy log std Std           0.26545608
Policy log std Max           -0.032764375
Policy log std Min           -2.1276364
Z mean eval                  0.9599248
Z variance eval              0.012054667
total_rewards                [ 595.2129721  1722.59343407 1538.37883313 1528.36518867 1595.24540497
 1593.15296746 1686.02571407  406.14310337 1600.38132877 1477.86556249]
total_rewards_mean           1374.3364509081055
total_rewards_std            444.07157411988675
total_rewards_max            1722.5934340696901
total_rewards_min            406.14310336967617
Number of train steps total  132000
Number of env steps total    662000
Number of rollouts total     0
Train Time (s)               29.614381862338632
(Previous) Eval Time (s)     27.267592686694115
Sample Time (s)              18.331947466358542
Epoch Time (s)               75.21392201539129
Total Train Time (s)         9183.55745117087
Epoch                        131
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:48:35.131982 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #131 | Epoch Duration: 75.55449891090393
2020-01-11 05:48:35.132244 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #131 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9599142
Z variance train             0.012048892
KL Divergence                16.523834
KL Loss                      1.6523834
QF Loss                      658.43695
VF Loss                      62.705807
Policy Loss                  -616.90784
Q Predictions Mean           613.37946
Q Predictions Std            140.44853
Q Predictions Max            779.4036
Q Predictions Min            -29.928007
V Predictions Mean           615.42426
V Predictions Std            137.59193
V Predictions Max            773.9059
V Predictions Min            35.00443
Log Pis Mean                 -1.4662322
Log Pis Std                  2.2660909
Log Pis Max                  10.8426695
Log Pis Min                  -7.181153
Policy mu Mean               0.021306185
Policy mu Std                0.5147457
Policy mu Max                1.7396464
Policy mu Min                -2.8540013
Policy log std Mean          -0.81264335
Policy log std Std           0.23238827
Policy log std Max           -0.14009604
Policy log std Min           -1.64065
Z mean eval                  0.9272725
Z variance eval              0.01558467
total_rewards                [1817.29347194 1890.00279539 1349.58138687  874.505863     62.18686765
  683.97063542 1100.0214828   219.42622055  580.97680619 1139.52447702]
total_rewards_mean           971.7490006846976
total_rewards_std            581.7012634699877
total_rewards_max            1890.0027953857896
total_rewards_min            62.186867650540606
Number of train steps total  133000
Number of env steps total    667000
Number of rollouts total     0
Train Time (s)               28.519165951292962
(Previous) Eval Time (s)     27.607852045912296
Sample Time (s)              18.332689722068608
Epoch Time (s)               74.45970771927387
Total Train Time (s)         9255.594023917336
Epoch                        132
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:49:47.170158 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #132 | Epoch Duration: 72.03773140907288
2020-01-11 05:49:47.170343 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #132 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9285264
Z variance train             0.015506836
KL Divergence                16.82597
KL Loss                      1.682597
QF Loss                      408.0681
VF Loss                      295.50977
Policy Loss                  -614.3654
Q Predictions Mean           609.24207
Q Predictions Std            143.69841
Q Predictions Max            787.2321
Q Predictions Min            14.35407
V Predictions Mean           613.85956
V Predictions Std            142.07922
V Predictions Max            785.93695
V Predictions Min            21.292439
Log Pis Mean                 -1.5237851
Log Pis Std                  2.471336
Log Pis Max                  9.4638
Log Pis Min                  -7.7910385
Policy mu Mean               0.048613288
Policy mu Std                0.50475997
Policy mu Max                1.6300956
Policy mu Min                -1.7266674
Policy log std Mean          -0.8362593
Policy log std Std           0.26224133
Policy log std Max           -0.093515694
Policy log std Min           -2.5465417
Z mean eval                  0.9459686
Z variance eval              0.010901848
total_rewards                [1723.49204541 1830.51225832 1877.71639268  248.63453708 1344.96811032
 1752.99621713 1840.98676548  103.69684484 1599.77341729 1174.70611874]
total_rewards_mean           1349.7482707270933
total_rewards_std            625.4409414870605
total_rewards_max            1877.7163926764815
total_rewards_min            103.69684483667237
Number of train steps total  134000
Number of env steps total    672000
Number of rollouts total     0
Train Time (s)               30.52769614942372
(Previous) Eval Time (s)     25.185590866021812
Sample Time (s)              17.82089738594368
Epoch Time (s)               73.53418440138921
Total Train Time (s)         9330.712644591462
Epoch                        133
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:51:02.289778 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #133 | Epoch Duration: 75.11929631233215
2020-01-11 05:51:02.289959 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #133 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.945666
Z variance train             0.010883558
KL Divergence                17.568356
KL Loss                      1.7568356
QF Loss                      464.03375
VF Loss                      76.57423
Policy Loss                  -622.8328
Q Predictions Mean           619.5637
Q Predictions Std            136.5143
Q Predictions Max            788.4484
Q Predictions Min            43.910103
V Predictions Mean           619.2096
V Predictions Std            132.18068
V Predictions Max            782.1267
V Predictions Min            125.69851
Log Pis Mean                 -1.729158
Log Pis Std                  2.437623
Log Pis Max                  4.9716425
Log Pis Min                  -7.732907
Policy mu Mean               0.074693926
Policy mu Std                0.48519778
Policy mu Max                2.1606472
Policy mu Min                -1.7605885
Policy log std Mean          -0.84857315
Policy log std Std           0.24001229
Policy log std Max           -0.22770134
Policy log std Min           -2.000152
Z mean eval                  0.91918737
Z variance eval              0.01051235
total_rewards                [  49.96979001 1901.54414577  121.22798402 1434.07471134  603.08084641
   -6.05247443 1523.15594145 1749.36582203  225.18282719 1543.67108951]
total_rewards_mean           914.5220683299891
total_rewards_std            741.8748657742692
total_rewards_max            1901.5441457681366
total_rewards_min            -6.0524744324720565
Number of train steps total  135000
Number of env steps total    677000
Number of rollouts total     0
Train Time (s)               29.08489962760359
(Previous) Eval Time (s)     26.770401720888913
Sample Time (s)              19.838583051692694
Epoch Time (s)               75.6938844001852
Total Train Time (s)         9403.823047568556
Epoch                        134
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:52:15.401771 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #134 | Epoch Duration: 73.11169075965881
2020-01-11 05:52:15.401984 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #134 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9186031
Z variance train             0.010492741
KL Divergence                17.625233
KL Loss                      1.7625233
QF Loss                      490.44766
VF Loss                      91.17157
Policy Loss                  -619.77344
Q Predictions Mean           615.4346
Q Predictions Std            132.11887
Q Predictions Max            770.6629
Q Predictions Min            -20.750174
V Predictions Mean           614.1891
V Predictions Std            129.86707
V Predictions Max            764.3712
V Predictions Min            -14.134573
Log Pis Mean                 -1.7180107
Log Pis Std                  2.1829348
Log Pis Max                  6.5231485
Log Pis Min                  -7.9608836
Policy mu Mean               0.016135775
Policy mu Std                0.5104664
Policy mu Max                2.3355143
Policy mu Min                -1.7539515
Policy log std Mean          -0.822973
Policy log std Std           0.23386031
Policy log std Max           -0.29776126
Policy log std Min           -2.3085666
Z mean eval                  0.901194
Z variance eval              0.007522373
total_rewards                [1038.72980211 1979.0409154  1032.04429372   92.84142411  384.89555777
 1333.64603133 1291.49162828  131.27315726  628.94943948  701.366222  ]
total_rewards_mean           861.427847144595
total_rewards_std            561.0837470699469
total_rewards_max            1979.0409154013712
total_rewards_min            92.84142411272106
Number of train steps total  136000
Number of env steps total    682000
Number of rollouts total     0
Train Time (s)               28.89182218303904
(Previous) Eval Time (s)     24.18790235929191
Sample Time (s)              19.067602030467242
Epoch Time (s)               72.14732657279819
Total Train Time (s)         9479.674215978011
Epoch                        135
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:53:31.256805 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #135 | Epoch Duration: 75.85463333129883
2020-01-11 05:53:31.257187 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #135 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9012583
Z variance train             0.0075200596
KL Divergence                18.028666
KL Loss                      1.8028666
QF Loss                      384.039
VF Loss                      57.551105
Policy Loss                  -624.37946
Q Predictions Mean           620.12085
Q Predictions Std            140.20262
Q Predictions Max            786.6228
Q Predictions Min            246.22581
V Predictions Mean           621.50305
V Predictions Std            140.60127
V Predictions Max            788.9514
V Predictions Min            242.99313
Log Pis Mean                 -1.4573505
Log Pis Std                  2.3482819
Log Pis Max                  7.485525
Log Pis Min                  -8.524056
Policy mu Mean               0.023633918
Policy mu Std                0.50201106
Policy mu Max                1.8015378
Policy mu Min                -1.4821355
Policy log std Mean          -0.82407403
Policy log std Std           0.24680708
Policy log std Max           -0.21921584
Policy log std Min           -2.468577
Z mean eval                  0.9241473
Z variance eval              0.009922966
total_rewards                [ 206.03174591 1761.60127488 1627.07957869 1060.47813961 1551.32663562
 1853.76440632 1224.85777095 1693.49258031  537.058625   1836.57025941]
total_rewards_mean           1335.2261016687014
total_rewards_std            544.2495120574645
total_rewards_max            1853.764406323
total_rewards_min            206.03174590540448
Number of train steps total  137000
Number of env steps total    687000
Number of rollouts total     0
Train Time (s)               27.966662431135774
(Previous) Eval Time (s)     27.8948365887627
Sample Time (s)              18.90930665563792
Epoch Time (s)               74.7708056755364
Total Train Time (s)         9550.144697886426
Epoch                        136
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:54:41.730750 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #136 | Epoch Duration: 70.47328639030457
2020-01-11 05:54:41.731033 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #136 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9236954
Z variance train             0.009910343
KL Divergence                17.750977
KL Loss                      1.7750977
QF Loss                      361.69293
VF Loss                      67.85152
Policy Loss                  -639.7775
Q Predictions Mean           636.9262
Q Predictions Std            133.47603
Q Predictions Max            807.1732
Q Predictions Min            273.8186
V Predictions Mean           645.13684
V Predictions Std            133.90244
V Predictions Max            815.0414
V Predictions Min            269.05127
Log Pis Mean                 -1.6239429
Log Pis Std                  2.245696
Log Pis Max                  6.7256155
Log Pis Min                  -11.315355
Policy mu Mean               0.06255646
Policy mu Std                0.5084589
Policy mu Max                1.8444197
Policy mu Min                -2.0426433
Policy log std Mean          -0.8459985
Policy log std Std           0.21757518
Policy log std Max           -0.29776555
Policy log std Min           -1.5406699
Z mean eval                  0.9082568
Z variance eval              0.0076393983
total_rewards                [1735.75599786 1920.49900858   23.41311187  667.82479898 1902.691088
 1780.76937748 1819.7071479  1973.90915452  864.01222109 1409.40583635]
total_rewards_mean           1409.7987742621187
total_rewards_std            632.7988589711126
total_rewards_max            1973.9091545215579
total_rewards_min            23.413111867850237
Number of train steps total  138000
Number of env steps total    692000
Number of rollouts total     0
Train Time (s)               28.981465303804725
(Previous) Eval Time (s)     23.597023084759712
Sample Time (s)              19.203291514422745
Epoch Time (s)               71.78177990298718
Total Train Time (s)         9625.52886929363
Epoch                        137
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:55:57.118370 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #137 | Epoch Duration: 75.38712310791016
2020-01-11 05:55:57.118584 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #137 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90853655
Z variance train             0.007637997
KL Divergence                18.423914
KL Loss                      1.8423914
QF Loss                      395.03027
VF Loss                      81.978195
Policy Loss                  -608.94727
Q Predictions Mean           605.93164
Q Predictions Std            157.13176
Q Predictions Max            861.59955
Q Predictions Min            -6.241667
V Predictions Mean           609.8098
V Predictions Std            152.3219
V Predictions Max            862.4472
V Predictions Min            254.71857
Log Pis Mean                 -1.3556722
Log Pis Std                  2.486811
Log Pis Max                  8.817165
Log Pis Min                  -8.340255
Policy mu Mean               0.11268709
Policy mu Std                0.5125263
Policy mu Max                2.0374002
Policy mu Min                -1.904864
Policy log std Mean          -0.8243618
Policy log std Std           0.245731
Policy log std Max           -0.24120533
Policy log std Min           -2.31642
Z mean eval                  0.9204157
Z variance eval              0.00854682
total_rewards                [1691.66469952   -1.94486599  543.98681289  669.69153061  308.99447898
  560.61908126 1276.63729202  853.3263151  1233.35643965 1040.20497197]
total_rewards_mean           817.653675602426
total_rewards_std            478.6962203007225
total_rewards_max            1691.6646995237254
total_rewards_min            -1.9448659871621459
Number of train steps total  139000
Number of env steps total    697000
Number of rollouts total     0
Train Time (s)               28.07877901615575
(Previous) Eval Time (s)     27.202037318143994
Sample Time (s)              18.29703260678798
Epoch Time (s)               73.57784894108772
Total Train Time (s)         9696.895501424558
Epoch                        138
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:57:08.489161 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #138 | Epoch Duration: 71.37038135528564
2020-01-11 05:57:08.489448 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #138 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92057484
Z variance train             0.00854736
KL Divergence                18.425297
KL Loss                      1.8425297
QF Loss                      350.51962
VF Loss                      132.88945
Policy Loss                  -638.0074
Q Predictions Mean           634.8308
Q Predictions Std            142.52472
Q Predictions Max            806.1523
Q Predictions Min            269.72568
V Predictions Mean           633.3617
V Predictions Std            139.86047
V Predictions Max            800.72266
V Predictions Min            269.2627
Log Pis Mean                 -1.3647679
Log Pis Std                  2.1125517
Log Pis Max                  7.1362724
Log Pis Min                  -6.77959
Policy mu Mean               0.05853194
Policy mu Std                0.49389848
Policy mu Max                1.6362002
Policy mu Min                -1.6674223
Policy log std Mean          -0.842612
Policy log std Std           0.24365227
Policy log std Max           -0.09224659
Policy log std Min           -2.1876867
Z mean eval                  0.9251506
Z variance eval              0.013192644
total_rewards                [ 660.20154884 1816.81904954  721.66616398  285.83458178 1010.0662638
 2012.50430449 2024.86118653  448.58114976  247.03855007  667.94545054]
total_rewards_mean           989.5518249318923
total_rewards_std            665.2779372225956
total_rewards_max            2024.861186526312
total_rewards_min            247.03855007064254
Number of train steps total  140000
Number of env steps total    702000
Number of rollouts total     0
Train Time (s)               27.822292170021683
(Previous) Eval Time (s)     24.994215907063335
Sample Time (s)              18.720075080171227
Epoch Time (s)               71.53658315725625
Total Train Time (s)         9760.151200733613
Epoch                        139
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:58:11.744908 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #139 | Epoch Duration: 63.255260944366455
2020-01-11 05:58:11.745059 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #139 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9247104
Z variance train             0.012985548
KL Divergence                17.088428
KL Loss                      1.7088429
QF Loss                      314.86826
VF Loss                      62.476032
Policy Loss                  -633.7744
Q Predictions Mean           629.71594
Q Predictions Std            150.2704
Q Predictions Max            801.55756
Q Predictions Min            256.61642
V Predictions Mean           637.933
V Predictions Std            151.18481
V Predictions Max            813.40137
V Predictions Min            272.35608
Log Pis Mean                 -1.8380275
Log Pis Std                  2.1348042
Log Pis Max                  3.9868977
Log Pis Min                  -8.357658
Policy mu Mean               0.028512698
Policy mu Std                0.48503232
Policy mu Max                1.6408877
Policy mu Min                -1.542851
Policy log std Mean          -0.80684394
Policy log std Std           0.22353147
Policy log std Max           -0.2341192
Policy log std Min           -1.62058
Z mean eval                  0.90486133
Z variance eval              0.018021524
total_rewards                [  24.59544164  495.62904107 1684.80815138 1807.75065892  421.11287332
 1377.4709615   567.12535489 1228.74215441 1931.09536355  229.18830167]
total_rewards_mean           976.7518302357861
total_rewards_std            670.8360446485635
total_rewards_max            1931.0953635535213
total_rewards_min            24.595441641105303
Number of train steps total  141000
Number of env steps total    707000
Number of rollouts total     0
Train Time (s)               30.410462585277855
(Previous) Eval Time (s)     16.71258370531723
Sample Time (s)              18.119282532017678
Epoch Time (s)               65.24232882261276
Total Train Time (s)         9830.267237536144
Epoch                        140
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:59:21.863419 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #140 | Epoch Duration: 70.11823987960815
2020-01-11 05:59:21.863580 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #140 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9051405
Z variance train             0.017994132
KL Divergence                16.755068
KL Loss                      1.6755068
QF Loss                      364.55322
VF Loss                      238.68216
Policy Loss                  -596.56854
Q Predictions Mean           593.87305
Q Predictions Std            154.05687
Q Predictions Max            798.2194
Q Predictions Min            160.28125
V Predictions Mean           604.773
V Predictions Std            157.05525
V Predictions Max            818.3068
V Predictions Min            140.7622
Log Pis Mean                 -1.7491469
Log Pis Std                  2.3560505
Log Pis Max                  5.0092735
Log Pis Min                  -9.979656
Policy mu Mean               0.05041992
Policy mu Std                0.46379966
Policy mu Max                1.4834678
Policy mu Min                -1.4813888
Policy log std Mean          -0.82741636
Policy log std Std           0.25784835
Policy log std Max           -0.22695494
Policy log std Min           -2.0793512
Z mean eval                  0.917424
Z variance eval              0.011448516
total_rewards                [1448.43901648  288.70085901 1044.69534995 1502.63568382 1503.70932206
 1944.91596972 1836.63878622 1947.7163177  1133.66295126 1714.51494878]
total_rewards_mean           1436.5629205002256
total_rewards_std            482.58987078717456
total_rewards_max            1947.7163176968131
total_rewards_min            288.7008590061935
Number of train steps total  142000
Number of env steps total    712000
Number of rollouts total     0
Train Time (s)               30.997672335710377
(Previous) Eval Time (s)     21.588199437130243
Sample Time (s)              17.80849422328174
Epoch Time (s)               70.39436599612236
Total Train Time (s)         9902.273371849675
Epoch                        141
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:00:33.870673 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #141 | Epoch Duration: 72.00692439079285
2020-01-11 06:00:33.870880 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #141 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.917425
Z variance train             0.011449711
KL Divergence                17.676369
KL Loss                      1.7676369
QF Loss                      473.34973
VF Loss                      323.5993
Policy Loss                  -626.0733
Q Predictions Mean           625.00684
Q Predictions Std            161.81921
Q Predictions Max            812.94086
Q Predictions Min            199.162
V Predictions Mean           632.95776
V Predictions Std            163.77701
V Predictions Max            824.781
V Predictions Min            169.13756
Log Pis Mean                 -1.5609127
Log Pis Std                  2.4143474
Log Pis Max                  8.155786
Log Pis Min                  -11.658497
Policy mu Mean               0.06290851
Policy mu Std                0.46876803
Policy mu Max                1.8997895
Policy mu Min                -1.5678461
Policy log std Mean          -0.8614733
Policy log std Std           0.2630684
Policy log std Max           -0.27542853
Policy log std Min           -2.3097134
Z mean eval                  0.908568
Z variance eval              0.013539565
total_rewards                [ 761.94945078 2057.58677184  124.01460794 1367.42071029  134.32021599
  723.58933298  453.47678151  524.15031745   45.78716213  161.67653496]
total_rewards_mean           635.397188586411
total_rewards_std            609.2936397610074
total_rewards_max            2057.5867718401373
total_rewards_min            45.787162125388406
Number of train steps total  143000
Number of env steps total    717000
Number of rollouts total     0
Train Time (s)               30.394436572212726
(Previous) Eval Time (s)     23.200424344278872
Sample Time (s)              17.665865031071007
Epoch Time (s)               71.2607259475626
Total Train Time (s)         9976.106280725915
Epoch                        142
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:01:47.708495 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #142 | Epoch Duration: 73.83742952346802
2020-01-11 06:01:47.708803 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #142 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9095706
Z variance train             0.013467049
KL Divergence                17.664955
KL Loss                      1.7664956
QF Loss                      408.8717
VF Loss                      124.08498
Policy Loss                  -650.91235
Q Predictions Mean           645.69196
Q Predictions Std            143.30312
Q Predictions Max            823.6267
Q Predictions Min            255.3677
V Predictions Mean           643.565
V Predictions Std            141.96007
V Predictions Max            810.9438
V Predictions Min            247.37363
Log Pis Mean                 -1.5302296
Log Pis Std                  2.314149
Log Pis Max                  5.4921875
Log Pis Min                  -7.5824695
Policy mu Mean               0.021701457
Policy mu Std                0.50995195
Policy mu Max                2.0500832
Policy mu Min                -1.8308868
Policy log std Mean          -0.8323365
Policy log std Std           0.22407083
Policy log std Max           -0.24733943
Policy log std Min           -1.7905512
Z mean eval                  0.89017373
Z variance eval              0.012604618
total_rewards                [1968.89059904 1993.41671501  587.63849443   32.90153989  520.37626785
 2054.33841165  486.67835838  592.7756872   457.8001292   612.25459548]
total_rewards_mean           930.7070798148554
total_rewards_std            720.9894919859797
total_rewards_max            2054.338411652913
total_rewards_min            32.90153989279237
Number of train steps total  144000
Number of env steps total    722000
Number of rollouts total     0
Train Time (s)               29.195325307082385
(Previous) Eval Time (s)     25.776809541042894
Sample Time (s)              17.787635514046997
Epoch Time (s)               72.75977036217228
Total Train Time (s)         10046.505752534606
Epoch                        143
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:02:58.111269 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #143 | Epoch Duration: 70.40221309661865
2020-01-11 06:02:58.111529 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #143 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8903147
Z variance train             0.012617876
KL Divergence                18.048744
KL Loss                      1.8048744
QF Loss                      366.0871
VF Loss                      77.30139
Policy Loss                  -643.3987
Q Predictions Mean           640.03125
Q Predictions Std            165.94196
Q Predictions Max            840.25867
Q Predictions Min            187.35776
V Predictions Mean           639.43884
V Predictions Std            165.1104
V Predictions Max            839.4346
V Predictions Min            182.12556
Log Pis Mean                 -1.6191585
Log Pis Std                  2.2381902
Log Pis Max                  6.2417235
Log Pis Min                  -8.650156
Policy mu Mean               -0.035209376
Policy mu Std                0.5044118
Policy mu Max                1.5565891
Policy mu Min                -1.9885725
Policy log std Mean          -0.8417373
Policy log std Std           0.25326136
Policy log std Max           -0.12587422
Policy log std Min           -1.8342724
Z mean eval                  0.8996881
Z variance eval              0.011662972
total_rewards                [ 591.45149753  345.67937023  951.62817071  857.26456438 2079.00825088
  532.4808096  1518.4072794   564.63668933 2074.41127575 1903.48196269]
total_rewards_mean           1141.8449870498791
total_rewards_std            650.2553471673391
total_rewards_max            2079.0082508825335
total_rewards_min            345.67937023390846
Number of train steps total  145000
Number of env steps total    727000
Number of rollouts total     0
Train Time (s)               28.220627430826426
(Previous) Eval Time (s)     23.41894706292078
Sample Time (s)              19.156648965086788
Epoch Time (s)               70.79622345883399
Total Train Time (s)         10114.577296478208
Epoch                        144
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:04:06.182528 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #144 | Epoch Duration: 68.07081747055054
2020-01-11 06:04:06.182706 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #144 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89797103
Z variance train             0.011631569
KL Divergence                18.377655
KL Loss                      1.8377656
QF Loss                      419.43402
VF Loss                      62.713215
Policy Loss                  -642.8635
Q Predictions Mean           640.34143
Q Predictions Std            150.05637
Q Predictions Max            818.9276
Q Predictions Min            261.22467
V Predictions Mean           644.25903
V Predictions Std            149.90411
V Predictions Max            820.58527
V Predictions Min            260.35464
Log Pis Mean                 -1.5542231
Log Pis Std                  2.2507882
Log Pis Max                  4.4429245
Log Pis Min                  -9.99245
Policy mu Mean               0.07058515
Policy mu Std                0.5210765
Policy mu Max                1.6544337
Policy mu Min                -2.3840227
Policy log std Mean          -0.8276099
Policy log std Std           0.25305334
Policy log std Max           -0.25579002
Policy log std Min           -1.7333331
Z mean eval                  0.9091851
Z variance eval              0.011651826
total_rewards                [ 106.77788512 1601.61189791  764.34090545  421.52936821 1788.03167952
  728.62032858 1908.47831193  353.48679286  510.19957029  679.6644748 ]
total_rewards_mean           886.2741214668519
total_rewards_std            608.3652424590794
total_rewards_max            1908.4783119254962
total_rewards_min            106.7778851217985
Number of train steps total  146000
Number of env steps total    732000
Number of rollouts total     0
Train Time (s)               26.81197093706578
(Previous) Eval Time (s)     20.693224384449422
Sample Time (s)              17.731096330098808
Epoch Time (s)               65.23629165161401
Total Train Time (s)         10182.041289628018
Epoch                        145
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:05:13.651264 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #145 | Epoch Duration: 67.46835803985596
2020-01-11 06:05:13.651582 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #145 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9084271
Z variance train             0.011655411
KL Divergence                19.069817
KL Loss                      1.9069817
QF Loss                      1230.5527
VF Loss                      218.75893
Policy Loss                  -622.1475
Q Predictions Mean           620.1351
Q Predictions Std            180.2072
Q Predictions Max            831.0746
Q Predictions Min            11.8205185
V Predictions Mean           622.7031
V Predictions Std            178.66995
V Predictions Max            827.1804
V Predictions Min            16.867277
Log Pis Mean                 -1.9277898
Log Pis Std                  2.2445226
Log Pis Max                  4.107145
Log Pis Min                  -8.620928
Policy mu Mean               0.040712908
Policy mu Std                0.48362207
Policy mu Max                1.9210367
Policy mu Min                -1.6639516
Policy log std Mean          -0.79881394
Policy log std Std           0.2562126
Policy log std Max           -0.19149134
Policy log std Min           -2.1063666
Z mean eval                  0.89827156
Z variance eval              0.013001548
total_rewards                [-1.33231948e+00  1.90658576e+03  4.53228518e+02  9.32341489e+02
  1.81228684e+03  2.88470283e+02  1.92052751e+03  1.67524576e+03
  1.92566741e+03  7.25867022e+02]
total_rewards_mean           1163.888828010688
total_rewards_std            725.3224552398417
total_rewards_max            1925.667413808008
total_rewards_min            -1.3323194802410472
Number of train steps total  147000
Number of env steps total    737000
Number of rollouts total     0
Train Time (s)               27.530126952100545
(Previous) Eval Time (s)     22.924964776728302
Sample Time (s)              17.944698134902865
Epoch Time (s)               68.39978986373171
Total Train Time (s)         10249.548463187646
Epoch                        146
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:06:21.174672 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #146 | Epoch Duration: 67.52282691001892
2020-01-11 06:06:21.174953 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #146 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89835215
Z variance train             0.013000285
KL Divergence                18.62936
KL Loss                      1.862936
QF Loss                      466.75122
VF Loss                      108.71352
Policy Loss                  -676.6872
Q Predictions Mean           674.88324
Q Predictions Std            145.16856
Q Predictions Max            837.8988
Q Predictions Min            3.6540985
V Predictions Mean           677.9096
V Predictions Std            145.30048
V Predictions Max            841.486
V Predictions Min            54.31743
Log Pis Mean                 -1.5749726
Log Pis Std                  2.1676018
Log Pis Max                  4.443273
Log Pis Min                  -9.006422
Policy mu Mean               0.092131004
Policy mu Std                0.5058444
Policy mu Max                1.9665378
Policy mu Min                -1.4605763
Policy log std Mean          -0.8425616
Policy log std Std           0.22823821
Policy log std Max           -0.25582
Policy log std Min           -1.8779831
Z mean eval                  0.880006
Z variance eval              0.012387248
total_rewards                [1779.53577771 1871.84593643  338.78805029 1989.29747092  402.53832391
 1957.48856785   17.05251797  713.57660601  816.03424067 -115.87843033]
total_rewards_mean           977.0279061424577
total_rewards_std            798.7128345015045
total_rewards_max            1989.2974709185803
total_rewards_min            -115.87843033262719
Number of train steps total  148000
Number of env steps total    742000
Number of rollouts total     0
Train Time (s)               29.859377013053745
(Previous) Eval Time (s)     22.047685915138572
Sample Time (s)              18.20669518550858
Epoch Time (s)               70.1137581137009
Total Train Time (s)         10319.748274452519
Epoch                        147
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:07:31.361143 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #147 | Epoch Duration: 70.1860032081604
2020-01-11 06:07:31.361326 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #147 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.879134
Z variance train             0.0123890955
KL Divergence                18.676178
KL Loss                      1.8676178
QF Loss                      379.21143
VF Loss                      275.96436
Policy Loss                  -652.8471
Q Predictions Mean           650.3395
Q Predictions Std            160.8327
Q Predictions Max            844.0251
Q Predictions Min            14.758818
V Predictions Mean           655.22546
V Predictions Std            161.24026
V Predictions Max            846.11096
V Predictions Min            9.25386
Log Pis Mean                 -1.555784
Log Pis Std                  2.509221
Log Pis Max                  12.944628
Log Pis Min                  -8.957582
Policy mu Mean               0.038894054
Policy mu Std                0.52852
Policy mu Max                1.9196326
Policy mu Min                -2.0956552
Policy log std Mean          -0.80721885
Policy log std Std           0.25073934
Policy log std Max           -0.24950168
Policy log std Min           -2.3141239
Z mean eval                  0.9124463
Z variance eval              0.015449459
total_rewards                [  53.82588795  980.70627416  883.0612138   154.92564634  365.75981048
 1705.50805931 1543.59213319 1947.44634563  874.37811575 1444.43186687]
total_rewards_mean           995.363535346742
total_rewards_std            626.8714254149498
total_rewards_max            1947.446345634622
total_rewards_min            53.82588795458246
Number of train steps total  149000
Number of env steps total    747000
Number of rollouts total     0
Train Time (s)               29.72472459077835
(Previous) Eval Time (s)     22.119629006832838
Sample Time (s)              18.433625378180295
Epoch Time (s)               70.27797897579148
Total Train Time (s)         10391.109975380357
Epoch                        148
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:08:42.724747 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #148 | Epoch Duration: 71.36326217651367
2020-01-11 06:08:42.724935 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #148 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90357286
Z variance train             0.015358025
KL Divergence                18.63355
KL Loss                      1.863355
QF Loss                      426.25763
VF Loss                      255.50893
Policy Loss                  -649.53156
Q Predictions Mean           648.90497
Q Predictions Std            135.12512
Q Predictions Max            822.77277
Q Predictions Min            223.03157
V Predictions Mean           662.6289
V Predictions Std            132.87671
V Predictions Max            829.4267
V Predictions Min            246.29543
Log Pis Mean                 -1.4258556
Log Pis Std                  2.0725584
Log Pis Max                  5.4326577
Log Pis Min                  -7.1637306
Policy mu Mean               0.086065024
Policy mu Std                0.5150606
Policy mu Max                1.8590984
Policy mu Min                -1.6856395
Policy log std Mean          -0.8258761
Policy log std Std           0.23422629
Policy log std Max           -0.23406172
Policy log std Min           -1.7017121
Z mean eval                  0.85630214
Z variance eval              0.011521732
total_rewards                [ 929.88185917  521.78217654 1969.97539039 1730.2948863   347.44828731
  607.519506    596.2633091  1774.11557935 1743.93182222  144.0548688 ]
total_rewards_mean           1036.526768519325
total_rewards_std            657.4685708461914
total_rewards_max            1969.975390394198
total_rewards_min            144.0548687973281
Number of train steps total  150000
Number of env steps total    752000
Number of rollouts total     0
Train Time (s)               26.853410922922194
(Previous) Eval Time (s)     23.204610178712755
Sample Time (s)              17.58566414192319
Epoch Time (s)               67.64368524355814
Total Train Time (s)         10454.678124137688
Epoch                        149
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:09:46.294116 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #149 | Epoch Duration: 63.56903696060181
2020-01-11 06:09:46.294335 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #149 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.85504675
Z variance train             0.011547072
KL Divergence                18.80973
KL Loss                      1.8809731
QF Loss                      1388.336
VF Loss                      181.08945
Policy Loss                  -637.11633
Q Predictions Mean           634.2253
Q Predictions Std            173.19899
Q Predictions Max            830.1429
Q Predictions Min            -13.317922
V Predictions Mean           645.04395
V Predictions Std            176.48724
V Predictions Max            847.74066
V Predictions Min            1.9697835
Log Pis Mean                 -1.6051924
Log Pis Std                  2.407291
Log Pis Max                  12.324188
Log Pis Min                  -9.368057
Policy mu Mean               0.00784995
Policy mu Std                0.48987573
Policy mu Max                3.2286918
Policy mu Min                -1.6747029
Policy log std Mean          -0.8331885
Policy log std Std           0.27647358
Policy log std Max           0.10874951
Policy log std Min           -2.617632
Z mean eval                  0.85994005
Z variance eval              0.023715867
total_rewards                [ 623.48470914 1734.36845019 1703.88166538  204.05588348  366.27581258
 1846.52375868 1530.09795422  351.39927188 1939.76895728 1817.55475914]
total_rewards_mean           1211.7411221979123
total_rewards_std            687.9790138252583
total_rewards_max            1939.7689572758545
total_rewards_min            204.05588348234082
Number of train steps total  151000
Number of env steps total    757000
Number of rollouts total     0
Train Time (s)               29.32195745781064
(Previous) Eval Time (s)     19.12965409224853
Sample Time (s)              17.806370487902313
Epoch Time (s)               66.25798203796148
Total Train Time (s)         10526.650386486668
Epoch                        150
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:10:58.293681 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #150 | Epoch Duration: 71.99916338920593
2020-01-11 06:10:58.294039 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #150 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.85647994
Z variance train             0.023713771
KL Divergence                17.747902
KL Loss                      1.7747902
QF Loss                      709.91754
VF Loss                      124.25536
Policy Loss                  -653.227
Q Predictions Mean           647.17285
Q Predictions Std            162.72675
Q Predictions Max            864.3616
Q Predictions Min            244.9196
V Predictions Mean           651.0779
V Predictions Std            161.62405
V Predictions Max            862.8964
V Predictions Min            242.18436
Log Pis Mean                 -1.4750034
Log Pis Std                  2.0765362
Log Pis Max                  7.4247293
Log Pis Min                  -7.229202
Policy mu Mean               0.047685772
Policy mu Std                0.5416347
Policy mu Max                2.0861592
Policy mu Min                -2.0827558
Policy log std Mean          -0.81985325
Policy log std Std           0.25548357
Policy log std Max           -0.22441661
Policy log std Min           -2.2744262
Z mean eval                  0.8640095
Z variance eval              0.017216139
total_rewards                [1857.83656392 2032.58782334  233.20690308 1146.31297328 1219.41741856
 1170.3962345  2056.75744645 1873.75925602  129.57978106 1916.1831151 ]
total_rewards_mean           1363.6037515308358
total_rewards_std            681.4555537978547
total_rewards_max            2056.7574464458403
total_rewards_min            129.5797810575071
Number of train steps total  152000
Number of env steps total    762000
Number of rollouts total     0
Train Time (s)               28.707666736096144
(Previous) Eval Time (s)     24.87046319618821
Sample Time (s)              17.617588182911277
Epoch Time (s)               71.19571811519563
Total Train Time (s)         10598.755681519397
Epoch                        151
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:12:10.377053 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #151 | Epoch Duration: 72.08277988433838
2020-01-11 06:12:10.377266 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #151 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.86073047
Z variance train             0.017210923
KL Divergence                18.478731
KL Loss                      1.8478731
QF Loss                      369.6625
VF Loss                      63.347923
Policy Loss                  -683.8194
Q Predictions Mean           680.3884
Q Predictions Std            152.70874
Q Predictions Max            833.2236
Q Predictions Min            249.95857
V Predictions Mean           685.5464
V Predictions Std            151.01556
V Predictions Max            836.1672
V Predictions Min            271.19467
Log Pis Mean                 -1.4237335
Log Pis Std                  2.3517842
Log Pis Max                  6.0113673
Log Pis Min                  -8.730392
Policy mu Mean               0.08503021
Policy mu Std                0.51419574
Policy mu Max                1.6406927
Policy mu Min                -1.5027243
Policy log std Mean          -0.84222937
Policy log std Std           0.24615228
Policy log std Max           -0.1696893
Policy log std Min           -1.7917128
Z mean eval                  0.83359766
Z variance eval              0.01284537
total_rewards                [-233.12312117 1748.79979532 1734.61229418 -203.3531843  1641.69858642
 1616.4203643  1652.8198267  1892.21193026  980.46890096 1824.17470788]
total_rewards_mean           1265.4730100552583
total_rewards_std            778.3226254311963
total_rewards_max            1892.2119302583815
total_rewards_min            -233.1231211700349
Number of train steps total  153000
Number of env steps total    767000
Number of rollouts total     0
Train Time (s)               29.444951817858964
(Previous) Eval Time (s)     25.7572530368343
Sample Time (s)              18.244487741030753
Epoch Time (s)               73.44669259572402
Total Train Time (s)         10673.145579653326
Epoch                        152
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:13:24.771247 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #152 | Epoch Duration: 74.3938422203064
2020-01-11 06:13:24.771448 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #152 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8358003
Z variance train             0.012814531
KL Divergence                19.161572
KL Loss                      1.9161571
QF Loss                      524.028
VF Loss                      167.21095
Policy Loss                  -667.7607
Q Predictions Mean           665.30676
Q Predictions Std            156.0321
Q Predictions Max            838.50085
Q Predictions Min            136.14018
V Predictions Mean           660.2969
V Predictions Std            154.16377
V Predictions Max            839.9037
V Predictions Min            242.2048
Log Pis Mean                 -1.3958502
Log Pis Std                  2.1240273
Log Pis Max                  9.002701
Log Pis Min                  -6.7675886
Policy mu Mean               0.08300631
Policy mu Std                0.49723852
Policy mu Max                2.1460521
Policy mu Min                -1.6199809
Policy log std Mean          -0.8609295
Policy log std Std           0.25580567
Policy log std Max           -0.26068568
Policy log std Min           -2.271402
Z mean eval                  0.88277894
Z variance eval              0.016129224
total_rewards                [ 546.35789106  706.9707542   992.66237776  208.54343479 1491.48531546
 1981.6405239  1598.15747284  781.13825202  691.99817411  954.12451663]
total_rewards_mean           995.3078712787217
total_rewards_std            512.4190591448593
total_rewards_max            1981.6405239029493
total_rewards_min            208.543434785733
Number of train steps total  154000
Number of env steps total    772000
Number of rollouts total     0
Train Time (s)               28.30528148636222
(Previous) Eval Time (s)     26.704110990744084
Sample Time (s)              18.485154449939728
Epoch Time (s)               73.49454692704603
Total Train Time (s)         10739.89920715196
Epoch                        153
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:14:31.528690 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #153 | Epoch Duration: 66.75704646110535
2020-01-11 06:14:31.529012 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #153 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8835473
Z variance train             0.016122717
KL Divergence                19.187675
KL Loss                      1.9187676
QF Loss                      776.55334
VF Loss                      213.54031
Policy Loss                  -651.98553
Q Predictions Mean           650.0544
Q Predictions Std            159.85634
Q Predictions Max            822.1803
Q Predictions Min            -25.30179
V Predictions Mean           656.0431
V Predictions Std            161.00763
V Predictions Max            833.8243
V Predictions Min            8.457481
Log Pis Mean                 -1.687397
Log Pis Std                  2.3711977
Log Pis Max                  7.687954
Log Pis Min                  -8.727292
Policy mu Mean               0.089260414
Policy mu Std                0.49155602
Policy mu Max                2.115038
Policy mu Min                -1.6012601
Policy log std Mean          -0.8330164
Policy log std Std           0.24957313
Policy log std Max           -0.17461342
Policy log std Min           -2.4209518
Z mean eval                  0.8392459
Z variance eval              0.02388299
total_rewards                [1827.43659151 2115.3991638   961.56829298  282.44688361  201.220357
  436.23092682 1882.49971879  604.79303935 1718.74368808   15.17625159]
total_rewards_mean           1004.5514913551136
total_rewards_std            763.0378761061654
total_rewards_max            2115.3991638044126
total_rewards_min            15.17625159494655
Number of train steps total  155000
Number of env steps total    777000
Number of rollouts total     0
Train Time (s)               29.112132034264505
(Previous) Eval Time (s)     19.96628424525261
Sample Time (s)              17.840877323411405
Epoch Time (s)               66.91929360292852
Total Train Time (s)         10807.424677927978
Epoch                        154
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:15:39.054581 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #154 | Epoch Duration: 67.52534508705139
2020-01-11 06:15:39.054777 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #154 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.83940065
Z variance train             0.023942556
KL Divergence                17.654251
KL Loss                      1.7654251
QF Loss                      404.1903
VF Loss                      139.67285
Policy Loss                  -674.8828
Q Predictions Mean           670.26624
Q Predictions Std            158.59286
Q Predictions Max            868.25653
Q Predictions Min            -27.719616
V Predictions Mean           669.99927
V Predictions Std            159.84239
V Predictions Max            861.7731
V Predictions Min            -2.7180939
Log Pis Mean                 -1.5462672
Log Pis Std                  2.5222745
Log Pis Max                  13.4037895
Log Pis Min                  -10.527397
Policy mu Mean               0.111161366
Policy mu Std                0.5013446
Policy mu Max                2.3691034
Policy mu Min                -1.873896
Policy log std Mean          -0.8345094
Policy log std Std           0.24211667
Policy log std Max           -0.14097744
Policy log std Min           -2.7480762
Z mean eval                  0.8500563
Z variance eval              0.015989978
total_rewards                [ 587.9549107  1320.87376877 1453.19544931 1317.65778249  906.3274405
 1388.66158957  124.11613689 1686.31781337  156.3621917   610.19383398]
total_rewards_mean           955.1660917281795
total_rewards_std            531.0973150669297
total_rewards_max            1686.3178133707336
total_rewards_min            124.11613689081646
Number of train steps total  156000
Number of env steps total    782000
Number of rollouts total     0
Train Time (s)               29.13166152499616
(Previous) Eval Time (s)     20.572052797768265
Sample Time (s)              18.410617765504867
Epoch Time (s)               68.1143320882693
Total Train Time (s)         10873.459612285718
Epoch                        155
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:16:45.091070 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #155 | Epoch Duration: 66.03616285324097
2020-01-11 06:16:45.091245 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #155 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.85039604
Z variance train             0.015976965
KL Divergence                18.406199
KL Loss                      1.8406199
QF Loss                      445.0116
VF Loss                      70.54905
Policy Loss                  -706.28516
Q Predictions Mean           704.35864
Q Predictions Std            144.6762
Q Predictions Max            862.34204
Q Predictions Min            204.42072
V Predictions Mean           705.51733
V Predictions Std            143.06686
V Predictions Max            861.85016
V Predictions Min            189.39597
Log Pis Mean                 -1.3102605
Log Pis Std                  2.1395104
Log Pis Max                  6.1136093
Log Pis Min                  -5.799201
Policy mu Mean               0.0819083
Policy mu Std                0.5230206
Policy mu Max                2.2022932
Policy mu Min                -1.4978125
Policy log std Mean          -0.8318039
Policy log std Std           0.22289382
Policy log std Max           -0.23646879
Policy log std Min           -1.7228558
Z mean eval                  0.8239563
Z variance eval              0.01223985
total_rewards                [1164.86788653   79.35925941  310.43788202  -32.85977666  340.27621296
 1080.69783318 1821.00807936   68.66315957  830.89032353  640.42438302]
total_rewards_mean           630.3765242924649
total_rewards_std            564.9711308803119
total_rewards_max            1821.0080793623679
total_rewards_min            -32.85977666274139
Number of train steps total  157000
Number of env steps total    787000
Number of rollouts total     0
Train Time (s)               27.92843603203073
(Previous) Eval Time (s)     18.493584422860295
Sample Time (s)              17.416934304405004
Epoch Time (s)               63.83895475929603
Total Train Time (s)         10938.21437683003
Epoch                        156
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:17:49.847326 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #156 | Epoch Duration: 64.75594353675842
2020-01-11 06:17:49.847519 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #156 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.81929505
Z variance train             0.012208215
KL Divergence                18.870152
KL Loss                      1.8870152
QF Loss                      1843.17
VF Loss                      225.20175
Policy Loss                  -678.17206
Q Predictions Mean           676.22314
Q Predictions Std            162.50578
Q Predictions Max            878.7579
Q Predictions Min            98.33727
V Predictions Mean           689.2041
V Predictions Std            165.29251
V Predictions Max            897.5724
V Predictions Min            77.32502
Log Pis Mean                 -1.4177811
Log Pis Std                  2.479952
Log Pis Max                  11.606152
Log Pis Min                  -8.3928995
Policy mu Mean               0.005645452
Policy mu Std                0.5322652
Policy mu Max                1.7613058
Policy mu Min                -1.6533433
Policy log std Mean          -0.8355279
Policy log std Std           0.2757006
Policy log std Max           -0.27688462
Policy log std Min           -2.9816594
Z mean eval                  0.82134944
Z variance eval              0.018221855
total_rewards                [ 366.96136426 1913.77541472 2031.45585385 1996.90954789 2019.56999251
  528.07695084 1742.0768972  2051.30527029 1986.62395896 1962.9645395 ]
total_rewards_mean           1659.971979001591
total_rewards_std            612.9197243258919
total_rewards_max            2051.305270289362
total_rewards_min            366.96136426320726
Number of train steps total  158000
Number of env steps total    792000
Number of rollouts total     0
Train Time (s)               27.886773185338825
(Previous) Eval Time (s)     19.410297045018524
Sample Time (s)              18.38802718091756
Epoch Time (s)               65.68509741127491
Total Train Time (s)         11011.31378668407
Epoch                        157
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:19:02.948323 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #157 | Epoch Duration: 73.1006727218628
2020-01-11 06:19:02.948544 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #157 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.82063067
Z variance train             0.018218134
KL Divergence                18.624554
KL Loss                      1.8624554
QF Loss                      302.99762
VF Loss                      125.69975
Policy Loss                  -679.37915
Q Predictions Mean           677.77966
Q Predictions Std            160.37462
Q Predictions Max            885.9108
Q Predictions Min            51.52686
V Predictions Mean           688.3916
V Predictions Std            162.4301
V Predictions Max            895.68915
V Predictions Min            12.905504
Log Pis Mean                 -1.3377583
Log Pis Std                  2.2561507
Log Pis Max                  4.98987
Log Pis Min                  -7.9197288
Policy mu Mean               0.013239624
Policy mu Std                0.53496367
Policy mu Max                1.8540194
Policy mu Min                -2.142886
Policy log std Mean          -0.82945037
Policy log std Std           0.23860341
Policy log std Max           0.0014126301
Policy log std Min           -1.8130844
Z mean eval                  0.859046
Z variance eval              0.015188031
total_rewards                [ 522.12453671 2017.49083459 2042.95701632 1953.49648948 1931.20499183
 1808.49064269 1124.14865884  983.99207259 1799.76216636 1774.98288851]
total_rewards_mean           1595.8650297911927
total_rewards_std            498.6685384622348
total_rewards_max            2042.9570163162387
total_rewards_min            522.1245367095037
Number of train steps total  159000
Number of env steps total    797000
Number of rollouts total     0
Train Time (s)               27.03338007396087
(Previous) Eval Time (s)     26.825535694137216
Sample Time (s)              17.658912940882146
Epoch Time (s)               71.51782870898023
Total Train Time (s)         11082.953349633142
Epoch                        158
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:20:14.589385 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #158 | Epoch Duration: 71.6407253742218
2020-01-11 06:20:14.589581 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #158 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8589137
Z variance train             0.015205884
KL Divergence                19.211285
KL Loss                      1.9211285
QF Loss                      670.8261
VF Loss                      201.34457
Policy Loss                  -667.2383
Q Predictions Mean           663.7522
Q Predictions Std            172.48964
Q Predictions Max            865.90564
Q Predictions Min            35.59107
V Predictions Mean           661.73926
V Predictions Std            167.18927
V Predictions Max            854.0969
V Predictions Min            -10.345655
Log Pis Mean                 -1.6343888
Log Pis Std                  2.666569
Log Pis Max                  10.662579
Log Pis Min                  -9.115431
Policy mu Mean               0.0043432796
Policy mu Std                0.5039334
Policy mu Max                1.5973685
Policy mu Min                -1.9595082
Policy log std Mean          -0.8711726
Policy log std Std           0.25066125
Policy log std Max           -0.22747415
Policy log std Min           -2.2192645
Z mean eval                  0.8372712
Z variance eval              0.01930528
total_rewards                [ 343.82068129  906.48481054 1643.33481385 1930.03758832  255.87709216
 1424.41124566 1080.97283427 1626.05379322 1008.89964939 1813.41765226]
total_rewards_mean           1203.331016095517
total_rewards_std            556.6688608457655
total_rewards_max            1930.0375883166207
total_rewards_min            255.87709216487784
Number of train steps total  160000
Number of env steps total    802000
Number of rollouts total     0
Train Time (s)               29.234118363820016
(Previous) Eval Time (s)     26.948137484956533
Sample Time (s)              18.345661351457238
Epoch Time (s)               74.52791720023379
Total Train Time (s)         11154.534230449703
Epoch                        159
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:21:26.175432 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #159 | Epoch Duration: 71.58568024635315
2020-01-11 06:21:26.175731 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #159 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8383981
Z variance train             0.019275973
KL Divergence                18.27675
KL Loss                      1.8276751
QF Loss                      507.7168
VF Loss                      55.441467
Policy Loss                  -693.8158
Q Predictions Mean           692.8254
Q Predictions Std            159.94984
Q Predictions Max            894.0006
Q Predictions Min            -20.397339
V Predictions Mean           694.00586
V Predictions Std            160.23997
V Predictions Max            896.4122
V Predictions Min            3.85586
Log Pis Mean                 -1.3495185
Log Pis Std                  2.2379127
Log Pis Max                  4.7451878
Log Pis Min                  -10.6568575
Policy mu Mean               0.106793776
Policy mu Std                0.5166639
Policy mu Max                1.7742065
Policy mu Min                -1.8012741
Policy log std Mean          -0.85483146
Policy log std Std           0.25441787
Policy log std Max           -0.19163638
Policy log std Min           -1.8324256
Z mean eval                  0.81971425
Z variance eval              0.016213765
total_rewards                [ 760.13971962 2110.10422067 2123.87195519  102.66048465 2249.00601045
 1551.16476154  444.8590491  1612.45784576 1836.16259859 2053.80233456]
total_rewards_mean           1484.4228980146559
total_rewards_std            732.6845992265396
total_rewards_max            2249.006010454035
total_rewards_min            102.66048465472345
Number of train steps total  161000
Number of env steps total    807000
Number of rollouts total     0
Train Time (s)               29.040245671290904
(Previous) Eval Time (s)     24.005552266724408
Sample Time (s)              18.28751004813239
Epoch Time (s)               71.3333079861477
Total Train Time (s)         11221.872854422312
Epoch                        160
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:22:33.517871 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #160 | Epoch Duration: 67.34189176559448
2020-01-11 06:22:33.518125 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #160 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.81859475
Z variance train             0.016160341
KL Divergence                18.338444
KL Loss                      1.8338444
QF Loss                      1436.306
VF Loss                      75.17243
Policy Loss                  -655.32416
Q Predictions Mean           651.75696
Q Predictions Std            186.61226
Q Predictions Max            855.7373
Q Predictions Min            142.566
V Predictions Mean           658.76
V Predictions Std            186.10435
V Predictions Max            864.2512
V Predictions Min            218.54579
Log Pis Mean                 -1.6641235
Log Pis Std                  2.39077
Log Pis Max                  7.6026297
Log Pis Min                  -9.53433
Policy mu Mean               0.07262607
Policy mu Std                0.49408624
Policy mu Max                1.8856342
Policy mu Min                -2.3359969
Policy log std Mean          -0.83355355
Policy log std Std           0.2591551
Policy log std Max           -0.17919415
Policy log std Min           -2.238822
Z mean eval                  0.85721254
Z variance eval              0.018971283
total_rewards                [2035.14872987  875.48997486  555.30740494  881.19463226  282.85953535
  615.90903404 1870.83475449 2251.46905335  582.56907012  651.65760566]
total_rewards_mean           1060.2439794945117
total_rewards_std            674.1323141910816
total_rewards_max            2251.469053353365
total_rewards_min            282.85953535125316
Number of train steps total  162000
Number of env steps total    812000
Number of rollouts total     0
Train Time (s)               29.600194244179875
(Previous) Eval Time (s)     20.013828482013196
Sample Time (s)              17.674477976746857
Epoch Time (s)               67.28850070293993
Total Train Time (s)         11286.944368782453
Epoch                        161
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:23:38.591572 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #161 | Epoch Duration: 65.07324743270874
2020-01-11 06:23:38.591780 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #161 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8589817
Z variance train             0.018972555
KL Divergence                16.738398
KL Loss                      1.6738398
QF Loss                      359.05762
VF Loss                      84.37394
Policy Loss                  -686.3024
Q Predictions Mean           681.5365
Q Predictions Std            175.04514
Q Predictions Max            883.4891
Q Predictions Min            245.21808
V Predictions Mean           688.334
V Predictions Std            173.04872
V Predictions Max            894.43024
V Predictions Min            255.1423
Log Pis Mean                 -1.5097852
Log Pis Std                  2.3671343
Log Pis Max                  8.928699
Log Pis Min                  -12.937976
Policy mu Mean               0.08868053
Policy mu Std                0.5127865
Policy mu Max                2.0093558
Policy mu Min                -1.6403543
Policy log std Mean          -0.8332268
Policy log std Std           0.2507778
Policy log std Max           -0.22605261
Policy log std Min           -2.060954
Z mean eval                  0.85218287
Z variance eval              0.027251292
total_rewards                [ 585.84817935 1306.78241052   91.44106495  325.41634325  936.29309634
 1823.65489956  100.16225018  258.99003511 1845.35963445 1161.7243738 ]
total_rewards_mean           843.5672287494265
total_rewards_std            639.0246395086347
total_rewards_max            1845.359634448304
total_rewards_min            91.44106495205617
Number of train steps total  163000
Number of env steps total    817000
Number of rollouts total     0
Train Time (s)               28.412486587185413
(Previous) Eval Time (s)     17.798308444209397
Sample Time (s)              17.93325679237023
Epoch Time (s)               64.14405182376504
Total Train Time (s)         11353.447631548624
Epoch                        162
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:24:45.095026 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #162 | Epoch Duration: 66.50306868553162
2020-01-11 06:24:45.095197 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #162 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8504039
Z variance train             0.027313258
KL Divergence                16.637985
KL Loss                      1.6637986
QF Loss                      418.01624
VF Loss                      124.23507
Policy Loss                  -685.4981
Q Predictions Mean           683.4579
Q Predictions Std            169.43224
Q Predictions Max            874.25165
Q Predictions Min            212.3936
V Predictions Mean           685.5866
V Predictions Std            167.85205
V Predictions Max            867.69946
V Predictions Min            203.65747
Log Pis Mean                 -1.3207201
Log Pis Std                  2.3097928
Log Pis Max                  6.185344
Log Pis Min                  -7.9579554
Policy mu Mean               0.062515885
Policy mu Std                0.55408514
Policy mu Max                1.8206956
Policy mu Min                -1.5519388
Policy log std Mean          -0.830903
Policy log std Std           0.24614589
Policy log std Max           -0.1944567
Policy log std Min           -2.0572631
Z mean eval                  0.8568629
Z variance eval              0.029809928
total_rewards                [ 142.67514326 1808.72447904 1852.48042485  310.29570105  222.70174002
   46.88924047   80.4851718   172.2236538   649.10816451  154.43906513]
total_rewards_mean           544.0022783937324
total_rewards_std            662.8385282191495
total_rewards_max            1852.4804248502946
total_rewards_min            46.88924047391596
Number of train steps total  164000
Number of env steps total    822000
Number of rollouts total     0
Train Time (s)               27.881848933175206
(Previous) Eval Time (s)     20.157012501731515
Sample Time (s)              18.879665868822485
Epoch Time (s)               66.9185273037292
Total Train Time (s)         11420.810725977179
Epoch                        163
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:25:52.462223 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #163 | Epoch Duration: 67.36682963371277
2020-01-11 06:25:52.462527 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #163 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8581769
Z variance train             0.029800754
KL Divergence                17.315815
KL Loss                      1.7315816
QF Loss                      652.584
VF Loss                      157.25107
Policy Loss                  -721.72845
Q Predictions Mean           720.10077
Q Predictions Std            155.57018
Q Predictions Max            907.26385
Q Predictions Min            261.29297
V Predictions Mean           724.0337
V Predictions Std            154.35606
V Predictions Max            897.2245
V Predictions Min            271.29312
Log Pis Mean                 -1.2240045
Log Pis Std                  2.21259
Log Pis Max                  6.932263
Log Pis Min                  -8.127363
Policy mu Mean               0.049534492
Policy mu Std                0.53461844
Policy mu Max                2.0804791
Policy mu Min                -1.8455963
Policy log std Mean          -0.82787937
Policy log std Std           0.25278488
Policy log std Max           -0.19142976
Policy log std Min           -1.9381236
Z mean eval                  0.8382813
Z variance eval              0.027647907
total_rewards                [1852.04776444 2091.81513941 1901.41943292  182.28244726 2039.11227947
  923.10064689 1612.0814742  2205.25314896 2081.34998883 1647.62102268]
total_rewards_mean           1653.6083345042975
total_rewards_std            602.403821670194
total_rewards_max            2205.253148956153
total_rewards_min            182.28244725571454
Number of train steps total  165000
Number of env steps total    827000
Number of rollouts total     0
Train Time (s)               29.706959596835077
(Previous) Eval Time (s)     20.604984725359827
Sample Time (s)              19.19059603707865
Epoch Time (s)               69.50254035927355
Total Train Time (s)         11494.411059441045
Epoch                        164
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:27:06.066720 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #164 | Epoch Duration: 73.603919506073
2020-01-11 06:27:06.067051 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #164 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.839214
Z variance train             0.027578663
KL Divergence                16.90505
KL Loss                      1.690505
QF Loss                      746.7398
VF Loss                      87.03931
Policy Loss                  -680.4221
Q Predictions Mean           675.121
Q Predictions Std            178.70526
Q Predictions Max            876.3501
Q Predictions Min            10.266909
V Predictions Mean           678.54865
V Predictions Std            177.75647
V Predictions Max            881.5423
V Predictions Min            -4.708802
Log Pis Mean                 -1.2749817
Log Pis Std                  2.6396494
Log Pis Max                  9.768925
Log Pis Min                  -7.236408
Policy mu Mean               0.01721117
Policy mu Std                0.51277006
Policy mu Max                1.6643797
Policy mu Min                -2.1986485
Policy log std Mean          -0.86633
Policy log std Std           0.28708795
Policy log std Max           0.3494112
Policy log std Min           -2.525789
Z mean eval                  0.892186
Z variance eval              0.026422957
total_rewards                [ -24.57983964  128.61130523   12.78801489  738.24718417 1632.7330469
 1635.82456805  195.97484927 1733.84005181  252.89606792  371.54847907]
total_rewards_mean           667.788372767837
total_rewards_std            684.9274229236449
total_rewards_max            1733.840051809805
total_rewards_min            -24.57983963725237
Number of train steps total  166000
Number of env steps total    832000
Number of rollouts total     0
Train Time (s)               30.84274872392416
(Previous) Eval Time (s)     24.706053988076746
Sample Time (s)              18.808499751146883
Epoch Time (s)               74.35730246314779
Total Train Time (s)         11565.020014057867
Epoch                        165
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:28:16.679707 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #165 | Epoch Duration: 70.61229825019836
2020-01-11 06:28:16.680113 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #165 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89628905
Z variance train             0.026472379
KL Divergence                16.658329
KL Loss                      1.6658329
QF Loss                      596.56226
VF Loss                      109.80812
Policy Loss                  -697.94305
Q Predictions Mean           692.01184
Q Predictions Std            180.13072
Q Predictions Max            876.5499
Q Predictions Min            26.875193
V Predictions Mean           691.3163
V Predictions Std            179.96864
V Predictions Max            882.24066
V Predictions Min            15.583972
Log Pis Mean                 -1.499231
Log Pis Std                  2.427178
Log Pis Max                  6.425311
Log Pis Min                  -11.05109
Policy mu Mean               -0.019551676
Policy mu Std                0.5507241
Policy mu Max                1.8044037
Policy mu Min                -1.8308594
Policy log std Mean          -0.8236116
Policy log std Std           0.23662171
Policy log std Max           -0.2843007
Policy log std Min           -1.7155436
Z mean eval                  0.84702367
Z variance eval              0.026544679
total_rewards                [1077.40314247  100.88654648  775.6848584   670.68585783 1053.50974314
   18.1571009   841.04183378  869.4235102   261.89983614  234.41504435]
total_rewards_mean           590.3107473683992
total_rewards_std            378.7898314581747
total_rewards_max            1077.403142465769
total_rewards_min            18.15710089620944
Number of train steps total  167000
Number of env steps total    837000
Number of rollouts total     0
Train Time (s)               28.51159847807139
(Previous) Eval Time (s)     20.96070344839245
Sample Time (s)              18.449741607066244
Epoch Time (s)               67.92204353353009
Total Train Time (s)         11633.16342164483
Epoch                        166
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:29:24.823693 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #166 | Epoch Duration: 68.14334225654602
2020-01-11 06:29:24.823937 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #166 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.84481496
Z variance train             0.026529152
KL Divergence                16.891838
KL Loss                      1.6891838
QF Loss                      518.12695
VF Loss                      81.167534
Policy Loss                  -708.0543
Q Predictions Mean           703.9048
Q Predictions Std            160.00446
Q Predictions Max            884.7737
Q Predictions Min            235.79633
V Predictions Mean           704.31036
V Predictions Std            157.06717
V Predictions Max            876.1826
V Predictions Min            252.71864
Log Pis Mean                 -1.4891322
Log Pis Std                  2.3003564
Log Pis Max                  6.4874797
Log Pis Min                  -7.446602
Policy mu Mean               0.072967455
Policy mu Std                0.50085604
Policy mu Max                1.9078966
Policy mu Min                -1.5741192
Policy log std Mean          -0.83470976
Policy log std Std           0.23365209
Policy log std Max           -0.20122176
Policy log std Min           -1.8578936
Z mean eval                  0.870463
Z variance eval              0.030650835
total_rewards                [  84.03175381 1736.69693773 1871.12017407  345.86100482  469.62324468
  213.83742735  324.27006806 1859.97658563  459.28056768  706.02875626]
total_rewards_mean           807.0726520087037
total_rewards_std            683.4162078372583
total_rewards_max            1871.120174065453
total_rewards_min            84.0317538099378
Number of train steps total  168000
Number of env steps total    842000
Number of rollouts total     0
Train Time (s)               27.983199211768806
(Previous) Eval Time (s)     21.18171532638371
Sample Time (s)              18.14640617929399
Epoch Time (s)               67.3113207174465
Total Train Time (s)         11701.012787937652
Epoch                        167
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:30:32.678985 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #167 | Epoch Duration: 67.85484385490417
2020-01-11 06:30:32.679284 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #167 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8691641
Z variance train             0.030689854
KL Divergence                16.488808
KL Loss                      1.6488808
QF Loss                      350.76242
VF Loss                      112.307724
Policy Loss                  -682.3855
Q Predictions Mean           680.4442
Q Predictions Std            189.66057
Q Predictions Max            918.0946
Q Predictions Min            232.34802
V Predictions Mean           686.78
V Predictions Std            186.346
V Predictions Max            910.0638
V Predictions Min            207.90962
Log Pis Mean                 -1.2944736
Log Pis Std                  2.3472505
Log Pis Max                  8.338856
Log Pis Min                  -7.7377386
Policy mu Mean               0.11312613
Policy mu Std                0.5333121
Policy mu Max                1.7683764
Policy mu Min                -2.5891182
Policy log std Mean          -0.8158159
Policy log std Std           0.23595595
Policy log std Max           -0.26914334
Policy log std Min           -1.7107108
Z mean eval                  0.8395545
Z variance eval              0.03394622
total_rewards                [ 825.29173369 1939.1491775  2056.93881562 2070.85551949 2050.19006289
  112.28631772 1757.08400022 1417.97884857  770.12684288  238.64935378]
total_rewards_mean           1323.8550672364304
total_rewards_std            734.7698986599058
total_rewards_max            2070.855519489429
total_rewards_min            112.28631771780181
Number of train steps total  169000
Number of env steps total    847000
Number of rollouts total     0
Train Time (s)               30.89216466108337
(Previous) Eval Time (s)     21.72492211777717
Sample Time (s)              17.6157740582712
Epoch Time (s)               70.23286083713174
Total Train Time (s)         11772.715725000016
Epoch                        168
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:31:44.382711 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #168 | Epoch Duration: 71.70319199562073
2020-01-11 06:31:44.382935 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #168 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.840114
Z variance train             0.033917565
KL Divergence                16.13276
KL Loss                      1.6132759
QF Loss                      906.88
VF Loss                      565.3959
Policy Loss                  -705.5114
Q Predictions Mean           699.3705
Q Predictions Std            181.24774
Q Predictions Max            929.7482
Q Predictions Min            -4.4322705
V Predictions Mean           708.90857
V Predictions Std            175.4598
V Predictions Max            928.9248
V Predictions Min            245.98099
Log Pis Mean                 -1.2583615
Log Pis Std                  2.6365347
Log Pis Max                  13.351006
Log Pis Min                  -9.634598
Policy mu Mean               0.0241085
Policy mu Std                0.5295954
Policy mu Max                1.7060848
Policy mu Min                -2.265985
Policy log std Mean          -0.8614832
Policy log std Std           0.2743311
Policy log std Max           -0.21921939
Policy log std Min           -2.845683
Z mean eval                  0.85675776
Z variance eval              0.034800533
total_rewards                [2040.06058546  113.74814724    4.89136893  464.38804256 1821.85913285
 2012.85059414  158.70931897  793.32203818 1957.81357392 2021.31917001]
total_rewards_mean           1138.8961972268962
total_rewards_std            858.1184316915886
total_rewards_max            2040.0605854586183
total_rewards_min            4.891368933198978
Number of train steps total  170000
Number of env steps total    852000
Number of rollouts total     0
Train Time (s)               28.57452674722299
(Previous) Eval Time (s)     23.194986963178962
Sample Time (s)              17.769222935196012
Epoch Time (s)               69.53873664559796
Total Train Time (s)         11841.898914819118
Epoch                        169
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:32:53.571938 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #169 | Epoch Duration: 69.18865942955017
2020-01-11 06:32:53.572369 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #169 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.85928345
Z variance train             0.034847748
KL Divergence                16.64136
KL Loss                      1.6641359
QF Loss                      348.17383
VF Loss                      149.27103
Policy Loss                  -727.5866
Q Predictions Mean           724.46405
Q Predictions Std            168.20879
Q Predictions Max            898.45245
Q Predictions Min            6.564848
V Predictions Mean           717.26074
V Predictions Std            167.27638
V Predictions Max            887.7491
V Predictions Min            3.7743044
Log Pis Mean                 -1.5036134
Log Pis Std                  2.2249968
Log Pis Max                  5.9708424
Log Pis Min                  -7.5427976
Policy mu Mean               0.011917435
Policy mu Std                0.50822943
Policy mu Max                1.7471153
Policy mu Min                -1.8906325
Policy log std Mean          -0.84347904
Policy log std Std           0.25301343
Policy log std Max           -0.27984264
Policy log std Min           -1.8337873
Z mean eval                  0.84158504
Z variance eval              0.02618215
total_rewards                [  -7.74200268   25.23024193  294.57849251  715.70336717  793.88924929
 2077.29385121 1288.55451498 1304.49705267 1009.23324179  523.70428773]
total_rewards_mean           802.4942296602969
total_rewards_std            613.1922631297936
total_rewards_max            2077.293851213811
total_rewards_min            -7.742002684540969
Number of train steps total  171000
Number of env steps total    857000
Number of rollouts total     0
Train Time (s)               30.06943271169439
(Previous) Eval Time (s)     22.844591620843858
Sample Time (s)              18.217409506905824
Epoch Time (s)               71.13143383944407
Total Train Time (s)         11907.439108082093
Epoch                        170
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:33:59.113258 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #170 | Epoch Duration: 65.54063630104065
2020-01-11 06:33:59.113500 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #170 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8407677
Z variance train             0.026149089
KL Divergence                17.07975
KL Loss                      1.707975
QF Loss                      936.65625
VF Loss                      802.1537
Policy Loss                  -711.9905
Q Predictions Mean           708.79175
Q Predictions Std            172.28856
Q Predictions Max            906.95856
Q Predictions Min            7.415257
V Predictions Mean           716.3684
V Predictions Std            165.439
V Predictions Max            906.4319
V Predictions Min            18.610523
Log Pis Mean                 -0.9547513
Log Pis Std                  2.564943
Log Pis Max                  9.866013
Log Pis Min                  -7.3819647
Policy mu Mean               0.07058053
Policy mu Std                0.55858856
Policy mu Max                1.8992869
Policy mu Min                -1.7835675
Policy log std Mean          -0.86715734
Policy log std Std           0.2642844
Policy log std Max           -0.3284905
Policy log std Min           -2.7509356
Z mean eval                  0.83967626
Z variance eval              0.029775133
total_rewards                [-119.79434458 2032.77403649   59.05693092 1631.11277824 2149.40279482
 2010.64738102 2187.83776496 2015.67558629 1259.24956783  856.67567613]
total_rewards_mean           1408.2638172112638
total_rewards_std            825.2446851965815
total_rewards_max            2187.83776496264
total_rewards_min            -119.79434458371934
Number of train steps total  172000
Number of env steps total    862000
Number of rollouts total     0
Train Time (s)               27.261728992685676
(Previous) Eval Time (s)     17.253469021990895
Sample Time (s)              17.72076769405976
Epoch Time (s)               62.23596570873633
Total Train Time (s)         11977.017407105304
Epoch                        171
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:35:08.692999 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #171 | Epoch Duration: 69.57932877540588
2020-01-11 06:35:08.693192 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #171 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8412026
Z variance train             0.02978054
KL Divergence                16.855568
KL Loss                      1.6855568
QF Loss                      479.73364
VF Loss                      86.770325
Policy Loss                  -694.1629
Q Predictions Mean           690.0977
Q Predictions Std            188.15797
Q Predictions Max            930.3285
Q Predictions Min            -0.67645985
V Predictions Mean           691.1305
V Predictions Std            185.35548
V Predictions Max            919.86676
V Predictions Min            68.09013
Log Pis Mean                 -1.457758
Log Pis Std                  2.377034
Log Pis Max                  8.070157
Log Pis Min                  -11.5057335
Policy mu Mean               0.063185245
Policy mu Std                0.51950675
Policy mu Max                2.3425202
Policy mu Min                -2.2377992
Policy log std Mean          -0.835044
Policy log std Std           0.25034952
Policy log std Max           0.00073844194
Policy log std Min           -1.7164302
Z mean eval                  0.8407365
Z variance eval              0.025280306
total_rewards                [-130.75253838 1899.32523884 1274.71905524 1869.01741466 2039.09649255
 1956.2257999  1940.15552883 1004.7848722   969.54075568   48.19422722]
total_rewards_mean           1287.030684674425
total_rewards_std            766.7495995682775
total_rewards_max            2039.0964925463657
total_rewards_min            -130.75253837970652
Number of train steps total  173000
Number of env steps total    867000
Number of rollouts total     0
Train Time (s)               26.65781770274043
(Previous) Eval Time (s)     24.59654729999602
Sample Time (s)              17.988059483934194
Epoch Time (s)               69.24242448667064
Total Train Time (s)         12046.31554286601
Epoch                        172
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:36:17.993855 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #172 | Epoch Duration: 69.3005256652832
2020-01-11 06:36:17.994083 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #172 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8411976
Z variance train             0.025193473
KL Divergence                17.80541
KL Loss                      1.7805411
QF Loss                      707.7095
VF Loss                      171.95027
Policy Loss                  -718.5083
Q Predictions Mean           715.6007
Q Predictions Std            166.4117
Q Predictions Max            911.3505
Q Predictions Min            231.57767
V Predictions Mean           721.2289
V Predictions Std            166.62042
V Predictions Max            908.9998
V Predictions Min            242.43852
Log Pis Mean                 -1.0402656
Log Pis Std                  2.2490914
Log Pis Max                  5.935773
Log Pis Min                  -7.7202973
Policy mu Mean               0.07919889
Policy mu Std                0.5325241
Policy mu Max                1.9077272
Policy mu Min                -1.6626987
Policy log std Mean          -0.86430943
Policy log std Std           0.25962403
Policy log std Max           -0.19115394
Policy log std Min           -2.1532793
Z mean eval                  0.8605944
Z variance eval              0.050263762
total_rewards                [1108.14728764  439.85065309 1985.09560761  550.16610989 1406.78691856
 2279.23308591  240.24499661 1024.86021637  514.65569579 2157.95961168]
total_rewards_mean           1170.7000183144278
total_rewards_std            718.542287247133
total_rewards_max            2279.233085912082
total_rewards_min            240.2449966053982
Number of train steps total  174000
Number of env steps total    872000
Number of rollouts total     0
Train Time (s)               28.575186701025814
(Previous) Eval Time (s)     24.654290392063558
Sample Time (s)              17.891711182892323
Epoch Time (s)               71.1211882759817
Total Train Time (s)         12115.34684197884
Epoch                        173
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:37:27.027477 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #173 | Epoch Duration: 69.03322052955627
2020-01-11 06:37:27.027679 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #173 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8610811
Z variance train             0.050257016
KL Divergence                17.181091
KL Loss                      1.7181091
QF Loss                      545.1564
VF Loss                      86.07829
Policy Loss                  -734.63446
Q Predictions Mean           733.2798
Q Predictions Std            204.54573
Q Predictions Max            955.97626
Q Predictions Min            -0.17340088
V Predictions Mean           739.78546
V Predictions Std            203.56535
V Predictions Max            953.6128
V Predictions Min            36.648212
Log Pis Mean                 -1.556454
Log Pis Std                  2.5158002
Log Pis Max                  8.9661045
Log Pis Min                  -10.198595
Policy mu Mean               0.049106747
Policy mu Std                0.5622167
Policy mu Max                1.7762742
Policy mu Min                -2.0176435
Policy log std Mean          -0.81311595
Policy log std Std           0.26167572
Policy log std Max           -0.15886694
Policy log std Min           -2.1550412
Z mean eval                  0.8566271
Z variance eval              0.04794312
total_rewards                [2185.52931298 1271.78234092  532.16847465 1793.23744674 1363.7803126
 2103.91029543 2232.56287672 2245.36489692  377.06015225  958.48884511]
total_rewards_mean           1506.3884954310831
total_rewards_std            676.3150560473216
total_rewards_max            2245.3648969175742
total_rewards_min            377.0601522461853
Number of train steps total  175000
Number of env steps total    877000
Number of rollouts total     0
Train Time (s)               28.419509518891573
(Previous) Eval Time (s)     22.56601796578616
Sample Time (s)              18.05018411995843
Epoch Time (s)               69.03571160463616
Total Train Time (s)         12183.718220593873
Epoch                        174
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:38:35.402409 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #174 | Epoch Duration: 68.37455677986145
2020-01-11 06:38:35.402636 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #174 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8568085
Z variance train             0.04788716
KL Divergence                17.35931
KL Loss                      1.735931
QF Loss                      652.12
VF Loss                      440.83813
Policy Loss                  -727.83624
Q Predictions Mean           724.21924
Q Predictions Std            171.79634
Q Predictions Max            925.35626
Q Predictions Min            28.965996
V Predictions Mean           723.21344
V Predictions Std            175.2356
V Predictions Max            926.7712
V Predictions Min            -7.995717
Log Pis Mean                 -0.8621923
Log Pis Std                  2.4835079
Log Pis Max                  13.417464
Log Pis Min                  -8.019941
Policy mu Mean               0.07686843
Policy mu Std                0.5464167
Policy mu Max                1.7751083
Policy mu Min                -2.0091054
Policy log std Mean          -0.8790087
Policy log std Std           0.29353985
Policy log std Max           -0.100274086
Policy log std Min           -2.8746662
Z mean eval                  0.8457901
Z variance eval              0.02643313
total_rewards                [1874.75804599  672.28584647 1963.75547135  809.12349459  593.71717439
  260.49134757 1225.67272089 1900.91122633 1026.73173149 1013.04729292]
total_rewards_mean           1134.049435199861
total_rewards_std            568.6437335423357
total_rewards_max            1963.755471349753
total_rewards_min            260.4913475712446
Number of train steps total  176000
Number of env steps total    882000
Number of rollouts total     0
Train Time (s)               29.48955184686929
(Previous) Eval Time (s)     21.90450272196904
Sample Time (s)              18.812772476579994
Epoch Time (s)               70.20682704541832
Total Train Time (s)         12254.052187489346
Epoch                        175
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:39:45.738697 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #175 | Epoch Duration: 70.33580875396729
2020-01-11 06:39:45.739003 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #175 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.84643924
Z variance train             0.026472684
KL Divergence                18.12807
KL Loss                      1.8128071
QF Loss                      371.21344
VF Loss                      105.77424
Policy Loss                  -732.6789
Q Predictions Mean           728.72327
Q Predictions Std            159.90356
Q Predictions Max            926.8915
Q Predictions Min            220.51965
V Predictions Mean           738.0039
V Predictions Std            160.37701
V Predictions Max            929.3978
V Predictions Min            222.03004
Log Pis Mean                 -1.2926075
Log Pis Std                  2.243682
Log Pis Max                  4.9958982
Log Pis Min                  -8.383234
Policy mu Mean               0.17146835
Policy mu Std                0.5460621
Policy mu Max                1.921153
Policy mu Min                -1.5716945
Policy log std Mean          -0.8062627
Policy log std Std           0.24410155
Policy log std Max           -0.2278493
Policy log std Min           -1.9379048
Z mean eval                  0.9204925
Z variance eval              0.02550289
total_rewards                [1898.16792314 1987.4370985  1899.6505527  1871.12681316 2035.79924365
 1008.15061324 1085.71927349 2039.47080867  914.58107199 2166.61493366]
total_rewards_mean           1690.671833219879
total_rewards_std            459.21406004928633
total_rewards_max            2166.614933660819
total_rewards_min            914.5810719875202
Number of train steps total  177000
Number of env steps total    887000
Number of rollouts total     0
Train Time (s)               29.20315606612712
(Previous) Eval Time (s)     22.033164065796882
Sample Time (s)              19.123558080289513
Epoch Time (s)               70.35987821221352
Total Train Time (s)         12327.862378204241
Epoch                        176
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:40:59.553177 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #176 | Epoch Duration: 73.81397151947021
2020-01-11 06:40:59.553458 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #176 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.919098
Z variance train             0.025507282
KL Divergence                18.126266
KL Loss                      1.8126267
QF Loss                      662.5781
VF Loss                      226.05968
Policy Loss                  -713.4545
Q Predictions Mean           708.75507
Q Predictions Std            185.58939
Q Predictions Max            913.1171
Q Predictions Min            -32.447357
V Predictions Mean           714.6035
V Predictions Std            178.45241
V Predictions Max            923.3242
V Predictions Min            -10.161637
Log Pis Mean                 -0.91810936
Log Pis Std                  2.5736651
Log Pis Max                  14.69406
Log Pis Min                  -8.370752
Policy mu Mean               0.06999507
Policy mu Std                0.5464093
Policy mu Max                2.4320307
Policy mu Min                -2.0773475
Policy log std Mean          -0.8695598
Policy log std Std           0.26716492
Policy log std Max           -0.30698383
Policy log std Min           -2.4641707
Z mean eval                  0.8552531
Z variance eval              0.025018254
total_rewards                [2329.18059166 1405.57573284 2378.3683995   604.98978841 2201.52289254
 2498.44096816 2136.8231797  2098.12471606 1095.02013729 1502.7649366 ]
total_rewards_mean           1825.0811342773109
total_rewards_std            602.3773974168325
total_rewards_max            2498.4409681629336
total_rewards_min            604.9897884101707
Number of train steps total  178000
Number of env steps total    892000
Number of rollouts total     0
Train Time (s)               27.331809140276164
(Previous) Eval Time (s)     25.48692612396553
Sample Time (s)              18.69181605707854
Epoch Time (s)               71.51055132132024
Total Train Time (s)         12399.40685383603
Epoch                        177
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:42:11.101578 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #177 | Epoch Duration: 71.54778933525085
2020-01-11 06:42:11.101966 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #177 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8556145
Z variance train             0.024952829
KL Divergence                17.962946
KL Loss                      1.7962946
QF Loss                      481.80185
VF Loss                      85.99346
Policy Loss                  -696.53815
Q Predictions Mean           691.49634
Q Predictions Std            191.83244
Q Predictions Max            901.43933
Q Predictions Min            -3.9948504
V Predictions Mean           701.3196
V Predictions Std            193.8325
V Predictions Max            913.71124
V Predictions Min            -3.1759353
Log Pis Mean                 -1.429558
Log Pis Std                  2.625893
Log Pis Max                  10.055319
Log Pis Min                  -9.64174
Policy mu Mean               0.07324208
Policy mu Std                0.57043743
Policy mu Max                2.3322566
Policy mu Min                -2.5309603
Policy log std Mean          -0.8037821
Policy log std Std           0.25952414
Policy log std Max           0.34999764
Policy log std Min           -2.614459
Z mean eval                  0.8708495
Z variance eval              0.030618599
total_rewards                [2069.21194855 2101.87828211 2010.78370359  314.20028187 2148.42183099
 1337.13594912 2202.06466508 2063.47002013 2077.17874152  998.14823338]
total_rewards_mean           1732.2493656329923
total_rewards_std            604.6686957879214
total_rewards_max            2202.064665077902
total_rewards_min            314.20028187228996
Number of train steps total  179000
Number of env steps total    897000
Number of rollouts total     0
Train Time (s)               27.34305260423571
(Previous) Eval Time (s)     25.523855725303292
Sample Time (s)              17.883623816538602
Epoch Time (s)               70.7505321460776
Total Train Time (s)         12470.33214721037
Epoch                        178
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:43:22.027585 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #178 | Epoch Duration: 70.92540144920349
2020-01-11 06:43:22.027787 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #178 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.868755
Z variance train             0.030600185
KL Divergence                17.900427
KL Loss                      1.7900428
QF Loss                      682.70874
VF Loss                      236.09634
Policy Loss                  -743.08704
Q Predictions Mean           737.5663
Q Predictions Std            176.9481
Q Predictions Max            972.55066
Q Predictions Min            244.26822
V Predictions Mean           743.1163
V Predictions Std            176.83263
V Predictions Max            974.67694
V Predictions Min            233.17052
Log Pis Mean                 -1.1787941
Log Pis Std                  2.4707072
Log Pis Max                  9.467156
Log Pis Min                  -9.718966
Policy mu Mean               0.0465495
Policy mu Std                0.5561664
Policy mu Max                2.1083717
Policy mu Min                -2.3338141
Policy log std Mean          -0.85436124
Policy log std Std           0.2587233
Policy log std Max           -0.21161407
Policy log std Min           -2.5709107
Z mean eval                  0.8676276
Z variance eval              0.02520902
total_rewards                [2142.47450581   60.97555794 2076.44226707 1328.66403883  438.57497257
  596.08346265  178.23996317  837.66648739 1594.99403586 1366.23176101]
total_rewards_mean           1062.034705230497
total_rewards_std            712.9804920849298
total_rewards_max            2142.4745058107865
total_rewards_min            60.97555793698825
Number of train steps total  180000
Number of env steps total    902000
Number of rollouts total     0
Train Time (s)               28.09499430283904
(Previous) Eval Time (s)     25.698440115898848
Sample Time (s)              18.378966903313994
Epoch Time (s)               72.17240132205188
Total Train Time (s)         12532.743869298603
Epoch                        179
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:44:24.440699 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #179 | Epoch Duration: 62.41274833679199
2020-01-11 06:44:24.440911 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #179 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8682227
Z variance train             0.025201404
KL Divergence                18.294306
KL Loss                      1.8294306
QF Loss                      825.3965
VF Loss                      122.49331
Policy Loss                  -736.4164
Q Predictions Mean           733.349
Q Predictions Std            177.53261
Q Predictions Max            926.8512
Q Predictions Min            243.92854
V Predictions Mean           730.9352
V Predictions Std            177.85379
V Predictions Max            924.5342
V Predictions Min            252.8749
Log Pis Mean                 -1.1313009
Log Pis Std                  2.5030136
Log Pis Max                  9.620572
Log Pis Min                  -7.7574105
Policy mu Mean               0.053234003
Policy mu Std                0.5128173
Policy mu Max                2.4192913
Policy mu Min                -1.8367319
Policy log std Mean          -0.8800797
Policy log std Std           0.27451918
Policy log std Max           -0.17440629
Policy log std Min           -2.0780408
Z mean eval                  0.8739525
Z variance eval              0.02013875
total_rewards                [1740.95647144 2316.10811653 2119.7278062  2238.90364986  626.83119461
  741.870367   1115.62567221 2238.8758663   268.93566494 1261.38441521]
total_rewards_mean           1466.921922429197
total_rewards_std            724.3282620176321
total_rewards_max            2316.1081165286582
total_rewards_min            268.935664939743
Number of train steps total  181000
Number of env steps total    907000
Number of rollouts total     0
Train Time (s)               28.56016511004418
(Previous) Eval Time (s)     15.938420477788895
Sample Time (s)              17.881663914304227
Epoch Time (s)               62.3802495021373
Total Train Time (s)         12602.556869996246
Epoch                        180
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:45:34.259433 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #180 | Epoch Duration: 69.81833338737488
2020-01-11 06:45:34.259702 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #180 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8741754
Z variance train             0.02016257
KL Divergence                19.160942
KL Loss                      1.9160942
QF Loss                      411.91693
VF Loss                      58.059483
Policy Loss                  -759.9483
Q Predictions Mean           757.73083
Q Predictions Std            171.66335
Q Predictions Max            966.8772
Q Predictions Min            240.449
V Predictions Mean           757.6356
V Predictions Std            170.49353
V Predictions Max            970.70514
V Predictions Min            248.57509
Log Pis Mean                 -1.2127361
Log Pis Std                  2.4416635
Log Pis Max                  5.9788218
Log Pis Min                  -8.283618
Policy mu Mean               0.03156731
Policy mu Std                0.5467192
Policy mu Max                1.8892338
Policy mu Min                -1.8510666
Policy log std Mean          -0.82565343
Policy log std Std           0.2384649
Policy log std Max           -0.23432305
Policy log std Min           -1.9782104
Z mean eval                  0.87306595
Z variance eval              0.02190827
total_rewards                [2188.74503894 2230.19269002 2115.3571283  2106.53630665 2183.84440608
  179.30388586 2232.24038882 2080.84639711 2271.31268019 1347.67333456]
total_rewards_mean           1893.6052256519263
total_rewards_std            625.1733862339848
total_rewards_max            2271.312680185492
total_rewards_min            179.30388585970067
Number of train steps total  182000
Number of env steps total    912000
Number of rollouts total     0
Train Time (s)               29.235582598950714
(Previous) Eval Time (s)     23.376185717061162
Sample Time (s)              17.38278878806159
Epoch Time (s)               69.99455710407346
Total Train Time (s)         12672.578340969048
Epoch                        181
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:46:44.283968 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #181 | Epoch Duration: 70.02400326728821
2020-01-11 06:46:44.284293 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #181 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8726398
Z variance train             0.021892166
KL Divergence                18.180283
KL Loss                      1.8180283
QF Loss                      465.25778
VF Loss                      76.83553
Policy Loss                  -762.1639
Q Predictions Mean           759.17316
Q Predictions Std            165.87518
Q Predictions Max            963.8808
Q Predictions Min            221.17044
V Predictions Mean           760.33655
V Predictions Std            164.19884
V Predictions Max            958.2248
V Predictions Min            227.80829
Log Pis Mean                 -1.2216116
Log Pis Std                  2.5828168
Log Pis Max                  6.160179
Log Pis Min                  -12.202311
Policy mu Mean               0.05528848
Policy mu Std                0.5525125
Policy mu Max                2.1214824
Policy mu Min                -1.8841625
Policy log std Mean          -0.85996276
Policy log std Std           0.22529174
Policy log std Max           -0.32111496
Policy log std Min           -1.7585512
Z mean eval                  0.8799903
Z variance eval              0.018881489
total_rewards                [1843.32896117 1977.52508967 1810.26342374  663.75607002 1849.83860432
 2020.99535434 2008.79007029 2099.54077611 1976.82414834 2010.23500122]
total_rewards_mean           1826.109749922943
total_rewards_std            397.22000333586453
total_rewards_max            2099.540776109031
total_rewards_min            663.7560700232461
Number of train steps total  183000
Number of env steps total    917000
Number of rollouts total     0
Train Time (s)               31.623645420651883
(Previous) Eval Time (s)     23.405321639031172
Sample Time (s)              19.240056965965778
Epoch Time (s)               74.26902402564883
Total Train Time (s)         12748.37468412472
Epoch                        182
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:48:00.083767 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #182 | Epoch Duration: 75.799143075943
2020-01-11 06:48:00.084137 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #182 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8793726
Z variance train             0.01886909
KL Divergence                18.458748
KL Loss                      1.8458748
QF Loss                      906.72876
VF Loss                      437.86304
Policy Loss                  -730.36926
Q Predictions Mean           726.8118
Q Predictions Std            192.54695
Q Predictions Max            929.32043
Q Predictions Min            38.868187
V Predictions Mean           734.83057
V Predictions Std            191.97173
V Predictions Max            919.7631
V Predictions Min            -6.9750156
Log Pis Mean                 -1.1821618
Log Pis Std                  2.4251003
Log Pis Max                  12.569532
Log Pis Min                  -6.593288
Policy mu Mean               0.055929463
Policy mu Std                0.5393329
Policy mu Max                1.9315346
Policy mu Min                -1.5320044
Policy log std Mean          -0.8428937
Policy log std Std           0.25400668
Policy log std Max           -0.24941438
Policy log std Min           -2.5510762
Z mean eval                  0.8743399
Z variance eval              0.017366495
total_rewards                [1594.58361656 1525.14282588 1390.65828932 1301.3159428   311.38976028
   97.99512525 2156.43095359   54.43820317   59.37601346  322.20109184]
total_rewards_mean           881.3531822154175
total_rewards_std            748.0200899494829
total_rewards_max            2156.430953594225
total_rewards_min            54.43820316924995
Number of train steps total  184000
Number of env steps total    922000
Number of rollouts total     0
Train Time (s)               29.084878670983016
(Previous) Eval Time (s)     24.935098596848547
Sample Time (s)              18.813554979860783
Epoch Time (s)               72.83353224769235
Total Train Time (s)         12813.502388271969
Epoch                        183
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:49:05.211749 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #183 | Epoch Duration: 65.12742185592651
2020-01-11 06:49:05.221432 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #183 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8737136
Z variance train             0.017404102
KL Divergence                18.447975
KL Loss                      1.8447975
QF Loss                      492.07953
VF Loss                      129.45131
Policy Loss                  -755.9767
Q Predictions Mean           751.91626
Q Predictions Std            173.53044
Q Predictions Max            929.8318
Q Predictions Min            -19.637028
V Predictions Mean           747.60583
V Predictions Std            169.18918
V Predictions Max            919.3156
V Predictions Min            -1.6032854
Log Pis Mean                 -1.2698572
Log Pis Std                  2.6983123
Log Pis Max                  8.03458
Log Pis Min                  -9.241719
Policy mu Mean               0.04592763
Policy mu Std                0.56265277
Policy mu Max                2.2447019
Policy mu Min                -2.120943
Policy log std Mean          -0.84001726
Policy log std Std           0.261182
Policy log std Max           -0.31261447
Policy log std Min           -2.1280737
Z mean eval                  0.90394175
Z variance eval              0.022685822
total_rewards                [2191.71915023 2200.73636151 2370.27578387 2217.17972223 1152.13299132
  906.56167094  957.73041537 2315.32599332 2407.75863454  909.72497761]
total_rewards_mean           1762.9145700954257
total_rewards_std            644.5491787284456
total_rewards_max            2407.7586345449386
total_rewards_min            906.5616709379423
Number of train steps total  185000
Number of env steps total    927000
Number of rollouts total     0
Train Time (s)               26.224016495049
(Previous) Eval Time (s)     17.228648360818624
Sample Time (s)              17.286542269401252
Epoch Time (s)               60.73920712526888
Total Train Time (s)         12880.015577212442
Epoch                        184
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:50:11.729346 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #184 | Epoch Duration: 66.5076699256897
2020-01-11 06:50:11.729610 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #184 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.902372
Z variance train             0.022583509
KL Divergence                19.122757
KL Loss                      1.9122757
QF Loss                      697.23755
VF Loss                      86.28881
Policy Loss                  -739.5411
Q Predictions Mean           736.4267
Q Predictions Std            189.18413
Q Predictions Max            942.12885
Q Predictions Min            43.218746
V Predictions Mean           741.395
V Predictions Std            185.36818
V Predictions Max            938.04083
V Predictions Min            204.72293
Log Pis Mean                 -1.2023066
Log Pis Std                  2.502295
Log Pis Max                  7.022338
Log Pis Min                  -7.1060915
Policy mu Mean               -0.028083827
Policy mu Std                0.565167
Policy mu Max                2.0255067
Policy mu Min                -2.3577187
Policy log std Mean          -0.8419125
Policy log std Std           0.25021097
Policy log std Max           -0.23205328
Policy log std Min           -2.1697662
Z mean eval                  0.89414656
Z variance eval              0.019970123
total_rewards                [ -10.93413727 1215.43233948 2233.73100218  371.02669357 2093.91891594
  859.77551684  910.71542488 2148.00703608  335.93869044 1620.60436092]
total_rewards_mean           1177.8215843047333
total_rewards_std            777.0607412878763
total_rewards_max            2233.731002183781
total_rewards_min            -10.934137265943635
Number of train steps total  186000
Number of env steps total    932000
Number of rollouts total     0
Train Time (s)               31.012923560105264
(Previous) Eval Time (s)     22.99685845617205
Sample Time (s)              18.93228387553245
Epoch Time (s)               72.94206589180976
Total Train Time (s)         12948.552953191102
Epoch                        185
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:51:20.267935 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #185 | Epoch Duration: 68.53817796707153
2020-01-11 06:51:20.268118 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #185 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8962326
Z variance train             0.020012388
KL Divergence                18.743097
KL Loss                      1.8743098
QF Loss                      285.50848
VF Loss                      163.62527
Policy Loss                  -750.8156
Q Predictions Mean           747.11475
Q Predictions Std            186.96844
Q Predictions Max            956.2516
Q Predictions Min            239.73314
V Predictions Mean           739.81995
V Predictions Std            184.81636
V Predictions Max            945.30505
V Predictions Min            244.19284
Log Pis Mean                 -1.210207
Log Pis Std                  2.5027776
Log Pis Max                  5.491795
Log Pis Min                  -9.11908
Policy mu Mean               0.02901471
Policy mu Std                0.53416604
Policy mu Max                1.9860158
Policy mu Min                -2.164637
Policy log std Mean          -0.8492007
Policy log std Std           0.24213395
Policy log std Max           -0.24086457
Policy log std Min           -1.9544163
Z mean eval                  0.8636014
Z variance eval              0.019201482
total_rewards                [1713.20687616 1902.99410399  105.95723974  157.66477887 1489.90185773
 1120.54437305 1771.77854086 1997.98024548  864.25197074 1864.13807761]
total_rewards_mean           1298.841806424154
total_rewards_std            674.6215855220277
total_rewards_max            1997.9802454796381
total_rewards_min            105.95723973972969
Number of train steps total  187000
Number of env steps total    937000
Number of rollouts total     0
Train Time (s)               28.97566079488024
(Previous) Eval Time (s)     18.592617864254862
Sample Time (s)              18.268889965955168
Epoch Time (s)               65.83716862509027
Total Train Time (s)         13016.183401833288
Epoch                        186
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:52:27.901115 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #186 | Epoch Duration: 67.63283824920654
2020-01-11 06:52:27.901319 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #186 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8647753
Z variance train             0.019235719
KL Divergence                18.521847
KL Loss                      1.8521847
QF Loss                      3249.751
VF Loss                      254.05707
Policy Loss                  -738.25775
Q Predictions Mean           736.5505
Q Predictions Std            198.88306
Q Predictions Max            973.5285
Q Predictions Min            1.8749263
V Predictions Mean           724.7416
V Predictions Std            197.72264
V Predictions Max            946.7163
V Predictions Min            0.91933554
Log Pis Mean                 -1.3147349
Log Pis Std                  2.5389647
Log Pis Max                  9.1434
Log Pis Min                  -6.4438047
Policy mu Mean               0.053190686
Policy mu Std                0.5426712
Policy mu Max                2.368954
Policy mu Min                -1.937347
Policy log std Mean          -0.83365476
Policy log std Std           0.27345642
Policy log std Max           -0.26366305
Policy log std Min           -2.2092574
Z mean eval                  0.8751733
Z variance eval              0.019587966
total_rewards                [1385.66425975 2059.56285801 2308.39448125  244.15675527 2108.14762408
 1770.61747447 2089.08138464  450.81543173 1974.44429459 2148.30328223]
total_rewards_mean           1653.9187846027046
total_rewards_std            696.8639927773589
total_rewards_max            2308.3944812502236
total_rewards_min            244.15675526680482
Number of train steps total  188000
Number of env steps total    942000
Number of rollouts total     0
Train Time (s)               32.11724514234811
(Previous) Eval Time (s)     20.387987199705094
Sample Time (s)              17.47785374522209
Epoch Time (s)               69.9830860872753
Total Train Time (s)         13088.752103735693
Epoch                        187
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:53:40.474780 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #187 | Epoch Duration: 72.57326745986938
2020-01-11 06:53:40.475088 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #187 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8775104
Z variance train             0.019617941
KL Divergence                19.007753
KL Loss                      1.9007753
QF Loss                      403.2577
VF Loss                      41.3908
Policy Loss                  -782.3217
Q Predictions Mean           782.86383
Q Predictions Std            165.3155
Q Predictions Max            964.0278
Q Predictions Min            19.003048
V Predictions Mean           783.05225
V Predictions Std            164.55417
V Predictions Max            951.9716
V Predictions Min            -5.1851244
Log Pis Mean                 -1.4493183
Log Pis Std                  2.5068314
Log Pis Max                  7.756547
Log Pis Min                  -10.317197
Policy mu Mean               0.050269663
Policy mu Std                0.5237905
Policy mu Max                3.1015553
Policy mu Min                -3.5315585
Policy log std Mean          -0.86250275
Policy log std Std           0.2350915
Policy log std Max           0.24803722
Policy log std Min           -1.8725421
Z mean eval                  0.8731159
Z variance eval              0.024157632
total_rewards                [  20.90108074   87.96816631   53.89642629  -64.31493235  585.16481846
 1125.38772275 2115.98686081   26.90402392  754.68003853 2128.77235249]
total_rewards_mean           683.5346557961481
total_rewards_std            808.162949794226
total_rewards_max            2128.772352487796
total_rewards_min            -64.31493234801457
Number of train steps total  189000
Number of env steps total    947000
Number of rollouts total     0
Train Time (s)               26.264216877985746
(Previous) Eval Time (s)     22.977845061570406
Sample Time (s)              18.86725711915642
Epoch Time (s)               68.10931905871257
Total Train Time (s)         13155.072982177138
Epoch                        188
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:54:46.796248 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #188 | Epoch Duration: 66.32093214988708
2020-01-11 06:54:46.796457 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #188 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.87364113
Z variance train             0.024209276
KL Divergence                18.877565
KL Loss                      1.8877566
QF Loss                      533.1825
VF Loss                      83.53441
Policy Loss                  -751.4411
Q Predictions Mean           749.03906
Q Predictions Std            198.52193
Q Predictions Max            952.40326
Q Predictions Min            18.196493
V Predictions Mean           749.43396
V Predictions Std            199.21477
V Predictions Max            955.26874
V Predictions Min            -10.198326
Log Pis Mean                 -1.3018508
Log Pis Std                  2.7328053
Log Pis Max                  13.272774
Log Pis Min                  -8.555173
Policy mu Mean               0.024094678
Policy mu Std                0.52759826
Policy mu Max                2.2832208
Policy mu Min                -2.2932255
Policy log std Mean          -0.8753852
Policy log std Std           0.27389798
Policy log std Max           0.5049715
Policy log std Min           -2.1921206
Z mean eval                  0.88190097
Z variance eval              0.024216924
total_rewards                [ -17.29082887  -53.50291856 2286.58190064 1271.61650908 2124.00090916
 2137.42238827  318.28405535 1938.03225469  866.84234911  739.04772564]
total_rewards_mean           1161.1034344507898
total_rewards_std            871.8859043312906
total_rewards_max            2286.5819006426427
total_rewards_min            -53.502918564965384
Number of train steps total  190000
Number of env steps total    952000
Number of rollouts total     0
Train Time (s)               29.00051109213382
(Previous) Eval Time (s)     21.189141983166337
Sample Time (s)              18.0175939979963
Epoch Time (s)               68.20724707329646
Total Train Time (s)         13223.319765531924
Epoch                        189
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:55:55.047951 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #189 | Epoch Duration: 68.25133395195007
2020-01-11 06:55:55.048211 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #189 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.87979734
Z variance train             0.024113659
KL Divergence                19.197378
KL Loss                      1.9197378
QF Loss                      1353.0837
VF Loss                      172.51352
Policy Loss                  -739.0921
Q Predictions Mean           734.66833
Q Predictions Std            204.25272
Q Predictions Max            949.8206
Q Predictions Min            210.83197
V Predictions Mean           732.07275
V Predictions Std            200.93326
V Predictions Max            929.8687
V Predictions Min            215.44904
Log Pis Mean                 -1.4036326
Log Pis Std                  2.5675552
Log Pis Max                  8.591467
Log Pis Min                  -8.693478
Policy mu Mean               0.08655454
Policy mu Std                0.5629345
Policy mu Max                1.9513339
Policy mu Min                -1.6992968
Policy log std Mean          -0.81590986
Policy log std Std           0.24232693
Policy log std Max           -0.21062109
Policy log std Min           -2.080449
Z mean eval                  0.8852352
Z variance eval              0.02279171
total_rewards                [1224.85399158  -90.43909451   49.28727995  287.12299295  789.94408461
  329.79890503 1627.130255    805.17127828  113.19223459  408.25760271]
total_rewards_mean           554.4319530201545
total_rewards_std            522.2534686412735
total_rewards_max            1627.1302550009182
total_rewards_min            -90.4390945119713
Number of train steps total  191000
Number of env steps total    957000
Number of rollouts total     0
Train Time (s)               26.825892340857536
(Previous) Eval Time (s)     21.232864140998572
Sample Time (s)              17.342768262140453
Epoch Time (s)               65.40152474399656
Total Train Time (s)         13288.13678842457
Epoch                        190
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:56:59.867033 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #190 | Epoch Duration: 64.81863927841187
2020-01-11 06:56:59.867283 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #190 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.88910085
Z variance train             0.022963423
KL Divergence                20.010227
KL Loss                      2.0010228
QF Loss                      532.71216
VF Loss                      581.77704
Policy Loss                  -766.92004
Q Predictions Mean           762.4806
Q Predictions Std            199.51477
Q Predictions Max            978.70276
Q Predictions Min            236.89261
V Predictions Mean           760.0293
V Predictions Std            199.62852
V Predictions Max            969.9219
V Predictions Min            244.38753
Log Pis Mean                 -1.3203142
Log Pis Std                  2.4146914
Log Pis Max                  6.9748588
Log Pis Min                  -8.40484
Policy mu Mean               0.063762575
Policy mu Std                0.53212416
Policy mu Max                1.9847884
Policy mu Min                -1.8779364
Policy log std Mean          -0.8381679
Policy log std Std           0.2640294
Policy log std Max           -0.14890596
Policy log std Min           -2.6090004
Z mean eval                  0.88088
Z variance eval              0.021960767
total_rewards                [ 391.77148418   75.69023205 1367.23868495  982.39873554 1841.24140633
  775.71138943 1667.80479728   28.11800085    7.74795832 2206.05412794]
total_rewards_mean           934.3776816889509
total_rewards_std            768.3776851281269
total_rewards_max            2206.054127936799
total_rewards_min            7.747958323033578
Number of train steps total  192000
Number of env steps total    962000
Number of rollouts total     0
Train Time (s)               30.01040680380538
(Previous) Eval Time (s)     20.649663225281984
Sample Time (s)              18.583789599128067
Epoch Time (s)               69.24385962821543
Total Train Time (s)         13356.54096602602
Epoch                        191
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:58:08.274079 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #191 | Epoch Duration: 68.40657711029053
2020-01-11 06:58:08.274313 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #191 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.88125527
Z variance train             0.02192007
KL Divergence                19.933834
KL Loss                      1.9933834
QF Loss                      944.901
VF Loss                      79.104355
Policy Loss                  -769.0296
Q Predictions Mean           766.2587
Q Predictions Std            171.3724
Q Predictions Max            944.64575
Q Predictions Min            225.16934
V Predictions Mean           764.8581
V Predictions Std            170.71083
V Predictions Max            942.0686
V Predictions Min            240.30284
Log Pis Mean                 -1.374546
Log Pis Std                  2.2841647
Log Pis Max                  6.2473736
Log Pis Min                  -7.7369633
Policy mu Mean               0.1125497
Policy mu Std                0.5264177
Policy mu Max                3.5909023
Policy mu Min                -1.954858
Policy log std Mean          -0.8274686
Policy log std Std           0.23638877
Policy log std Max           -0.20421499
Policy log std Min           -1.9192991
Z mean eval                  0.8925492
Z variance eval              0.020297581
total_rewards                [-143.35230564  541.42321655 2081.7666602   482.77291749 2332.21559443
 1035.67467646 1225.916201   1898.63172701  664.67614933 2014.1990676 ]
total_rewards_mean           1213.3923904421893
total_rewards_std            792.187920694563
total_rewards_max            2332.2155944309216
total_rewards_min            -143.35230564321012
Number of train steps total  193000
Number of env steps total    967000
Number of rollouts total     0
Train Time (s)               28.50868816813454
(Previous) Eval Time (s)     19.81201552832499
Sample Time (s)              17.744069560430944
Epoch Time (s)               66.06477325689048
Total Train Time (s)         13426.20925429603
Epoch                        192
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:59:17.946455 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #192 | Epoch Duration: 69.67193841934204
2020-01-11 06:59:17.946700 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #192 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89580727
Z variance train             0.020310318
KL Divergence                20.2604
KL Loss                      2.02604
QF Loss                      783.073
VF Loss                      343.1824
Policy Loss                  -754.3293
Q Predictions Mean           753.3158
Q Predictions Std            213.16777
Q Predictions Max            969.9456
Q Predictions Min            -45.51585
V Predictions Mean           755.126
V Predictions Std            208.82748
V Predictions Max            968.6226
V Predictions Min            78.56482
Log Pis Mean                 -0.9746195
Log Pis Std                  2.621958
Log Pis Max                  11.028948
Log Pis Min                  -7.699609
Policy mu Mean               0.019951526
Policy mu Std                0.59351724
Policy mu Max                2.367992
Policy mu Min                -2.2559695
Policy log std Mean          -0.8300984
Policy log std Std           0.26013547
Policy log std Max           -0.23556647
Policy log std Min           -2.5878918
Z mean eval                  0.86791784
Z variance eval              0.022265604
total_rewards                [ 153.78306034 2271.09476251  254.06189104 2179.95489171 1003.96766703
  808.9184569    92.6672996  2054.00152968 2315.02619682 2423.78403868]
total_rewards_mean           1355.7259794311262
total_rewards_std            934.9987769048618
total_rewards_max            2423.7840386844573
total_rewards_min            92.66729960019313
Number of train steps total  194000
Number of env steps total    972000
Number of rollouts total     0
Train Time (s)               31.358881333377212
(Previous) Eval Time (s)     23.41888768505305
Sample Time (s)              18.204966923687607
Epoch Time (s)               72.98273594211787
Total Train Time (s)         13497.695158869494
Epoch                        193
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:00:29.436252 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #193 | Epoch Duration: 71.48933839797974
2020-01-11 07:00:29.436563 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #193 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.86866647
Z variance train             0.022205573
KL Divergence                19.758121
KL Loss                      1.9758122
QF Loss                      477.93018
VF Loss                      52.057034
Policy Loss                  -748.995
Q Predictions Mean           745.5253
Q Predictions Std            207.87117
Q Predictions Max            956.8949
Q Predictions Min            3.6012578
V Predictions Mean           749.9586
V Predictions Std            206.14888
V Predictions Max            947.0319
V Predictions Min            -4.0817356
Log Pis Mean                 -1.0532839
Log Pis Std                  2.4660828
Log Pis Max                  6.4892497
Log Pis Min                  -7.482943
Policy mu Mean               0.024234308
Policy mu Std                0.55862045
Policy mu Max                1.9678422
Policy mu Min                -2.1582026
Policy log std Mean          -0.8431473
Policy log std Std           0.26111755
Policy log std Max           -0.20538437
Policy log std Min           -1.8710679
Z mean eval                  0.87206984
Z variance eval              0.029930478
total_rewards                [2050.00242065 1339.02185674 1403.8458454   284.56967114 1465.62472792
 2351.88687129 1583.20733948 2278.2144282   433.2650301   147.30323123]
total_rewards_mean           1333.6941422148634
total_rewards_std            764.5588826525651
total_rewards_max            2351.8868712903695
total_rewards_min            147.30323122644998
Number of train steps total  195000
Number of env steps total    977000
Number of rollouts total     0
Train Time (s)               27.819790630135685
(Previous) Eval Time (s)     21.9251685612835
Sample Time (s)              18.787655923049897
Epoch Time (s)               68.53261511446908
Total Train Time (s)         13563.85675640963
Epoch                        194
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:01:35.600066 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #194 | Epoch Duration: 66.1632821559906
2020-01-11 07:01:35.600249 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #194 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8712457
Z variance train             0.029932851
KL Divergence                18.475334
KL Loss                      1.8475335
QF Loss                      449.6406
VF Loss                      113.92348
Policy Loss                  -744.4924
Q Predictions Mean           740.14154
Q Predictions Std            214.48346
Q Predictions Max            961.5616
Q Predictions Min            -10.077074
V Predictions Mean           740.92944
V Predictions Std            213.45663
V Predictions Max            963.89374
V Predictions Min            -0.25517833
Log Pis Mean                 -1.4537323
Log Pis Std                  2.4160001
Log Pis Max                  6.0031214
Log Pis Min                  -11.20072
Policy mu Mean               0.052930377
Policy mu Std                0.5007635
Policy mu Max                1.8068177
Policy mu Min                -1.9341162
Policy log std Mean          -0.8529836
Policy log std Std           0.2407441
Policy log std Max           -0.26996854
Policy log std Min           -1.9189122
Z mean eval                  0.8871309
Z variance eval              0.039280094
total_rewards                [2432.83567341 1419.75374769  915.0600546  2313.59913791  537.63696547
 2236.74321114 1076.73351426 2381.94907699 1444.67566188 2476.34365864]
total_rewards_mean           1723.5330701988696
total_rewards_std            690.16515419835
total_rewards_max            2476.3436586403577
total_rewards_min            537.6369654732226
Number of train steps total  196000
Number of env steps total    982000
Number of rollouts total     0
Train Time (s)               26.59854738600552
(Previous) Eval Time (s)     19.555524681229144
Sample Time (s)              17.734105933923274
Epoch Time (s)               63.88817800115794
Total Train Time (s)         13634.633739105426
Epoch                        195
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:02:46.378933 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #195 | Epoch Duration: 70.77853441238403
2020-01-11 07:02:46.379129 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #195 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.88698006
Z variance train             0.03922988
KL Divergence                18.343733
KL Loss                      1.8343734
QF Loss                      544.96045
VF Loss                      162.99254
Policy Loss                  -745.0145
Q Predictions Mean           737.7122
Q Predictions Std            207.32504
Q Predictions Max            964.263
Q Predictions Min            -59.953598
V Predictions Mean           737.6669
V Predictions Std            201.62746
V Predictions Max            952.2441
V Predictions Min            -9.183401
Log Pis Mean                 -1.1942711
Log Pis Std                  2.736752
Log Pis Max                  8.470852
Log Pis Min                  -10.039185
Policy mu Mean               0.046334222
Policy mu Std                0.55335903
Policy mu Max                2.0048935
Policy mu Min                -2.044038
Policy log std Mean          -0.86412615
Policy log std Std           0.26481628
Policy log std Max           0.64285517
Policy log std Min           -2.63751
Z mean eval                  0.8968269
Z variance eval              0.029029077
total_rewards                [ 755.72939029 1344.69581277 2292.9543006   775.00485123 2277.17023896
 1460.58866948 1881.41116794 2323.06640886  816.23621146 1909.84429449]
total_rewards_mean           1583.6701346081077
total_rewards_std            610.4433303210541
total_rewards_max            2323.0664088588414
total_rewards_min            755.7293902942895
Number of train steps total  197000
Number of env steps total    987000
Number of rollouts total     0
Train Time (s)               27.92179656494409
(Previous) Eval Time (s)     26.445563103072345
Sample Time (s)              19.26329720998183
Epoch Time (s)               73.63065687799826
Total Train Time (s)         13706.39338889718
Epoch                        196
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:03:58.142607 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #196 | Epoch Duration: 71.7633101940155
2020-01-11 07:03:58.142824 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #196 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8979575
Z variance train             0.028978419
KL Divergence                18.65589
KL Loss                      1.865589
QF Loss                      750.35565
VF Loss                      221.05447
Policy Loss                  -804.00037
Q Predictions Mean           803.36786
Q Predictions Std            178.9386
Q Predictions Max            1000.3932
Q Predictions Min            -21.051651
V Predictions Mean           810.7643
V Predictions Std            179.99898
V Predictions Max            1007.4158
V Predictions Min            -6.6305656
Log Pis Mean                 -1.1524757
Log Pis Std                  2.417353
Log Pis Max                  5.357071
Log Pis Min                  -11.044561
Policy mu Mean               0.05485282
Policy mu Std                0.52791214
Policy mu Max                1.7546166
Policy mu Min                -1.8221585
Policy log std Mean          -0.8848065
Policy log std Std           0.24940194
Policy log std Max           -0.27564642
Policy log std Min           -2.0863433
Z mean eval                  0.9056298
Z variance eval              0.029114861
total_rewards                [2193.37316502 1601.55070983 2082.32121281 1936.69865351 1455.39021612
 2221.78575827 1913.52689851 2142.27843787 1088.44125313  854.18310669]
total_rewards_mean           1748.9549411772837
total_rewards_std            457.6076744501541
total_rewards_max            2221.785758273415
total_rewards_min            854.1831066906346
Number of train steps total  198000
Number of env steps total    992000
Number of rollouts total     0
Train Time (s)               27.133638376835734
(Previous) Eval Time (s)     24.577912437729537
Sample Time (s)              18.144684536382556
Epoch Time (s)               69.85623535094783
Total Train Time (s)         13777.07408453431
Epoch                        197
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:05:08.827060 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #197 | Epoch Duration: 70.68402814865112
2020-01-11 07:05:08.827347 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #197 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9054338
Z variance train             0.029024068
KL Divergence                18.519707
KL Loss                      1.8519707
QF Loss                      701.00507
VF Loss                      192.76607
Policy Loss                  -759.21857
Q Predictions Mean           754.8726
Q Predictions Std            218.16666
Q Predictions Max            992.0588
Q Predictions Min            54.049484
V Predictions Mean           754.3285
V Predictions Std            214.75429
V Predictions Max            991.78186
V Predictions Min            101.56822
Log Pis Mean                 -1.2815385
Log Pis Std                  2.4552248
Log Pis Max                  8.736111
Log Pis Min                  -7.187215
Policy mu Mean               0.05136023
Policy mu Std                0.56274194
Policy mu Max                2.356771
Policy mu Min                -2.0973518
Policy log std Mean          -0.81666684
Policy log std Std           0.2589386
Policy log std Max           -0.08154011
Policy log std Min           -2.5298235
Z mean eval                  0.91253203
Z variance eval              0.031991117
total_rewards                [ 178.298219    911.16719696  323.81801532  940.20333177 2046.60847207
  483.83490665  565.56577592 2128.81320264  867.32750944  635.1905374 ]
total_rewards_mean           908.0827167146215
total_rewards_std            635.2047626336996
total_rewards_max            2128.813202635631
total_rewards_min            178.29821899814846
Number of train steps total  199000
Number of env steps total    997000
Number of rollouts total     0
Train Time (s)               25.14725627982989
(Previous) Eval Time (s)     25.405394199304283
Sample Time (s)              18.16912735067308
Epoch Time (s)               68.72177782980725
Total Train Time (s)         13847.563493852504
Epoch                        198
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:06:19.317394 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #198 | Epoch Duration: 70.4898293018341
2020-01-11 07:06:19.317578 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #198 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9158577
Z variance train             0.03186357
KL Divergence                18.734627
KL Loss                      1.8734627
QF Loss                      1092.4833
VF Loss                      758.1558
Policy Loss                  -784.4798
Q Predictions Mean           783.2052
Q Predictions Std            185.34488
Q Predictions Max            991.52155
Q Predictions Min            118.110214
V Predictions Mean           786.8938
V Predictions Std            178.35399
V Predictions Max            994.23553
V Predictions Min            147.27306
Log Pis Mean                 -0.825767
Log Pis Std                  2.4281282
Log Pis Max                  8.106259
Log Pis Min                  -7.996271
Policy mu Mean               0.06954099
Policy mu Std                0.5195311
Policy mu Max                1.8817027
Policy mu Min                -1.8917319
Policy log std Mean          -0.8977649
Policy log std Std           0.25397813
Policy log std Max           -0.34323633
Policy log std Min           -2.1783638
Z mean eval                  0.89058465
Z variance eval              0.022910353
total_rewards                [ -19.01503335 1065.43501945  853.95413534 2459.95157911 1568.94790539
 2163.86523659  641.06718705 1219.22198012  205.18492856 2305.84526468]
total_rewards_mean           1246.4458202940398
total_rewards_std            823.4223622376807
total_rewards_max            2459.951579107579
total_rewards_min            -19.01503335203031
Number of train steps total  200000
Number of env steps total    1002000
Number of rollouts total     0
Train Time (s)               30.895132947713137
(Previous) Eval Time (s)     27.173105917871
Sample Time (s)              18.183656515087932
Epoch Time (s)               76.25189538067207
Total Train Time (s)         13918.151952947956
Epoch                        199
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:07:29.922140 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #199 | Epoch Duration: 70.60444116592407
2020-01-11 07:07:29.922291 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #199 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8906479
Z variance train             0.02286815
KL Divergence                18.907333
KL Loss                      1.8907334
QF Loss                      848.42896
VF Loss                      136.0881
Policy Loss                  -772.1053
Q Predictions Mean           769.3457
Q Predictions Std            194.34763
Q Predictions Max            961.7341
Q Predictions Min            232.44545
V Predictions Mean           776.56384
V Predictions Std            197.71729
V Predictions Max            971.9921
V Predictions Min            237.56888
Log Pis Mean                 -1.5170102
Log Pis Std                  2.371862
Log Pis Max                  7.497196
Log Pis Min                  -7.2317476
Policy mu Mean               0.08358185
Policy mu Std                0.53121644
Policy mu Max                2.008035
Policy mu Min                -1.9791582
Policy log std Mean          -0.84992325
Policy log std Std           0.25137198
Policy log std Max           -0.29922295
Policy log std Min           -2.2921774
Z mean eval                  0.89058053
Z variance eval              0.023963755
total_rewards                [1091.73154989 1214.84904136 1926.4928525  2267.79332083 1965.90939677
 2124.87794718 1979.14607352  641.23194314 2103.32270476  659.92340023]
total_rewards_mean           1597.5278230175938
total_rewards_std            597.3788329326694
total_rewards_max            2267.79332082657
total_rewards_min            641.2319431424112
Number of train steps total  201000
Number of env steps total    1007000
Number of rollouts total     0
Train Time (s)               30.36908079497516
(Previous) Eval Time (s)     21.525334787089378
Sample Time (s)              17.887564107310027
Epoch Time (s)               69.78197968937457
Total Train Time (s)         13993.819289547857
Epoch                        200
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:08:45.593023 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #200 | Epoch Duration: 75.67059278488159
2020-01-11 07:08:45.593242 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #200 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8945117
Z variance train             0.023934994
KL Divergence                18.859058
KL Loss                      1.8859059
QF Loss                      441.66974
VF Loss                      135.42293
Policy Loss                  -799.57855
Q Predictions Mean           794.2169
Q Predictions Std            180.22546
Q Predictions Max            1001.343
Q Predictions Min            27.275545
V Predictions Mean           792.7636
V Predictions Std            176.76263
V Predictions Max            995.7561
V Predictions Min            16.14297
Log Pis Mean                 -0.80970055
Log Pis Std                  2.348429
Log Pis Max                  6.2134476
Log Pis Min                  -8.9256115
Policy mu Mean               0.024012335
Policy mu Std                0.56122553
Policy mu Max                1.8939772
Policy mu Min                -1.694551
Policy log std Mean          -0.87410116
Policy log std Std           0.24853435
Policy log std Max           -0.22701311
Policy log std Min           -2.1445003
Z mean eval                  0.9038037
Z variance eval              0.028720671
total_rewards                [2184.11130368 2144.60661721 2222.6977667  2326.68177967 2013.33022662
 2165.11204575 2038.0306477  1526.86441514 2114.50694926 2265.92753381]
total_rewards_mean           2100.186928553695
total_rewards_std            211.49981297954895
total_rewards_max            2326.68177967016
total_rewards_min            1526.864415137425
Number of train steps total  202000
Number of env steps total    1012000
Number of rollouts total     0
Train Time (s)               30.376308771781623
(Previous) Eval Time (s)     27.413634659722447
Sample Time (s)              17.65865120338276
Epoch Time (s)               75.44859463488683
Total Train Time (s)         14069.75552587118
Epoch                        201
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:10:01.531002 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #201 | Epoch Duration: 75.9375991821289
2020-01-11 07:10:01.531187 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #201 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90567684
Z variance train             0.028724033
KL Divergence                18.590467
KL Loss                      1.8590468
QF Loss                      456.96906
VF Loss                      233.41457
Policy Loss                  -803.87445
Q Predictions Mean           799.9772
Q Predictions Std            172.52011
Q Predictions Max            1019.10614
Q Predictions Min            223.27382
V Predictions Mean           795.05145
V Predictions Std            170.87495
V Predictions Max            988.5003
V Predictions Min            226.53273
Log Pis Mean                 -1.1262268
Log Pis Std                  2.2255926
Log Pis Max                  4.47002
Log Pis Min                  -7.44232
Policy mu Mean               0.011461891
Policy mu Std                0.53084695
Policy mu Max                2.0701127
Policy mu Min                -1.6301701
Policy log std Mean          -0.89333946
Policy log std Std           0.24378821
Policy log std Max           -0.27941206
Policy log std Min           -1.8930974
Z mean eval                  0.8806221
Z variance eval              0.029801458
total_rewards                [ 936.04071393 2111.24160459 1951.16666818  118.27778329 1670.07020642
  682.44120035  529.39633829 2252.99647584 1542.6841086   442.70584199]
total_rewards_mean           1223.7020941477522
total_rewards_std            732.6024154206535
total_rewards_max            2252.99647584225
total_rewards_min            118.27778328507051
Number of train steps total  203000
Number of env steps total    1017000
Number of rollouts total     0
Train Time (s)               27.910317370668054
(Previous) Eval Time (s)     27.902349766343832
Sample Time (s)              18.97931686323136
Epoch Time (s)               74.79198400024325
Total Train Time (s)         14143.055136910174
Epoch                        202
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:11:14.834290 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #202 | Epoch Duration: 73.3029522895813
2020-01-11 07:11:14.834534 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #202 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8804908
Z variance train             0.029891005
KL Divergence                18.42997
KL Loss                      1.842997
QF Loss                      855.98224
VF Loss                      131.40791
Policy Loss                  -804.4717
Q Predictions Mean           803.177
Q Predictions Std            193.33957
Q Predictions Max            1009.3441
Q Predictions Min            241.07903
V Predictions Mean           810.06635
V Predictions Std            194.17552
V Predictions Max            1019.6454
V Predictions Min            250.73491
Log Pis Mean                 -1.140413
Log Pis Std                  2.3267167
Log Pis Max                  5.5854297
Log Pis Min                  -6.5538588
Policy mu Mean               0.08884521
Policy mu Std                0.5571324
Policy mu Max                2.1267245
Policy mu Min                -1.8032532
Policy log std Mean          -0.84809905
Policy log std Std           0.242117
Policy log std Max           -0.2490685
Policy log std Min           -2.0255928
Z mean eval                  0.8827019
Z variance eval              0.03518176
total_rewards                [ -20.32278301  457.82633213 2406.15677411  307.17430733  134.12598829
 1239.55279353 2303.19182458 2427.28333796 1260.96372087  863.35409986]
total_rewards_mean           1137.9306395655633
total_rewards_std            907.2701217009902
total_rewards_max            2427.283337960801
total_rewards_min            -20.322783007888873
Number of train steps total  204000
Number of env steps total    1022000
Number of rollouts total     0
Train Time (s)               26.63246754836291
(Previous) Eval Time (s)     26.4129351307638
Sample Time (s)              18.631400095298886
Epoch Time (s)               71.6768027744256
Total Train Time (s)         14210.291365849786
Epoch                        203
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:12:22.072510 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #203 | Epoch Duration: 67.23780179023743
2020-01-11 07:12:22.072691 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #203 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8829891
Z variance train             0.035297073
KL Divergence                17.860533
KL Loss                      1.7860533
QF Loss                      525.61084
VF Loss                      101.3382
Policy Loss                  -776.6174
Q Predictions Mean           774.32275
Q Predictions Std            211.98941
Q Predictions Max            983.6099
Q Predictions Min            -0.26490688
V Predictions Mean           774.6382
V Predictions Std            208.093
V Predictions Max            984.16815
V Predictions Min            225.53302
Log Pis Mean                 -1.2534204
Log Pis Std                  2.5990665
Log Pis Max                  14.839266
Log Pis Min                  -9.235204
Policy mu Mean               0.03367264
Policy mu Std                0.52562875
Policy mu Max                1.858425
Policy mu Min                -1.9017699
Policy log std Mean          -0.8803842
Policy log std Std           0.30193305
Policy log std Max           -0.2733818
Policy log std Min           -3.553193
Z mean eval                  0.89781487
Z variance eval              0.0312997
total_rewards                [1676.16929247 1225.09604315  193.06945134 2376.31286665 2202.52338983
 1981.01350095 2231.81701117  748.23539425  479.08763023 2292.27946109]
total_rewards_mean           1540.560404113962
total_rewards_std            778.5715197361307
total_rewards_max            2376.3128666519015
total_rewards_min            193.06945133606445
Number of train steps total  205000
Number of env steps total    1027000
Number of rollouts total     0
Train Time (s)               28.79831184912473
(Previous) Eval Time (s)     21.973597540985793
Sample Time (s)              17.92754489928484
Epoch Time (s)               68.69945428939536
Total Train Time (s)         14279.538690280635
Epoch                        204
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:13:31.322487 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #204 | Epoch Duration: 69.24965691566467
2020-01-11 07:13:31.322713 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #204 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8973526
Z variance train             0.031276457
KL Divergence                17.96555
KL Loss                      1.7965549
QF Loss                      403.4271
VF Loss                      151.23807
Policy Loss                  -799.22906
Q Predictions Mean           797.103
Q Predictions Std            200.02907
Q Predictions Max            980.2731
Q Predictions Min            108.248314
V Predictions Mean           798.9917
V Predictions Std            200.9212
V Predictions Max            980.70374
V Predictions Min            24.288494
Log Pis Mean                 -1.2900681
Log Pis Std                  2.6066272
Log Pis Max                  8.370832
Log Pis Min                  -9.744072
Policy mu Mean               0.05669637
Policy mu Std                0.56285024
Policy mu Max                1.789504
Policy mu Min                -1.9620239
Policy log std Mean          -0.83544075
Policy log std Std           0.23489538
Policy log std Max           -0.24632272
Policy log std Min           -1.8458288
Z mean eval                  0.9031631
Z variance eval              0.027595114
total_rewards                [1398.66194004 2213.96704104 1544.30580514  408.81025422 1971.15064587
  318.14562103  706.71734744   54.79309238 2119.95999748  244.42926195]
total_rewards_mean           1098.0941006581154
total_rewards_std            799.6802009604243
total_rewards_max            2213.9670410356875
total_rewards_min            54.79309238208869
Number of train steps total  206000
Number of env steps total    1032000
Number of rollouts total     0
Train Time (s)               30.213288402184844
(Previous) Eval Time (s)     22.52349223801866
Sample Time (s)              17.914285367820412
Epoch Time (s)               70.65106600802392
Total Train Time (s)         14344.83722382877
Epoch                        205
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:14:36.623785 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #205 | Epoch Duration: 65.30090117454529
2020-01-11 07:14:36.623977 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #205 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90321076
Z variance train             0.027547345
KL Divergence                17.391289
KL Loss                      1.739129
QF Loss                      824.23846
VF Loss                      97.69083
Policy Loss                  -807.2435
Q Predictions Mean           804.9173
Q Predictions Std            197.37158
Q Predictions Max            1007.78973
Q Predictions Min            -1.8903414
V Predictions Mean           808.3379
V Predictions Std            198.43568
V Predictions Max            1020.40686
V Predictions Min            0.12350327
Log Pis Mean                 -1.1462691
Log Pis Std                  2.568298
Log Pis Max                  7.062255
Log Pis Min                  -11.070309
Policy mu Mean               0.07177378
Policy mu Std                0.54421866
Policy mu Max                1.7884396
Policy mu Min                -2.2891846
Policy log std Mean          -0.8468722
Policy log std Std           0.24939147
Policy log std Max           -0.16986823
Policy log std Min           -1.9807522
Z mean eval                  0.8762329
Z variance eval              0.036821656
total_rewards                [2050.21116435 1205.41632806 1979.62513498  275.59552874 2237.35177561
 2455.00673181 1859.46104275 1447.275927   1303.44252416  740.76302332]
total_rewards_mean           1555.4149180779766
total_rewards_std            655.0422512354537
total_rewards_max            2455.0067318094684
total_rewards_min            275.5955287383438
Number of train steps total  207000
Number of env steps total    1037000
Number of rollouts total     0
Train Time (s)               28.739350656978786
(Previous) Eval Time (s)     17.17299790820107
Sample Time (s)              18.6428523985669
Epoch Time (s)               64.55520096374676
Total Train Time (s)         14415.044206094462
Epoch                        206
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:15:46.832016 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #206 | Epoch Duration: 70.20790004730225
2020-01-11 07:15:46.832182 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #206 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.87346154
Z variance train             0.036746852
KL Divergence                16.638008
KL Loss                      1.6638008
QF Loss                      617.9413
VF Loss                      289.8471
Policy Loss                  -799.7429
Q Predictions Mean           797.6231
Q Predictions Std            204.34491
Q Predictions Max            1003.3285
Q Predictions Min            218.59396
V Predictions Mean           814.6506
V Predictions Std            204.56708
V Predictions Max            1025.0734
V Predictions Min            234.37273
Log Pis Mean                 -1.4472255
Log Pis Std                  2.7123132
Log Pis Max                  12.335918
Log Pis Min                  -9.073878
Policy mu Mean               0.032146446
Policy mu Std                0.5343999
Policy mu Max                2.0274546
Policy mu Min                -2.5104728
Policy log std Mean          -0.8561432
Policy log std Std           0.24762134
Policy log std Max           -0.35917333
Policy log std Min           -2.0769289
Z mean eval                  0.8851673
Z variance eval              0.020749325
total_rewards                [1911.74988083  686.77878835 2058.74660245 2057.5829502  2065.60582671
 1150.42768075 2107.67467057 2600.86571624 2074.94836731  610.91417373]
total_rewards_mean           1732.5294657126901
total_rewards_std            636.9919552782229
total_rewards_max            2600.865716241743
total_rewards_min            610.9141737289619
Number of train steps total  208000
Number of env steps total    1042000
Number of rollouts total     0
Train Time (s)               26.929682314861566
(Previous) Eval Time (s)     22.8253586278297
Sample Time (s)              17.96392533974722
Epoch Time (s)               67.71896628243849
Total Train Time (s)         14483.41589210229
Epoch                        207
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:16:55.208813 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #207 | Epoch Duration: 68.37647080421448
2020-01-11 07:16:55.209092 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #207 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8849479
Z variance train             0.020743672
KL Divergence                17.629402
KL Loss                      1.7629403
QF Loss                      768.5258
VF Loss                      122.129036
Policy Loss                  -794.5579
Q Predictions Mean           794.1497
Q Predictions Std            207.48384
Q Predictions Max            1033.8372
Q Predictions Min            220.02042
V Predictions Mean           799.1256
V Predictions Std            206.60397
V Predictions Max            1021.6264
V Predictions Min            223.11275
Log Pis Mean                 -1.1558583
Log Pis Std                  2.5831301
Log Pis Max                  7.7282557
Log Pis Min                  -7.8760605
Policy mu Mean               0.11762868
Policy mu Std                0.542327
Policy mu Max                2.2223527
Policy mu Min                -1.6708615
Policy log std Mean          -0.87643206
Policy log std Std           0.2591348
Policy log std Max           -0.251207
Policy log std Min           -2.4027772
Z mean eval                  0.9084314
Z variance eval              0.019732177
total_rewards                [1562.14131051  388.17810116  565.10205288  718.08914061 1489.9329919
    9.51883718  516.35605399  991.10854874   82.80864567  257.01775838]
total_rewards_mean           658.0253441022903
total_rewards_std            513.5963960019877
total_rewards_max            1562.1413105143984
total_rewards_min            9.518837183432671
Number of train steps total  209000
Number of env steps total    1047000
Number of rollouts total     0
Train Time (s)               27.40230122068897
(Previous) Eval Time (s)     23.482582970988005
Sample Time (s)              17.938337035942823
Epoch Time (s)               68.8232212276198
Total Train Time (s)         14546.780740627088
Epoch                        208
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:17:58.577382 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #208 | Epoch Duration: 63.36807584762573
2020-01-11 07:17:58.577614 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #208 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9083842
Z variance train             0.019767616
KL Divergence                18.404278
KL Loss                      1.8404278
QF Loss                      856.37866
VF Loss                      135.41064
Policy Loss                  -787.02264
Q Predictions Mean           783.9774
Q Predictions Std            214.93921
Q Predictions Max            1000.36536
Q Predictions Min            221.67377
V Predictions Mean           782.78467
V Predictions Std            212.78755
V Predictions Max            988.0756
V Predictions Min            233.87428
Log Pis Mean                 -1.2592716
Log Pis Std                  2.6258624
Log Pis Max                  10.243604
Log Pis Min                  -8.943987
Policy mu Mean               0.07771649
Policy mu Std                0.5636447
Policy mu Max                2.134429
Policy mu Min                -1.9341282
Policy log std Mean          -0.8342283
Policy log std Std           0.26306245
Policy log std Max           -0.16484612
Policy log std Min           -2.3455458
Z mean eval                  0.90461886
Z variance eval              0.022450346
total_rewards                [2160.69661773 2339.47802927  138.90879441 2533.36831153  772.16253135
  447.83318548  980.77522443    7.43543659   10.89790437  421.8085942 ]
total_rewards_mean           981.3364629368155
total_rewards_std            942.6352190180471
total_rewards_max            2533.3683115296153
total_rewards_min            7.4354365918411
Number of train steps total  210000
Number of env steps total    1052000
Number of rollouts total     0
Train Time (s)               28.841260695829988
(Previous) Eval Time (s)     18.02712775580585
Sample Time (s)              17.35856654215604
Epoch Time (s)               64.22695499379188
Total Train Time (s)         14611.346849665977
Epoch                        209
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:19:03.144727 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #209 | Epoch Duration: 64.56694340705872
2020-01-11 07:19:03.144921 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #209 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9024445
Z variance train             0.022607824
KL Divergence                18.031265
KL Loss                      1.8031266
QF Loss                      1686.3484
VF Loss                      393.88782
Policy Loss                  -806.0708
Q Predictions Mean           806.12476
Q Predictions Std            203.00731
Q Predictions Max            1011.66394
Q Predictions Min            205.02965
V Predictions Mean           822.8347
V Predictions Std            205.06853
V Predictions Max            1027.5499
V Predictions Min            213.97063
Log Pis Mean                 -1.0069355
Log Pis Std                  2.4699655
Log Pis Max                  5.7573524
Log Pis Min                  -8.752551
Policy mu Mean               0.031035664
Policy mu Std                0.584122
Policy mu Max                1.7856367
Policy mu Min                -1.9904797
Policy log std Mean          -0.8417694
Policy log std Std           0.23779659
Policy log std Max           -0.23152414
Policy log std Min           -2.1534355
Z mean eval                  0.89252186
Z variance eval              0.033848226
total_rewards                [2085.98798239 1887.66943398  261.93982187   22.6137016  1966.42290689
 1819.72810313  305.98611814 1176.07960971  721.98083532  125.07535387]
total_rewards_mean           1037.3483866904246
total_rewards_std            800.922542596365
total_rewards_max            2085.9879823926944
total_rewards_min            22.613701599334508
Number of train steps total  211000
Number of env steps total    1057000
Number of rollouts total     0
Train Time (s)               27.869472796097398
(Previous) Eval Time (s)     18.366830586921424
Sample Time (s)              18.04380439268425
Epoch Time (s)               64.28010777570307
Total Train Time (s)         14675.32212604722
Epoch                        210
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:20:07.121901 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #210 | Epoch Duration: 63.976848125457764
2020-01-11 07:20:07.122100 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #210 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8945365
Z variance train             0.03383287
KL Divergence                17.290298
KL Loss                      1.7290299
QF Loss                      514.4214
VF Loss                      158.9614
Policy Loss                  -788.39233
Q Predictions Mean           789.45337
Q Predictions Std            192.11093
Q Predictions Max            996.03705
Q Predictions Min            25.257902
V Predictions Mean           798.4634
V Predictions Std            192.50197
V Predictions Max            1007.32007
V Predictions Min            42.758213
Log Pis Mean                 -1.3542039
Log Pis Std                  2.6811476
Log Pis Max                  10.149639
Log Pis Min                  -8.144724
Policy mu Mean               0.043736286
Policy mu Std                0.5393474
Policy mu Max                1.9221625
Policy mu Min                -1.9893032
Policy log std Mean          -0.8561361
Policy log std Std           0.24776016
Policy log std Max           -0.27879536
Policy log std Min           -2.4199133
Z mean eval                  0.88714886
Z variance eval              0.031584736
total_rewards                [2369.9480596   141.37491813 2521.04420094 1239.30584679 1995.56970279
 2504.91331114 2353.87333408 1352.10588926 2361.52359593 2381.68692555]
total_rewards_mean           1922.1345784221025
total_rewards_std            738.7283391885023
total_rewards_max            2521.044200939252
total_rewards_min            141.37491812982532
Number of train steps total  212000
Number of env steps total    1062000
Number of rollouts total     0
Train Time (s)               29.67068298580125
(Previous) Eval Time (s)     18.06321822386235
Sample Time (s)              17.782120381481946
Epoch Time (s)               65.51602159114555
Total Train Time (s)         14747.84284120053
Epoch                        211
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:21:19.648008 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #211 | Epoch Duration: 72.52572536468506
2020-01-11 07:21:19.648340 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #211 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8869726
Z variance train             0.031611077
KL Divergence                17.483042
KL Loss                      1.7483042
QF Loss                      537.842
VF Loss                      126.03917
Policy Loss                  -789.8076
Q Predictions Mean           787.5867
Q Predictions Std            211.8005
Q Predictions Max            1008.1305
Q Predictions Min            37.188503
V Predictions Mean           788.3047
V Predictions Std            213.99661
V Predictions Max            1021.5934
V Predictions Min            -2.1434934
Log Pis Mean                 -1.0111163
Log Pis Std                  2.4170465
Log Pis Max                  7.0783777
Log Pis Min                  -7.11218
Policy mu Mean               0.010273598
Policy mu Std                0.5404193
Policy mu Max                1.916156
Policy mu Min                -1.8778374
Policy log std Mean          -0.86662674
Policy log std Std           0.2603531
Policy log std Max           -0.29046428
Policy log std Min           -2.3661375
Z mean eval                  0.89198035
Z variance eval              0.036585145
total_rewards                [   5.40751882 1920.14238846 2298.41954277  428.13158812 2286.08033446
 1236.77283535 2407.84179934  889.98879787  745.9758606  2489.73738971]
total_rewards_mean           1470.849805548992
total_rewards_std            872.9168555402147
total_rewards_max            2489.737389711995
total_rewards_min            5.407518816512831
Number of train steps total  213000
Number of env steps total    1067000
Number of rollouts total     0
Train Time (s)               26.6726816999726
(Previous) Eval Time (s)     25.072553584352136
Sample Time (s)              18.100710086524487
Epoch Time (s)               69.84594537084922
Total Train Time (s)         14815.12896725582
Epoch                        212
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:22:26.936237 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #212 | Epoch Duration: 67.28766989707947
2020-01-11 07:22:26.936456 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #212 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8947116
Z variance train             0.0362212
KL Divergence                17.471848
KL Loss                      1.7471848
QF Loss                      1759.3068
VF Loss                      116.052315
Policy Loss                  -832.3073
Q Predictions Mean           825.8048
Q Predictions Std            184.92119
Q Predictions Max            1006.59357
Q Predictions Min            1.7569026
V Predictions Mean           831.1207
V Predictions Std            181.17007
V Predictions Max            1007.264
V Predictions Min            95.754524
Log Pis Mean                 -0.8394961
Log Pis Std                  2.2123382
Log Pis Max                  6.7734795
Log Pis Min                  -6.8441286
Policy mu Mean               0.08837642
Policy mu Std                0.5497942
Policy mu Max                1.9524139
Policy mu Min                -1.7903124
Policy log std Mean          -0.8781552
Policy log std Std           0.2632846
Policy log std Max           -0.2673131
Policy log std Min           -2.164072
Z mean eval                  0.90413535
Z variance eval              0.018557696
total_rewards                [ 381.33556978  820.85933058  675.81176601 2290.58301071  693.56277151
 1638.3997565  1844.29456608  498.88719272  376.99002825  535.66904669]
total_rewards_mean           975.6393038827715
total_rewards_std            651.8247604409669
total_rewards_max            2290.5830107133224
total_rewards_min            376.9900282491399
Number of train steps total  214000
Number of env steps total    1072000
Number of rollouts total     0
Train Time (s)               30.140503004658967
(Previous) Eval Time (s)     22.513982620090246
Sample Time (s)              17.681880647782236
Epoch Time (s)               70.33636627253145
Total Train Time (s)         14881.749787615146
Epoch                        213
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:23:33.561474 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #213 | Epoch Duration: 66.62481880187988
2020-01-11 07:23:33.561785 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #213 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90347767
Z variance train             0.018531341
KL Divergence                18.626493
KL Loss                      1.8626493
QF Loss                      568.1511
VF Loss                      61.84188
Policy Loss                  -787.95917
Q Predictions Mean           786.8675
Q Predictions Std            227.66776
Q Predictions Max            1028.5934
Q Predictions Min            212.26985
V Predictions Mean           790.08875
V Predictions Std            225.0276
V Predictions Max            1028.7299
V Predictions Min            225.65405
Log Pis Mean                 -1.23243
Log Pis Std                  2.3765402
Log Pis Max                  5.7190523
Log Pis Min                  -12.600009
Policy mu Mean               0.083908126
Policy mu Std                0.5547246
Policy mu Max                2.013625
Policy mu Min                -1.6895576
Policy log std Mean          -0.8259723
Policy log std Std           0.23702359
Policy log std Max           -0.12667763
Policy log std Min           -1.8341922
Z mean eval                  0.8973285
Z variance eval              0.035978705
total_rewards                [ 227.62468239 2260.18836328 2594.89207597  818.01420189 1300.96147514
   56.86542161 2594.33029878  141.03938536  101.73306241 1163.0013587 ]
total_rewards_mean           1125.8650325537371
total_rewards_std            984.6955802894042
total_rewards_max            2594.892075970778
total_rewards_min            56.86542161068731
Number of train steps total  215000
Number of env steps total    1077000
Number of rollouts total     0
Train Time (s)               28.63473399821669
(Previous) Eval Time (s)     18.802097885869443
Sample Time (s)              17.973972861655056
Epoch Time (s)               65.41080474574119
Total Train Time (s)         14943.86301723402
Epoch                        214
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:24:35.677117 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #214 | Epoch Duration: 62.11510491371155
2020-01-11 07:24:35.677339 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #214 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89784926
Z variance train             0.036065355
KL Divergence                17.290255
KL Loss                      1.7290255
QF Loss                      635.154
VF Loss                      139.5032
Policy Loss                  -788.28674
Q Predictions Mean           787.8086
Q Predictions Std            201.69826
Q Predictions Max            991.06274
Q Predictions Min            186.92863
V Predictions Mean           793.558
V Predictions Std            201.04147
V Predictions Max            998.8019
V Predictions Min            193.23799
Log Pis Mean                 -0.83330435
Log Pis Std                  2.650124
Log Pis Max                  6.5685263
Log Pis Min                  -9.885757
Policy mu Mean               0.04184378
Policy mu Std                0.5751649
Policy mu Max                2.047103
Policy mu Min                -2.0661225
Policy log std Mean          -0.8615378
Policy log std Std           0.25581637
Policy log std Max           -0.22651112
Policy log std Min           -2.0573723
Z mean eval                  0.9392789
Z variance eval              0.029702146
total_rewards                [ 530.38865555 1791.365245    961.65742118 1198.43919199  613.53996382
  303.97210199 2503.62106763 2521.7401443  1078.49201175  796.3883729 ]
total_rewards_mean           1229.9604176118673
total_rewards_std            749.4543589963122
total_rewards_max            2521.740144303598
total_rewards_min            303.972101989894
Number of train steps total  216000
Number of env steps total    1082000
Number of rollouts total     0
Train Time (s)               27.96670295810327
(Previous) Eval Time (s)     15.506105312146246
Sample Time (s)              17.84178548352793
Epoch Time (s)               61.314593753777444
Total Train Time (s)         15005.942031174432
Epoch                        215
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:25:37.759182 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #215 | Epoch Duration: 62.081666231155396
2020-01-11 07:25:37.759384 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #215 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9393878
Z variance train             0.029693102
KL Divergence                17.859283
KL Loss                      1.7859284
QF Loss                      1361.7339
VF Loss                      242.82521
Policy Loss                  -847.44495
Q Predictions Mean           844.21484
Q Predictions Std            170.06021
Q Predictions Max            1035.6644
Q Predictions Min            222.5475
V Predictions Mean           848.3185
V Predictions Std            170.17303
V Predictions Max            1035.3434
V Predictions Min            222.15816
Log Pis Mean                 -1.0354838
Log Pis Std                  2.6122646
Log Pis Max                  12.907438
Log Pis Min                  -6.3273125
Policy mu Mean               0.0069793668
Policy mu Std                0.55884165
Policy mu Max                2.2465382
Policy mu Min                -2.0521688
Policy log std Mean          -0.84710485
Policy log std Std           0.24445076
Policy log std Max           -0.25978154
Policy log std Min           -2.762173
Z mean eval                  0.92467225
Z variance eval              0.024528122
total_rewards                [2418.9830316  1137.74539539  768.8388211  1637.231412    495.1942294
 1376.47833956  365.90274791 2334.728472    746.59145216  708.791052  ]
total_rewards_mean           1199.0484953097534
total_rewards_std            694.6182933748029
total_rewards_max            2418.9830315969702
total_rewards_min            365.9027479077893
Number of train steps total  217000
Number of env steps total    1087000
Number of rollouts total     0
Train Time (s)               27.764920444227755
(Previous) Eval Time (s)     16.272896519862115
Sample Time (s)              17.893636564724147
Epoch Time (s)               61.93145352881402
Total Train Time (s)         15071.82841291232
Epoch                        216
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:26:43.647410 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #216 | Epoch Duration: 65.88787865638733
2020-01-11 07:26:43.647608 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #216 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92642146
Z variance train             0.024475481
KL Divergence                18.345163
KL Loss                      1.8345164
QF Loss                      1071.9058
VF Loss                      62.374092
Policy Loss                  -809.4266
Q Predictions Mean           809.1603
Q Predictions Std            215.13521
Q Predictions Max            1008.23773
Q Predictions Min            -5.658721
V Predictions Mean           810.6455
V Predictions Std            215.60829
V Predictions Max            995.2769
V Predictions Min            8.625889
Log Pis Mean                 -1.2813556
Log Pis Std                  2.3102703
Log Pis Max                  6.7366915
Log Pis Min                  -8.328246
Policy mu Mean               0.07403428
Policy mu Std                0.5401834
Policy mu Max                1.9165871
Policy mu Min                -1.9018227
Policy log std Mean          -0.8652717
Policy log std Std           0.24876621
Policy log std Max           -0.16493535
Policy log std Min           -2.1409082
Z mean eval                  0.8957459
Z variance eval              0.018374834
total_rewards                [2460.28124683 1082.09644498  931.49396531  382.5236999    66.13985549
  565.05657017  159.02066319  878.64247496 2124.11239767 1832.8710142 ]
total_rewards_mean           1048.2238332700042
total_rewards_std            790.0900633804579
total_rewards_max            2460.2812468348807
total_rewards_min            66.13985548944619
Number of train steps total  218000
Number of env steps total    1092000
Number of rollouts total     0
Train Time (s)               28.12252569012344
(Previous) Eval Time (s)     20.22901846189052
Sample Time (s)              17.89639313099906
Epoch Time (s)               66.24793728301302
Total Train Time (s)         15136.424479247537
Epoch                        217
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:27:48.247664 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #217 | Epoch Duration: 64.59987902641296
2020-01-11 07:27:48.247971 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #217 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8968312
Z variance train             0.01834917
KL Divergence                18.426125
KL Loss                      1.8426125
QF Loss                      950.63074
VF Loss                      178.8994
Policy Loss                  -816.6303
Q Predictions Mean           814.5304
Q Predictions Std            193.53888
Q Predictions Max            1026.563
Q Predictions Min            207.51018
V Predictions Mean           820.20764
V Predictions Std            190.26506
V Predictions Max            1029.8453
V Predictions Min            214.78523
Log Pis Mean                 -0.96770394
Log Pis Std                  2.434821
Log Pis Max                  8.236074
Log Pis Min                  -7.3010635
Policy mu Mean               0.06371875
Policy mu Std                0.5381957
Policy mu Max                2.472687
Policy mu Min                -1.7068977
Policy log std Mean          -0.87762904
Policy log std Std           0.27998847
Policy log std Max           -0.27224267
Policy log std Min           -2.5690274
Z mean eval                  0.9060708
Z variance eval              0.021648325
total_rewards                [2222.67593643 1491.31154983 1809.54299589 2363.1495623   669.84168996
 2364.19343261  178.27542078  499.46796152  462.10593922 2454.7994412 ]
total_rewards_mean           1451.5363929723646
total_rewards_std            866.750956489586
total_rewards_max            2454.7994411977375
total_rewards_min            178.2754207816086
Number of train steps total  219000
Number of env steps total    1097000
Number of rollouts total     0
Train Time (s)               26.688435908872634
(Previous) Eval Time (s)     18.58064903272316
Sample Time (s)              17.816187313757837
Epoch Time (s)               63.08527225535363
Total Train Time (s)         15205.229816776235
Epoch                        218
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:28:57.053754 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #218 | Epoch Duration: 68.8055830001831
2020-01-11 07:28:57.053907 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #218 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9068383
Z variance train             0.021685498
KL Divergence                18.07195
KL Loss                      1.8071951
QF Loss                      494.04956
VF Loss                      405.53973
Policy Loss                  -856.5457
Q Predictions Mean           852.7414
Q Predictions Std            194.58252
Q Predictions Max            1071.4625
Q Predictions Min            -27.493866
V Predictions Mean           838.56445
V Predictions Std            191.67322
V Predictions Max            1052.7864
V Predictions Min            -11.763226
Log Pis Mean                 -1.0623286
Log Pis Std                  2.1935651
Log Pis Max                  7.2935386
Log Pis Min                  -6.5441465
Policy mu Mean               0.09327859
Policy mu Std                0.53720707
Policy mu Max                2.1664755
Policy mu Min                -1.6611142
Policy log std Mean          -0.8879358
Policy log std Std           0.24512666
Policy log std Max           -0.07132316
Policy log std Min           -2.1211004
Z mean eval                  0.91414595
Z variance eval              0.026000211
total_rewards                [ 383.17166711   27.14714813 2009.83596025  291.10781858 1511.59444373
 1402.23308006 1182.92671367 2376.39393521 2035.33190197 1398.9627284 ]
total_rewards_mean           1261.8705397113931
total_rewards_std            758.0224955994016
total_rewards_max            2376.393935214166
total_rewards_min            27.147148134258835
Number of train steps total  220000
Number of env steps total    1102000
Number of rollouts total     0
Train Time (s)               26.771545572206378
(Previous) Eval Time (s)     24.300636899191886
Sample Time (s)              18.84773922059685
Epoch Time (s)               69.91992169199511
Total Train Time (s)         15277.303198188078
Epoch                        219
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:30:09.132281 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #219 | Epoch Duration: 72.07821106910706
2020-01-11 07:30:09.132586 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #219 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9139678
Z variance train             0.025973916
KL Divergence                17.425251
KL Loss                      1.7425251
QF Loss                      2751.239
VF Loss                      78.38382
Policy Loss                  -825.1565
Q Predictions Mean           821.9261
Q Predictions Std            233.43355
Q Predictions Max            1058.0006
Q Predictions Min            5.8307695
V Predictions Mean           827.43445
V Predictions Std            229.88484
V Predictions Max            1057.906
V Predictions Min            208.62733
Log Pis Mean                 -1.0683224
Log Pis Std                  2.6198132
Log Pis Max                  10.490007
Log Pis Min                  -7.219631
Policy mu Mean               -0.012612167
Policy mu Std                0.52553385
Policy mu Max                2.1058424
Policy mu Min                -2.1959448
Policy log std Mean          -0.8637483
Policy log std Std           0.29057425
Policy log std Max           -0.16861534
Policy log std Min           -2.4656043
Z mean eval                  0.9270501
Z variance eval              0.03876052
total_rewards                [1763.8815406   132.29180934  289.16075986 2431.29644905 2493.10053618
 1361.53759402 2390.06924898   33.05706674 2282.10112811 2005.72229954]
total_rewards_mean           1518.2218432433342
total_rewards_std            953.2778250400548
total_rewards_max            2493.100536183139
total_rewards_min            33.05706674037029
Number of train steps total  221000
Number of env steps total    1107000
Number of rollouts total     0
Train Time (s)               28.653937176335603
(Previous) Eval Time (s)     26.45857953513041
Sample Time (s)              17.938303749077022
Epoch Time (s)               73.05082046054304
Total Train Time (s)         15342.067889573518
Epoch                        220
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:31:13.898211 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #220 | Epoch Duration: 64.76540756225586
2020-01-11 07:31:13.898415 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #220 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9281769
Z variance train             0.038834848
KL Divergence                17.203314
KL Loss                      1.7203314
QF Loss                      550.9136
VF Loss                      70.49881
Policy Loss                  -794.78705
Q Predictions Mean           791.4546
Q Predictions Std            237.48991
Q Predictions Max            1029.5773
Q Predictions Min            27.317963
V Predictions Mean           794.3877
V Predictions Std            234.74466
V Predictions Max            1027.4131
V Predictions Min            121.32347
Log Pis Mean                 -1.3199965
Log Pis Std                  2.7774656
Log Pis Max                  12.639208
Log Pis Min                  -8.847277
Policy mu Mean               0.04751617
Policy mu Std                0.54268557
Policy mu Max                2.0173116
Policy mu Min                -2.4470263
Policy log std Mean          -0.8635516
Policy log std Std           0.30446765
Policy log std Max           -0.16584808
Policy log std Min           -2.9638443
Z mean eval                  0.9094385
Z variance eval              0.03164023
total_rewards                [2238.52087907 2296.61835269 1228.1168675   236.7110324  2366.73228179
 1609.43693567  714.8597745   205.52707998  555.11343965 2458.3081025 ]
total_rewards_mean           1390.9944745750875
total_rewards_std            871.6354130665395
total_rewards_max            2458.3081025003835
total_rewards_min            205.5270799845606
Number of train steps total  222000
Number of env steps total    1112000
Number of rollouts total     0
Train Time (s)               27.808329130988568
(Previous) Eval Time (s)     18.172865212894976
Sample Time (s)              17.584256776608527
Epoch Time (s)               63.56545112049207
Total Train Time (s)         15406.177709036972
Epoch                        221
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:32:18.013534 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #221 | Epoch Duration: 64.11495161056519
2020-01-11 07:32:18.013819 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #221 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9091095
Z variance train             0.031555254
KL Divergence                17.029755
KL Loss                      1.7029755
QF Loss                      671.249
VF Loss                      96.49398
Policy Loss                  -819.93524
Q Predictions Mean           814.40857
Q Predictions Std            210.31802
Q Predictions Max            1022.6197
Q Predictions Min            7.084676
V Predictions Mean           821.4592
V Predictions Std            208.98848
V Predictions Max            1020.3874
V Predictions Min            0.4064145
Log Pis Mean                 -0.96458167
Log Pis Std                  2.7318428
Log Pis Max                  11.568736
Log Pis Min                  -9.027813
Policy mu Mean               0.008153314
Policy mu Std                0.58859175
Policy mu Max                2.363624
Policy mu Min                -3.0434442
Policy log std Mean          -0.8632195
Policy log std Std           0.2691812
Policy log std Max           -0.01478982
Policy log std Min           -2.1242082
Z mean eval                  0.91746825
Z variance eval              0.039557457
total_rewards                [1567.28951741 1864.49127715 2399.15086927 2519.24044955 2356.26899794
 2149.42709319 1702.77152299   45.52410238  -67.44517553 2270.87478848]
total_rewards_mean           1680.7593442830864
total_rewards_std            895.5817458955551
total_rewards_max            2519.2404495464502
total_rewards_min            -67.44517552761985
Number of train steps total  223000
Number of env steps total    1117000
Number of rollouts total     0
Train Time (s)               28.235947703011334
(Previous) Eval Time (s)     18.722053282894194
Sample Time (s)              17.824303622357547
Epoch Time (s)               64.78230460826308
Total Train Time (s)         15478.359337669332
Epoch                        222
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:33:30.198334 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #222 | Epoch Duration: 72.18428659439087
2020-01-11 07:33:30.198582 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #222 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9184491
Z variance train             0.039501064
KL Divergence                17.255842
KL Loss                      1.7255843
QF Loss                      576.1752
VF Loss                      341.14944
Policy Loss                  -827.44635
Q Predictions Mean           821.38403
Q Predictions Std            217.59818
Q Predictions Max            1056.7068
Q Predictions Min            21.999746
V Predictions Mean           832.6506
V Predictions Std            211.61577
V Predictions Max            1056.3374
V Predictions Min            214.95676
Log Pis Mean                 -0.87287736
Log Pis Std                  2.754186
Log Pis Max                  6.7591324
Log Pis Min                  -7.895851
Policy mu Mean               0.0061069583
Policy mu Std                0.5619878
Policy mu Max                2.895223
Policy mu Min                -1.8646858
Policy log std Mean          -0.8649121
Policy log std Std           0.28139427
Policy log std Max           -0.21048516
Policy log std Min           -2.4031897
Z mean eval                  0.9377812
Z variance eval              0.024368484
total_rewards                [ 136.56125837  217.34120147  384.01488422  234.746271   2237.09391652
  338.14167251 1235.3972916  1229.64441655  614.53607139  304.01136536]
total_rewards_mean           693.1488349001845
total_rewards_std            639.6205656116102
total_rewards_max            2237.0939165197397
total_rewards_min            136.56125837218107
Number of train steps total  224000
Number of env steps total    1122000
Number of rollouts total     0
Train Time (s)               29.412406876683235
(Previous) Eval Time (s)     26.123737435322255
Sample Time (s)              18.456664081197232
Epoch Time (s)               73.99280839320272
Total Train Time (s)         15545.289501605555
Epoch                        223
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:34:37.129848 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #223 | Epoch Duration: 66.93108749389648
2020-01-11 07:34:37.130052 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #223 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93749046
Z variance train             0.024322769
KL Divergence                17.935135
KL Loss                      1.7935135
QF Loss                      413.14978
VF Loss                      78.57461
Policy Loss                  -840.55566
Q Predictions Mean           837.4485
Q Predictions Std            210.48456
Q Predictions Max            1075.3888
Q Predictions Min            198.44936
V Predictions Mean           842.53406
V Predictions Std            209.02586
V Predictions Max            1080.1627
V Predictions Min            221.34961
Log Pis Mean                 -1.1271112
Log Pis Std                  2.6177485
Log Pis Max                  9.421644
Log Pis Min                  -9.662814
Policy mu Mean               0.01176643
Policy mu Std                0.5727739
Policy mu Max                2.2183883
Policy mu Min                -2.865027
Policy log std Mean          -0.8589066
Policy log std Std           0.24825938
Policy log std Max           -0.27027333
Policy log std Min           -1.8763418
Z mean eval                  0.9136569
Z variance eval              0.021621902
total_rewards                [1967.37334416 1635.82432602 1183.82670483  366.23769795 1374.26606089
 1610.85584899   70.85212182   69.81080101  283.771744    437.79841369]
total_rewards_mean           900.0617063363783
total_rewards_std            688.9481304440313
total_rewards_max            1967.373344162491
total_rewards_min            69.81080101483357
Number of train steps total  225000
Number of env steps total    1127000
Number of rollouts total     0
Train Time (s)               29.149119480978698
(Previous) Eval Time (s)     19.061650540214032
Sample Time (s)              18.029907611198723
Epoch Time (s)               66.24067763239145
Total Train Time (s)         15606.506213911343
Epoch                        224
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:35:38.352558 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #224 | Epoch Duration: 61.22230815887451
2020-01-11 07:35:38.352916 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #224 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91369456
Z variance train             0.021674167
KL Divergence                18.814661
KL Loss                      1.8814662
QF Loss                      971.2253
VF Loss                      79.558205
Policy Loss                  -839.0036
Q Predictions Mean           837.39075
Q Predictions Std            212.42094
Q Predictions Max            1044.7859
Q Predictions Min            215.71754
V Predictions Mean           834.9824
V Predictions Std            210.67114
V Predictions Max            1036.7474
V Predictions Min            214.86694
Log Pis Mean                 -0.8280182
Log Pis Std                  2.5967412
Log Pis Max                  8.388755
Log Pis Min                  -8.087148
Policy mu Mean               0.027600214
Policy mu Std                0.57143384
Policy mu Max                2.04182
Policy mu Min                -2.2770827
Policy log std Mean          -0.8697031
Policy log std Std           0.2547841
Policy log std Max           -0.25721276
Policy log std Min           -1.856753
Z mean eval                  0.9252744
Z variance eval              0.020353753
total_rewards                [2548.44179607 2479.65712515 2617.37575136 2386.70191591  898.53074114
 2624.33201496  637.18303835  299.74755635 2327.43908462 1946.9968275 ]
total_rewards_mean           1876.640585139877
total_rewards_std            858.5193198646183
total_rewards_max            2624.3320149604087
total_rewards_min            299.74755635482654
Number of train steps total  226000
Number of env steps total    1132000
Number of rollouts total     0
Train Time (s)               28.49449265189469
(Previous) Eval Time (s)     14.042975133284926
Sample Time (s)              17.6553426948376
Epoch Time (s)               60.192810480017215
Total Train Time (s)         15675.953453442082
Epoch                        225
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:36:47.801562 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #225 | Epoch Duration: 69.4483995437622
2020-01-11 07:36:47.801810 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #225 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92705756
Z variance train             0.020275984
KL Divergence                18.776077
KL Loss                      1.8776077
QF Loss                      1619.238
VF Loss                      290.6661
Policy Loss                  -854.2941
Q Predictions Mean           847.57947
Q Predictions Std            206.76564
Q Predictions Max            1066.149
Q Predictions Min            182.9307
V Predictions Mean           840.65796
V Predictions Std            204.25488
V Predictions Max            1059.8483
V Predictions Min            188.4418
Log Pis Mean                 -0.57301825
Log Pis Std                  2.6486452
Log Pis Max                  13.022369
Log Pis Min                  -8.275018
Policy mu Mean               -0.01336365
Policy mu Std                0.5733943
Policy mu Max                2.1299152
Policy mu Min                -2.025824
Policy log std Mean          -0.8901856
Policy log std Std           0.26033682
Policy log std Max           -0.15134126
Policy log std Min           -2.1268198
Z mean eval                  0.981654
Z variance eval              0.023398394
total_rewards                [2053.06612156  237.91860566  901.31203928 -115.88443666 2559.34473596
  532.7291043   392.17336859 2434.59525874 2401.69982764  757.83325865]
total_rewards_mean           1215.4787883728434
total_rewards_std            978.8342361399658
total_rewards_max            2559.3447359629267
total_rewards_min            -115.884436662653
Number of train steps total  227000
Number of env steps total    1137000
Number of rollouts total     0
Train Time (s)               30.020164217799902
(Previous) Eval Time (s)     23.29830720881
Sample Time (s)              17.94073812616989
Epoch Time (s)               71.2592095527798
Total Train Time (s)         15748.43804164324
Epoch                        226
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:38:00.287572 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #226 | Epoch Duration: 72.48560118675232
2020-01-11 07:38:00.287755 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #226 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98162186
Z variance train             0.023420507
KL Divergence                18.673647
KL Loss                      1.8673648
QF Loss                      450.99048
VF Loss                      102.48361
Policy Loss                  -842.3549
Q Predictions Mean           841.5033
Q Predictions Std            225.27696
Q Predictions Max            1063.1108
Q Predictions Min            219.432
V Predictions Mean           848.22424
V Predictions Std            224.8701
V Predictions Max            1063.0592
V Predictions Min            236.44518
Log Pis Mean                 -1.5547327
Log Pis Std                  2.4192765
Log Pis Max                  8.002946
Log Pis Min                  -7.2453756
Policy mu Mean               0.061014
Policy mu Std                0.5286211
Policy mu Max                1.7970911
Policy mu Min                -2.6620095
Policy log std Mean          -0.84574693
Policy log std Std           0.23530088
Policy log std Max           -0.2513343
Policy log std Min           -2.0481844
Z mean eval                  0.92845076
Z variance eval              0.03262732
total_rewards                [  47.19171256 1290.41563226 1834.51189383  673.45081675  338.22792081
 1904.51635267  351.93395575 2391.70152913  121.2325556    92.33261909]
total_rewards_mean           904.5514988460945
total_rewards_std            831.4524842108991
total_rewards_max            2391.701529130529
total_rewards_min            47.19171256383579
Number of train steps total  228000
Number of env steps total    1142000
Number of rollouts total     0
Train Time (s)               29.062598083168268
(Previous) Eval Time (s)     24.524388436693698
Sample Time (s)              18.643157300539315
Epoch Time (s)               72.23014382040128
Total Train Time (s)         15815.686804668047
Epoch                        227
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:39:07.542239 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #227 | Epoch Duration: 67.25430989265442
2020-01-11 07:39:07.542484 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #227 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9250368
Z variance train             0.032602843
KL Divergence                18.034376
KL Loss                      1.8034376
QF Loss                      2709.16
VF Loss                      250.66768
Policy Loss                  -842.9089
Q Predictions Mean           839.8943
Q Predictions Std            227.44241
Q Predictions Max            1079.2368
Q Predictions Min            175.62207
V Predictions Mean           841.7057
V Predictions Std            226.13388
V Predictions Max            1077.7185
V Predictions Min            168.42834
Log Pis Mean                 -0.8948122
Log Pis Std                  2.5300004
Log Pis Max                  10.768778
Log Pis Min                  -7.7116895
Policy mu Mean               0.0028438005
Policy mu Std                0.5550159
Policy mu Max                2.8535564
Policy mu Min                -2.002683
Policy log std Mean          -0.89320934
Policy log std Std           0.28551954
Policy log std Max           -0.29363543
Policy log std Min           -2.692379
Z mean eval                  0.91205835
Z variance eval              0.022687811
total_rewards                [2379.94772056 1205.57668326 2354.02200233 2478.54120502  610.08127508
 2356.03049641 2329.7098148  2755.0543595   133.40943484 2619.28443759]
total_rewards_mean           1922.1657429387888
total_rewards_std            876.0331729152709
total_rewards_max            2755.0543595024074
total_rewards_min            133.40943483973234
Number of train steps total  229000
Number of env steps total    1147000
Number of rollouts total     0
Train Time (s)               27.832549849990755
(Previous) Eval Time (s)     19.548228680621833
Sample Time (s)              17.930450518149883
Epoch Time (s)               65.31122904876247
Total Train Time (s)         15886.237439440563
Epoch                        228
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:40:18.094293 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #228 | Epoch Duration: 70.5516152381897
2020-01-11 07:40:18.094506 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #228 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91019475
Z variance train             0.022694202
KL Divergence                18.06128
KL Loss                      1.8061279
QF Loss                      2013.354
VF Loss                      248.75926
Policy Loss                  -858.71405
Q Predictions Mean           856.98816
Q Predictions Std            206.52283
Q Predictions Max            1072.3768
Q Predictions Min            153.83926
V Predictions Mean           867.09735
V Predictions Std            204.93277
V Predictions Max            1074.5107
V Predictions Min            29.666124
Log Pis Mean                 -0.7039119
Log Pis Std                  2.6992962
Log Pis Max                  12.091978
Log Pis Min                  -10.46785
Policy mu Mean               0.001063617
Policy mu Std                0.5560648
Policy mu Max                2.025539
Policy mu Min                -3.1367114
Policy log std Mean          -0.9100698
Policy log std Std           0.25699154
Policy log std Max           -0.16548389
Policy log std Min           -2.0650413
Z mean eval                  0.9203684
Z variance eval              0.027721401
total_rewards                [2562.63906623 1033.13131059  538.06881697 1588.82742082 2351.41257206
 2658.92404091 2660.53614542 2290.12675259 1239.23996176  556.75176959]
total_rewards_mean           1747.965785694066
total_rewards_std            816.2331476492619
total_rewards_max            2660.536145422041
total_rewards_min            538.0688169710055
Number of train steps total  230000
Number of env steps total    1152000
Number of rollouts total     0
Train Time (s)               29.800752037670463
(Previous) Eval Time (s)     24.7883133739233
Sample Time (s)              17.509353656787425
Epoch Time (s)               72.09841906838119
Total Train Time (s)         15952.60121538397
Epoch                        229
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:41:24.463964 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #229 | Epoch Duration: 66.36925101280212
2020-01-11 07:41:24.464256 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #229 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91989976
Z variance train             0.027716005
KL Divergence                18.033333
KL Loss                      1.8033333
QF Loss                      816.5305
VF Loss                      137.99306
Policy Loss                  -898.3069
Q Predictions Mean           897.17993
Q Predictions Std            169.05388
Q Predictions Max            1105.1049
Q Predictions Min            215.50974
V Predictions Mean           890.7461
V Predictions Std            167.625
V Predictions Max            1096.3989
V Predictions Min            214.943
Log Pis Mean                 -0.95398754
Log Pis Std                  2.6050642
Log Pis Max                  5.406732
Log Pis Min                  -9.362825
Policy mu Mean               -0.021483228
Policy mu Std                0.5608888
Policy mu Max                1.7009593
Policy mu Min                -1.7945235
Policy log std Mean          -0.88994515
Policy log std Std           0.23671593
Policy log std Max           -0.27770928
Policy log std Min           -1.801943
Z mean eval                  0.923089
Z variance eval              0.033486355
total_rewards                [2456.52748702 1592.00973415 2599.43455085 2440.37147677 2232.23413693
   74.21418933 2440.13234233 2494.39399912  138.30978998  309.95320689]
total_rewards_mean           1677.7580913358192
total_rewards_std            1020.4213803039936
total_rewards_max            2599.434550853751
total_rewards_min            74.21418933244863
Number of train steps total  231000
Number of env steps total    1157000
Number of rollouts total     0
Train Time (s)               28.170271749142557
(Previous) Eval Time (s)     19.05885041691363
Sample Time (s)              19.11378706758842
Epoch Time (s)               66.3429092336446
Total Train Time (s)         16019.805853934027
Epoch                        230
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:42:31.669146 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #230 | Epoch Duration: 67.20465302467346
2020-01-11 07:42:31.669338 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #230 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92314684
Z variance train             0.03350187
KL Divergence                18.132278
KL Loss                      1.8132279
QF Loss                      2694.8228
VF Loss                      151.33786
Policy Loss                  -850.9246
Q Predictions Mean           846.3528
Q Predictions Std            207.17007
Q Predictions Max            1063.4609
Q Predictions Min            93.68702
V Predictions Mean           852.8944
V Predictions Std            203.22891
V Predictions Max            1067.0903
V Predictions Min            212.91208
Log Pis Mean                 -1.0755652
Log Pis Std                  2.793683
Log Pis Max                  11.046738
Log Pis Min                  -12.295298
Policy mu Mean               0.047238827
Policy mu Std                0.5618612
Policy mu Max                2.0302832
Policy mu Min                -2.4063277
Policy log std Mean          -0.87856567
Policy log std Std           0.26683146
Policy log std Max           -0.21510988
Policy log std Min           -2.3919735
Z mean eval                  0.94813406
Z variance eval              0.025260508
total_rewards                [2453.07416568 2533.17967925 2568.70007881 2116.60023387 2116.19402886
 1259.70959882 2047.85862502 2140.52883897 2499.68365731 2715.6911649 ]
total_rewards_mean           2245.1220071499065
total_rewards_std            396.38258212753834
total_rewards_max            2715.6911649023655
total_rewards_min            1259.7095988244673
Number of train steps total  232000
Number of env steps total    1162000
Number of rollouts total     0
Train Time (s)               27.31170838791877
(Previous) Eval Time (s)     19.920290583744645
Sample Time (s)              18.586598872672766
Epoch Time (s)               65.81859784433618
Total Train Time (s)         16090.204400309362
Epoch                        231
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:43:42.071330 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #231 | Epoch Duration: 70.4018383026123
2020-01-11 07:43:42.071551 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #231 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9487171
Z variance train             0.025373623
KL Divergence                19.433857
KL Loss                      1.9433857
QF Loss                      561.36487
VF Loss                      193.94096
Policy Loss                  -855.43463
Q Predictions Mean           854.9358
Q Predictions Std            213.34668
Q Predictions Max            1075.6041
Q Predictions Min            221.63835
V Predictions Mean           860.71106
V Predictions Std            213.40805
V Predictions Max            1071.6904
V Predictions Min            216.09567
Log Pis Mean                 -0.79476994
Log Pis Std                  2.4518855
Log Pis Max                  8.317295
Log Pis Min                  -9.8723545
Policy mu Mean               0.05016307
Policy mu Std                0.54279256
Policy mu Max                1.9017622
Policy mu Min                -2.3266168
Policy log std Mean          -0.90368354
Policy log std Std           0.25619972
Policy log std Max           -0.11162126
Policy log std Min           -2.153827
Z mean eval                  0.94387037
Z variance eval              0.027456308
total_rewards                [ 466.53516618  110.21934179 2504.84609365 2460.75030651 2090.31579784
 2196.97435727 2537.48825308 2371.4159792  2509.175921   2517.28193208]
total_rewards_mean           1976.500314860122
total_rewards_std            859.3639166427015
total_rewards_max            2537.4882530795185
total_rewards_min            110.21934178950758
Number of train steps total  233000
Number of env steps total    1167000
Number of rollouts total     0
Train Time (s)               29.792110482230783
(Previous) Eval Time (s)     24.503184537403286
Sample Time (s)              19.536089454311877
Epoch Time (s)               73.83138447394595
Total Train Time (s)         16163.817209887784
Epoch                        232
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:44:55.685616 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #232 | Epoch Duration: 73.61390423774719
2020-01-11 07:44:55.685771 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #232 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94447595
Z variance train             0.027416756
KL Divergence                18.951515
KL Loss                      1.8951515
QF Loss                      586.92285
VF Loss                      280.0288
Policy Loss                  -876.40826
Q Predictions Mean           874.82983
Q Predictions Std            197.70332
Q Predictions Max            1094.0547
Q Predictions Min            210.69334
V Predictions Mean           890.0152
V Predictions Std            196.78296
V Predictions Max            1110.0778
V Predictions Min            223.92195
Log Pis Mean                 -1.1550047
Log Pis Std                  2.3625703
Log Pis Max                  5.020261
Log Pis Min                  -9.083185
Policy mu Mean               0.05947338
Policy mu Std                0.56150395
Policy mu Max                1.8174933
Policy mu Min                -1.7410431
Policy log std Mean          -0.88496923
Policy log std Std           0.23535351
Policy log std Max           -0.27407044
Policy log std Min           -1.8603656
Z mean eval                  0.9547799
Z variance eval              0.03211764
total_rewards                [1018.20922969 2106.54541255  183.16494059 2351.09909373  143.52272667
 2151.76152791  864.7356517   958.23793809 1419.43744705  209.71639787]
total_rewards_mean           1140.643036583699
total_rewards_std            800.017647208707
total_rewards_max            2351.0990937270217
total_rewards_min            143.52272666981648
Number of train steps total  234000
Number of env steps total    1172000
Number of rollouts total     0
Train Time (s)               29.919786021113396
(Previous) Eval Time (s)     24.28535736259073
Sample Time (s)              18.607818891759962
Epoch Time (s)               72.81296227546409
Total Train Time (s)         16233.780147992074
Epoch                        233
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:46:05.652924 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #233 | Epoch Duration: 69.96701908111572
2020-01-11 07:46:05.653128 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #233 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95348614
Z variance train             0.03213029
KL Divergence                18.658949
KL Loss                      1.8658949
QF Loss                      693.5288
VF Loss                      83.65359
Policy Loss                  -872.024
Q Predictions Mean           870.979
Q Predictions Std            234.94759
Q Predictions Max            1101.5432
Q Predictions Min            209.16667
V Predictions Mean           871.2866
V Predictions Std            234.02538
V Predictions Max            1090.5815
V Predictions Min            225.36995
Log Pis Mean                 -0.9741608
Log Pis Std                  2.34593
Log Pis Max                  5.4712353
Log Pis Min                  -8.617279
Policy mu Mean               0.057672527
Policy mu Std                0.5609868
Policy mu Max                2.1191506
Policy mu Min                -2.37908
Policy log std Mean          -0.8669294
Policy log std Std           0.26083255
Policy log std Max           -0.20655382
Policy log std Min           -2.1280048
Z mean eval                  0.92606336
Z variance eval              0.020759046
total_rewards                [2449.25149704   67.48646409  168.66940601 2391.6448842  2341.50170104
  681.62137164 2464.33175506 2633.35029788 2581.13511224  536.76554066]
total_rewards_mean           1631.5758029862616
total_rewards_std            1050.5467311939788
total_rewards_max            2633.350297875907
total_rewards_min            67.48646408668391
Number of train steps total  235000
Number of env steps total    1177000
Number of rollouts total     0
Train Time (s)               28.53042808594182
(Previous) Eval Time (s)     21.43909792881459
Sample Time (s)              17.925816202070564
Epoch Time (s)               67.89534221682698
Total Train Time (s)         16300.515857206192
Epoch                        234
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:47:12.391859 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #234 | Epoch Duration: 66.73852896690369
2020-01-11 07:47:12.392107 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #234 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9226878
Z variance train             0.020677451
KL Divergence                19.307821
KL Loss                      1.9307822
QF Loss                      617.7543
VF Loss                      140.99167
Policy Loss                  -834.87604
Q Predictions Mean           830.46606
Q Predictions Std            246.76636
Q Predictions Max            1071.7705
Q Predictions Min            -42.778374
V Predictions Mean           833.8989
V Predictions Std            244.87611
V Predictions Max            1080.8641
V Predictions Min            21.176619
Log Pis Mean                 -1.0376773
Log Pis Std                  2.8892283
Log Pis Max                  12.868138
Log Pis Min                  -8.117537
Policy mu Mean               0.011214128
Policy mu Std                0.55234975
Policy mu Max                1.9714632
Policy mu Min                -2.7544994
Policy log std Mean          -0.8731276
Policy log std Std           0.30051216
Policy log std Max           -0.24227345
Policy log std Min           -2.9539776
Z mean eval                  0.92460716
Z variance eval              0.028665274
total_rewards                [2338.97943326 2559.17924558 2362.71230621 2512.71519683 2625.63051348
 2330.2878741  2658.9211787  2480.04116178 2564.4033351   211.48153675]
total_rewards_mean           2264.435178178156
total_rewards_std            693.1980679705587
total_rewards_max            2658.921178699514
total_rewards_min            211.48153675085288
Number of train steps total  236000
Number of env steps total    1182000
Number of rollouts total     0
Train Time (s)               29.92368688667193
(Previous) Eval Time (s)     20.281927614938468
Sample Time (s)              19.082693099975586
Epoch Time (s)               69.28830760158598
Total Train Time (s)         16376.853166677058
Epoch                        235
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:48:28.730723 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #235 | Epoch Duration: 76.3384051322937
2020-01-11 07:48:28.730936 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #235 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92395514
Z variance train             0.028751556
KL Divergence                18.1916
KL Loss                      1.8191601
QF Loss                      805.85266
VF Loss                      142.9092
Policy Loss                  -875.96356
Q Predictions Mean           875.1934
Q Predictions Std            218.02007
Q Predictions Max            1087.4946
Q Predictions Min            16.324814
V Predictions Mean           876.0127
V Predictions Std            217.48543
V Predictions Max            1083.6952
V Predictions Min            40.549244
Log Pis Mean                 -0.9335752
Log Pis Std                  2.6137292
Log Pis Max                  10.710255
Log Pis Min                  -9.163162
Policy mu Mean               -0.0086597325
Policy mu Std                0.5446572
Policy mu Max                1.7443776
Policy mu Min                -3.5917652
Policy log std Mean          -0.9080618
Policy log std Std           0.25775385
Policy log std Max           -0.25101638
Policy log std Min           -2.4548185
Z mean eval                  0.9175102
Z variance eval              0.026960135
total_rewards                [2393.69915036 1432.13798542 2475.53036218 2331.12472814 2364.22929179
 2493.80751692  365.89039365 2403.68342288 1720.86917368  715.78252345]
total_rewards_mean           1869.6754548454464
total_rewards_std            747.0144594557341
total_rewards_max            2493.8075169201074
total_rewards_min            365.89039364873554
Number of train steps total  237000
Number of env steps total    1187000
Number of rollouts total     0
Train Time (s)               29.768539554905146
(Previous) Eval Time (s)     27.33171678520739
Sample Time (s)              18.039172504097223
Epoch Time (s)               75.13942884420976
Total Train Time (s)         16451.15907862829
Epoch                        236
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:49:43.039534 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #236 | Epoch Duration: 74.30843305587769
2020-01-11 07:49:43.039705 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #236 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91694593
Z variance train             0.026947614
KL Divergence                18.094028
KL Loss                      1.8094028
QF Loss                      3389.8027
VF Loss                      147.08281
Policy Loss                  -847.45026
Q Predictions Mean           847.6128
Q Predictions Std            227.63483
Q Predictions Max            1082.5323
Q Predictions Min            166.2647
V Predictions Mean           848.9758
V Predictions Std            228.82222
V Predictions Max            1090.2217
V Predictions Min            95.570755
Log Pis Mean                 -1.0085747
Log Pis Std                  2.6481757
Log Pis Max                  11.157551
Log Pis Min                  -9.709049
Policy mu Mean               0.057696484
Policy mu Std                0.55623215
Policy mu Max                2.2823532
Policy mu Min                -2.8908389
Policy log std Mean          -0.8784978
Policy log std Std           0.26841566
Policy log std Max           -0.19126701
Policy log std Min           -2.5670805
Z mean eval                  0.9167549
Z variance eval              0.013845904
total_rewards                [ -27.09079031 2479.88172784 1243.16762704 1497.46654987 2491.51773265
  812.25154158  816.73318426  466.07435819  396.00684431  227.89608833]
total_rewards_mean           1040.3904863746304
total_rewards_std            841.1150396242894
total_rewards_max            2491.5177326485286
total_rewards_min            -27.090790306539375
Number of train steps total  238000
Number of env steps total    1192000
Number of rollouts total     0
Train Time (s)               30.76295567676425
(Previous) Eval Time (s)     26.500440466683358
Sample Time (s)              17.964437508024275
Epoch Time (s)               75.22783365147188
Total Train Time (s)         16515.87262905063
Epoch                        237
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:50:47.760826 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #237 | Epoch Duration: 64.72094631195068
2020-01-11 07:50:47.761128 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #237 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91776884
Z variance train             0.013848138
KL Divergence                19.020594
KL Loss                      1.9020594
QF Loss                      2354.4631
VF Loss                      136.37617
Policy Loss                  -871.6082
Q Predictions Mean           871.38477
Q Predictions Std            192.63985
Q Predictions Max            1079.733
Q Predictions Min            226.7762
V Predictions Mean           868.6595
V Predictions Std            190.83728
V Predictions Max            1065.7261
V Predictions Min            234.14694
Log Pis Mean                 -0.6515087
Log Pis Std                  2.566628
Log Pis Max                  6.867543
Log Pis Min                  -8.52327
Policy mu Mean               0.036140583
Policy mu Std                0.56612414
Policy mu Max                2.1106708
Policy mu Min                -2.0340884
Policy log std Mean          -0.907969
Policy log std Std           0.25834283
Policy log std Max           -0.26996148
Policy log std Min           -2.185688
Z mean eval                  0.92575055
Z variance eval              0.020540796
total_rewards                [2423.29098922 1537.80799446 2385.87011613 2079.19721458 2525.85224761
 2321.36651056 1704.23818041  240.38452368   59.13322501 2582.88420723]
total_rewards_mean           1786.0025208887237
total_rewards_std            880.9229241163138
total_rewards_max            2582.884207228649
total_rewards_min            59.13322501232846
Number of train steps total  239000
Number of env steps total    1197000
Number of rollouts total     0
Train Time (s)               29.242495893035084
(Previous) Eval Time (s)     15.993195435963571
Sample Time (s)              18.60471291327849
Epoch Time (s)               63.840404242277145
Total Train Time (s)         16586.165507470258
Epoch                        238
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:51:58.052310 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #238 | Epoch Duration: 70.29093194007874
2020-01-11 07:51:58.052508 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #238 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9259178
Z variance train             0.020543773
KL Divergence                18.582336
KL Loss                      1.8582337
QF Loss                      776.50146
VF Loss                      59.18593
Policy Loss                  -862.619
Q Predictions Mean           860.4193
Q Predictions Std            235.78293
Q Predictions Max            1082.0684
Q Predictions Min            -53.02841
V Predictions Mean           866.4869
V Predictions Std            233.88759
V Predictions Max            1089.933
V Predictions Min            24.761454
Log Pis Mean                 -1.2439322
Log Pis Std                  2.3841915
Log Pis Max                  6.399221
Log Pis Min                  -9.462927
Policy mu Mean               0.049122505
Policy mu Std                0.5589335
Policy mu Max                1.9004985
Policy mu Min                -2.2823858
Policy log std Mean          -0.8565633
Policy log std Std           0.23408434
Policy log std Max           -0.21092623
Policy log std Min           -1.8323127
Z mean eval                  0.9141979
Z variance eval              0.018110137
total_rewards                [ -25.8934468  1907.39636297  873.70382012 1712.87705017 1438.04847718
 2471.90848957 2402.90174094 2281.87302207 2543.08409753 2260.31796689]
total_rewards_mean           1786.6217580631135
total_rewards_std            784.313378313766
total_rewards_max            2543.0840975262836
total_rewards_min            -25.89344680020273
Number of train steps total  240000
Number of env steps total    1202000
Number of rollouts total     0
Train Time (s)               27.56171403825283
(Previous) Eval Time (s)     22.443370413035154
Sample Time (s)              17.96428428031504
Epoch Time (s)               67.96936873160303
Total Train Time (s)         16655.156342037953
Epoch                        239
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:53:07.049342 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #239 | Epoch Duration: 68.99666571617126
2020-01-11 07:53:07.049617 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #239 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9161021
Z variance train             0.018077785
KL Divergence                18.822546
KL Loss                      1.8822546
QF Loss                      675.7075
VF Loss                      354.84177
Policy Loss                  -865.1475
Q Predictions Mean           861.61554
Q Predictions Std            228.33687
Q Predictions Max            1065.7267
Q Predictions Min            148.26912
V Predictions Mean           854.80054
V Predictions Std            225.15446
V Predictions Max            1060.0963
V Predictions Min            192.72966
Log Pis Mean                 -0.79853517
Log Pis Std                  2.2763014
Log Pis Max                  7.8523026
Log Pis Min                  -6.0916386
Policy mu Mean               -0.028463943
Policy mu Std                0.5614306
Policy mu Max                2.6091104
Policy mu Min                -2.3750253
Policy log std Mean          -0.8858993
Policy log std Std           0.2552359
Policy log std Max           -0.27007908
Policy log std Min           -1.9561714
Z mean eval                  0.93567026
Z variance eval              0.024351873
total_rewards                [2317.9594825  2328.14023434 2473.93112532 1917.9322927  2556.06769913
 2379.13836659 2561.7016233  1119.67619625  475.15381843 1471.71362076]
total_rewards_mean           1960.1414459312896
total_rewards_std            676.159101008116
total_rewards_max            2561.7016232989386
total_rewards_min            475.1538184275004
Number of train steps total  241000
Number of env steps total    1207000
Number of rollouts total     0
Train Time (s)               28.466538733337075
(Previous) Eval Time (s)     23.470369229093194
Sample Time (s)              18.723596394993365
Epoch Time (s)               70.66050435742363
Total Train Time (s)         16729.246614432894
Epoch                        240
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:54:21.139962 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #240 | Epoch Duration: 74.09014058113098
2020-01-11 07:54:21.140129 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #240 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.934855
Z variance train             0.024463544
KL Divergence                18.718185
KL Loss                      1.8718185
QF Loss                      719.3566
VF Loss                      108.4
Policy Loss                  -886.5573
Q Predictions Mean           887.4689
Q Predictions Std            212.87627
Q Predictions Max            1089.9382
Q Predictions Min            216.155
V Predictions Mean           881.7864
V Predictions Std            210.68626
V Predictions Max            1084.747
V Predictions Min            214.82474
Log Pis Mean                 -0.76414543
Log Pis Std                  2.4371269
Log Pis Max                  6.7055864
Log Pis Min                  -6.5195947
Policy mu Mean               0.026045006
Policy mu Std                0.57097477
Policy mu Max                2.386206
Policy mu Min                -2.0089734
Policy log std Mean          -0.89183164
Policy log std Std           0.26828775
Policy log std Max           -0.28032345
Policy log std Min           -2.510981
Z mean eval                  0.96724796
Z variance eval              0.019093374
total_rewards                [1429.50274073 2402.22208869 1339.93249324 2419.99133563 2199.3008643
 2592.07530796 1439.61326462 1521.7208105  2662.26918696 1478.68896276]
total_rewards_mean           1948.531705539177
total_rewards_std            521.178056738443
total_rewards_max            2662.2691869586383
total_rewards_min            1339.9324932398656
Number of train steps total  242000
Number of env steps total    1212000
Number of rollouts total     0
Train Time (s)               30.351242681965232
(Previous) Eval Time (s)     26.899706471245736
Sample Time (s)              18.808598613832146
Epoch Time (s)               76.05954776704311
Total Train Time (s)         16804.027149961796
Epoch                        241
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:55:35.928683 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #241 | Epoch Duration: 74.78837871551514
2020-01-11 07:55:35.929007 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #241 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9678152
Z variance train             0.019130567
KL Divergence                19.18555
KL Loss                      1.9185551
QF Loss                      856.3222
VF Loss                      146.04062
Policy Loss                  -859.6999
Q Predictions Mean           857.29736
Q Predictions Std            232.89159
Q Predictions Max            1054.3989
Q Predictions Min            216.98288
V Predictions Mean           862.05273
V Predictions Std            234.24654
V Predictions Max            1050.5956
V Predictions Min            214.35141
Log Pis Mean                 -1.1726682
Log Pis Std                  2.4236436
Log Pis Max                  9.41299
Log Pis Min                  -8.184031
Policy mu Mean               -0.065621495
Policy mu Std                0.5436402
Policy mu Max                2.1874952
Policy mu Min                -2.0277183
Policy log std Mean          -0.87105006
Policy log std Std           0.27296472
Policy log std Max           -0.22068033
Policy log std Min           -1.8953905
Z mean eval                  0.93447447
Z variance eval              0.024046373
total_rewards                [2682.51174065 1623.88559441 2666.73474716 1696.08418686 1129.45642895
 2068.32831666 2622.08425534 2883.42416399  496.10377874 2612.50866055]
total_rewards_mean           2048.112187330062
total_rewards_std            754.1783069564478
total_rewards_max            2883.424163988776
total_rewards_min            496.10377874155336
Number of train steps total  243000
Number of env steps total    1217000
Number of rollouts total     0
Train Time (s)               29.60092037776485
(Previous) Eval Time (s)     25.62809456884861
Sample Time (s)              19.113515711855143
Epoch Time (s)               74.3425306584686
Total Train Time (s)         16876.760841942392
Epoch                        242
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:56:48.666376 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #242 | Epoch Duration: 72.7371153831482
2020-01-11 07:56:48.666633 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #242 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93588513
Z variance train             0.024099652
KL Divergence                19.369547
KL Loss                      1.9369547
QF Loss                      458.3742
VF Loss                      122.97567
Policy Loss                  -882.27405
Q Predictions Mean           880.3296
Q Predictions Std            208.96896
Q Predictions Max            1078.0721
Q Predictions Min            100.2208
V Predictions Mean           882.5998
V Predictions Std            206.72406
V Predictions Max            1074.4629
V Predictions Min            164.13931
Log Pis Mean                 -0.659799
Log Pis Std                  2.5024707
Log Pis Max                  8.661798
Log Pis Min                  -7.843589
Policy mu Mean               -0.01851742
Policy mu Std                0.5387945
Policy mu Max                2.0275943
Policy mu Min                -2.0359364
Policy log std Mean          -0.93394405
Policy log std Std           0.28805912
Policy log std Max           -0.22492546
Policy log std Min           -2.6974554
Z mean eval                  0.91299057
Z variance eval              0.017941229
total_rewards                [ 997.46554713  428.39627568 2355.81034688 2081.48687546  789.9118435
  416.70307239  880.20476917 1186.49874649 1041.93054144 2467.47164141]
total_rewards_mean           1264.587965955026
total_rewards_std            722.7199381503664
total_rewards_max            2467.471641409008
total_rewards_min            416.70307238584303
Number of train steps total  244000
Number of env steps total    1222000
Number of rollouts total     0
Train Time (s)               29.8542733611539
(Previous) Eval Time (s)     24.022348961792886
Sample Time (s)              18.108993301633745
Epoch Time (s)               71.98561562458053
Total Train Time (s)         16944.395703725517
Epoch                        243
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:57:56.306155 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #243 | Epoch Duration: 67.6391909122467
2020-01-11 07:57:56.306565 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #243 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91547954
Z variance train             0.017938029
KL Divergence                19.783312
KL Loss                      1.9783312
QF Loss                      442.56415
VF Loss                      213.9078
Policy Loss                  -876.2862
Q Predictions Mean           870.90076
Q Predictions Std            233.20142
Q Predictions Max            1093.7684
Q Predictions Min            -89.513336
V Predictions Mean           869.6437
V Predictions Std            229.92938
V Predictions Max            1075.3048
V Predictions Min            -9.078875
Log Pis Mean                 -1.2117219
Log Pis Std                  2.4132934
Log Pis Max                  5.6706796
Log Pis Min                  -8.137093
Policy mu Mean               0.07374394
Policy mu Std                0.52144414
Policy mu Max                1.8923658
Policy mu Min                -1.6465585
Policy log std Mean          -0.888872
Policy log std Std           0.26287088
Policy log std Max           -0.18041608
Policy log std Min           -1.9675432
Z mean eval                  0.9361016
Z variance eval              0.01661494
total_rewards                [2761.51090296 1580.17854103  142.44135687 1563.32921392 2307.94585312
  869.09087042 2462.83438896 2745.02857896 2669.82633776 1189.0748407 ]
total_rewards_mean           1829.1260884716182
total_rewards_std            857.596161607723
total_rewards_max            2761.5109029604255
total_rewards_min            142.4413568711096
Number of train steps total  245000
Number of env steps total    1227000
Number of rollouts total     0
Train Time (s)               27.074757282156497
(Previous) Eval Time (s)     19.675610238220543
Sample Time (s)              18.908982569817454
Epoch Time (s)               65.6593500901945
Total Train Time (s)         17014.89533511363
Epoch                        244
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:59:06.807289 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #244 | Epoch Duration: 70.50050592422485
2020-01-11 07:59:06.807483 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #244 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93390894
Z variance train             0.016607486
KL Divergence                20.40672
KL Loss                      2.040672
QF Loss                      824.6384
VF Loss                      102.19244
Policy Loss                  -893.64636
Q Predictions Mean           892.29694
Q Predictions Std            228.65637
Q Predictions Max            1084.3021
Q Predictions Min            72.19458
V Predictions Mean           897.823
V Predictions Std            230.8403
V Predictions Max            1080.9226
V Predictions Min            0.55825555
Log Pis Mean                 -0.8780793
Log Pis Std                  2.656591
Log Pis Max                  13.503624
Log Pis Min                  -6.844331
Policy mu Mean               -0.019897513
Policy mu Std                0.5864003
Policy mu Max                2.36396
Policy mu Min                -2.143478
Policy log std Mean          -0.8732109
Policy log std Std           0.26942235
Policy log std Max           0.55272704
Policy log std Min           -1.9617503
Z mean eval                  0.9474513
Z variance eval              0.027131319
total_rewards                [ 348.00341875 2005.84685497  104.78258074  488.47531104 1328.04401988
 2556.40203341 2371.63879679   98.45415322 2428.87786861 2686.0906575 ]
total_rewards_mean           1441.6615694907637
total_rewards_std            1032.376941485801
total_rewards_max            2686.090657501207
total_rewards_min            98.45415322212813
Number of train steps total  246000
Number of env steps total    1232000
Number of rollouts total     0
Train Time (s)               31.09782271878794
(Previous) Eval Time (s)     24.51645251410082
Sample Time (s)              17.590647883713245
Epoch Time (s)               73.204923116602
Total Train Time (s)         17082.863311520778
Epoch                        245
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:00:14.777179 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #245 | Epoch Duration: 67.96950650215149
2020-01-11 08:00:14.777444 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #245 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9495875
Z variance train             0.02734389
KL Divergence                18.446524
KL Loss                      1.8446524
QF Loss                      900.0399
VF Loss                      368.12128
Policy Loss                  -872.7542
Q Predictions Mean           871.78986
Q Predictions Std            238.32224
Q Predictions Max            1089.475
Q Predictions Min            213.83105
V Predictions Mean           886.8794
V Predictions Std            238.74405
V Predictions Max            1100.5553
V Predictions Min            213.4425
Log Pis Mean                 -0.9878991
Log Pis Std                  2.6940753
Log Pis Max                  7.7957497
Log Pis Min                  -8.419519
Policy mu Mean               0.006849708
Policy mu Std                0.56122893
Policy mu Max                1.7756138
Policy mu Min                -2.8177884
Policy log std Mean          -0.8843515
Policy log std Std           0.2681175
Policy log std Max           -0.21539813
Policy log std Min           -2.2024732
Z mean eval                  0.9252349
Z variance eval              0.03635185
total_rewards                [ -33.20314946 2132.17843261 2525.22171065 2490.80929745 2713.21927639
  641.18978179 2669.07704896 2491.0188345  1502.78370664 2464.27231353]
total_rewards_mean           1959.6567253079454
total_rewards_std            903.2411284265617
total_rewards_max            2713.2192763943603
total_rewards_min            -33.20314945938235
Number of train steps total  247000
Number of env steps total    1237000
Number of rollouts total     0
Train Time (s)               29.071815295144916
(Previous) Eval Time (s)     19.280711516272277
Sample Time (s)              18.308447387069464
Epoch Time (s)               66.66097419848666
Total Train Time (s)         17156.531640710775
Epoch                        246
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:01:28.447073 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #246 | Epoch Duration: 73.66947412490845
2020-01-11 08:01:28.447273 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #246 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92302144
Z variance train             0.036803864
KL Divergence                17.063265
KL Loss                      1.7063265
QF Loss                      691.8236
VF Loss                      230.6611
Policy Loss                  -893.92175
Q Predictions Mean           889.3595
Q Predictions Std            234.98196
Q Predictions Max            1120.3484
Q Predictions Min            22.20405
V Predictions Mean           884.6437
V Predictions Std            233.42838
V Predictions Max            1095.4895
V Predictions Min            13.525678
Log Pis Mean                 -1.0957136
Log Pis Std                  2.5449362
Log Pis Max                  8.295882
Log Pis Min                  -9.225952
Policy mu Mean               0.021498784
Policy mu Std                0.51721776
Policy mu Max                1.9084185
Policy mu Min                -2.0526884
Policy log std Mean          -0.90725356
Policy log std Std           0.29540712
Policy log std Max           -0.2226212
Policy log std Min           -2.5323744
Z mean eval                  0.92721385
Z variance eval              0.027410096
total_rewards                [2534.79071062 2421.03092273 1503.72348089 1635.00775249  616.13582041
  608.73404861 2811.90109014  627.3955128  1324.15952151 2861.48578586]
total_rewards_mean           1694.436464607136
total_rewards_std            866.1369816419368
total_rewards_max            2861.4857858553237
total_rewards_min            608.7340486136297
Number of train steps total  248000
Number of env steps total    1242000
Number of rollouts total     0
Train Time (s)               28.24726201593876
(Previous) Eval Time (s)     26.288922999054193
Sample Time (s)              17.74338366277516
Epoch Time (s)               72.27956867776811
Total Train Time (s)         17225.98938885238
Epoch                        247
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:02:37.908133 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #247 | Epoch Duration: 69.46070528030396
2020-01-11 08:02:37.908328 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #247 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9247314
Z variance train             0.027466753
KL Divergence                17.402533
KL Loss                      1.7402533
QF Loss                      887.06024
VF Loss                      89.31756
Policy Loss                  -911.62695
Q Predictions Mean           908.6611
Q Predictions Std            216.20866
Q Predictions Max            1105.6494
Q Predictions Min            -24.318949
V Predictions Mean           908.3584
V Predictions Std            215.04579
V Predictions Max            1117.8622
V Predictions Min            58.205643
Log Pis Mean                 -0.9198636
Log Pis Std                  2.4527397
Log Pis Max                  6.6362877
Log Pis Min                  -7.6783214
Policy mu Mean               0.044838578
Policy mu Std                0.56051755
Policy mu Max                2.6646624
Policy mu Min                -2.1802428
Policy log std Mean          -0.9009171
Policy log std Std           0.25781897
Policy log std Max           -0.12001526
Policy log std Min           -2.1470733
Z mean eval                  0.93986005
Z variance eval              0.024759984
total_rewards                [2444.86364977 1223.46498136 2631.28258415 1870.81879934 2518.34443334
  380.66763683  542.65689774 -104.14213498   70.80832693  368.42775681]
total_rewards_mean           1194.7192931291218
total_rewards_std            1027.488949293791
total_rewards_max            2631.282584149887
total_rewards_min            -104.14213497736563
Number of train steps total  249000
Number of env steps total    1247000
Number of rollouts total     0
Train Time (s)               29.67462343722582
(Previous) Eval Time (s)     23.469773364253342
Sample Time (s)              18.401101747062057
Epoch Time (s)               71.54549854854122
Total Train Time (s)         17289.95708027389
Epoch                        248
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:03:41.880649 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #248 | Epoch Duration: 63.97214603424072
2020-01-11 08:03:41.880910 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #248 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9365717
Z variance train             0.024676982
KL Divergence                17.996782
KL Loss                      1.7996782
QF Loss                      631.28
VF Loss                      119.38758
Policy Loss                  -912.5642
Q Predictions Mean           910.65906
Q Predictions Std            224.4157
Q Predictions Max            1125.1448
Q Predictions Min            -1.1237154
V Predictions Mean           918.9562
V Predictions Std            222.34587
V Predictions Max            1123.5726
V Predictions Min            37.523537
Log Pis Mean                 -0.70512664
Log Pis Std                  2.341211
Log Pis Max                  8.061026
Log Pis Min                  -7.6862183
Policy mu Mean               -0.0067550903
Policy mu Std                0.5478292
Policy mu Max                2.0626774
Policy mu Min                -1.9113902
Policy log std Mean          -0.91291225
Policy log std Std           0.24769886
Policy log std Max           -0.1966967
Policy log std Min           -2.1856816
Z mean eval                  0.94765884
Z variance eval              0.02200008
total_rewards                [ 392.69172248 1640.06847946 2649.51270225  920.12542629 2445.96976122
  488.15564007 2618.19472013  826.75619855  165.26975044 1853.59166844]
total_rewards_mean           1400.0336069329765
total_rewards_std            912.8136901963834
total_rewards_max            2649.512702251577
total_rewards_min            165.26975044434477
Number of train steps total  250000
Number of env steps total    1252000
Number of rollouts total     0
Train Time (s)               27.34389538085088
(Previous) Eval Time (s)     15.896087189670652
Sample Time (s)              18.442212029360235
Epoch Time (s)               61.68219459988177
Total Train Time (s)         17358.24344996875
Epoch                        249
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:04:50.169860 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #249 | Epoch Duration: 68.28875041007996
2020-01-11 08:04:50.170041 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #249 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94873685
Z variance train             0.021986105
KL Divergence                18.487553
KL Loss                      1.8487552
QF Loss                      864.0531
VF Loss                      212.73207
Policy Loss                  -896.11615
Q Predictions Mean           896.00006
Q Predictions Std            230.13423
Q Predictions Max            1113.6277
Q Predictions Min            184.87746
V Predictions Mean           905.3037
V Predictions Std            230.08817
V Predictions Max            1130.2028
V Predictions Min            213.85753
Log Pis Mean                 -0.77122045
Log Pis Std                  2.608098
Log Pis Max                  6.968402
Log Pis Min                  -9.727021
Policy mu Mean               0.019139115
Policy mu Std                0.55602723
Policy mu Max                1.9995441
Policy mu Min                -2.0016105
Policy log std Mean          -0.8973024
Policy log std Std           0.25918734
Policy log std Max           -0.18904263
Policy log std Min           -2.004994
Z mean eval                  0.9392859
Z variance eval              0.036138322
total_rewards                [ 789.01752322 1105.43859018 1810.52486591 1903.06109997 2558.60225392
 2595.55756882 2566.31038292 2522.48860589 1860.8929106  2614.76241758]
total_rewards_mean           2032.6656219006643
total_rewards_std            629.2103721781617
total_rewards_max            2614.762417575725
total_rewards_min            789.0175232219351
Number of train steps total  251000
Number of env steps total    1257000
Number of rollouts total     0
Train Time (s)               28.871503327973187
(Previous) Eval Time (s)     22.502339004073292
Sample Time (s)              18.20539720263332
Epoch Time (s)               69.5792395346798
Total Train Time (s)         17430.198141679168
Epoch                        250
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:06:02.128130 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #250 | Epoch Duration: 71.95792889595032
2020-01-11 08:06:02.128393 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #250 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9369464
Z variance train             0.03614458
KL Divergence                17.756351
KL Loss                      1.7756351
QF Loss                      1687.636
VF Loss                      269.56427
Policy Loss                  -904.8086
Q Predictions Mean           904.0029
Q Predictions Std            239.76398
Q Predictions Max            1165.2555
Q Predictions Min            -8.975048
V Predictions Mean           909.8237
V Predictions Std            235.63187
V Predictions Max            1178.8087
V Predictions Min            49.143604
Log Pis Mean                 -1.0225815
Log Pis Std                  2.7232208
Log Pis Max                  9.105858
Log Pis Min                  -8.7782955
Policy mu Mean               -0.020806652
Policy mu Std                0.5507915
Policy mu Max                2.3486767
Policy mu Min                -2.6107872
Policy log std Mean          -0.90752137
Policy log std Std           0.2753307
Policy log std Max           -0.25930423
Policy log std Min           -2.3936028
Z mean eval                  0.9711261
Z variance eval              0.044641256
total_rewards                [2689.78305015 2632.02372201 2676.70905149 2853.25425016 1366.79502981
  639.62139005   41.26334957 2743.26762685 2798.20864909 2549.44337002]
total_rewards_mean           2099.0369489188593
total_rewards_std            976.8750696278405
total_rewards_max            2853.254250155883
total_rewards_min            41.263349569099866
Number of train steps total  252000
Number of env steps total    1262000
Number of rollouts total     0
Train Time (s)               28.745271385181695
(Previous) Eval Time (s)     24.8807053421624
Sample Time (s)              18.550352044869214
Epoch Time (s)               72.17632877221331
Total Train Time (s)         17499.37430734327
Epoch                        251
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:07:11.307587 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #251 | Epoch Duration: 69.17900609970093
2020-01-11 08:07:11.307808 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #251 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9692615
Z variance train             0.044568248
KL Divergence                17.773617
KL Loss                      1.7773618
QF Loss                      1060.8872
VF Loss                      208.18037
Policy Loss                  -900.7518
Q Predictions Mean           897.0504
Q Predictions Std            233.6057
Q Predictions Max            1110.1827
Q Predictions Min            220.83504
V Predictions Mean           892.5353
V Predictions Std            232.40524
V Predictions Max            1110.0829
V Predictions Min            198.45192
Log Pis Mean                 -1.0141639
Log Pis Std                  2.4278219
Log Pis Max                  7.121056
Log Pis Min                  -7.963864
Policy mu Mean               0.008327452
Policy mu Std                0.5460385
Policy mu Max                3.0509303
Policy mu Min                -1.6251389
Policy log std Mean          -0.9021312
Policy log std Std           0.26110443
Policy log std Max           -0.14059585
Policy log std Min           -2.4727058
Z mean eval                  0.95378524
Z variance eval              0.025737846
total_rewards                [ 713.87330022  677.60380713 2061.5743183  2250.75837824 2035.46133829
  494.56244176  200.05566953 1054.18198782 1572.77841841 2262.11271832]
total_rewards_mean           1332.29623780232
total_rewards_std            752.6243425046742
total_rewards_max            2262.1127183170083
total_rewards_min            200.05566953122934
Number of train steps total  253000
Number of env steps total    1267000
Number of rollouts total     0
Train Time (s)               30.217944227159023
(Previous) Eval Time (s)     21.88304568314925
Sample Time (s)              18.601145889610052
Epoch Time (s)               70.70213579991832
Total Train Time (s)         17564.76422792673
Epoch                        252
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:08:16.702721 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #252 | Epoch Duration: 65.39470386505127
2020-01-11 08:08:16.703037 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #252 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9523082
Z variance train             0.025788287
KL Divergence                18.28426
KL Loss                      1.828426
QF Loss                      618.2805
VF Loss                      172.43774
Policy Loss                  -897.6215
Q Predictions Mean           895.47485
Q Predictions Std            214.39062
Q Predictions Max            1106.3302
Q Predictions Min            192.85399
V Predictions Mean           905.6917
V Predictions Std            212.40698
V Predictions Max            1123.5273
V Predictions Min            220.44884
Log Pis Mean                 -0.702381
Log Pis Std                  2.5493464
Log Pis Max                  7.9760265
Log Pis Min                  -6.8761296
Policy mu Mean               0.04831638
Policy mu Std                0.55169046
Policy mu Max                2.0295484
Policy mu Min                -2.3989275
Policy log std Mean          -0.9253608
Policy log std Std           0.27224866
Policy log std Max           -0.23610914
Policy log std Min           -2.486945
Z mean eval                  0.9448649
Z variance eval              0.029942747
total_rewards                [  41.18816205  989.11057351  311.13511585  190.38212221  271.714661
 1082.69802891  798.76201095  595.62086488 2659.23679817 1232.9856366 ]
total_rewards_mean           817.2833974121476
total_rewards_std            725.5486103385207
total_rewards_max            2659.236798168392
total_rewards_min            41.1881620544665
Number of train steps total  254000
Number of env steps total    1272000
Number of rollouts total     0
Train Time (s)               27.45206371601671
(Previous) Eval Time (s)     16.57528018997982
Sample Time (s)              18.84845507470891
Epoch Time (s)               62.87579898070544
Total Train Time (s)         17623.4816097226
Epoch                        253
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:09:15.424718 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #253 | Epoch Duration: 58.721431255340576
2020-01-11 08:09:15.425005 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #253 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94295454
Z variance train             0.029953087
KL Divergence                17.798903
KL Loss                      1.7798903
QF Loss                      1218.8525
VF Loss                      102.96335
Policy Loss                  -909.7947
Q Predictions Mean           911.30505
Q Predictions Std            222.38817
Q Predictions Max            1132.3975
Q Predictions Min            157.60432
V Predictions Mean           912.88324
V Predictions Std            225.71
V Predictions Max            1137.1237
V Predictions Min            40.556866
Log Pis Mean                 -0.6133996
Log Pis Std                  3.1183186
Log Pis Max                  12.516827
Log Pis Min                  -11.725645
Policy mu Mean               0.02742127
Policy mu Std                0.58601123
Policy mu Max                2.3689942
Policy mu Min                -2.4511094
Policy log std Mean          -0.8993959
Policy log std Std           0.28722015
Policy log std Max           -0.1872521
Policy log std Min           -2.8568451
Z mean eval                  0.93744755
Z variance eval              0.02690569
total_rewards                [2357.86865498  -26.04434143  556.55530455 1077.86008247 2596.3004861
 2463.65072367 1938.57246575  800.4428763  2729.68127686 1864.15985353]
total_rewards_mean           1635.9047382788417
total_rewards_std            916.8037345760059
total_rewards_max            2729.6812768552136
total_rewards_min            -26.04434143038262
Number of train steps total  255000
Number of env steps total    1277000
Number of rollouts total     0
Train Time (s)               28.10335302213207
(Previous) Eval Time (s)     12.420615163166076
Sample Time (s)              18.614548318088055
Epoch Time (s)               59.1385165033862
Total Train Time (s)         17694.618922865484
Epoch                        254
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:10:26.586368 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #254 | Epoch Duration: 71.1611180305481
2020-01-11 08:10:26.586676 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #254 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9372778
Z variance train             0.026927466
KL Divergence                18.345335
KL Loss                      1.8345336
QF Loss                      929.20447
VF Loss                      99.8484
Policy Loss                  -912.0884
Q Predictions Mean           910.978
Q Predictions Std            228.86916
Q Predictions Max            1122.9913
Q Predictions Min            3.0897772
V Predictions Mean           907.87866
V Predictions Std            228.91576
V Predictions Max            1111.8221
V Predictions Min            3.8389404
Log Pis Mean                 -0.7919455
Log Pis Std                  2.7592142
Log Pis Max                  13.631057
Log Pis Min                  -7.789043
Policy mu Mean               0.064500436
Policy mu Std                0.5541392
Policy mu Max                2.2510757
Policy mu Min                -2.1698506
Policy log std Mean          -0.9033371
Policy log std Std           0.28052866
Policy log std Max           -0.19608164
Policy log std Min           -2.5883994
Z mean eval                  0.9554559
Z variance eval              0.028318385
total_rewards                [ 206.55123216 2544.01969103  979.54894422 2801.62218341 2907.5863429
 1118.13704425  952.6613602  1991.87794842 1496.80350125  771.62406099]
total_rewards_mean           1577.0432308830873
total_rewards_std            887.0120463907294
total_rewards_max            2907.5863428961934
total_rewards_min            206.55123216081793
Number of train steps total  256000
Number of env steps total    1282000
Number of rollouts total     0
Train Time (s)               29.554026904981583
(Previous) Eval Time (s)     24.442884634714574
Sample Time (s)              18.676864847540855
Epoch Time (s)               72.67377638723701
Total Train Time (s)         17762.281220743433
Epoch                        255
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:11:34.233828 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #255 | Epoch Duration: 67.64689326286316
2020-01-11 08:11:34.234148 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #255 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9557166
Z variance train             0.02830882
KL Divergence                18.556149
KL Loss                      1.8556149
QF Loss                      551.9176
VF Loss                      70.25395
Policy Loss                  -891.6634
Q Predictions Mean           889.64136
Q Predictions Std            258.397
Q Predictions Max            1139.0432
Q Predictions Min            211.28194
V Predictions Mean           892.45984
V Predictions Std            259.70703
V Predictions Max            1126.8702
V Predictions Min            224.25919
Log Pis Mean                 -1.0996405
Log Pis Std                  2.454031
Log Pis Max                  8.873881
Log Pis Min                  -8.857151
Policy mu Mean               0.03160839
Policy mu Std                0.55124724
Policy mu Max                1.9847487
Policy mu Min                -1.9066821
Policy log std Mean          -0.87705547
Policy log std Std           0.2598276
Policy log std Max           -0.17224836
Policy log std Min           -2.1101272
Z mean eval                  0.95902216
Z variance eval              0.028317148
total_rewards                [ -28.69973504 1703.02787005 1110.54670517 1409.14340384 1298.73668489
 1413.5044823   874.59612276 1531.84023104  419.32116973  892.12294939]
total_rewards_mean           1062.4139884138299
total_rewards_std            509.9774759641445
total_rewards_max            1703.027870054469
total_rewards_min            -28.699735038920366
Number of train steps total  257000
Number of env steps total    1287000
Number of rollouts total     0
Train Time (s)               29.615179917775095
(Previous) Eval Time (s)     19.415687709115446
Sample Time (s)              19.0076373629272
Epoch Time (s)               68.03850498981774
Total Train Time (s)         17828.213258637115
Epoch                        256
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:12:40.166400 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #256 | Epoch Duration: 65.93203616142273
2020-01-11 08:12:40.166602 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #256 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95608366
Z variance train             0.02820541
KL Divergence                17.814482
KL Loss                      1.7814482
QF Loss                      2928.693
VF Loss                      2077.1306
Policy Loss                  -904.8279
Q Predictions Mean           900.1463
Q Predictions Std            242.3305
Q Predictions Max            1113.2496
Q Predictions Min            49.949696
V Predictions Mean           919.55566
V Predictions Std            232.49184
V Predictions Max            1137.9342
V Predictions Min            220.44789
Log Pis Mean                 -0.8812002
Log Pis Std                  2.824293
Log Pis Max                  12.02819
Log Pis Min                  -11.538235
Policy mu Mean               -0.05733068
Policy mu Std                0.54770327
Policy mu Max                2.2589426
Policy mu Min                -3.4361825
Policy log std Mean          -0.9161228
Policy log std Std           0.26949656
Policy log std Max           -0.16801363
Policy log std Min           -2.7833662
Z mean eval                  0.9743804
Z variance eval              0.025839994
total_rewards                [1581.0693333  2533.64945465 2521.91674962 1870.10757966 2593.56677903
 2388.29893387 2711.13949003 2649.54139756 2515.39766722 1367.54550296]
total_rewards_mean           2273.223288788703
total_rewards_std            458.19194163567977
total_rewards_max            2711.1394900299756
total_rewards_min            1367.5455029620603
Number of train steps total  258000
Number of env steps total    1292000
Number of rollouts total     0
Train Time (s)               31.864231899846345
(Previous) Eval Time (s)     17.308948644436896
Sample Time (s)              18.443651183042675
Epoch Time (s)               67.61683172732592
Total Train Time (s)         17903.35017370293
Epoch                        257
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:13:55.305441 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #257 | Epoch Duration: 75.1386935710907
2020-01-11 08:13:55.305596 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #257 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9797969
Z variance train             0.025819376
KL Divergence                18.32274
KL Loss                      1.8322741
QF Loss                      1017.46625
VF Loss                      566.675
Policy Loss                  -915.82446
Q Predictions Mean           918.78186
Q Predictions Std            236.59567
Q Predictions Max            1172.9167
Q Predictions Min            182.0911
V Predictions Mean           931.19635
V Predictions Std            237.79002
V Predictions Max            1182.9382
V Predictions Min            212.43553
Log Pis Mean                 -0.7309377
Log Pis Std                  2.5701873
Log Pis Max                  7.1124563
Log Pis Min                  -10.644365
Policy mu Mean               -0.013894947
Policy mu Std                0.5666858
Policy mu Max                2.4704862
Policy mu Min                -2.798747
Policy log std Mean          -0.91282326
Policy log std Std           0.25961065
Policy log std Max           -0.23753095
Policy log std Min           -2.4096613
Z mean eval                  0.94236296
Z variance eval              0.02254998
total_rewards                [1623.90878118 2753.43644334 2600.19241283 2795.36802836 2491.52994709
  120.64003533 2785.007311    263.01485697 2339.75025458  646.19177854]
total_rewards_mean           1841.9039849206947
total_rewards_std            1039.5761241606613
total_rewards_max            2795.3680283584495
total_rewards_min            120.64003533014515
Number of train steps total  259000
Number of env steps total    1297000
Number of rollouts total     0
Train Time (s)               28.966166269034147
(Previous) Eval Time (s)     24.83051085891202
Sample Time (s)              18.142430834006518
Epoch Time (s)               71.93910796195269
Total Train Time (s)         17970.864580288064
Epoch                        258
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:15:02.826609 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #258 | Epoch Duration: 67.52085781097412
2020-01-11 08:15:02.826877 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #258 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.942224
Z variance train             0.022569606
KL Divergence                18.836836
KL Loss                      1.8836836
QF Loss                      642.1618
VF Loss                      112.799484
Policy Loss                  -925.8782
Q Predictions Mean           926.0701
Q Predictions Std            232.56647
Q Predictions Max            1176.2289
Q Predictions Min            27.266499
V Predictions Mean           926.14233
V Predictions Std            231.08913
V Predictions Max            1172.3293
V Predictions Min            4.810712
Log Pis Mean                 -1.0211531
Log Pis Std                  2.5194926
Log Pis Max                  5.779808
Log Pis Min                  -9.526345
Policy mu Mean               0.04571762
Policy mu Std                0.57074213
Policy mu Max                1.82378
Policy mu Min                -2.5523293
Policy log std Mean          -0.9078686
Policy log std Std           0.25279802
Policy log std Max           -0.11361337
Policy log std Min           -1.9657531
Z mean eval                  0.95122087
Z variance eval              0.015711647
total_rewards                [2745.67533573 1298.58461177 2365.94112692   60.92758547   35.42328444
 1257.93296663  194.45701743 2807.29395779 2465.2225721  2596.17401672]
total_rewards_mean           1582.7632475009143
total_rewards_std            1099.7660916424613
total_rewards_max            2807.29395779026
total_rewards_min            35.42328444348435
Number of train steps total  260000
Number of env steps total    1302000
Number of rollouts total     0
Train Time (s)               30.471297970972955
(Previous) Eval Time (s)     20.411914727650583
Sample Time (s)              18.664497023448348
Epoch Time (s)               69.54770972207189
Total Train Time (s)         18041.573182887398
Epoch                        259
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:16:13.535361 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #259 | Epoch Duration: 70.70829439163208
2020-01-11 08:16:13.535560 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #259 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9479469
Z variance train             0.015701333
KL Divergence                19.665289
KL Loss                      1.9665289
QF Loss                      529.76587
VF Loss                      102.62699
Policy Loss                  -934.32587
Q Predictions Mean           933.71216
Q Predictions Std            230.26512
Q Predictions Max            1133.148
Q Predictions Min            29.49901
V Predictions Mean           931.9986
V Predictions Std            227.85965
V Predictions Max            1138.7079
V Predictions Min            5.6386595
Log Pis Mean                 -0.90521574
Log Pis Std                  2.3459744
Log Pis Max                  7.1766567
Log Pis Min                  -8.43993
Policy mu Mean               0.047162183
Policy mu Std                0.5337778
Policy mu Max                2.5592947
Policy mu Min                -1.899666
Policy log std Mean          -0.919437
Policy log std Std           0.26092398
Policy log std Max           -0.1349914
Policy log std Min           -2.0178359
Z mean eval                  0.95758504
Z variance eval              0.018248824
total_rewards                [2644.02731142 2873.60999535 3031.82620615 2677.57364495  182.46760229
 2587.31832388 2098.37098216 2986.37898594   27.05295042 2957.12315171]
total_rewards_mean           2206.5749154261
total_rewards_std            1082.3399180158237
total_rewards_max            3031.82620614799
total_rewards_min            27.052950421668136
Number of train steps total  261000
Number of env steps total    1307000
Number of rollouts total     0
Train Time (s)               29.135387738700956
(Previous) Eval Time (s)     21.572190378792584
Sample Time (s)              18.875350617337972
Epoch Time (s)               69.58292873483151
Total Train Time (s)         18110.719359093346
Epoch                        260
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:17:22.691061 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #260 | Epoch Duration: 69.15528988838196
2020-01-11 08:17:22.691373 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #260 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95863754
Z variance train             0.01821758
KL Divergence                19.866184
KL Loss                      1.9866184
QF Loss                      1189.854
VF Loss                      160.9096
Policy Loss                  -923.5161
Q Predictions Mean           923.8302
Q Predictions Std            235.56296
Q Predictions Max            1141.3666
Q Predictions Min            223.13422
V Predictions Mean           927.5819
V Predictions Std            236.59834
V Predictions Max            1152.739
V Predictions Min            151.24644
Log Pis Mean                 -0.90968966
Log Pis Std                  2.4748971
Log Pis Max                  8.393955
Log Pis Min                  -7.207617
Policy mu Mean               0.014843491
Policy mu Std                0.5447495
Policy mu Max                2.4103827
Policy mu Min                -2.553052
Policy log std Mean          -0.8872611
Policy log std Std           0.24596652
Policy log std Max           -0.1873379
Policy log std Min           -2.5966277
Z mean eval                  0.9661409
Z variance eval              0.018426586
total_rewards                [2417.47892181 2073.4993313   326.12355887 2466.40141903  865.95312419
 1746.97781979 2664.73791582 2515.00056652 2536.84246128  743.39379977]
total_rewards_mean           1835.6408918387192
total_rewards_std            827.8519102171477
total_rewards_max            2664.737915819428
total_rewards_min            326.1235588727875
Number of train steps total  262000
Number of env steps total    1312000
Number of rollouts total     0
Train Time (s)               28.850722576957196
(Previous) Eval Time (s)     21.144186593126506
Sample Time (s)              19.047022285405546
Epoch Time (s)               69.04193145548925
Total Train Time (s)         18180.52626497438
Epoch                        261
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:18:32.496157 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #261 | Epoch Duration: 69.80453610420227
2020-01-11 08:18:32.496397 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #261 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96569645
Z variance train             0.018424755
KL Divergence                20.05821
KL Loss                      2.005821
QF Loss                      481.88998
VF Loss                      134.48859
Policy Loss                  -955.27594
Q Predictions Mean           953.0349
Q Predictions Std            232.09865
Q Predictions Max            1215.4187
Q Predictions Min            208.60507
V Predictions Mean           956.2883
V Predictions Std            229.3073
V Predictions Max            1232.298
V Predictions Min            225.07124
Log Pis Mean                 -1.1542563
Log Pis Std                  2.4929826
Log Pis Max                  6.7018137
Log Pis Min                  -8.480636
Policy mu Mean               0.032985955
Policy mu Std                0.5303168
Policy mu Max                2.0935614
Policy mu Min                -1.9592499
Policy log std Mean          -0.89708984
Policy log std Std           0.25194874
Policy log std Max           -0.13511807
Policy log std Min           -2.0002584
Z mean eval                  0.9562416
Z variance eval              0.028705826
total_rewards                [2673.89588026 2638.18142864 2573.69689669 2507.09258191 2504.37492638
 2692.90799797 2793.69367195 2472.59168313 2482.99962143 2649.24305343]
total_rewards_mean           2598.867774179379
total_rewards_std            101.91632856930026
total_rewards_max            2793.693671954397
total_rewards_min            2472.5916831286895
Number of train steps total  263000
Number of env steps total    1317000
Number of rollouts total     0
Train Time (s)               28.588969186879694
(Previous) Eval Time (s)     21.906475526746362
Sample Time (s)              18.241868307814002
Epoch Time (s)               68.73731302144006
Total Train Time (s)         18254.54895925196
Epoch                        262
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:19:46.522341 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #262 | Epoch Duration: 74.02575159072876
2020-01-11 08:19:46.522562 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #262 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9566061
Z variance train             0.02852979
KL Divergence                18.768143
KL Loss                      1.8768142
QF Loss                      1497.6605
VF Loss                      147.8255
Policy Loss                  -949.18085
Q Predictions Mean           945.08325
Q Predictions Std            219.85867
Q Predictions Max            1142.8955
Q Predictions Min            24.605213
V Predictions Mean           952.37366
V Predictions Std            220.35413
V Predictions Max            1161.9943
V Predictions Min            20.174118
Log Pis Mean                 -0.92969894
Log Pis Std                  2.7634943
Log Pis Max                  10.929201
Log Pis Min                  -12.921792
Policy mu Mean               0.042914666
Policy mu Std                0.5612136
Policy mu Max                2.5755172
Policy mu Min                -2.2567084
Policy log std Mean          -0.8927113
Policy log std Std           0.25580645
Policy log std Max           -0.1816293
Policy log std Min           -2.3957195
Z mean eval                  0.9422768
Z variance eval              0.023592463
total_rewards                [2311.12998609 1876.53620347 2578.76138597 2674.219349   2542.51521942
  491.88003057  714.59089295 2715.33036934  481.15718334  972.82005296]
total_rewards_mean           1735.894067310844
total_rewards_std            910.9756897708318
total_rewards_max            2715.3303693439702
total_rewards_min            481.15718334295997
Number of train steps total  264000
Number of env steps total    1322000
Number of rollouts total     0
Train Time (s)               29.770463815890253
(Previous) Eval Time (s)     27.194626914337277
Sample Time (s)              17.562837024684995
Epoch Time (s)               74.52792775491253
Total Train Time (s)         18320.48717993498
Epoch                        263
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:20:52.465351 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #263 | Epoch Duration: 65.9425859451294
2020-01-11 08:20:52.465628 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #263 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94229853
Z variance train             0.02361604
KL Divergence                19.093214
KL Loss                      1.9093214
QF Loss                      1343.4504
VF Loss                      324.5171
Policy Loss                  -932.8443
Q Predictions Mean           933.1562
Q Predictions Std            230.99886
Q Predictions Max            1141.5325
Q Predictions Min            217.40785
V Predictions Mean           939.5511
V Predictions Std            230.56235
V Predictions Max            1153.8776
V Predictions Min            217.99712
Log Pis Mean                 -1.068821
Log Pis Std                  2.5195622
Log Pis Max                  10.198889
Log Pis Min                  -9.6985
Policy mu Mean               -0.0072131553
Policy mu Std                0.5277378
Policy mu Max                2.0445693
Policy mu Min                -1.6975014
Policy log std Mean          -0.89496636
Policy log std Std           0.25325644
Policy log std Max           -0.2899487
Policy log std Min           -2.8082244
Z mean eval                  0.93767816
Z variance eval              0.022560755
total_rewards                [ 480.58611292 2316.94700398 2237.48659826 2145.21470229 2145.75820784
 2219.88649086 1540.17366325 2160.58209698 2526.94960176 2435.52428713]
total_rewards_mean           2020.9108765272322
total_rewards_std            570.6459665542699
total_rewards_max            2526.9496017616893
total_rewards_min            480.5861129238513
Number of train steps total  265000
Number of env steps total    1327000
Number of rollouts total     0
Train Time (s)               27.616259199101478
(Previous) Eval Time (s)     18.609000836964697
Sample Time (s)              18.261350391432643
Epoch Time (s)               64.48661042749882
Total Train Time (s)         18393.623733310495
Epoch                        264
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:22:05.603159 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #264 | Epoch Duration: 73.13734173774719
2020-01-11 08:22:05.603375 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #264 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93655765
Z variance train             0.022485124
KL Divergence                19.928944
KL Loss                      1.9928944
QF Loss                      671.58984
VF Loss                      364.00177
Policy Loss                  -927.1595
Q Predictions Mean           929.21936
Q Predictions Std            251.09755
Q Predictions Max            1178.5479
Q Predictions Min            27.824406
V Predictions Mean           937.34326
V Predictions Std            251.94325
V Predictions Max            1186.6084
V Predictions Min            43.67303
Log Pis Mean                 -0.5886258
Log Pis Std                  2.9512146
Log Pis Max                  14.817766
Log Pis Min                  -7.9653544
Policy mu Mean               -0.028695853
Policy mu Std                0.55096203
Policy mu Max                1.9703089
Policy mu Min                -2.5072446
Policy log std Mean          -0.9422263
Policy log std Std           0.3024558
Policy log std Max           -0.16707164
Policy log std Min           -3.200778
Z mean eval                  0.9350117
Z variance eval              0.019623805
total_rewards                [2705.4835373  2772.54010091 1704.68980366 2668.50541348 2715.39705883
 2639.93563577 2848.43321871 2583.35819394   78.58540037 2709.26746287]
total_rewards_mean           2342.6195825845894
total_rewards_std            814.3157693073841
total_rewards_max            2848.4332187129257
total_rewards_min            78.58540037322302
Number of train steps total  266000
Number of env steps total    1332000
Number of rollouts total     0
Train Time (s)               28.598074399400502
(Previous) Eval Time (s)     27.259424154181033
Sample Time (s)              18.259149289689958
Epoch Time (s)               74.1166478432715
Total Train Time (s)         18464.477830617223
Epoch                        265
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:23:16.459263 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #265 | Epoch Duration: 70.85575151443481
2020-01-11 08:23:16.459449 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #265 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9346911
Z variance train             0.01965185
KL Divergence                19.912933
KL Loss                      1.9912933
QF Loss                      877.54834
VF Loss                      254.60023
Policy Loss                  -940.7421
Q Predictions Mean           941.505
Q Predictions Std            217.9322
Q Predictions Max            1192.389
Q Predictions Min            217.17151
V Predictions Mean           942.2827
V Predictions Std            215.67148
V Predictions Max            1166.7902
V Predictions Min            212.58684
Log Pis Mean                 -1.0352967
Log Pis Std                  2.4439616
Log Pis Max                  9.812263
Log Pis Min                  -7.0683756
Policy mu Mean               0.040859863
Policy mu Std                0.5374054
Policy mu Max                1.9172431
Policy mu Min                -2.4562085
Policy log std Mean          -0.9089472
Policy log std Std           0.24512118
Policy log std Max           -0.20901263
Policy log std Min           -2.1651902
Z mean eval                  0.9613374
Z variance eval              0.020611543
total_rewards                [2680.14739566 2536.52402795 1949.01509215 2516.72350792 2382.86782997
 2407.38702888  252.28407178 2658.380261   2241.39581776  707.59915006]
total_rewards_mean           2033.2324183125195
total_rewards_std            808.5862117722824
total_rewards_max            2680.1473956610107
total_rewards_min            252.2840717782916
Number of train steps total  267000
Number of env steps total    1337000
Number of rollouts total     0
Train Time (s)               26.430531528778374
(Previous) Eval Time (s)     23.998253948055208
Sample Time (s)              18.647133784368634
Epoch Time (s)               69.07591926120222
Total Train Time (s)         18536.592202575877
Epoch                        266
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:24:28.576989 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #266 | Epoch Duration: 72.11740326881409
2020-01-11 08:24:28.577149 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #266 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.960807
Z variance train             0.02060557
KL Divergence                19.985966
KL Loss                      1.9985965
QF Loss                      848.369
VF Loss                      90.53276
Policy Loss                  -945.1085
Q Predictions Mean           944.59845
Q Predictions Std            237.18134
Q Predictions Max            1175.7645
Q Predictions Min            157.97496
V Predictions Mean           946.76355
V Predictions Std            236.71411
V Predictions Max            1162.2561
V Predictions Min            167.97229
Log Pis Mean                 -1.0641508
Log Pis Std                  2.5813777
Log Pis Max                  11.421577
Log Pis Min                  -9.829818
Policy mu Mean               0.005550222
Policy mu Std                0.5447575
Policy mu Max                2.9853616
Policy mu Min                -1.9979098
Policy log std Mean          -0.8969818
Policy log std Std           0.24545677
Policy log std Max           -0.14156938
Policy log std Min           -1.9388577
Z mean eval                  0.97309196
Z variance eval              0.018782884
total_rewards                [ 189.86782478 1984.9485672   169.390612    710.19842791 2621.10821352
 1847.49814351 2744.62611879 2746.91371919 2189.5445928  2665.22773077]
total_rewards_mean           1786.9323950472312
total_rewards_std            991.835737290704
total_rewards_max            2746.9137191923583
total_rewards_min            169.39061199952283
Number of train steps total  268000
Number of env steps total    1342000
Number of rollouts total     0
Train Time (s)               28.390909078065306
(Previous) Eval Time (s)     27.03944656299427
Sample Time (s)              17.81749355746433
Epoch Time (s)               73.24784919852391
Total Train Time (s)         18603.635010964237
Epoch                        267
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:25:35.621091 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #267 | Epoch Duration: 67.04381585121155
2020-01-11 08:25:35.621250 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #267 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9730695
Z variance train             0.018711997
KL Divergence                20.780556
KL Loss                      2.0780556
QF Loss                      1632.5986
VF Loss                      541.0375
Policy Loss                  -954.1827
Q Predictions Mean           952.113
Q Predictions Std            220.11331
Q Predictions Max            1230.9729
Q Predictions Min            163.06963
V Predictions Mean           937.4934
V Predictions Std            213.63902
V Predictions Max            1210.862
V Predictions Min            162.02379
Log Pis Mean                 -0.9475565
Log Pis Std                  2.7196786
Log Pis Max                  8.868357
Log Pis Min                  -10.539837
Policy mu Mean               -0.012185356
Policy mu Std                0.54432154
Policy mu Max                1.9378135
Policy mu Min                -2.4087427
Policy log std Mean          -0.9466716
Policy log std Std           0.27746677
Policy log std Max           -0.25460112
Policy log std Min           -2.2659364
Z mean eval                  0.97276336
Z variance eval              0.017586034
total_rewards                [2118.88200635  120.5940651   329.50211996 2326.20381677  466.47801754
 1697.53646997 2394.63603113   33.50403503 1788.2756482  2518.88318757]
total_rewards_mean           1379.4495397605426
total_rewards_std            968.1181621215087
total_rewards_max            2518.883187566143
total_rewards_min            33.50403503151371
Number of train steps total  269000
Number of env steps total    1347000
Number of rollouts total     0
Train Time (s)               29.834383898880333
(Previous) Eval Time (s)     20.835119815077633
Sample Time (s)              17.9646168127656
Epoch Time (s)               68.63412052672356
Total Train Time (s)         18675.349455229472
Epoch                        268
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:26:47.340377 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #268 | Epoch Duration: 71.7190055847168
2020-01-11 08:26:47.340572 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #268 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97230065
Z variance train             0.017570833
KL Divergence                20.717579
KL Loss                      2.071758
QF Loss                      596.39453
VF Loss                      245.22083
Policy Loss                  -951.20544
Q Predictions Mean           949.2621
Q Predictions Std            241.83994
Q Predictions Max            1188.2013
Q Predictions Min            211.91777
V Predictions Mean           961.394
V Predictions Std            239.36082
V Predictions Max            1201.4502
V Predictions Min            223.86209
Log Pis Mean                 -0.9304898
Log Pis Std                  2.75157
Log Pis Max                  9.401225
Log Pis Min                  -8.143623
Policy mu Mean               0.024979781
Policy mu Std                0.5215995
Policy mu Max                1.9342264
Policy mu Min                -2.1527903
Policy log std Mean          -0.93968385
Policy log std Std           0.2694295
Policy log std Max           -0.2599188
Policy log std Min           -1.9815333
Z mean eval                  0.94810647
Z variance eval              0.020062488
total_rewards                [2770.01899255 2787.94925448 2747.60794526 1028.91994683 2710.94018341
 1458.22553726 2762.06632807 2827.7981631  1359.95149886  932.56037185]
total_rewards_mean           2138.6038221688914
total_rewards_std            783.4307266399943
total_rewards_max            2827.798163103256
total_rewards_min            932.5603718521982
Number of train steps total  270000
Number of env steps total    1352000
Number of rollouts total     0
Train Time (s)               31.75892403628677
(Previous) Eval Time (s)     23.91973400488496
Sample Time (s)              18.408568614162505
Epoch Time (s)               74.08722665533423
Total Train Time (s)         18750.266314502805
Epoch                        269
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:28:02.258844 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #269 | Epoch Duration: 74.9181261062622
2020-01-11 08:28:02.259086 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #269 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94911146
Z variance train             0.020023603
KL Divergence                20.824099
KL Loss                      2.0824099
QF Loss                      1281.7631
VF Loss                      93.952774
Policy Loss                  -975.1322
Q Predictions Mean           974.3658
Q Predictions Std            199.88245
Q Predictions Max            1166.4221
Q Predictions Min            -31.952728
V Predictions Mean           976.9514
V Predictions Std            197.24785
V Predictions Max            1165.0695
V Predictions Min            27.624989
Log Pis Mean                 -0.93354267
Log Pis Std                  2.4731035
Log Pis Max                  8.485842
Log Pis Min                  -8.36191
Policy mu Mean               -0.0031338627
Policy mu Std                0.55512494
Policy mu Max                2.2712328
Policy mu Min                -1.8365124
Policy log std Mean          -0.9092028
Policy log std Std           0.26113936
Policy log std Max           -0.20468473
Policy log std Min           -2.8673708
Z mean eval                  0.9840268
Z variance eval              0.017936615
total_rewards                [ 558.98559429 1067.98359828 1400.31502007  613.64153043  585.80703615
  188.49335824  860.552264   2443.59770402  234.89846713  582.8014091 ]
total_rewards_mean           853.7075981723258
total_rewards_std            631.4728539315911
total_rewards_max            2443.597704015351
total_rewards_min            188.49335824351155
Number of train steps total  271000
Number of env steps total    1357000
Number of rollouts total     0
Train Time (s)               28.919176320079714
(Previous) Eval Time (s)     24.750281310174614
Sample Time (s)              18.591629980131984
Epoch Time (s)               72.26108761038631
Total Train Time (s)         18809.965902919415
Epoch                        270
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:29:01.961064 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #270 | Epoch Duration: 59.70177984237671
2020-01-11 08:29:01.961241 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #270 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97856176
Z variance train             0.017903369
KL Divergence                20.889008
KL Loss                      2.0889008
QF Loss                      604.50397
VF Loss                      406.5916
Policy Loss                  -974.7683
Q Predictions Mean           970.25
Q Predictions Std            205.47226
Q Predictions Max            1148.0773
Q Predictions Min            201.18466
V Predictions Mean           957.1553
V Predictions Std            201.8206
V Predictions Max            1134.1938
V Predictions Min            185.1465
Log Pis Mean                 -0.814245
Log Pis Std                  2.2504127
Log Pis Max                  8.664513
Log Pis Min                  -7.1079226
Policy mu Mean               0.016407836
Policy mu Std                0.52810484
Policy mu Max                2.1576633
Policy mu Min                -2.419011
Policy log std Mean          -0.9317478
Policy log std Std           0.25369886
Policy log std Max           -0.28760326
Policy log std Min           -2.1760304
Z mean eval                  0.96157044
Z variance eval              0.018411702
total_rewards                [ 724.62354845 2448.75235289 1090.76516313 2777.7195147  1070.66569208
 2770.04637958 2235.41778433 2178.07902307  298.72112767 1901.97477906]
total_rewards_mean           1749.6765364948417
total_rewards_std            841.4646240515457
total_rewards_max            2777.719514695438
total_rewards_min            298.72112767087657
Number of train steps total  272000
Number of env steps total    1362000
Number of rollouts total     0
Train Time (s)               28.27397532714531
(Previous) Eval Time (s)     12.190696700941771
Sample Time (s)              17.389723810832947
Epoch Time (s)               57.85439583892003
Total Train Time (s)         18878.89904190181
Epoch                        271
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:30:10.895864 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #271 | Epoch Duration: 68.9344642162323
2020-01-11 08:30:10.896040 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #271 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96388274
Z variance train             0.018394046
KL Divergence                21.228397
KL Loss                      2.1228397
QF Loss                      842.16315
VF Loss                      95.63217
Policy Loss                  -945.97003
Q Predictions Mean           945.38385
Q Predictions Std            238.84924
Q Predictions Max            1241.5853
Q Predictions Min            25.553167
V Predictions Mean           951.07996
V Predictions Std            240.26776
V Predictions Max            1237.9379
V Predictions Min            9.523024
Log Pis Mean                 -0.9939533
Log Pis Std                  2.7943068
Log Pis Max                  9.7239065
Log Pis Min                  -12.136492
Policy mu Mean               0.016068427
Policy mu Std                0.5811491
Policy mu Max                2.2883022
Policy mu Min                -2.6678658
Policy log std Mean          -0.88006943
Policy log std Std           0.25522658
Policy log std Max           -0.2343775
Policy log std Min           -2.4360814
Z mean eval                  0.94661725
Z variance eval              0.017932173
total_rewards                [2643.81661764 2592.11422213 1907.20418241 2778.57784015 2699.87921409
 2498.24431953 2830.23376493 2422.25524592 2612.87922146 2578.11420457]
total_rewards_mean           2556.3318832835175
total_rewards_std            245.0193562930265
total_rewards_max            2830.2337649290344
total_rewards_min            1907.2041824074274
Number of train steps total  273000
Number of env steps total    1367000
Number of rollouts total     0
Train Time (s)               26.906636844854802
(Previous) Eval Time (s)     23.27047092700377
Sample Time (s)              17.50559878302738
Epoch Time (s)               67.68270655488595
Total Train Time (s)         18949.28200466791
Epoch                        272
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:31:21.281999 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #272 | Epoch Duration: 70.38579964637756
2020-01-11 08:31:21.282171 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #272 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9476099
Z variance train             0.017984526
KL Divergence                21.434166
KL Loss                      2.1434166
QF Loss                      1259.5568
VF Loss                      331.2734
Policy Loss                  -952.659
Q Predictions Mean           951.494
Q Predictions Std            248.72667
Q Predictions Max            1195.1526
Q Predictions Min            61.474785
V Predictions Mean           964.6294
V Predictions Std            251.23184
V Predictions Max            1205.0487
V Predictions Min            11.611884
Log Pis Mean                 -0.6042479
Log Pis Std                  2.5802462
Log Pis Max                  9.855669
Log Pis Min                  -11.8867035
Policy mu Mean               0.061376624
Policy mu Std                0.5479968
Policy mu Max                3.0108676
Policy mu Min                -1.9970524
Policy log std Mean          -0.9368279
Policy log std Std           0.26901367
Policy log std Max           -0.16654408
Policy log std Min           -2.4300387
Z mean eval                  0.9845239
Z variance eval              0.029411893
total_rewards                [1957.94386817 2455.67712336 1327.17467798 2425.1599182  2327.03106003
 1386.01366687  646.53991737 2234.2483797   826.39706223 1456.84278006]
total_rewards_mean           1704.302845397929
total_rewards_std            633.3652822701233
total_rewards_max            2455.677123363509
total_rewards_min            646.5399173747008
Number of train steps total  274000
Number of env steps total    1372000
Number of rollouts total     0
Train Time (s)               29.613697161898017
(Previous) Eval Time (s)     25.97328896773979
Sample Time (s)              19.21489203348756
Epoch Time (s)               74.80187816312537
Total Train Time (s)         19018.243637294974
Epoch                        273
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:32:30.245560 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #273 | Epoch Duration: 68.96322798728943
2020-01-11 08:32:30.245790 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #273 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9834347
Z variance train             0.02943967
KL Divergence                21.31956
KL Loss                      2.1319559
QF Loss                      1264.8815
VF Loss                      252.52661
Policy Loss                  -970.0892
Q Predictions Mean           969.9731
Q Predictions Std            253.18262
Q Predictions Max            1177.8267
Q Predictions Min            27.10243
V Predictions Mean           971.15076
V Predictions Std            252.24634
V Predictions Max            1184.4899
V Predictions Min            121.64522
Log Pis Mean                 -0.64262843
Log Pis Std                  2.9535525
Log Pis Max                  12.361588
Log Pis Min                  -10.93326
Policy mu Mean               0.040661514
Policy mu Std                0.568814
Policy mu Max                2.924331
Policy mu Min                -2.1224544
Policy log std Mean          -0.91623235
Policy log std Std           0.28145573
Policy log std Max           0.04530078
Policy log std Min           -2.6083484
Z mean eval                  0.9413112
Z variance eval              0.02506803
total_rewards                [2748.00553297  101.42249601 1142.09011423 2956.24659172 2938.79909345
 2829.5584564  1806.3086598  3047.07633022  790.57475491   87.3320663 ]
total_rewards_mean           1844.7414096016662
total_rewards_std            1157.4920141599582
total_rewards_max            3047.0763302198056
total_rewards_min            87.33206630156067
Number of train steps total  275000
Number of env steps total    1377000
Number of rollouts total     0
Train Time (s)               27.75840541580692
(Previous) Eval Time (s)     20.134307294152677
Sample Time (s)              17.95676493551582
Epoch Time (s)               65.84947764547542
Total Train Time (s)         19081.374750651885
Epoch                        274
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:33:33.379572 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #274 | Epoch Duration: 63.13360095024109
2020-01-11 08:33:33.379769 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #274 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9420477
Z variance train             0.025109794
KL Divergence                21.160007
KL Loss                      2.116001
QF Loss                      609.8369
VF Loss                      165.52493
Policy Loss                  -963.55695
Q Predictions Mean           961.8228
Q Predictions Std            256.38867
Q Predictions Max            1194.0923
Q Predictions Min            192.20062
V Predictions Mean           960.4851
V Predictions Std            257.50616
V Predictions Max            1185.6235
V Predictions Min            189.03493
Log Pis Mean                 -0.6180699
Log Pis Std                  2.8699381
Log Pis Max                  8.320943
Log Pis Min                  -9.18242
Policy mu Mean               0.01849006
Policy mu Std                0.58698756
Policy mu Max                2.0264938
Policy mu Min                -3.0681586
Policy log std Mean          -0.920218
Policy log std Std           0.25651285
Policy log std Max           -0.22916245
Policy log std Min           -2.2610042
Z mean eval                  0.9607369
Z variance eval              0.023676531
total_rewards                [2787.7601588  2591.79667255 2385.82477972 2608.86573367    5.65514661
 1004.12976302 2926.11938001 1530.81425021 2650.92575052 2744.28008078]
total_rewards_mean           2123.6171715895057
total_rewards_std            914.4514218327171
total_rewards_max            2926.119380014972
total_rewards_min            5.655146611401172
Number of train steps total  276000
Number of env steps total    1382000
Number of rollouts total     0
Train Time (s)               28.94559695199132
(Previous) Eval Time (s)     17.418141006026417
Sample Time (s)              17.694401894696057
Epoch Time (s)               64.0581398527138
Total Train Time (s)         19151.671235559974
Epoch                        275
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:34:43.678046 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #275 | Epoch Duration: 70.29811120033264
2020-01-11 08:34:43.678210 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #275 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96206367
Z variance train             0.023673156
KL Divergence                21.225895
KL Loss                      2.1225896
QF Loss                      612.12366
VF Loss                      96.99818
Policy Loss                  -951.90497
Q Predictions Mean           949.9511
Q Predictions Std            262.55035
Q Predictions Max            1169.5952
Q Predictions Min            46.80893
V Predictions Mean           955.66315
V Predictions Std            261.17352
V Predictions Max            1173.6406
V Predictions Min            43.6692
Log Pis Mean                 -0.9899842
Log Pis Std                  2.547952
Log Pis Max                  10.013716
Log Pis Min                  -8.898963
Policy mu Mean               -0.0044309366
Policy mu Std                0.5395897
Policy mu Max                1.8894162
Policy mu Min                -2.727322
Policy log std Mean          -0.9306141
Policy log std Std           0.2782037
Policy log std Max           -0.24921727
Policy log std Min           -3.1583633
Z mean eval                  0.9411913
Z variance eval              0.01900946
total_rewards                [2473.12049841 1094.67684958  839.526845   2284.49411419 2404.98721218
 2853.31058717 2938.84879781  257.83229776 2784.54997784  729.6461021 ]
total_rewards_mean           1866.0993282038767
total_rewards_std            965.9115187137352
total_rewards_max            2938.8487978085386
total_rewards_min            257.83229776187045
Number of train steps total  277000
Number of env steps total    1387000
Number of rollouts total     0
Train Time (s)               27.214037312660366
(Previous) Eval Time (s)     23.657817136030644
Sample Time (s)              17.427150243427604
Epoch Time (s)               68.29900469211861
Total Train Time (s)         19216.881542794872
Epoch                        276
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:35:48.890612 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #276 | Epoch Duration: 65.21225476264954
2020-01-11 08:35:48.890805 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #276 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94131726
Z variance train             0.01895076
KL Divergence                20.969387
KL Loss                      2.0969388
QF Loss                      688.0587
VF Loss                      290.23523
Policy Loss                  -965.6133
Q Predictions Mean           964.79083
Q Predictions Std            241.15952
Q Predictions Max            1157.556
Q Predictions Min            -13.843012
V Predictions Mean           974.4971
V Predictions Std            242.74596
V Predictions Max            1180.0726
V Predictions Min            15.781375
Log Pis Mean                 -0.9325637
Log Pis Std                  2.3628807
Log Pis Max                  6.875214
Log Pis Min                  -8.764905
Policy mu Mean               -0.0025807477
Policy mu Std                0.5530358
Policy mu Max                1.8832563
Policy mu Min                -1.795576
Policy log std Mean          -0.93661064
Policy log std Std           0.26013044
Policy log std Max           -0.22256637
Policy log std Min           -2.2319117
Z mean eval                  0.9665712
Z variance eval              0.018633017
total_rewards                [2749.35707921  686.36090638 1099.03044294 2482.08710882  328.11385861
 2679.42332113 1585.42713021 2459.70932354 2609.53769395 1871.62007758]
total_rewards_mean           1855.0666942354285
total_rewards_std            845.5366013891415
total_rewards_max            2749.3570792099663
total_rewards_min            328.1138586147534
Number of train steps total  278000
Number of env steps total    1392000
Number of rollouts total     0
Train Time (s)               30.134988063015044
(Previous) Eval Time (s)     20.5707746129483
Sample Time (s)              18.03553053177893
Epoch Time (s)               68.74129320774227
Total Train Time (s)         19288.395596046932
Epoch                        277
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:37:00.407721 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #277 | Epoch Duration: 71.51675629615784
2020-01-11 08:37:00.407914 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #277 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9659751
Z variance train             0.018577872
KL Divergence                21.342896
KL Loss                      2.1342895
QF Loss                      674.29065
VF Loss                      287.6961
Policy Loss                  -969.2947
Q Predictions Mean           968.3994
Q Predictions Std            248.41695
Q Predictions Max            1201.7563
Q Predictions Min            0.96247566
V Predictions Mean           980.1164
V Predictions Std            244.24626
V Predictions Max            1208.7864
V Predictions Min            6.0451813
Log Pis Mean                 -0.44868708
Log Pis Std                  2.9203372
Log Pis Max                  10.719087
Log Pis Min                  -12.413293
Policy mu Mean               0.05370553
Policy mu Std                0.58334374
Policy mu Max                2.7794292
Policy mu Min                -2.9407995
Policy log std Mean          -0.9143796
Policy log std Std           0.25854474
Policy log std Max           -0.19749957
Policy log std Min           -1.8903401
Z mean eval                  0.9817233
Z variance eval              0.013863939
total_rewards                [2564.60923081 2527.82046308  416.5956276   135.79511109 1288.20614402
 2509.00365213 2711.09890859  861.56968375 2725.226881    695.11905839]
total_rewards_mean           1643.5044760469657
total_rewards_std            1005.2365625994341
total_rewards_max            2725.2268810006813
total_rewards_min            135.795111092296
Number of train steps total  279000
Number of env steps total    1397000
Number of rollouts total     0
Train Time (s)               26.916435678955168
(Previous) Eval Time (s)     23.345904739107937
Sample Time (s)              18.035858403425664
Epoch Time (s)               68.29819882148877
Total Train Time (s)         19351.935573165305
Epoch                        278
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:38:03.949473 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #278 | Epoch Duration: 63.54137420654297
2020-01-11 08:38:03.949641 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #278 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9816324
Z variance train             0.013869239
KL Divergence                21.434872
KL Loss                      2.1434872
QF Loss                      471.97577
VF Loss                      83.84941
Policy Loss                  -1017.2503
Q Predictions Mean           1016.02264
Q Predictions Std            186.81361
Q Predictions Max            1231.208
Q Predictions Min            197.51277
V Predictions Mean           1016.30774
V Predictions Std            185.22737
V Predictions Max            1215.5858
V Predictions Min            202.81985
Log Pis Mean                 -0.33598834
Log Pis Std                  2.6981494
Log Pis Max                  8.769824
Log Pis Min                  -7.336196
Policy mu Mean               -0.000827322
Policy mu Std                0.5666678
Policy mu Max                2.382897
Policy mu Min                -2.2416494
Policy log std Mean          -0.9437562
Policy log std Std           0.25680655
Policy log std Max           -0.2794544
Policy log std Min           -2.4850667
Z mean eval                  1.0034134
Z variance eval              0.013064869
total_rewards                [2699.42816611 1222.20132363 2772.91826125 2785.61883157  118.23092954
 1702.04660164 1129.01841665  634.59467924  142.43857271  -44.14110322]
total_rewards_mean           1316.2354679112743
total_rewards_std            1073.0913172176186
total_rewards_max            2785.618831574092
total_rewards_min            -44.14110322497466
Number of train steps total  280000
Number of env steps total    1402000
Number of rollouts total     0
Train Time (s)               28.214889065828174
(Previous) Eval Time (s)     18.588782225269824
Sample Time (s)              18.44725735904649
Epoch Time (s)               65.25092865014449
Total Train Time (s)         19414.048739335965
Epoch                        279
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:39:06.064657 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #279 | Epoch Duration: 62.11488127708435
2020-01-11 08:39:06.064850 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #279 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.00324
Z variance train             0.013069252
KL Divergence                21.890858
KL Loss                      2.1890857
QF Loss                      1217.9052
VF Loss                      84.050476
Policy Loss                  -984.87854
Q Predictions Mean           981.9866
Q Predictions Std            238.74878
Q Predictions Max            1197.3895
Q Predictions Min            66.39337
V Predictions Mean           981.7793
V Predictions Std            233.32538
V Predictions Max            1187.1978
V Predictions Min            203.93323
Log Pis Mean                 -1.083596
Log Pis Std                  2.8087487
Log Pis Max                  9.799165
Log Pis Min                  -9.629069
Policy mu Mean               0.048304453
Policy mu Std                0.5501197
Policy mu Max                2.2579613
Policy mu Min                -1.7856241
Policy log std Mean          -0.91756916
Policy log std Std           0.2615818
Policy log std Max           -0.17663443
Policy log std Min           -2.2849445
Z mean eval                  0.9725062
Z variance eval              0.018030861
total_rewards                [2723.11805861 3019.20253593 2672.02604322  462.66381342 2682.74947059
 1213.52823829  346.92597061 2717.06575985 2751.31612838 2960.77607325]
total_rewards_mean           2154.93720921386
total_rewards_std            997.7839451072631
total_rewards_max            3019.2025359322497
total_rewards_min            346.9259706109066
Number of train steps total  281000
Number of env steps total    1407000
Number of rollouts total     0
Train Time (s)               28.39891829714179
(Previous) Eval Time (s)     15.452423000242561
Sample Time (s)              18.006762318313122
Epoch Time (s)               61.85810361569747
Total Train Time (s)         19482.796999422833
Epoch                        280
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:40:14.815767 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #280 | Epoch Duration: 68.75079321861267
2020-01-11 08:40:14.815943 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #280 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97250384
Z variance train             0.018100059
KL Divergence                20.451563
KL Loss                      2.0451562
QF Loss                      965.86646
VF Loss                      180.21439
Policy Loss                  -999.5759
Q Predictions Mean           997.17175
Q Predictions Std            209.71596
Q Predictions Max            1215.5778
Q Predictions Min            186.88666
V Predictions Mean           991.49316
V Predictions Std            206.88573
V Predictions Max            1217.4894
V Predictions Min            196.11752
Log Pis Mean                 -0.5740268
Log Pis Std                  2.4754252
Log Pis Max                  12.710774
Log Pis Min                  -7.1575313
Policy mu Mean               0.0007742818
Policy mu Std                0.5809941
Policy mu Max                1.9940453
Policy mu Min                -3.5542603
Policy log std Mean          -0.91457456
Policy log std Std           0.25755316
Policy log std Max           -0.15064347
Policy log std Min           -2.531649
Z mean eval                  0.98456347
Z variance eval              0.01333523
total_rewards                [1498.73083882 2780.5673771  2743.59852653  188.36265347  585.94620545
   78.74244782  275.07372816 1795.6138714  1368.48739427  750.51643075]
total_rewards_mean           1206.5639473782646
total_rewards_std            952.2634908305721
total_rewards_max            2780.5673771045213
total_rewards_min            78.7424478171285
Number of train steps total  282000
Number of env steps total    1412000
Number of rollouts total     0
Train Time (s)               29.398831170983613
(Previous) Eval Time (s)     22.344789501279593
Sample Time (s)              18.054657140746713
Epoch Time (s)               69.79827781300992
Total Train Time (s)         19547.40380659001
Epoch                        281
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:41:19.425027 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #281 | Epoch Duration: 64.60894560813904
2020-01-11 08:41:19.425210 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #281 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98316395
Z variance train             0.013319841
KL Divergence                21.13892
KL Loss                      2.113892
QF Loss                      1097.8367
VF Loss                      170.1114
Policy Loss                  -977.745
Q Predictions Mean           976.5045
Q Predictions Std            240.53084
Q Predictions Max            1206.1165
Q Predictions Min            187.35388
V Predictions Mean           976.7007
V Predictions Std            235.86725
V Predictions Max            1196.5977
V Predictions Min            192.52643
Log Pis Mean                 -0.59395635
Log Pis Std                  2.5288472
Log Pis Max                  9.159933
Log Pis Min                  -7.7777705
Policy mu Mean               0.00093196565
Policy mu Std                0.57756716
Policy mu Max                2.3353224
Policy mu Min                -2.9391282
Policy log std Mean          -0.9078336
Policy log std Std           0.27221707
Policy log std Max           -0.24292979
Policy log std Min           -2.7346108
Z mean eval                  0.9891645
Z variance eval              0.012197351
total_rewards                [1429.48783107  536.21369272 1281.89997937  451.33097444 1222.97288966
 2085.95209523  632.17533606  206.5228879  2003.30347524  301.29791586]
total_rewards_mean           1015.1157077545179
total_rewards_std            653.1837587471001
total_rewards_max            2085.9520952292614
total_rewards_min            206.52288790371244
Number of train steps total  283000
Number of env steps total    1417000
Number of rollouts total     0
Train Time (s)               26.604722534306347
(Previous) Eval Time (s)     17.155190762598068
Sample Time (s)              17.677926021628082
Epoch Time (s)               61.4378393185325
Total Train Time (s)         19606.636247057468
Epoch                        282
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:42:18.664179 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #282 | Epoch Duration: 59.23879361152649
2020-01-11 08:42:18.664454 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #282 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98751765
Z variance train             0.012199576
KL Divergence                21.708883
KL Loss                      2.1708884
QF Loss                      785.8716
VF Loss                      142.16093
Policy Loss                  -985.7951
Q Predictions Mean           983.2407
Q Predictions Std            246.9486
Q Predictions Max            1244.2126
Q Predictions Min            189.71196
V Predictions Mean           984.02893
V Predictions Std            242.29588
V Predictions Max            1242.8679
V Predictions Min            204.53743
Log Pis Mean                 -0.928576
Log Pis Std                  2.4446416
Log Pis Max                  6.6338334
Log Pis Min                  -8.163437
Policy mu Mean               0.0046418835
Policy mu Std                0.5543156
Policy mu Max                2.0014572
Policy mu Min                -2.2173867
Policy log std Mean          -0.889307
Policy log std Std           0.257624
Policy log std Max           -0.16574174
Policy log std Min           -2.3974257
Z mean eval                  0.9948322
Z variance eval              0.012822755
total_rewards                [2699.70729982 1504.44859205 1762.67179006 2716.26600341 2432.39734827
  791.6969955   402.8677789  2604.73577124 1696.99249457 1024.48677434]
total_rewards_mean           1763.6270848152028
total_rewards_std            797.0408724686304
total_rewards_max            2716.2660034090477
total_rewards_min            402.8677789024126
Number of train steps total  284000
Number of env steps total    1422000
Number of rollouts total     0
Train Time (s)               30.072708372958004
(Previous) Eval Time (s)     14.955827474128455
Sample Time (s)              17.804980455432087
Epoch Time (s)               62.83351630251855
Total Train Time (s)         19677.204993563704
Epoch                        283
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:43:29.235173 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #283 | Epoch Duration: 70.57050085067749
2020-01-11 08:43:29.235417 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #283 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9971854
Z variance train             0.012848785
KL Divergence                21.699654
KL Loss                      2.1699655
QF Loss                      898.6343
VF Loss                      163.88783
Policy Loss                  -994.92535
Q Predictions Mean           993.7029
Q Predictions Std            242.70284
Q Predictions Max            1226.5186
Q Predictions Min            153.05249
V Predictions Mean           993.5508
V Predictions Std            239.93051
V Predictions Max            1225.629
V Predictions Min            208.95844
Log Pis Mean                 -0.7192426
Log Pis Std                  2.4939601
Log Pis Max                  9.487399
Log Pis Min                  -7.852015
Policy mu Mean               0.044583343
Policy mu Std                0.5687089
Policy mu Max                2.0252037
Policy mu Min                -1.8942013
Policy log std Mean          -0.92668605
Policy log std Std           0.26300696
Policy log std Max           -0.022086322
Policy log std Min           -2.4736533
Z mean eval                  0.9706335
Z variance eval              0.008642638
total_rewards                [2467.80041285  587.95463136  882.19724784 2762.14012742  175.42332907
 2662.32534308 1958.09438381 2728.22393296 2816.90644963   32.81364111]
total_rewards_mean           1707.3879499120376
total_rewards_std            1096.5314031433863
total_rewards_max            2816.906449627369
total_rewards_min            32.813641114243815
Number of train steps total  285000
Number of env steps total    1427000
Number of rollouts total     0
Train Time (s)               27.451157657895237
(Previous) Eval Time (s)     22.692499585915357
Sample Time (s)              18.536211075261235
Epoch Time (s)               68.67986831907183
Total Train Time (s)         19742.32780171372
Epoch                        284
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:44:34.363958 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #284 | Epoch Duration: 65.12831902503967
2020-01-11 08:44:34.364282 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #284 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.970693
Z variance train             0.008618806
KL Divergence                22.765413
KL Loss                      2.2765415
QF Loss                      1331.8992
VF Loss                      155.51062
Policy Loss                  -992.31055
Q Predictions Mean           991.55927
Q Predictions Std            248.14049
Q Predictions Max            1234.3345
Q Predictions Min            -37.054924
V Predictions Mean           990.41516
V Predictions Std            242.96033
V Predictions Max            1228.0107
V Predictions Min            48.16532
Log Pis Mean                 -0.93615496
Log Pis Std                  2.3824651
Log Pis Max                  6.7202396
Log Pis Min                  -9.345359
Policy mu Mean               0.02586007
Policy mu Std                0.5279806
Policy mu Max                1.740595
Policy mu Min                -1.7286052
Policy log std Mean          -0.94259536
Policy log std Std           0.26272786
Policy log std Max           -0.25017303
Policy log std Min           -2.2158425
Z mean eval                  0.95114404
Z variance eval              0.017058374
total_rewards                [ 332.99439752 1642.49913357   27.070355   1077.52011488  309.80611934
 2739.95030839 1943.51510007  683.92907002 2839.34482115  279.96415068]
total_rewards_mean           1187.6593570613284
total_rewards_std            992.6580463874773
total_rewards_max            2839.3448211478626
total_rewards_min            27.07035500297172
Number of train steps total  286000
Number of env steps total    1432000
Number of rollouts total     0
Train Time (s)               27.93633846612647
(Previous) Eval Time (s)     19.14062048867345
Sample Time (s)              17.75099237728864
Epoch Time (s)               64.82795133208856
Total Train Time (s)         19800.618681967724
Epoch                        285
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:45:32.656063 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #285 | Epoch Duration: 58.29156565666199
2020-01-11 08:45:32.656238 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #285 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95248014
Z variance train             0.017053977
KL Divergence                21.107704
KL Loss                      2.1107705
QF Loss                      1206.1846
VF Loss                      140.18236
Policy Loss                  -992.99304
Q Predictions Mean           989.87305
Q Predictions Std            237.9048
Q Predictions Max            1223.4258
Q Predictions Min            163.29108
V Predictions Mean           988.4863
V Predictions Std            235.45836
V Predictions Max            1224.2012
V Predictions Min            177.5927
Log Pis Mean                 -0.81303906
Log Pis Std                  2.6881888
Log Pis Max                  7.3159285
Log Pis Min                  -11.50816
Policy mu Mean               0.04995314
Policy mu Std                0.5570719
Policy mu Max                2.3145258
Policy mu Min                -2.0927672
Policy log std Mean          -0.90815794
Policy log std Std           0.26572114
Policy log std Max           -0.087248385
Policy log std Min           -2.2150912
Z mean eval                  0.9889906
Z variance eval              0.019622155
total_rewards                [ 406.4961589  2735.2403834  2256.54527646 2681.63750842 2734.5834724
 2667.71993843 3003.22224094  419.0213502  2667.17918206 2885.03424668]
total_rewards_mean           2245.6679757892043
total_rewards_std            934.1614084381222
total_rewards_max            3003.2222409421006
total_rewards_min            406.496158900822
Number of train steps total  287000
Number of env steps total    1437000
Number of rollouts total     0
Train Time (s)               27.558294726070017
(Previous) Eval Time (s)     12.60396349336952
Sample Time (s)              17.731458948459476
Epoch Time (s)               57.89371716789901
Total Train Time (s)         19870.875338524114
Epoch                        286
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:46:42.916172 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #286 | Epoch Duration: 70.2597599029541
2020-01-11 08:46:42.916350 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #286 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98837614
Z variance train             0.01967522
KL Divergence                20.933096
KL Loss                      2.0933096
QF Loss                      719.3629
VF Loss                      447.44626
Policy Loss                  -1040.2999
Q Predictions Mean           1039.502
Q Predictions Std            205.80202
Q Predictions Max            1251.9819
Q Predictions Min            -20.169662
V Predictions Mean           1027.4536
V Predictions Std            203.28615
V Predictions Max            1228.1858
V Predictions Min            83.012344
Log Pis Mean                 -0.5114736
Log Pis Std                  2.63809
Log Pis Max                  10.702351
Log Pis Min                  -8.33171
Policy mu Mean               -0.004221846
Policy mu Std                0.56447
Policy mu Max                1.8380836
Policy mu Min                -2.8506522
Policy log std Mean          -0.97039473
Policy log std Std           0.27283934
Policy log std Max           -0.27633703
Policy log std Min           -2.8501194
Z mean eval                  0.9845462
Z variance eval              0.018725166
total_rewards                [2928.93013424 2720.69585193 1367.54376988 1497.81386086 2965.9145651
 2823.08764161  726.98358529 3161.61636713  894.99426944 3056.83636711]
total_rewards_mean           2214.4416412597975
total_rewards_std            921.5737459552788
total_rewards_max            3161.6163671322174
total_rewards_min            726.9835852940932
Number of train steps total  288000
Number of env steps total    1442000
Number of rollouts total     0
Train Time (s)               27.176779748871922
(Previous) Eval Time (s)     24.969716851133853
Sample Time (s)              17.410834246315062
Epoch Time (s)               69.55733084632084
Total Train Time (s)         19940.23902124772
Epoch                        287
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:47:52.281096 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #287 | Epoch Duration: 69.3646068572998
2020-01-11 08:47:52.281250 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #287 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9850215
Z variance train             0.018688682
KL Divergence                20.70414
KL Loss                      2.070414
QF Loss                      709.7019
VF Loss                      108.89184
Policy Loss                  -979.53485
Q Predictions Mean           977.0354
Q Predictions Std            265.1939
Q Predictions Max            1191.0099
Q Predictions Min            49.783646
V Predictions Mean           979.60785
V Predictions Std            260.8798
V Predictions Max            1192.9882
V Predictions Min            153.99817
Log Pis Mean                 -0.7638339
Log Pis Std                  2.5294235
Log Pis Max                  12.705559
Log Pis Min                  -9.052983
Policy mu Mean               -0.027720567
Policy mu Std                0.57078594
Policy mu Max                2.1787262
Policy mu Min                -2.119836
Policy log std Mean          -0.92665136
Policy log std Std           0.27204382
Policy log std Max           -0.25070179
Policy log std Min           -2.7723763
Z mean eval                  0.9585146
Z variance eval              0.01313054
total_rewards                [ 173.46733619 2711.57495616 3093.06830189  637.65057556 2832.87590981
 2417.67244897 1631.93738465 2896.83091811 2857.00666904 2813.49608625]
total_rewards_mean           2206.558058663878
total_rewards_std            983.4041434954028
total_rewards_max            3093.068301885775
total_rewards_min            173.46733619451743
Number of train steps total  289000
Number of env steps total    1447000
Number of rollouts total     0
Train Time (s)               28.780223749112338
(Previous) Eval Time (s)     24.776719061192125
Sample Time (s)              17.826332496013492
Epoch Time (s)               71.38327530631796
Total Train Time (s)         20010.33339024894
Epoch                        288
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:49:02.379807 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #288 | Epoch Duration: 70.09841060638428
2020-01-11 08:49:02.380007 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #288 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95845044
Z variance train             0.013111906
KL Divergence                20.81727
KL Loss                      2.081727
QF Loss                      646.1208
VF Loss                      200.48392
Policy Loss                  -996.09894
Q Predictions Mean           995.6133
Q Predictions Std            244.66774
Q Predictions Max            1224.1925
Q Predictions Min            196.79826
V Predictions Mean           995.9641
V Predictions Std            244.56224
V Predictions Max            1207.1105
V Predictions Min            197.73965
Log Pis Mean                 -0.7080251
Log Pis Std                  2.7925863
Log Pis Max                  9.470972
Log Pis Min                  -9.027713
Policy mu Mean               -0.031487748
Policy mu Std                0.5478889
Policy mu Max                1.9953502
Policy mu Min                -2.0607772
Policy log std Mean          -0.9604434
Policy log std Std           0.27524307
Policy log std Max           -0.18056703
Policy log std Min           -2.6511383
Z mean eval                  0.9918542
Z variance eval              0.015914151
total_rewards                [ 175.1280809  2916.09860516 2658.63312517 2514.3688019  2824.065807
  996.62272491 2117.53112209 2317.38034675 2749.10655149 2044.71302201]
total_rewards_mean           2131.3648187370677
total_rewards_std            840.1639135807231
total_rewards_max            2916.098605160666
total_rewards_min            175.12808090034164
Number of train steps total  290000
Number of env steps total    1452000
Number of rollouts total     0
Train Time (s)               28.847811996005476
(Previous) Eval Time (s)     23.49155746260658
Sample Time (s)              17.597696573473513
Epoch Time (s)               69.93706603208557
Total Train Time (s)         20079.25471341377
Epoch                        289
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:50:11.305794 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #289 | Epoch Duration: 68.92560172080994
2020-01-11 08:50:11.306083 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #289 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9934894
Z variance train             0.015923847
KL Divergence                20.458597
KL Loss                      2.0458598
QF Loss                      1241.4775
VF Loss                      183.3079
Policy Loss                  -1010.36523
Q Predictions Mean           1007.79565
Q Predictions Std            217.00061
Q Predictions Max            1220.8066
Q Predictions Min            178.89714
V Predictions Mean           1007.571
V Predictions Std            216.96475
V Predictions Max            1218.4756
V Predictions Min            151.69254
Log Pis Mean                 -0.51056874
Log Pis Std                  2.7699246
Log Pis Max                  11.811334
Log Pis Min                  -8.23887
Policy mu Mean               0.019389648
Policy mu Std                0.5457267
Policy mu Max                3.127679
Policy mu Min                -2.108801
Policy log std Mean          -0.9753953
Policy log std Std           0.26657647
Policy log std Max           -0.099070966
Policy log std Min           -2.4155777
Z mean eval                  0.96355516
Z variance eval              0.015808854
total_rewards                [ -68.9823651   460.16492087 2655.48731578 2951.56464719  783.13901203
 2949.71229195  862.86310531 2528.00028379 2807.94684815 2675.23755519]
total_rewards_mean           1860.5133615153204
total_rewards_std            1133.8274276808754
total_rewards_max            2951.564647191349
total_rewards_min            -68.98236510066928
Number of train steps total  291000
Number of env steps total    1457000
Number of rollouts total     0
Train Time (s)               26.626282849814743
(Previous) Eval Time (s)     22.47982009127736
Sample Time (s)              17.621487942989916
Epoch Time (s)               66.72759088408202
Total Train Time (s)         20144.424559214152
Epoch                        290
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:51:16.477759 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #290 | Epoch Duration: 65.17147517204285
2020-01-11 08:51:16.477952 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #290 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9626733
Z variance train             0.015825724
KL Divergence                20.707602
KL Loss                      2.0707603
QF Loss                      2185.0244
VF Loss                      194.93944
Policy Loss                  -1025.5912
Q Predictions Mean           1024.2404
Q Predictions Std            189.85712
Q Predictions Max            1208.8654
Q Predictions Min            184.60144
V Predictions Mean           1028.6564
V Predictions Std            187.37125
V Predictions Max            1213.5773
V Predictions Min            196.70107
Log Pis Mean                 -0.4822239
Log Pis Std                  2.6981933
Log Pis Max                  16.139519
Log Pis Min                  -6.839864
Policy mu Mean               0.039995044
Policy mu Std                0.5623378
Policy mu Max                3.024603
Policy mu Min                -2.620271
Policy log std Mean          -0.9427496
Policy log std Std           0.25161842
Policy log std Max           -0.24505255
Policy log std Min           -2.473021
Z mean eval                  0.9883525
Z variance eval              0.022509474
total_rewards                [  -8.47007751 1791.93701403  884.84843609 2841.53444638 2704.59417001
 2883.44003365 2845.76471514 1144.46259465  632.74019097 2950.6745771 ]
total_rewards_mean           1867.1526100516032
total_rewards_std            1065.3574134016267
total_rewards_max            2950.6745771025962
total_rewards_min            -8.470077514965151
Number of train steps total  292000
Number of env steps total    1462000
Number of rollouts total     0
Train Time (s)               28.75298480130732
(Previous) Eval Time (s)     20.923448436893523
Sample Time (s)              19.132541581522673
Epoch Time (s)               68.80897481972352
Total Train Time (s)         20209.910300896503
Epoch                        291
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:52:21.965794 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #291 | Epoch Duration: 65.48771262168884
2020-01-11 08:52:21.965973 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #291 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98841065
Z variance train             0.022491682
KL Divergence                20.451347
KL Loss                      2.0451348
QF Loss                      674.43176
VF Loss                      130.64
Policy Loss                  -1003.15424
Q Predictions Mean           1001.9164
Q Predictions Std            240.91226
Q Predictions Max            1231.6685
Q Predictions Min            174.65114
V Predictions Mean           996.5497
V Predictions Std            237.06786
V Predictions Max            1228.6523
V Predictions Min            177.61948
Log Pis Mean                 -0.57096475
Log Pis Std                  2.566654
Log Pis Max                  7.6027565
Log Pis Min                  -8.184429
Policy mu Mean               0.055970725
Policy mu Std                0.5325196
Policy mu Max                2.0776591
Policy mu Min                -1.9488724
Policy log std Mean          -0.9462828
Policy log std Std           0.26630655
Policy log std Max           -0.22602636
Policy log std Min           -2.255158
Z mean eval                  1.0062072
Z variance eval              0.018455029
total_rewards                [2652.67525419 1418.48994409  360.73408203 2749.02153333 2762.89996925
 2785.15988748 2750.59822665 2785.13683016 2532.12198297 2802.60331712]
total_rewards_mean           2359.9441027270273
total_rewards_std            776.0427314418394
total_rewards_max            2802.603317123706
total_rewards_min            360.7340820271248
Number of train steps total  293000
Number of env steps total    1467000
Number of rollouts total     0
Train Time (s)               25.911016115918756
(Previous) Eval Time (s)     17.601829512044787
Sample Time (s)              18.252729852683842
Epoch Time (s)               61.765575480647385
Total Train Time (s)         20276.338876459282
Epoch                        292
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:53:28.397927 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #292 | Epoch Duration: 66.43180418014526
2020-01-11 08:53:28.398133 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #292 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0068252
Z variance train             0.018499652
KL Divergence                20.740566
KL Loss                      2.0740566
QF Loss                      3644.1084
VF Loss                      913.843
Policy Loss                  -1040.1288
Q Predictions Mean           1038.3839
Q Predictions Std            222.88094
Q Predictions Max            1235.9335
Q Predictions Min            192.49425
V Predictions Mean           1030.4087
V Predictions Std            218.46826
V Predictions Max            1222.0157
V Predictions Min            182.03763
Log Pis Mean                 -0.66768134
Log Pis Std                  2.60504
Log Pis Max                  10.854344
Log Pis Min                  -9.150272
Policy mu Mean               0.0466723
Policy mu Std                0.56529564
Policy mu Max                2.17443
Policy mu Min                -2.6273994
Policy log std Mean          -0.9448849
Policy log std Std           0.2845296
Policy log std Max           -0.18558556
Policy log std Min           -2.975766
Z mean eval                  0.9796325
Z variance eval              0.015150445
total_rewards                [ 569.80748132  623.33920323  152.53973074  750.27249412 2531.67834375
 2627.67182987  458.16253188 2731.16781594 1825.35656875  830.08686451]
total_rewards_mean           1310.00828641145
total_rewards_std            956.1594134945669
total_rewards_max            2731.1678159407156
total_rewards_min            152.53973073905468
Number of train steps total  294000
Number of env steps total    1472000
Number of rollouts total     0
Train Time (s)               31.104777714703232
(Previous) Eval Time (s)     22.26776241278276
Sample Time (s)              17.60227844817564
Epoch Time (s)               70.97481857566163
Total Train Time (s)         20338.26529416954
Epoch                        293
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:54:30.329960 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #293 | Epoch Duration: 61.93164253234863
2020-01-11 08:54:30.330228 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #293 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9791769
Z variance train             0.01514214
KL Divergence                20.034925
KL Loss                      2.0034926
QF Loss                      719.5033
VF Loss                      115.81386
Policy Loss                  -1003.71356
Q Predictions Mean           1002.64636
Q Predictions Std            243.11014
Q Predictions Max            1273.7958
Q Predictions Min            181.99736
V Predictions Mean           1003.2544
V Predictions Std            243.20854
V Predictions Max            1273.9158
V Predictions Min            174.48927
Log Pis Mean                 -0.6012325
Log Pis Std                  2.9178607
Log Pis Max                  19.126907
Log Pis Min                  -6.6868396
Policy mu Mean               0.04281719
Policy mu Std                0.5643686
Policy mu Max                3.366173
Policy mu Min                -4.378579
Policy log std Mean          -0.9440088
Policy log std Std           0.28387585
Policy log std Max           -0.23371673
Policy log std Min           -2.8292577
Z mean eval                  1.012339
Z variance eval              0.014743145
total_rewards                [ 752.7806644  2807.67197286 2434.34237801 1122.35859333 2753.14999045
 1268.64485868  124.50133193 2306.98728434  991.25512423  694.38750721]
total_rewards_mean           1525.6079705443694
total_rewards_std            913.912564417465
total_rewards_max            2807.671972863221
total_rewards_min            124.50133193252728
Number of train steps total  295000
Number of env steps total    1477000
Number of rollouts total     0
Train Time (s)               28.249680125620216
(Previous) Eval Time (s)     13.224280964583158
Sample Time (s)              17.689317076466978
Epoch Time (s)               59.16327816667035
Total Train Time (s)         20401.578219010495
Epoch                        294
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:55:33.646450 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #294 | Epoch Duration: 63.31600499153137
2020-01-11 08:55:33.646701 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #294 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.014199
Z variance train             0.014645775
KL Divergence                20.644096
KL Loss                      2.0644097
QF Loss                      643.27844
VF Loss                      231.60207
Policy Loss                  -1070.6542
Q Predictions Mean           1068.0854
Q Predictions Std            197.62715
Q Predictions Max            1278.5927
Q Predictions Min            -62.931873
V Predictions Mean           1058.1372
V Predictions Std            188.49379
V Predictions Max            1256.3541
V Predictions Min            -3.317434
Log Pis Mean                 -0.2672299
Log Pis Std                  2.830993
Log Pis Max                  20.9891
Log Pis Min                  -6.8864107
Policy mu Mean               0.023029428
Policy mu Std                0.6090449
Policy mu Max                2.054446
Policy mu Min                -3.196817
Policy log std Mean          -0.9357914
Policy log std Std           0.24300279
Policy log std Max           -0.22364318
Policy log std Min           -2.6083837
Z mean eval                  0.98116094
Z variance eval              0.020908691
total_rewards                [2915.35188468  952.37607084 3183.16685483 3274.68853424  126.14950054
 2193.17668745 2794.66449498 3129.51198426 3058.74375515 2227.876807  ]
total_rewards_mean           2385.570657397904
total_rewards_std            1005.0990202098066
total_rewards_max            3274.688534243922
total_rewards_min            126.14950054189484
Number of train steps total  296000
Number of env steps total    1482000
Number of rollouts total     0
Train Time (s)               31.445467167999595
(Previous) Eval Time (s)     17.376690763048828
Sample Time (s)              17.398818348534405
Epoch Time (s)               66.22097627958283
Total Train Time (s)         20476.63697717944
Epoch                        295
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:56:48.707194 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #295 | Epoch Duration: 75.06030321121216
2020-01-11 08:56:48.707367 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #295 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98099434
Z variance train             0.020935306
KL Divergence                20.43367
KL Loss                      2.0433671
QF Loss                      1733.4856
VF Loss                      303.79425
Policy Loss                  -1009.3521
Q Predictions Mean           1008.0818
Q Predictions Std            271.49478
Q Predictions Max            1240.0647
Q Predictions Min            9.2720785
V Predictions Mean           998.53613
V Predictions Std            265.36163
V Predictions Max            1226.1014
V Predictions Min            159.82417
Log Pis Mean                 -0.6731702
Log Pis Std                  2.4474409
Log Pis Max                  10.403327
Log Pis Min                  -7.7080727
Policy mu Mean               0.0019396106
Policy mu Std                0.5173705
Policy mu Max                1.692059
Policy mu Min                -1.8655103
Policy log std Mean          -0.9721993
Policy log std Std           0.30363813
Policy log std Max           -0.13763654
Policy log std Min           -2.708753
Z mean eval                  1.0203621
Z variance eval              0.015834445
total_rewards                [  74.44250899 2597.50346452 3093.62722267 2657.71473621 2312.02586743
  414.22663678  405.31989716  109.45159763 2068.16369417 1633.15588055]
total_rewards_mean           1536.563150611233
total_rewards_std            1114.1853604634698
total_rewards_max            3093.6272226703495
total_rewards_min            74.44250898974366
Number of train steps total  297000
Number of env steps total    1487000
Number of rollouts total     0
Train Time (s)               28.72117742104456
(Previous) Eval Time (s)     26.215742751024663
Sample Time (s)              18.446811047382653
Epoch Time (s)               73.38373121945187
Total Train Time (s)         20543.16864346806
Epoch                        296
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:57:55.243741 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #296 | Epoch Duration: 66.53622388839722
2020-01-11 08:57:55.243965 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #296 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0218171
Z variance train             0.01584483
KL Divergence                21.281424
KL Loss                      2.1281424
QF Loss                      7941.8164
VF Loss                      255.9177
Policy Loss                  -1013.5749
Q Predictions Mean           1015.9099
Q Predictions Std            253.49915
Q Predictions Max            1254.2598
Q Predictions Min            -14.918844
V Predictions Mean           1024.1212
V Predictions Std            251.16422
V Predictions Max            1260.8378
V Predictions Min            5.0513434
Log Pis Mean                 -0.8360374
Log Pis Std                  2.7956026
Log Pis Max                  11.445609
Log Pis Min                  -11.703376
Policy mu Mean               0.028285515
Policy mu Std                0.5517872
Policy mu Max                2.0793483
Policy mu Min                -2.085218
Policy log std Mean          -0.92284966
Policy log std Std           0.26031077
Policy log std Max           -0.18233222
Policy log std Min           -2.215471
Z mean eval                  1.0061617
Z variance eval              0.013323833
total_rewards                [3093.43755615 2886.20232327 2423.96372768 2729.14742816 2844.77289667
  533.5924521  2641.8788851  1864.05170912 2341.85772469 2956.88990029]
total_rewards_mean           2431.579460322486
total_rewards_std            718.1045136517845
total_rewards_max            3093.437556152457
total_rewards_min            533.5924520962541
Number of train steps total  298000
Number of env steps total    1492000
Number of rollouts total     0
Train Time (s)               28.527733487077057
(Previous) Eval Time (s)     19.367927559651434
Sample Time (s)              18.35458673769608
Epoch Time (s)               66.25024778442457
Total Train Time (s)         20615.036079605576
Epoch                        297
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:59:07.112403 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #297 | Epoch Duration: 71.86828088760376
2020-01-11 08:59:07.112610 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #297 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0061135
Z variance train             0.013313946
KL Divergence                21.242277
KL Loss                      2.1242278
QF Loss                      1160.8334
VF Loss                      141.23807
Policy Loss                  -1052.7239
Q Predictions Mean           1048.9817
Q Predictions Std            197.95969
Q Predictions Max            1260.3365
Q Predictions Min            45.098785
V Predictions Mean           1059.7166
V Predictions Std            194.4307
V Predictions Max            1254.0142
V Predictions Min            191.63202
Log Pis Mean                 -0.2333852
Log Pis Std                  2.614247
Log Pis Max                  13.2809105
Log Pis Min                  -8.200191
Policy mu Mean               -0.0016814738
Policy mu Std                0.5642091
Policy mu Max                1.974562
Policy mu Min                -2.044259
Policy log std Mean          -0.9796079
Policy log std Std           0.28237224
Policy log std Max           -0.17808956
Policy log std Min           -2.9520044
Z mean eval                  1.0069494
Z variance eval              0.025677016
total_rewards                [2912.43392646 2805.28728411 2876.39001051 3021.71382266  431.75149965
    5.85752725 2708.58110965  710.81308168 2995.0803427  2854.3674384 ]
total_rewards_mean           2132.2276043069774
total_rewards_std            1159.2396965549456
total_rewards_max            3021.713822661875
total_rewards_min            5.857527246786799
Number of train steps total  299000
Number of env steps total    1497000
Number of rollouts total     0
Train Time (s)               28.183228339999914
(Previous) Eval Time (s)     24.985637047793716
Sample Time (s)              17.3959924983792
Epoch Time (s)               70.56485788617283
Total Train Time (s)         20683.694337628316
Epoch                        298
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:00:15.777619 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #298 | Epoch Duration: 68.66482782363892
2020-01-11 09:00:15.777911 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #298 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0057617
Z variance train             0.025836026
KL Divergence                19.829573
KL Loss                      1.9829572
QF Loss                      4567.0127
VF Loss                      189.60066
Policy Loss                  -1033.5544
Q Predictions Mean           1030.2817
Q Predictions Std            235.61568
Q Predictions Max            1201.6774
Q Predictions Min            172.0043
V Predictions Mean           1037.1929
V Predictions Std            235.4988
V Predictions Max            1207.4465
V Predictions Min            170.61995
Log Pis Mean                 -0.60154045
Log Pis Std                  2.630797
Log Pis Max                  8.961423
Log Pis Min                  -8.553708
Policy mu Mean               0.045447223
Policy mu Std                0.5616901
Policy mu Max                1.9632881
Policy mu Min                -2.4202948
Policy log std Mean          -0.94319475
Policy log std Std           0.26335096
Policy log std Max           -0.1349113
Policy log std Min           -2.056931
Z mean eval                  0.99307954
Z variance eval              0.020947676
total_rewards                [2790.10892499 2693.53489233 1688.2942517  2959.65491308 2990.93220755
 2770.01966561 2887.01168752 2141.37762698 2852.43866473 2651.29056886]
total_rewards_mean           2642.4663403352915
total_rewards_std            390.9240560678031
total_rewards_max            2990.932207551882
total_rewards_min            1688.294251700738
Number of train steps total  300000
Number of env steps total    1502000
Number of rollouts total     0
Train Time (s)               28.33671235991642
(Previous) Eval Time (s)     23.085308710113168
Sample Time (s)              17.737847020849586
Epoch Time (s)               69.15986809087917
Total Train Time (s)         20756.971401505172
Epoch                        299
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:01:29.056998 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #299 | Epoch Duration: 73.27887082099915
2020-01-11 09:01:29.057207 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #299 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9926506
Z variance train             0.021014784
KL Divergence                20.328236
KL Loss                      2.0328236
QF Loss                      1622.7433
VF Loss                      249.09515
Policy Loss                  -1053.3785
Q Predictions Mean           1052.5216
Q Predictions Std            237.02556
Q Predictions Max            1274.7701
Q Predictions Min            74.2307
V Predictions Mean           1055.4099
V Predictions Std            234.5965
V Predictions Max            1267.1003
V Predictions Min            81.902725
Log Pis Mean                 -0.40585116
Log Pis Std                  2.6753666
Log Pis Max                  9.8624325
Log Pis Min                  -9.818968
Policy mu Mean               0.0047626486
Policy mu Std                0.56891555
Policy mu Max                2.0737352
Policy mu Min                -2.6034935
Policy log std Mean          -0.95753485
Policy log std Std           0.2792751
Policy log std Max           -0.26344126
Policy log std Min           -2.6404853
Z mean eval                  0.98853046
Z variance eval              0.030718114
total_rewards                [2397.30429474 2986.10400615 2873.76965494 1066.81986145 3036.15833092
 3031.8148493  2815.58087241  818.39795359 2834.53814709 3062.92445615]
total_rewards_mean           2492.34124267447
total_rewards_std            797.8994451665416
total_rewards_max            3062.924456145404
total_rewards_min            818.3979535923171
Number of train steps total  301000
Number of env steps total    1507000
Number of rollouts total     0
Train Time (s)               27.884153217077255
(Previous) Eval Time (s)     27.20401699002832
Sample Time (s)              18.392523063346744
Epoch Time (s)               73.48069327045232
Total Train Time (s)         20826.045789769385
Epoch                        300
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:02:38.138766 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #300 | Epoch Duration: 69.08136248588562
2020-01-11 09:02:38.139066 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #300 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98808277
Z variance train             0.03067493
KL Divergence                19.887707
KL Loss                      1.9887707
QF Loss                      584.20355
VF Loss                      100.844185
Policy Loss                  -1036.4213
Q Predictions Mean           1035.9457
Q Predictions Std            216.26062
Q Predictions Max            1303.0645
Q Predictions Min            168.20717
V Predictions Mean           1031.2152
V Predictions Std            213.4179
V Predictions Max            1285.3353
V Predictions Min            167.57693
Log Pis Mean                 -0.33005565
Log Pis Std                  2.8552094
Log Pis Max                  11.172192
Log Pis Min                  -6.9492397
Policy mu Mean               0.037132524
Policy mu Std                0.56902117
Policy mu Max                2.2893949
Policy mu Min                -1.946026
Policy log std Mean          -0.9851533
Policy log std Std           0.27211595
Policy log std Max           -0.14332122
Policy log std Min           -2.296825
Z mean eval                  0.9663043
Z variance eval              0.023973797
total_rewards                [2067.96754229 2763.02919031 1265.1095861    95.29481099 2754.51933991
  577.25960303  169.14326372 2962.73205621 2154.97005989  239.45896939]
total_rewards_mean           1504.9484421844404
total_rewards_std            1109.0508542352488
total_rewards_max            2962.7320562055716
total_rewards_min            95.2948109931715
Number of train steps total  302000
Number of env steps total    1512000
Number of rollouts total     0
Train Time (s)               29.425149991177022
(Previous) Eval Time (s)     22.80436234967783
Sample Time (s)              17.870709882117808
Epoch Time (s)               70.10022222297266
Total Train Time (s)         20887.91647733096
Epoch                        301
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:03:40.011522 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #301 | Epoch Duration: 61.87222599983215
2020-01-11 09:03:40.011734 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #301 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9668237
Z variance train             0.024052186
KL Divergence                20.100212
KL Loss                      2.0100212
QF Loss                      911.77014
VF Loss                      93.012665
Policy Loss                  -1084.4312
Q Predictions Mean           1085.2336
Q Predictions Std            195.27063
Q Predictions Max            1307.8561
Q Predictions Min            150.87776
V Predictions Mean           1081.7743
V Predictions Std            192.38812
V Predictions Max            1290.2275
V Predictions Min            145.37112
Log Pis Mean                 -0.6295414
Log Pis Std                  2.7149692
Log Pis Max                  7.3654737
Log Pis Min                  -8.132061
Policy mu Mean               0.033812556
Policy mu Std                0.6035768
Policy mu Max                2.1058316
Policy mu Min                -2.715131
Policy log std Mean          -0.9195733
Policy log std Std           0.2389767
Policy log std Max           -0.17569554
Policy log std Min           -1.9084489
Z mean eval                  0.97807866
Z variance eval              0.023461908
total_rewards                [ 273.85611612  485.3184871  2580.80407028    7.21649025  683.67451132
  448.19827746 3150.05712265 1785.83711689 2873.08909021 2039.95626073]
total_rewards_mean           1432.8007543011875
total_rewards_std            1124.2055862362092
total_rewards_max            3150.0571226503585
total_rewards_min            7.21649025136494
Number of train steps total  303000
Number of env steps total    1517000
Number of rollouts total     0
Train Time (s)               26.48399672936648
(Previous) Eval Time (s)     14.576075269840658
Sample Time (s)              18.115101367700845
Epoch Time (s)               59.175173366907984
Total Train Time (s)         20947.871640178375
Epoch                        302
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:04:39.971994 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #302 | Epoch Duration: 59.95994424819946
2020-01-11 09:04:39.972248 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #302 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9773372
Z variance train             0.023382917
KL Divergence                19.3237
KL Loss                      1.9323701
QF Loss                      1150.8115
VF Loss                      302.50897
Policy Loss                  -1032.224
Q Predictions Mean           1030.9424
Q Predictions Std            245.8133
Q Predictions Max            1226.1471
Q Predictions Min            37.185295
V Predictions Mean           1046.2551
V Predictions Std            246.69434
V Predictions Max            1250.4598
V Predictions Min            38.397957
Log Pis Mean                 -0.7324753
Log Pis Std                  2.5872047
Log Pis Max                  9.286767
Log Pis Min                  -7.519699
Policy mu Mean               0.016574968
Policy mu Std                0.5395583
Policy mu Max                2.217634
Policy mu Min                -2.4487972
Policy log std Mean          -0.9573746
Policy log std Std           0.27179262
Policy log std Max           -0.19288945
Policy log std Min           -2.5444453
Z mean eval                  0.9738925
Z variance eval              0.026530767
total_rewards                [2496.81504488 2833.67125659 2049.54822297 1551.68855328 2668.10659036
 2736.73910795 2659.84603171 2662.87573502 2622.02643641 2639.25757845]
total_rewards_mean           2492.057455762021
total_rewards_std            371.9657012344663
total_rewards_max            2833.6712565869975
total_rewards_min            1551.6885532775516
Number of train steps total  304000
Number of env steps total    1522000
Number of rollouts total     0
Train Time (s)               28.283010341227055
(Previous) Eval Time (s)     15.360579940024763
Sample Time (s)              17.332224453333765
Epoch Time (s)               60.97581473458558
Total Train Time (s)         21020.24897094723
Epoch                        303
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:05:52.354235 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #303 | Epoch Duration: 72.38176846504211
2020-01-11 09:05:52.354545 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #303 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9748564
Z variance train             0.026517471
KL Divergence                19.451626
KL Loss                      1.9451627
QF Loss                      890.87646
VF Loss                      199.21815
Policy Loss                  -1040.8842
Q Predictions Mean           1036.7302
Q Predictions Std            228.52597
Q Predictions Max            1249.9775
Q Predictions Min            -7.068587
V Predictions Mean           1049.4438
V Predictions Std            226.6762
V Predictions Max            1255.1283
V Predictions Min            -17.287848
Log Pis Mean                 -0.42143223
Log Pis Std                  2.5535932
Log Pis Max                  6.882023
Log Pis Min                  -8.06723
Policy mu Mean               0.10246697
Policy mu Std                0.5665942
Policy mu Max                2.159653
Policy mu Min                -2.1354103
Policy log std Mean          -0.96956456
Policy log std Std           0.2745529
Policy log std Max           -0.21829695
Policy log std Min           -2.2841036
Z mean eval                  0.99834573
Z variance eval              0.026705569
total_rewards                [2971.83478853 1021.27003757 3027.99202226  714.20113987 2813.19260475
 1287.36476476  164.15476974  807.66304678  -73.64639371  926.07614781]
total_rewards_mean           1366.010292836647
total_rewards_std            1095.78465635753
total_rewards_max            3027.9920222627043
total_rewards_min            -73.64639371392383
Number of train steps total  305000
Number of env steps total    1527000
Number of rollouts total     0
Train Time (s)               29.291408041957766
(Previous) Eval Time (s)     26.766230867709965
Sample Time (s)              18.656755515839905
Epoch Time (s)               74.71439442550763
Total Train Time (s)         21085.895788887516
Epoch                        304
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:06:58.004226 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #304 | Epoch Duration: 65.6494402885437
2020-01-11 09:06:58.004445 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #304 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0001984
Z variance train             0.026716804
KL Divergence                19.539986
KL Loss                      1.9539986
QF Loss                      917.94727
VF Loss                      434.02164
Policy Loss                  -1008.2492
Q Predictions Mean           1008.3783
Q Predictions Std            267.87622
Q Predictions Max            1254.4891
Q Predictions Min            75.094124
V Predictions Mean           1005.18146
V Predictions Std            266.46893
V Predictions Max            1250.1052
V Predictions Min            53.59222
Log Pis Mean                 -0.9320471
Log Pis Std                  2.9036002
Log Pis Max                  9.770605
Log Pis Min                  -10.581258
Policy mu Mean               0.01932251
Policy mu Std                0.561569
Policy mu Max                2.1387355
Policy mu Min                -2.1742446
Policy log std Mean          -0.9176662
Policy log std Std           0.2960008
Policy log std Max           -0.14139885
Policy log std Min           -2.5208669
Z mean eval                  1.0081497
Z variance eval              0.017283274
total_rewards                [ 905.6870811   204.44272999 2903.05751898  286.17725739 1480.46565143
 2659.90401279  504.34631348  306.46171885 2727.98586275  410.91454017]
total_rewards_mean           1238.9442686947696
total_rewards_std            1060.5558358062733
total_rewards_max            2903.057518978202
total_rewards_min            204.4427299897942
Number of train steps total  306000
Number of env steps total    1532000
Number of rollouts total     0
Train Time (s)               30.797388850711286
(Previous) Eval Time (s)     17.700955886859447
Sample Time (s)              17.230112145189196
Epoch Time (s)               65.72845688275993
Total Train Time (s)         21148.273979478516
Epoch                        305
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:08:00.385921 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #305 | Epoch Duration: 62.38131403923035
2020-01-11 09:08:00.386120 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #305 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0068719
Z variance train             0.017299287
KL Divergence                20.407143
KL Loss                      2.0407143
QF Loss                      1375.2338
VF Loss                      195.81284
Policy Loss                  -1057.4172
Q Predictions Mean           1054.9971
Q Predictions Std            228.2878
Q Predictions Max            1260.2094
Q Predictions Min            -28.397121
V Predictions Mean           1063.0122
V Predictions Std            226.18924
V Predictions Max            1255.0864
V Predictions Min            16.330431
Log Pis Mean                 -0.33964083
Log Pis Std                  2.5071208
Log Pis Max                  7.1939316
Log Pis Min                  -6.9316354
Policy mu Mean               0.044372175
Policy mu Std                0.5349126
Policy mu Max                2.0193293
Policy mu Min                -1.8697464
Policy log std Mean          -0.99112225
Policy log std Std           0.27059308
Policy log std Max           -0.23299927
Policy log std Min           -2.2806473
Z mean eval                  1.0195557
Z variance eval              0.02092285
total_rewards                [ 357.14100575 2604.93782599  612.80841893 2744.725734   2819.8178194
   83.04225197  496.83013617  957.09886351 2297.78433928 2904.0830428 ]
total_rewards_mean           1587.8269437791964
total_rewards_std            1115.5724276261722
total_rewards_max            2904.0830428016925
total_rewards_min            83.04225196505193
Number of train steps total  307000
Number of env steps total    1537000
Number of rollouts total     0
Train Time (s)               30.022724030073732
(Previous) Eval Time (s)     14.35351020982489
Sample Time (s)              17.63049224158749
Epoch Time (s)               62.00672648148611
Total Train Time (s)         21215.486346770544
Epoch                        306
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:09:07.603767 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #306 | Epoch Duration: 67.21745729446411
2020-01-11 09:09:07.604092 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #306 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0217844
Z variance train             0.020969925
KL Divergence                20.145203
KL Loss                      2.0145204
QF Loss                      923.868
VF Loss                      431.26752
Policy Loss                  -1053.7152
Q Predictions Mean           1054.4565
Q Predictions Std            218.00517
Q Predictions Max            1255.0039
Q Predictions Min            59.956005
V Predictions Mean           1061.3998
V Predictions Std            217.06105
V Predictions Max            1267.7164
V Predictions Min            172.23132
Log Pis Mean                 -0.5588993
Log Pis Std                  2.7477708
Log Pis Max                  10.633938
Log Pis Min                  -7.860686
Policy mu Mean               0.021653915
Policy mu Std                0.57688785
Policy mu Max                2.3648608
Policy mu Min                -1.7907964
Policy log std Mean          -0.9512547
Policy log std Std           0.2965987
Policy log std Max           -0.21922368
Policy log std Min           -2.938651
Z mean eval                  0.97390306
Z variance eval              0.03262391
total_rewards                [1622.86560642 3050.67340109 2044.54994303  378.40473728 2930.88701872
 3149.1042869   518.64531108 2478.46880763 1241.74614027 2882.25631506]
total_rewards_mean           2029.76015674847
total_rewards_std            991.5898703640505
total_rewards_max            3149.10428689897
total_rewards_min            378.4047372784942
Number of train steps total  308000
Number of env steps total    1542000
Number of rollouts total     0
Train Time (s)               30.678619049023837
(Previous) Eval Time (s)     19.56393198762089
Sample Time (s)              17.92216497566551
Epoch Time (s)               68.16471601231024
Total Train Time (s)         21282.61849936424
Epoch                        307
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:10:14.740514 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #307 | Epoch Duration: 67.13618874549866
2020-01-11 09:10:14.740745 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #307 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9744889
Z variance train             0.032605015
KL Divergence                19.692396
KL Loss                      1.9692396
QF Loss                      2277.3997
VF Loss                      248.07684
Policy Loss                  -1035.1415
Q Predictions Mean           1034.3914
Q Predictions Std            264.2236
Q Predictions Max            1316.9464
Q Predictions Min            163.7661
V Predictions Mean           1030.8706
V Predictions Std            261.74542
V Predictions Max            1317.1694
V Predictions Min            162.8198
Log Pis Mean                 -0.022179686
Log Pis Std                  2.9477115
Log Pis Max                  18.182037
Log Pis Min                  -7.305978
Policy mu Mean               0.035587147
Policy mu Std                0.59914905
Policy mu Max                2.2279582
Policy mu Min                -2.7574012
Policy log std Mean          -0.9607788
Policy log std Std           0.26507685
Policy log std Max           -0.25102645
Policy log std Min           -2.2056317
Z mean eval                  1.0123551
Z variance eval              0.03401237
total_rewards                [2632.96351506 2091.61993651  318.4116312  2708.03420312 2688.24788185
  936.13642488 2793.66799518 1217.33618456  609.58635514 2717.33159822]
total_rewards_mean           1871.333572571625
total_rewards_std            941.7173417254581
total_rewards_max            2793.6679951784154
total_rewards_min            318.41163120262814
Number of train steps total  309000
Number of env steps total    1547000
Number of rollouts total     0
Train Time (s)               28.473962591961026
(Previous) Eval Time (s)     18.53511200286448
Sample Time (s)              18.390847377479076
Epoch Time (s)               65.39992197230458
Total Train Time (s)         21349.180088550318
Epoch                        308
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:11:21.309024 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #308 | Epoch Duration: 66.56806707382202
2020-01-11 09:11:21.309304 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #308 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0128176
Z variance train             0.034120187
KL Divergence                19.474382
KL Loss                      1.9474382
QF Loss                      526.2445
VF Loss                      68.427826
Policy Loss                  -1055.6942
Q Predictions Mean           1056.9686
Q Predictions Std            244.31229
Q Predictions Max            1256.946
Q Predictions Min            176.80331
V Predictions Mean           1055.5361
V Predictions Std            243.7173
V Predictions Max            1251.9637
V Predictions Min            156.54538
Log Pis Mean                 -0.6904525
Log Pis Std                  2.4308412
Log Pis Max                  6.5655975
Log Pis Min                  -8.058447
Policy mu Mean               0.05097173
Policy mu Std                0.56259215
Policy mu Max                2.2043304
Policy mu Min                -2.1036327
Policy log std Mean          -0.94507945
Policy log std Std           0.25678396
Policy log std Max           -0.16305715
Policy log std Min           -1.950237
Z mean eval                  0.98297226
Z variance eval              0.036143783
total_rewards                [2670.80484494 2935.71669101 2972.33166543  235.99731055  197.49070248
 2057.74673683 1192.81849069 3112.84178125 2999.54596498 2873.89337288]
total_rewards_mean           2124.918756104404
total_rewards_std            1101.4421138287184
total_rewards_max            3112.8417812532275
total_rewards_min            197.49070248301607
Number of train steps total  310000
Number of env steps total    1552000
Number of rollouts total     0
Train Time (s)               28.8198460964486
(Previous) Eval Time (s)     19.702971911989152
Sample Time (s)              18.379524159710854
Epoch Time (s)               66.9023421681486
Total Train Time (s)         21415.855576032307
Epoch                        309
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:12:27.984732 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #309 | Epoch Duration: 66.67521238327026
2020-01-11 09:12:27.984918 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #309 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98296916
Z variance train             0.03606073
KL Divergence                19.34702
KL Loss                      1.9347019
QF Loss                      495.4521
VF Loss                      134.56197
Policy Loss                  -1050.15
Q Predictions Mean           1049.1448
Q Predictions Std            260.22656
Q Predictions Max            1283.812
Q Predictions Min            140.66919
V Predictions Mean           1056.9084
V Predictions Std            260.60306
V Predictions Max            1286.3862
V Predictions Min            154.43176
Log Pis Mean                 -0.53169197
Log Pis Std                  2.624324
Log Pis Max                  10.853621
Log Pis Min                  -7.913077
Policy mu Mean               0.015351791
Policy mu Std                0.5920282
Policy mu Max                2.2115064
Policy mu Min                -2.8509035
Policy log std Mean          -0.9317231
Policy log std Std           0.2573614
Policy log std Max           -0.16682088
Policy log std Min           -1.9824841
Z mean eval                  1.0099905
Z variance eval              0.029047698
total_rewards                [1381.33737994  513.94150129  339.69932673  761.82258274 2976.67117209
  381.01398533  204.58949766 2712.79656799  569.14877987 2545.4747663 ]
total_rewards_mean           1238.649555993919
total_rewards_std            1036.132617168523
total_rewards_max            2976.6711720893873
total_rewards_min            204.58949766220752
Number of train steps total  311000
Number of env steps total    1557000
Number of rollouts total     0
Train Time (s)               28.00510703213513
(Previous) Eval Time (s)     19.475480790715665
Sample Time (s)              17.451713774818927
Epoch Time (s)               64.93230159766972
Total Train Time (s)         21478.569676911924
Epoch                        310
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:13:30.703624 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #310 | Epoch Duration: 62.71852159500122
2020-01-11 09:13:30.703892 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #310 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0083933
Z variance train             0.0289159
KL Divergence                19.987972
KL Loss                      1.9987973
QF Loss                      1603.1385
VF Loss                      508.02585
Policy Loss                  -1075.1838
Q Predictions Mean           1076.196
Q Predictions Std            223.29945
Q Predictions Max            1270.4182
Q Predictions Min            139.27246
V Predictions Mean           1081.5203
V Predictions Std            221.7275
V Predictions Max            1280.5603
V Predictions Min            166.53925
Log Pis Mean                 -0.2417176
Log Pis Std                  2.5691257
Log Pis Max                  8.968539
Log Pis Min                  -6.7913094
Policy mu Mean               -0.029698249
Policy mu Std                0.59569937
Policy mu Max                2.2214077
Policy mu Min                -2.554051
Policy log std Mean          -0.9246405
Policy log std Std           0.24383873
Policy log std Max           -0.18587571
Policy log std Min           -2.0281847
Z mean eval                  0.9964177
Z variance eval              0.025899982
total_rewards                [-108.23995826  165.98676928 2860.07745859  821.21604958  588.44105136
  203.78499639 2846.89883879  245.17695769 2890.85053045  837.30458994]
total_rewards_mean           1135.149728381008
total_rewards_std            1166.999957465907
total_rewards_max            2890.850530452948
total_rewards_min            -108.23995826332323
Number of train steps total  312000
Number of env steps total    1562000
Number of rollouts total     0
Train Time (s)               28.266807966399938
(Previous) Eval Time (s)     17.26143078599125
Sample Time (s)              18.038191513624042
Epoch Time (s)               63.56643026601523
Total Train Time (s)         21540.99831008725
Epoch                        311
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:14:33.139495 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #311 | Epoch Duration: 62.43537735939026
2020-01-11 09:14:33.139827 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #311 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9954174
Z variance train             0.02593919
KL Divergence                19.754168
KL Loss                      1.9754168
QF Loss                      933.122
VF Loss                      390.14407
Policy Loss                  -1064.9244
Q Predictions Mean           1062.904
Q Predictions Std            250.78664
Q Predictions Max            1275.238
Q Predictions Min            70.75218
V Predictions Mean           1065.5565
V Predictions Std            248.00319
V Predictions Max            1268.3618
V Predictions Min            57.329464
Log Pis Mean                 -0.43172938
Log Pis Std                  2.704872
Log Pis Max                  11.265795
Log Pis Min                  -6.886937
Policy mu Mean               0.018788476
Policy mu Std                0.5860016
Policy mu Max                1.9649295
Policy mu Min                -2.1390142
Policy log std Mean          -0.94780827
Policy log std Std           0.26564586
Policy log std Max           -0.073820174
Policy log std Min           -2.5965614
Z mean eval                  0.9902836
Z variance eval              0.022057746
total_rewards                [2569.61526483  541.63850524 3151.27142669 2814.12609263  378.13750944
 3101.21395149 3134.11092981 2476.51913335 2949.6673949    36.46230214]
total_rewards_mean           2115.2762510509465
total_rewards_std            1200.8479293405762
total_rewards_max            3151.2714266901635
total_rewards_min            36.46230213687012
Number of train steps total  313000
Number of env steps total    1567000
Number of rollouts total     0
Train Time (s)               29.892063884064555
(Previous) Eval Time (s)     16.13005932699889
Sample Time (s)              17.67887875251472
Epoch Time (s)               63.701001963578165
Total Train Time (s)         21615.771813700907
Epoch                        312
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:15:47.916986 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #312 | Epoch Duration: 74.77689599990845
2020-01-11 09:15:47.917286 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #312 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.987426
Z variance train             0.022024896
KL Divergence                19.836
KL Loss                      1.9836
QF Loss                      725.2283
VF Loss                      233.98712
Policy Loss                  -1064.6079
Q Predictions Mean           1062.55
Q Predictions Std            234.20879
Q Predictions Max            1258.637
Q Predictions Min            146.78354
V Predictions Mean           1061.1318
V Predictions Std            230.5557
V Predictions Max            1254.967
V Predictions Min            149.86627
Log Pis Mean                 -0.09228193
Log Pis Std                  2.7093494
Log Pis Max                  14.304205
Log Pis Min                  -8.265812
Policy mu Mean               0.048306413
Policy mu Std                0.5700121
Policy mu Max                2.2198477
Policy mu Min                -2.8673377
Policy log std Mean          -1.005068
Policy log std Std           0.28490657
Policy log std Max           -0.18511516
Policy log std Min           -2.6872807
Z mean eval                  0.97519237
Z variance eval              0.018285884
total_rewards                [ -25.95277186 2737.92611431 2683.38360004 2916.51965103  133.17530259
 2553.41240835 1693.88681608 2833.75973475 2564.11317201 2872.24452159]
total_rewards_mean           2096.246854889579
total_rewards_std            1073.4337858612428
total_rewards_max            2916.519651034905
total_rewards_min            -25.952771862634933
Number of train steps total  314000
Number of env steps total    1572000
Number of rollouts total     0
Train Time (s)               30.863842546008527
(Previous) Eval Time (s)     27.205626524984837
Sample Time (s)              18.733370623085648
Epoch Time (s)               76.80283969407901
Total Train Time (s)         21687.44222687278
Epoch                        313
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:16:59.591531 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #313 | Epoch Duration: 71.67401385307312
2020-01-11 09:16:59.591757 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #313 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9748524
Z variance train             0.01829255
KL Divergence                20.83434
KL Loss                      2.0834339
QF Loss                      872.8684
VF Loss                      276.0911
Policy Loss                  -1032.8549
Q Predictions Mean           1031.3083
Q Predictions Std            278.76392
Q Predictions Max            1299.0631
Q Predictions Min            133.26567
V Predictions Mean           1028.2958
V Predictions Std            276.49695
V Predictions Max            1259.9866
V Predictions Min            144.749
Log Pis Mean                 -0.2763607
Log Pis Std                  2.5242074
Log Pis Max                  9.596468
Log Pis Min                  -8.150757
Policy mu Mean               -0.005370942
Policy mu Std                0.5865445
Policy mu Max                2.2683582
Policy mu Min                -2.4513416
Policy log std Mean          -0.97095644
Policy log std Std           0.2893315
Policy log std Max           -0.12743753
Policy log std Min           -2.3888345
Z mean eval                  0.9670744
Z variance eval              0.012972856
total_rewards                [2735.30121939  681.83026764 2783.03441286 2753.27944318  246.13932427
 2981.62517469 2560.2971364   953.94562795 2978.14434312 2418.32148742]
total_rewards_mean           2109.1918436916103
total_rewards_std            995.947822784549
total_rewards_max            2981.625174689766
total_rewards_min            246.13932427123177
Number of train steps total  315000
Number of env steps total    1577000
Number of rollouts total     0
Train Time (s)               31.091162621974945
(Previous) Eval Time (s)     22.07644093595445
Sample Time (s)              18.66854906314984
Epoch Time (s)               71.83615262107924
Total Train Time (s)         21757.28445451986
Epoch                        314
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:18:09.438604 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #314 | Epoch Duration: 69.84662532806396
2020-01-11 09:18:09.438885 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #314 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.966821
Z variance train             0.01289892
KL Divergence                21.634922
KL Loss                      2.1634922
QF Loss                      1170.2654
VF Loss                      123.68385
Policy Loss                  -1043.095
Q Predictions Mean           1042.5042
Q Predictions Std            243.55159
Q Predictions Max            1284.4198
Q Predictions Min            116.063705
V Predictions Mean           1046.9941
V Predictions Std            241.63222
V Predictions Max            1274.0424
V Predictions Min            132.37039
Log Pis Mean                 -0.14640181
Log Pis Std                  2.5346987
Log Pis Max                  8.548422
Log Pis Min                  -6.758331
Policy mu Mean               0.032971404
Policy mu Std                0.5911001
Policy mu Max                2.3634233
Policy mu Min                -2.6865149
Policy log std Mean          -0.9558002
Policy log std Std           0.2734966
Policy log std Max           -0.0448038
Policy log std Min           -2.5305243
Z mean eval                  0.9984436
Z variance eval              0.01559138
total_rewards                [2989.45513957  887.21851681 1568.09903886  800.30221745  971.36831882
 1157.05646335 -192.79359138 2776.8980831  3045.38416948 2475.07304766]
total_rewards_mean           1647.8061403725144
total_rewards_std            1053.6501285762552
total_rewards_max            3045.3841694797775
total_rewards_min            -192.7935913808174
Number of train steps total  316000
Number of env steps total    1582000
Number of rollouts total     0
Train Time (s)               26.902330433949828
(Previous) Eval Time (s)     20.08660934586078
Sample Time (s)              18.154490866232663
Epoch Time (s)               65.14343064604327
Total Train Time (s)         21821.576526679564
Epoch                        315
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:19:13.735020 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #315 | Epoch Duration: 64.29591298103333
2020-01-11 09:19:13.735254 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #315 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99882126
Z variance train             0.015602732
KL Divergence                22.130861
KL Loss                      2.2130861
QF Loss                      643.3672
VF Loss                      442.56396
Policy Loss                  -1056.049
Q Predictions Mean           1055.723
Q Predictions Std            252.07036
Q Predictions Max            1275.042
Q Predictions Min            129.08159
V Predictions Mean           1061.749
V Predictions Std            254.4967
V Predictions Max            1286.2076
V Predictions Min            135.86641
Log Pis Mean                 -0.66313183
Log Pis Std                  2.717858
Log Pis Max                  13.30518
Log Pis Min                  -7.418049
Policy mu Mean               -0.014722718
Policy mu Std                0.5621886
Policy mu Max                2.8403554
Policy mu Min                -2.3219209
Policy log std Mean          -0.9450085
Policy log std Std           0.298629
Policy log std Max           -0.14436966
Policy log std Min           -3.3191886
Z mean eval                  0.97591764
Z variance eval              0.013024275
total_rewards                [ 924.62814142 3196.35511449 3231.99597701  542.00876189   63.71621038
 3219.53871469 2980.76948339  654.7160254  1706.20510758 3209.1364589 ]
total_rewards_mean           1972.9069995154382
total_rewards_std            1256.2004689825567
total_rewards_max            3231.9959770115374
total_rewards_min            63.716210380880995
Number of train steps total  317000
Number of env steps total    1587000
Number of rollouts total     0
Train Time (s)               29.09198392322287
(Previous) Eval Time (s)     19.238745351787657
Sample Time (s)              17.525610058568418
Epoch Time (s)               65.85633933357894
Total Train Time (s)         21885.33779255068
Epoch                        316
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:20:17.502606 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #316 | Epoch Duration: 63.767141819000244
2020-01-11 09:20:17.502877 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #316 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97466326
Z variance train             0.01305854
KL Divergence                22.018286
KL Loss                      2.2018287
QF Loss                      826.7205
VF Loss                      264.31268
Policy Loss                  -1079.7457
Q Predictions Mean           1076.1172
Q Predictions Std            214.29944
Q Predictions Max            1272.006
Q Predictions Min            114.241806
V Predictions Mean           1077.0756
V Predictions Std            204.61739
V Predictions Max            1267.2852
V Predictions Min            130.63199
Log Pis Mean                 -0.044703424
Log Pis Std                  2.6479826
Log Pis Max                  9.772928
Log Pis Min                  -9.396
Policy mu Mean               -0.000706502
Policy mu Std                0.58705574
Policy mu Max                2.017875
Policy mu Min                -2.4167557
Policy log std Mean          -0.97443116
Policy log std Std           0.26359004
Policy log std Max           -0.23424101
Policy log std Min           -2.4275227
Z mean eval                  0.98596716
Z variance eval              0.012809718
total_rewards                [2926.54149955 2556.26849224 2416.41687521 1169.86822588   50.7607313
 2623.10933283 1384.99654809 2436.44709398  647.26076417 2905.27735798]
total_rewards_mean           1911.6946921228905
total_rewards_std            967.3883450949139
total_rewards_max            2926.5414995544324
total_rewards_min            50.76073130133009
Number of train steps total  318000
Number of env steps total    1592000
Number of rollouts total     0
Train Time (s)               30.159846077207476
(Previous) Eval Time (s)     17.149245463777333
Sample Time (s)              17.701962357386947
Epoch Time (s)               65.01105389837176
Total Train Time (s)         21955.902055298444
Epoch                        317
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:21:28.070565 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #317 | Epoch Duration: 70.56747484207153
2020-01-11 09:21:28.070811 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #317 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9849966
Z variance train             0.012770134
KL Divergence                22.291204
KL Loss                      2.2291205
QF Loss                      792.337
VF Loss                      478.48566
Policy Loss                  -1054.5106
Q Predictions Mean           1051.8027
Q Predictions Std            261.92236
Q Predictions Max            1279.8124
Q Predictions Min            74.89922
V Predictions Mean           1062.5817
V Predictions Std            252.77342
V Predictions Max            1280.7369
V Predictions Min            167.79266
Log Pis Mean                 -0.15189835
Log Pis Std                  2.8485022
Log Pis Max                  16.146328
Log Pis Min                  -6.6520367
Policy mu Mean               0.06077254
Policy mu Std                0.5570097
Policy mu Max                2.3565886
Policy mu Min                -3.685113
Policy log std Mean          -0.9580292
Policy log std Std           0.27290022
Policy log std Max           -0.1781525
Policy log std Min           -2.1881433
Z mean eval                  1.001871
Z variance eval              0.034555323
total_rewards                [ 265.51322932 2224.60067231 2923.63894203 1384.02908429 2188.86312779
 3218.22459679 2775.84471127  175.22896344 3001.56487585 2166.04658348]
total_rewards_mean           2032.35547865642
total_rewards_std            1037.4545090490315
total_rewards_max            3218.2245967925187
total_rewards_min            175.2289634402405
Number of train steps total  319000
Number of env steps total    1597000
Number of rollouts total     0
Train Time (s)               27.461160372011364
(Previous) Eval Time (s)     22.705373084172606
Sample Time (s)              17.542715571355075
Epoch Time (s)               67.70924902753904
Total Train Time (s)         22023.630448984448
Epoch                        318
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:22:35.804977 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #318 | Epoch Duration: 67.73394751548767
2020-01-11 09:22:35.805272 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #318 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0058444
Z variance train             0.034425598
KL Divergence                20.595821
KL Loss                      2.0595822
QF Loss                      856.1541
VF Loss                      382.12778
Policy Loss                  -1065.182
Q Predictions Mean           1064.6072
Q Predictions Std            243.97984
Q Predictions Max            1255.6918
Q Predictions Min            -12.725475
V Predictions Mean           1079.0403
V Predictions Std            243.824
V Predictions Max            1270.5356
V Predictions Min            5.196602
Log Pis Mean                 -0.25671428
Log Pis Std                  2.7569087
Log Pis Max                  11.661677
Log Pis Min                  -8.698469
Policy mu Mean               0.06887941
Policy mu Std                0.5905398
Policy mu Max                2.26439
Policy mu Min                -2.0738547
Policy log std Mean          -0.9562479
Policy log std Std           0.27300483
Policy log std Max           -0.21260399
Policy log std Min           -2.7473927
Z mean eval                  0.9746453
Z variance eval              0.03365044
total_rewards                [2814.29358389 3009.79706345 3126.47330629 2188.13845068 1374.26751184
 1917.67176476 2521.86607152 1763.4718661  3096.58397117  879.51708403]
total_rewards_mean           2269.2080673716137
total_rewards_std            738.0352099814648
total_rewards_max            3126.473306286732
total_rewards_min            879.5170840285793
Number of train steps total  320000
Number of env steps total    1602000
Number of rollouts total     0
Train Time (s)               27.65380699187517
(Previous) Eval Time (s)     22.72979160770774
Sample Time (s)              18.16176707483828
Epoch Time (s)               68.54536567442119
Total Train Time (s)         22089.771465452388
Epoch                        319
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:23:41.948711 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #319 | Epoch Duration: 66.14322447776794
2020-01-11 09:23:41.948929 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #319 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.974738
Z variance train             0.03359967
KL Divergence                20.004345
KL Loss                      2.0004346
QF Loss                      726.9928
VF Loss                      198.33728
Policy Loss                  -1084.5934
Q Predictions Mean           1085.2432
Q Predictions Std            191.83139
Q Predictions Max            1270.3906
Q Predictions Min            104.1647
V Predictions Mean           1089.9955
V Predictions Std            189.44006
V Predictions Max            1258.1178
V Predictions Min            109.797005
Log Pis Mean                 -0.24178466
Log Pis Std                  2.4811432
Log Pis Max                  9.701738
Log Pis Min                  -7.4779835
Policy mu Mean               0.07483011
Policy mu Std                0.5726705
Policy mu Max                1.9429824
Policy mu Min                -2.1070774
Policy log std Mean          -0.97870016
Policy log std Std           0.25777346
Policy log std Max           -0.22234148
Policy log std Min           -2.7074509
Z mean eval                  0.99879247
Z variance eval              0.030614322
total_rewards                [2937.40335418 3098.30839311 2978.76162305 2781.09670616 1064.84095488
 3197.64931359  803.69297144 3148.34959318 3171.18597324 3116.80958199]
total_rewards_mean           2629.809846481594
total_rewards_std            858.1475494207601
total_rewards_max            3197.6493135863843
total_rewards_min            803.6929714393368
Number of train steps total  321000
Number of env steps total    1607000
Number of rollouts total     0
Train Time (s)               30.690022793132812
(Previous) Eval Time (s)     20.32734536798671
Sample Time (s)              17.684594008605927
Epoch Time (s)               68.70196216972545
Total Train Time (s)         22160.67503310833
Epoch                        320
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:24:52.857534 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #320 | Epoch Duration: 70.90841245651245
2020-01-11 09:24:52.857805 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #320 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99821454
Z variance train             0.030591387
KL Divergence                19.944836
KL Loss                      1.9944836
QF Loss                      1449.4352
VF Loss                      202.6426
Policy Loss                  -1093.2168
Q Predictions Mean           1094.5577
Q Predictions Std            222.96254
Q Predictions Max            1329.3243
Q Predictions Min            52.297325
V Predictions Mean           1095.341
V Predictions Std            223.4137
V Predictions Max            1327.4106
V Predictions Min            9.876013
Log Pis Mean                 -0.16722977
Log Pis Std                  2.709308
Log Pis Max                  13.64159
Log Pis Min                  -6.619955
Policy mu Mean               0.022690516
Policy mu Std                0.5563431
Policy mu Max                2.6666744
Policy mu Min                -2.6739113
Policy log std Mean          -1.0088687
Policy log std Std           0.28489065
Policy log std Max           -0.15619773
Policy log std Min           -3.037221
Z mean eval                  0.97624207
Z variance eval              0.034670375
total_rewards                [ 958.84376379  850.26465579  277.46785358  252.02916651  968.0612621
 2816.78417151 2950.99415269  118.08769987 2919.93923806 3023.68151439]
total_rewards_mean           1513.6153478274373
total_rewards_std            1188.9047973445731
total_rewards_max            3023.681514388823
total_rewards_min            118.08769986674234
Number of train steps total  322000
Number of env steps total    1612000
Number of rollouts total     0
Train Time (s)               29.901661458890885
(Previous) Eval Time (s)     22.53346274001524
Sample Time (s)              17.944726647343487
Epoch Time (s)               70.37985084624961
Total Train Time (s)         22222.951304684393
Epoch                        321
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:25:55.140020 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #321 | Epoch Duration: 62.28188180923462
2020-01-11 09:25:55.140379 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #321 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9767278
Z variance train             0.03467516
KL Divergence                20.041985
KL Loss                      2.0041986
QF Loss                      1475.1702
VF Loss                      462.14923
Policy Loss                  -1074.9425
Q Predictions Mean           1076.4208
Q Predictions Std            224.1386
Q Predictions Max            1269.2736
Q Predictions Min            132.19637
V Predictions Mean           1086.9026
V Predictions Std            225.57411
V Predictions Max            1275.9735
V Predictions Min            99.01111
Log Pis Mean                 -0.62034583
Log Pis Std                  2.6546636
Log Pis Max                  6.9960203
Log Pis Min                  -7.172279
Policy mu Mean               -0.00975695
Policy mu Std                0.58887297
Policy mu Max                2.2391338
Policy mu Min                -2.849246
Policy log std Mean          -0.94262177
Policy log std Std           0.2581516
Policy log std Max           -0.041246712
Policy log std Min           -2.0124457
Z mean eval                  0.9803184
Z variance eval              0.02375439
total_rewards                [2645.90709915 2844.47820487 2998.71318097  889.63359098  529.03512208
 2983.97354399  123.31046013 3053.64588049  130.58142626 3035.86137969]
total_rewards_mean           1923.5139888626206
total_rewards_std            1250.3595234984627
total_rewards_max            3053.6458804930353
total_rewards_min            123.31046012733187
Number of train steps total  323000
Number of env steps total    1617000
Number of rollouts total     0
Train Time (s)               30.26470291102305
(Previous) Eval Time (s)     14.43516037799418
Sample Time (s)              18.380587627645582
Epoch Time (s)               63.08045091666281
Total Train Time (s)         22293.397516037337
Epoch                        322
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:27:05.591368 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #322 | Epoch Duration: 70.45074462890625
2020-01-11 09:27:05.591657 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #322 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9806329
Z variance train             0.023701012
KL Divergence                20.216911
KL Loss                      2.021691
QF Loss                      1112.6448
VF Loss                      157.41843
Policy Loss                  -1090.6416
Q Predictions Mean           1089.1376
Q Predictions Std            207.30418
Q Predictions Max            1320.1935
Q Predictions Min            56.752083
V Predictions Mean           1088.7197
V Predictions Std            208.79684
V Predictions Max            1308.9404
V Predictions Min            52.176926
Log Pis Mean                 -0.1669769
Log Pis Std                  2.6918292
Log Pis Max                  9.953959
Log Pis Min                  -7.2973347
Policy mu Mean               0.013734487
Policy mu Std                0.53599834
Policy mu Max                2.0844297
Policy mu Min                -2.668159
Policy log std Mean          -1.0189979
Policy log std Std           0.28351295
Policy log std Max           -0.26024675
Policy log std Min           -2.5155816
Z mean eval                  0.9890879
Z variance eval              0.022424335
total_rewards                [1488.25438799 1174.06410716 3029.67343244 2776.38761203  390.48479127
 1753.08095597 2745.36016618 2726.14239595 1571.58553199 3088.4920766 ]
total_rewards_mean           2074.35254575778
total_rewards_std            874.8989939782011
total_rewards_max            3088.4920765963243
total_rewards_min            390.48479127282735
Number of train steps total  324000
Number of env steps total    1622000
Number of rollouts total     0
Train Time (s)               31.52818787889555
(Previous) Eval Time (s)     21.80515002971515
Sample Time (s)              18.025173804722726
Epoch Time (s)               71.35851171333343
Total Train Time (s)         22364.762533692643
Epoch                        323
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:28:16.959117 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #323 | Epoch Duration: 71.36722421646118
2020-01-11 09:28:16.959329 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #323 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9921525
Z variance train             0.022460109
KL Divergence                20.142967
KL Loss                      2.0142968
QF Loss                      1016.7467
VF Loss                      202.12787
Policy Loss                  -1101.4417
Q Predictions Mean           1103.9224
Q Predictions Std            226.05779
Q Predictions Max            1299.9816
Q Predictions Min            35.63227
V Predictions Mean           1092.1149
V Predictions Std            222.552
V Predictions Max            1283.343
V Predictions Min            -6.5670557
Log Pis Mean                 -0.114468634
Log Pis Std                  2.4941616
Log Pis Max                  7.839177
Log Pis Min                  -6.8054266
Policy mu Mean               0.04943592
Policy mu Std                0.57480246
Policy mu Max                2.2311726
Policy mu Min                -2.410113
Policy log std Mean          -0.97220874
Policy log std Std           0.23967835
Policy log std Max           -0.26414067
Policy log std Min           -2.017599
Z mean eval                  0.9936797
Z variance eval              0.016033791
total_rewards                [1660.49223179  120.69982837 1820.89596072 2565.74823491 2972.95948338
 2803.01078415 2773.27247923 2962.03045339 2722.17904503 2328.34433788]
total_rewards_mean           2272.963283884845
total_rewards_std            836.5629929601043
total_rewards_max            2972.959483377803
total_rewards_min            120.69982836765386
Number of train steps total  325000
Number of env steps total    1627000
Number of rollouts total     0
Train Time (s)               29.308257713913918
(Previous) Eval Time (s)     21.813563061878085
Sample Time (s)              18.154324313160032
Epoch Time (s)               69.27614508895203
Total Train Time (s)         22434.50226959586
Epoch                        324
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:29:26.703664 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #324 | Epoch Duration: 69.74416184425354
2020-01-11 09:29:26.703924 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #324 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99147666
Z variance train             0.016040092
KL Divergence                20.913792
KL Loss                      2.0913792
QF Loss                      1603.6948
VF Loss                      288.3218
Policy Loss                  -1083.8842
Q Predictions Mean           1089.606
Q Predictions Std            249.32156
Q Predictions Max            1294.2864
Q Predictions Min            118.5723
V Predictions Mean           1094.5493
V Predictions Std            247.6931
V Predictions Max            1300.3693
V Predictions Min            118.10072
Log Pis Mean                 -0.65554214
Log Pis Std                  2.6224554
Log Pis Max                  7.481987
Log Pis Min                  -12.786793
Policy mu Mean               -0.048769962
Policy mu Std                0.574395
Policy mu Max                2.646734
Policy mu Min                -2.3316944
Policy log std Mean          -0.94945574
Policy log std Std           0.26214415
Policy log std Max           -0.20389777
Policy log std Min           -2.2997065
Z mean eval                  1.0238006
Z variance eval              0.014227906
total_rewards                [1189.67011023  916.66954123 3145.7230457  3041.58347196 1485.80367793
 2634.54805274  139.54676563  903.36101535 2414.1645964   964.93338668]
total_rewards_mean           1683.6003663841832
total_rewards_std            989.9786439026681
total_rewards_max            3145.7230456951547
total_rewards_min            139.54676563469624
Number of train steps total  326000
Number of env steps total    1632000
Number of rollouts total     0
Train Time (s)               27.147306659258902
(Previous) Eval Time (s)     22.281231049913913
Sample Time (s)              18.541803745087236
Epoch Time (s)               67.97034145426005
Total Train Time (s)         22501.08815042721
Epoch                        325
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:30:33.295777 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #325 | Epoch Duration: 66.59164214134216
2020-01-11 09:30:33.296115 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #325 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.023588
Z variance train             0.014199247
KL Divergence                21.738
KL Loss                      2.1738002
QF Loss                      616.00073
VF Loss                      294.96143
Policy Loss                  -1083.8007
Q Predictions Mean           1084.0403
Q Predictions Std            218.75444
Q Predictions Max            1269.7762
Q Predictions Min            126.78726
V Predictions Mean           1094.5511
V Predictions Std            221.24179
V Predictions Max            1277.4681
V Predictions Min            135.1063
Log Pis Mean                 -0.6593369
Log Pis Std                  2.644576
Log Pis Max                  16.54529
Log Pis Min                  -9.30226
Policy mu Mean               0.014793524
Policy mu Std                0.5424812
Policy mu Max                2.5422237
Policy mu Min                -2.2762716
Policy log std Mean          -0.978638
Policy log std Std           0.28326595
Policy log std Max           -0.27180976
Policy log std Min           -3.3776119
Z mean eval                  1.013221
Z variance eval              0.016625134
total_rewards                [2012.25806774 2962.67257713 1446.09640963  270.76107372 1464.41178371
 3151.91837862 1992.99844774 2919.39568346 1228.16081108 3092.10580326]
total_rewards_mean           2054.077903608296
total_rewards_std            918.8177163050285
total_rewards_max            3151.9183786169588
total_rewards_min            270.7610737220083
Number of train steps total  327000
Number of env steps total    1637000
Number of rollouts total     0
Train Time (s)               29.999400584958494
(Previous) Eval Time (s)     20.90222475398332
Sample Time (s)              18.109129247721285
Epoch Time (s)               69.0107545866631
Total Train Time (s)         22568.640735561494
Epoch                        326
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:31:40.851427 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #326 | Epoch Duration: 67.55508255958557
2020-01-11 09:31:40.851618 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #326 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0108467
Z variance train             0.016693287
KL Divergence                21.542694
KL Loss                      2.1542695
QF Loss                      2300.1143
VF Loss                      298.67313
Policy Loss                  -1095.2426
Q Predictions Mean           1093.7769
Q Predictions Std            244.64972
Q Predictions Max            1309.5902
Q Predictions Min            66.785355
V Predictions Mean           1086.2628
V Predictions Std            237.25066
V Predictions Max            1294.487
V Predictions Min            99.09465
Log Pis Mean                 -0.41249755
Log Pis Std                  2.7143507
Log Pis Max                  12.777639
Log Pis Min                  -8.445118
Policy mu Mean               -0.017540082
Policy mu Std                0.5753869
Policy mu Max                2.1969516
Policy mu Min                -2.268235
Policy log std Mean          -0.9741813
Policy log std Std           0.28423056
Policy log std Max           -0.11344057
Policy log std Min           -2.4397233
Z mean eval                  0.98627186
Z variance eval              0.015672084
total_rewards                [1909.78817934 2718.13052556 2924.42198946 2769.27123235 2808.36871235
 2870.59418883  162.17477904  203.19612928 3057.47963266  571.38650523]
total_rewards_mean           1999.4811874087268
total_rewards_std            1146.5984814435212
total_rewards_max            3057.479632655103
total_rewards_min            162.17477903649603
Number of train steps total  328000
Number of env steps total    1642000
Number of rollouts total     0
Train Time (s)               30.92589187808335
(Previous) Eval Time (s)     19.446241817437112
Sample Time (s)              19.155502691864967
Epoch Time (s)               69.52763638738543
Total Train Time (s)         22641.76695746137
Epoch                        327
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:32:53.981176 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #327 | Epoch Duration: 73.12939524650574
2020-01-11 09:32:53.981399 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #327 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98505765
Z variance train             0.015669426
KL Divergence                21.895735
KL Loss                      2.1895735
QF Loss                      1258.0299
VF Loss                      730.30914
Policy Loss                  -1112.8584
Q Predictions Mean           1109.6134
Q Predictions Std            209.02751
Q Predictions Max            1286.0167
Q Predictions Min            147.48439
V Predictions Mean           1105.794
V Predictions Std            203.87537
V Predictions Max            1274.434
V Predictions Min            147.98721
Log Pis Mean                 -0.12019431
Log Pis Std                  2.5969553
Log Pis Max                  9.855599
Log Pis Min                  -7.523113
Policy mu Mean               0.051058814
Policy mu Std                0.6254677
Policy mu Max                2.3373315
Policy mu Min                -2.5957355
Policy log std Mean          -0.9497503
Policy log std Std           0.26105043
Policy log std Max           -0.09415853
Policy log std Min           -2.5332599
Z mean eval                  1.01311
Z variance eval              0.0130971
total_rewards                [ 909.01872284   10.17386052 3238.23525829 1223.94052071 3101.76356484
 2968.09407752 1931.73705137 1909.7262078  2084.49554622  221.42968541]
total_rewards_mean           1759.8614495542013
total_rewards_std            1097.3981954313551
total_rewards_max            3238.2352582942112
total_rewards_min            10.173860520195158
Number of train steps total  329000
Number of env steps total    1647000
Number of rollouts total     0
Train Time (s)               27.71290743490681
(Previous) Eval Time (s)     23.047663446050137
Sample Time (s)              20.623641851358116
Epoch Time (s)               71.38421273231506
Total Train Time (s)         22708.451891373377
Epoch                        328
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:34:00.670786 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #328 | Epoch Duration: 66.68915033340454
2020-01-11 09:34:00.671065 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #328 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0133297
Z variance train             0.013067925
KL Divergence                21.980524
KL Loss                      2.1980524
QF Loss                      933.6843
VF Loss                      229.54549
Policy Loss                  -1068.1036
Q Predictions Mean           1067.8319
Q Predictions Std            270.42514
Q Predictions Max            1292.7567
Q Predictions Min            40.31384
V Predictions Mean           1072.6982
V Predictions Std            274.43942
V Predictions Max            1297.6467
V Predictions Min            46.721237
Log Pis Mean                 -0.43380854
Log Pis Std                  2.8808007
Log Pis Max                  11.471288
Log Pis Min                  -10.779967
Policy mu Mean               0.0480293
Policy mu Std                0.58608437
Policy mu Max                2.252428
Policy mu Min                -2.1639228
Policy log std Mean          -0.97255325
Policy log std Std           0.3025141
Policy log std Max           -0.18034935
Policy log std Min           -2.9356532
Z mean eval                  1.0141777
Z variance eval              0.016378138
total_rewards                [-109.67131953  947.51590451 3037.04057285  179.38526949 2666.9312125
 2767.75352015 2955.95716157 3127.82881186 2935.8113375  2881.0018504 ]
total_rewards_mean           2138.9554321305964
total_rewards_std            1209.4396482068814
total_rewards_max            3127.82881186464
total_rewards_min            -109.67131952717804
Number of train steps total  330000
Number of env steps total    1652000
Number of rollouts total     0
Train Time (s)               27.531206801068038
(Previous) Eval Time (s)     18.352235348895192
Sample Time (s)              18.813197372481227
Epoch Time (s)               64.69663952244446
Total Train Time (s)         22777.244588541333
Epoch                        329
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:35:09.468374 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #329 | Epoch Duration: 68.79711771011353
2020-01-11 09:35:09.468662 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #329 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0145495
Z variance train             0.01636235
KL Divergence                21.83104
KL Loss                      2.183104
QF Loss                      736.398
VF Loss                      379.4298
Policy Loss                  -1080.7457
Q Predictions Mean           1080.5568
Q Predictions Std            262.12393
Q Predictions Max            1301.4941
Q Predictions Min            42.67697
V Predictions Mean           1082.592
V Predictions Std            263.42746
V Predictions Max            1301.015
V Predictions Min            28.612276
Log Pis Mean                 -0.5427434
Log Pis Std                  2.8709419
Log Pis Max                  13.663339
Log Pis Min                  -7.5593815
Policy mu Mean               0.054412667
Policy mu Std                0.5819468
Policy mu Max                2.5031855
Policy mu Min                -2.4969573
Policy log std Mean          -0.96899456
Policy log std Std           0.2745832
Policy log std Max           -0.1563955
Policy log std Min           -2.125781
Z mean eval                  1.0093956
Z variance eval              0.015691474
total_rewards                [ 344.06724436 3111.2437811   284.30800747  610.16978257  877.07448412
 3049.67510441  687.74851337  649.95202675  772.16182603  215.6980281 ]
total_rewards_mean           1060.2098798265365
total_rewards_std            1030.4795738249024
total_rewards_max            3111.24378110261
total_rewards_min            215.69802809536387
Number of train steps total  331000
Number of env steps total    1657000
Number of rollouts total     0
Train Time (s)               26.59391111601144
(Previous) Eval Time (s)     22.452404668089002
Sample Time (s)              17.590869171079248
Epoch Time (s)               66.63718495517969
Total Train Time (s)         22830.98341786256
Epoch                        330
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:36:03.209723 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #330 | Epoch Duration: 53.740864753723145
2020-01-11 09:36:03.209904 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #330 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0134088
Z variance train             0.015688574
KL Divergence                21.902447
KL Loss                      2.1902447
QF Loss                      874.6952
VF Loss                      434.8271
Policy Loss                  -1097.7456
Q Predictions Mean           1100.6458
Q Predictions Std            239.73419
Q Predictions Max            1327.8904
Q Predictions Min            157.22928
V Predictions Mean           1108.8557
V Predictions Std            239.09964
V Predictions Max            1327.3464
V Predictions Min            155.84111
Log Pis Mean                 -0.30314165
Log Pis Std                  2.9428074
Log Pis Max                  19.106916
Log Pis Min                  -8.381808
Policy mu Mean               0.03747081
Policy mu Std                0.6118906
Policy mu Max                4.7597833
Policy mu Min                -4.3533955
Policy log std Mean          -0.9632702
Policy log std Std           0.28059873
Policy log std Max           -0.061739028
Policy log std Min           -2.754671
Z mean eval                  0.97996014
Z variance eval              0.015619941
total_rewards                [-186.47013621  561.80895595 2965.71578644  455.23839156 3234.79346133
 1373.33174974 2922.02583636 3129.48276837  150.50215097 3353.20800506]
total_rewards_mean           1795.963696958536
total_rewards_std            1380.0991836370301
total_rewards_max            3353.2080050648988
total_rewards_min            -186.4701362064267
Number of train steps total  332000
Number of env steps total    1662000
Number of rollouts total     0
Train Time (s)               27.307886332273483
(Previous) Eval Time (s)     9.555800077971071
Sample Time (s)              17.513841789681464
Epoch Time (s)               54.37752819992602
Total Train Time (s)         22900.23929539742
Epoch                        331
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:37:12.468285 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #331 | Epoch Duration: 69.2582528591156
2020-01-11 09:37:12.468473 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #331 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9801356
Z variance train             0.015643282
KL Divergence                22.443674
KL Loss                      2.2443674
QF Loss                      1542.4608
VF Loss                      287.54306
Policy Loss                  -1103.0114
Q Predictions Mean           1101.9076
Q Predictions Std            232.7878
Q Predictions Max            1312.2278
Q Predictions Min            162.67868
V Predictions Mean           1100.1897
V Predictions Std            230.95238
V Predictions Max            1307.3473
V Predictions Min            165.50882
Log Pis Mean                 -0.40033856
Log Pis Std                  2.6982915
Log Pis Max                  9.422277
Log Pis Min                  -8.950502
Policy mu Mean               -0.01276851
Policy mu Std                0.5712364
Policy mu Max                2.0056565
Policy mu Min                -1.837507
Policy log std Mean          -0.9786337
Policy log std Std           0.29005307
Policy log std Max           -0.20102847
Policy log std Min           -2.8527937
Z mean eval                  1.0061114
Z variance eval              0.012132977
total_rewards                [3264.73560543 3111.55222609 3091.95093977 3164.83424697 3119.39033538
 3047.42383527 3073.22557472 3325.20231088 3112.18897573 3074.85845154]
total_rewards_mean           3138.5362501784475
total_rewards_std            84.87813161375037
total_rewards_max            3325.202310878456
total_rewards_min            3047.4238352736725
Number of train steps total  333000
Number of env steps total    1667000
Number of rollouts total     0
Train Time (s)               31.253624157980084
(Previous) Eval Time (s)     24.436217478942126
Sample Time (s)              18.26610183203593
Epoch Time (s)               73.95594346895814
Total Train Time (s)         22977.252759761177
Epoch                        332
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:38:29.483976 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #332 | Epoch Duration: 77.01535940170288
2020-01-11 09:38:29.484135 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #332 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0057746
Z variance train             0.012118997
KL Divergence                22.706846
KL Loss                      2.2706847
QF Loss                      958.2926
VF Loss                      146.52968
Policy Loss                  -1113.2942
Q Predictions Mean           1112.181
Q Predictions Std            220.28905
Q Predictions Max            1301.858
Q Predictions Min            42.649998
V Predictions Mean           1114.5435
V Predictions Std            218.79814
V Predictions Max            1303.9652
V Predictions Min            27.517145
Log Pis Mean                 -0.2512936
Log Pis Std                  2.841677
Log Pis Max                  12.135904
Log Pis Min                  -6.8263865
Policy mu Mean               0.014362231
Policy mu Std                0.5613972
Policy mu Max                1.8486516
Policy mu Min                -1.9904436
Policy log std Mean          -1.0077544
Policy log std Std           0.303988
Policy log std Max           -0.21158332
Policy log std Min           -3.3083353
Z mean eval                  0.98039734
Z variance eval              0.01395447
total_rewards                [3212.89759065 1795.2768866  3126.27605596 3114.3169011  3386.30782871
 1335.6649466  1546.06011425 3073.88009889 3100.86251999 3272.51397862]
total_rewards_mean           2696.4056921362762
total_rewards_std            756.7749736851883
total_rewards_max            3386.307828711522
total_rewards_min            1335.664946598414
Number of train steps total  334000
Number of env steps total    1672000
Number of rollouts total     0
Train Time (s)               26.145671343896538
(Previous) Eval Time (s)     27.495289932005107
Sample Time (s)              18.90292161051184
Epoch Time (s)               72.54388288641348
Total Train Time (s)         23046.899279094767
Epoch                        333
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:39:39.133781 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #333 | Epoch Duration: 69.64952111244202
2020-01-11 09:39:39.133971 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #333 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98250306
Z variance train             0.014020848
KL Divergence                22.594975
KL Loss                      2.2594974
QF Loss                      11426.663
VF Loss                      1501.8892
Policy Loss                  -1114.4635
Q Predictions Mean           1110.7932
Q Predictions Std            209.51442
Q Predictions Max            1314.1178
Q Predictions Min            -49.061455
V Predictions Mean           1103.9962
V Predictions Std            199.2326
V Predictions Max            1299.5178
V Predictions Min            153.7362
Log Pis Mean                 -0.27356648
Log Pis Std                  2.6017087
Log Pis Max                  11.206686
Log Pis Min                  -9.097956
Policy mu Mean               0.030752879
Policy mu Std                0.5932675
Policy mu Max                2.0018454
Policy mu Min                -2.0251951
Policy log std Mean          -0.9664303
Policy log std Std           0.275216
Policy log std Max           -0.0020769835
Policy log std Min           -3.1481304
Z mean eval                  0.9855746
Z variance eval              0.015951067
total_rewards                [2947.42313435 2988.16841616 2955.38856696 3078.11256179 1638.58010997
 2559.81288295 3261.89318863 3192.92637344 3290.95618573 1169.28722408]
total_rewards_mean           2708.2548644052613
total_rewards_std            689.1332263619211
total_rewards_max            3290.9561857306335
total_rewards_min            1169.287224079873
Number of train steps total  335000
Number of env steps total    1677000
Number of rollouts total     0
Train Time (s)               30.098564783111215
(Previous) Eval Time (s)     24.600595560856164
Sample Time (s)              18.092898750677705
Epoch Time (s)               72.79205909464508
Total Train Time (s)         23118.764009451494
Epoch                        334
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:40:51.003016 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #334 | Epoch Duration: 71.86890459060669
2020-01-11 09:40:51.003249 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #334 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9857038
Z variance train             0.015856652
KL Divergence                22.903809
KL Loss                      2.290381
QF Loss                      729.42444
VF Loss                      283.00958
Policy Loss                  -1101.5433
Q Predictions Mean           1100.4724
Q Predictions Std            222.38223
Q Predictions Max            1301.8585
Q Predictions Min            4.0107846
V Predictions Mean           1095.3679
V Predictions Std            219.32332
V Predictions Max            1288.9491
V Predictions Min            34.744167
Log Pis Mean                 -0.24278314
Log Pis Std                  2.4804995
Log Pis Max                  11.56436
Log Pis Min                  -8.404519
Policy mu Mean               0.0795421
Policy mu Std                0.5795621
Policy mu Max                2.8574622
Policy mu Min                -2.2091978
Policy log std Mean          -0.94147545
Policy log std Std           0.25114918
Policy log std Max           -0.15013409
Policy log std Min           -1.9367919
Z mean eval                  1.0075462
Z variance eval              0.015700078
total_rewards                [1449.27270503 3088.36637412 1130.40408853  252.93768704 3013.92192989
 2788.0577749  1225.36512473 2998.28822529 1663.76780118 3037.55992194]
total_rewards_mean           2064.794163265771
total_rewards_std            984.3564825209534
total_rewards_max            3088.3663741205232
total_rewards_min            252.93768703909274
Number of train steps total  336000
Number of env steps total    1682000
Number of rollouts total     0
Train Time (s)               30.345483750104904
(Previous) Eval Time (s)     23.67708579869941
Sample Time (s)              19.075644710101187
Epoch Time (s)               73.0982142589055
Total Train Time (s)         23191.790534154512
Epoch                        335
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:42:04.032557 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #335 | Epoch Duration: 73.02912497520447
2020-01-11 09:42:04.032724 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #335 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0084544
Z variance train             0.015699312
KL Divergence                22.964191
KL Loss                      2.2964191
QF Loss                      644.23535
VF Loss                      124.45215
Policy Loss                  -1073.1874
Q Predictions Mean           1074.2439
Q Predictions Std            277.87787
Q Predictions Max            1273.442
Q Predictions Min            111.43658
V Predictions Mean           1079.0271
V Predictions Std            278.01294
V Predictions Max            1285.9485
V Predictions Min            111.15867
Log Pis Mean                 -0.23913115
Log Pis Std                  2.8329732
Log Pis Max                  10.394018
Log Pis Min                  -7.0644073
Policy mu Mean               0.0101633975
Policy mu Std                0.59020734
Policy mu Max                2.6376216
Policy mu Min                -2.447815
Policy log std Mean          -0.9490113
Policy log std Std           0.29378635
Policy log std Max           -0.18623269
Policy log std Min           -2.3823
Z mean eval                  1.0585359
Z variance eval              0.0143991355
total_rewards                [2748.91939787 2854.23782415 2968.91687925  -58.6388457  1856.43361716
  339.36813916 1032.36394852  255.09230477  396.61484879 1440.18977742]
total_rewards_mean           1383.3497891402917
total_rewards_std            1109.4316031224064
total_rewards_max            2968.9168792525234
total_rewards_min            -58.63884570443368
Number of train steps total  337000
Number of env steps total    1687000
Number of rollouts total     0
Train Time (s)               27.790129837114364
(Previous) Eval Time (s)     23.607661546673626
Sample Time (s)              18.21917873248458
Epoch Time (s)               69.61697011627257
Total Train Time (s)         23258.84704296058
Epoch                        336
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:43:11.092594 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #336 | Epoch Duration: 67.05972409248352
2020-01-11 09:43:11.092836 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #336 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0597084
Z variance train             0.0142875705
KL Divergence                24.064793
KL Loss                      2.4064794
QF Loss                      955.69324
VF Loss                      353.61298
Policy Loss                  -1129.9073
Q Predictions Mean           1128.947
Q Predictions Std            235.53001
Q Predictions Max            1342.2135
Q Predictions Min            61.66643
V Predictions Mean           1116.9443
V Predictions Std            232.19313
V Predictions Max            1327.3599
V Predictions Min            62.647293
Log Pis Mean                 -0.12697978
Log Pis Std                  2.6838152
Log Pis Max                  9.938757
Log Pis Min                  -8.741535
Policy mu Mean               0.044260193
Policy mu Std                0.5883558
Policy mu Max                2.1718018
Policy mu Min                -2.116065
Policy log std Mean          -0.9881339
Policy log std Std           0.27029583
Policy log std Max           -0.2166661
Policy log std Min           -2.425599
Z mean eval                  0.9894913
Z variance eval              0.013674943
total_rewards                [ 348.27133472 1639.76277605  620.35734945  368.16740248 3061.52435774
 -109.53870167 2474.60649786 3113.18277295  584.88327987  685.53840808]
total_rewards_mean           1278.675547751233
total_rewards_std            1139.8666402106435
total_rewards_max            3113.18277294976
total_rewards_min            -109.53870166870782
Number of train steps total  338000
Number of env steps total    1692000
Number of rollouts total     0
Train Time (s)               29.828878290951252
(Previous) Eval Time (s)     21.05007706908509
Sample Time (s)              19.27167836483568
Epoch Time (s)               70.15063372487202
Total Train Time (s)         23326.74126715213
Epoch                        337
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:44:18.989938 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #337 | Epoch Duration: 67.89692234992981
2020-01-11 09:44:18.990125 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #337 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9895727
Z variance train             0.0136191845
KL Divergence                23.6035
KL Loss                      2.3603501
QF Loss                      483.7822
VF Loss                      180.73303
Policy Loss                  -1129.1919
Q Predictions Mean           1132.02
Q Predictions Std            210.75204
Q Predictions Max            1350.0256
Q Predictions Min            126.762215
V Predictions Mean           1137.1193
V Predictions Std            213.21234
V Predictions Max            1343.9484
V Predictions Min            118.6183
Log Pis Mean                 -0.5265158
Log Pis Std                  2.395001
Log Pis Max                  8.30299
Log Pis Min                  -6.5455317
Policy mu Mean               0.002255537
Policy mu Std                0.5534995
Policy mu Max                1.818382
Policy mu Min                -1.9700211
Policy log std Mean          -0.9719348
Policy log std Std           0.26262876
Policy log std Max           -0.1879493
Policy log std Min           -2.406204
Z mean eval                  1.0064907
Z variance eval              0.012592685
total_rewards                [ 961.82237782 3099.40220154 3287.62616448  646.55201357 3070.24123785
 3231.35342943 2321.92580719   81.34760261 3239.8635076   920.03034903]
total_rewards_mean           2086.016469111829
total_rewards_std            1218.7050104506732
total_rewards_max            3287.6261644754486
total_rewards_min            81.34760261138914
Number of train steps total  339000
Number of env steps total    1697000
Number of rollouts total     0
Train Time (s)               26.95043887803331
(Previous) Eval Time (s)     18.79604686331004
Sample Time (s)              18.1165960887447
Epoch Time (s)               63.86308183008805
Total Train Time (s)         23396.78976703575
Epoch                        338
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:45:29.041841 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #338 | Epoch Duration: 70.05155873298645
2020-01-11 09:45:29.042068 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #338 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0051088
Z variance train             0.012593739
KL Divergence                23.759153
KL Loss                      2.3759153
QF Loss                      915.0687
VF Loss                      203.14198
Policy Loss                  -1117.911
Q Predictions Mean           1117.1389
Q Predictions Std            235.59557
Q Predictions Max            1359.5723
Q Predictions Min            99.75943
V Predictions Mean           1111.5612
V Predictions Std            232.50467
V Predictions Max            1355.5189
V Predictions Min            102.075226
Log Pis Mean                 0.0012730733
Log Pis Std                  2.815766
Log Pis Max                  16.12265
Log Pis Min                  -9.113911
Policy mu Mean               0.034475062
Policy mu Std                0.6325057
Policy mu Max                2.6324263
Policy mu Min                -3.27812
Policy log std Mean          -0.9366188
Policy log std Std           0.27007928
Policy log std Max           -0.18944788
Policy log std Min           -2.595179
Z mean eval                  1.0653112
Z variance eval              0.020901611
total_rewards                [1227.42425877  684.80109851  600.89691616 2680.81287372 2015.06274758
  156.87961183 2808.1075737  2801.30826338  390.46006706 1104.12048544]
total_rewards_mean           1446.98738961487
total_rewards_std            988.6889752494366
total_rewards_max            2808.1075736978405
total_rewards_min            156.87961183312802
Number of train steps total  340000
Number of env steps total    1702000
Number of rollouts total     0
Train Time (s)               28.763451101258397
(Previous) Eval Time (s)     24.984167526010424
Sample Time (s)              17.628152278717607
Epoch Time (s)               71.37577090598643
Total Train Time (s)         23461.292512598913
Epoch                        339
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:46:33.551514 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #339 | Epoch Duration: 64.50913333892822
2020-01-11 09:46:33.551960 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #339 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0634041
Z variance train             0.020959137
KL Divergence                23.092806
KL Loss                      2.3092806
QF Loss                      2181.1392
VF Loss                      222.3195
Policy Loss                  -1157.6672
Q Predictions Mean           1157.204
Q Predictions Std            177.55844
Q Predictions Max            1357.7142
Q Predictions Min            136.96725
V Predictions Mean           1162.2233
V Predictions Std            174.142
V Predictions Max            1351.7695
V Predictions Min            150.87085
Log Pis Mean                 -0.11877778
Log Pis Std                  3.0626338
Log Pis Max                  10.375174
Log Pis Min                  -7.6926894
Policy mu Mean               -0.04435087
Policy mu Std                0.6157241
Policy mu Max                2.553758
Policy mu Min                -2.4193523
Policy log std Mean          -0.9862424
Policy log std Std           0.27491507
Policy log std Max           -0.17310524
Policy log std Min           -2.2921767
Z mean eval                  0.99839145
Z variance eval              0.015132224
total_rewards                [ 806.82691867 3160.61200699 3140.52678248  663.75250207 2937.69049124
 3082.08724353 3094.07340833 3118.39462603 1317.31327084 1062.3079433 ]
total_rewards_mean           2238.3585193472777
total_rewards_std            1055.0924176698907
total_rewards_max            3160.6120069898852
total_rewards_min            663.7525020700627
Number of train steps total  341000
Number of env steps total    1707000
Number of rollouts total     0
Train Time (s)               30.28406098810956
(Previous) Eval Time (s)     18.117219371255487
Sample Time (s)              18.056381749920547
Epoch Time (s)               66.4576621092856
Total Train Time (s)         23534.112977497745
Epoch                        340
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:47:46.373264 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #340 | Epoch Duration: 72.82108426094055
2020-01-11 09:47:46.373471 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #340 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99843633
Z variance train             0.015100582
KL Divergence                23.128551
KL Loss                      2.3128552
QF Loss                      1051.849
VF Loss                      60.90102
Policy Loss                  -1132.3905
Q Predictions Mean           1134.3567
Q Predictions Std            229.92581
Q Predictions Max            1339.6111
Q Predictions Min            111.18436
V Predictions Mean           1132.7079
V Predictions Std            231.83633
V Predictions Max            1333.8518
V Predictions Min            122.32173
Log Pis Mean                 -0.5684651
Log Pis Std                  2.4536588
Log Pis Max                  10.543291
Log Pis Min                  -7.4283695
Policy mu Mean               0.056919143
Policy mu Std                0.56682813
Policy mu Max                3.2122946
Policy mu Min                -2.2092412
Policy log std Mean          -0.9384762
Policy log std Std           0.2520016
Policy log std Max           -0.08661628
Policy log std Min           -2.503862
Z mean eval                  1.0120938
Z variance eval              0.015579127
total_rewards                [1222.15263142 3021.21079038 2945.66332501  523.02942623 2882.9082599
 3051.20291988 1020.17636398 1577.32508019 3040.58899098 2804.81237997]
total_rewards_mean           2208.907016795431
total_rewards_std            950.8432691757293
total_rewards_max            3051.202919879922
total_rewards_min            523.0294262348935
Number of train steps total  342000
Number of env steps total    1712000
Number of rollouts total     0
Train Time (s)               29.17287139268592
(Previous) Eval Time (s)     24.480346056167036
Sample Time (s)              17.6835624887608
Epoch Time (s)               71.33677993761376
Total Train Time (s)         23602.103146431968
Epoch                        341
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:48:54.369796 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #341 | Epoch Duration: 67.996084690094
2020-01-11 09:48:54.370134 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #341 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.012646
Z variance train             0.015566254
KL Divergence                23.408136
KL Loss                      2.3408136
QF Loss                      8504.771
VF Loss                      634.44867
Policy Loss                  -1129.1666
Q Predictions Mean           1131.9376
Q Predictions Std            211.33183
Q Predictions Max            1334.1078
Q Predictions Min            151.39996
V Predictions Mean           1145.8435
V Predictions Std            212.23349
V Predictions Max            1335.6917
V Predictions Min            166.52692
Log Pis Mean                 -0.19506562
Log Pis Std                  2.8894563
Log Pis Max                  10.981052
Log Pis Min                  -9.987757
Policy mu Mean               0.038590923
Policy mu Std                0.5931163
Policy mu Max                2.2683482
Policy mu Min                -3.013198
Policy log std Mean          -0.9701901
Policy log std Std           0.28739268
Policy log std Max           -0.0998981
Policy log std Min           -2.977436
Z mean eval                  1.0061404
Z variance eval              0.013730337
total_rewards                [-160.76807282 2910.08904214 3083.42826781 2918.51261039 2013.29093666
 2953.9213003  2884.19678994 1216.63600485 3095.04606946 2742.49581631]
total_rewards_mean           2365.684876504854
total_rewards_std            1011.6046760907965
total_rewards_max            3095.0460694631665
total_rewards_min            -160.7680728162801
Number of train steps total  343000
Number of env steps total    1717000
Number of rollouts total     0
Train Time (s)               29.991128124762326
(Previous) Eval Time (s)     21.139308491256088
Sample Time (s)              18.474988873116672
Epoch Time (s)               69.60542548913509
Total Train Time (s)         23676.23834009003
Epoch                        342
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:50:08.509244 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #342 | Epoch Duration: 74.13889646530151
2020-01-11 09:50:08.509514 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #342 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0021851
Z variance train             0.013741235
KL Divergence                23.527172
KL Loss                      2.3527172
QF Loss                      529.3707
VF Loss                      175.79672
Policy Loss                  -1113.5261
Q Predictions Mean           1113.3152
Q Predictions Std            267.33856
Q Predictions Max            1362.2213
Q Predictions Min            59.64902
V Predictions Mean           1104.59
V Predictions Std            264.79172
V Predictions Max            1354.8634
V Predictions Min            39.760944
Log Pis Mean                 -0.44912222
Log Pis Std                  2.7602115
Log Pis Max                  9.698363
Log Pis Min                  -8.120164
Policy mu Mean               0.010129589
Policy mu Std                0.56122214
Policy mu Max                2.300055
Policy mu Min                -2.4373324
Policy log std Mean          -0.9729006
Policy log std Std           0.2749512
Policy log std Max           -0.18550432
Policy log std Min           -2.588779
Z mean eval                  0.99899626
Z variance eval              0.011868527
total_rewards                [2347.15621746 3085.92956803  969.09641351 3078.13858161 1604.60706619
 3243.95043207 3175.68054427 2988.35680414 2975.55875133 3211.26751191]
total_rewards_mean           2667.97418905201
total_rewards_std            744.6285198790628
total_rewards_max            3243.950432065898
total_rewards_min            969.0964135102514
Number of train steps total  344000
Number of env steps total    1722000
Number of rollouts total     0
Train Time (s)               31.200308417901397
(Previous) Eval Time (s)     25.67247076611966
Sample Time (s)              19.216132619418204
Epoch Time (s)               76.08891180343926
Total Train Time (s)         23751.552873493172
Epoch                        343
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:51:23.826483 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #343 | Epoch Duration: 75.31677746772766
2020-01-11 09:51:23.826670 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #343 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9991425
Z variance train             0.011851093
KL Divergence                23.61214
KL Loss                      2.3612142
QF Loss                      681.8482
VF Loss                      123.613716
Policy Loss                  -1119.0637
Q Predictions Mean           1117.032
Q Predictions Std            243.25952
Q Predictions Max            1355.1346
Q Predictions Min            84.89583
V Predictions Mean           1115.5583
V Predictions Std            243.80424
V Predictions Max            1357.8877
V Predictions Min            90.407394
Log Pis Mean                 -0.3214483
Log Pis Std                  2.9116178
Log Pis Max                  10.344496
Log Pis Min                  -9.428064
Policy mu Mean               0.040066212
Policy mu Std                0.58150506
Policy mu Max                2.366848
Policy mu Min                -1.8184624
Policy log std Mean          -0.98428345
Policy log std Std           0.28501055
Policy log std Max           -0.17060858
Policy log std Min           -2.4851542
Z mean eval                  1.0478674
Z variance eval              0.011888896
total_rewards                [3071.41800698 1399.46182292 3090.93220896 2262.64977786  336.78875019
 2911.90869744 3081.14287068 3326.39815689 3059.77353246 2833.48932151]
total_rewards_mean           2537.3963145882194
total_rewards_std            906.8422216343856
total_rewards_max            3326.3981568875483
total_rewards_min            336.7887501897336
Number of train steps total  345000
Number of env steps total    1727000
Number of rollouts total     0
Train Time (s)               28.445981533266604
(Previous) Eval Time (s)     24.900008044671267
Sample Time (s)              17.63771555479616
Epoch Time (s)               70.98370513273403
Total Train Time (s)         23824.778746361844
Epoch                        344
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:52:37.055437 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #344 | Epoch Duration: 73.22863245010376
2020-01-11 09:52:37.055627 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #344 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0503956
Z variance train             0.0118877385
KL Divergence                23.524467
KL Loss                      2.3524468
QF Loss                      953.94775
VF Loss                      643.85913
Policy Loss                  -1131.5868
Q Predictions Mean           1131.8326
Q Predictions Std            236.75076
Q Predictions Max            1333.1141
Q Predictions Min            75.219406
V Predictions Mean           1138.1904
V Predictions Std            232.07797
V Predictions Max            1337.3877
V Predictions Min            28.03419
Log Pis Mean                 -0.22509284
Log Pis Std                  2.6278906
Log Pis Max                  10.221614
Log Pis Min                  -8.52687
Policy mu Mean               0.014011652
Policy mu Std                0.5798057
Policy mu Max                2.6053495
Policy mu Min                -2.093813
Policy log std Mean          -0.99760866
Policy log std Std           0.26708522
Policy log std Max           -0.20095092
Policy log std Min           -2.7023783
Z mean eval                  1.0210333
Z variance eval              0.013089339
total_rewards                [3187.92755587 2913.1492654  3147.66261991 2985.14398022 1779.4372261
  551.33094675 2477.039782   1313.62867489 3099.00355701 3175.90566792]
total_rewards_mean           2463.0229276055093
total_rewards_std            884.6058311857405
total_rewards_max            3187.927555871457
total_rewards_min            551.3309467478733
Number of train steps total  346000
Number of env steps total    1732000
Number of rollouts total     0
Train Time (s)               30.55469521973282
(Previous) Eval Time (s)     27.144625267013907
Sample Time (s)              17.700904830824584
Epoch Time (s)               75.40022531757131
Total Train Time (s)         23895.77500326652
Epoch                        345
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:53:48.058329 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #345 | Epoch Duration: 71.00252437591553
2020-01-11 09:53:48.058641 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #345 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0233264
Z variance train             0.013159819
KL Divergence                23.42455
KL Loss                      2.342455
QF Loss                      1950.8151
VF Loss                      583.3455
Policy Loss                  -1138.8539
Q Predictions Mean           1136.176
Q Predictions Std            231.14006
Q Predictions Max            1351.795
Q Predictions Min            10.133749
V Predictions Mean           1133.0787
V Predictions Std            227.39757
V Predictions Max            1357.2972
V Predictions Min            78.32524
Log Pis Mean                 -0.12351492
Log Pis Std                  2.6494067
Log Pis Max                  9.951696
Log Pis Min                  -6.0199137
Policy mu Mean               0.059942633
Policy mu Std                0.59608084
Policy mu Max                2.6035168
Policy mu Min                -2.0299034
Policy log std Mean          -0.9619647
Policy log std Std           0.2943348
Policy log std Max           -0.20197773
Policy log std Min           -3.5277417
Z mean eval                  1.0152324
Z variance eval              0.014301151
total_rewards                [1919.73093423  694.99003256 3292.21477951 3495.42936504 3314.4928653
 3221.90753859  366.1989113  3134.7998546  3284.1291801  3391.27558428]
total_rewards_mean           2611.5169045508474
total_rewards_std            1124.222160008246
total_rewards_max            3495.4293650365753
total_rewards_min            366.19891130105276
Number of train steps total  347000
Number of env steps total    1737000
Number of rollouts total     0
Train Time (s)               29.277839341200888
(Previous) Eval Time (s)     22.74661434534937
Sample Time (s)              18.04166539432481
Epoch Time (s)               70.06611908087507
Total Train Time (s)         23968.444123731926
Epoch                        346
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:55:00.730312 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #346 | Epoch Duration: 72.6714415550232
2020-01-11 09:55:00.730497 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #346 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.016099
Z variance train             0.014342857
KL Divergence                22.985184
KL Loss                      2.2985184
QF Loss                      868.6992
VF Loss                      876.0865
Policy Loss                  -1122.3066
Q Predictions Mean           1122.8259
Q Predictions Std            241.61356
Q Predictions Max            1318.1366
Q Predictions Min            137.66273
V Predictions Mean           1111.2498
V Predictions Std            241.68336
V Predictions Max            1309.7128
V Predictions Min            133.37546
Log Pis Mean                 -0.13698567
Log Pis Std                  2.6683178
Log Pis Max                  11.361408
Log Pis Min                  -6.7082357
Policy mu Mean               0.009386364
Policy mu Std                0.59610707
Policy mu Max                2.2855594
Policy mu Min                -2.6740198
Policy log std Mean          -0.98364043
Policy log std Std           0.295514
Policy log std Max           -0.21451795
Policy log std Min           -3.0903282
Z mean eval                  1.0061524
Z variance eval              0.013825262
total_rewards                [3036.3049446  3123.81338005 2499.42823278 3225.442933   3006.34862075
 3383.11481456 3018.13214963 2710.69153237 3084.54751374 3263.21465026]
total_rewards_mean           3035.1038771728513
total_rewards_std            247.58781370378227
total_rewards_max            3383.114814562514
total_rewards_min            2499.4282327754527
Number of train steps total  348000
Number of env steps total    1742000
Number of rollouts total     0
Train Time (s)               25.97595457592979
(Previous) Eval Time (s)     25.351656186860055
Sample Time (s)              18.42848982801661
Epoch Time (s)               69.75610059080645
Total Train Time (s)         24038.397015915718
Epoch                        347
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:56:10.686615 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #347 | Epoch Duration: 69.95595240592957
2020-01-11 09:56:10.686827 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #347 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0047374
Z variance train             0.013784816
KL Divergence                22.978567
KL Loss                      2.2978568
QF Loss                      947.1095
VF Loss                      320.28424
Policy Loss                  -1133.5465
Q Predictions Mean           1133.7617
Q Predictions Std            224.21912
Q Predictions Max            1343.9856
Q Predictions Min            47.69711
V Predictions Mean           1120.0757
V Predictions Std            219.77686
V Predictions Max            1332.5707
V Predictions Min            53.727222
Log Pis Mean                 -0.17436305
Log Pis Std                  2.7216983
Log Pis Max                  15.206807
Log Pis Min                  -8.443073
Policy mu Mean               0.03972049
Policy mu Std                0.57565856
Policy mu Max                2.61658
Policy mu Min                -2.2030704
Policy log std Mean          -0.9781349
Policy log std Std           0.2669909
Policy log std Max           -0.20717508
Policy log std Min           -2.986608
Z mean eval                  1.027374
Z variance eval              0.007649748
total_rewards                [ 858.09034437  596.00474523  515.80730139 2728.08616755 3031.39256064
   84.47355462 1381.22751859 2287.04974511 2899.54823876 3241.31866956]
total_rewards_mean           1762.2998845834277
total_rewards_std            1139.7996539998096
total_rewards_max            3241.318669561993
total_rewards_min            84.47355462493428
Number of train steps total  349000
Number of env steps total    1747000
Number of rollouts total     0
Train Time (s)               28.461923066992313
(Previous) Eval Time (s)     25.551175964064896
Sample Time (s)              17.916298083029687
Epoch Time (s)               71.9293971140869
Total Train Time (s)         24101.813871048857
Epoch                        348
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:57:14.107835 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #348 | Epoch Duration: 63.42081928253174
2020-01-11 09:57:14.108064 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #348 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0279965
Z variance train             0.0076353317
KL Divergence                24.696949
KL Loss                      2.4696949
QF Loss                      1769.1106
VF Loss                      194.13562
Policy Loss                  -1141.7802
Q Predictions Mean           1145.0074
Q Predictions Std            241.42737
Q Predictions Max            1353.715
Q Predictions Min            4.625004
V Predictions Mean           1150.8037
V Predictions Std            240.73193
V Predictions Max            1344.6644
V Predictions Min            14.192532
Log Pis Mean                 -0.09663627
Log Pis Std                  2.9284766
Log Pis Max                  13.985065
Log Pis Min                  -8.067235
Policy mu Mean               -0.010002548
Policy mu Std                0.6607612
Policy mu Max                3.1375005
Policy mu Min                -2.9943266
Policy log std Mean          -0.94692546
Policy log std Std           0.25859433
Policy log std Max           -0.24249518
Policy log std Min           -2.0995965
Z mean eval                  1.043331
Z variance eval              0.010283906
total_rewards                [2830.89102761 2918.74732766 3169.85552961 3032.20905355 2031.55525604
 2983.84654327 3048.83228467 3105.94978928 3130.5458637  3241.06225186]
total_rewards_mean           2949.3494927248757
total_rewards_std            326.5490414088069
total_rewards_max            3241.062251857391
total_rewards_min            2031.5552560386027
Number of train steps total  350000
Number of env steps total    1752000
Number of rollouts total     0
Train Time (s)               30.89896528236568
(Previous) Eval Time (s)     17.042256526183337
Sample Time (s)              18.205460749100894
Epoch Time (s)               66.14668255764991
Total Train Time (s)         24176.888787053525
Epoch                        349
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:58:29.184840 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #349 | Epoch Duration: 75.07661128044128
2020-01-11 09:58:29.184993 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #349 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0421137
Z variance train             0.010282113
KL Divergence                24.46883
KL Loss                      2.446883
QF Loss                      711.8219
VF Loss                      115.42007
Policy Loss                  -1162.5277
Q Predictions Mean           1162.9414
Q Predictions Std            201.64297
Q Predictions Max            1357.8354
Q Predictions Min            10.596499
V Predictions Mean           1160.4403
V Predictions Std            200.65007
V Predictions Max            1333.9377
V Predictions Min            1.8635069
Log Pis Mean                 -0.15805644
Log Pis Std                  2.5731454
Log Pis Max                  8.966317
Log Pis Min                  -8.428847
Policy mu Mean               -0.045564108
Policy mu Std                0.5831258
Policy mu Max                1.9893576
Policy mu Min                -2.201113
Policy log std Mean          -0.9968686
Policy log std Std           0.2666649
Policy log std Max           0.17035675
Policy log std Min           -2.1928613
Z mean eval                  1.0179751
Z variance eval              0.01309344
total_rewards                [ 725.0227942  3571.54941839 2063.20269461  583.50660071 1030.02928877
  925.00155516  958.52606606 1375.74696853 3421.11467048 3419.06222223]
total_rewards_mean           1807.2762279136616
total_rewards_std            1154.9236855293016
total_rewards_max            3571.5494183896053
total_rewards_min            583.5066007088792
Number of train steps total  351000
Number of env steps total    1757000
Number of rollouts total     0
Train Time (s)               30.73679610528052
(Previous) Eval Time (s)     25.971876721829176
Sample Time (s)              18.23699684534222
Epoch Time (s)               74.94566967245191
Total Train Time (s)         24242.03011422651
Epoch                        350
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:59:34.333029 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #350 | Epoch Duration: 65.14787435531616
2020-01-11 09:59:34.333337 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #350 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0201255
Z variance train             0.0130569395
KL Divergence                23.714508
KL Loss                      2.371451
QF Loss                      1085.0593
VF Loss                      196.24672
Policy Loss                  -1149.7734
Q Predictions Mean           1147.9031
Q Predictions Std            210.47319
Q Predictions Max            1375.7311
Q Predictions Min            57.119873
V Predictions Mean           1140.1796
V Predictions Std            211.88382
V Predictions Max            1363.57
V Predictions Min            39.945023
Log Pis Mean                 -0.2042175
Log Pis Std                  2.5747724
Log Pis Max                  8.523798
Log Pis Min                  -7.495237
Policy mu Mean               0.016942088
Policy mu Std                0.60405105
Policy mu Max                2.2705548
Policy mu Min                -2.0706096
Policy log std Mean          -0.9848777
Policy log std Std           0.23309116
Policy log std Max           -0.2047475
Policy log std Min           -2.1437297
Z mean eval                  1.0382478
Z variance eval              0.015079315
total_rewards                [3317.74266806 3108.19440897 3046.34903227  254.68992717  935.11963782
 3224.09826855 2960.57616969 3065.28555697 3500.05580061 3388.41306612]
total_rewards_mean           2680.0524536223406
total_rewards_std            1065.2964675508138
total_rewards_max            3500.0558006147576
total_rewards_min            254.68992717393064
Number of train steps total  352000
Number of env steps total    1762000
Number of rollouts total     0
Train Time (s)               26.677798813208938
(Previous) Eval Time (s)     16.173750557936728
Sample Time (s)              19.6432752199471
Epoch Time (s)               62.494824591092765
Total Train Time (s)         24312.767424063757
Epoch                        351
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:00:45.075698 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #351 | Epoch Duration: 70.74211764335632
2020-01-11 10:00:45.076002 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #351 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0395072
Z variance train             0.015084542
KL Divergence                22.677511
KL Loss                      2.2677512
QF Loss                      768.61
VF Loss                      319.9837
Policy Loss                  -1135.1593
Q Predictions Mean           1133.7302
Q Predictions Std            237.34637
Q Predictions Max            1350.322
Q Predictions Min            52.11398
V Predictions Mean           1134.6414
V Predictions Std            233.54732
V Predictions Max            1351.8501
V Predictions Min            58.588627
Log Pis Mean                 -0.041531906
Log Pis Std                  2.7290103
Log Pis Max                  12.009189
Log Pis Min                  -7.414036
Policy mu Mean               -0.055245966
Policy mu Std                0.6157071
Policy mu Max                2.353957
Policy mu Min                -2.3876235
Policy log std Mean          -0.9782201
Policy log std Std           0.27312654
Policy log std Max           -0.19204748
Policy log std Min           -2.56414
Z mean eval                  1.0066975
Z variance eval              0.012123516
total_rewards                [ 398.9245151    62.65138576 1710.44362826 3172.87039303 3321.21251161
 1498.31709131  857.12777707 3272.07565356 1906.94809532 3264.46529654]
total_rewards_mean           1946.5036347564333
total_rewards_std            1194.8541489612896
total_rewards_max            3321.212511607302
total_rewards_min            62.651385762017725
Number of train steps total  353000
Number of env steps total    1767000
Number of rollouts total     0
Train Time (s)               28.313547597732395
(Previous) Eval Time (s)     24.420731232035905
Sample Time (s)              18.143305318430066
Epoch Time (s)               70.87758414819837
Total Train Time (s)         24375.54909896385
Epoch                        352
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:01:47.860021 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #352 | Epoch Duration: 62.783809423446655
2020-01-11 10:01:47.860207 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #352 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0075824
Z variance train             0.012092894
KL Divergence                23.946135
KL Loss                      2.3946135
QF Loss                      1170.1936
VF Loss                      569.232
Policy Loss                  -1162.9058
Q Predictions Mean           1160.9248
Q Predictions Std            221.4864
Q Predictions Max            1356.2285
Q Predictions Min            109.30809
V Predictions Mean           1162.3456
V Predictions Std            219.98776
V Predictions Max            1357.3015
V Predictions Min            142.18544
Log Pis Mean                 -0.46135747
Log Pis Std                  2.7501864
Log Pis Max                  14.613127
Log Pis Min                  -9.430922
Policy mu Mean               0.031094845
Policy mu Std                0.5877112
Policy mu Max                2.3381498
Policy mu Min                -2.3357341
Policy log std Mean          -0.96597505
Policy log std Std           0.27442017
Policy log std Max           -0.18238133
Policy log std Min           -3.1193838
Z mean eval                  1.0462314
Z variance eval              0.009773475
total_rewards                [3182.01150558 3016.54039299 1664.95998553 1292.46835558 3324.48042914
 3185.00457663 3140.20407638 1759.75137823 3359.23660438 1633.56726304]
total_rewards_mean           2555.822456746556
total_rewards_std            803.2458192904763
total_rewards_max            3359.2366043768193
total_rewards_min            1292.4683555803435
Number of train steps total  354000
Number of env steps total    1772000
Number of rollouts total     0
Train Time (s)               29.52053381688893
(Previous) Eval Time (s)     16.32666878402233
Sample Time (s)              17.421928016934544
Epoch Time (s)               63.2691306178458
Total Train Time (s)         24445.61304865824
Epoch                        353
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:02:57.931881 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #353 | Epoch Duration: 70.07148671150208
2020-01-11 10:02:57.932121 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #353 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0465553
Z variance train             0.00977569
KL Divergence                24.31175
KL Loss                      2.431175
QF Loss                      6096.42
VF Loss                      181.58435
Policy Loss                  -1157.1759
Q Predictions Mean           1157.9965
Q Predictions Std            210.44006
Q Predictions Max            1330.3423
Q Predictions Min            19.885221
V Predictions Mean           1161.9243
V Predictions Std            210.66046
V Predictions Max            1335.6797
V Predictions Min            2.1584418
Log Pis Mean                 -0.041750822
Log Pis Std                  2.6157863
Log Pis Max                  15.470556
Log Pis Min                  -6.0335917
Policy mu Mean               -0.022597253
Policy mu Std                0.5985908
Policy mu Max                2.173489
Policy mu Min                -2.2734122
Policy log std Mean          -0.969661
Policy log std Std           0.2788658
Policy log std Max           0.5422113
Policy log std Min           -3.2825923
Z mean eval                  1.0432452
Z variance eval              0.008254779
total_rewards                [ -98.2889366  3052.89986224 1802.1979627  3389.61250017 1719.33866363
 1982.1213579   772.01090628 1464.58881104 3167.68089243 2636.099869  ]
total_rewards_mean           1988.8261888776583
total_rewards_std            1054.6150522535943
total_rewards_max            3389.6125001657642
total_rewards_min            -98.28893659695717
Number of train steps total  355000
Number of env steps total    1777000
Number of rollouts total     0
Train Time (s)               26.253711177036166
(Previous) Eval Time (s)     23.12875723093748
Sample Time (s)              18.943053773604333
Epoch Time (s)               68.32552218157798
Total Train Time (s)         24513.365216060076
Epoch                        354
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:04:05.689133 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #354 | Epoch Duration: 67.7568154335022
2020-01-11 10:04:05.689417 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #354 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0447825
Z variance train             0.00830835
KL Divergence                24.733458
KL Loss                      2.4733458
QF Loss                      654.9707
VF Loss                      106.065735
Policy Loss                  -1151.6271
Q Predictions Mean           1151.6099
Q Predictions Std            249.7721
Q Predictions Max            1369.3843
Q Predictions Min            31.631598
V Predictions Mean           1149.1311
V Predictions Std            246.43918
V Predictions Max            1366.3828
V Predictions Min            46.095436
Log Pis Mean                 -0.28579655
Log Pis Std                  2.5759733
Log Pis Max                  9.048721
Log Pis Min                  -8.179902
Policy mu Mean               0.018237159
Policy mu Std                0.58994246
Policy mu Max                2.2614188
Policy mu Min                -3.007348
Policy log std Mean          -0.9699839
Policy log std Std           0.25816268
Policy log std Max           0.010779619
Policy log std Min           -1.9892654
Z mean eval                  1.0380774
Z variance eval              0.009039312
total_rewards                [3198.79473063  324.0424702  3362.08563488 1833.43562356 3207.26444149
 3275.92652993 3311.86152638 3164.72914986 2926.71064185 3040.07881045]
total_rewards_mean           2764.492955922661
total_rewards_std            915.8643875396552
total_rewards_max            3362.085634880485
total_rewards_min            324.0424701985459
Number of train steps total  356000
Number of env steps total    1782000
Number of rollouts total     0
Train Time (s)               29.014781466685236
(Previous) Eval Time (s)     22.559735811781138
Sample Time (s)              18.836914707440883
Epoch Time (s)               70.41143198590726
Total Train Time (s)         24584.276095107663
Epoch                        355
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:05:16.606460 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #355 | Epoch Duration: 70.91678857803345
2020-01-11 10:05:16.606742 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #355 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0373826
Z variance train             0.009022741
KL Divergence                24.393145
KL Loss                      2.4393146
QF Loss                      1064.1086
VF Loss                      400.58017
Policy Loss                  -1145.0913
Q Predictions Mean           1142.2723
Q Predictions Std            246.50769
Q Predictions Max            1361.4999
Q Predictions Min            18.507275
V Predictions Mean           1143.6528
V Predictions Std            241.58209
V Predictions Max            1362.4935
V Predictions Min            43.218563
Log Pis Mean                 -0.0054832287
Log Pis Std                  2.667461
Log Pis Max                  11.247547
Log Pis Min                  -6.803172
Policy mu Mean               0.050650094
Policy mu Std                0.58867234
Policy mu Max                2.7147877
Policy mu Min                -2.140011
Policy log std Mean          -0.9908124
Policy log std Std           0.27263546
Policy log std Max           -0.007361412
Policy log std Min           -2.6998906
Z mean eval                  1.0252656
Z variance eval              0.009264717
total_rewards                [ 479.61154777 1382.4446049   445.99135663 3145.22703541 2083.93104995
 3133.50412601  874.79031439 3048.45574543  -98.92868088  245.43717875]
total_rewards_mean           1474.0464278348836
total_rewards_std            1216.3221838765137
total_rewards_max            3145.2270354051134
total_rewards_min            -98.92868087606033
Number of train steps total  357000
Number of env steps total    1787000
Number of rollouts total     0
Train Time (s)               29.966282036155462
(Previous) Eval Time (s)     23.06476165819913
Sample Time (s)              18.88575069885701
Epoch Time (s)               71.9167943932116
Total Train Time (s)         24650.616974751465
Epoch                        356
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:06:22.951409 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #356 | Epoch Duration: 66.34435224533081
2020-01-11 10:06:22.951747 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #356 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0256771
Z variance train             0.009265149
KL Divergence                24.37878
KL Loss                      2.4378781
QF Loss                      1532.7361
VF Loss                      581.71735
Policy Loss                  -1152.8535
Q Predictions Mean           1149.6577
Q Predictions Std            237.84938
Q Predictions Max            1405.1414
Q Predictions Min            30.422865
V Predictions Mean           1140.9219
V Predictions Std            233.00122
V Predictions Max            1369.7915
V Predictions Min            18.320124
Log Pis Mean                 0.03599602
Log Pis Std                  2.7919323
Log Pis Max                  16.125668
Log Pis Min                  -6.5550556
Policy mu Mean               0.05765555
Policy mu Std                0.61162806
Policy mu Max                2.5846517
Policy mu Min                -1.9966733
Policy log std Mean          -1.001014
Policy log std Std           0.3169511
Policy log std Max           -0.10182595
Policy log std Min           -3.500032
Z mean eval                  1.0127617
Z variance eval              0.012167757
total_rewards                [ -17.02782152 3187.39863065 3401.6996909  2889.46232155 3340.80557509
 3282.54035065 1028.2233201   237.84103974 1930.5541996  2741.51726894]
total_rewards_mean           2202.301457569224
total_rewards_std            1259.8355934708295
total_rewards_max            3401.699690895034
total_rewards_min            -17.02782151555922
Number of train steps total  358000
Number of env steps total    1792000
Number of rollouts total     0
Train Time (s)               31.04513581423089
(Previous) Eval Time (s)     17.491982927080244
Sample Time (s)              18.196650312282145
Epoch Time (s)               66.73376905359328
Total Train Time (s)         24721.351392933168
Epoch                        357
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:07:33.690008 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #357 | Epoch Duration: 70.73802995681763
2020-01-11 10:07:33.690250 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #357 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0122802
Z variance train             0.0121364035
KL Divergence                23.68524
KL Loss                      2.368524
QF Loss                      739.5372
VF Loss                      364.73215
Policy Loss                  -1164.8077
Q Predictions Mean           1162.6089
Q Predictions Std            211.00215
Q Predictions Max            1353.9429
Q Predictions Min            47.32496
V Predictions Mean           1152.9216
V Predictions Std            206.82526
V Predictions Max            1333.6292
V Predictions Min            45.22043
Log Pis Mean                 -0.19207689
Log Pis Std                  2.6932464
Log Pis Max                  12.17292
Log Pis Min                  -6.8126955
Policy mu Mean               -0.015851378
Policy mu Std                0.605812
Policy mu Max                2.5369692
Policy mu Min                -2.1886215
Policy log std Mean          -0.9674889
Policy log std Std           0.27999315
Policy log std Max           -0.107601404
Policy log std Min           -3.1618648
Z mean eval                  1.075789
Z variance eval              0.0069881068
total_rewards                [3303.3488628  3427.49132471  832.61515693  740.81305263  804.97516635
 2515.16692121 3173.02846484 1668.94325346 3022.56283724 3169.6400597 ]
total_rewards_mean           2265.8585099869088
total_rewards_std            1075.6741928239255
total_rewards_max            3427.491324714769
total_rewards_min            740.8130526319536
Number of train steps total  359000
Number of env steps total    1797000
Number of rollouts total     0
Train Time (s)               29.885734441690147
(Previous) Eval Time (s)     21.495961582753807
Sample Time (s)              19.290673398878425
Epoch Time (s)               70.67236942332238
Total Train Time (s)         24789.487816771027
Epoch                        358
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:08:41.830508 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #358 | Epoch Duration: 68.14007925987244
2020-01-11 10:08:41.830701 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #358 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0760843
Z variance train             0.006981538
KL Divergence                24.70729
KL Loss                      2.470729
QF Loss                      774.6759
VF Loss                      166.45413
Policy Loss                  -1143.9615
Q Predictions Mean           1145.081
Q Predictions Std            235.39838
Q Predictions Max            1392.8934
Q Predictions Min            71.93862
V Predictions Mean           1147.5027
V Predictions Std            236.07841
V Predictions Max            1386.843
V Predictions Min            43.013283
Log Pis Mean                 -0.37903827
Log Pis Std                  2.3906214
Log Pis Max                  8.815872
Log Pis Min                  -5.574041
Policy mu Mean               0.021543559
Policy mu Std                0.58726007
Policy mu Max                2.336184
Policy mu Min                -1.9915444
Policy log std Mean          -0.95940447
Policy log std Std           0.26626435
Policy log std Max           -0.08507943
Policy log std Min           -2.554189
Z mean eval                  1.0680902
Z variance eval              0.0065347487
total_rewards                [1391.64339074  211.90056861 2864.87919458 3386.20514931   44.58614624
 3161.88673757  898.88527569 3219.14961124 3015.22546686   28.06911687]
total_rewards_mean           1822.2430657718917
total_rewards_std            1367.940075390081
total_rewards_max            3386.205149313493
total_rewards_min            28.06911686763499
Number of train steps total  360000
Number of env steps total    1802000
Number of rollouts total     0
Train Time (s)               26.953898450825363
(Previous) Eval Time (s)     18.963293965905905
Sample Time (s)              17.924877545796335
Epoch Time (s)               63.8420699625276
Total Train Time (s)         24849.9554443229
Epoch                        359
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:09:42.303945 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #359 | Epoch Duration: 60.473053216934204
2020-01-11 10:09:42.304232 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #359 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0637071
Z variance train             0.006522103
KL Divergence                24.901663
KL Loss                      2.4901664
QF Loss                      3551.6826
VF Loss                      2799.9177
Policy Loss                  -1175.2859
Q Predictions Mean           1173.7268
Q Predictions Std            225.82033
Q Predictions Max            1378.0248
Q Predictions Min            69.4518
V Predictions Mean           1167.8003
V Predictions Std            206.5182
V Predictions Max            1356.5171
V Predictions Min            50.905552
Log Pis Mean                 -0.19054055
Log Pis Std                  2.760766
Log Pis Max                  12.2237835
Log Pis Min                  -9.081968
Policy mu Mean               0.0057059317
Policy mu Std                0.59721303
Policy mu Max                2.4101193
Policy mu Min                -2.3082714
Policy log std Mean          -0.9792311
Policy log std Std           0.26841965
Policy log std Max           -0.24240011
Policy log std Min           -3.1648507
Z mean eval                  1.0457815
Z variance eval              0.010492642
total_rewards                [3354.65903397 2370.6495908  3325.55535112 3457.76617954 3635.61123302
 3264.29982807 3258.03629123 3468.13815244 3343.41471201 3230.75982078]
total_rewards_mean           3270.889019296238
total_rewards_std            321.6159786574033
total_rewards_max            3635.611233017636
total_rewards_min            2370.6495907987046
Number of train steps total  361000
Number of env steps total    1807000
Number of rollouts total     0
Train Time (s)               28.18517016293481
(Previous) Eval Time (s)     15.593964114785194
Sample Time (s)              18.43208595085889
Epoch Time (s)               62.211220228578895
Total Train Time (s)         24922.10704424884
Epoch                        360
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:10:54.460849 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #360 | Epoch Duration: 72.15629720687866
2020-01-11 10:10:54.461188 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #360 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0449626
Z variance train             0.010493597
KL Divergence                23.585905
KL Loss                      2.3585906
QF Loss                      620.4259
VF Loss                      157.39912
Policy Loss                  -1152.9886
Q Predictions Mean           1155.4225
Q Predictions Std            241.76884
Q Predictions Max            1378.4563
Q Predictions Min            -83.25872
V Predictions Mean           1160.157
V Predictions Std            239.08698
V Predictions Max            1383.8972
V Predictions Min            -41.581394
Log Pis Mean                 -0.08151417
Log Pis Std                  2.7882752
Log Pis Max                  20.858198
Log Pis Min                  -7.485083
Policy mu Mean               -0.022362687
Policy mu Std                0.59208244
Policy mu Max                2.4046035
Policy mu Min                -2.9802341
Policy log std Mean          -0.9718932
Policy log std Std           0.26663798
Policy log std Max           0.11088157
Policy log std Min           -2.051501
Z mean eval                  1.0590037
Z variance eval              0.009858945
total_rewards                [ 483.76547782   28.54050708 3014.94314556 1057.00604383 2856.43865174
 1122.20482853  503.40159478 2907.21902356 2980.05751154 3222.45774198]
total_rewards_mean           1817.6034526397223
total_rewards_std            1216.3084383086027
total_rewards_max            3222.4577419813095
total_rewards_min            28.540507080453956
Number of train steps total  362000
Number of env steps total    1812000
Number of rollouts total     0
Train Time (s)               27.918184106238186
(Previous) Eval Time (s)     25.538680035620928
Sample Time (s)              18.270645547658205
Epoch Time (s)               71.72750968951732
Total Train Time (s)         24988.777156427503
Epoch                        361
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:12:01.136911 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #361 | Epoch Duration: 66.67551326751709
2020-01-11 10:12:01.137120 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #361 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0618149
Z variance train             0.009839431
KL Divergence                24.063753
KL Loss                      2.4063754
QF Loss                      639.477
VF Loss                      149.66188
Policy Loss                  -1155.4257
Q Predictions Mean           1160.385
Q Predictions Std            263.57193
Q Predictions Max            1364.4692
Q Predictions Min            38.441105
V Predictions Mean           1149.8937
V Predictions Std            262.18936
V Predictions Max            1354.974
V Predictions Min            11.132352
Log Pis Mean                 -0.08006829
Log Pis Std                  2.686722
Log Pis Max                  11.4818125
Log Pis Min                  -7.4674115
Policy mu Mean               0.102088846
Policy mu Std                0.5870343
Policy mu Max                3.4542403
Policy mu Min                -2.702118
Policy log std Mean          -0.9871503
Policy log std Std           0.29382813
Policy log std Max           0.13086021
Policy log std Min           -2.6009436
Z mean eval                  1.0032803
Z variance eval              0.013326155
total_rewards                [2970.8099039  3378.52287665 3448.3199317  3123.83352664 1985.13309318
 1342.19647751 1525.14600336 2277.24851573 3042.84861413 2764.23576575]
total_rewards_mean           2585.8294708539784
total_rewards_std            719.6066297804192
total_rewards_max            3448.319931699777
total_rewards_min            1342.1964775069657
Number of train steps total  363000
Number of env steps total    1817000
Number of rollouts total     0
Train Time (s)               25.342100691981614
(Previous) Eval Time (s)     20.48636183794588
Sample Time (s)              17.559597632382065
Epoch Time (s)               63.38806016230956
Total Train Time (s)         25053.743741394486
Epoch                        362
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:13:06.106613 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #362 | Epoch Duration: 64.9692394733429
2020-01-11 10:13:06.106916 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #362 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0036101
Z variance train             0.013353085
KL Divergence                22.925726
KL Loss                      2.2925727
QF Loss                      5121.66
VF Loss                      1059.9408
Policy Loss                  -1151.9246
Q Predictions Mean           1155.6599
Q Predictions Std            239.86865
Q Predictions Max            1375.0029
Q Predictions Min            33.98103
V Predictions Mean           1160.2214
V Predictions Std            242.89249
V Predictions Max            1371.4227
V Predictions Min            43.728447
Log Pis Mean                 -0.123962015
Log Pis Std                  2.872815
Log Pis Max                  15.845196
Log Pis Min                  -7.2494535
Policy mu Mean               0.005212531
Policy mu Std                0.5765674
Policy mu Max                2.123018
Policy mu Min                -2.4022439
Policy log std Mean          -1.0142832
Policy log std Std           0.29468098
Policy log std Max           -0.09346056
Policy log std Min           -3.610756
Z mean eval                  1.0231822
Z variance eval              0.012037283
total_rewards                [2067.24068104  482.50072245  645.72571112 2145.83635452   28.04430841
 3214.94047119 2371.35642679 1212.53371031  484.35507097  802.09687635]
total_rewards_mean           1345.463033316562
total_rewards_std            986.5756862296187
total_rewards_max            3214.9404711929365
total_rewards_min            28.044308414193175
Number of train steps total  364000
Number of env steps total    1822000
Number of rollouts total     0
Train Time (s)               30.0210149330087
(Previous) Eval Time (s)     22.06723247701302
Sample Time (s)              18.52584096090868
Epoch Time (s)               70.6140883709304
Total Train Time (s)         25120.67944658175
Epoch                        363
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:14:13.047302 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #363 | Epoch Duration: 66.94019556045532
2020-01-11 10:14:13.047546 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #363 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0236328
Z variance train             0.012035395
KL Divergence                23.701986
KL Loss                      2.3701987
QF Loss                      1181.0798
VF Loss                      144.47455
Policy Loss                  -1177.718
Q Predictions Mean           1175.4615
Q Predictions Std            216.33766
Q Predictions Max            1383.1791
Q Predictions Min            16.341318
V Predictions Mean           1176.737
V Predictions Std            214.51854
V Predictions Max            1378.2094
V Predictions Min            21.476507
Log Pis Mean                 0.3048653
Log Pis Std                  2.761308
Log Pis Max                  14.556942
Log Pis Min                  -7.858931
Policy mu Mean               0.0016439937
Policy mu Std                0.6615638
Policy mu Max                3.1797209
Policy mu Min                -3.0917335
Policy log std Mean          -0.9975946
Policy log std Std           0.25155777
Policy log std Max           -0.16727364
Policy log std Min           -2.0693984
Z mean eval                  1.0216628
Z variance eval              0.0111947525
total_rewards                [3165.49580875  750.96377708 3155.18534683 1344.83712387 3390.79493963
  833.71412266 3060.80915541 1349.52967517 3183.83649653 3220.72095866]
total_rewards_mean           2345.588740456924
total_rewards_std            1059.3600568145098
total_rewards_max            3390.794939625774
total_rewards_min            750.9637770760891
Number of train steps total  365000
Number of env steps total    1827000
Number of rollouts total     0
Train Time (s)               28.04392139893025
(Previous) Eval Time (s)     18.393006114289165
Sample Time (s)              17.55563693959266
Epoch Time (s)               63.992564452812076
Total Train Time (s)         25190.69720222894
Epoch                        364
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:15:23.069475 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #364 | Epoch Duration: 70.02173948287964
2020-01-11 10:15:23.069706 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #364 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0197966
Z variance train             0.011194621
KL Divergence                23.663296
KL Loss                      2.3663297
QF Loss                      673.8032
VF Loss                      1345.2748
Policy Loss                  -1159.1014
Q Predictions Mean           1161.0303
Q Predictions Std            244.6821
Q Predictions Max            1380.5332
Q Predictions Min            64.51013
V Predictions Mean           1158.3918
V Predictions Std            247.74518
V Predictions Max            1374.3674
V Predictions Min            64.30359
Log Pis Mean                 -0.046598844
Log Pis Std                  2.8418815
Log Pis Max                  12.352081
Log Pis Min                  -8.671959
Policy mu Mean               0.0029845897
Policy mu Std                0.57989305
Policy mu Max                1.978957
Policy mu Min                -2.6850097
Policy log std Mean          -1.0189064
Policy log std Std           0.29130706
Policy log std Max           -0.1544118
Policy log std Min           -2.6675167
Z mean eval                  1.062602
Z variance eval              0.013833182
total_rewards                [3062.99939656 1281.87404207 3181.74127921 3194.64051149 2512.06472946
 3164.0179612  3051.24111372 3351.54093118 3287.83376148 2426.43513141]
total_rewards_mean           2851.43888577807
total_rewards_std            600.7620857337072
total_rewards_max            3351.540931182404
total_rewards_min            1281.8740420726156
Number of train steps total  366000
Number of env steps total    1832000
Number of rollouts total     0
Train Time (s)               29.28731579799205
(Previous) Eval Time (s)     24.421881386078894
Sample Time (s)              18.962535026017576
Epoch Time (s)               72.67173221008852
Total Train Time (s)         25264.659541579895
Epoch                        365
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:16:37.034841 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #365 | Epoch Duration: 73.96495985984802
2020-01-11 10:16:37.035052 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #365 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0625287
Z variance train             0.013813421
KL Divergence                23.597359
KL Loss                      2.359736
QF Loss                      2263.7808
VF Loss                      1612.9154
Policy Loss                  -1197.0409
Q Predictions Mean           1198.7228
Q Predictions Std            182.68376
Q Predictions Max            1385.6255
Q Predictions Min            129.94493
V Predictions Mean           1189.3203
V Predictions Std            187.70807
V Predictions Max            1374.4464
V Predictions Min            116.73331
Log Pis Mean                 0.0168011
Log Pis Std                  2.6196222
Log Pis Max                  14.825928
Log Pis Min                  -7.8164864
Policy mu Mean               0.035983544
Policy mu Std                0.5812685
Policy mu Max                2.4412792
Policy mu Min                -1.9614339
Policy log std Mean          -0.9898204
Policy log std Std           0.2587075
Policy log std Max           -0.216174
Policy log std Min           -2.9412947
Z mean eval                  0.9985846
Z variance eval              0.012759608
total_rewards                [3187.41409141  692.52472889 1973.86511667 3464.95967685  231.56227415
 2753.88139024 2192.05613218 1690.26413938   22.01711206 3153.6395359 ]
total_rewards_mean           1936.2184197736303
total_rewards_std            1195.7167006444456
total_rewards_max            3464.9596768467263
total_rewards_min            22.01711206394866
Number of train steps total  367000
Number of env steps total    1837000
Number of rollouts total     0
Train Time (s)               28.117284012958407
(Previous) Eval Time (s)     25.71473567839712
Sample Time (s)              18.450358969625086
Epoch Time (s)               72.28237866098061
Total Train Time (s)         25328.819939220324
Epoch                        366
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:17:41.200546 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #366 | Epoch Duration: 64.16532588005066
2020-01-11 10:17:41.200767 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #366 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99789107
Z variance train             0.012859581
KL Divergence                23.492151
KL Loss                      2.3492153
QF Loss                      1289.2523
VF Loss                      191.56331
Policy Loss                  -1149.4481
Q Predictions Mean           1150.8457
Q Predictions Std            271.5522
Q Predictions Max            1398.8682
Q Predictions Min            -14.353775
V Predictions Mean           1146.5598
V Predictions Std            269.4657
V Predictions Max            1392.8811
V Predictions Min            -54.99979
Log Pis Mean                 -0.47027016
Log Pis Std                  2.8284056
Log Pis Max                  7.9969454
Log Pis Min                  -10.431415
Policy mu Mean               0.01105339
Policy mu Std                0.58571464
Policy mu Max                2.5301073
Policy mu Min                -2.1010184
Policy log std Mean          -0.99023193
Policy log std Std           0.27137902
Policy log std Max           -0.13735545
Policy log std Min           -2.4623098
Z mean eval                  1.0078168
Z variance eval              0.015146121
total_rewards                [3296.2969192    19.29102013 3227.4495938   652.21816703 3360.732837
 3546.54674942 2508.73299382 3267.93360824 1525.66228998 3428.92854361]
total_rewards_mean           2483.37927222308
total_rewards_std            1223.39223365784
total_rewards_max            3546.5467494191153
total_rewards_min            19.29102013498741
Number of train steps total  368000
Number of env steps total    1842000
Number of rollouts total     0
Train Time (s)               27.667590137105435
(Previous) Eval Time (s)     17.597398161888123
Sample Time (s)              18.1715099317953
Epoch Time (s)               63.43649823078886
Total Train Time (s)         25394.132659547962
Epoch                        367
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:18:46.520431 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #367 | Epoch Duration: 65.31945562362671
2020-01-11 10:18:46.520746 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #367 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0077013
Z variance train             0.015090826
KL Divergence                23.755703
KL Loss                      2.3755703
QF Loss                      732.1476
VF Loss                      277.006
Policy Loss                  -1154.2109
Q Predictions Mean           1152.5327
Q Predictions Std            269.187
Q Predictions Max            1388.4186
Q Predictions Min            31.744371
V Predictions Mean           1155.7515
V Predictions Std            265.15744
V Predictions Max            1407.7207
V Predictions Min            34.148216
Log Pis Mean                 0.08371865
Log Pis Std                  2.690371
Log Pis Max                  11.144128
Log Pis Min                  -5.3005867
Policy mu Mean               -0.018881764
Policy mu Std                0.61857593
Policy mu Max                2.4571939
Policy mu Min                -2.0929189
Policy log std Mean          -1.0032415
Policy log std Std           0.28839284
Policy log std Max           -0.1362716
Policy log std Min           -2.5621696
Z mean eval                  1.0208021
Z variance eval              0.014149666
total_rewards                [2692.08768162 1619.7138192  1168.58306974 3552.30755099 3556.4251081
 3552.24930352  361.08190489 3247.56918005 3203.05489008  762.77214327]
total_rewards_mean           2371.5844651464104
total_rewards_std            1199.8440678978766
total_rewards_max            3556.425108102014
total_rewards_min            361.0819048878168
Number of train steps total  369000
Number of env steps total    1847000
Number of rollouts total     0
Train Time (s)               31.143161787185818
(Previous) Eval Time (s)     19.480037606321275
Sample Time (s)              17.856969045940787
Epoch Time (s)               68.48016843944788
Total Train Time (s)         25466.222683897242
Epoch                        368
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:19:58.616393 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #368 | Epoch Duration: 72.09537291526794
2020-01-11 10:19:58.616747 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #368 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0196617
Z variance train             0.014085782
KL Divergence                24.278812
KL Loss                      2.4278812
QF Loss                      976.25867
VF Loss                      127.73022
Policy Loss                  -1178.5627
Q Predictions Mean           1178.856
Q Predictions Std            236.86852
Q Predictions Max            1414.6337
Q Predictions Min            43.213158
V Predictions Mean           1180.533
V Predictions Std            237.63005
V Predictions Max            1416.5416
V Predictions Min            40.998608
Log Pis Mean                 -0.013660543
Log Pis Std                  2.8212543
Log Pis Max                  12.377348
Log Pis Min                  -7.3643312
Policy mu Mean               0.02259176
Policy mu Std                0.5926204
Policy mu Max                2.0171452
Policy mu Min                -2.332323
Policy log std Mean          -0.99907005
Policy log std Std           0.25760266
Policy log std Max           -0.07908833
Policy log std Min           -2.1455817
Z mean eval                  1.0217491
Z variance eval              0.0122233415
total_rewards                [3137.42104847  618.9005031  3487.36180326 1075.978664   3071.05353825
 2759.85693356 3362.96486727 2490.37300688 1986.61223935 2424.98424431]
total_rewards_mean           2441.5506848444847
total_rewards_std            912.1963028194808
total_rewards_max            3487.3618032583163
total_rewards_min            618.9005030981023
Number of train steps total  370000
Number of env steps total    1852000
Number of rollouts total     0
Train Time (s)               27.393707429990172
(Previous) Eval Time (s)     23.09492112090811
Sample Time (s)              17.798045669682324
Epoch Time (s)               68.28667422058061
Total Train Time (s)         25531.495930894744
Epoch                        369
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:21:03.894873 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #369 | Epoch Duration: 65.27786755561829
2020-01-11 10:21:03.895116 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #369 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0224347
Z variance train             0.012248352
KL Divergence                23.624554
KL Loss                      2.3624554
QF Loss                      1856.1693
VF Loss                      277.39386
Policy Loss                  -1156.9843
Q Predictions Mean           1155.8037
Q Predictions Std            279.1057
Q Predictions Max            1414.6279
Q Predictions Min            11.815375
V Predictions Mean           1157.7917
V Predictions Std            274.46658
V Predictions Max            1411.4762
V Predictions Min            69.72299
Log Pis Mean                 -0.38878012
Log Pis Std                  2.7502365
Log Pis Max                  14.469484
Log Pis Min                  -7.44635
Policy mu Mean               0.007865584
Policy mu Std                0.5942808
Policy mu Max                2.7786279
Policy mu Min                -2.2512217
Policy log std Mean          -0.9753272
Policy log std Std           0.27462184
Policy log std Max           -0.17324638
Policy log std Min           -2.0314221
Z mean eval                  1.002944
Z variance eval              0.015217835
total_rewards                [1784.75672215   70.23625263 3432.92326207  805.47152419 3619.33815055
 3193.19563086 1189.47063135 3383.30624241 1172.79595054  392.3830829 ]
total_rewards_mean           1904.387744964819
total_rewards_std            1305.5356249192414
total_rewards_max            3619.3381505516645
total_rewards_min            70.23625262810815
Number of train steps total  371000
Number of env steps total    1857000
Number of rollouts total     0
Train Time (s)               27.379461736883968
(Previous) Eval Time (s)     20.085813351906836
Sample Time (s)              17.55261391075328
Epoch Time (s)               65.01788899954408
Total Train Time (s)         25591.94446252659
Epoch                        370
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:22:04.351079 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #370 | Epoch Duration: 60.45574426651001
2020-01-11 10:22:04.351375 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #370 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0016794
Z variance train             0.01523073
KL Divergence                23.049194
KL Loss                      2.3049195
QF Loss                      669.91516
VF Loss                      114.663315
Policy Loss                  -1161.0602
Q Predictions Mean           1162.0059
Q Predictions Std            265.20084
Q Predictions Max            1429.4048
Q Predictions Min            -7.951243
V Predictions Mean           1165.1333
V Predictions Std            267.90622
V Predictions Max            1431.6854
V Predictions Min            -23.064991
Log Pis Mean                 -0.35160238
Log Pis Std                  2.4914253
Log Pis Max                  7.678337
Log Pis Min                  -9.571658
Policy mu Mean               0.02492949
Policy mu Std                0.58350694
Policy mu Max                2.093635
Policy mu Min                -2.0693378
Policy log std Mean          -0.97636735
Policy log std Std           0.25859582
Policy log std Max           -0.10462266
Policy log std Min           -2.1855147
Z mean eval                  1.011009
Z variance eval              0.01308158
total_rewards                [ 778.62996084 3237.66360814 3127.27922914 3418.80619877 3415.90575717
 3295.86336886 1297.46167359 3435.09189073 3509.16289845 3328.5688521 ]
total_rewards_mean           2884.443343779742
total_rewards_std            936.1993833437823
total_rewards_max            3509.162898452535
total_rewards_min            778.6299608364366
Number of train steps total  372000
Number of env steps total    1862000
Number of rollouts total     0
Train Time (s)               26.800557070877403
(Previous) Eval Time (s)     15.523325381800532
Sample Time (s)              19.05318430857733
Epoch Time (s)               61.377066761255264
Total Train Time (s)         25660.426981495228
Epoch                        371
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:23:12.835724 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #371 | Epoch Duration: 68.484126329422
2020-01-11 10:23:12.835981 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #371 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0108707
Z variance train             0.013088484
KL Divergence                23.51001
KL Loss                      2.351001
QF Loss                      1405.0403
VF Loss                      146.55876
Policy Loss                  -1168.8564
Q Predictions Mean           1168.39
Q Predictions Std            270.31683
Q Predictions Max            1370.2363
Q Predictions Min            22.094458
V Predictions Mean           1166.0286
V Predictions Std            270.60843
V Predictions Max            1375.757
V Predictions Min            25.760954
Log Pis Mean                 -0.061355792
Log Pis Std                  3.1471374
Log Pis Max                  14.51868
Log Pis Min                  -7.690611
Policy mu Mean               0.027299624
Policy mu Std                0.60326743
Policy mu Max                2.8626223
Policy mu Min                -4.110896
Policy log std Mean          -1.0000567
Policy log std Std           0.2891319
Policy log std Max           -0.007569909
Policy log std Min           -2.343452
Z mean eval                  1.04422
Z variance eval              0.01766969
total_rewards                [3229.09104339 2243.3856982  3427.8286269   636.1804456  1991.2885348
 3351.2148975    30.95799865 3202.08692486 3563.95576472 2621.66626124]
total_rewards_mean           2429.7656195852933
total_rewards_std            1166.2777721968298
total_rewards_max            3563.955764716834
total_rewards_min            30.95799865436243
Number of train steps total  373000
Number of env steps total    1867000
Number of rollouts total     0
Train Time (s)               29.28902501333505
(Previous) Eval Time (s)     22.630080560222268
Sample Time (s)              18.252115786541253
Epoch Time (s)               70.17122136009857
Total Train Time (s)         25730.712596795987
Epoch                        372
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:24:23.124997 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #372 | Epoch Duration: 70.28877449035645
2020-01-11 10:24:23.125251 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #372 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.045638
Z variance train             0.017741209
KL Divergence                23.646852
KL Loss                      2.3646853
QF Loss                      802.5237
VF Loss                      116.602646
Policy Loss                  -1195.5557
Q Predictions Mean           1195.4558
Q Predictions Std            261.41025
Q Predictions Max            1465.7681
Q Predictions Min            8.498764
V Predictions Mean           1201.5568
V Predictions Std            262.32278
V Predictions Max            1472.5807
V Predictions Min            12.799059
Log Pis Mean                 -0.20470989
Log Pis Std                  2.7787702
Log Pis Max                  7.8815823
Log Pis Min                  -9.263371
Policy mu Mean               0.018775161
Policy mu Std                0.62571096
Policy mu Max                2.6958952
Policy mu Min                -2.5717256
Policy log std Mean          -0.9620676
Policy log std Std           0.2637561
Policy log std Max           -0.074310064
Policy log std Min           -2.005996
Z mean eval                  1.0203168
Z variance eval              0.016080774
total_rewards                [2804.33441223 1466.60989697 1925.449097   3157.55742734 3155.28621261
 3211.78533307 3012.37807475 3096.61510784 3151.33122157 2238.95050224]
total_rewards_mean           2722.029728562668
total_rewards_std            589.6551115598594
total_rewards_max            3211.785333070973
total_rewards_min            1466.6098969738973
Number of train steps total  374000
Number of env steps total    1872000
Number of rollouts total     0
Train Time (s)               29.482706129085273
(Previous) Eval Time (s)     22.747342112008482
Sample Time (s)              17.590391299221665
Epoch Time (s)               69.82043954031542
Total Train Time (s)         25802.332088989206
Epoch                        373
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:25:34.749909 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #373 | Epoch Duration: 71.6244912147522
2020-01-11 10:25:34.750182 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #373 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0225546
Z variance train             0.016065344
KL Divergence                23.632172
KL Loss                      2.363217
QF Loss                      968.2206
VF Loss                      198.81842
Policy Loss                  -1147.9031
Q Predictions Mean           1144.5768
Q Predictions Std            302.63495
Q Predictions Max            1396.3557
Q Predictions Min            -60.480442
V Predictions Mean           1141.54
V Predictions Std            297.48282
V Predictions Max            1397.1034
V Predictions Min            2.7326775
Log Pis Mean                 -0.60770744
Log Pis Std                  2.7190197
Log Pis Max                  8.807031
Log Pis Min                  -8.721594
Policy mu Mean               0.00819079
Policy mu Std                0.5416429
Policy mu Max                2.348038
Policy mu Min                -2.0560477
Policy log std Mean          -0.9921553
Policy log std Std           0.30887777
Policy log std Max           -0.2241832
Policy log std Min           -3.0978794
Z mean eval                  1.0160518
Z variance eval              0.020595126
total_rewards                [2949.6609004   559.53385346  775.44981026 1601.08560548 2544.98811743
  506.22934748  101.95819461 3307.14710766 2554.42854284  142.47578029]
total_rewards_mean           1504.2957259899244
total_rewards_std            1173.6938883804592
total_rewards_max            3307.1471076625003
total_rewards_min            101.95819460599688
Number of train steps total  375000
Number of env steps total    1877000
Number of rollouts total     0
Train Time (s)               30.94963203696534
(Previous) Eval Time (s)     24.551102834753692
Sample Time (s)              17.770217281766236
Epoch Time (s)               73.27095215348527
Total Train Time (s)         25863.7463203785
Epoch                        374
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:26:36.170460 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #374 | Epoch Duration: 61.42004656791687
2020-01-11 10:26:36.170750 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #374 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0165979
Z variance train             0.020605592
KL Divergence                22.657368
KL Loss                      2.2657368
QF Loss                      1013.3858
VF Loss                      134.36499
Policy Loss                  -1188.3947
Q Predictions Mean           1185.9052
Q Predictions Std            236.74762
Q Predictions Max            1365.7303
Q Predictions Min            20.313332
V Predictions Mean           1183.5774
V Predictions Std            232.7039
V Predictions Max            1362.0132
V Predictions Min            1.0790703
Log Pis Mean                 0.090322316
Log Pis Std                  2.7926939
Log Pis Max                  9.689169
Log Pis Min                  -8.924161
Policy mu Mean               -0.0034580105
Policy mu Std                0.61340827
Policy mu Max                2.5084398
Policy mu Min                -2.5517778
Policy log std Mean          -0.98142016
Policy log std Std           0.25919577
Policy log std Max           -0.20571029
Policy log std Min           -2.2731497
Z mean eval                  1.0221052
Z variance eval              0.015920747
total_rewards                [3334.30875572 2499.39824159 3478.61631746 3486.55756024  837.90831697
 3309.11412606 1354.52450805 2589.73035842 3301.1917083   637.75918007]
total_rewards_mean           2482.910907287792
total_rewards_std            1071.044625778834
total_rewards_max            3486.5575602367953
total_rewards_min            637.7591800657244
Number of train steps total  376000
Number of env steps total    1882000
Number of rollouts total     0
Train Time (s)               28.544296248350292
(Previous) Eval Time (s)     12.699880904052407
Sample Time (s)              17.79243152309209
Epoch Time (s)               59.03660867549479
Total Train Time (s)         25930.994730154052
Epoch                        375
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:27:43.424093 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #375 | Epoch Duration: 67.25309944152832
2020-01-11 10:27:43.424340 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #375 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0230918
Z variance train             0.015908897
KL Divergence                22.349503
KL Loss                      2.2349503
QF Loss                      768.90894
VF Loss                      283.6929
Policy Loss                  -1197.8757
Q Predictions Mean           1197.8643
Q Predictions Std            245.26874
Q Predictions Max            1419.1854
Q Predictions Min            24.647226
V Predictions Mean           1193.3506
V Predictions Std            244.28537
V Predictions Max            1407.6006
V Predictions Min            10.357453
Log Pis Mean                 -0.20856783
Log Pis Std                  2.8414772
Log Pis Max                  11.155365
Log Pis Min                  -8.903247
Policy mu Mean               -0.07298273
Policy mu Std                0.5649299
Policy mu Max                2.992684
Policy mu Min                -3.8154356
Policy log std Mean          -1.0361423
Policy log std Std           0.2745973
Policy log std Max           -0.010664821
Policy log std Min           -2.2525203
Z mean eval                  1.0573933
Z variance eval              0.020054761
total_rewards                [2189.69119019 3303.39228182 2154.22282923 3228.18956486 2121.16730235
 3221.30681306 3143.38482232 3251.67854628 3185.29913024    3.88553379]
total_rewards_mean           2580.221801414772
total_rewards_std            983.3708334162748
total_rewards_max            3303.392281816563
total_rewards_min            3.885533794404168
Number of train steps total  377000
Number of env steps total    1887000
Number of rollouts total     0
Train Time (s)               29.002927834633738
(Previous) Eval Time (s)     20.916093311738223
Sample Time (s)              17.569444163236767
Epoch Time (s)               67.48846530960873
Total Train Time (s)         26003.24495009845
Epoch                        376
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:28:55.675837 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #376 | Epoch Duration: 72.25131058692932
2020-01-11 10:28:55.676033 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #376 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.05808
Z variance train             0.020042863
KL Divergence                22.016598
KL Loss                      2.20166
QF Loss                      1137.9629
VF Loss                      628.5109
Policy Loss                  -1184.3527
Q Predictions Mean           1184.2063
Q Predictions Std            255.86426
Q Predictions Max            1403.1555
Q Predictions Min            24.234632
V Predictions Mean           1193.5178
V Predictions Std            252.27242
V Predictions Max            1404.463
V Predictions Min            29.419266
Log Pis Mean                 -0.2426928
Log Pis Std                  3.0077958
Log Pis Max                  13.384534
Log Pis Min                  -9.066222
Policy mu Mean               -0.027830966
Policy mu Std                0.59705657
Policy mu Max                2.316385
Policy mu Min                -2.6999116
Policy log std Mean          -1.01073
Policy log std Std           0.28353742
Policy log std Max           -0.2595017
Policy log std Min           -3.1027837
Z mean eval                  1.0305147
Z variance eval              0.014270465
total_rewards                [3178.6100353  1331.64513561 3473.53114932 3562.72436889 1895.60418989
 3181.70437501 3516.98598363  944.78279167  167.27716728 3370.30163752]
total_rewards_mean           2462.316683412414
total_rewards_std            1198.7705072008278
total_rewards_max            3562.72436889388
total_rewards_min            167.27716727596848
Number of train steps total  378000
Number of env steps total    1892000
Number of rollouts total     0
Train Time (s)               31.60717121185735
(Previous) Eval Time (s)     25.678648785687983
Sample Time (s)              17.302924726624042
Epoch Time (s)               74.58874472416937
Total Train Time (s)         26073.90886657918
Epoch                        377
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:30:06.342381 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #377 | Epoch Duration: 70.66620659828186
2020-01-11 10:30:06.342575 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #377 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0303425
Z variance train             0.014245967
KL Divergence                21.792673
KL Loss                      2.1792674
QF Loss                      1440.5986
VF Loss                      221.65627
Policy Loss                  -1199.2542
Q Predictions Mean           1197.7542
Q Predictions Std            232.76978
Q Predictions Max            1430.9026
Q Predictions Min            -7.855971
V Predictions Mean           1201.8525
V Predictions Std            235.31784
V Predictions Max            1429.6461
V Predictions Min            -7.0425615
Log Pis Mean                 0.057953052
Log Pis Std                  2.5905108
Log Pis Max                  11.54875
Log Pis Min                  -7.010535
Policy mu Mean               0.047207944
Policy mu Std                0.5725133
Policy mu Max                2.313557
Policy mu Min                -2.1201758
Policy log std Mean          -1.0217855
Policy log std Std           0.2839266
Policy log std Max           0.45994788
Policy log std Min           -3.1033654
Z mean eval                  1.0144086
Z variance eval              0.010158809
total_rewards                [2879.13589264 1959.83436898 3353.17947351 3207.85491942 3266.93956304
  147.5548402  3049.48975421 3471.39215907 3062.58445237 3163.06735427]
total_rewards_mean           2756.1032777701757
total_rewards_std            955.6413379712618
total_rewards_max            3471.3921590702453
total_rewards_min            147.55484019910227
Number of train steps total  379000
Number of env steps total    1897000
Number of rollouts total     0
Train Time (s)               27.415950094815344
(Previous) Eval Time (s)     21.75582858035341
Sample Time (s)              17.861740121617913
Epoch Time (s)               67.03351879678667
Total Train Time (s)         26143.318876290694
Epoch                        378
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:31:15.755088 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #378 | Epoch Duration: 69.41239213943481
2020-01-11 10:31:15.755286 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #378 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0132198
Z variance train             0.010155834
KL Divergence                22.83934
KL Loss                      2.283934
QF Loss                      912.1067
VF Loss                      362.69043
Policy Loss                  -1170.2474
Q Predictions Mean           1170.2788
Q Predictions Std            296.39066
Q Predictions Max            1421.2925
Q Predictions Min            -6.2564907
V Predictions Mean           1172.3525
V Predictions Std            293.26505
V Predictions Max            1429.1099
V Predictions Min            -5.866732
Log Pis Mean                 0.3004769
Log Pis Std                  2.904497
Log Pis Max                  12.634815
Log Pis Min                  -6.560395
Policy mu Mean               -0.03104674
Policy mu Std                0.6514288
Policy mu Max                2.615424
Policy mu Min                -4.013384
Policy log std Mean          -0.97558624
Policy log std Std           0.2949194
Policy log std Max           0.10460627
Policy log std Min           -2.8465598
Z mean eval                  0.9998208
Z variance eval              0.010428933
total_rewards                [3104.00438585 2031.25216361 1731.53828865 3344.17494127 2655.25865196
 3314.59680391 2751.12661888 3206.7965753  3287.46573286 3458.22948804]
total_rewards_mean           2888.444365032552
total_rewards_std            562.7988566054809
total_rewards_max            3458.2294880418476
total_rewards_min            1731.5382886473978
Number of train steps total  380000
Number of env steps total    1902000
Number of rollouts total     0
Train Time (s)               29.18954784795642
(Previous) Eval Time (s)     24.134368921164423
Sample Time (s)              17.31459088390693
Epoch Time (s)               70.63850765302777
Total Train Time (s)         26214.81342214765
Epoch                        379
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:32:27.253430 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #379 | Epoch Duration: 71.49798130989075
2020-01-11 10:32:27.253633 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #379 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0028666
Z variance train             0.010535859
KL Divergence                22.602468
KL Loss                      2.260247
QF Loss                      566.4612
VF Loss                      111.43121
Policy Loss                  -1237.9932
Q Predictions Mean           1241.6711
Q Predictions Std            168.34511
Q Predictions Max            1426.0077
Q Predictions Min            40.367786
V Predictions Mean           1240.1074
V Predictions Std            170.01643
V Predictions Max            1420.2969
V Predictions Min            13.80443
Log Pis Mean                 -0.08363356
Log Pis Std                  2.225029
Log Pis Max                  6.5432167
Log Pis Min                  -5.9612455
Policy mu Mean               0.05707327
Policy mu Std                0.5617658
Policy mu Max                2.2694564
Policy mu Min                -2.0145202
Policy log std Mean          -1.018088
Policy log std Std           0.23529434
Policy log std Max           -0.10002327
Policy log std Min           -1.9047709
Z mean eval                  1.0229577
Z variance eval              0.009778999
total_rewards                [ 236.33878105 1158.64666706 1533.94368574 3199.60457514 3409.08364202
  194.05723159  425.68457027  956.95784336   86.24431202 1904.62011316]
total_rewards_mean           1310.5181421407428
total_rewards_std            1149.1602929769126
total_rewards_max            3409.0836420165824
total_rewards_min            86.24431202395735
Number of train steps total  381000
Number of env steps total    1907000
Number of rollouts total     0
Train Time (s)               28.04586952412501
(Previous) Eval Time (s)     24.99357152171433
Sample Time (s)              17.539942231494933
Epoch Time (s)               70.57938327733427
Total Train Time (s)         26273.903616505675
Epoch                        380
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:33:26.349018 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #380 | Epoch Duration: 59.09521532058716
2020-01-11 10:33:26.349243 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #380 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0231442
Z variance train             0.009771677
KL Divergence                23.06784
KL Loss                      2.3067842
QF Loss                      600.39185
VF Loss                      120.9145
Policy Loss                  -1213.2959
Q Predictions Mean           1214.2478
Q Predictions Std            241.83835
Q Predictions Max            1418.596
Q Predictions Min            -3.8010879
V Predictions Mean           1215.7573
V Predictions Std            241.88281
V Predictions Max            1417.674
V Predictions Min            -21.19251
Log Pis Mean                 0.28313833
Log Pis Std                  2.5670078
Log Pis Max                  6.580591
Log Pis Min                  -8.327183
Policy mu Mean               -0.013348484
Policy mu Std                0.6261296
Policy mu Max                2.1722329
Policy mu Min                -1.9547642
Policy log std Mean          -0.9935914
Policy log std Std           0.25789675
Policy log std Max           -0.24468344
Policy log std Min           -2.341473
Z mean eval                  1.0367639
Z variance eval              0.011086758
total_rewards                [1091.79741687  167.75981945 3580.06058729 1457.06716284 2023.14787453
 3175.87709756 3508.46106165 2636.65600589 3015.13632957   61.26744543]
total_rewards_mean           2071.723080109278
total_rewards_std            1255.987883578021
total_rewards_max            3580.060587293167
total_rewards_min            61.26744543447601
Number of train steps total  382000
Number of env steps total    1912000
Number of rollouts total     0
Train Time (s)               29.520756314042956
(Previous) Eval Time (s)     13.509073142893612
Sample Time (s)              17.61034297477454
Epoch Time (s)               60.64017243171111
Total Train Time (s)         26338.12843935564
Epoch                        381
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:34:30.578703 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #381 | Epoch Duration: 64.22925782203674
2020-01-11 10:34:30.579018 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #381 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0348824
Z variance train             0.011087444
KL Divergence                21.9109
KL Loss                      2.19109
QF Loss                      1438.5999
VF Loss                      210.70047
Policy Loss                  -1191.7826
Q Predictions Mean           1192.9404
Q Predictions Std            270.54672
Q Predictions Max            1446.428
Q Predictions Min            -15.725668
V Predictions Mean           1194.9235
V Predictions Std            271.4147
V Predictions Max            1445.1146
V Predictions Min            -14.959059
Log Pis Mean                 0.052661434
Log Pis Std                  2.6993556
Log Pis Max                  13.3622875
Log Pis Min                  -9.777869
Policy mu Mean               -0.02467445
Policy mu Std                0.5990467
Policy mu Max                2.378943
Policy mu Min                -3.106833
Policy log std Mean          -1.0090189
Policy log std Std           0.2778159
Policy log std Max           -0.22376102
Policy log std Min           -2.297546
Z mean eval                  1.0524162
Z variance eval              0.011304838
total_rewards                [ 260.38921751 3380.85329995 2650.08792702 1157.56245366 3463.85272857
 3417.45183414 2357.6787455  3738.12823581 1009.93107371 3495.07098533]
total_rewards_mean           2493.1006501195006
total_rewards_std            1189.5531271666985
total_rewards_max            3738.1282358053377
total_rewards_min            260.38921751378496
Number of train steps total  383000
Number of env steps total    1917000
Number of rollouts total     0
Train Time (s)               29.991975399199873
(Previous) Eval Time (s)     17.09781954996288
Sample Time (s)              17.82621411094442
Epoch Time (s)               64.91600906010717
Total Train Time (s)         26406.6405782355
Epoch                        382
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:35:39.092298 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #382 | Epoch Duration: 68.51305890083313
2020-01-11 10:35:39.092454 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #382 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0509878
Z variance train             0.011316538
KL Divergence                21.266985
KL Loss                      2.1266985
QF Loss                      753.2881
VF Loss                      138.66962
Policy Loss                  -1214.0651
Q Predictions Mean           1212.0759
Q Predictions Std            257.0746
Q Predictions Max            1432.83
Q Predictions Min            -36.192482
V Predictions Mean           1214.5167
V Predictions Std            246.044
V Predictions Max            1446.1039
V Predictions Min            1.1523967
Log Pis Mean                 0.23141599
Log Pis Std                  2.9715106
Log Pis Max                  15.462575
Log Pis Min                  -8.314453
Policy mu Mean               0.011508183
Policy mu Std                0.60473907
Policy mu Max                2.4328065
Policy mu Min                -2.6101592
Policy log std Mean          -1.0342249
Policy log std Std           0.3079703
Policy log std Max           0.42876488
Policy log std Min           -3.3521552
Z mean eval                  1.0567974
Z variance eval              0.010010403
total_rewards                [2946.45736742 3183.3308927  3276.35835882 2736.30768654 3358.80019866
 3316.8667579  3286.77210357 3424.62304809 3464.19455694 2139.2256438 ]
total_rewards_mean           3113.293661444376
total_rewards_std            387.572476746389
total_rewards_max            3464.194556935303
total_rewards_min            2139.2256438015206
Number of train steps total  384000
Number of env steps total    1922000
Number of rollouts total     0
Train Time (s)               30.521932407747954
(Previous) Eval Time (s)     20.69458209304139
Sample Time (s)              17.888990581966937
Epoch Time (s)               69.10550508275628
Total Train Time (s)         26479.99452613108
Epoch                        383
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:36:52.448982 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #383 | Epoch Duration: 73.35637497901917
2020-01-11 10:36:52.449164 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #383 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0569109
Z variance train             0.009992817
KL Divergence                21.661882
KL Loss                      2.1661882
QF Loss                      1966.2461
VF Loss                      514.6378
Policy Loss                  -1223.3708
Q Predictions Mean           1218.8303
Q Predictions Std            241.44887
Q Predictions Max            1452.9934
Q Predictions Min            12.00476
V Predictions Mean           1214.0162
V Predictions Std            239.46152
V Predictions Max            1438.7603
V Predictions Min            -6.8282022
Log Pis Mean                 -0.034023672
Log Pis Std                  2.9607043
Log Pis Max                  14.550201
Log Pis Min                  -7.4333973
Policy mu Mean               -0.011306488
Policy mu Std                0.6296047
Policy mu Max                2.3015938
Policy mu Min                -2.1532648
Policy log std Mean          -0.9782955
Policy log std Std           0.27447984
Policy log std Max           0.023048043
Policy log std Min           -2.4225578
Z mean eval                  1.0512835
Z variance eval              0.018827341
total_rewards                [3518.84406396  220.0649005  3322.13399421 3112.71656217 3449.82083429
   58.71786244 2948.6520979  3311.66209005  919.06673461 3579.47785791]
total_rewards_mean           2444.1156998042643
total_rewards_std            1365.392515199504
total_rewards_max            3579.4778579097074
total_rewards_min            58.71786243939472
Number of train steps total  385000
Number of env steps total    1927000
Number of rollouts total     0
Train Time (s)               29.70361338974908
(Previous) Eval Time (s)     24.945083762984723
Sample Time (s)              17.848449467215687
Epoch Time (s)               72.49714661994949
Total Train Time (s)         26550.307875978295
Epoch                        384
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:38:02.765722 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #384 | Epoch Duration: 70.31641411781311
2020-01-11 10:38:02.765913 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #384 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0517212
Z variance train             0.018854612
KL Divergence                21.418507
KL Loss                      2.1418507
QF Loss                      1074.149
VF Loss                      315.19733
Policy Loss                  -1228.5913
Q Predictions Mean           1226.3215
Q Predictions Std            261.81613
Q Predictions Max            1436.6536
Q Predictions Min            46.394882
V Predictions Mean           1236.0687
V Predictions Std            258.84515
V Predictions Max            1443.835
V Predictions Min            42.31669
Log Pis Mean                 0.12344618
Log Pis Std                  2.8143826
Log Pis Max                  18.812769
Log Pis Min                  -7.696678
Policy mu Mean               -0.019603342
Policy mu Std                0.60414404
Policy mu Max                2.094396
Policy mu Min                -2.606269
Policy log std Mean          -1.0049255
Policy log std Std           0.2818865
Policy log std Max           -0.17132843
Policy log std Min           -2.9003563
Z mean eval                  1.0616057
Z variance eval              0.020881694
total_rewards                [3424.21245377 3399.74146157 1172.48012301 3650.53699688 1556.51294956
 3556.49455241 3154.65186967 3520.24138492 3306.75700742 3419.73460113]
total_rewards_mean           3016.1363400344117
total_rewards_std            840.1404204339071
total_rewards_max            3650.5369968844434
total_rewards_min            1172.4801230081437
Number of train steps total  386000
Number of env steps total    1932000
Number of rollouts total     0
Train Time (s)               28.638402921147645
(Previous) Eval Time (s)     22.76405272586271
Sample Time (s)              18.323875037953258
Epoch Time (s)               69.72633068496361
Total Train Time (s)         26624.416993611958
Epoch                        385
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:39:16.877201 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #385 | Epoch Duration: 74.11114835739136
2020-01-11 10:39:16.877396 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #385 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0578473
Z variance train             0.02084304
KL Divergence                21.61423
KL Loss                      2.161423
QF Loss                      1028.904
VF Loss                      180.3489
Policy Loss                  -1210.0295
Q Predictions Mean           1206.0979
Q Predictions Std            282.33624
Q Predictions Max            1435.4734
Q Predictions Min            22.700026
V Predictions Mean           1217.8136
V Predictions Std            273.1966
V Predictions Max            1457.7477
V Predictions Min            22.594017
Log Pis Mean                 0.05765997
Log Pis Std                  2.8762722
Log Pis Max                  8.560275
Log Pis Min                  -7.4809484
Policy mu Mean               0.030859668
Policy mu Std                0.60284865
Policy mu Max                2.7023942
Policy mu Min                -2.2272158
Policy log std Mean          -1.0311527
Policy log std Std           0.30866402
Policy log std Max           -0.18387681
Policy log std Min           -2.7871323
Z mean eval                  1.0818704
Z variance eval              0.01147574
total_rewards                [3483.36284906 3057.88660798 3194.30550672 3711.16358407 3397.98414798
 3336.18525097 3425.56099782 3229.60135951 3251.25194792 1539.11272357]
total_rewards_mean           3162.6414975594885
total_rewards_std            567.3205652128071
total_rewards_max            3711.16358407138
total_rewards_min            1539.1127235700565
Number of train steps total  387000
Number of env steps total    1937000
Number of rollouts total     0
Train Time (s)               29.388784326147288
(Previous) Eval Time (s)     27.148575555998832
Sample Time (s)              18.3025098759681
Epoch Time (s)               74.83986975811422
Total Train Time (s)         26698.053674626164
Epoch                        386
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:40:30.520017 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #386 | Epoch Duration: 73.6424446105957
2020-01-11 10:40:30.520288 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #386 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.082698
Z variance train             0.011462295
KL Divergence                22.193398
KL Loss                      2.2193398
QF Loss                      1385.1622
VF Loss                      2772.8406
Policy Loss                  -1224.3577
Q Predictions Mean           1223.7224
Q Predictions Std            257.01236
Q Predictions Max            1450.689
Q Predictions Min            5.320549
V Predictions Mean           1217.7296
V Predictions Std            254.54047
V Predictions Max            1439.9255
V Predictions Min            10.407814
Log Pis Mean                 0.5125929
Log Pis Std                  3.1171217
Log Pis Max                  19.719353
Log Pis Min                  -7.657277
Policy mu Mean               -0.007163902
Policy mu Std                0.6332844
Policy mu Max                3.8168461
Policy mu Min                -3.497353
Policy log std Mean          -1.0488383
Policy log std Std           0.319269
Policy log std Max           -0.18782163
Policy log std Min           -3.0696726
Z mean eval                  1.0227177
Z variance eval              0.012962492
total_rewards                [3407.40496558 2431.0353613  3394.34965495 3736.74222949 3509.85241622
 3619.25426201 3755.19204875 3479.15251816 2149.36988599 3185.95322406]
total_rewards_mean           3266.8306566522338
total_rewards_std            517.4448783935865
total_rewards_max            3755.1920487538337
total_rewards_min            2149.36988599373
Number of train steps total  388000
Number of env steps total    1942000
Number of rollouts total     0
Train Time (s)               28.58073744829744
(Previous) Eval Time (s)     25.950757063925266
Sample Time (s)              18.805471973028034
Epoch Time (s)               73.33696648525074
Total Train Time (s)         26772.31982140802
Epoch                        387
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:41:44.788469 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #387 | Epoch Duration: 74.2679934501648
2020-01-11 10:41:44.788719 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #387 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0225388
Z variance train             0.012972387
KL Divergence                22.287981
KL Loss                      2.2287982
QF Loss                      722.59216
VF Loss                      272.89444
Policy Loss                  -1233.9706
Q Predictions Mean           1235.0463
Q Predictions Std            226.40154
Q Predictions Max            1474.131
Q Predictions Min            -64.916145
V Predictions Mean           1227.579
V Predictions Std            222.46902
V Predictions Max            1463.6058
V Predictions Min            -5.128584
Log Pis Mean                 0.014269888
Log Pis Std                  2.2931988
Log Pis Max                  5.9445763
Log Pis Min                  -6.7508698
Policy mu Mean               0.0253812
Policy mu Std                0.5776474
Policy mu Max                2.0321772
Policy mu Min                -2.236875
Policy log std Mean          -1.0055891
Policy log std Std           0.25701782
Policy log std Max           -0.21242118
Policy log std Min           -2.3132377
Z mean eval                  1.0454532
Z variance eval              0.016665548
total_rewards                [3336.357514   3484.85784295 3322.31700647 1915.77870466  866.5200153
  891.77014873  116.05764449 3426.56161572 3369.56971846 3188.07927328]
total_rewards_mean           2391.7869484054418
total_rewards_std            1248.8322656136754
total_rewards_max            3484.8578429450154
total_rewards_min            116.05764448719813
Number of train steps total  389000
Number of env steps total    1947000
Number of rollouts total     0
Train Time (s)               26.98362998198718
(Previous) Eval Time (s)     26.881407937034965
Sample Time (s)              18.34110075002536
Epoch Time (s)               72.2061386690475
Total Train Time (s)         26837.040263689123
Epoch                        388
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:42:49.514278 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #388 | Epoch Duration: 64.72541427612305
2020-01-11 10:42:49.514456 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #388 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.046294
Z variance train             0.016630324
KL Divergence                22.014383
KL Loss                      2.2014384
QF Loss                      1395.7681
VF Loss                      305.12762
Policy Loss                  -1212.2916
Q Predictions Mean           1211.5579
Q Predictions Std            285.95224
Q Predictions Max            1451.0148
Q Predictions Min            -8.033325
V Predictions Mean           1211.0203
V Predictions Std            276.7515
V Predictions Max            1457.2222
V Predictions Min            2.678422
Log Pis Mean                 0.022926563
Log Pis Std                  2.5630553
Log Pis Max                  13.267937
Log Pis Min                  -6.99057
Policy mu Mean               0.05047497
Policy mu Std                0.5605451
Policy mu Max                2.217451
Policy mu Min                -2.5269866
Policy log std Mean          -1.0297856
Policy log std Std           0.27659088
Policy log std Max           -0.15613568
Policy log std Min           -2.3807368
Z mean eval                  1.015579
Z variance eval              0.013128025
total_rewards                [ 771.97181017 1424.88815795 1539.97230983 3568.13873873 1354.71061304
 3264.75907336 2831.36822995 2425.50264958 3487.89977831 3398.13845298]
total_rewards_mean           2406.734981389244
total_rewards_std            995.5920059837189
total_rewards_max            3568.1387387342206
total_rewards_min            771.9718101655657
Number of train steps total  390000
Number of env steps total    1952000
Number of rollouts total     0
Train Time (s)               28.949527125805616
(Previous) Eval Time (s)     19.400366230867803
Sample Time (s)              17.356937545351684
Epoch Time (s)               65.7068309020251
Total Train Time (s)         26902.349132534117
Epoch                        389
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:43:54.825673 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #389 | Epoch Duration: 65.31108331680298
2020-01-11 10:43:54.825827 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #389 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.015118
Z variance train             0.013141696
KL Divergence                22.247347
KL Loss                      2.2247348
QF Loss                      1006.3773
VF Loss                      232.89566
Policy Loss                  -1210.1515
Q Predictions Mean           1208.8124
Q Predictions Std            264.41248
Q Predictions Max            1468.0334
Q Predictions Min            -73.24062
V Predictions Mean           1212.3013
V Predictions Std            247.9929
V Predictions Max            1450.5251
V Predictions Min            22.51017
Log Pis Mean                 0.31812555
Log Pis Std                  3.018902
Log Pis Max                  16.64677
Log Pis Min                  -9.508872
Policy mu Mean               0.07506052
Policy mu Std                0.5968284
Policy mu Max                2.5928578
Policy mu Min                -2.4898293
Policy log std Mean          -1.0541928
Policy log std Std           0.30133823
Policy log std Max           -0.0017048717
Policy log std Min           -3.497045
Z mean eval                  1.0393207
Z variance eval              0.015171552
total_rewards                [3240.79504298 3335.27306549  915.91097499 1937.06103962 1497.95176308
 3216.37310687  555.14770434   45.78625726 3453.57233102 1597.33847088]
total_rewards_mean           1979.5209756540382
total_rewards_std            1200.4464679874764
total_rewards_max            3453.5723310171597
total_rewards_min            45.78625725504332
Number of train steps total  391000
Number of env steps total    1957000
Number of rollouts total     0
Train Time (s)               29.883494519628584
(Previous) Eval Time (s)     19.004317802842706
Sample Time (s)              17.992655725218356
Epoch Time (s)               66.88046804768965
Total Train Time (s)         26968.63005190855
Epoch                        390
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:45:01.110533 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #390 | Epoch Duration: 66.2845687866211
2020-01-11 10:45:01.110713 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #390 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0385231
Z variance train             0.015219035
KL Divergence                22.067163
KL Loss                      2.2067163
QF Loss                      817.26135
VF Loss                      110.36641
Policy Loss                  -1235.6171
Q Predictions Mean           1238.783
Q Predictions Std            231.53546
Q Predictions Max            1425.3033
Q Predictions Min            90.68267
V Predictions Mean           1237.3049
V Predictions Std            233.30084
V Predictions Max            1417.8411
V Predictions Min            70.6947
Log Pis Mean                 0.4431402
Log Pis Std                  2.531648
Log Pis Max                  7.9098406
Log Pis Min                  -7.470559
Policy mu Mean               0.016398298
Policy mu Std                0.60735047
Policy mu Max                2.1860125
Policy mu Min                -2.7409878
Policy log std Mean          -1.048714
Policy log std Std           0.26665688
Policy log std Max           -0.023424268
Policy log std Min           -2.0673633
Z mean eval                  1.0238584
Z variance eval              0.012122169
total_rewards                [3519.02356585 3551.88893274 3344.77337024  370.7064836  1103.03575233
 3383.88942286 3189.06400454 3673.48935643 1439.04885169  285.52797554]
total_rewards_mean           2386.044771582295
total_rewards_std            1337.0382985958768
total_rewards_max            3673.4893564299864
total_rewards_min            285.5279755397886
Number of train steps total  392000
Number of env steps total    1962000
Number of rollouts total     0
Train Time (s)               28.921060161665082
(Previous) Eval Time (s)     18.408096320927143
Sample Time (s)              18.43119227932766
Epoch Time (s)               65.76034876191989
Total Train Time (s)         27035.08206286514
Epoch                        391
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:46:07.564371 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #391 | Epoch Duration: 66.45353245735168
2020-01-11 10:46:07.564567 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #391 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0234256
Z variance train             0.012095703
KL Divergence                22.183123
KL Loss                      2.2183123
QF Loss                      3807.2202
VF Loss                      564.5994
Policy Loss                  -1198.5582
Q Predictions Mean           1199.8213
Q Predictions Std            278.46988
Q Predictions Max            1445.9375
Q Predictions Min            39.90635
V Predictions Mean           1210.2139
V Predictions Std            268.5165
V Predictions Max            1445.4298
V Predictions Min            46.796455
Log Pis Mean                 -0.0054866336
Log Pis Std                  2.7546623
Log Pis Max                  10.02842
Log Pis Min                  -6.656881
Policy mu Mean               -0.02493708
Policy mu Std                0.59379774
Policy mu Max                2.2744706
Policy mu Min                -2.3082361
Policy log std Mean          -1.0027106
Policy log std Std           0.28578058
Policy log std Max           0.21152163
Policy log std Min           -2.3413825
Z mean eval                  1.0528127
Z variance eval              0.011742557
total_rewards                [3422.11887155 2428.40494552 3299.24202352 3505.16927297 3566.25155607
 3581.26188801 2518.52191443   82.67917155 2655.74199366  488.79847873]
total_rewards_mean           2554.819011601568
total_rewards_std            1212.1683353496246
total_rewards_max            3581.261888006244
total_rewards_min            82.6791715513009
Number of train steps total  393000
Number of env steps total    1967000
Number of rollouts total     0
Train Time (s)               29.65652137529105
(Previous) Eval Time (s)     19.10098840110004
Sample Time (s)              17.753801554441452
Epoch Time (s)               66.51131133083254
Total Train Time (s)         27102.86704754457
Epoch                        392
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:47:15.357352 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #392 | Epoch Duration: 67.79259037971497
2020-01-11 10:47:15.357705 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #392 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0509272
Z variance train             0.011750316
KL Divergence                23.38034
KL Loss                      2.3380342
QF Loss                      1664.0724
VF Loss                      879.1885
Policy Loss                  -1225.4886
Q Predictions Mean           1226.0969
Q Predictions Std            255.5227
Q Predictions Max            1494.959
Q Predictions Min            -54.804348
V Predictions Mean           1237.0382
V Predictions Std            247.13701
V Predictions Max            1497.5869
V Predictions Min            6.763589
Log Pis Mean                 0.21956635
Log Pis Std                  2.782402
Log Pis Max                  19.50631
Log Pis Min                  -5.9312973
Policy mu Mean               0.028762117
Policy mu Std                0.59592897
Policy mu Max                2.337904
Policy mu Min                -3.4713247
Policy log std Mean          -1.0579816
Policy log std Std           0.26358476
Policy log std Max           -0.31518537
Policy log std Min           -2.609423
Z mean eval                  1.0654922
Z variance eval              0.008919427
total_rewards                [3418.50538577 2909.73729758   80.90076673 3427.79069246 3250.92875312
 1219.47850448 3435.47832494 3360.31216966 3629.05322804 3420.03155423]
total_rewards_mean           2815.2216676998737
total_rewards_std            1125.6478907377145
total_rewards_max            3629.0532280372463
total_rewards_min            80.90076673090532
Number of train steps total  394000
Number of env steps total    1972000
Number of rollouts total     0
Train Time (s)               28.77635719301179
(Previous) Eval Time (s)     20.381918503902853
Sample Time (s)              18.178436217829585
Epoch Time (s)               67.33671191474423
Total Train Time (s)         27175.026320975274
Epoch                        393
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:48:27.523261 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #393 | Epoch Duration: 72.16523051261902
2020-01-11 10:48:27.523568 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #393 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0663022
Z variance train             0.008933568
KL Divergence                24.21429
KL Loss                      2.4214292
QF Loss                      1353.2733
VF Loss                      267.19855
Policy Loss                  -1236.3802
Q Predictions Mean           1237.9307
Q Predictions Std            231.02068
Q Predictions Max            1436.8904
Q Predictions Min            46.096275
V Predictions Mean           1233.5593
V Predictions Std            230.37222
V Predictions Max            1432.0747
V Predictions Min            35.222244
Log Pis Mean                 0.21612601
Log Pis Std                  3.2130096
Log Pis Max                  18.277414
Log Pis Min                  -8.622486
Policy mu Mean               -0.09217122
Policy mu Std                0.6152752
Policy mu Max                3.0737114
Policy mu Min                -3.7096035
Policy log std Mean          -1.0300287
Policy log std Std           0.2786347
Policy log std Max           -0.19305766
Policy log std Min           -2.5406487
Z mean eval                  1.0247693
Z variance eval              0.010469964
total_rewards                [3344.2626181  3529.87881964 3384.10925769 3562.18315086 3070.68171955
 3208.01923476 3684.82669305 3221.74919304 3446.74056648 3276.96413604]
total_rewards_mean           3372.9415389196
total_rewards_std            177.40876364432881
total_rewards_max            3684.8266930498025
total_rewards_min            3070.6817195459716
Number of train steps total  395000
Number of env steps total    1977000
Number of rollouts total     0
Train Time (s)               28.65399013599381
(Previous) Eval Time (s)     25.210089810192585
Sample Time (s)              18.148823202122003
Epoch Time (s)               72.0129031483084
Total Train Time (s)         27248.675501455087
Epoch                        394
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:49:41.172287 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #394 | Epoch Duration: 73.6485505104065
2020-01-11 10:49:41.172494 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #394 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.024792
Z variance train             0.010447821
KL Divergence                24.178127
KL Loss                      2.4178128
QF Loss                      907.26733
VF Loss                      726.6972
Policy Loss                  -1235.6896
Q Predictions Mean           1236.9268
Q Predictions Std            238.1016
Q Predictions Max            1441.9896
Q Predictions Min            -72.00098
V Predictions Mean           1243.6311
V Predictions Std            229.20807
V Predictions Max            1444.9115
V Predictions Min            -49.147823
Log Pis Mean                 0.055819996
Log Pis Std                  3.0725229
Log Pis Max                  16.45005
Log Pis Min                  -8.03491
Policy mu Mean               0.0013206373
Policy mu Std                0.56844586
Policy mu Max                1.9779466
Policy mu Min                -2.4291985
Policy log std Mean          -1.0617554
Policy log std Std           0.30286857
Policy log std Max           -0.11479008
Policy log std Min           -3.1350117
Z mean eval                  1.0291598
Z variance eval              0.011800496
total_rewards                [ 953.04026752 3444.41137503 3499.80366513 2825.4675083  3276.44730943
 3542.27280771 3370.93025001  208.0006365  3356.25758209  115.37901387]
total_rewards_mean           2459.201041559417
total_rewards_std            1359.943604857778
total_rewards_max            3542.2728077060624
total_rewards_min            115.37901387036837
Number of train steps total  396000
Number of env steps total    1982000
Number of rollouts total     0
Train Time (s)               31.011681609321386
(Previous) Eval Time (s)     26.845414764247835
Sample Time (s)              18.156284825410694
Epoch Time (s)               76.01338119897991
Total Train Time (s)         27316.98590753833
Epoch                        395
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:50:49.488195 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #395 | Epoch Duration: 68.31554913520813
2020-01-11 10:50:49.488438 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #395 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0277545
Z variance train             0.011823526
KL Divergence                23.720608
KL Loss                      2.3720608
QF Loss                      1169.8658
VF Loss                      232.01788
Policy Loss                  -1243.625
Q Predictions Mean           1242.6257
Q Predictions Std            231.56128
Q Predictions Max            1466.9832
Q Predictions Min            -28.033007
V Predictions Mean           1246.0483
V Predictions Std            227.60295
V Predictions Max            1456.517
V Predictions Min            -30.484308
Log Pis Mean                 -0.1299129
Log Pis Std                  2.7845945
Log Pis Max                  8.494994
Log Pis Min                  -12.564507
Policy mu Mean               0.06132878
Policy mu Std                0.6189654
Policy mu Max                2.5571077
Policy mu Min                -2.745516
Policy log std Mean          -1.0108404
Policy log std Std           0.2537963
Policy log std Max           -0.20694822
Policy log std Min           -2.478437
Z mean eval                  1.0345285
Z variance eval              0.008241205
total_rewards                [1408.34963404 3390.64486731 3256.08387292 1949.16384243 3502.88630046
  554.0299666  2769.57837725 3583.02229039 3497.82406592 2742.61196353]
total_rewards_mean           2665.419518083493
total_rewards_std            983.8241430159544
total_rewards_max            3583.02229039075
total_rewards_min            554.0299665980289
Number of train steps total  397000
Number of env steps total    1987000
Number of rollouts total     0
Train Time (s)               29.559227658901364
(Previous) Eval Time (s)     19.1472585410811
Sample Time (s)              18.609555622097105
Epoch Time (s)               67.31604182207957
Total Train Time (s)         27386.20635916572
Epoch                        396
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:51:58.712692 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #396 | Epoch Duration: 69.2240629196167
2020-01-11 10:51:58.712906 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #396 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0362618
Z variance train             0.008212467
KL Divergence                24.526754
KL Loss                      2.4526756
QF Loss                      1054.8037
VF Loss                      208.22154
Policy Loss                  -1265.8489
Q Predictions Mean           1265.6692
Q Predictions Std            194.42413
Q Predictions Max            1449.6799
Q Predictions Min            27.110807
V Predictions Mean           1258.7396
V Predictions Std            191.66484
V Predictions Max            1453.2587
V Predictions Min            41.69674
Log Pis Mean                 0.4371667
Log Pis Std                  2.7617729
Log Pis Max                  12.03377
Log Pis Min                  -6.4059143
Policy mu Mean               -0.008728874
Policy mu Std                0.6126996
Policy mu Max                1.94693
Policy mu Min                -2.692942
Policy log std Mean          -1.0422175
Policy log std Std           0.2829179
Policy log std Max           -0.15577328
Policy log std Min           -2.9762692
Z mean eval                  1.046572
Z variance eval              0.016482329
total_rewards                [3396.89169967 3466.91399619 1821.70709735 1637.94332362 3773.58547955
 2023.14401835 3655.5014436  3565.97853126 3324.11236042 1998.1736328 ]
total_rewards_mean           2866.3951582806467
total_rewards_std            827.7682377066825
total_rewards_max            3773.585479549008
total_rewards_min            1637.9433236158347
Number of train steps total  398000
Number of env steps total    1992000
Number of rollouts total     0
Train Time (s)               28.273642234969884
(Previous) Eval Time (s)     21.05492576956749
Sample Time (s)              17.738529645372182
Epoch Time (s)               67.06709764990956
Total Train Time (s)         27457.07885859534
Epoch                        397
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:53:09.590463 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #397 | Epoch Duration: 70.87731218338013
2020-01-11 10:53:09.590760 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #397 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0466254
Z variance train             0.016487952
KL Divergence                24.040466
KL Loss                      2.4040468
QF Loss                      1215.1504
VF Loss                      309.08215
Policy Loss                  -1249.1364
Q Predictions Mean           1249.3165
Q Predictions Std            223.10568
Q Predictions Max            1453.3112
Q Predictions Min            -52.36399
V Predictions Mean           1247.6559
V Predictions Std            223.19844
V Predictions Max            1466.9657
V Predictions Min            -43.55745
Log Pis Mean                 0.31805015
Log Pis Std                  2.6940093
Log Pis Max                  10.766855
Log Pis Min                  -7.4615774
Policy mu Mean               0.0064634006
Policy mu Std                0.6258503
Policy mu Max                2.9079504
Policy mu Min                -2.4418294
Policy log std Mean          -1.0130165
Policy log std Std           0.2804107
Policy log std Max           -0.16843992
Policy log std Min           -2.484094
Z mean eval                  1.0816616
Z variance eval              0.014829735
total_rewards                [3502.26865326 3468.55263342 1973.10654229 2576.32607907 3657.45226296
 2106.62142138 3038.63864241 3426.31723709 3394.39040723 3596.26308291]
total_rewards_mean           3073.9936962009815
total_rewards_std            597.9762550303795
total_rewards_max            3657.4522629585263
total_rewards_min            1973.1065422924921
Number of train steps total  399000
Number of env steps total    1997000
Number of rollouts total     0
Train Time (s)               29.082295547705144
(Previous) Eval Time (s)     24.86483641061932
Sample Time (s)              18.4708295292221
Epoch Time (s)               72.41796148754656
Total Train Time (s)         27528.853926868178
Epoch                        398
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:54:21.370982 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #398 | Epoch Duration: 71.78001856803894
2020-01-11 10:54:21.371167 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #398 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.081453
Z variance train             0.014833188
KL Divergence                24.768337
KL Loss                      2.4768338
QF Loss                      1156.1611
VF Loss                      156.65033
Policy Loss                  -1254.4802
Q Predictions Mean           1254.8806
Q Predictions Std            233.79121
Q Predictions Max            1482.4004
Q Predictions Min            -43.938915
V Predictions Mean           1253.8372
V Predictions Std            230.35756
V Predictions Max            1480.602
V Predictions Min            -40.847908
Log Pis Mean                 0.24772312
Log Pis Std                  2.9983628
Log Pis Max                  16.945532
Log Pis Min                  -6.2650175
Policy mu Mean               0.0042068316
Policy mu Std                0.6225109
Policy mu Max                2.4886425
Policy mu Min                -3.1032972
Policy log std Mean          -1.0270791
Policy log std Std           0.26259565
Policy log std Max           -0.1908356
Policy log std Min           -2.522553
Z mean eval                  1.0547526
Z variance eval              0.01669091
total_rewards                [3517.71199249 3605.32867222 3478.00197043 3521.17740753 3864.13207643
 3901.03616056 3723.25007586 3726.25925595 3646.44127239 3764.90081085]
total_rewards_mean           3674.8239694702147
total_rewards_std            138.84507230488344
total_rewards_max            3901.036160555114
total_rewards_min            3478.0019704252627
Number of train steps total  400000
Number of env steps total    2002000
Number of rollouts total     0
Train Time (s)               29.10091269388795
(Previous) Eval Time (s)     24.226507554296404
Sample Time (s)              18.05635688500479
Epoch Time (s)               71.38377713318914
Total Train Time (s)         27603.49722452322
Epoch                        399
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:55:36.017615 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #399 | Epoch Duration: 74.64631199836731
2020-01-11 10:55:36.017763 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #399 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.054989
Z variance train             0.016713772
KL Divergence                24.102146
KL Loss                      2.4102147
QF Loss                      1635.2173
VF Loss                      249.47406
Policy Loss                  -1243.3888
Q Predictions Mean           1242.4647
Q Predictions Std            260.53687
Q Predictions Max            1490.0443
Q Predictions Min            -28.54375
V Predictions Mean           1235.5449
V Predictions Std            262.1988
V Predictions Max            1486.3638
V Predictions Min            -37.67232
Log Pis Mean                 0.29584068
Log Pis Std                  2.8834383
Log Pis Max                  19.557907
Log Pis Min                  -7.259055
Policy mu Mean               0.018670723
Policy mu Std                0.57728064
Policy mu Max                2.4115553
Policy mu Min                -2.6615815
Policy log std Mean          -1.042136
Policy log std Std           0.2781719
Policy log std Max           -0.2232539
Policy log std Min           -2.4585657
Z mean eval                  1.0297515
Z variance eval              0.01799798
total_rewards                [3464.70142623 3660.63257372 2662.89480216 3631.60203299 3510.93191656
 3679.92590081  466.98870218 3621.62058712  988.742397   3638.03323212]
total_rewards_mean           2932.6073570890017
total_rewards_std            1144.4509061714386
total_rewards_max            3679.925900810565
total_rewards_min            466.9887021809758
Number of train steps total  401000
Number of env steps total    2007000
Number of rollouts total     0
Train Time (s)               29.051479432731867
(Previous) Eval Time (s)     27.488725210074335
Sample Time (s)              18.93669390399009
Epoch Time (s)               75.47689854679629
Total Train Time (s)         27676.585334953386
Epoch                        400
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:56:49.109581 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #400 | Epoch Duration: 73.0916919708252
2020-01-11 10:56:49.109756 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #400 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.028415
Z variance train             0.018081412
KL Divergence                24.175777
KL Loss                      2.4175777
QF Loss                      1098.3085
VF Loss                      207.02734
Policy Loss                  -1254.4192
Q Predictions Mean           1255.6882
Q Predictions Std            208.5065
Q Predictions Max            1481.3231
Q Predictions Min            -44.84877
V Predictions Mean           1254.1958
V Predictions Std            203.53302
V Predictions Max            1468.9604
V Predictions Min            -19.496727
Log Pis Mean                 0.1330543
Log Pis Std                  2.7038026
Log Pis Max                  10.211344
Log Pis Min                  -7.3203325
Policy mu Mean               0.025125833
Policy mu Std                0.61979383
Policy mu Max                2.5480874
Policy mu Min                -2.4233334
Policy log std Mean          -1.0218045
Policy log std Std           0.25866055
Policy log std Max           -0.19174826
Policy log std Min           -2.1018896
Z mean eval                  1.0528758
Z variance eval              0.013488037
total_rewards                [3630.99507196 3475.82306013 3496.39982369 3459.14381983 3523.34672775
  660.87117657 3595.56213921  357.06397192 3437.76845788 2412.79426157]
total_rewards_mean           2804.9768510493063
total_rewards_std            1196.7923910833183
total_rewards_max            3630.9950719597723
total_rewards_min            357.06397191757344
Number of train steps total  402000
Number of env steps total    2012000
Number of rollouts total     0
Train Time (s)               27.58769515203312
(Previous) Eval Time (s)     25.103173847775906
Sample Time (s)              18.91261049453169
Epoch Time (s)               71.60347949434072
Total Train Time (s)         27743.539875992574
Epoch                        401
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:57:56.070614 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #401 | Epoch Duration: 66.96067786216736
2020-01-11 10:57:56.070904 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #401 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0533209
Z variance train             0.013436018
KL Divergence                24.386425
KL Loss                      2.4386425
QF Loss                      749.6886
VF Loss                      225.15797
Policy Loss                  -1256.2903
Q Predictions Mean           1254.446
Q Predictions Std            225.30197
Q Predictions Max            1460.9377
Q Predictions Min            18.534927
V Predictions Mean           1248.4197
V Predictions Std            221.47786
V Predictions Max            1454.2733
V Predictions Min            38.847286
Log Pis Mean                 0.045999587
Log Pis Std                  2.8739114
Log Pis Max                  9.0148325
Log Pis Min                  -11.771747
Policy mu Mean               0.013946354
Policy mu Std                0.564439
Policy mu Max                2.3920803
Policy mu Min                -3.0188615
Policy log std Mean          -1.0599768
Policy log std Std           0.25818634
Policy log std Max           -0.19843364
Policy log std Min           -2.1267958
Z mean eval                  1.0593894
Z variance eval              0.008440833
total_rewards                [1545.11898448  453.1495477  3185.82445514 3463.70896418  881.93657694
  690.81133053 3508.58835993 3276.86549028 2818.61992089   10.98187536]
total_rewards_mean           1983.5605505410542
total_rewards_std            1328.2387157650571
total_rewards_max            3508.588359926419
total_rewards_min            10.981875356219687
Number of train steps total  403000
Number of env steps total    2017000
Number of rollouts total     0
Train Time (s)               29.492519821971655
(Previous) Eval Time (s)     20.460044874809682
Sample Time (s)              18.456272875890136
Epoch Time (s)               68.40883757267147
Total Train Time (s)         27806.728930150624
Epoch                        402
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:58:59.264025 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #402 | Epoch Duration: 63.192925453186035
2020-01-11 10:58:59.264210 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #402 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0585124
Z variance train             0.008398524
KL Divergence                25.299067
KL Loss                      2.5299067
QF Loss                      1158.7092
VF Loss                      134.0683
Policy Loss                  -1228.0912
Q Predictions Mean           1225.9724
Q Predictions Std            275.5941
Q Predictions Max            1448.646
Q Predictions Min            -99.18271
V Predictions Mean           1223.4918
V Predictions Std            275.40256
V Predictions Max            1443.6198
V Predictions Min            -88.68722
Log Pis Mean                 0.16058648
Log Pis Std                  2.7141426
Log Pis Max                  9.131649
Log Pis Min                  -7.8885016
Policy mu Mean               0.01835439
Policy mu Std                0.6132275
Policy mu Max                2.145347
Policy mu Min                -2.306374
Policy log std Mean          -1.0367663
Policy log std Std           0.2622695
Policy log std Max           -0.2781378
Policy log std Min           -2.537051
Z mean eval                  1.0456655
Z variance eval              0.014814412
total_rewards                [2962.46917034 3479.43435904 3417.58355074 3304.8835964  3435.20975578
 3385.01603138  439.34011085 3505.58599924 3480.41663186 3522.24180064]
total_rewards_mean           3093.2181006271435
total_rewards_std            898.0800375878118
total_rewards_max            3522.2418006362277
total_rewards_min            439.34011084961935
Number of train steps total  404000
Number of env steps total    2022000
Number of rollouts total     0
Train Time (s)               27.152486614882946
(Previous) Eval Time (s)     15.243855691049248
Sample Time (s)              18.567901492118835
Epoch Time (s)               60.96424379805103
Total Train Time (s)         27876.63447500253
Epoch                        403
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:00:09.174212 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #403 | Epoch Duration: 69.90983057022095
2020-01-11 11:00:09.174470 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #403 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0462264
Z variance train             0.0148589555
KL Divergence                24.128464
KL Loss                      2.4128463
QF Loss                      1277.4769
VF Loss                      210.29837
Policy Loss                  -1248.2622
Q Predictions Mean           1249.7869
Q Predictions Std            269.0279
Q Predictions Max            1502.8978
Q Predictions Min            -49.32745
V Predictions Mean           1246.3411
V Predictions Std            269.0706
V Predictions Max            1504.4071
V Predictions Min            -36.96441
Log Pis Mean                 0.5595161
Log Pis Std                  2.639003
Log Pis Max                  13.0980215
Log Pis Min                  -7.447267
Policy mu Mean               0.06770039
Policy mu Std                0.6451735
Policy mu Max                2.1237013
Policy mu Min                -2.1491888
Policy log std Mean          -1.023655
Policy log std Std           0.28063613
Policy log std Max           0.13259739
Policy log std Min           -2.3076553
Z mean eval                  1.0557529
Z variance eval              0.02068292
total_rewards                [2474.32730485 3492.3501323  3642.76950582 3668.0961374  3405.35062537
 3605.39534922 3357.49972222 3463.1723326  3547.88003288  813.02756269]
total_rewards_mean           3146.9868705346175
total_rewards_std            843.7038824107187
total_rewards_max            3668.0961373965633
total_rewards_min            813.0275626863724
Number of train steps total  405000
Number of env steps total    2027000
Number of rollouts total     0
Train Time (s)               30.265500674955547
(Previous) Eval Time (s)     24.189097337890416
Sample Time (s)              17.59563397197053
Epoch Time (s)               72.05023198481649
Total Train Time (s)         27949.4270477416
Epoch                        404
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:01:21.975111 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #404 | Epoch Duration: 72.80041790008545
2020-01-11 11:01:21.975424 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #404 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0562332
Z variance train             0.020692833
KL Divergence                22.103596
KL Loss                      2.2103596
QF Loss                      972.4932
VF Loss                      295.9957
Policy Loss                  -1244.756
Q Predictions Mean           1244.9856
Q Predictions Std            203.93077
Q Predictions Max            1429.4154
Q Predictions Min            -61.15948
V Predictions Mean           1240.0784
V Predictions Std            205.38344
V Predictions Max            1428.2971
V Predictions Min            -19.853243
Log Pis Mean                 0.6721425
Log Pis Std                  2.6276984
Log Pis Max                  9.019787
Log Pis Min                  -7.1295066
Policy mu Mean               0.023425078
Policy mu Std                0.6368032
Policy mu Max                2.1663845
Policy mu Min                -2.4168286
Policy log std Mean          -1.0522134
Policy log std Std           0.28248766
Policy log std Max           -0.13139284
Policy log std Min           -2.659694
Z mean eval                  1.0247356
Z variance eval              0.020058716
total_rewards                [3379.20710029 3558.12409422 3650.26661318 3455.40731163 1377.7015725
 3541.69339433 3110.6959807  3532.5445362  1353.53809968 3736.92247932]
total_rewards_mean           3069.6101182046914
total_rewards_std            866.724873639584
total_rewards_max            3736.9224793219696
total_rewards_min            1353.5380996767071
Number of train steps total  406000
Number of env steps total    2032000
Number of rollouts total     0
Train Time (s)               29.309824408032
(Previous) Eval Time (s)     24.93895454937592
Sample Time (s)              17.853008361998945
Epoch Time (s)               72.10178731940687
Total Train Time (s)         28020.21086443495
Epoch                        405
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:02:32.764649 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #405 | Epoch Duration: 70.78897404670715
2020-01-11 11:02:32.764936 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #405 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0218151
Z variance train             0.020120662
KL Divergence                21.723694
KL Loss                      2.1723695
QF Loss                      845.57056
VF Loss                      418.32828
Policy Loss                  -1288.5062
Q Predictions Mean           1286.6401
Q Predictions Std            197.27808
Q Predictions Max            1481.0618
Q Predictions Min            123.41127
V Predictions Mean           1272.7156
V Predictions Std            194.34767
V Predictions Max            1465.9474
V Predictions Min            121.0065
Log Pis Mean                 0.45955816
Log Pis Std                  2.811684
Log Pis Max                  14.451015
Log Pis Min                  -7.373371
Policy mu Mean               -0.029751718
Policy mu Std                0.61934453
Policy mu Max                2.50002
Policy mu Min                -2.6400309
Policy log std Mean          -1.0725443
Policy log std Std           0.263068
Policy log std Max           -0.14996964
Policy log std Min           -2.3771358
Z mean eval                  1.0289682
Z variance eval              0.02575163
total_rewards                [3732.54490513  963.03662177 3587.70533967 3687.20071873 3393.35203044
 3416.00349985 3661.19020531 3607.69510167 3692.02397816 3620.04675338]
total_rewards_mean           3336.0799154107917
total_rewards_std            798.2225792116099
total_rewards_max            3732.544905125728
total_rewards_min            963.0366217656297
Number of train steps total  407000
Number of env steps total    2037000
Number of rollouts total     0
Train Time (s)               27.84059527795762
(Previous) Eval Time (s)     23.62583946203813
Sample Time (s)              18.398297767620534
Epoch Time (s)               69.86473250761628
Total Train Time (s)         28090.97124556359
Epoch                        406
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:03:43.528810 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #406 | Epoch Duration: 70.76366639137268
2020-01-11 11:03:43.528999 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #406 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0304788
Z variance train             0.02586495
KL Divergence                22.767109
KL Loss                      2.276711
QF Loss                      977.2705
VF Loss                      106.615875
Policy Loss                  -1250.3114
Q Predictions Mean           1250.4675
Q Predictions Std            255.83995
Q Predictions Max            1502.9548
Q Predictions Min            -33.15708
V Predictions Mean           1250.1603
V Predictions Std            255.17178
V Predictions Max            1492.6967
V Predictions Min            -20.338797
Log Pis Mean                 0.44683257
Log Pis Std                  2.7462738
Log Pis Max                  12.354706
Log Pis Min                  -6.2083693
Policy mu Mean               0.032008335
Policy mu Std                0.6248356
Policy mu Max                2.99713
Policy mu Min                -2.566301
Policy log std Mean          -1.0093486
Policy log std Std           0.29806706
Policy log std Max           -0.17766571
Policy log std Min           -2.9795423
Z mean eval                  1.0375646
Z variance eval              0.020107862
total_rewards                [3757.12032016 3444.35685899 2276.63623262  308.21232235 3280.02159706
 3167.37926979 3814.63114415 4078.10609393 1142.61213209 3782.98331827]
total_rewards_mean           2905.2059289399444
total_rewards_std            1201.8784553287949
total_rewards_max            4078.106093927807
total_rewards_min            308.21232235292854
Number of train steps total  408000
Number of env steps total    2042000
Number of rollouts total     0
Train Time (s)               28.9607048118487
(Previous) Eval Time (s)     24.524467123206705
Sample Time (s)              18.346290751360357
Epoch Time (s)               71.83146268641576
Total Train Time (s)         28159.40707808826
Epoch                        407
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:04:51.967624 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #407 | Epoch Duration: 68.43848156929016
2020-01-11 11:04:51.967856 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #407 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0346751
Z variance train             0.020184232
KL Divergence                23.404087
KL Loss                      2.3404088
QF Loss                      1116.686
VF Loss                      169.87257
Policy Loss                  -1258.776
Q Predictions Mean           1261.6115
Q Predictions Std            261.559
Q Predictions Max            1460.4043
Q Predictions Min            -11.979231
V Predictions Mean           1263.4939
V Predictions Std            259.57773
V Predictions Max            1463.4037
V Predictions Min            -8.638794
Log Pis Mean                 0.5068393
Log Pis Std                  2.763177
Log Pis Max                  11.157181
Log Pis Min                  -7.9018197
Policy mu Mean               0.027877647
Policy mu Std                0.61609423
Policy mu Max                2.724535
Policy mu Min                -2.738413
Policy log std Mean          -1.0455512
Policy log std Std           0.2831245
Policy log std Max           -0.14798385
Policy log std Min           -2.5138345
Z mean eval                  1.0315354
Z variance eval              0.027310371
total_rewards                [3596.12876692 3321.07530839 3618.66293618 2690.26151362 3501.35190859
 3519.91746259 3433.35118753 3517.61565265 3982.25092527 3471.30089769]
total_rewards_mean           3465.191655942639
total_rewards_std            306.1758297918866
total_rewards_max            3982.250925274782
total_rewards_min            2690.261513615177
Number of train steps total  409000
Number of env steps total    2047000
Number of rollouts total     0
Train Time (s)               30.452992506325245
(Previous) Eval Time (s)     21.131157004274428
Sample Time (s)              17.739109160844237
Epoch Time (s)               69.32325867144391
Total Train Time (s)         28234.27797506936
Epoch                        408
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:06:06.843755 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #408 | Epoch Duration: 74.87572121620178
2020-01-11 11:06:06.843974 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #408 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.031718
Z variance train             0.027416784
KL Divergence                22.222908
KL Loss                      2.2222908
QF Loss                      975.5089
VF Loss                      404.97092
Policy Loss                  -1267.3384
Q Predictions Mean           1267.8674
Q Predictions Std            242.33194
Q Predictions Max            1469.9993
Q Predictions Min            -42.93161
V Predictions Mean           1267.4402
V Predictions Std            240.19978
V Predictions Max            1465.3098
V Predictions Min            -30.020716
Log Pis Mean                 0.5220923
Log Pis Std                  2.712396
Log Pis Max                  9.549077
Log Pis Min                  -8.31182
Policy mu Mean               0.014251463
Policy mu Std                0.60748947
Policy mu Max                2.4356914
Policy mu Min                -2.396843
Policy log std Mean          -1.0575044
Policy log std Std           0.26476336
Policy log std Max           -0.18948495
Policy log std Min           -2.5759826
Z mean eval                  1.1069338
Z variance eval              0.022020495
total_rewards                [3371.91968848 3725.03302158 2088.99294085 3221.69768464 3446.85396707
 3294.58325736 3387.42083342 3572.20061783 3503.76180133 3372.83563513]
total_rewards_mean           3298.5299447695725
total_rewards_std            425.279691370872
total_rewards_max            3725.033021579816
total_rewards_min            2088.9929408543176
Number of train steps total  410000
Number of env steps total    2052000
Number of rollouts total     0
Train Time (s)               29.013433302287012
(Previous) Eval Time (s)     26.683333337306976
Sample Time (s)              17.59465883485973
Epoch Time (s)               73.29142547445372
Total Train Time (s)         28306.839406716637
Epoch                        409
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:07:19.407040 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #409 | Epoch Duration: 72.56289768218994
2020-01-11 11:07:19.407237 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #409 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1062992
Z variance train             0.021937931
KL Divergence                22.587427
KL Loss                      2.2587428
QF Loss                      772.4008
VF Loss                      118.10523
Policy Loss                  -1234.9392
Q Predictions Mean           1234.5833
Q Predictions Std            265.32233
Q Predictions Max            1492.1692
Q Predictions Min            41.749058
V Predictions Mean           1231.3901
V Predictions Std            267.29138
V Predictions Max            1479.7029
V Predictions Min            23.197771
Log Pis Mean                 0.16630892
Log Pis Std                  2.679351
Log Pis Max                  8.111682
Log Pis Min                  -7.473866
Policy mu Mean               -0.0029980545
Policy mu Std                0.6235056
Policy mu Max                2.5985548
Policy mu Min                -2.451088
Policy log std Mean          -1.000438
Policy log std Std           0.26572588
Policy log std Max           -0.028321147
Policy log std Min           -2.2212305
Z mean eval                  1.0573986
Z variance eval              0.01700563
total_rewards                [3361.15108025 3527.87718682 3023.2076831  3331.89716625 3455.35412109
  393.97555935 3348.00587362  614.83025642   65.5338724  1580.34408581]
total_rewards_mean           2270.21768851043
total_rewards_std            1364.8928329509174
total_rewards_max            3527.877186819695
total_rewards_min            65.53387239637644
Number of train steps total  411000
Number of env steps total    2057000
Number of rollouts total     0
Train Time (s)               26.203156913165003
(Previous) Eval Time (s)     25.954531471710652
Sample Time (s)              18.079477542545646
Epoch Time (s)               70.2371659274213
Total Train Time (s)         28368.925090515055
Epoch                        410
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:08:21.496887 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #410 | Epoch Duration: 62.08951187133789
2020-01-11 11:08:21.497083 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #410 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0557501
Z variance train             0.017014643
KL Divergence                22.941362
KL Loss                      2.2941363
QF Loss                      11156.942
VF Loss                      727.07074
Policy Loss                  -1243.3372
Q Predictions Mean           1248.0471
Q Predictions Std            266.0849
Q Predictions Max            1473.1975
Q Predictions Min            -23.31509
V Predictions Mean           1250.9221
V Predictions Std            265.27646
V Predictions Max            1491.4198
V Predictions Min            15.084437
Log Pis Mean                 0.26325747
Log Pis Std                  2.962155
Log Pis Max                  21.38328
Log Pis Min                  -6.960455
Policy mu Mean               0.077849016
Policy mu Std                0.6252382
Policy mu Max                5.6533947
Policy mu Min                -3.466384
Policy log std Mean          -1.0280011
Policy log std Std           0.28393084
Policy log std Max           0.4067024
Policy log std Min           -2.880978
Z mean eval                  1.0505645
Z variance eval              0.03102937
total_rewards                [-326.44977865 3926.26642034  375.92426315 3588.98652443  315.92093944
 3653.47848743 3539.18027429 3516.64306924  373.61039465 3925.55604514]
total_rewards_mean           2288.9116639453055
total_rewards_std            1733.2909828163565
total_rewards_max            3926.2664203399177
total_rewards_min            -326.44977864998225
Number of train steps total  412000
Number of env steps total    2062000
Number of rollouts total     0
Train Time (s)               26.076556679792702
(Previous) Eval Time (s)     17.80658055935055
Sample Time (s)              17.614294703118503
Epoch Time (s)               61.497431942261755
Total Train Time (s)         28432.5011514551
Epoch                        411
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:09:25.076156 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #411 | Epoch Duration: 63.57893919944763
2020-01-11 11:09:25.076350 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #411 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0484036
Z variance train             0.031093622
KL Divergence                22.149801
KL Loss                      2.2149801
QF Loss                      1125.9036
VF Loss                      142.98544
Policy Loss                  -1255.8557
Q Predictions Mean           1257.3408
Q Predictions Std            255.85849
Q Predictions Max            1497.1029
Q Predictions Min            -6.184212
V Predictions Mean           1260.5823
V Predictions Std            256.40793
V Predictions Max            1498.0302
V Predictions Min            -10.591026
Log Pis Mean                 0.09626585
Log Pis Std                  2.5877435
Log Pis Max                  7.000787
Log Pis Min                  -7.1602077
Policy mu Mean               -0.030464254
Policy mu Std                0.62011176
Policy mu Max                2.7904365
Policy mu Min                -2.1669614
Policy log std Mean          -1.0324359
Policy log std Std           0.26993677
Policy log std Max           -0.12366009
Policy log std Min           -2.0647697
Z mean eval                  1.0390964
Z variance eval              0.023878101
total_rewards                [3292.78629966 3358.69263785 1790.49216224   26.63843261 2400.34561241
  222.68882485 1142.80523616 1155.5995912  3774.39162808  226.72467536]
total_rewards_mean           1739.1165100429407
total_rewards_std            1335.464979704403
total_rewards_max            3774.3916280819644
total_rewards_min            26.63843260981199
Number of train steps total  413000
Number of env steps total    2067000
Number of rollouts total     0
Train Time (s)               28.791951623745263
(Previous) Eval Time (s)     19.887802805751562
Sample Time (s)              17.371915604919195
Epoch Time (s)               66.05167003441602
Total Train Time (s)         28496.22135794675
Epoch                        412
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:10:28.831778 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #412 | Epoch Duration: 63.7552330493927
2020-01-11 11:10:28.832124 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #412 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0381944
Z variance train             0.023932464
KL Divergence                22.31923
KL Loss                      2.2319229
QF Loss                      909.6017
VF Loss                      1082.1539
Policy Loss                  -1303.5891
Q Predictions Mean           1304.0143
Q Predictions Std            233.70923
Q Predictions Max            1504.4498
Q Predictions Min            -48.32577
V Predictions Mean           1300.3123
V Predictions Std            219.61913
V Predictions Max            1502.1007
V Predictions Min            -36.272736
Log Pis Mean                 0.6429194
Log Pis Std                  2.809693
Log Pis Max                  15.038869
Log Pis Min                  -9.554406
Policy mu Mean               -0.045701794
Policy mu Std                0.63579047
Policy mu Max                2.1622112
Policy mu Min                -2.4745052
Policy log std Mean          -1.0553443
Policy log std Std           0.33312064
Policy log std Max           -0.25650233
Policy log std Min           -3.2399564
Z mean eval                  1.0584862
Z variance eval              0.017032374
total_rewards                [3421.92156601 3267.98377109 3405.78816308 3361.23306449 3541.53441434
 3497.44266255 3470.49894649 3535.17049085 1110.3007101  1171.53677473]
total_rewards_mean           2978.341056372929
total_rewards_std            922.1183210948433
total_rewards_max            3541.534414343292
total_rewards_min            1110.300710103818
Number of train steps total  414000
Number of env steps total    2072000
Number of rollouts total     0
Train Time (s)               31.96719653485343
(Previous) Eval Time (s)     17.591049937997013
Sample Time (s)              18.36682831728831
Epoch Time (s)               67.92507479013875
Total Train Time (s)         28573.472863965668
Epoch                        413
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:11:46.057566 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #413 | Epoch Duration: 77.2252037525177
2020-01-11 11:11:46.057758 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #413 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0624945
Z variance train             0.017030649
KL Divergence                23.023418
KL Loss                      2.302342
QF Loss                      1881.2415
VF Loss                      208.19608
Policy Loss                  -1275.7854
Q Predictions Mean           1270.5605
Q Predictions Std            251.75633
Q Predictions Max            1518.5524
Q Predictions Min            -48.758076
V Predictions Mean           1277.7657
V Predictions Std            245.44572
V Predictions Max            1516.591
V Predictions Min            15.782855
Log Pis Mean                 0.80115473
Log Pis Std                  3.0042992
Log Pis Max                  18.594864
Log Pis Min                  -7.0677156
Policy mu Mean               -0.016725501
Policy mu Std                0.6444763
Policy mu Max                3.2607813
Policy mu Min                -3.44138
Policy log std Mean          -1.0707378
Policy log std Std           0.300926
Policy log std Max           -0.19389307
Policy log std Min           -2.7119255
Z mean eval                  1.0528983
Z variance eval              0.016634751
total_rewards                [1080.05386833 3466.75282729 3432.93518456 1770.74456894 2937.62421226
 3903.91138092 2394.06470198 3290.57292818 3840.32657049 3502.77075896]
total_rewards_mean           2961.9757001923854
total_rewards_std            884.2826800262086
total_rewards_max            3903.911380924118
total_rewards_min            1080.0538683304433
Number of train steps total  415000
Number of env steps total    2077000
Number of rollouts total     0
Train Time (s)               27.712494731880724
(Previous) Eval Time (s)     26.890903221908957
Sample Time (s)              18.658813728485256
Epoch Time (s)               73.26221168227494
Total Train Time (s)         28642.126417996362
Epoch                        414
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:12:54.716304 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #414 | Epoch Duration: 68.65838527679443
2020-01-11 11:12:54.716524 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #414 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0512275
Z variance train             0.016605895
KL Divergence                23.246693
KL Loss                      2.3246694
QF Loss                      1094.2517
VF Loss                      267.24054
Policy Loss                  -1276.1503
Q Predictions Mean           1273.1102
Q Predictions Std            231.78494
Q Predictions Max            1478.9692
Q Predictions Min            58.804382
V Predictions Mean           1265.2759
V Predictions Std            231.84538
V Predictions Max            1497.7284
V Predictions Min            56.113743
Log Pis Mean                 0.54269904
Log Pis Std                  2.54152
Log Pis Max                  8.884384
Log Pis Min                  -5.536247
Policy mu Mean               -0.013485349
Policy mu Std                0.673295
Policy mu Max                2.8704038
Policy mu Min                -2.7540998
Policy log std Mean          -1.007618
Policy log std Std           0.25372413
Policy log std Max           0.06383002
Policy log std Min           -2.3427694
Z mean eval                  1.0447603
Z variance eval              0.014768308
total_rewards                [3375.12548595 3670.97897526 3349.11772617 3007.46486208 3363.46124075
 3399.51043115 3496.65740286 2617.06313941 3722.74251805 3370.94689398]
total_rewards_mean           3337.3068675661516
total_rewards_std            303.330152797277
total_rewards_max            3722.742518050768
total_rewards_min            2617.0631394077777
Number of train steps total  416000
Number of env steps total    2082000
Number of rollouts total     0
Train Time (s)               28.507669985760003
(Previous) Eval Time (s)     22.286747300066054
Sample Time (s)              18.20703994948417
Epoch Time (s)               69.00145723531023
Total Train Time (s)         28714.976770827547
Epoch                        415
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:14:07.579778 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #415 | Epoch Duration: 72.86307668685913
2020-01-11 11:14:07.579982 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #415 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.044411
Z variance train             0.0147730755
KL Divergence                22.9468
KL Loss                      2.29468
QF Loss                      537.59155
VF Loss                      66.127144
Policy Loss                  -1268.1317
Q Predictions Mean           1270.8556
Q Predictions Std            226.89786
Q Predictions Max            1455.9547
Q Predictions Min            20.804956
V Predictions Mean           1269.4767
V Predictions Std            224.50865
V Predictions Max            1446.7374
V Predictions Min            17.352774
Log Pis Mean                 0.30264542
Log Pis Std                  2.9672241
Log Pis Max                  23.314163
Log Pis Min                  -7.9298005
Policy mu Mean               0.021548009
Policy mu Std                0.60868984
Policy mu Max                4.8966103
Policy mu Min                -4.79128
Policy log std Mean          -1.0518298
Policy log std Std           0.24745356
Policy log std Max           0.29217088
Policy log std Min           -2.0422401
Z mean eval                  1.0404581
Z variance eval              0.013763194
total_rewards                [3608.16254043 1864.47392851 3756.38265251 2868.60806051  258.09769744
 3717.00081263 3511.37298102 2932.10386565 3657.91194705 2396.3962489 ]
total_rewards_mean           2857.0510734650293
total_rewards_std            1055.4492867358906
total_rewards_max            3756.382652507839
total_rewards_min            258.09769743766526
Number of train steps total  417000
Number of env steps total    2087000
Number of rollouts total     0
Train Time (s)               28.425003950018436
(Previous) Eval Time (s)     26.14800935704261
Sample Time (s)              18.129377319011837
Epoch Time (s)               72.70239062607288
Total Train Time (s)         28786.060752250254
Epoch                        416
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:15:18.657847 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #416 | Epoch Duration: 71.0777153968811
2020-01-11 11:15:18.658026 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #416 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0373724
Z variance train             0.013753462
KL Divergence                23.247782
KL Loss                      2.3247783
QF Loss                      796.5761
VF Loss                      199.7285
Policy Loss                  -1271.0345
Q Predictions Mean           1269.6835
Q Predictions Std            252.73743
Q Predictions Max            1457.2744
Q Predictions Min            -31.972158
V Predictions Mean           1267.8823
V Predictions Std            251.53452
V Predictions Max            1466.1068
V Predictions Min            -54.744713
Log Pis Mean                 0.5137918
Log Pis Std                  2.734793
Log Pis Max                  11.184172
Log Pis Min                  -7.6642494
Policy mu Mean               0.052814364
Policy mu Std                0.58829135
Policy mu Max                2.4662101
Policy mu Min                -2.2540638
Policy log std Mean          -1.0647244
Policy log std Std           0.2633021
Policy log std Max           -0.052528143
Policy log std Min           -2.1938052
Z mean eval                  1.0559231
Z variance eval              0.008804823
total_rewards                [1074.33409412 1275.14760762  112.15983472  929.89536759 2429.17657006
 3320.76841168 3916.64319679 1816.92017601 3902.90231601 4043.523477  ]
total_rewards_mean           2282.1471051604303
total_rewards_std            1368.5009828697919
total_rewards_max            4043.5234770018888
total_rewards_min            112.15983472132758
Number of train steps total  418000
Number of env steps total    2092000
Number of rollouts total     0
Train Time (s)               29.19131122995168
(Previous) Eval Time (s)     24.522983917035162
Sample Time (s)              17.940703351981938
Epoch Time (s)               71.65499849896878
Total Train Time (s)         28852.607675765175
Epoch                        417
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:16:25.212366 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #417 | Epoch Duration: 66.55419063568115
2020-01-11 11:16:25.212583 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #417 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0568593
Z variance train             0.008795155
KL Divergence                23.86961
KL Loss                      2.386961
QF Loss                      1203.623
VF Loss                      320.14624
Policy Loss                  -1266.4169
Q Predictions Mean           1269.989
Q Predictions Std            281.73563
Q Predictions Max            1512.5817
Q Predictions Min            -11.678167
V Predictions Mean           1272.3435
V Predictions Std            277.37946
V Predictions Max            1502.4398
V Predictions Min            -13.374748
Log Pis Mean                 0.3801093
Log Pis Std                  3.1318054
Log Pis Max                  14.627616
Log Pis Min                  -6.936606
Policy mu Mean               0.0133601455
Policy mu Std                0.6211473
Policy mu Max                4.1455827
Policy mu Min                -2.5561512
Policy log std Mean          -1.0707664
Policy log std Std           0.30377227
Policy log std Max           0.031576037
Policy log std Min           -2.5044832
Z mean eval                  1.0422834
Z variance eval              0.010057168
total_rewards                [1242.6559875  3530.10664349 3819.41700807 3752.43484271 3451.55849716
 3705.32179858 3850.91333683  406.27679574 3668.46986035 3228.74371392]
total_rewards_mean           3065.589848435372
total_rewards_std            1149.6028139790571
total_rewards_max            3850.913336828613
total_rewards_min            406.27679574132753
Number of train steps total  419000
Number of env steps total    2097000
Number of rollouts total     0
Train Time (s)               28.101313071791083
(Previous) Eval Time (s)     19.421887035947293
Sample Time (s)              17.886772455181926
Epoch Time (s)               65.4099725629203
Total Train Time (s)         28922.53182137618
Epoch                        418
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:17:35.138445 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #418 | Epoch Duration: 69.92568755149841
2020-01-11 11:17:35.138614 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #418 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0441236
Z variance train             0.010025866
KL Divergence                23.586369
KL Loss                      2.3586369
QF Loss                      1360.8495
VF Loss                      285.28827
Policy Loss                  -1297.6124
Q Predictions Mean           1296.5853
Q Predictions Std            212.48305
Q Predictions Max            1513.3207
Q Predictions Min            -28.833803
V Predictions Mean           1292.3503
V Predictions Std            202.41078
V Predictions Max            1496.5961
V Predictions Min            -16.308146
Log Pis Mean                 0.40778
Log Pis Std                  2.8247619
Log Pis Max                  16.328205
Log Pis Min                  -8.960055
Policy mu Mean               0.0151219
Policy mu Std                0.6384834
Policy mu Max                2.161544
Policy mu Min                -2.1640015
Policy log std Mean          -1.0363479
Policy log std Std           0.275484
Policy log std Max           -0.14900929
Policy log std Min           -3.4597132
Z mean eval                  1.0790076
Z variance eval              0.006274765
total_rewards                [3610.63695045 3762.54520359 3801.15856476 3053.49147079 3962.32325179
 2278.84838173 3174.4406598   437.5328175  3962.74942231 3727.15887377]
total_rewards_mean           3177.0885596489393
total_rewards_std            1038.4558371467033
total_rewards_max            3962.7494223100134
total_rewards_min            437.53281749683254
Number of train steps total  420000
Number of env steps total    2102000
Number of rollouts total     0
Train Time (s)               28.86885364493355
(Previous) Eval Time (s)     23.937303092330694
Sample Time (s)              18.02577371848747
Epoch Time (s)               70.83193045575172
Total Train Time (s)         28991.2155023627
Epoch                        419
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:18:43.831359 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #419 | Epoch Duration: 68.6926109790802
2020-01-11 11:18:43.831528 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #419 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0787302
Z variance train             0.006281691
KL Divergence                24.576704
KL Loss                      2.4576705
QF Loss                      803.85583
VF Loss                      230.96187
Policy Loss                  -1296.8712
Q Predictions Mean           1297.3716
Q Predictions Std            218.20111
Q Predictions Max            1518.2867
Q Predictions Min            13.915966
V Predictions Mean           1305.8068
V Predictions Std            215.67607
V Predictions Max            1516.5997
V Predictions Min            23.764755
Log Pis Mean                 0.5678083
Log Pis Std                  2.742947
Log Pis Max                  10.94832
Log Pis Min                  -7.657794
Policy mu Mean               -0.0137686115
Policy mu Std                0.6798118
Policy mu Max                2.782322
Policy mu Min                -2.4016712
Policy log std Mean          -1.0137372
Policy log std Std           0.25865555
Policy log std Max           -0.17038935
Policy log std Min           -2.0059404
Z mean eval                  1.0467976
Z variance eval              0.010301196
total_rewards                [3834.94508993 3843.53752011 3608.38167913  916.02757307   13.26327558
 3873.81428705 3357.87077256   25.43573243 3565.03547286  831.18447719]
total_rewards_mean           2386.9495879903598
total_rewards_std            1613.899864201506
total_rewards_max            3873.814287054397
total_rewards_min            13.26327557646918
Number of train steps total  421000
Number of env steps total    2107000
Number of rollouts total     0
Train Time (s)               30.639387178234756
(Previous) Eval Time (s)     21.797592056915164
Sample Time (s)              18.56189763965085
Epoch Time (s)               70.99887687480077
Total Train Time (s)         29058.00180266658
Epoch                        420
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:19:50.620408 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #420 | Epoch Duration: 66.78869795799255
2020-01-11 11:19:50.620756 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #420 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0487154
Z variance train             0.0102943685
KL Divergence                24.193995
KL Loss                      2.4193995
QF Loss                      599.2288
VF Loss                      135.95668
Policy Loss                  -1279.1598
Q Predictions Mean           1282.9412
Q Predictions Std            262.77295
Q Predictions Max            1511.4211
Q Predictions Min            15.517498
V Predictions Mean           1286.7295
V Predictions Std            262.86368
V Predictions Max            1519.387
V Predictions Min            26.72686
Log Pis Mean                 0.36191684
Log Pis Std                  2.8221946
Log Pis Max                  10.4140415
Log Pis Min                  -8.05389
Policy mu Mean               0.013288796
Policy mu Std                0.6057645
Policy mu Max                2.5039732
Policy mu Min                -2.666607
Policy log std Mean          -1.0680436
Policy log std Std           0.28250247
Policy log std Max           -0.087436914
Policy log std Min           -2.3910613
Z mean eval                  1.0614427
Z variance eval              0.008412227
total_rewards                [  30.08270665 3867.70264779 3763.43952886 3761.0576575  3866.09505183
 3804.97814782 3213.18400371 3633.69489785 3799.98239657 3889.00512013]
total_rewards_mean           3362.922215871606
total_rewards_std            1126.6618382436786
total_rewards_max            3889.005120126879
total_rewards_min            30.08270665428774
Number of train steps total  422000
Number of env steps total    2112000
Number of rollouts total     0
Train Time (s)               30.08667631307617
(Previous) Eval Time (s)     17.58707834687084
Sample Time (s)              18.432790552265942
Epoch Time (s)               66.10654521221295
Total Train Time (s)         29133.595023395028
Epoch                        421
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:21:06.214391 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #421 | Epoch Duration: 75.59338784217834
2020-01-11 11:21:06.214618 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #421 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0600941
Z variance train             0.008422314
KL Divergence                24.501621
KL Loss                      2.4501622
QF Loss                      2833.1545
VF Loss                      804.3265
Policy Loss                  -1293.7634
Q Predictions Mean           1289.6296
Q Predictions Std            256.08194
Q Predictions Max            1537.0006
Q Predictions Min            -41.786915
V Predictions Mean           1296.937
V Predictions Std            239.77109
V Predictions Max            1534.87
V Predictions Min            -31.770018
Log Pis Mean                 0.811823
Log Pis Std                  3.2507987
Log Pis Max                  18.31849
Log Pis Min                  -10.9166565
Policy mu Mean               0.014005346
Policy mu Std                0.6271881
Policy mu Max                2.7125065
Policy mu Min                -3.3566895
Policy log std Mean          -1.088593
Policy log std Std           0.29104963
Policy log std Max           -0.051550746
Policy log std Min           -2.884182
Z mean eval                  1.0700431
Z variance eval              0.007232681
total_rewards                [3571.03487746 1338.16559983 3051.24501477 3927.8051982  2571.91326609
  146.98439407 3555.13946047 2754.26815264  463.0245477     6.36246428]
total_rewards_mean           2138.5942975503376
total_rewards_std            1435.9893976536025
total_rewards_max            3927.805198201396
total_rewards_min            6.362464276989963
Number of train steps total  423000
Number of env steps total    2117000
Number of rollouts total     0
Train Time (s)               29.162534767296165
(Previous) Eval Time (s)     27.073609681334347
Sample Time (s)              17.821830628439784
Epoch Time (s)               74.0579750770703
Total Train Time (s)         29196.560908357147
Epoch                        422
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:22:09.186334 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #422 | Epoch Duration: 62.971529722213745
2020-01-11 11:22:09.186563 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #422 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0701482
Z variance train             0.007219774
KL Divergence                24.26477
KL Loss                      2.4264772
QF Loss                      4516.853
VF Loss                      1357.132
Policy Loss                  -1299.6868
Q Predictions Mean           1298.2854
Q Predictions Std            272.42944
Q Predictions Max            1542.5481
Q Predictions Min            -7.584041
V Predictions Mean           1298.2698
V Predictions Std            267.226
V Predictions Max            1536.0548
V Predictions Min            11.145004
Log Pis Mean                 0.44894636
Log Pis Std                  2.8519344
Log Pis Max                  11.840395
Log Pis Min                  -6.8406
Policy mu Mean               -0.044539772
Policy mu Std                0.6190645
Policy mu Max                2.1214764
Policy mu Min                -2.673555
Policy log std Mean          -1.0557787
Policy log std Std           0.30397925
Policy log std Max           -0.031184316
Policy log std Min           -3.2343946
Z mean eval                  1.0936134
Z variance eval              0.010656958
total_rewards                [3357.64657051 3477.62652667 3510.89530768 3551.83360301 3368.50812858
 3562.46225477 3525.46852664   69.33533147 3658.76858077 3727.95973316]
total_rewards_mean           3181.0504563267073
total_rewards_std            1042.8209745048487
total_rewards_max            3727.9597331623368
total_rewards_min            69.33533147184056
Number of train steps total  424000
Number of env steps total    2122000
Number of rollouts total     0
Train Time (s)               30.381432875059545
(Previous) Eval Time (s)     15.986870479304343
Sample Time (s)              17.42694468703121
Epoch Time (s)               63.7952480413951
Total Train Time (s)         29268.38717988832
Epoch                        423
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:23:21.019076 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #423 | Epoch Duration: 71.83230543136597
2020-01-11 11:23:21.019371 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #423 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0933454
Z variance train             0.010650964
KL Divergence                24.005964
KL Loss                      2.4005964
QF Loss                      881.5773
VF Loss                      115.029045
Policy Loss                  -1323.984
Q Predictions Mean           1323.7458
Q Predictions Std            221.27855
Q Predictions Max            1535.2625
Q Predictions Min            -32.665886
V Predictions Mean           1321.1864
V Predictions Std            222.14168
V Predictions Max            1533.1941
V Predictions Min            -31.890968
Log Pis Mean                 0.7299856
Log Pis Std                  2.9224772
Log Pis Max                  11.497317
Log Pis Min                  -7.4142885
Policy mu Mean               -0.0014221959
Policy mu Std                0.6205678
Policy mu Max                2.6850812
Policy mu Min                -2.4318588
Policy log std Mean          -1.0861251
Policy log std Std           0.295327
Policy log std Max           -0.19644511
Policy log std Min           -2.8840315
Z mean eval                  1.030404
Z variance eval              0.0083595235
total_rewards                [3623.78405168 3558.25245328 3504.97085265 3309.29292883 2106.32619856
 3363.38562783  623.86353806 1464.38711123 1123.20527962 3593.24145432]
total_rewards_mean           2627.070949607271
total_rewards_std            1116.6815351594416
total_rewards_max            3623.7840516822826
total_rewards_min            623.8635380631254
Number of train steps total  425000
Number of env steps total    2127000
Number of rollouts total     0
Train Time (s)               29.278022427111864
(Previous) Eval Time (s)     24.023643969092518
Sample Time (s)              17.70877118036151
Epoch Time (s)               71.01043757656589
Total Train Time (s)         29336.68654482579
Epoch                        424
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:24:29.324649 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #424 | Epoch Duration: 68.30504179000854
2020-01-11 11:24:29.324896 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #424 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.030564
Z variance train             0.008348809
KL Divergence                24.37411
KL Loss                      2.437411
QF Loss                      948.4378
VF Loss                      1358.3618
Policy Loss                  -1299.868
Q Predictions Mean           1295.2559
Q Predictions Std            256.54825
Q Predictions Max            1502.7789
Q Predictions Min            -64.444244
V Predictions Mean           1298.7388
V Predictions Std            254.36911
V Predictions Max            1512.0537
V Predictions Min            -59.19246
Log Pis Mean                 0.529914
Log Pis Std                  2.7848387
Log Pis Max                  8.98697
Log Pis Min                  -6.1457334
Policy mu Mean               0.020760205
Policy mu Std                0.62546444
Policy mu Max                2.2023919
Policy mu Min                -2.1214745
Policy log std Mean          -1.0576774
Policy log std Std           0.26224276
Policy log std Max           -0.29039556
Policy log std Min           -2.8171067
Z mean eval                  1.0316029
Z variance eval              0.012443478
total_rewards                [3555.31603101 3785.3514776  3835.67009291 3483.02795461 1578.09111907
 3617.9380968  3684.03150358 3620.03708035 3501.24832983 3362.04646968]
total_rewards_mean           3402.275815543714
total_rewards_std            622.6475728273845
total_rewards_max            3835.670092909439
total_rewards_min            1578.091119069835
Number of train steps total  426000
Number of env steps total    2132000
Number of rollouts total     0
Train Time (s)               29.61568156303838
(Previous) Eval Time (s)     21.317927749827504
Sample Time (s)              17.928072622045875
Epoch Time (s)               68.86168193491176
Total Train Time (s)         29409.62780708447
Epoch                        425
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:25:42.268035 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #425 | Epoch Duration: 72.94296479225159
2020-01-11 11:25:42.268233 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #425 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0333822
Z variance train             0.012473051
KL Divergence                23.874897
KL Loss                      2.3874898
QF Loss                      668.4201
VF Loss                      161.95842
Policy Loss                  -1295.8524
Q Predictions Mean           1296.6072
Q Predictions Std            239.31898
Q Predictions Max            1561.5859
Q Predictions Min            -4.207455
V Predictions Mean           1293.3171
V Predictions Std            240.62675
V Predictions Max            1536.6061
V Predictions Min            -27.225903
Log Pis Mean                 0.31638682
Log Pis Std                  2.8238504
Log Pis Max                  12.689434
Log Pis Min                  -6.9007034
Policy mu Mean               0.030393291
Policy mu Std                0.61609626
Policy mu Max                2.2526112
Policy mu Min                -2.528969
Policy log std Mean          -1.0588437
Policy log std Std           0.2584722
Policy log std Max           -0.15452462
Policy log std Min           -2.1969867
Z mean eval                  1.087022
Z variance eval              0.00976536
total_rewards                [3699.8865941  3488.65516037  553.22319055  420.00302893 3613.42593361
 3636.9002827  3507.11315597 3813.70614334 3744.56655953 3481.67283331]
total_rewards_mean           2995.915288241728
total_rewards_std            1259.33165823615
total_rewards_max            3813.706143335109
total_rewards_min            420.0030289339293
Number of train steps total  427000
Number of env steps total    2137000
Number of rollouts total     0
Train Time (s)               30.713317258283496
(Previous) Eval Time (s)     25.39892021473497
Sample Time (s)              17.63853061525151
Epoch Time (s)               73.75076808826998
Total Train Time (s)         29481.664352966473
Epoch                        426
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:26:54.308589 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #426 | Epoch Duration: 72.04021334648132
2020-01-11 11:26:54.308789 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #426 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.086029
Z variance train             0.009766084
KL Divergence                24.277376
KL Loss                      2.4277377
QF Loss                      1089.5758
VF Loss                      154.65202
Policy Loss                  -1312.4042
Q Predictions Mean           1313.7422
Q Predictions Std            236.96298
Q Predictions Max            1524.4938
Q Predictions Min            -48.447662
V Predictions Mean           1316.4397
V Predictions Std            237.14862
V Predictions Max            1525.4728
V Predictions Min            -26.594673
Log Pis Mean                 0.57200825
Log Pis Std                  2.7316806
Log Pis Max                  8.702864
Log Pis Min                  -7.468652
Policy mu Mean               -0.009125156
Policy mu Std                0.62709695
Policy mu Max                2.5770774
Policy mu Min                -2.3581893
Policy log std Mean          -1.0441107
Policy log std Std           0.28707102
Policy log std Max           0.4381103
Policy log std Min           -2.4495683
Z mean eval                  1.06702
Z variance eval              0.01210654
total_rewards                [3554.34331044 1319.35800406 1608.7678071  3417.0999175  3512.83687802
 3881.75356567 4009.93310385 3674.50108969 3863.65585744 2598.42589445]
total_rewards_mean           3144.067542820957
total_rewards_std            919.5852120257148
total_rewards_max            4009.9331038472155
total_rewards_min            1319.3580040558563
Number of train steps total  428000
Number of env steps total    2142000
Number of rollouts total     0
Train Time (s)               29.990325233899057
(Previous) Eval Time (s)     23.68805923918262
Sample Time (s)              18.1999242301099
Epoch Time (s)               71.87830870319158
Total Train Time (s)         29552.585163829848
Epoch                        427
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:28:05.233128 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #427 | Epoch Duration: 70.92417001724243
2020-01-11 11:28:05.233310 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #427 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0702375
Z variance train             0.012071235
KL Divergence                24.357872
KL Loss                      2.4357872
QF Loss                      956.2626
VF Loss                      257.12744
Policy Loss                  -1310.7561
Q Predictions Mean           1312.7086
Q Predictions Std            244.71252
Q Predictions Max            1550.7836
Q Predictions Min            -20.632843
V Predictions Mean           1319.523
V Predictions Std            251.65514
V Predictions Max            1546.5586
V Predictions Min            -49.83162
Log Pis Mean                 0.46296167
Log Pis Std                  2.5202725
Log Pis Max                  9.5314
Log Pis Min                  -5.9350615
Policy mu Mean               -0.0053336266
Policy mu Std                0.6247478
Policy mu Max                2.2730105
Policy mu Min                -2.220027
Policy log std Mean          -1.040374
Policy log std Std           0.26929978
Policy log std Max           -0.16134405
Policy log std Min           -2.0250425
Z mean eval                  1.0577545
Z variance eval              0.009383815
total_rewards                [3589.18899695 3811.88665243  171.43107477 3702.32414475   28.42877915
 1588.84246348 1723.2853905  3626.41520963 3977.92933934 3833.16363825]
total_rewards_mean           2605.289568924842
total_rewards_std            1497.8954068589821
total_rewards_max            3977.9293393446633
total_rewards_min            28.428779149490257
Number of train steps total  429000
Number of env steps total    2147000
Number of rollouts total     0
Train Time (s)               31.11813125014305
(Previous) Eval Time (s)     22.733583624009043
Sample Time (s)              17.622312035411596
Epoch Time (s)               71.47402690956369
Total Train Time (s)         29621.442919312976
Epoch                        428
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:29:14.099688 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #428 | Epoch Duration: 68.86620593070984
2020-01-11 11:29:14.099986 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #428 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0581205
Z variance train             0.0094721755
KL Divergence                25.369335
KL Loss                      2.5369337
QF Loss                      1523.785
VF Loss                      621.7776
Policy Loss                  -1325.9587
Q Predictions Mean           1328.6942
Q Predictions Std            212.58548
Q Predictions Max            1571.7921
Q Predictions Min            67.067894
V Predictions Mean           1335.8997
V Predictions Std            206.72012
V Predictions Max            1581.6462
V Predictions Min            65.43292
Log Pis Mean                 0.2412125
Log Pis Std                  2.8074589
Log Pis Max                  12.823129
Log Pis Min                  -10.479114
Policy mu Mean               -0.014928247
Policy mu Std                0.57944053
Policy mu Max                2.0247862
Policy mu Min                -3.0129015
Policy log std Mean          -1.0539556
Policy log std Std           0.27160156
Policy log std Max           -0.13073903
Policy log std Min           -2.948822
Z mean eval                  1.0694709
Z variance eval              0.011644522
total_rewards                [3691.46586116  520.31616706 3587.91810629  855.32487817 3621.1936898
  326.33264253 3339.78480908 3399.27995769 3630.62233869 3351.16207278]
total_rewards_mean           2632.3400523245314
total_rewards_std            1362.0115245586194
total_rewards_max            3691.4658611615123
total_rewards_min            326.33264253258534
Number of train steps total  430000
Number of env steps total    2152000
Number of rollouts total     0
Train Time (s)               31.30647953879088
(Previous) Eval Time (s)     20.125471976120025
Sample Time (s)              17.84033152181655
Epoch Time (s)               69.27228303672746
Total Train Time (s)         29693.484568559565
Epoch                        429
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:30:26.143226 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #429 | Epoch Duration: 72.04306244850159
2020-01-11 11:30:26.143435 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #429 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0691421
Z variance train             0.01163623
KL Divergence                24.97993
KL Loss                      2.4979932
QF Loss                      1184.7954
VF Loss                      326.23325
Policy Loss                  -1287.7218
Q Predictions Mean           1287.5117
Q Predictions Std            275.87088
Q Predictions Max            1529.0557
Q Predictions Min            -26.56804
V Predictions Mean           1274.6581
V Predictions Std            271.85678
V Predictions Max            1511.422
V Predictions Min            -42.194317
Log Pis Mean                 0.6155426
Log Pis Std                  2.7563586
Log Pis Max                  8.639948
Log Pis Min                  -6.1575174
Policy mu Mean               -0.008756502
Policy mu Std                0.6089073
Policy mu Max                2.2555747
Policy mu Min                -2.3450468
Policy log std Mean          -1.068762
Policy log std Std           0.2963861
Policy log std Max           -0.08631301
Policy log std Min           -2.8726134
Z mean eval                  1.0736632
Z variance eval              0.010116921
total_rewards                [2638.20996617 2917.56181015  301.77848173  177.58133854  508.01061848
 1479.3320351  2479.88054509   20.07697835 3597.71816664  190.35209318]
total_rewards_mean           1431.0502033441594
total_rewards_std            1291.9905521360656
total_rewards_max            3597.718166643505
total_rewards_min            20.076978348491597
Number of train steps total  431000
Number of env steps total    2157000
Number of rollouts total     0
Train Time (s)               27.77892647124827
(Previous) Eval Time (s)     22.895962121896446
Sample Time (s)              18.378744402434677
Epoch Time (s)               69.05363299557939
Total Train Time (s)         29752.41693174839
Epoch                        430
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:31:25.078842 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #430 | Epoch Duration: 58.93524956703186
2020-01-11 11:31:25.079025 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #430 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0746133
Z variance train             0.010070978
KL Divergence                25.677841
KL Loss                      2.567784
QF Loss                      581.3268
VF Loss                      395.69183
Policy Loss                  -1314.7102
Q Predictions Mean           1314.6416
Q Predictions Std            250.708
Q Predictions Max            1554.9888
Q Predictions Min            -44.073742
V Predictions Mean           1331.2332
V Predictions Std            252.6921
V Predictions Max            1566.3883
V Predictions Min            -42.77895
Log Pis Mean                 0.46532172
Log Pis Std                  2.8109295
Log Pis Max                  9.052944
Log Pis Min                  -12.011862
Policy mu Mean               -0.0003613776
Policy mu Std                0.61906874
Policy mu Max                2.7740865
Policy mu Min                -2.556682
Policy log std Mean          -1.067328
Policy log std Std           0.28771985
Policy log std Max           -0.05349028
Policy log std Min           -2.2713957
Z mean eval                  1.0709836
Z variance eval              0.008510722
total_rewards                [3721.82778994 1788.34357681 4084.64326938 2522.94705181  948.67498229
 1588.25575552  297.26864962  570.58818545  212.13687615 1251.02322191]
total_rewards_mean           1698.570935887247
total_rewards_std            1292.0857680099507
total_rewards_max            4084.6432693763804
total_rewards_min            212.1368761451839
Number of train steps total  432000
Number of env steps total    2162000
Number of rollouts total     0
Train Time (s)               29.465267692692578
(Previous) Eval Time (s)     12.77725771209225
Sample Time (s)              17.78388315392658
Epoch Time (s)               60.02640855871141
Total Train Time (s)         29813.83090714831
Epoch                        431
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:32:26.497637 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #431 | Epoch Duration: 61.41847085952759
2020-01-11 11:32:26.497849 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #431 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0710193
Z variance train             0.008541191
KL Divergence                25.772614
KL Loss                      2.5772614
QF Loss                      3767.8843
VF Loss                      264.56506
Policy Loss                  -1312.0533
Q Predictions Mean           1308.771
Q Predictions Std            272.24307
Q Predictions Max            1537.0663
Q Predictions Min            -31.741724
V Predictions Mean           1314.3372
V Predictions Std            264.7517
V Predictions Max            1538.0094
V Predictions Min            -34.130417
Log Pis Mean                 0.6992408
Log Pis Std                  3.262123
Log Pis Max                  18.983334
Log Pis Min                  -8.420227
Policy mu Mean               -0.03261416
Policy mu Std                0.6583898
Policy mu Max                4.0998297
Policy mu Min                -4.3407254
Policy log std Mean          -1.0541805
Policy log std Std           0.29389986
Policy log std Max           0.28358865
Policy log std Min           -2.6189222
Z mean eval                  1.0503325
Z variance eval              0.0076401224
total_rewards                [2258.26216021 4138.23339125 3885.521874   3262.20711841 4010.05010413
 3856.98620817 3552.31784091 3748.02470301 3774.73237772 3897.3564784 ]
total_rewards_mean           3638.3692256192953
total_rewards_std            514.6047599835686
total_rewards_max            4138.233391250433
total_rewards_min            2258.262160208185
Number of train steps total  433000
Number of env steps total    2167000
Number of rollouts total     0
Train Time (s)               27.72600162308663
(Previous) Eval Time (s)     14.168975558597594
Sample Time (s)              17.179934763815254
Epoch Time (s)               59.07491194549948
Total Train Time (s)         29887.10801331699
Epoch                        432
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:33:39.777648 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #432 | Epoch Duration: 73.27961158752441
2020-01-11 11:33:39.777840 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #432 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0495851
Z variance train             0.007630737
KL Divergence                26.783604
KL Loss                      2.6783605
QF Loss                      1483.7668
VF Loss                      235.68245
Policy Loss                  -1331.3495
Q Predictions Mean           1337.4932
Q Predictions Std            217.41895
Q Predictions Max            1566.8334
Q Predictions Min            -27.738495
V Predictions Mean           1328.8726
V Predictions Std            213.37119
V Predictions Max            1549.7449
V Predictions Min            -33.080914
Log Pis Mean                 0.35739917
Log Pis Std                  2.8208156
Log Pis Max                  9.975852
Log Pis Min                  -9.358074
Policy mu Mean               -0.032635927
Policy mu Std                0.6020931
Policy mu Max                2.9940395
Policy mu Min                -2.8400574
Policy log std Mean          -1.0863564
Policy log std Std           0.25536644
Policy log std Max           -0.032941163
Policy log std Min           -2.311278
Z mean eval                  1.0571568
Z variance eval              0.008998729
total_rewards                [3876.57010589  593.38236338 3669.64969315 3711.7884496  2055.4796935
 3624.74022999  111.23467763  723.56237203 2002.15154264 3904.88441135]
total_rewards_mean           2427.3443539168416
total_rewards_std            1444.2985109010554
total_rewards_max            3904.8844113494906
total_rewards_min            111.23467762959947
Number of train steps total  434000
Number of env steps total    2172000
Number of rollouts total     0
Train Time (s)               31.26923719001934
(Previous) Eval Time (s)     28.373378434218466
Sample Time (s)              18.973213008604944
Epoch Time (s)               78.61582863284275
Total Train Time (s)         29956.99852428306
Epoch                        433
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:34:49.672823 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #433 | Epoch Duration: 69.89482855796814
2020-01-11 11:34:49.673028 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #433 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0587628
Z variance train             0.009074429
KL Divergence                25.633358
KL Loss                      2.563336
QF Loss                      742.8892
VF Loss                      227.70045
Policy Loss                  -1327.761
Q Predictions Mean           1327.5447
Q Predictions Std            238.38712
Q Predictions Max            1543.9049
Q Predictions Min            -60.57432
V Predictions Mean           1323.261
V Predictions Std            237.72746
V Predictions Max            1546.6663
V Predictions Min            -49.830353
Log Pis Mean                 0.54368436
Log Pis Std                  3.0007687
Log Pis Max                  12.307491
Log Pis Min                  -11.23862
Policy mu Mean               0.017987909
Policy mu Std                0.63978016
Policy mu Max                2.1933758
Policy mu Min                -2.3852644
Policy log std Mean          -1.0374842
Policy log std Std           0.27688763
Policy log std Max           -0.099843204
Policy log std Min           -2.5292559
Z mean eval                  1.098253
Z variance eval              0.013045509
total_rewards                [3710.04139936 3740.47370561 3489.76143454 3167.93591847 3913.29047897
 3657.79702683 3579.93720894 3431.42226895  218.66773286 3610.7616336 ]
total_rewards_mean           3252.008880814118
total_rewards_std            1028.7629364501781
total_rewards_max            3913.2904789682
total_rewards_min            218.66773286320392
Number of train steps total  435000
Number of env steps total    2177000
Number of rollouts total     0
Train Time (s)               28.093750606290996
(Previous) Eval Time (s)     19.652031775098294
Sample Time (s)              18.227117963600904
Epoch Time (s)               65.9729003449902
Total Train Time (s)         30029.41681254795
Epoch                        434
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:36:02.096181 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #434 | Epoch Duration: 72.42298245429993
2020-01-11 11:36:02.096400 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #434 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1003354
Z variance train             0.013037709
KL Divergence                24.731398
KL Loss                      2.4731398
QF Loss                      7505.991
VF Loss                      122.94977
Policy Loss                  -1322.4244
Q Predictions Mean           1320.425
Q Predictions Std            255.46597
Q Predictions Max            1579.414
Q Predictions Min            -18.729607
V Predictions Mean           1328.1947
V Predictions Std            255.0157
V Predictions Max            1591.3323
V Predictions Min            -11.269333
Log Pis Mean                 0.5527642
Log Pis Std                  2.7136078
Log Pis Max                  10.0971365
Log Pis Min                  -6.5874367
Policy mu Mean               0.007349462
Policy mu Std                0.6231501
Policy mu Max                2.4218752
Policy mu Min                -2.8739705
Policy log std Mean          -1.0653812
Policy log std Std           0.2618531
Policy log std Max           -0.17184913
Policy log std Min           -2.3339376
Z mean eval                  1.0490278
Z variance eval              0.015008169
total_rewards                [3299.46378248 3289.34995665   68.45169826 3509.49488856 3412.79667149
 3820.58791013 3297.0858213  3264.26284054  465.00981444 3719.13662598]
total_rewards_mean           2814.5640009840617
total_rewards_std            1289.5072902494915
total_rewards_max            3820.5879101313844
total_rewards_min            68.4516982638421
Number of train steps total  436000
Number of env steps total    2182000
Number of rollouts total     0
Train Time (s)               29.439416707027704
(Previous) Eval Time (s)     26.101815572939813
Sample Time (s)              18.040454090572894
Epoch Time (s)               73.58168637054041
Total Train Time (s)         30101.528963815887
Epoch                        435
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:37:14.217626 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #435 | Epoch Duration: 72.12100458145142
2020-01-11 11:37:14.217912 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #435 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0495939
Z variance train             0.015034998
KL Divergence                24.063845
KL Loss                      2.4063845
QF Loss                      1599.9375
VF Loss                      152.42168
Policy Loss                  -1331.6836
Q Predictions Mean           1333.4998
Q Predictions Std            219.21367
Q Predictions Max            1549.1688
Q Predictions Min            -3.4233398
V Predictions Mean           1330.2997
V Predictions Std            220.82892
V Predictions Max            1541.9421
V Predictions Min            -19.116905
Log Pis Mean                 0.45273244
Log Pis Std                  2.894439
Log Pis Max                  14.48131
Log Pis Min                  -7.7920403
Policy mu Mean               -0.05802469
Policy mu Std                0.6225029
Policy mu Max                2.1979575
Policy mu Min                -2.6082675
Policy log std Mean          -1.0629292
Policy log std Std           0.27874964
Policy log std Max           -0.16762036
Policy log std Min           -2.7627938
Z mean eval                  1.0580713
Z variance eval              0.015056695
total_rewards                [-2.84958433e+02  1.47465241e+03  4.13554124e+03  2.42568530e+02
 -3.32100701e+02  4.07325159e+03  3.66957814e+03  5.00768985e+02
  4.43364311e+03  4.34343267e+00]
total_rewards_mean           1791.7288302238544
total_rewards_std            1933.6461067387568
total_rewards_max            4433.643111475591
total_rewards_min            -332.1007010034532
Number of train steps total  437000
Number of env steps total    2187000
Number of rollouts total     0
Train Time (s)               29.866602295078337
(Previous) Eval Time (s)     24.640759146306664
Sample Time (s)              18.09798266319558
Epoch Time (s)               72.60534410458058
Total Train Time (s)         30166.98032857012
Epoch                        436
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:38:19.670317 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #436 | Epoch Duration: 65.45219349861145
2020-01-11 11:38:19.670492 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #436 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0585878
Z variance train             0.015086522
KL Divergence                23.233131
KL Loss                      2.3233132
QF Loss                      1213.8032
VF Loss                      390.9227
Policy Loss                  -1321.2837
Q Predictions Mean           1320.9182
Q Predictions Std            228.09966
Q Predictions Max            1523.9208
Q Predictions Min            43.009647
V Predictions Mean           1318.6952
V Predictions Std            229.51971
V Predictions Max            1518.8794
V Predictions Min            55.276695
Log Pis Mean                 0.811272
Log Pis Std                  2.7251945
Log Pis Max                  11.970748
Log Pis Min                  -6.9708376
Policy mu Mean               0.013172978
Policy mu Std                0.6086841
Policy mu Max                2.411912
Policy mu Min                -3.8096836
Policy log std Mean          -1.091534
Policy log std Std           0.29090768
Policy log std Max           0.24671412
Policy log std Min           -3.0419564
Z mean eval                  1.0878621
Z variance eval              0.012560177
total_rewards                [3109.24670455 4062.73871289 3532.14389093 2482.42927541 3269.61770689
 3383.10990841 3705.7745283  3359.71479226  791.09627756 3419.16732739]
total_rewards_mean           3111.503912460121
total_rewards_std            864.2921956566514
total_rewards_max            4062.7387128940877
total_rewards_min            791.0962775610247
Number of train steps total  438000
Number of env steps total    2192000
Number of rollouts total     0
Train Time (s)               28.32713548792526
(Previous) Eval Time (s)     17.487311420030892
Sample Time (s)              17.834964760113508
Epoch Time (s)               63.64941166806966
Total Train Time (s)         30237.084345593117
Epoch                        437
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:39:29.779310 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #437 | Epoch Duration: 70.10866165161133
2020-01-11 11:39:29.779518 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #437 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0879385
Z variance train             0.012574126
KL Divergence                24.259804
KL Loss                      2.4259803
QF Loss                      6691.507
VF Loss                      376.23077
Policy Loss                  -1349.1205
Q Predictions Mean           1354.8354
Q Predictions Std            242.24693
Q Predictions Max            1567.843
Q Predictions Min            66.967735
V Predictions Mean           1349.1462
V Predictions Std            237.21933
V Predictions Max            1560.0944
V Predictions Min            78.515076
Log Pis Mean                 0.7081783
Log Pis Std                  2.8459682
Log Pis Max                  11.662335
Log Pis Min                  -5.553728
Policy mu Mean               0.023569247
Policy mu Std                0.6096608
Policy mu Max                2.4995594
Policy mu Min                -2.1792967
Policy log std Mean          -1.0741796
Policy log std Std           0.30671254
Policy log std Max           -0.081835866
Policy log std Min           -3.089797
Z mean eval                  1.1049716
Z variance eval              0.014416302
total_rewards                [2487.79214327 3734.33348737 2193.2381709  3947.33293195 3778.72929666
  559.7361604  2008.23015721  109.98440422  856.8308449  1324.38386887]
total_rewards_mean           2100.0591465750736
total_rewards_std            1324.7241007440775
total_rewards_max            3947.33293195117
total_rewards_min            109.98440422089556
Number of train steps total  439000
Number of env steps total    2197000
Number of rollouts total     0
Train Time (s)               30.07841057702899
(Previous) Eval Time (s)     23.94627104094252
Sample Time (s)              18.40123756788671
Epoch Time (s)               72.42591918585822
Total Train Time (s)         30305.982162879314
Epoch                        438
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:40:38.684494 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #438 | Epoch Duration: 68.90478491783142
2020-01-11 11:40:38.684784 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #438 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1065642
Z variance train             0.014422134
KL Divergence                23.324467
KL Loss                      2.3324468
QF Loss                      845.35803
VF Loss                      199.05063
Policy Loss                  -1340.637
Q Predictions Mean           1337.6715
Q Predictions Std            229.35417
Q Predictions Max            1559.7865
Q Predictions Min            55.178425
V Predictions Mean           1331.4893
V Predictions Std            224.01299
V Predictions Max            1553.0758
V Predictions Min            51.87338
Log Pis Mean                 0.6696466
Log Pis Std                  2.7205245
Log Pis Max                  9.231951
Log Pis Min                  -7.246661
Policy mu Mean               0.022728488
Policy mu Std                0.6372393
Policy mu Max                2.4898102
Policy mu Min                -2.867058
Policy log std Mean          -1.0772028
Policy log std Std           0.27241406
Policy log std Max           -0.22930515
Policy log std Min           -3.0347648
Z mean eval                  1.0811508
Z variance eval              0.011911904
total_rewards                [3364.84798733 3603.79422617 3351.46886607 3180.40170138 3018.85190621
 2885.94193361 3420.0305249  3566.74620668 3147.15221102 3062.20106551]
total_rewards_mean           3260.1436628889023
total_rewards_std            226.6106116107278
total_rewards_max            3603.794226171798
total_rewards_min            2885.9419336144456
Number of train steps total  440000
Number of env steps total    2202000
Number of rollouts total     0
Train Time (s)               29.48206761199981
(Previous) Eval Time (s)     20.424841993954033
Sample Time (s)              17.480748950969428
Epoch Time (s)               67.38765855692327
Total Train Time (s)         30380.067578955088
Epoch                        439
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:41:52.776067 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #439 | Epoch Duration: 74.09103751182556
2020-01-11 11:41:52.776332 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #439 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0813714
Z variance train             0.011945286
KL Divergence                23.490211
KL Loss                      2.3490212
QF Loss                      1278.2991
VF Loss                      362.53363
Policy Loss                  -1366.8444
Q Predictions Mean           1368.7031
Q Predictions Std            214.98448
Q Predictions Max            1574.8436
Q Predictions Min            -13.78725
V Predictions Mean           1355.5813
V Predictions Std            215.83047
V Predictions Max            1576.5492
V Predictions Min            -38.3026
Log Pis Mean                 0.4367814
Log Pis Std                  2.6346278
Log Pis Max                  8.964181
Log Pis Min                  -7.408823
Policy mu Mean               0.07344269
Policy mu Std                0.59854454
Policy mu Max                2.1404397
Policy mu Min                -2.40949
Policy log std Mean          -1.0937961
Policy log std Std           0.25733906
Policy log std Max           -0.19713545
Policy log std Min           -2.2679303
Z mean eval                  1.0533487
Z variance eval              0.009072176
total_rewards                [4049.14367569 3651.94444551 4044.03190104 4105.7920959   227.14272394
 3913.40854637 4062.59483422 3900.32756179 4178.88500312 3880.30587813]
total_rewards_mean           3601.357666570876
total_rewards_std            1133.5634427068378
total_rewards_max            4178.885003119315
total_rewards_min            227.14272394362152
Number of train steps total  441000
Number of env steps total    2207000
Number of rollouts total     0
Train Time (s)               29.97774903802201
(Previous) Eval Time (s)     27.127947306726128
Sample Time (s)              17.851188539061695
Epoch Time (s)               74.95688488380983
Total Train Time (s)         30452.386190173216
Epoch                        440
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:43:05.101330 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #440 | Epoch Duration: 72.32478713989258
2020-01-11 11:43:05.101581 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #440 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0539954
Z variance train             0.009065164
KL Divergence                23.376099
KL Loss                      2.33761
QF Loss                      937.2561
VF Loss                      230.22185
Policy Loss                  -1354.6337
Q Predictions Mean           1353.7704
Q Predictions Std            228.67993
Q Predictions Max            1569.6654
Q Predictions Min            22.731276
V Predictions Mean           1343.4279
V Predictions Std            227.56812
V Predictions Max            1562.6841
V Predictions Min            14.156682
Log Pis Mean                 0.613675
Log Pis Std                  2.685998
Log Pis Max                  8.790777
Log Pis Min                  -8.97053
Policy mu Mean               -0.013053318
Policy mu Std                0.6454385
Policy mu Max                2.5259163
Policy mu Min                -2.6347163
Policy log std Mean          -1.0646542
Policy log std Std           0.26307985
Policy log std Max           -0.26413757
Policy log std Min           -2.0739317
Z mean eval                  1.092067
Z variance eval              0.009120641
total_rewards                [ 294.53484113 1716.3677149   848.15663309 1629.39954017 1452.23381837
 2266.05888307 1044.35478468 1154.25596379  461.25394804  350.8903702 ]
total_rewards_mean           1121.7506497440222
total_rewards_std            618.59560025962
total_rewards_max            2266.058883066388
total_rewards_min            294.5348411285508
Number of train steps total  442000
Number of env steps total    2212000
Number of rollouts total     0
Train Time (s)               27.361390699632466
(Previous) Eval Time (s)     24.495536717120558
Sample Time (s)              17.863890434149653
Epoch Time (s)               69.72081785090268
Total Train Time (s)         30512.002051467076
Epoch                        441
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:44:04.720660 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #441 | Epoch Duration: 59.61888384819031
2020-01-11 11:44:04.720852 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #441 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0931377
Z variance train             0.009115665
KL Divergence                24.18061
KL Loss                      2.418061
QF Loss                      1901.4628
VF Loss                      401.1145
Policy Loss                  -1373.926
Q Predictions Mean           1376.2375
Q Predictions Std            185.96928
Q Predictions Max            1597.5751
Q Predictions Min            -9.805397
V Predictions Mean           1383.6653
V Predictions Std            185.05104
V Predictions Max            1594.0809
V Predictions Min            -9.521034
Log Pis Mean                 0.9296463
Log Pis Std                  2.871258
Log Pis Max                  13.679313
Log Pis Min                  -5.1571903
Policy mu Mean               -0.028959025
Policy mu Std                0.6551293
Policy mu Max                3.1360855
Policy mu Min                -2.4333398
Policy log std Mean          -1.0765926
Policy log std Std           0.28407642
Policy log std Max           -0.21938413
Policy log std Min           -2.614553
Z mean eval                  1.048715
Z variance eval              0.012206019
total_rewards                [3877.61069236 3756.55153857 1665.37784267 3711.43669664 2657.90956793
 3800.39798501  258.50714577  187.63135805 1296.90713952 3885.3239946 ]
total_rewards_mean           2509.765396110872
total_rewards_std            1452.3710503353136
total_rewards_max            3885.3239945954524
total_rewards_min            187.6313580501273
Number of train steps total  443000
Number of env steps total    2217000
Number of rollouts total     0
Train Time (s)               30.547622358892113
(Previous) Eval Time (s)     14.39331097714603
Sample Time (s)              17.715539888478816
Epoch Time (s)               62.65647322451696
Total Train Time (s)         30579.67299662251
Epoch                        442
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:45:12.400118 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #442 | Epoch Duration: 67.6790714263916
2020-01-11 11:45:12.400440 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #442 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0493839
Z variance train             0.012230244
KL Divergence                22.509315
KL Loss                      2.2509315
QF Loss                      2775.6
VF Loss                      136.40167
Policy Loss                  -1370.4296
Q Predictions Mean           1370.356
Q Predictions Std            197.59856
Q Predictions Max            1601.2827
Q Predictions Min            -45.049232
V Predictions Mean           1367.0828
V Predictions Std            194.89973
V Predictions Max            1580.6647
V Predictions Min            -6.869009
Log Pis Mean                 0.7792388
Log Pis Std                  2.797814
Log Pis Max                  10.351512
Log Pis Min                  -5.9367876
Policy mu Mean               -0.015469344
Policy mu Std                0.63583463
Policy mu Max                2.7173162
Policy mu Min                -2.5866091
Policy log std Mean          -1.0693376
Policy log std Std           0.25174338
Policy log std Max           -0.24277246
Policy log std Min           -2.4439154
Z mean eval                  1.0650156
Z variance eval              0.010422664
total_rewards                [3571.52696249 3453.08138592 1466.43185544 3946.50693019 3613.71461345
 2752.52098017  866.53999135 3868.65807107   77.97413199 2307.00527224]
total_rewards_mean           2592.396019430216
total_rewards_std            1299.261682467285
total_rewards_max            3946.50693018594
total_rewards_min            77.974131986174
Number of train steps total  444000
Number of env steps total    2222000
Number of rollouts total     0
Train Time (s)               29.389230945147574
(Previous) Eval Time (s)     19.415568508207798
Sample Time (s)              18.378259778022766
Epoch Time (s)               67.18305923137814
Total Train Time (s)         30646.314450425096
Epoch                        443
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:46:19.044148 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #443 | Epoch Duration: 66.6434690952301
2020-01-11 11:46:19.044345 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #443 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0629449
Z variance train             0.010453919
KL Divergence                23.05419
KL Loss                      2.305419
QF Loss                      1143.2238
VF Loss                      568.18896
Policy Loss                  -1338.8114
Q Predictions Mean           1342.6318
Q Predictions Std            261.77756
Q Predictions Max            1588.0275
Q Predictions Min            -67.394005
V Predictions Mean           1357.7228
V Predictions Std            262.71426
V Predictions Max            1609.5344
V Predictions Min            -49.28499
Log Pis Mean                 0.5038228
Log Pis Std                  2.9030097
Log Pis Max                  12.562794
Log Pis Min                  -9.994015
Policy mu Mean               -0.017141804
Policy mu Std                0.6412618
Policy mu Max                2.8528788
Policy mu Min                -2.477166
Policy log std Mean          -1.0641346
Policy log std Std           0.2810739
Policy log std Max           -0.078052044
Policy log std Min           -2.19732
Z mean eval                  1.1064638
Z variance eval              0.012377968
total_rewards                [ 234.67052742  604.3613764  1117.04641565 2441.85455589 3487.21186907
 1123.97903821 1720.39413468 2177.41005006 1600.7548577  3748.96237431]
total_rewards_mean           1825.6645199385662
total_rewards_std            1097.371445967555
total_rewards_max            3748.9623743095804
total_rewards_min            234.670527415079
Number of train steps total  445000
Number of env steps total    2227000
Number of rollouts total     0
Train Time (s)               28.17510622087866
(Previous) Eval Time (s)     18.87564251385629
Sample Time (s)              17.12777049932629
Epoch Time (s)               64.17851923406124
Total Train Time (s)         30706.686098861042
Epoch                        444
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:47:19.423675 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #444 | Epoch Duration: 60.37914562225342
2020-01-11 11:47:19.423984 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #444 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1048262
Z variance train             0.012376884
KL Divergence                22.687572
KL Loss                      2.2687573
QF Loss                      4264.949
VF Loss                      301.09885
Policy Loss                  -1352.7983
Q Predictions Mean           1351.8398
Q Predictions Std            260.81363
Q Predictions Max            1591.2631
Q Predictions Min            -100.130325
V Predictions Mean           1360.1804
V Predictions Std            252.41245
V Predictions Max            1598.5525
V Predictions Min            -71.32655
Log Pis Mean                 0.9347005
Log Pis Std                  2.9044766
Log Pis Max                  11.960793
Log Pis Min                  -8.353277
Policy mu Mean               0.023803798
Policy mu Std                0.6434313
Policy mu Max                2.9970977
Policy mu Min                -2.2640574
Policy log std Mean          -1.09329
Policy log std Std           0.3301016
Policy log std Max           -0.021545112
Policy log std Min           -2.9603636
Z mean eval                  1.06616
Z variance eval              0.009974401
total_rewards                [2906.95002519 3701.55021101 3647.95305446 3647.32558641 3867.97634401
 1336.52711885  146.40823373 3001.43364115  832.06057945  949.44101635]
total_rewards_mean           2403.762581061649
total_rewards_std            1354.731723814615
total_rewards_max            3867.976344005345
total_rewards_min            146.40823372541087
Number of train steps total  446000
Number of env steps total    2232000
Number of rollouts total     0
Train Time (s)               24.893646298907697
(Previous) Eval Time (s)     15.07595290709287
Sample Time (s)              17.988527222536504
Epoch Time (s)               57.95812642853707
Total Train Time (s)         30766.929475953802
Epoch                        445
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:48:19.670755 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #445 | Epoch Duration: 60.24654269218445
2020-01-11 11:48:19.670961 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #445 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0654503
Z variance train             0.009993525
KL Divergence                22.697474
KL Loss                      2.2697475
QF Loss                      1079.8958
VF Loss                      248.12384
Policy Loss                  -1384.9521
Q Predictions Mean           1384.8206
Q Predictions Std            211.20175
Q Predictions Max            1597.2446
Q Predictions Min            -67.401306
V Predictions Mean           1376.906
V Predictions Std            206.12016
V Predictions Max            1588.2932
V Predictions Min            -27.710283
Log Pis Mean                 0.93784374
Log Pis Std                  2.9475374
Log Pis Max                  13.090261
Log Pis Min                  -6.9606433
Policy mu Mean               0.014507851
Policy mu Std                0.6775348
Policy mu Max                2.4540687
Policy mu Min                -2.4001942
Policy log std Mean          -1.0706426
Policy log std Std           0.27686572
Policy log std Max           0.07519233
Policy log std Min           -2.3962746
Z mean eval                  1.0906957
Z variance eval              0.00900548
total_rewards                [1154.51100238 1985.04068866 4070.62440877 3694.24549413 3249.66481087
  177.23108429  721.955014   3853.6172137  4119.18831357 3762.27936253]
total_rewards_mean           2678.8357392911394
total_rewards_std            1442.7363284418636
total_rewards_max            4119.188313570192
total_rewards_min            177.23108428897262
Number of train steps total  447000
Number of env steps total    2237000
Number of rollouts total     0
Train Time (s)               29.832450463902205
(Previous) Eval Time (s)     17.364068838767707
Sample Time (s)              17.84863160131499
Epoch Time (s)               65.0451509039849
Total Train Time (s)         30833.587288181297
Epoch                        446
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:49:26.334541 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #446 | Epoch Duration: 66.66340780258179
2020-01-11 11:49:26.334778 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #446 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0861691
Z variance train             0.009023195
KL Divergence                23.30608
KL Loss                      2.3306081
QF Loss                      1874.386
VF Loss                      111.85326
Policy Loss                  -1339.7482
Q Predictions Mean           1342.5641
Q Predictions Std            290.40762
Q Predictions Max            1575.0511
Q Predictions Min            -67.25959
V Predictions Mean           1340.3401
V Predictions Std            288.09488
V Predictions Max            1573.2388
V Predictions Min            -71.69675
Log Pis Mean                 0.66746026
Log Pis Std                  2.5749645
Log Pis Max                  11.027925
Log Pis Min                  -6.0651
Policy mu Mean               -0.004319664
Policy mu Std                0.66235065
Policy mu Max                2.5618076
Policy mu Min                -2.6038625
Policy log std Mean          -1.0286477
Policy log std Std           0.27298778
Policy log std Max           -0.07566732
Policy log std Min           -2.4157887
Z mean eval                  1.0606854
Z variance eval              0.008303578
total_rewards                [3876.84690876  835.79071982 3763.46488608 1455.12036945 3796.47566585
   61.98646687 3676.61570955 3862.66397567 3612.9322602   292.72571246]
total_rewards_mean           2523.4622674708044
total_rewards_std            1559.6354347662154
total_rewards_max            3876.846908758647
total_rewards_min            61.986466865591936
Number of train steps total  448000
Number of env steps total    2242000
Number of rollouts total     0
Train Time (s)               26.161186492070556
(Previous) Eval Time (s)     18.98200487298891
Sample Time (s)              17.742613119073212
Epoch Time (s)               62.88580448413268
Total Train Time (s)         30895.069155672565
Epoch                        447
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:50:27.819179 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #447 | Epoch Duration: 61.484227895736694
2020-01-11 11:50:27.819370 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #447 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.060099
Z variance train             0.008295623
KL Divergence                23.607841
KL Loss                      2.3607843
QF Loss                      712.9872
VF Loss                      384.67007
Policy Loss                  -1336.942
Q Predictions Mean           1340.7643
Q Predictions Std            290.9149
Q Predictions Max            1627.8501
Q Predictions Min            -94.95982
V Predictions Mean           1353.4296
V Predictions Std            288.93198
V Predictions Max            1646.3708
V Predictions Min            -61.19758
Log Pis Mean                 0.52016187
Log Pis Std                  3.0607374
Log Pis Max                  10.394989
Log Pis Min                  -9.941018
Policy mu Mean               0.02634035
Policy mu Std                0.63114923
Policy mu Max                2.6869922
Policy mu Min                -2.8359015
Policy log std Mean          -1.0713158
Policy log std Std           0.28904948
Policy log std Max           0.26245558
Policy log std Min           -2.151949
Z mean eval                  1.0990368
Z variance eval              0.009570032
total_rewards                [3962.44569554 2904.37489858 2412.83894634 3200.42328893 4025.00163926
 3739.53453555 3586.31173414 3763.22626855 3837.80816224 4098.89901364]
total_rewards_mean           3553.086418276033
total_rewards_std            519.0996675969077
total_rewards_max            4098.899013639854
total_rewards_min            2412.838946339737
Number of train steps total  449000
Number of env steps total    2247000
Number of rollouts total     0
Train Time (s)               27.26124212378636
(Previous) Eval Time (s)     17.580112335272133
Sample Time (s)              18.030823660083115
Epoch Time (s)               62.87217811914161
Total Train Time (s)         30964.594491664786
Epoch                        448
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:51:37.349492 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #448 | Epoch Duration: 69.52998471260071
2020-01-11 11:51:37.349682 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #448 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1005704
Z variance train             0.009597065
KL Divergence                23.0448
KL Loss                      2.30448
QF Loss                      3275.7773
VF Loss                      326.63333
Policy Loss                  -1382.8318
Q Predictions Mean           1384.002
Q Predictions Std            203.8752
Q Predictions Max            1624.6921
Q Predictions Min            62.02896
V Predictions Mean           1371.2634
V Predictions Std            206.04805
V Predictions Max            1613.4359
V Predictions Min            -7.991645
Log Pis Mean                 0.9461623
Log Pis Std                  2.6312468
Log Pis Max                  8.802568
Log Pis Min                  -6.463123
Policy mu Mean               0.038853478
Policy mu Std                0.6256248
Policy mu Max                2.4761639
Policy mu Min                -2.0638483
Policy log std Mean          -1.1066281
Policy log std Std           0.2842509
Policy log std Max           -0.22890627
Policy log std Min           -2.7477465
Z mean eval                  1.0749555
Z variance eval              0.012003965
total_rewards                [3734.59310888 4024.15768521 4024.46812873 3932.27009402 4007.38726468
 4100.02397158  205.05317388 4033.97736601  970.26204564 3782.17325941]
total_rewards_mean           3281.436609803445
total_rewards_std            1362.0746229861923
total_rewards_max            4100.023971577484
total_rewards_min            205.05317387800483
Number of train steps total  450000
Number of env steps total    2252000
Number of rollouts total     0
Train Time (s)               25.577107690740377
(Previous) Eval Time (s)     24.23759741988033
Sample Time (s)              17.45194842526689
Epoch Time (s)               67.2666535358876
Total Train Time (s)         31029.938822967466
Epoch                        449
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:52:42.699221 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #449 | Epoch Duration: 65.34938025474548
2020-01-11 11:52:42.699486 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #449 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0747726
Z variance train             0.011983251
KL Divergence                22.469574
KL Loss                      2.2469575
QF Loss                      1692.0917
VF Loss                      1298.7114
Policy Loss                  -1371.221
Q Predictions Mean           1368.3883
Q Predictions Std            237.32521
Q Predictions Max            1588.5764
Q Predictions Min            -39.124123
V Predictions Mean           1361.4606
V Predictions Std            223.67355
V Predictions Max            1565.8468
V Predictions Min            -45.68942
Log Pis Mean                 0.8807971
Log Pis Std                  3.1942754
Log Pis Max                  14.450936
Log Pis Min                  -6.5866942
Policy mu Mean               -0.007411213
Policy mu Std                0.62666184
Policy mu Max                2.7673156
Policy mu Min                -2.453128
Policy log std Mean          -1.1053765
Policy log std Std           0.33469558
Policy log std Max           -0.15366161
Policy log std Min           -3.2868633
Z mean eval                  1.0771885
Z variance eval              0.008028266
total_rewards                [ 302.17653792 1130.8989689  4071.84704891 4119.62965241 2204.36415739
 4027.52046896 4142.99385884 3702.54745649 3855.46296855 4013.28316812]
total_rewards_mean           3157.0724286490863
total_rewards_std            1348.1432246215904
total_rewards_max            4142.993858835105
total_rewards_min            302.17653791547707
Number of train steps total  451000
Number of env steps total    2257000
Number of rollouts total     0
Train Time (s)               29.316928475163877
(Previous) Eval Time (s)     22.32000614888966
Sample Time (s)              18.527893145103008
Epoch Time (s)               70.16482776915655
Total Train Time (s)         31099.0415158025
Epoch                        450
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:53:51.806213 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #450 | Epoch Duration: 69.10653758049011
2020-01-11 11:53:51.806387 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #450 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0767843
Z variance train             0.0080503905
KL Divergence                23.189617
KL Loss                      2.3189619
QF Loss                      5275.7617
VF Loss                      1549.9572
Policy Loss                  -1315.7367
Q Predictions Mean           1317.1938
Q Predictions Std            340.63113
Q Predictions Max            1618.0481
Q Predictions Min            -67.15119
V Predictions Mean           1323.5151
V Predictions Std            334.8702
V Predictions Max            1628.1713
V Predictions Min            -88.39059
Log Pis Mean                 0.673018
Log Pis Std                  3.0663764
Log Pis Max                  11.457758
Log Pis Min                  -6.9303007
Policy mu Mean               0.03013332
Policy mu Std                0.66458386
Policy mu Max                2.4576905
Policy mu Min                -2.8948529
Policy log std Mean          -1.0553819
Policy log std Std           0.3251353
Policy log std Max           -0.17610562
Policy log std Min           -3.104601
Z mean eval                  1.0436525
Z variance eval              0.013474246
total_rewards                [3651.1426192  3672.5518905  3136.44979189 3664.74697934  396.18060862
 3667.14820993 3850.89892608 3213.80393703 3802.23691499 3874.09228738]
total_rewards_mean           3292.9252164951495
total_rewards_std            994.0368545020297
total_rewards_max            3874.0922873826444
total_rewards_min            396.18060861732255
Number of train steps total  452000
Number of env steps total    2262000
Number of rollouts total     0
Train Time (s)               29.73053283104673
(Previous) Eval Time (s)     21.261458958964795
Sample Time (s)              17.769365868531168
Epoch Time (s)               68.76135765854269
Total Train Time (s)         31169.890871409327
Epoch                        451
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:55:02.661767 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #451 | Epoch Duration: 70.85519886016846
2020-01-11 11:55:02.662078 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #451 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0452547
Z variance train             0.013527093
KL Divergence                22.68624
KL Loss                      2.268624
QF Loss                      1575.1299
VF Loss                      625.1023
Policy Loss                  -1363.3517
Q Predictions Mean           1363.4531
Q Predictions Std            209.9646
Q Predictions Max            1566.7765
Q Predictions Min            52.88953
V Predictions Mean           1370.5875
V Predictions Std            206.4659
V Predictions Max            1578.6254
V Predictions Min            44.64984
Log Pis Mean                 1.0171752
Log Pis Std                  2.8353202
Log Pis Max                  12.143886
Log Pis Min                  -6.1610937
Policy mu Mean               0.020013947
Policy mu Std                0.6217519
Policy mu Max                2.5116773
Policy mu Min                -2.571972
Policy log std Mean          -1.1253705
Policy log std Std           0.2872307
Policy log std Max           -0.17449474
Policy log std Min           -2.7323523
Z mean eval                  1.0630624
Z variance eval              0.011897012
total_rewards                [3497.24796212 3417.33671725  570.08317637 3766.77501009 3973.16574318
 4482.84323934 3998.76700959  353.9582656  4156.44471593  409.74356004]
total_rewards_mean           2862.636539951358
total_rewards_std            1609.873249582994
total_rewards_max            4482.843239341043
total_rewards_min            353.95826559587033
Number of train steps total  453000
Number of env steps total    2267000
Number of rollouts total     0
Train Time (s)               27.231262462213635
(Previous) Eval Time (s)     23.35498704202473
Sample Time (s)              18.077934691682458
Epoch Time (s)               68.66418419592083
Total Train Time (s)         31238.137548081577
Epoch                        452
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:56:10.915238 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #452 | Epoch Duration: 68.25290822982788
2020-01-11 11:56:10.915529 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #452 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0623678
Z variance train             0.0118678035
KL Divergence                23.238394
KL Loss                      2.3238394
QF Loss                      631.0583
VF Loss                      73.78441
Policy Loss                  -1368.5203
Q Predictions Mean           1369.0469
Q Predictions Std            283.19684
Q Predictions Max            1602.6414
Q Predictions Min            -70.00415
V Predictions Mean           1368.2815
V Predictions Std            282.72653
V Predictions Max            1607.9911
V Predictions Min            -69.587585
Log Pis Mean                 0.5274494
Log Pis Std                  2.7923617
Log Pis Max                  10.221006
Log Pis Min                  -7.245244
Policy mu Mean               -0.0034056234
Policy mu Std                0.64666784
Policy mu Max                2.3964443
Policy mu Min                -2.6193585
Policy log std Mean          -1.0503533
Policy log std Std           0.2866833
Policy log std Max           -0.11648202
Policy log std Min           -2.1974359
Z mean eval                  1.083688
Z variance eval              0.01562194
total_rewards                [3763.4380713   913.6983864  3979.27106218   90.70619713 3618.27563674
 2915.36686485 3973.93039871 3926.19921462 3977.31768502 3842.6187257 ]
total_rewards_mean           3100.0822242648997
total_rewards_std            1346.0779677160558
total_rewards_max            3979.2710621753818
total_rewards_min            90.70619713172397
Number of train steps total  454000
Number of env steps total    2272000
Number of rollouts total     0
Train Time (s)               28.742477805819362
(Previous) Eval Time (s)     22.943402274977416
Sample Time (s)              18.237005597446114
Epoch Time (s)               69.92288567824289
Total Train Time (s)         31309.43041100353
Epoch                        453
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:57:22.210417 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #453 | Epoch Duration: 71.29469180107117
2020-01-11 11:57:22.210622 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #453 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0833267
Z variance train             0.015646549
KL Divergence                22.492128
KL Loss                      2.249213
QF Loss                      4797.5195
VF Loss                      526.933
Policy Loss                  -1380.3143
Q Predictions Mean           1380.8835
Q Predictions Std            254.09642
Q Predictions Max            1652.4194
Q Predictions Min            -135.35385
V Predictions Mean           1376.9137
V Predictions Std            255.20988
V Predictions Max            1648.9441
V Predictions Min            -112.96536
Log Pis Mean                 0.6104242
Log Pis Std                  2.7511082
Log Pis Max                  9.563387
Log Pis Min                  -6.105235
Policy mu Mean               -0.00067453086
Policy mu Std                0.6105196
Policy mu Max                3.0149302
Policy mu Min                -2.558341
Policy log std Mean          -1.0810394
Policy log std Std           0.25047624
Policy log std Max           -0.115773976
Policy log std Min           -2.1239915
Z mean eval                  1.0665356
Z variance eval              0.01413161
total_rewards                [3558.44934107 1380.11053036 3876.58372003 4037.40453974 3074.8450793
 3633.09086916 3900.60905493 4087.74108988 3691.72239639 4207.81599854]
total_rewards_mean           3544.8372619406773
total_rewards_std            784.2206883671483
total_rewards_max            4207.815998540045
total_rewards_min            1380.1105303647844
Number of train steps total  455000
Number of env steps total    2277000
Number of rollouts total     0
Train Time (s)               28.378696685191244
(Previous) Eval Time (s)     24.314897644799203
Sample Time (s)              18.111733279190958
Epoch Time (s)               70.8053276091814
Total Train Time (s)         31380.803056891542
Epoch                        454
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:58:33.588540 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #454 | Epoch Duration: 71.37776708602905
2020-01-11 11:58:33.588751 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #454 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0654197
Z variance train             0.014119235
KL Divergence                22.499939
KL Loss                      2.249994
QF Loss                      2985.776
VF Loss                      549.35077
Policy Loss                  -1393.7114
Q Predictions Mean           1393.0194
Q Predictions Std            198.51515
Q Predictions Max            1601.9106
Q Predictions Min            -25.69689
V Predictions Mean           1387.9355
V Predictions Std            200.93723
V Predictions Max            1600.4526
V Predictions Min            -32.199158
Log Pis Mean                 1.149518
Log Pis Std                  2.8517427
Log Pis Max                  11.490227
Log Pis Min                  -9.08453
Policy mu Mean               0.011587471
Policy mu Std                0.60766435
Policy mu Max                2.7438776
Policy mu Min                -2.4987514
Policy log std Mean          -1.1360781
Policy log std Std           0.27636704
Policy log std Max           -0.1200462
Policy log std Min           -2.7182858
Z mean eval                  1.1419154
Z variance eval              0.013263707
total_rewards                [3664.95264803 3914.37771593 4089.01857387 3947.51962676 1134.15766884
  957.75088302 3482.00992894 2950.83479354 3808.24339879 4188.00493585]
total_rewards_mean           3213.687017358172
total_rewards_std            1133.8824932034336
total_rewards_max            4188.004935853402
total_rewards_min            957.7508830206156
Number of train steps total  456000
Number of env steps total    2282000
Number of rollouts total     0
Train Time (s)               30.043722114991397
(Previous) Eval Time (s)     24.887025642208755
Sample Time (s)              17.39198022009805
Epoch Time (s)               72.3227279772982
Total Train Time (s)         31451.896682607476
Epoch                        455
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:59:44.687297 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #455 | Epoch Duration: 71.09835815429688
2020-01-11 11:59:44.687544 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #455 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1416199
Z variance train             0.013321263
KL Divergence                22.873013
KL Loss                      2.2873013
QF Loss                      895.69275
VF Loss                      308.80707
Policy Loss                  -1376.2068
Q Predictions Mean           1380.0125
Q Predictions Std            252.0122
Q Predictions Max            1593.6501
Q Predictions Min            -33.893597
V Predictions Mean           1386.4943
V Predictions Std            252.65372
V Predictions Max            1610.3207
V Predictions Min            -34.021038
Log Pis Mean                 1.0898994
Log Pis Std                  2.916763
Log Pis Max                  10.279496
Log Pis Min                  -7.0635824
Policy mu Mean               -0.02688041
Policy mu Std                0.65793604
Policy mu Max                2.3449767
Policy mu Min                -2.5367272
Policy log std Mean          -1.091752
Policy log std Std           0.29701546
Policy log std Max           -0.12840009
Policy log std Min           -2.8332064
Z mean eval                  1.0678152
Z variance eval              0.012985771
total_rewards                [3888.95983216 3828.40995121 3915.68221528 3808.00334419 1098.93414519
  854.51546897 3666.73178227 3570.11611522 1665.16447086 3944.78996386]
total_rewards_mean           3024.1307289205324
total_rewards_std            1209.2628295991149
total_rewards_max            3944.7899638609383
total_rewards_min            854.5154689672526
Number of train steps total  457000
Number of env steps total    2287000
Number of rollouts total     0
Train Time (s)               28.691308772191405
(Previous) Eval Time (s)     23.662357504013926
Sample Time (s)              17.649808942805976
Epoch Time (s)               70.0034752190113
Total Train Time (s)         31520.030158194248
Epoch                        456
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:00:52.825684 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #456 | Epoch Duration: 68.13794660568237
2020-01-11 12:00:52.825882 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #456 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0675659
Z variance train             0.012956113
KL Divergence                23.021765
KL Loss                      2.3021765
QF Loss                      4926.8203
VF Loss                      698.73914
Policy Loss                  -1347.2972
Q Predictions Mean           1349.9431
Q Predictions Std            310.9519
Q Predictions Max            1595.2625
Q Predictions Min            -99.39636
V Predictions Mean           1349.2256
V Predictions Std            303.70255
V Predictions Max            1602.6617
V Predictions Min            -89.978546
Log Pis Mean                 0.9267147
Log Pis Std                  3.0736072
Log Pis Max                  12.528967
Log Pis Min                  -6.1377654
Policy mu Mean               0.016209124
Policy mu Std                0.6895156
Policy mu Max                2.2184985
Policy mu Min                -2.4862418
Policy log std Mean          -1.036162
Policy log std Std           0.30873084
Policy log std Max           -0.093298316
Policy log std Min           -2.4349887
Z mean eval                  1.0641477
Z variance eval              0.011827157
total_rewards                [4122.16883888   88.38934363 3391.62589597 4302.95703788 3517.4253755
 2903.94084892 3581.14024716 3882.66794335 4042.70306173 3716.75380567]
total_rewards_mean           3354.9772398671303
total_rewards_std            1154.2299489981042
total_rewards_max            4302.9570378753115
total_rewards_min            88.38934362651014
Number of train steps total  458000
Number of env steps total    2292000
Number of rollouts total     0
Train Time (s)               28.0563609697856
(Previous) Eval Time (s)     21.796536766923964
Sample Time (s)              18.015422673430294
Epoch Time (s)               67.86832041013986
Total Train Time (s)         31589.022189214826
Epoch                        457
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:02:01.819700 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #457 | Epoch Duration: 68.99365234375
2020-01-11 12:02:01.819897 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #457 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0647185
Z variance train             0.011831108
KL Divergence                23.480795
KL Loss                      2.3480794
QF Loss                      1060.9629
VF Loss                      122.09188
Policy Loss                  -1355.8093
Q Predictions Mean           1354.1575
Q Predictions Std            293.13385
Q Predictions Max            1628.3406
Q Predictions Min            -71.398605
V Predictions Mean           1356.7872
V Predictions Std            289.78366
V Predictions Max            1623.5825
V Predictions Min            -77.25946
Log Pis Mean                 0.73450005
Log Pis Std                  2.793908
Log Pis Max                  16.230328
Log Pis Min                  -7.489187
Policy mu Mean               -0.0058305156
Policy mu Std                0.6721033
Policy mu Max                2.6955333
Policy mu Min                -2.6336195
Policy log std Mean          -1.0293555
Policy log std Std           0.27141148
Policy log std Max           -0.22400397
Policy log std Min           -2.5474417
Z mean eval                  1.086438
Z variance eval              0.0153942155
total_rewards                [3602.03150933 2350.15992381 3613.02817514 3583.84680727 3881.97314704
  348.72344076 3735.2602031  3801.85811126 3235.50878511 3424.48546473]
total_rewards_mean           3157.687556755437
total_rewards_std            1023.6767734663059
total_rewards_max            3881.9731470417837
total_rewards_min            348.72344075904243
Number of train steps total  459000
Number of env steps total    2297000
Number of rollouts total     0
Train Time (s)               29.563075298909098
(Previous) Eval Time (s)     22.921571015845984
Sample Time (s)              17.571580092422664
Epoch Time (s)               70.05622640717775
Total Train Time (s)         31662.9773844718
Epoch                        458
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:03:15.781457 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #458 | Epoch Duration: 73.96140170097351
2020-01-11 12:03:15.781714 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #458 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0865064
Z variance train             0.015387021
KL Divergence                23.221756
KL Loss                      2.3221757
QF Loss                      1018.1295
VF Loss                      197.69557
Policy Loss                  -1379.5796
Q Predictions Mean           1378.9758
Q Predictions Std            237.72296
Q Predictions Max            1623.8405
Q Predictions Min            -44.171944
V Predictions Mean           1371.0674
V Predictions Std            238.56664
V Predictions Max            1591.3582
V Predictions Min            -51.523376
Log Pis Mean                 0.48005286
Log Pis Std                  2.6951275
Log Pis Max                  13.184718
Log Pis Min                  -4.7181463
Policy mu Mean               0.075120896
Policy mu Std                0.6049716
Policy mu Max                2.2277417
Policy mu Min                -2.4792655
Policy log std Mean          -1.1102161
Policy log std Std           0.29058632
Policy log std Max           -0.18963903
Policy log std Min           -3.2883348
Z mean eval                  1.0824351
Z variance eval              0.012338904
total_rewards                [2986.925425   3811.97501069 3748.92489702  498.44647899 3740.79538154
 3941.85288997  373.32099579 4178.15924536 4086.80002667 3873.96880304]
total_rewards_mean           3124.116915406961
total_rewards_std            1378.1293489495029
total_rewards_max            4178.159245359569
total_rewards_min            373.32099578509207
Number of train steps total  460000
Number of env steps total    2302000
Number of rollouts total     0
Train Time (s)               29.317169232293963
(Previous) Eval Time (s)     26.826454396825284
Sample Time (s)              18.536416373681277
Epoch Time (s)               74.68004000280052
Total Train Time (s)         31734.450252521317
Epoch                        459
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:04:27.261255 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #459 | Epoch Duration: 71.47931981086731
2020-01-11 12:04:27.261542 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #459 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.082517
Z variance train             0.012336068
KL Divergence                24.049376
KL Loss                      2.4049375
QF Loss                      1696.9991
VF Loss                      332.4685
Policy Loss                  -1367.889
Q Predictions Mean           1368.7671
Q Predictions Std            311.1323
Q Predictions Max            1623.8966
Q Predictions Min            -78.79816
V Predictions Mean           1376.6235
V Predictions Std            306.81668
V Predictions Max            1635.6736
V Predictions Min            -65.24351
Log Pis Mean                 0.76885355
Log Pis Std                  2.8970888
Log Pis Max                  11.961159
Log Pis Min                  -6.409392
Policy mu Mean               0.021683853
Policy mu Std                0.6605351
Policy mu Max                2.8217618
Policy mu Min                -2.4836574
Policy log std Mean          -1.0348175
Policy log std Std           0.30183598
Policy log std Max           -0.14972526
Policy log std Min           -2.7188206
Z mean eval                  1.0775121
Z variance eval              0.013546589
total_rewards                [4141.76412025 3914.87298362  309.58037326 4001.41735361 3496.92478023
 3584.69363335 3829.64140304 3657.84520384 1791.52280208 3941.09776265]
total_rewards_mean           3266.936041592501
total_rewards_std            1171.5465015178527
total_rewards_max            4141.764120247316
total_rewards_min            309.5803732589222
Number of train steps total  461000
Number of env steps total    2307000
Number of rollouts total     0
Train Time (s)               29.694924669340253
(Previous) Eval Time (s)     23.625451458152384
Sample Time (s)              17.774020954035223
Epoch Time (s)               71.09439708152786
Total Train Time (s)         31804.629081483465
Epoch                        460
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:05:37.444263 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #460 | Epoch Duration: 70.18251466751099
2020-01-11 12:05:37.444423 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #460 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0784876
Z variance train             0.013513456
KL Divergence                23.069553
KL Loss                      2.3069553
QF Loss                      760.3934
VF Loss                      311.15518
Policy Loss                  -1400.2574
Q Predictions Mean           1401.6517
Q Predictions Std            238.27109
Q Predictions Max            1616.3932
Q Predictions Min            -97.85625
V Predictions Mean           1409.3105
V Predictions Std            236.05962
V Predictions Max            1627.008
V Predictions Min            -101.65543
Log Pis Mean                 0.7352971
Log Pis Std                  2.9597526
Log Pis Max                  18.834904
Log Pis Min                  -13.240385
Policy mu Mean               0.027320638
Policy mu Std                0.65708774
Policy mu Max                3.4232087
Policy mu Min                -2.7739878
Policy log std Mean          -1.0586843
Policy log std Std           0.28496552
Policy log std Max           0.22555196
Policy log std Min           -2.4452622
Z mean eval                  1.0677361
Z variance eval              0.008135353
total_rewards                [ 883.90971135 1067.96454385 3832.18570677 4046.59933965 3907.45180923
 1222.45614533 3851.07849809 3433.31962133  246.39250082 3983.11906872]
total_rewards_mean           2647.447694516006
total_rewards_std            1489.955699646891
total_rewards_max            4046.5993396495546
total_rewards_min            246.39250082433676
Number of train steps total  462000
Number of env steps total    2312000
Number of rollouts total     0
Train Time (s)               30.447391911409795
(Previous) Eval Time (s)     22.71328029828146
Sample Time (s)              18.154194094240665
Epoch Time (s)               71.31486630393192
Total Train Time (s)         31871.69262360502
Epoch                        461
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:06:44.513479 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #461 | Epoch Duration: 67.06889581680298
2020-01-11 12:06:44.513750 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #461 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.06925
Z variance train             0.008135505
KL Divergence                24.088247
KL Loss                      2.4088247
QF Loss                      1480.0562
VF Loss                      287.00497
Policy Loss                  -1394.7943
Q Predictions Mean           1393.0929
Q Predictions Std            208.3188
Q Predictions Max            1623.9764
Q Predictions Min            5.480918
V Predictions Mean           1384.8934
V Predictions Std            204.98723
V Predictions Max            1612.4445
V Predictions Min            -21.120031
Log Pis Mean                 0.6351534
Log Pis Std                  2.787583
Log Pis Max                  18.231575
Log Pis Min                  -6.220312
Policy mu Mean               0.0647221
Policy mu Std                0.5927191
Policy mu Max                2.1765876
Policy mu Min                -2.146244
Policy log std Mean          -1.1055863
Policy log std Std           0.26951253
Policy log std Max           -0.2369067
Policy log std Min           -3.6854515
Z mean eval                  1.0762959
Z variance eval              0.011386721
total_rewards                [4128.17295499 3842.72368885 3804.94013416 3962.0974448  3739.18401744
  615.35166905 3801.4526125  4133.70837148 3999.24703226 4048.97504036]
total_rewards_mean           3607.585296588997
total_rewards_std            1006.1969748043971
total_rewards_max            4133.708371482591
total_rewards_min            615.3516690487229
Number of train steps total  463000
Number of env steps total    2317000
Number of rollouts total     0
Train Time (s)               29.574937601108104
(Previous) Eval Time (s)     18.46697222115472
Sample Time (s)              18.35427095880732
Epoch Time (s)               66.39618078107014
Total Train Time (s)         31944.26143216295
Epoch                        462
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:07:57.085619 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #462 | Epoch Duration: 72.5716757774353
2020-01-11 12:07:57.085795 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #462 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0764334
Z variance train             0.011329441
KL Divergence                23.731419
KL Loss                      2.373142
QF Loss                      751.27893
VF Loss                      154.1344
Policy Loss                  -1395.1572
Q Predictions Mean           1396.66
Q Predictions Std            235.80661
Q Predictions Max            1630.6016
Q Predictions Min            -47.68991
V Predictions Mean           1401.2744
V Predictions Std            235.40988
V Predictions Max            1637.3054
V Predictions Min            -35.47266
Log Pis Mean                 1.2981796
Log Pis Std                  2.6848264
Log Pis Max                  14.52965
Log Pis Min                  -4.688011
Policy mu Mean               -0.011046826
Policy mu Std                0.6464905
Policy mu Max                2.6490912
Policy mu Min                -2.8716433
Policy log std Mean          -1.1060617
Policy log std Std           0.30043498
Policy log std Max           -0.089722335
Policy log std Min           -3.0563054
Z mean eval                  1.1250994
Z variance eval              0.0058645224
total_rewards                [3953.4070025  3839.50481154 2679.25615569 1047.28569659 3770.49781346
  931.82419606 1801.07400815 4165.66382667 3376.5235938  1204.57683736]
total_rewards_mean           2676.9613941800835
total_rewards_std            1245.741212045302
total_rewards_max            4165.663826670275
total_rewards_min            931.824196055031
Number of train steps total  464000
Number of env steps total    2322000
Number of rollouts total     0
Train Time (s)               28.52777083031833
(Previous) Eval Time (s)     24.642132255248725
Sample Time (s)              18.55962284654379
Epoch Time (s)               71.72952593211085
Total Train Time (s)         32010.70213933289
Epoch                        463
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:09:03.533184 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #463 | Epoch Duration: 66.44722414016724
2020-01-11 12:09:03.533439 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #463 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.125769
Z variance train             0.005845685
KL Divergence                25.064388
KL Loss                      2.506439
QF Loss                      8112.8447
VF Loss                      991.28375
Policy Loss                  -1391.0691
Q Predictions Mean           1399.992
Q Predictions Std            267.70004
Q Predictions Max            1622.2458
Q Predictions Min            -80.29511
V Predictions Mean           1400.0295
V Predictions Std            270.24036
V Predictions Max            1625.942
V Predictions Min            -64.88725
Log Pis Mean                 1.3197262
Log Pis Std                  3.0637648
Log Pis Max                  13.891224
Log Pis Min                  -6.5852795
Policy mu Mean               -0.05958164
Policy mu Std                0.701224
Policy mu Max                2.6506934
Policy mu Min                -3.6044023
Policy log std Mean          -1.0680103
Policy log std Std           0.32341862
Policy log std Max           -0.17173475
Policy log std Min           -2.9692073
Z mean eval                  1.085866
Z variance eval              0.012203334
total_rewards                [3056.26040589  285.07331737  392.10400484 2602.38439448 4011.25740335
 2290.5579995    67.53231532   93.05266382 2996.23135479  575.11183496]
total_rewards_mean           1636.956569432254
total_rewards_std            1421.6220918740019
total_rewards_max            4011.25740334939
total_rewards_min            67.53231532074923
Number of train steps total  465000
Number of env steps total    2327000
Number of rollouts total     0
Train Time (s)               28.78531481605023
(Previous) Eval Time (s)     19.359498501755297
Sample Time (s)              18.02837149007246
Epoch Time (s)               66.17318480787799
Total Train Time (s)         32070.410295757465
Epoch                        464
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:10:03.245474 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #464 | Epoch Duration: 59.711849212646484
2020-01-11 12:10:03.245666 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #464 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.084232
Z variance train             0.012161488
KL Divergence                23.372946
KL Loss                      2.3372946
QF Loss                      6786.8306
VF Loss                      210.26302
Policy Loss                  -1381.3042
Q Predictions Mean           1380.7122
Q Predictions Std            252.87242
Q Predictions Max            1635.9398
Q Predictions Min            -83.64698
V Predictions Mean           1382.2368
V Predictions Std            243.1667
V Predictions Max            1628.5126
V Predictions Min            -71.71966
Log Pis Mean                 1.0153638
Log Pis Std                  2.8810413
Log Pis Max                  11.321984
Log Pis Min                  -8.1404085
Policy mu Mean               0.0018932663
Policy mu Std                0.6388944
Policy mu Max                2.3607452
Policy mu Min                -2.7424679
Policy log std Mean          -1.1001812
Policy log std Std           0.3067739
Policy log std Max           -0.2293716
Policy log std Min           -3.1037223
Z mean eval                  1.080426
Z variance eval              0.013373582
total_rewards                [3981.32041345 4094.51109109 3875.37512745 4256.30602043 3798.09662685
  860.73692196 3867.69523862 4248.56143494 3542.15025362 4112.91902748]
total_rewards_mean           3663.7672155888627
total_rewards_std            956.9421421488615
total_rewards_max            4256.306020431541
total_rewards_min            860.7369219623597
Number of train steps total  466000
Number of env steps total    2332000
Number of rollouts total     0
Train Time (s)               31.601566702127457
(Previous) Eval Time (s)     12.89787045866251
Sample Time (s)              17.675252890214324
Epoch Time (s)               62.17469005100429
Total Train Time (s)         32146.246726593934
Epoch                        465
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:11:19.086485 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #465 | Epoch Duration: 75.84067487716675
2020-01-11 12:11:19.086712 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #465 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.080226
Z variance train             0.013507003
KL Divergence                23.391401
KL Loss                      2.3391402
QF Loss                      4334.227
VF Loss                      958.3298
Policy Loss                  -1389.4758
Q Predictions Mean           1388.063
Q Predictions Std            272.27502
Q Predictions Max            1624.3849
Q Predictions Min            -89.43961
V Predictions Mean           1375.1655
V Predictions Std            267.0549
V Predictions Max            1618.5015
V Predictions Min            -89.60887
Log Pis Mean                 1.014451
Log Pis Std                  2.974439
Log Pis Max                  13.773092
Log Pis Min                  -11.602759
Policy mu Mean               0.041334674
Policy mu Std                0.6578067
Policy mu Max                3.074046
Policy mu Min                -2.5224767
Policy log std Mean          -1.0662048
Policy log std Std           0.29237837
Policy log std Max           -0.03129089
Policy log std Min           -2.919458
Z mean eval                  1.1207589
Z variance eval              0.009911003
total_rewards                [2577.89260044 4153.43552597 4003.10020378 4050.11384695 3854.45912791
 3599.71527616 4003.45449334 4009.13406363 3817.79575669 2634.38942827]
total_rewards_mean           3670.3490323149003
total_rewards_std            551.4844794370381
total_rewards_max            4153.435525970397
total_rewards_min            2577.892600439238
Number of train steps total  467000
Number of env steps total    2337000
Number of rollouts total     0
Train Time (s)               29.32144682155922
(Previous) Eval Time (s)     26.56353534385562
Sample Time (s)              19.191311849281192
Epoch Time (s)               75.07629401469603
Total Train Time (s)         32219.69369828375
Epoch                        466
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:12:32.537023 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #466 | Epoch Duration: 73.45017623901367
2020-01-11 12:12:32.537309 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #466 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1203436
Z variance train             0.009886744
KL Divergence                23.76534
KL Loss                      2.3765342
QF Loss                      1572.5503
VF Loss                      292.80615
Policy Loss                  -1374.0531
Q Predictions Mean           1373.9355
Q Predictions Std            301.61392
Q Predictions Max            1629.7102
Q Predictions Min            -128.55046
V Predictions Mean           1368.897
V Predictions Std            301.42618
V Predictions Max            1612.3336
V Predictions Min            -113.00409
Log Pis Mean                 0.7827728
Log Pis Std                  2.7818375
Log Pis Max                  13.523774
Log Pis Min                  -7.0334654
Policy mu Mean               0.02281069
Policy mu Std                0.61205655
Policy mu Max                3.0175169
Policy mu Min                -2.835216
Policy log std Mean          -1.0945718
Policy log std Std           0.29419273
Policy log std Max           -0.19449359
Policy log std Min           -2.8826241
Z mean eval                  1.1242311
Z variance eval              0.010002458
total_rewards                [4018.45281676  469.4324333  4115.52880076 4297.76314385   42.7624017
 4189.04552889 3022.59318965 4053.87769811 2889.345756   3184.03204181]
total_rewards_mean           3028.2833810830657
total_rewards_std            1472.34428132441
total_rewards_max            4297.763143845812
total_rewards_min            42.76240169817065
Number of train steps total  468000
Number of env steps total    2342000
Number of rollouts total     0
Train Time (s)               28.708277623169124
(Previous) Eval Time (s)     24.937064005061984
Sample Time (s)              17.97645400231704
Epoch Time (s)               71.62179563054815
Total Train Time (s)         32289.329437914304
Epoch                        467
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:13:42.181666 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #467 | Epoch Duration: 69.64418029785156
2020-01-11 12:13:42.181953 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #467 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1235874
Z variance train             0.009992278
KL Divergence                23.393536
KL Loss                      2.3393536
QF Loss                      708.0995
VF Loss                      406.4903
Policy Loss                  -1411.7493
Q Predictions Mean           1412.3362
Q Predictions Std            207.09517
Q Predictions Max            1619.2938
Q Predictions Min            -139.44151
V Predictions Mean           1412.7078
V Predictions Std            205.07004
V Predictions Max            1615.3324
V Predictions Min            -128.01648
Log Pis Mean                 1.0306237
Log Pis Std                  2.9097133
Log Pis Max                  9.464571
Log Pis Min                  -7.006626
Policy mu Mean               -0.012437216
Policy mu Std                0.67451036
Policy mu Max                2.6208422
Policy mu Min                -2.2107174
Policy log std Mean          -1.0906285
Policy log std Std           0.28555351
Policy log std Max           -0.07527381
Policy log std Min           -2.6042466
Z mean eval                  1.0946778
Z variance eval              0.007789175
total_rewards                [1766.30643595  321.68424336   91.86827273 4061.7569365  3286.73008163
 4123.72464903 4205.87844306 3783.43158733 4110.26307275  476.02585626]
total_rewards_mean           2622.7669578604814
total_rewards_std            1669.5177155018087
total_rewards_max            4205.878443060918
total_rewards_min            91.86827273481765
Number of train steps total  469000
Number of env steps total    2347000
Number of rollouts total     0
Train Time (s)               29.66373254545033
(Previous) Eval Time (s)     22.95911307260394
Sample Time (s)              18.25801516743377
Epoch Time (s)               70.88086078548804
Total Train Time (s)         32360.204245259054
Epoch                        468
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:14:53.060792 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #468 | Epoch Duration: 70.8785891532898
2020-01-11 12:14:53.061067 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #468 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0934821
Z variance train             0.0077958903
KL Divergence                24.248405
KL Loss                      2.4248407
QF Loss                      1086.8251
VF Loss                      275.37952
Policy Loss                  -1400.8911
Q Predictions Mean           1402.1924
Q Predictions Std            274.6348
Q Predictions Max            1660.0282
Q Predictions Min            -102.07592
V Predictions Mean           1389.418
V Predictions Std            274.38004
V Predictions Max            1650.6271
V Predictions Min            -111.94751
Log Pis Mean                 0.7022408
Log Pis Std                  3.093421
Log Pis Max                  13.1786785
Log Pis Min                  -8.47232
Policy mu Mean               0.034559786
Policy mu Std                0.6413632
Policy mu Max                3.309947
Policy mu Min                -2.8976665
Policy log std Mean          -1.0838084
Policy log std Std           0.2847894
Policy log std Max           -0.16068959
Policy log std Min           -2.410006
Z mean eval                  1.063735
Z variance eval              0.010783081
total_rewards                [3117.66192203 4276.05025301 2771.11965254 1203.33631383 4220.39283909
 3968.8350746  4085.93114239 4247.38134907 4195.54690923 2851.17164037]
total_rewards_mean           3493.7427096156925
total_rewards_std            953.9080464090736
total_rewards_max            4276.050253011063
total_rewards_min            1203.3363138342586
Number of train steps total  470000
Number of env steps total    2352000
Number of rollouts total     0
Train Time (s)               29.571667273063213
(Previous) Eval Time (s)     22.95652961404994
Sample Time (s)              17.956216755788773
Epoch Time (s)               70.48441364290193
Total Train Time (s)         32431.285268584732
Epoch                        469
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:16:04.144671 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #469 | Epoch Duration: 71.08340525627136
2020-01-11 12:16:04.144880 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #469 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0622966
Z variance train             0.010798576
KL Divergence                24.000492
KL Loss                      2.4000492
QF Loss                      870.34424
VF Loss                      598.87744
Policy Loss                  -1428.9094
Q Predictions Mean           1434.3898
Q Predictions Std            212.13269
Q Predictions Max            1658.7349
Q Predictions Min            -76.28758
V Predictions Mean           1424.6606
V Predictions Std            204.83742
V Predictions Max            1646.7056
V Predictions Min            -80.713486
Log Pis Mean                 1.1026385
Log Pis Std                  2.756267
Log Pis Max                  12.588972
Log Pis Min                  -10.521227
Policy mu Mean               0.009742767
Policy mu Std                0.6600313
Policy mu Max                2.6070125
Policy mu Min                -2.410822
Policy log std Mean          -1.0985557
Policy log std Std           0.276495
Policy log std Max           -0.20539069
Policy log std Min           -2.8135936
Z mean eval                  1.0853002
Z variance eval              0.0115347635
total_rewards                [ 990.48294865 1418.45039211 4083.3591828  4335.1774251  3840.48028256
  301.76296296 4001.25418079 4022.63334261 4114.74255431 2185.88132689]
total_rewards_mean           2929.422459878297
total_rewards_std            1462.4168763824362
total_rewards_max            4335.177425097128
total_rewards_min            301.76296296442604
Number of train steps total  471000
Number of env steps total    2357000
Number of rollouts total     0
Train Time (s)               30.469227354042232
(Previous) Eval Time (s)     23.5552273937501
Sample Time (s)              18.032830588519573
Epoch Time (s)               72.0572853363119
Total Train Time (s)         32499.47510884842
Epoch                        470
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:17:12.338376 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #470 | Epoch Duration: 68.19335055351257
2020-01-11 12:17:12.338559 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #470 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0845665
Z variance train             0.011533765
KL Divergence                23.44046
KL Loss                      2.344046
QF Loss                      6976.446
VF Loss                      487.39276
Policy Loss                  -1401.5942
Q Predictions Mean           1405.3303
Q Predictions Std            263.2489
Q Predictions Max            1674.4402
Q Predictions Min            -91.67714
V Predictions Mean           1417.013
V Predictions Std            266.9129
V Predictions Max            1675.3395
V Predictions Min            -99.36669
Log Pis Mean                 1.1035302
Log Pis Std                  2.9970963
Log Pis Max                  16.609352
Log Pis Min                  -6.306489
Policy mu Mean               -0.038073175
Policy mu Std                0.64775866
Policy mu Max                3.0539281
Policy mu Min                -2.5376706
Policy log std Mean          -1.1153584
Policy log std Std           0.2851139
Policy log std Max           0.059633136
Policy log std Min           -2.238245
Z mean eval                  1.1219347
Z variance eval              0.010392066
total_rewards                [2172.84600577  346.70755587 4402.40955775   73.53992951 3799.08679793
 1389.46720616 2014.68471847 1983.07517417 4248.33564109 4197.24019003]
total_rewards_mean           2462.7392776746788
total_rewards_std            1536.152291931533
total_rewards_max            4402.409557746816
total_rewards_min            73.5399295055712
Number of train steps total  472000
Number of env steps total    2362000
Number of rollouts total     0
Train Time (s)               29.38429060904309
(Previous) Eval Time (s)     19.690999762155116
Sample Time (s)              18.728483581915498
Epoch Time (s)               67.8037739531137
Total Train Time (s)         32563.193874282762
Epoch                        471
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:18:16.060833 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #471 | Epoch Duration: 63.72212600708008
2020-01-11 12:18:16.061025 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #471 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1221114
Z variance train             0.010396204
KL Divergence                23.669386
KL Loss                      2.3669386
QF Loss                      795.57227
VF Loss                      198.34753
Policy Loss                  -1379.4523
Q Predictions Mean           1380.086
Q Predictions Std            310.6291
Q Predictions Max            1641.4038
Q Predictions Min            -102.1185
V Predictions Mean           1387.1571
V Predictions Std            313.37057
V Predictions Max            1640.4294
V Predictions Min            -116.98716
Log Pis Mean                 0.9407251
Log Pis Std                  3.3134804
Log Pis Max                  27.82128
Log Pis Min                  -8.000745
Policy mu Mean               0.004430885
Policy mu Std                0.67948794
Policy mu Max                7.119903
Policy mu Min                -3.716514
Policy log std Mean          -1.0999963
Policy log std Std           0.28186798
Policy log std Max           0.42045337
Policy log std Min           -2.7016919
Z mean eval                  1.0920125
Z variance eval              0.006665739
total_rewards                [3644.33775742 3993.82775541 -278.3320153  3762.03833595 4163.48613263
 3844.20550878 4008.98447928 1460.71264699 4118.94816663 1408.01409137]
total_rewards_mean           3012.622285915693
total_rewards_std            1482.2191824869192
total_rewards_max            4163.486132633575
total_rewards_min            -278.3320152954788
Number of train steps total  473000
Number of env steps total    2367000
Number of rollouts total     0
Train Time (s)               30.07652655802667
(Previous) Eval Time (s)     15.608975965995342
Sample Time (s)              18.661186858080328
Epoch Time (s)               64.34668938210234
Total Train Time (s)         32635.261206837837
Epoch                        472
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:19:28.133439 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #472 | Epoch Duration: 72.07226085662842
2020-01-11 12:19:28.133658 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #472 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0878656
Z variance train             0.0066564605
KL Divergence                24.571857
KL Loss                      2.4571857
QF Loss                      2463.219
VF Loss                      362.73315
Policy Loss                  -1422.3531
Q Predictions Mean           1422.1455
Q Predictions Std            228.39911
Q Predictions Max            1692.1721
Q Predictions Min            32.321552
V Predictions Mean           1426.3142
V Predictions Std            223.33736
V Predictions Max            1686.7747
V Predictions Min            31.321598
Log Pis Mean                 1.3029957
Log Pis Std                  2.9526808
Log Pis Max                  12.962264
Log Pis Min                  -5.466115
Policy mu Mean               0.007714193
Policy mu Std                0.65418756
Policy mu Max                2.3503761
Policy mu Min                -2.519532
Policy log std Mean          -1.1228838
Policy log std Std           0.29941088
Policy log std Max           -0.123006105
Policy log std Min           -3.2491474
Z mean eval                  1.0780809
Z variance eval              0.0062578097
total_rewards                [ -14.33415439 4001.45636353 4013.07295581  665.0612795    69.19659327
 1276.71731505 3879.60350199  257.29336676 2101.99644665 4352.06024796]
total_rewards_mean           2060.2123916141154
total_rewards_std            1738.5426227077298
total_rewards_max            4352.060247963646
total_rewards_min            -14.334154390531499
Number of train steps total  474000
Number of env steps total    2372000
Number of rollouts total     0
Train Time (s)               29.98587130662054
(Previous) Eval Time (s)     23.334194963797927
Sample Time (s)              18.029814942274243
Epoch Time (s)               71.34988121269271
Total Train Time (s)         32696.735208578873
Epoch                        473
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:20:29.614774 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #473 | Epoch Duration: 61.48091435432434
2020-01-11 12:20:29.615059 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #473 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.07922
Z variance train             0.0062663564
KL Divergence                24.574251
KL Loss                      2.457425
QF Loss                      834.84314
VF Loss                      196.17236
Policy Loss                  -1431.8372
Q Predictions Mean           1436.3203
Q Predictions Std            223.99417
Q Predictions Max            1666.2186
Q Predictions Min            44.85973
V Predictions Mean           1428.5935
V Predictions Std            224.23154
V Predictions Max            1662.5797
V Predictions Min            35.210777
Log Pis Mean                 1.12853
Log Pis Std                  2.94518
Log Pis Max                  14.468722
Log Pis Min                  -7.106678
Policy mu Mean               -0.022606475
Policy mu Std                0.6830027
Policy mu Max                2.6785862
Policy mu Min                -2.8962379
Policy log std Mean          -1.1076785
Policy log std Std           0.2751623
Policy log std Max           -0.048196793
Policy log std Min           -2.1653903
Z mean eval                  1.084914
Z variance eval              0.006871774
total_rewards                [4036.98362279 4378.6759957  1964.39033607 4341.64114181 4376.54018016
 4041.30437059 4187.37502703 4035.34311135 1394.2246522  4372.20241276]
total_rewards_mean           3712.8680850460623
total_rewards_std            1033.885303102672
total_rewards_max            4378.6759956964115
total_rewards_min            1394.2246522013138
Number of train steps total  475000
Number of env steps total    2377000
Number of rollouts total     0
Train Time (s)               27.82839407166466
(Previous) Eval Time (s)     13.464919872116297
Sample Time (s)              17.444556607864797
Epoch Time (s)               58.737870551645756
Total Train Time (s)         32765.40212785825
Epoch                        474
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:21:38.288003 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #474 | Epoch Duration: 68.6727294921875
2020-01-11 12:21:38.288224 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #474 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0839814
Z variance train             0.0068804086
KL Divergence                24.537899
KL Loss                      2.45379
QF Loss                      1630.2544
VF Loss                      278.75952
Policy Loss                  -1383.0516
Q Predictions Mean           1383.9409
Q Predictions Std            319.8455
Q Predictions Max            1674.2039
Q Predictions Min            -125.07517
V Predictions Mean           1384.9675
V Predictions Std            321.86948
V Predictions Max            1628.9636
V Predictions Min            -135.31985
Log Pis Mean                 0.9380474
Log Pis Std                  2.723691
Log Pis Max                  9.721958
Log Pis Min                  -9.035697
Policy mu Mean               0.07468772
Policy mu Std                0.62889
Policy mu Max                2.3404891
Policy mu Min                -2.4559824
Policy log std Mean          -1.0963851
Policy log std Std           0.3094518
Policy log std Max           -0.07606411
Policy log std Min           -2.706281
Z mean eval                  1.0794997
Z variance eval              0.009628082
total_rewards                [3979.12946503  241.27111198 3870.87085372  749.99239273 3934.88161718
 1967.74010593  287.43015623   41.3794019  3818.75980827 2451.30661386]
total_rewards_mean           2134.2761526814634
total_rewards_std            1609.9043216573646
total_rewards_max            3979.129465031735
total_rewards_min            41.37940189538802
Number of train steps total  476000
Number of env steps total    2382000
Number of rollouts total     0
Train Time (s)               30.52596286404878
(Previous) Eval Time (s)     23.399510846938938
Sample Time (s)              17.429665431380272
Epoch Time (s)               71.35513914236799
Total Train Time (s)         32829.612401483115
Epoch                        475
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:22:42.503176 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #475 | Epoch Duration: 64.21478009223938
2020-01-11 12:22:42.503385 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #475 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0789487
Z variance train             0.009589122
KL Divergence                24.436247
KL Loss                      2.4436247
QF Loss                      1333.7153
VF Loss                      244.91658
Policy Loss                  -1421.0304
Q Predictions Mean           1418.3175
Q Predictions Std            253.29588
Q Predictions Max            1643.2885
Q Predictions Min            -20.775532
V Predictions Mean           1418.3901
V Predictions Std            246.78317
V Predictions Max            1660.6302
V Predictions Min            1.9139247
Log Pis Mean                 1.1480381
Log Pis Std                  3.1793215
Log Pis Max                  13.725923
Log Pis Min                  -9.1830845
Policy mu Mean               -0.015262523
Policy mu Std                0.6303736
Policy mu Max                2.2759383
Policy mu Min                -2.990157
Policy log std Mean          -1.1508043
Policy log std Std           0.3012473
Policy log std Max           -0.15286559
Policy log std Min           -2.7816942
Z mean eval                  1.1496024
Z variance eval              0.013229905
total_rewards                [4173.51897171 1363.83310375 4036.68061907 4211.87304642 3189.69448682
 4204.98406354 4056.26855729 4330.65684077 4439.79089765  889.76442481]
total_rewards_mean           3489.7065011829136
total_rewards_std            1228.8132811546543
total_rewards_max            4439.790897654392
total_rewards_min            889.7644248062667
Number of train steps total  477000
Number of env steps total    2387000
Number of rollouts total     0
Train Time (s)               27.56529990117997
(Previous) Eval Time (s)     16.258848522324115
Sample Time (s)              17.856268452014774
Epoch Time (s)               61.68041687551886
Total Train Time (s)         32897.31525086751
Epoch                        476
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:23:50.212056 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #476 | Epoch Duration: 67.70847487449646
2020-01-11 12:23:50.212357 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #476 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1508048
Z variance train             0.013265036
KL Divergence                24.324512
KL Loss                      2.4324512
QF Loss                      822.241
VF Loss                      117.71231
Policy Loss                  -1459.4988
Q Predictions Mean           1461.0004
Q Predictions Std            218.7905
Q Predictions Max            1659.7662
Q Predictions Min            -116.89032
V Predictions Mean           1462.1172
V Predictions Std            216.87228
V Predictions Max            1658.2021
V Predictions Min            -108.34395
Log Pis Mean                 1.2392881
Log Pis Std                  2.9132156
Log Pis Max                  10.219845
Log Pis Min                  -8.160822
Policy mu Mean               0.012347225
Policy mu Std                0.68416464
Policy mu Max                3.177831
Policy mu Min                -2.3346944
Policy log std Mean          -1.1066234
Policy log std Std           0.2773788
Policy log std Max           0.16197747
Policy log std Min           -2.3120217
Z mean eval                  1.1116714
Z variance eval              0.012577449
total_rewards                [4115.72771805 3828.95292309 4029.15001834 3209.04015285 3915.30353909
 4326.39561144 4206.40831825 3920.08044376 3908.71173747 4026.9987786 ]
total_rewards_mean           3948.6769240928697
total_rewards_std            285.4011607037828
total_rewards_max            4326.395611439242
total_rewards_min            3209.0401528456773
Number of train steps total  478000
Number of env steps total    2392000
Number of rollouts total     0
Train Time (s)               30.712526015006006
(Previous) Eval Time (s)     22.286585413850844
Sample Time (s)              18.688925730995834
Epoch Time (s)               71.68803715985268
Total Train Time (s)         32973.2213122542
Epoch                        477
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:25:06.120738 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #477 | Epoch Duration: 75.90818238258362
2020-01-11 12:25:06.120888 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #477 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1128725
Z variance train             0.012609003
KL Divergence                24.360151
KL Loss                      2.4360151
QF Loss                      1241.4214
VF Loss                      224.9638
Policy Loss                  -1409.1626
Q Predictions Mean           1409.7825
Q Predictions Std            288.14713
Q Predictions Max            1675.7064
Q Predictions Min            11.047518
V Predictions Mean           1418.1345
V Predictions Std            290.35852
V Predictions Max            1673.9481
V Predictions Min            -6.043947
Log Pis Mean                 1.1353197
Log Pis Std                  2.9338226
Log Pis Max                  11.4841175
Log Pis Min                  -6.145811
Policy mu Mean               -0.019807242
Policy mu Std                0.65142304
Policy mu Max                2.9864352
Policy mu Min                -2.6917112
Policy log std Mean          -1.1243145
Policy log std Std           0.29482538
Policy log std Max           -0.22631264
Policy log std Min           -2.497013
Z mean eval                  1.1062957
Z variance eval              0.009483828
total_rewards                [1400.82702722 3745.61032419 3998.65814841 4471.54653392 2821.8789778
 4127.70691648 1537.02979698 4141.6063651   824.50285383 4573.30902711]
total_rewards_mean           3164.267597105081
total_rewards_std            1340.1978898759148
total_rewards_max            4573.309027113695
total_rewards_min            824.5028538281312
Number of train steps total  479000
Number of env steps total    2397000
Number of rollouts total     0
Train Time (s)               29.742460242006928
(Previous) Eval Time (s)     26.50644123274833
Sample Time (s)              17.993042377755046
Epoch Time (s)               74.2419438525103
Total Train Time (s)         33044.69520605309
Epoch                        478
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:26:17.602855 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #478 | Epoch Duration: 71.48179078102112
2020-01-11 12:26:17.603202 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #478 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1050433
Z variance train             0.00948892
KL Divergence                24.854753
KL Loss                      2.4854753
QF Loss                      1076.3313
VF Loss                      115.37928
Policy Loss                  -1405.6699
Q Predictions Mean           1403.182
Q Predictions Std            267.15106
Q Predictions Max            1655.8904
Q Predictions Min            -208.06055
V Predictions Mean           1408.4819
V Predictions Std            264.27597
V Predictions Max            1641.5068
V Predictions Min            -182.66353
Log Pis Mean                 0.7367197
Log Pis Std                  2.8827596
Log Pis Max                  9.90599
Log Pis Min                  -5.8599024
Policy mu Mean               0.011914157
Policy mu Std                0.6571141
Policy mu Max                2.3907983
Policy mu Min                -2.6837082
Policy log std Mean          -1.073963
Policy log std Std           0.2680504
Policy log std Max           0.07780665
Policy log std Min           -2.1740165
Z mean eval                  1.0685403
Z variance eval              0.010629169
total_rewards                [3485.89571312 3274.165699   3906.42232335 1049.03923185 3830.41143521
 2669.19430084 4160.32495934 3855.14478277 3485.2204062  3773.39007721]
total_rewards_mean           3348.920892889081
total_rewards_std            862.082719575593
total_rewards_max            4160.32495933622
total_rewards_min            1049.0392318546833
Number of train steps total  480000
Number of env steps total    2402000
Number of rollouts total     0
Train Time (s)               28.079137197695673
(Previous) Eval Time (s)     23.745963140390813
Sample Time (s)              17.63641756726429
Epoch Time (s)               69.46151790535077
Total Train Time (s)         33114.95933220629
Epoch                        479
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:27:27.869406 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #479 | Epoch Duration: 70.26598525047302
2020-01-11 12:27:27.869593 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #479 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0677938
Z variance train             0.010576499
KL Divergence                24.388144
KL Loss                      2.4388144
QF Loss                      972.0615
VF Loss                      192.36526
Policy Loss                  -1418.447
Q Predictions Mean           1415.4055
Q Predictions Std            233.56622
Q Predictions Max            1667.1727
Q Predictions Min            -57.843693
V Predictions Mean           1419.1243
V Predictions Std            235.02034
V Predictions Max            1655.2161
V Predictions Min            -88.20698
Log Pis Mean                 1.1001773
Log Pis Std                  2.867877
Log Pis Max                  11.700023
Log Pis Min                  -6.376766
Policy mu Mean               0.034458376
Policy mu Std                0.66107357
Policy mu Max                2.5332642
Policy mu Min                -2.666053
Policy log std Mean          -1.1028746
Policy log std Std           0.2854381
Policy log std Max           -0.15154845
Policy log std Min           -2.719668
Z mean eval                  1.0887096
Z variance eval              0.009955493
total_rewards                [3952.98422281 4258.54074219 3838.44168192 3925.56584543 2987.29068634
 1363.59383103 4246.32701474 4355.13788852 3985.15617094 4198.87347632]
total_rewards_mean           3711.1911560233893
total_rewards_std            864.2556570400235
total_rewards_max            4355.137888516659
total_rewards_min            1363.5938310282218
Number of train steps total  481000
Number of env steps total    2407000
Number of rollouts total     0
Train Time (s)               26.49729222524911
(Previous) Eval Time (s)     24.55016425391659
Sample Time (s)              18.52179751638323
Epoch Time (s)               69.56925399554893
Total Train Time (s)         33183.7104790858
Epoch                        480
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:28:36.625962 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #480 | Epoch Duration: 68.75623035430908
2020-01-11 12:28:36.626174 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #480 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0906904
Z variance train             0.00994402
KL Divergence                24.82131
KL Loss                      2.482131
QF Loss                      918.0179
VF Loss                      325.08197
Policy Loss                  -1430.0591
Q Predictions Mean           1432.0486
Q Predictions Std            298.88702
Q Predictions Max            1723.7794
Q Predictions Min            -128.25543
V Predictions Mean           1427.1029
V Predictions Std            301.90524
V Predictions Max            1702.1125
V Predictions Min            -151.81305
Log Pis Mean                 0.98075277
Log Pis Std                  3.2369063
Log Pis Max                  14.876493
Log Pis Min                  -8.694649
Policy mu Mean               0.022764511
Policy mu Std                0.6454744
Policy mu Max                2.3080943
Policy mu Min                -2.5615053
Policy log std Mean          -1.111938
Policy log std Std           0.28748563
Policy log std Max           -0.038089514
Policy log std Min           -2.442233
Z mean eval                  1.1183782
Z variance eval              0.006435649
total_rewards                [3967.2717273   232.09711536 2218.65227782 1705.83174177 3989.11502776
 3940.61545463 4122.54304066 2541.95989803 3927.98251242  912.53106873]
total_rewards_mean           2755.8599864472726
total_rewards_std            1372.5130571989494
total_rewards_max            4122.543040659766
total_rewards_min            232.0971153552623
Number of train steps total  482000
Number of env steps total    2412000
Number of rollouts total     0
Train Time (s)               29.513250877149403
(Previous) Eval Time (s)     23.736814276780933
Sample Time (s)              17.767781927715987
Epoch Time (s)               71.01784708164632
Total Train Time (s)         33250.05613788869
Epoch                        481
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:29:42.975129 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #481 | Epoch Duration: 66.34878993034363
2020-01-11 12:29:42.975323 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #481 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1159714
Z variance train             0.0064221127
KL Divergence                25.84747
KL Loss                      2.584747
QF Loss                      1381.8167
VF Loss                      295.0161
Policy Loss                  -1420.1799
Q Predictions Mean           1414.6956
Q Predictions Std            292.15652
Q Predictions Max            1670.9757
Q Predictions Min            -169.88379
V Predictions Mean           1416.9097
V Predictions Std            289.5729
V Predictions Max            1674.6462
V Predictions Min            -158.04213
Log Pis Mean                 0.5237353
Log Pis Std                  2.8366573
Log Pis Max                  14.817944
Log Pis Min                  -6.688136
Policy mu Mean               0.025786873
Policy mu Std                0.6056755
Policy mu Max                3.0814676
Policy mu Min                -2.22463
Policy log std Mean          -1.1188736
Policy log std Std           0.2760667
Policy log std Max           -0.09822428
Policy log std Min           -2.4632158
Z mean eval                  1.079403
Z variance eval              0.006728478
total_rewards                [1253.16718016 3803.2279973  3891.22084116 4073.23819938 4081.26967711
 4069.19775118 4154.48035797 3984.55042903 4257.6930653  4066.49292588]
total_rewards_mean           3763.45384244655
total_rewards_std            845.4459556012571
total_rewards_max            4257.693065296894
total_rewards_min            1253.1671801613886
Number of train steps total  483000
Number of env steps total    2417000
Number of rollouts total     0
Train Time (s)               29.0140719152987
(Previous) Eval Time (s)     19.06747209886089
Sample Time (s)              17.578498310409486
Epoch Time (s)               65.66004232456908
Total Train Time (s)         33321.37796348194
Epoch                        482
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:30:54.301464 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #482 | Epoch Duration: 71.32595205307007
2020-01-11 12:30:54.301682 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #482 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0802968
Z variance train             0.00670216
KL Divergence                25.40517
KL Loss                      2.540517
QF Loss                      2813.5781
VF Loss                      1438.3256
Policy Loss                  -1417.6515
Q Predictions Mean           1415.8965
Q Predictions Std            290.9385
Q Predictions Max            1711.5287
Q Predictions Min            -153.81549
V Predictions Mean           1398.355
V Predictions Std            273.19012
V Predictions Max            1656.633
V Predictions Min            -166.49287
Log Pis Mean                 1.2458309
Log Pis Std                  3.2003546
Log Pis Max                  12.814249
Log Pis Min                  -8.354951
Policy mu Mean               -0.03333135
Policy mu Std                0.6609124
Policy mu Max                2.1554234
Policy mu Min                -2.4156206
Policy log std Mean          -1.146707
Policy log std Std           0.35953853
Policy log std Max           -0.17787367
Policy log std Min           -3.2823286
Z mean eval                  1.1096561
Z variance eval              0.0136800725
total_rewards                [4208.61218553 4431.06060054 1576.26921526 4293.05063091 4244.65917788
 4050.00092131 4302.26078803 2411.40286012 4204.93994077 4144.06774329]
total_rewards_mean           3786.632406363221
total_rewards_std            920.572709272891
total_rewards_max            4431.06060053904
total_rewards_min            1576.269215259518
Number of train steps total  484000
Number of env steps total    2422000
Number of rollouts total     0
Train Time (s)               29.944017190951854
(Previous) Eval Time (s)     24.733140972908586
Sample Time (s)              17.702135547529906
Epoch Time (s)               72.37929371139035
Total Train Time (s)         33393.15673569264
Epoch                        483
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:32:06.084521 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #483 | Epoch Duration: 71.78266310691833
2020-01-11 12:32:06.084728 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #483 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1114986
Z variance train             0.013714636
KL Divergence                24.220306
KL Loss                      2.4220307
QF Loss                      1070.4568
VF Loss                      136.07944
Policy Loss                  -1438.1505
Q Predictions Mean           1438.7786
Q Predictions Std            293.5671
Q Predictions Max            1700.5991
Q Predictions Min            -155.04012
V Predictions Mean           1436.6805
V Predictions Std            295.56613
V Predictions Max            1704.8585
V Predictions Min            -173.01903
Log Pis Mean                 1.3341424
Log Pis Std                  2.6952674
Log Pis Max                  14.69828
Log Pis Min                  -6.672661
Policy mu Mean               0.031853974
Policy mu Std                0.6276978
Policy mu Max                2.4473016
Policy mu Min                -2.7921412
Policy log std Mean          -1.1418519
Policy log std Std           0.29366478
Policy log std Max           0.14551288
Policy log std Min           -2.5600498
Z mean eval                  1.1130182
Z variance eval              0.013901807
total_rewards                [ 804.42659323 3698.37576024 3966.2313157  2676.15232867 4311.33977343
 3916.5493089  4010.72357908 4077.72515747 4050.78167442 3971.45598689]
total_rewards_mean           3548.3761478050956
total_rewards_std            1006.4881881596499
total_rewards_max            4311.339773433449
total_rewards_min            804.4265932263553
Number of train steps total  485000
Number of env steps total    2427000
Number of rollouts total     0
Train Time (s)               29.412539281416684
(Previous) Eval Time (s)     24.136210462078452
Sample Time (s)              18.298324376810342
Epoch Time (s)               71.84707412030548
Total Train Time (s)         33465.16277015349
Epoch                        484
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:33:18.093612 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #484 | Epoch Duration: 72.00874137878418
2020-01-11 12:33:18.093809 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #484 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1141336
Z variance train             0.013896952
KL Divergence                24.535488
KL Loss                      2.453549
QF Loss                      9894.779
VF Loss                      166.90085
Policy Loss                  -1451.0151
Q Predictions Mean           1453.1466
Q Predictions Std            250.41092
Q Predictions Max            1703.9873
Q Predictions Min            -180.56985
V Predictions Mean           1447.6934
V Predictions Std            250.88667
V Predictions Max            1692.9551
V Predictions Min            -175.05003
Log Pis Mean                 1.3931208
Log Pis Std                  2.9386153
Log Pis Max                  14.040864
Log Pis Min                  -6.602315
Policy mu Mean               0.0574959
Policy mu Std                0.6947905
Policy mu Max                2.3787134
Policy mu Min                -2.5253036
Policy log std Mean          -1.0898321
Policy log std Std           0.30377394
Policy log std Max           -0.16034645
Policy log std Min           -2.7859464
Z mean eval                  1.1217114
Z variance eval              0.019466426
total_rewards                [ 752.25997715 3052.03078411 3203.27234122 4068.50575324 4035.00323429
 4403.20824488 4065.2804806  4103.76352232 4177.46387756 4112.97915655]
total_rewards_mean           3597.376737190396
total_rewards_std            1033.8260112682842
total_rewards_max            4403.208244876254
total_rewards_min            752.2599771494521
Number of train steps total  486000
Number of env steps total    2432000
Number of rollouts total     0
Train Time (s)               28.116910104174167
(Previous) Eval Time (s)     24.297570921014994
Sample Time (s)              19.283392790239304
Epoch Time (s)               71.69787381542847
Total Train Time (s)         33537.77947558276
Epoch                        485
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:34:30.717950 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #485 | Epoch Duration: 72.6239881515503
2020-01-11 12:34:30.718212 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #485 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1232127
Z variance train             0.019407276
KL Divergence                24.202202
KL Loss                      2.4202201
QF Loss                      1057.0497
VF Loss                      1158.6919
Policy Loss                  -1442.7122
Q Predictions Mean           1444.6566
Q Predictions Std            271.02686
Q Predictions Max            1742.3962
Q Predictions Min            -21.08833
V Predictions Mean           1441.086
V Predictions Std            255.48106
V Predictions Max            1721.53
V Predictions Min            -19.55438
Log Pis Mean                 0.9875421
Log Pis Std                  2.7649982
Log Pis Max                  12.350023
Log Pis Min                  -7.6221585
Policy mu Mean               0.012127451
Policy mu Std                0.6590996
Policy mu Max                2.3858285
Policy mu Min                -3.2104974
Policy log std Mean          -1.1245768
Policy log std Std           0.2853122
Policy log std Max           -0.24342048
Policy log std Min           -2.7419662
Z mean eval                  1.0946577
Z variance eval              0.012501514
total_rewards                [ 468.41699052  551.30603803 2643.49362351  962.98602885  677.01526646
 1257.85670175 2210.447277   1489.61637202 3505.17072883 1771.22048668]
total_rewards_mean           1553.7529513651182
total_rewards_std            941.610440637622
total_rewards_max            3505.170728831945
total_rewards_min            468.4169905175479
Number of train steps total  487000
Number of env steps total    2437000
Number of rollouts total     0
Train Time (s)               27.835128653794527
(Previous) Eval Time (s)     25.22331763105467
Sample Time (s)              17.977629062253982
Epoch Time (s)               71.03607534710318
Total Train Time (s)         33596.844768245704
Epoch                        486
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:35:29.786950 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #486 | Epoch Duration: 59.0685510635376
2020-01-11 12:35:29.787146 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #486 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0957366
Z variance train             0.012535
KL Divergence                24.916382
KL Loss                      2.4916382
QF Loss                      1325.5261
VF Loss                      320.01367
Policy Loss                  -1475.995
Q Predictions Mean           1482.0227
Q Predictions Std            167.689
Q Predictions Max            1688.6356
Q Predictions Min            -169.15152
V Predictions Mean           1481.2493
V Predictions Std            175.56625
V Predictions Max            1685.2562
V Predictions Min            -166.69162
Log Pis Mean                 1.3240993
Log Pis Std                  2.8655946
Log Pis Max                  12.349484
Log Pis Min                  -6.5922737
Policy mu Mean               0.016073518
Policy mu Std                0.64880073
Policy mu Max                2.7262232
Policy mu Min                -2.6846528
Policy log std Mean          -1.1191411
Policy log std Std           0.28709942
Policy log std Max           0.27409816
Policy log std Min           -3.0673928
Z mean eval                  1.1053767
Z variance eval              0.015446566
total_rewards                [-436.81462456 4260.32247499 4323.3137648  4497.01216327 1908.13887629
 4014.89118184 4239.99227476 4337.05721173 4218.48223976 4263.61464065]
total_rewards_mean           3562.601020353777
total_rewards_std            1511.8201527505094
total_rewards_max            4497.012163272899
total_rewards_min            -436.8146245589408
Number of train steps total  488000
Number of env steps total    2442000
Number of rollouts total     0
Train Time (s)               28.442349520977587
(Previous) Eval Time (s)     13.255476486869156
Sample Time (s)              17.37741124536842
Epoch Time (s)               59.075237253215164
Total Train Time (s)         33669.69417888485
Epoch                        487
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:36:42.640609 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #487 | Epoch Duration: 72.85332560539246
2020-01-11 12:36:42.640814 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #487 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1057508
Z variance train             0.015409015
KL Divergence                25.02864
KL Loss                      2.5028641
QF Loss                      1248.1443
VF Loss                      198.30652
Policy Loss                  -1459.2079
Q Predictions Mean           1460.3378
Q Predictions Std            259.83926
Q Predictions Max            1700.3923
Q Predictions Min            -91.866936
V Predictions Mean           1453.0314
V Predictions Std            259.41376
V Predictions Max            1682.3307
V Predictions Min            -100.61279
Log Pis Mean                 1.2841518
Log Pis Std                  2.837566
Log Pis Max                  12.6067505
Log Pis Min                  -9.545532
Policy mu Mean               0.020438377
Policy mu Std                0.60606855
Policy mu Max                2.7399116
Policy mu Min                -2.488078
Policy log std Mean          -1.1790707
Policy log std Std           0.2722815
Policy log std Max           -0.18491024
Policy log std Min           -2.4086657
Z mean eval                  1.1055573
Z variance eval              0.017757269
total_rewards                [3312.25679373 3906.79504927 4124.09105875 3937.01149705 3919.46774582
 4178.0131431  4366.89242756  662.48185541 4420.95131881 4305.04732166]
total_rewards_mean           3713.3008211160327
total_rewards_std            1061.185434052765
total_rewards_max            4420.951318811538
total_rewards_min            662.4818554089431
Number of train steps total  489000
Number of env steps total    2447000
Number of rollouts total     0
Train Time (s)               28.901309906039387
(Previous) Eval Time (s)     27.033226512372494
Sample Time (s)              18.370590719394386
Epoch Time (s)               74.30512713780627
Total Train Time (s)         33741.66654687701
Epoch                        488
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:37:54.617027 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #488 | Epoch Duration: 71.97605276107788
2020-01-11 12:37:54.617224 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #488 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1040742
Z variance train             0.017813776
KL Divergence                24.577076
KL Loss                      2.4577076
QF Loss                      2269.0188
VF Loss                      4164.1904
Policy Loss                  -1431.8256
Q Predictions Mean           1438.1992
Q Predictions Std            254.82487
Q Predictions Max            1670.6847
Q Predictions Min            -81.22055
V Predictions Mean           1441.9033
V Predictions Std            248.83348
V Predictions Max            1679.3672
V Predictions Min            -97.64046
Log Pis Mean                 1.3888221
Log Pis Std                  2.7849426
Log Pis Max                  13.410122
Log Pis Min                  -5.0145836
Policy mu Mean               -0.017878374
Policy mu Std                0.62945235
Policy mu Max                2.4925718
Policy mu Min                -2.9662433
Policy log std Mean          -1.1650801
Policy log std Std           0.31618568
Policy log std Max           -0.24219388
Policy log std Min           -3.014251
Z mean eval                  1.1133326
Z variance eval              0.010957731
total_rewards                [3276.27806276 4415.43609024 4127.65900312 3984.71721426 4141.03714755
 4229.6033337  4171.19069618 4246.98679689 4183.32067589 4203.66186459]
total_rewards_mean           4097.9890885180785
total_rewards_std            292.38243498463066
total_rewards_max            4415.436090240758
total_rewards_min            3276.278062760594
Number of train steps total  490000
Number of env steps total    2452000
Number of rollouts total     0
Train Time (s)               27.05145596107468
(Previous) Eval Time (s)     24.703821287024766
Sample Time (s)              18.60927166696638
Epoch Time (s)               70.36454891506582
Total Train Time (s)         33813.634041879326
Epoch                        489
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:39:06.591093 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #489 | Epoch Duration: 71.97371006011963
2020-01-11 12:39:06.591374 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #489 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1150217
Z variance train             0.010946744
KL Divergence                25.305567
KL Loss                      2.5305567
QF Loss                      1280.8934
VF Loss                      311.98245
Policy Loss                  -1435.8699
Q Predictions Mean           1439.2888
Q Predictions Std            282.64246
Q Predictions Max            1689.3673
Q Predictions Min            -145.71794
V Predictions Mean           1443.7751
V Predictions Std            280.8516
V Predictions Max            1691.7933
V Predictions Min            -158.51271
Log Pis Mean                 1.3685973
Log Pis Std                  3.478603
Log Pis Max                  14.360147
Log Pis Min                  -6.961455
Policy mu Mean               0.0039899885
Policy mu Std                0.679891
Policy mu Max                3.7421637
Policy mu Min                -2.9594142
Policy log std Mean          -1.133788
Policy log std Std           0.32833862
Policy log std Max           -0.15967977
Policy log std Min           -3.6450353
Z mean eval                  1.0661113
Z variance eval              0.015726838
total_rewards                [  59.48381614  183.24519295  324.38468251 4174.23465273 1408.36302088
 1573.48193138 4400.15258745 4415.43008036 4352.29920341 2177.2537547 ]
total_rewards_mean           2306.832892251047
total_rewards_std            1770.633705721388
total_rewards_max            4415.430080355292
total_rewards_min            59.48381614172621
Number of train steps total  491000
Number of env steps total    2457000
Number of rollouts total     0
Train Time (s)               27.687461069319397
(Previous) Eval Time (s)     26.312673488166183
Sample Time (s)              17.78615897987038
Epoch Time (s)               71.78629353735596
Total Train Time (s)         33873.713576219976
Epoch                        490
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:40:06.675408 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #490 | Epoch Duration: 60.08383131027222
2020-01-11 12:40:06.675624 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #490 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0609003
Z variance train             0.0156971
KL Divergence                24.842596
KL Loss                      2.4842596
QF Loss                      5029.1987
VF Loss                      327.20206
Policy Loss                  -1442.7211
Q Predictions Mean           1441.009
Q Predictions Std            291.07266
Q Predictions Max            1739.5938
Q Predictions Min            -178.76244
V Predictions Mean           1433.8422
V Predictions Std            278.7975
V Predictions Max            1723.3503
V Predictions Min            -181.58476
Log Pis Mean                 1.0694364
Log Pis Std                  3.1314178
Log Pis Max                  10.334375
Log Pis Min                  -9.830943
Policy mu Mean               0.008243624
Policy mu Std                0.68818647
Policy mu Max                2.3631663
Policy mu Min                -2.524964
Policy log std Mean          -1.0911014
Policy log std Std           0.30494276
Policy log std Max           -0.14406204
Policy log std Min           -2.9145875
Z mean eval                  1.0869224
Z variance eval              0.015996803
total_rewards                [-256.43604516 4089.31431488 4287.74213106 4240.48141303 1882.95631387
 4080.28949846 4319.16449125 4356.67586645 4122.61355438 3878.96195623]
total_rewards_mean           3500.1763494450083
total_rewards_std            1432.29547200609
total_rewards_max            4356.675866453765
total_rewards_min            -256.4360451555361
Number of train steps total  492000
Number of env steps total    2462000
Number of rollouts total     0
Train Time (s)               29.393980970606208
(Previous) Eval Time (s)     14.609940426889807
Sample Time (s)              18.542811776977032
Epoch Time (s)               62.54673317447305
Total Train Time (s)         33947.05913821235
Epoch                        491
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:41:20.027274 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #491 | Epoch Duration: 73.35148310661316
2020-01-11 12:41:20.027486 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #491 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0855248
Z variance train             0.015994256
KL Divergence                24.639996
KL Loss                      2.4639995
QF Loss                      3696.1345
VF Loss                      602.2471
Policy Loss                  -1448.6556
Q Predictions Mean           1454.0519
Q Predictions Std            221.72644
Q Predictions Max            1714.1698
Q Predictions Min            -110.86534
V Predictions Mean           1457.3813
V Predictions Std            223.85513
V Predictions Max            1725.4843
V Predictions Min            -102.958984
Log Pis Mean                 1.3229294
Log Pis Std                  3.1352637
Log Pis Max                  16.007627
Log Pis Min                  -8.317493
Policy mu Mean               -0.011960284
Policy mu Std                0.6413033
Policy mu Max                2.6377783
Policy mu Min                -2.7738397
Policy log std Mean          -1.1644664
Policy log std Std           0.3044484
Policy log std Max           -0.20914733
Policy log std Min           -3.2473183
Z mean eval                  1.1286333
Z variance eval              0.014574741
total_rewards                [2920.06344242 2149.39719477  257.92974434  909.90350657 1765.96472982
 4176.26377767 4301.55240915 4112.05871818 4323.3074955  3509.83268175]
total_rewards_mean           2842.6273700170573
total_rewards_std            1421.8977128428157
total_rewards_max            4323.307495504567
total_rewards_min            257.92974433506186
Number of train steps total  493000
Number of env steps total    2467000
Number of rollouts total     0
Train Time (s)               30.095478967297822
(Previous) Eval Time (s)     25.41437919717282
Sample Time (s)              18.45961653534323
Epoch Time (s)               73.96947469981387
Total Train Time (s)         34014.689897655975
Epoch                        492
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:42:27.662353 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #492 | Epoch Duration: 67.63468885421753
2020-01-11 12:42:27.662573 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #492 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1323432
Z variance train             0.01460751
KL Divergence                24.074871
KL Loss                      2.4074872
QF Loss                      1165.4233
VF Loss                      812.247
Policy Loss                  -1430.3955
Q Predictions Mean           1440.1211
Q Predictions Std            277.05148
Q Predictions Max            1696.2183
Q Predictions Min            -102.284035
V Predictions Mean           1452.9312
V Predictions Std            278.64417
V Predictions Max            1716.7242
V Predictions Min            -120.56452
Log Pis Mean                 1.7050464
Log Pis Std                  3.3117464
Log Pis Max                  11.06378
Log Pis Min                  -7.005249
Policy mu Mean               0.03083559
Policy mu Std                0.6853119
Policy mu Max                2.9885352
Policy mu Min                -2.6564445
Policy log std Mean          -1.1327145
Policy log std Std           0.3026009
Policy log std Max           -0.07936418
Policy log std Min           -2.8049047
Z mean eval                  1.1144571
Z variance eval              0.015373772
total_rewards                [  66.96758692 1446.21327899 4248.66114199 3999.10949942 4062.94347384
 4023.49663504 4000.46035233 4002.71364806  388.93667657  113.55727902]
total_rewards_mean           2635.3059572172233
total_rewards_std            1776.9986586680286
total_rewards_max            4248.661141987236
total_rewards_min            66.96758691736474
Number of train steps total  494000
Number of env steps total    2472000
Number of rollouts total     0
Train Time (s)               27.271153992041945
(Previous) Eval Time (s)     19.079284687992185
Sample Time (s)              18.135179007425904
Epoch Time (s)               64.48561768746004
Total Train Time (s)         34079.70595659455
Epoch                        493
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:43:32.685250 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #493 | Epoch Duration: 65.02249455451965
2020-01-11 12:43:32.685515 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #493 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1146961
Z variance train             0.015422797
KL Divergence                24.466633
KL Loss                      2.4466634
QF Loss                      1573.8463
VF Loss                      181.706
Policy Loss                  -1474.2594
Q Predictions Mean           1474.5181
Q Predictions Std            233.91371
Q Predictions Max            1711.9348
Q Predictions Min            -180.26508
V Predictions Mean           1469.099
V Predictions Std            232.29979
V Predictions Max            1692.1642
V Predictions Min            -187.54819
Log Pis Mean                 1.2872167
Log Pis Std                  2.8596714
Log Pis Max                  11.122182
Log Pis Min                  -11.739807
Policy mu Mean               -0.029856797
Policy mu Std                0.6813471
Policy mu Max                2.6876042
Policy mu Min                -2.6091104
Policy log std Mean          -1.1216154
Policy log std Std           0.27951136
Policy log std Max           -0.26656306
Policy log std Min           -2.753796
Z mean eval                  1.096267
Z variance eval              0.016136786
total_rewards                [4125.72144555 1982.6727573  4118.10715584 3597.41102199 4393.4622796
 3933.73895036 4278.50291422 2647.78562585  857.56330223 3848.7106521 ]
total_rewards_mean           3378.367610505783
total_rewards_std            1111.7653322578353
total_rewards_max            4393.462279599347
total_rewards_min            857.5633022335265
Number of train steps total  495000
Number of env steps total    2477000
Number of rollouts total     0
Train Time (s)               29.08241142798215
(Previous) Eval Time (s)     19.615814849734306
Sample Time (s)              18.28069697925821
Epoch Time (s)               66.97892325697467
Total Train Time (s)         34150.35591925867
Epoch                        494
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:44:43.338808 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #494 | Epoch Duration: 70.65308833122253
2020-01-11 12:44:43.338989 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #494 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0953944
Z variance train             0.01613817
KL Divergence                23.657768
KL Loss                      2.3657768
QF Loss                      4141.289
VF Loss                      306.1309
Policy Loss                  -1449.1353
Q Predictions Mean           1449.2781
Q Predictions Std            279.42792
Q Predictions Max            1717.3751
Q Predictions Min            -148.0887
V Predictions Mean           1453.9048
V Predictions Std            271.47906
V Predictions Max            1714.1295
V Predictions Min            -160.08961
Log Pis Mean                 1.3426652
Log Pis Std                  3.104988
Log Pis Max                  15.601167
Log Pis Min                  -6.5120053
Policy mu Mean               0.031179521
Policy mu Std                0.6874385
Policy mu Max                2.526304
Policy mu Min                -2.5346053
Policy log std Mean          -1.1232705
Policy log std Std           0.32412195
Policy log std Max           -0.0070174932
Policy log std Min           -3.4105883
Z mean eval                  1.1064596
Z variance eval              0.013880497
total_rewards                [1639.86458838 3754.71821429  705.72784727 4357.77981184  377.58213034
 3998.62679941  452.91382553 1993.88618653 2822.78415352  756.1319642 ]
total_rewards_mean           2086.001552131019
total_rewards_std            1470.1523796485696
total_rewards_max            4357.77981183523
total_rewards_min            377.58213033579636
Number of train steps total  496000
Number of env steps total    2482000
Number of rollouts total     0
Train Time (s)               29.31776504823938
(Previous) Eval Time (s)     23.28965786099434
Sample Time (s)              17.360641956329346
Epoch Time (s)               69.96806486556306
Total Train Time (s)         34212.23774310341
Epoch                        495
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:45:45.223632 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #495 | Epoch Duration: 61.88451814651489
2020-01-11 12:45:45.223825 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #495 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1032937
Z variance train             0.013884759
KL Divergence                23.264475
KL Loss                      2.3264475
QF Loss                      681.54034
VF Loss                      298.12137
Policy Loss                  -1452.1669
Q Predictions Mean           1454.565
Q Predictions Std            306.93744
Q Predictions Max            1758.0676
Q Predictions Min            -156.40187
V Predictions Mean           1458.2385
V Predictions Std            310.82037
V Predictions Max            1757.5481
V Predictions Min            -177.04648
Log Pis Mean                 0.8984075
Log Pis Std                  3.0739744
Log Pis Max                  22.380634
Log Pis Min                  -9.804909
Policy mu Mean               0.01914366
Policy mu Std                0.62419915
Policy mu Max                3.7415545
Policy mu Min                -3.6855998
Policy log std Mean          -1.1202481
Policy log std Std           0.27146268
Policy log std Max           -0.015740514
Policy log std Min           -2.374764
Z mean eval                  1.0825357
Z variance eval              0.011485802
total_rewards                [4202.5817434  3982.82571725 4318.47184146 4232.70817713 2992.67371408
  496.62525447 4360.73221024 4278.57960162 3830.72028499 4278.47607175]
total_rewards_mean           3697.439461639099
total_rewards_std            1135.066634819487
total_rewards_max            4360.732210244198
total_rewards_min            496.6252544738023
Number of train steps total  497000
Number of env steps total    2487000
Number of rollouts total     0
Train Time (s)               28.453459286130965
(Previous) Eval Time (s)     15.205836148001254
Sample Time (s)              17.568538256455213
Epoch Time (s)               61.22783369058743
Total Train Time (s)         34282.396210735664
Epoch                        496
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:46:55.387880 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #496 | Epoch Duration: 70.16389036178589
2020-01-11 12:46:55.388096 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #496 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0818151
Z variance train             0.011491814
KL Divergence                23.42836
KL Loss                      2.3428361
QF Loss                      961.81274
VF Loss                      294.57678
Policy Loss                  -1448.4924
Q Predictions Mean           1449.841
Q Predictions Std            314.95374
Q Predictions Max            1700.3704
Q Predictions Min            -186.17683
V Predictions Mean           1437.8342
V Predictions Std            311.00812
V Predictions Max            1688.1814
V Predictions Min            -183.1864
Log Pis Mean                 1.1721553
Log Pis Std                  2.876304
Log Pis Max                  12.098468
Log Pis Min                  -6.491576
Policy mu Mean               -0.015779713
Policy mu Std                0.6615643
Policy mu Max                2.3823256
Policy mu Min                -2.928328
Policy log std Mean          -1.1262548
Policy log std Std           0.3084362
Policy log std Max           0.18565094
Policy log std Min           -2.9071143
Z mean eval                  1.0732399
Z variance eval              0.0135027915
total_rewards                [2021.50367744 3687.86773493 4442.33245658 3935.32984139 1546.24478928
 1203.02544088 4269.40423461 4061.50701354 4284.51274715 3962.10072086]
total_rewards_mean           3341.382865666129
total_rewards_std            1177.9930439507443
total_rewards_max            4442.332456580016
total_rewards_min            1203.0254408822818
Number of train steps total  498000
Number of env steps total    2492000
Number of rollouts total     0
Train Time (s)               30.265296548139304
(Previous) Eval Time (s)     24.141571772750467
Sample Time (s)              18.53913795016706
Epoch Time (s)               72.94600627105683
Total Train Time (s)         34353.31686219899
Epoch                        497
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:48:06.316140 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #497 | Epoch Duration: 70.9278495311737
2020-01-11 12:48:06.316447 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #497 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0737077
Z variance train             0.013550131
KL Divergence                23.210188
KL Loss                      2.321019
QF Loss                      3396.574
VF Loss                      344.02045
Policy Loss                  -1480.9948
Q Predictions Mean           1476.8563
Q Predictions Std            236.56741
Q Predictions Max            1717.7396
Q Predictions Min            -57.84755
V Predictions Mean           1488.6455
V Predictions Std            236.4618
V Predictions Max            1721.7397
V Predictions Min            -50.752785
Log Pis Mean                 1.1311063
Log Pis Std                  2.691512
Log Pis Max                  13.751603
Log Pis Min                  -6.0352316
Policy mu Mean               0.04538966
Policy mu Std                0.6391178
Policy mu Max                2.471516
Policy mu Min                -2.1431699
Policy log std Mean          -1.1173544
Policy log std Std           0.27723876
Policy log std Max           -0.07681805
Policy log std Min           -2.582728
Z mean eval                  1.1090715
Z variance eval              0.0136579005
total_rewards                [4120.36526797  338.2086358    51.565036   4442.38049794 4286.84924655
 4355.77260933 4023.5185045  2013.08553919 1443.520258   2897.08960279]
total_rewards_mean           2797.2355198082305
total_rewards_std            1632.5396737708086
total_rewards_max            4442.380497939565
total_rewards_min            51.565036004265295
Number of train steps total  499000
Number of env steps total    2497000
Number of rollouts total     0
Train Time (s)               28.477032056078315
(Previous) Eval Time (s)     22.123059257864952
Sample Time (s)              18.409235399216413
Epoch Time (s)               69.00932671315968
Total Train Time (s)         34417.90384353185
Epoch                        498
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:49:10.906408 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #498 | Epoch Duration: 64.58974361419678
2020-01-11 12:49:10.906605 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #498 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1098732
Z variance train             0.013690946
KL Divergence                23.417347
KL Loss                      2.3417346
QF Loss                      1243.1134
VF Loss                      443.50027
Policy Loss                  -1442.0519
Q Predictions Mean           1444.4299
Q Predictions Std            312.15576
Q Predictions Max            1702.4149
Q Predictions Min            -173.77846
V Predictions Mean           1444.3555
V Predictions Std            312.5458
V Predictions Max            1687.3232
V Predictions Min            -152.64632
Log Pis Mean                 1.1355234
Log Pis Std                  3.0862954
Log Pis Max                  19.582691
Log Pis Min                  -5.8629146
Policy mu Mean               0.030488227
Policy mu Std                0.677351
Policy mu Max                2.688716
Policy mu Min                -3.8824525
Policy log std Mean          -1.1297982
Policy log std Std           0.29843125
Policy log std Max           0.03255385
Policy log std Min           -2.3824143
Z mean eval                  1.0654815
Z variance eval              0.015748149
total_rewards                [4031.39987836 4172.4372509  4184.69555434 1718.77408503 4360.29541029
 4007.55896226 4263.67121723 4603.97948086  273.0495862  4243.55285882]
total_rewards_mean           3585.941428429932
total_rewards_std            1344.1741219233897
total_rewards_max            4603.9794808550105
total_rewards_min            273.0495862022335
Number of train steps total  500000
Number of env steps total    2502000
Number of rollouts total     0
Train Time (s)               30.99252194399014
(Previous) Eval Time (s)     17.70316989487037
Sample Time (s)              18.501530637033284
Epoch Time (s)               67.1972224758938
Total Train Time (s)         34492.88838833338
Epoch                        499
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:50:25.898525 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #499 | Epoch Duration: 74.99175214767456
2020-01-11 12:50:25.898810 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #499 | Started Training: True
2020-01-11 12:50:26.519091 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Variant:
2020-01-11 12:50:26.519463 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] {
  "env_name": "Hopper-v2",
  "n_train_tasks": 1,
  "n_eval_tasks": 1,
  "latent_size": 5,
  "net_size": 300,
  "path_to_weights": null,
  "env_params": {
    "n_tasks": 2,
    "randomize_tasks": true
  },
  "algo_params": {
    "meta_batch": 1,
    "num_iterations": 500,
    "num_initial_steps": 2000,
    "num_tasks_sample": 5,
    "num_steps_prior": 400,
    "num_steps_posterior": 0,
    "num_extra_rl_steps_posterior": 600,
    "num_train_steps_per_itr": 1000,
    "num_evals": 2,
    "num_steps_per_eval": 600,
    "batch_size": 256,
    "embedding_batch_size": 20,
    "embedding_mini_batch_size": 20,
    "max_path_length": 200,
    "discount": 0.99,
    "soft_target_tau": 0.005,
    "policy_lr": 0.0003,
    "qf_lr": 0.0003,
    "vf_lr": 0.0003,
    "context_lr": 0.0003,
    "reward_scale": 5.0,
    "sparse_rewards": false,
    "kl_lambda": 0.1,
    "use_information_bottleneck": true,
    "use_next_obs_in_context": false,
    "update_post_train": 1,
    "num_exp_traj_eval": 2,
    "recurrent": true,
    "dump_eval_paths": false
  },
  "util_params": {
    "base_log_dir": "./test/train1000/H-20",
    "use_gpu": true,
    "gpu_id": 0,
    "debug": false,
    "docker": false,
    "num_iterations": 1000
  }
}
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0019376408
Z variance train             0.693145
KL Divergence                0.14916778
KL Loss                      0.014916778
QF Loss                      70.34567
VF Loss                      4.4341574
Policy Loss                  -2.079393
Q Predictions Mean           -0.0023045375
Q Predictions Std            0.0010986081
Q Predictions Max            0.0017850115
Q Predictions Min            -0.0054990025
V Predictions Mean           0.00880776
V Predictions Std            0.0014018345
V Predictions Max            0.013202997
V Predictions Min            0.0060151126
Log Pis Mean                 -2.0737145
Log Pis Std                  0.3831366
Log Pis Max                  -0.82241416
Log Pis Min                  -3.171927
Policy mu Mean               3.8408183e-05
Policy mu Std                0.0009007452
Policy mu Max                0.001969648
Policy mu Min                -0.00234535
Policy log std Mean          -0.0005568333
Policy log std Std           0.0011438006
Policy log std Max           0.001831908
Policy log std Min           -0.0030535706
Z mean eval                  0.005756306
Z variance eval              0.674224
total_rewards                [ 61.38693623 113.01327395 116.02390092  78.44867491  73.2734333
 150.57021339  74.81610569  67.92799259 137.92069701  73.75640018]
total_rewards_mean           94.71376281701069
total_rewards_std            30.270942841517652
total_rewards_max            150.5702133908658
total_rewards_min            61.38693623112616
Number of train steps total  1000
Number of env steps total    7000
Number of rollouts total     0
Train Time (s)               23.39730157610029
(Previous) Eval Time (s)     0
Sample Time (s)              15.17737470054999
Epoch Time (s)               38.57467627665028
Total Train Time (s)         39.968701692763716
Epoch                        0
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:51:06.575276 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #0 | Epoch Duration: 39.97466492652893
2020-01-11 12:51:06.575542 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #0 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0069435285
Z variance train             0.67628586
KL Divergence                0.16881907
KL Loss                      0.016881907
QF Loss                      85.0119
VF Loss                      1.4627635
Policy Loss                  -10.905362
Q Predictions Mean           10.007549
Q Predictions Std            8.671779
Q Predictions Max            34.86257
Q Predictions Min            -6.73171
V Predictions Mean           11.5984535
V Predictions Std            8.22942
V Predictions Max            35.272766
V Predictions Min            -3.3859167
Log Pis Mean                 -1.920514
Log Pis Std                  0.50672823
Log Pis Max                  -0.3085872
Log Pis Min                  -3.628249
Policy mu Mean               0.117926694
Policy mu Std                0.2027278
Policy mu Max                0.4952334
Policy mu Min                -0.24866314
Policy log std Mean          -0.16378818
Policy log std Std           0.025983334
Policy log std Max           -0.101779826
Policy log std Min           -0.23183076
Z mean eval                  0.092427224
Z variance eval              0.22269996
total_rewards                [ 88.31661483 160.34940943 199.30750984  95.68465525 175.6756274
 112.24698586 136.9068843   55.84862928  52.47216383  77.45470909]
total_rewards_mean           115.42631891163653
total_rewards_std            48.202572036849375
total_rewards_max            199.30750984122517
total_rewards_min            52.47216383346039
Number of train steps total  2000
Number of env steps total    12000
Number of rollouts total     0
Train Time (s)               25.518305903766304
(Previous) Eval Time (s)     1.3997573098167777
Sample Time (s)              11.710441849660128
Epoch Time (s)               38.62850506324321
Total Train Time (s)         78.6954736080952
Epoch                        1
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:51:45.304851 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #1 | Epoch Duration: 38.72908687591553
2020-01-11 12:51:45.305136 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #1 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0934286
Z variance train             0.22231428
KL Divergence                1.8811272
KL Loss                      0.18811272
QF Loss                      36.145943
VF Loss                      3.5269725
Policy Loss                  -17.406351
Q Predictions Mean           15.449587
Q Predictions Std            16.395124
Q Predictions Max            67.51149
Q Predictions Min            -5.86962
V Predictions Mean           18.184551
V Predictions Std            16.13917
V Predictions Max            68.73525
V Predictions Min            -1.3462957
Log Pis Mean                 -1.8057686
Log Pis Std                  0.76702154
Log Pis Max                  1.3376659
Log Pis Min                  -3.7438653
Policy mu Mean               0.12421521
Policy mu Std                0.31657064
Policy mu Max                1.3321635
Policy mu Min                -0.33710226
Policy log std Mean          -0.1883903
Policy log std Std           0.10197929
Policy log std Max           -0.09061712
Policy log std Min           -0.5328781
Z mean eval                  0.060991425
Z variance eval              0.08260755
total_rewards                [198.45948536 203.83292039 187.31556748 197.42140996 187.39513631
 197.72362659 189.36371706 189.8156448  210.07286065 192.93700859]
total_rewards_mean           195.43373771996409
total_rewards_std            7.129974377300457
total_rewards_max            210.0728606465592
total_rewards_min            187.31556748001643
Number of train steps total  3000
Number of env steps total    17000
Number of rollouts total     0
Train Time (s)               25.6551773683168
(Previous) Eval Time (s)     1.500083340331912
Sample Time (s)              11.460345430765301
Epoch Time (s)               38.61560613941401
Total Train Time (s)         117.88746403809637
Epoch                        2
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:52:24.495236 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #2 | Epoch Duration: 39.18991160392761
2020-01-11 12:52:24.495435 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #2 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06522969
Z variance train             0.07827815
KL Divergence                4.0949674
KL Loss                      0.40949675
QF Loss                      41.060658
VF Loss                      30.66106
Policy Loss                  -24.804773
Q Predictions Mean           22.588032
Q Predictions Std            28.951641
Q Predictions Max            106.101166
Q Predictions Min            -2.1414497
V Predictions Mean           26.636106
V Predictions Std            32.089897
V Predictions Max            126.92295
V Predictions Min            -0.38471577
Log Pis Mean                 -1.7094694
Log Pis Std                  0.88051796
Log Pis Max                  2.426793
Log Pis Min                  -3.8710275
Policy mu Mean               0.021276304
Policy mu Std                0.36924258
Policy mu Max                1.6513544
Policy mu Min                -1.6084194
Policy log std Mean          -0.21116179
Policy log std Std           0.13883194
Policy log std Max           -0.0946959
Policy log std Min           -0.5879069
Z mean eval                  0.032008044
Z variance eval              0.03112787
total_rewards                [180.78277111 189.04334453 204.47166565 188.49249267 192.99342232
 188.41003375 200.60154835 190.37501448 197.51156167 195.99486851]
total_rewards_mean           192.86767230346985
total_rewards_std            6.570561461927455
total_rewards_max            204.4716656525169
total_rewards_min            180.78277110732273
Number of train steps total  4000
Number of env steps total    22000
Number of rollouts total     0
Train Time (s)               27.21719363378361
(Previous) Eval Time (s)     2.0741261886432767
Sample Time (s)              12.083760148379952
Epoch Time (s)               41.37507997080684
Total Train Time (s)         159.18084556423128
Epoch                        3
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:53:05.788779 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #3 | Epoch Duration: 41.293190479278564
2020-01-11 12:53:05.788970 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #3 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030359143
Z variance train             0.030940836
KL Divergence                6.3432026
KL Loss                      0.63432026
QF Loss                      30.265991
VF Loss                      9.992334
Policy Loss                  -42.422386
Q Predictions Mean           40.724205
Q Predictions Std            53.15372
Q Predictions Max            156.76782
Q Predictions Min            -4.8803844
V Predictions Mean           42.86013
V Predictions Std            53.4645
V Predictions Max            155.05243
V Predictions Min            -3.3447578
Log Pis Mean                 -1.4440154
Log Pis Std                  1.2674633
Log Pis Max                  4.5372353
Log Pis Min                  -3.9453616
Policy mu Mean               0.102510355
Policy mu Std                0.45624965
Policy mu Max                1.8393766
Policy mu Min                -1.8420365
Policy log std Mean          -0.26759928
Policy log std Std           0.20277216
Policy log std Max           -0.09863521
Policy log std Min           -0.70077074
Z mean eval                  0.031311277
Z variance eval              0.022602836
total_rewards                [192.82131874 196.90224099 199.67523725 189.05397271 198.24569968
 198.60206488 200.44821929 198.44775624 203.69860915 198.32021479]
total_rewards_mean           197.6215333708532
total_rewards_std            3.855166224528826
total_rewards_max            203.69860914767688
total_rewards_min            189.0539727062519
Number of train steps total  5000
Number of env steps total    27000
Number of rollouts total     0
Train Time (s)               28.47028563497588
(Previous) Eval Time (s)     1.991987959947437
Sample Time (s)              11.839425818994641
Epoch Time (s)               42.30169941391796
Total Train Time (s)         201.6900160573423
Epoch                        4
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:53:48.298723 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #4 | Epoch Duration: 42.509634017944336
2020-01-11 12:53:48.298891 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #4 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032603692
Z variance train             0.023442317
KL Divergence                7.02439
KL Loss                      0.702439
QF Loss                      74.19501
VF Loss                      12.818774
Policy Loss                  -61.690372
Q Predictions Mean           57.907906
Q Predictions Std            76.58031
Q Predictions Max            212.05153
Q Predictions Min            -3.6894991
V Predictions Mean           62.38302
V Predictions Std            77.89921
V Predictions Max            217.8136
V Predictions Min            -0.5535821
Log Pis Mean                 -1.3470914
Log Pis Std                  1.4546258
Log Pis Max                  6.6066985
Log Pis Min                  -3.5449965
Policy mu Mean               0.16581637
Policy mu Std                0.5069017
Policy mu Max                1.9460552
Policy mu Min                -2.256291
Policy log std Mean          -0.25565633
Policy log std Std           0.18732595
Policy log std Max           -0.10720019
Policy log std Min           -0.7820875
Z mean eval                  0.02878862
Z variance eval              0.0120406505
total_rewards                [294.78041485 304.08688073 312.75780315 299.14772629 310.14076885
 291.44787437 272.73195521 310.42914091 299.13162923 320.99124901]
total_rewards_mean           301.5645442612796
total_rewards_std            12.85546764143108
total_rewards_max            320.9912490149272
total_rewards_min            272.7319552136012
Number of train steps total  6000
Number of env steps total    32000
Number of rollouts total     0
Train Time (s)               27.70890953578055
(Previous) Eval Time (s)     2.1996500520035625
Sample Time (s)              13.135116294026375
Epoch Time (s)               43.043675881810486
Total Train Time (s)         246.08506594831124
Epoch                        5
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:54:32.695850 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #5 | Epoch Duration: 44.39677286148071
2020-01-11 12:54:32.696105 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #5 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028875506
Z variance train             0.012045466
KL Divergence                8.691999
KL Loss                      0.86919993
QF Loss                      61.950325
VF Loss                      22.923607
Policy Loss                  -85.095345
Q Predictions Mean           81.8862
Q Predictions Std            103.764244
Q Predictions Max            294.81274
Q Predictions Min            -5.376377
V Predictions Mean           86.883446
V Predictions Std            105.73498
V Predictions Max            298.95236
V Predictions Min            -1.424462
Log Pis Mean                 -1.4129854
Log Pis Std                  1.2774708
Log Pis Max                  5.8679495
Log Pis Min                  -4.5652566
Policy mu Mean               0.06769366
Policy mu Std                0.5012553
Policy mu Max                1.9583457
Policy mu Min                -2.1375446
Policy log std Mean          -0.2719567
Policy log std Std           0.20646518
Policy log std Max           -0.0152181685
Policy log std Min           -0.8507292
Z mean eval                  0.016350104
Z variance eval              0.007268662
total_rewards                [264.79057149 245.25071421 266.49339144 268.61445574 238.48052616
 263.84042937 261.13604042 254.1292542  255.26481632 260.27773127]
total_rewards_mean           257.8277930612465
total_rewards_std            9.196581714246058
total_rewards_max            268.61445573958133
total_rewards_min            238.48052615707937
Number of train steps total  7000
Number of env steps total    37000
Number of rollouts total     0
Train Time (s)               27.022027054335922
(Previous) Eval Time (s)     3.5524652749300003
Sample Time (s)              13.672847895883024
Epoch Time (s)               44.247340225148946
Total Train Time (s)         289.5073096798733
Epoch                        6
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:55:16.120486 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #6 | Epoch Duration: 43.42418098449707
2020-01-11 12:55:16.120768 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #6 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017883731
Z variance train             0.007342607
KL Divergence                9.9297905
KL Loss                      0.99297905
QF Loss                      313.59778
VF Loss                      34.392918
Policy Loss                  -107.3454
Q Predictions Mean           105.57936
Q Predictions Std            125.3626
Q Predictions Max            351.0733
Q Predictions Min            -7.1255717
V Predictions Mean           108.820854
V Predictions Std            125.48909
V Predictions Max            357.94427
V Predictions Min            -3.7286282
Log Pis Mean                 -1.2299261
Log Pis Std                  1.6994617
Log Pis Max                  7.6023884
Log Pis Min                  -4.8734956
Policy mu Mean               0.15871647
Policy mu Std                0.6014847
Policy mu Max                2.3599117
Policy mu Min                -2.0919447
Policy log std Mean          -0.31076297
Policy log std Std           0.24562816
Policy log std Max           -0.08538943
Policy log std Min           -1.1078196
Z mean eval                  0.028499087
Z variance eval              0.0055544935
total_rewards                [324.68602163 174.67681749 312.25923955 145.70039464 138.62284355
 198.39934765 137.0604313  322.55080727 297.44093724 333.31404467]
total_rewards_mean           238.47108849965116
total_rewards_std            81.82626895759033
total_rewards_max            333.31404467155454
total_rewards_min            137.0604313028823
Number of train steps total  8000
Number of env steps total    42000
Number of rollouts total     0
Train Time (s)               25.87000434473157
(Previous) Eval Time (s)     2.7290414650924504
Sample Time (s)              12.576032475568354
Epoch Time (s)               41.175078285392374
Total Train Time (s)         330.7518015606329
Epoch                        7
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:55:57.365924 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #7 | Epoch Duration: 41.244962215423584
2020-01-11 12:55:57.366102 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #7 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028020913
Z variance train             0.005487039
KL Divergence                10.596031
KL Loss                      1.0596031
QF Loss                      222.27383
VF Loss                      37.397354
Policy Loss                  -140.43898
Q Predictions Mean           141.57083
Q Predictions Std            149.77396
Q Predictions Max            431.63727
Q Predictions Min            -0.67681545
V Predictions Mean           138.8659
V Predictions Std            147.24893
V Predictions Max            423.73248
V Predictions Min            -0.69425374
Log Pis Mean                 -1.2059188
Log Pis Std                  1.7882757
Log Pis Max                  7.4660044
Log Pis Min                  -4.926438
Policy mu Mean               0.023681687
Policy mu Std                0.60924757
Policy mu Max                2.35797
Policy mu Min                -2.3924654
Policy log std Mean          -0.2933195
Policy log std Std           0.22172678
Policy log std Max           -0.065642536
Policy log std Min           -1.0818189
Z mean eval                  0.007943086
Z variance eval              0.0059326543
total_rewards                [340.25028009 344.83227967 316.41688581 321.73731293 322.85579613
 328.35697086 334.28665042 316.81886798 305.62254649 334.84827184]
total_rewards_mean           326.6025862213001
total_rewards_std            11.51536509804525
total_rewards_max            344.8322796705376
total_rewards_min            305.62254649047435
Number of train steps total  9000
Number of env steps total    47000
Number of rollouts total     0
Train Time (s)               25.415896309074014
(Previous) Eval Time (s)     2.7986742318607867
Sample Time (s)              12.883698219899088
Epoch Time (s)               41.09826876083389
Total Train Time (s)         372.08485841425136
Epoch                        8
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:56:38.698595 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #8 | Epoch Duration: 41.33233428001404
2020-01-11 12:56:38.698778 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #8 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0075393147
Z variance train             0.0058042263
KL Divergence                10.471015
KL Loss                      1.0471015
QF Loss                      434.64252
VF Loss                      36.76709
Policy Loss                  -170.07004
Q Predictions Mean           167.89148
Q Predictions Std            176.01837
Q Predictions Max            503.6988
Q Predictions Min            -5.044222
V Predictions Mean           170.50015
V Predictions Std            175.33011
V Predictions Max            502.67456
V Predictions Min            -3.8211603
Log Pis Mean                 -0.8425698
Log Pis Std                  1.8661742
Log Pis Max                  8.7835045
Log Pis Min                  -5.0919714
Policy mu Mean               0.1724419
Policy mu Std                0.6770782
Policy mu Max                2.7686133
Policy mu Min                -2.4612434
Policy log std Mean          -0.34372023
Policy log std Std           0.27189848
Policy log std Max           0.0067336336
Policy log std Min           -1.2197025
Z mean eval                  0.024420632
Z variance eval              0.0041689575
total_rewards                [301.09530432 337.6539805  303.56933047 280.90464274 317.51690505
 309.24326464 315.02968424 297.71174285 287.77312745 322.92234761]
total_rewards_mean           307.3420329873287
total_rewards_std            15.986488387127428
total_rewards_max            337.65398050284915
total_rewards_min            280.904642737178
Number of train steps total  10000
Number of env steps total    52000
Number of rollouts total     0
Train Time (s)               26.01996268099174
(Previous) Eval Time (s)     3.032453211955726
Sample Time (s)              12.985331521369517
Epoch Time (s)               42.03774741431698
Total Train Time (s)         414.1886532185599
Epoch                        9
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:57:20.804976 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #9 | Epoch Duration: 42.10604119300842
2020-01-11 12:57:20.805241 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #9 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02646622
Z variance train             0.00429978
KL Divergence                11.278105
KL Loss                      1.1278105
QF Loss                      73.95313
VF Loss                      14.119717
Policy Loss                  -165.16595
Q Predictions Mean           162.84343
Q Predictions Std            196.89377
Q Predictions Max            556.08344
Q Predictions Min            -4.5224214
V Predictions Mean           165.51758
V Predictions Std            197.91855
V Predictions Max            554.9185
V Predictions Min            -2.7175517
Log Pis Mean                 -1.0839729
Log Pis Std                  1.8196534
Log Pis Max                  9.703669
Log Pis Min                  -4.9922843
Policy mu Mean               0.028578533
Policy mu Std                0.59767014
Policy mu Max                2.679599
Policy mu Min                -2.5968673
Policy log std Mean          -0.3289263
Policy log std Std           0.2956758
Policy log std Max           -0.07970582
Policy log std Min           -1.370024
Z mean eval                  0.022232821
Z variance eval              0.0050627626
total_rewards                [301.56803375 308.3058364  291.86503133 275.14735524 284.64206346
 272.42313943 298.7009673  300.48605335 301.676092   305.27750757]
total_rewards_mean           294.0092079816226
total_rewards_std            11.938659822323112
total_rewards_max            308.30583640419593
total_rewards_min            272.4231394252992
Number of train steps total  11000
Number of env steps total    57000
Number of rollouts total     0
Train Time (s)               27.519884943030775
(Previous) Eval Time (s)     3.100476913154125
Sample Time (s)              13.157905467785895
Epoch Time (s)               43.778267323970795
Total Train Time (s)         457.70025158673525
Epoch                        10
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:58:04.317506 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #10 | Epoch Duration: 43.51204514503479
2020-01-11 12:58:04.317783 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #10 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024770185
Z variance train             0.005125423
KL Divergence                10.936361
KL Loss                      1.0936362
QF Loss                      295.73624
VF Loss                      26.168478
Policy Loss                  -201.3032
Q Predictions Mean           198.75148
Q Predictions Std            221.5504
Q Predictions Max            603.8952
Q Predictions Min            -6.3986573
V Predictions Mean           202.28491
V Predictions Std            222.77635
V Predictions Max            606.84247
V Predictions Min            -1.870068
Log Pis Mean                 -0.9997534
Log Pis Std                  1.6487101
Log Pis Max                  7.6677823
Log Pis Min                  -4.604624
Policy mu Mean               0.07650706
Policy mu Std                0.6019019
Policy mu Max                2.4174798
Policy mu Min                -2.8293886
Policy log std Mean          -0.35265258
Policy log std Std           0.30026853
Policy log std Max           0.07793287
Policy log std Min           -1.4116803
Z mean eval                  0.015652541
Z variance eval              0.005267519
total_rewards                [263.23380598 290.85230591 300.81964797 305.66319087 311.25661696
 282.0179303  296.88414964 273.23049351 307.62041785 292.90927204]
total_rewards_mean           292.4487831032951
total_rewards_std            14.773958730472446
total_rewards_max            311.2566169584714
total_rewards_min            263.2338059810577
Number of train steps total  12000
Number of env steps total    62000
Number of rollouts total     0
Train Time (s)               26.681740988977253
(Previous) Eval Time (s)     2.8339848471805453
Sample Time (s)              12.85430706338957
Epoch Time (s)               42.37003289954737
Total Train Time (s)         500.04698431445286
Epoch                        11
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:58:46.664871 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #11 | Epoch Duration: 42.34686255455017
2020-01-11 12:58:46.665104 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #11 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017202562
Z variance train             0.004865533
KL Divergence                11.002914
KL Loss                      1.1002915
QF Loss                      181.07234
VF Loss                      52.17975
Policy Loss                  -248.92714
Q Predictions Mean           245.00754
Q Predictions Std            245.6705
Q Predictions Max            662.5687
Q Predictions Min            -3.016951
V Predictions Mean           249.83835
V Predictions Std            246.93062
V Predictions Max            665.2566
V Predictions Min            -2.1041462
Log Pis Mean                 -0.774643
Log Pis Std                  1.8096651
Log Pis Max                  5.764523
Log Pis Min                  -4.814332
Policy mu Mean               0.185661
Policy mu Std                0.6644957
Policy mu Max                2.9382272
Policy mu Min                -2.1911383
Policy log std Mean          -0.36604786
Policy log std Std           0.28500217
Policy log std Max           0.08274603
Policy log std Min           -1.5257007
Z mean eval                  0.0148001285
Z variance eval              0.0052176416
total_rewards                [315.80193262 319.1162798  332.11650264 338.59017701 322.87048972
 316.22365896 334.25938578 331.94133847 335.77609556 338.08035707]
total_rewards_mean           328.4776217641104
total_rewards_std            8.580902948580936
total_rewards_max            338.59017701182074
total_rewards_min            315.80193261782637
Number of train steps total  13000
Number of env steps total    67000
Number of rollouts total     0
Train Time (s)               26.98285420006141
(Previous) Eval Time (s)     2.810535743832588
Sample Time (s)              13.544519854243845
Epoch Time (s)               43.337909798137844
Total Train Time (s)         543.4323657322675
Epoch                        12
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:59:30.049865 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #12 | Epoch Duration: 43.38459086418152
2020-01-11 12:59:30.050062 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #12 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014926562
Z variance train             0.00524496
KL Divergence                10.699949
KL Loss                      1.0699949
QF Loss                      265.7166
VF Loss                      61.28228
Policy Loss                  -258.06573
Q Predictions Mean           254.49438
Q Predictions Std            256.76083
Q Predictions Max            715.4876
Q Predictions Min            -1.3253379
V Predictions Mean           258.3325
V Predictions Std            257.37897
V Predictions Max            716.49335
V Predictions Min            -1.0958868
Log Pis Mean                 -0.9442928
Log Pis Std                  1.9438498
Log Pis Max                  7.921427
Log Pis Min                  -6.0506687
Policy mu Mean               0.048888493
Policy mu Std                0.70031065
Policy mu Max                2.8512623
Policy mu Min                -2.8321984
Policy log std Mean          -0.3788602
Policy log std Std           0.30704036
Policy log std Max           0.10775741
Policy log std Min           -1.7137343
Z mean eval                  0.029839326
Z variance eval              0.0053322827
total_rewards                [305.84743871 303.52871035 289.46504642 286.88144831 298.10187167
 284.37588975 280.12378248 286.1204261  291.85685653 298.09972152]
total_rewards_mean           292.4401191847412
total_rewards_std            8.14587105667993
total_rewards_max            305.8474387126886
total_rewards_min            280.1237824837426
Number of train steps total  14000
Number of env steps total    72000
Number of rollouts total     0
Train Time (s)               28.758478636853397
(Previous) Eval Time (s)     2.8569374782964587
Sample Time (s)              12.891096551902592
Epoch Time (s)               44.50651266705245
Total Train Time (s)         588.0653962534852
Epoch                        13
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:00:14.688431 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #13 | Epoch Duration: 44.638150215148926
2020-01-11 13:00:14.688773 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #13 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034245513
Z variance train             0.005297721
KL Divergence                10.659327
KL Loss                      1.0659326
QF Loss                      409.09558
VF Loss                      120.770355
Policy Loss                  -288.8505
Q Predictions Mean           283.13284
Q Predictions Std            279.66516
Q Predictions Max            755.8578
Q Predictions Min            -1.309652
V Predictions Mean           284.04657
V Predictions Std            277.7728
V Predictions Max            748.7658
V Predictions Min            -3.1427734
Log Pis Mean                 -0.6500893
Log Pis Std                  2.0287135
Log Pis Max                  8.4333315
Log Pis Min                  -6.6981454
Policy mu Mean               0.17819655
Policy mu Std                0.7385257
Policy mu Max                2.5760183
Policy mu Min                -2.7626138
Policy log std Mean          -0.38996825
Policy log std Std           0.29402006
Policy log std Max           0.07920103
Policy log std Min           -1.4692183
Z mean eval                  0.017868534
Z variance eval              0.004895323
total_rewards                [287.79326598 286.18283502 282.10209828 302.6775806  286.93192028
 278.67573386 287.71825528 281.85149321 278.10198471 279.57571844]
total_rewards_mean           285.16108856501006
total_rewards_std            6.840122357244287
total_rewards_max            302.6775805964505
total_rewards_min            278.1019847138413
Number of train steps total  15000
Number of env steps total    77000
Number of rollouts total     0
Train Time (s)               27.353071324992925
(Previous) Eval Time (s)     2.988294509705156
Sample Time (s)              13.610101957805455
Epoch Time (s)               43.951467792503536
Total Train Time (s)         631.5487938793376
Epoch                        14
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:00:58.171722 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #14 | Epoch Duration: 43.48271441459656
2020-01-11 13:00:58.171991 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #14 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017735012
Z variance train             0.004842176
KL Divergence                10.861052
KL Loss                      1.0861052
QF Loss                      278.8469
VF Loss                      98.97631
Policy Loss                  -250.65028
Q Predictions Mean           243.76315
Q Predictions Std            294.3006
Q Predictions Max            787.65955
Q Predictions Min            -9.744161
V Predictions Mean           252.67236
V Predictions Std            297.1654
V Predictions Max            802.03076
V Predictions Min            -8.565884
Log Pis Mean                 -0.7203664
Log Pis Std                  2.3904102
Log Pis Max                  13.491255
Log Pis Min                  -6.149107
Policy mu Mean               -0.023322454
Policy mu Std                0.7269004
Policy mu Max                2.6874213
Policy mu Min                -3.5207741
Policy log std Mean          -0.34617892
Policy log std Std           0.29688898
Policy log std Max           0.10735212
Policy log std Min           -1.6867508
Z mean eval                  0.016543983
Z variance eval              0.0047692684
total_rewards                [259.16347044 278.61242767 264.5536226  308.80801179 285.06491553
 262.4264823  279.68886253 296.98827703 266.55106717 278.59480663]
total_rewards_mean           278.0451943678251
total_rewards_std            15.074463201988229
total_rewards_max            308.80801178844075
total_rewards_min            259.1634704351494
Number of train steps total  16000
Number of env steps total    82000
Number of rollouts total     0
Train Time (s)               25.6920235469006
(Previous) Eval Time (s)     2.5192888299934566
Sample Time (s)              13.525228187907487
Epoch Time (s)               41.736540564801544
Total Train Time (s)         673.4962778198533
Epoch                        15
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:01:40.118654 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #15 | Epoch Duration: 41.946497201919556
2020-01-11 13:01:40.118806 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #15 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019408679
Z variance train             0.0047343187
KL Divergence                11.01398
KL Loss                      1.101398
QF Loss                      431.44366
VF Loss                      86.79666
Policy Loss                  -302.8077
Q Predictions Mean           296.873
Q Predictions Std            318.31573
Q Predictions Max            841.4767
Q Predictions Min            -6.799603
V Predictions Mean           300.3539
V Predictions Std            319.07706
V Predictions Max            850.0561
V Predictions Min            -4.9259877
Log Pis Mean                 -0.6664418
Log Pis Std                  1.9944844
Log Pis Max                  6.8548307
Log Pis Min                  -4.485857
Policy mu Mean               0.17554073
Policy mu Std                0.7427897
Policy mu Max                2.4492145
Policy mu Min                -2.7264948
Policy log std Mean          -0.39728817
Policy log std Std           0.31370053
Policy log std Max           0.036729224
Policy log std Min           -1.6720581
Z mean eval                  0.024265166
Z variance eval              0.0036865235
total_rewards                [286.71808674 290.9265508  298.56932278 268.78803955 342.19368946
 280.575141   300.15445992 300.70548829 290.26451723 341.70318684]
total_rewards_mean           300.0598482612112
total_rewards_std            22.862685234706607
total_rewards_max            342.1936894643089
total_rewards_min            268.78803954913303
Number of train steps total  17000
Number of env steps total    87000
Number of rollouts total     0
Train Time (s)               28.9319730498828
(Previous) Eval Time (s)     2.7289704671129584
Sample Time (s)              13.003757130354643
Epoch Time (s)               44.6647006473504
Total Train Time (s)         718.4887787993066
Epoch                        16
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:02:25.112110 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #16 | Epoch Duration: 44.99315047264099
2020-01-11 13:02:25.112309 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #16 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012826358
Z variance train             0.004156931
KL Divergence                11.552478
KL Loss                      1.1552478
QF Loss                      169.92691
VF Loss                      53.98797
Policy Loss                  -304.37158
Q Predictions Mean           299.9809
Q Predictions Std            321.44632
Q Predictions Max            885.4269
Q Predictions Min            -10.295655
V Predictions Mean           304.60956
V Predictions Std            320.62115
V Predictions Max            882.0562
V Predictions Min            0.18302876
Log Pis Mean                 -0.69500095
Log Pis Std                  1.7983378
Log Pis Max                  4.878118
Log Pis Min                  -7.5382595
Policy mu Mean               0.1433
Policy mu Std                0.72084486
Policy mu Max                2.3842416
Policy mu Min                -1.8988975
Policy log std Mean          -0.38823292
Policy log std Std           0.3070469
Policy log std Max           -0.032324918
Policy log std Min           -1.7396206
Z mean eval                  0.027338928
Z variance eval              0.0030665018
total_rewards                [280.07160029 249.5137855  277.10317104 314.90387581 272.89276356
 231.36277369 391.60446434 265.42814757 291.8043917  310.94758697]
total_rewards_mean           288.5632560458772
total_rewards_std            41.95697530076263
total_rewards_max            391.6044643407084
total_rewards_min            231.3627736867868
Number of train steps total  18000
Number of env steps total    92000
Number of rollouts total     0
Train Time (s)               26.16897400887683
(Previous) Eval Time (s)     3.057125468272716
Sample Time (s)              13.062044305726886
Epoch Time (s)               42.28814378287643
Total Train Time (s)         760.7763812541962
Epoch                        17
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:03:07.403874 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #17 | Epoch Duration: 42.29138255119324
2020-01-11 13:03:07.404158 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #17 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026848176
Z variance train             0.00306456
KL Divergence                12.276491
KL Loss                      1.2276491
QF Loss                      785.99976
VF Loss                      111.00566
Policy Loss                  -311.727
Q Predictions Mean           306.89636
Q Predictions Std            343.04355
Q Predictions Max            889.534
Q Predictions Min            -1.7269917
V Predictions Mean           308.83362
V Predictions Std            341.4034
V Predictions Max            888.31354
V Predictions Min            -2.698635
Log Pis Mean                 -0.6048809
Log Pis Std                  2.1523929
Log Pis Max                  8.921375
Log Pis Min                  -4.9406433
Policy mu Mean               0.010189795
Policy mu Std                0.8104257
Policy mu Max                2.6413598
Policy mu Min                -3.745624
Policy log std Mean          -0.3672398
Policy log std Std           0.27716634
Policy log std Max           0.074034095
Policy log std Min           -1.6216937
Z mean eval                  0.061852038
Z variance eval              0.002842093
total_rewards                [307.23247423 227.72623223 244.38140237 284.73971189 252.07115757
 231.81977491 242.13469929 253.64418222 266.75825984 239.95093254]
total_rewards_mean           255.04588270907752
total_rewards_std            23.552622068881476
total_rewards_max            307.23247423369526
total_rewards_min            227.72623222704664
Number of train steps total  19000
Number of env steps total    97000
Number of rollouts total     0
Train Time (s)               27.984274834860116
(Previous) Eval Time (s)     3.0600656997412443
Sample Time (s)              13.484332480002195
Epoch Time (s)               44.528673014603555
Total Train Time (s)         804.9761488540098
Epoch                        18
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:03:51.604245 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #18 | Epoch Duration: 44.19985818862915
2020-01-11 13:03:51.604528 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #18 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04909357
Z variance train             0.0019705826
KL Divergence                13.377094
KL Loss                      1.3377094
QF Loss                      265.0214
VF Loss                      130.58322
Policy Loss                  -306.8528
Q Predictions Mean           305.212
Q Predictions Std            342.80182
Q Predictions Max            958.12506
Q Predictions Min            -5.9291034
V Predictions Mean           312.5827
V Predictions Std            347.34378
V Predictions Max            970.6338
V Predictions Min            -4.371536
Log Pis Mean                 -0.45198244
Log Pis Std                  2.361471
Log Pis Max                  14.201766
Log Pis Min                  -3.4282153
Policy mu Mean               0.06978422
Policy mu Std                0.84315765
Policy mu Max                2.848539
Policy mu Min                -3.6156855
Policy log std Mean          -0.37655532
Policy log std Std           0.29750246
Policy log std Max           0.12699051
Policy log std Min           -1.5003128
Z mean eval                  0.032551955
Z variance eval              0.0023884312
total_rewards                [229.59976767 252.11726177 314.66253153 310.1411363  296.67004475
 311.79687717 223.08720538 320.0566634  229.4070158  259.32839416]
total_rewards_mean           274.6866897915763
total_rewards_std            37.76876573073495
total_rewards_max            320.0566633995989
total_rewards_min            223.08720537972485
Number of train steps total  20000
Number of env steps total    102000
Number of rollouts total     0
Train Time (s)               29.03593271691352
(Previous) Eval Time (s)     2.730958143249154
Sample Time (s)              13.010860747192055
Epoch Time (s)               44.77775160735473
Total Train Time (s)         850.054338642396
Epoch                        19
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:04:36.682599 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #19 | Epoch Duration: 45.07783389091492
2020-01-11 13:04:36.682927 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #19 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035602063
Z variance train             0.0024167045
KL Divergence                12.784178
KL Loss                      1.2784178
QF Loss                      692.8074
VF Loss                      57.885433
Policy Loss                  -320.45477
Q Predictions Mean           317.82422
Q Predictions Std            361.00085
Q Predictions Max            1017.2798
Q Predictions Min            -10.095617
V Predictions Mean           322.92346
V Predictions Std            362.23184
V Predictions Max            1021.9833
V Predictions Min            -6.0927887
Log Pis Mean                 -0.529155
Log Pis Std                  2.0769544
Log Pis Max                  7.918576
Log Pis Min                  -3.4868479
Policy mu Mean               0.16604418
Policy mu Std                0.77026176
Policy mu Max                2.4124887
Policy mu Min                -2.69885
Policy log std Mean          -0.41185126
Policy log std Std           0.332315
Policy log std Max           -0.034288123
Policy log std Min           -1.6310999
Z mean eval                  0.028429937
Z variance eval              0.0015821023
total_rewards                [359.90797637 397.50861844 350.53738241 307.23506261 422.24478604
 397.0734668  403.72526283 429.04803256 453.53165351 378.29415298]
total_rewards_mean           389.9106394560139
total_rewards_std            40.42938551379035
total_rewards_max            453.53165351180894
total_rewards_min            307.23506261023164
Number of train steps total  21000
Number of env steps total    107000
Number of rollouts total     0
Train Time (s)               25.97846653405577
(Previous) Eval Time (s)     3.030778472777456
Sample Time (s)              13.107301436830312
Epoch Time (s)               42.11654644366354
Total Train Time (s)         892.9637104491703
Epoch                        20
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:05:19.594108 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #20 | Epoch Duration: 42.910919189453125
2020-01-11 13:05:19.594416 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #20 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0131801125
Z variance train             0.00145547
KL Divergence                14.103607
KL Loss                      1.4103607
QF Loss                      213.44232
VF Loss                      46.81124
Policy Loss                  -363.33057
Q Predictions Mean           360.2741
Q Predictions Std            376.52155
Q Predictions Max            1025.1687
Q Predictions Min            -4.4116025
V Predictions Mean           363.04623
V Predictions Std            377.66635
V Predictions Max            1013.9024
V Predictions Min            -2.172397
Log Pis Mean                 -0.642649
Log Pis Std                  2.0666792
Log Pis Max                  9.714956
Log Pis Min                  -5.2287564
Policy mu Mean               0.006653484
Policy mu Std                0.7835911
Policy mu Max                2.6177874
Policy mu Min                -2.7577028
Policy log std Mean          -0.41435716
Policy log std Std           0.339225
Policy log std Max           0.16936746
Policy log std Min           -1.4961437
Z mean eval                  0.016211245
Z variance eval              0.0019518979
total_rewards                [381.70742756 396.98047642 394.02079063 390.87203211 439.94660362
 405.07513825 406.65967094 389.76137714 389.82789419 407.50312566]
total_rewards_mean           400.2354536522396
total_rewards_std            15.468320860047761
total_rewards_max            439.9466036172197
total_rewards_min            381.7074275615538
Number of train steps total  22000
Number of env steps total    112000
Number of rollouts total     0
Train Time (s)               25.24387700110674
(Previous) Eval Time (s)     3.8248661351390183
Sample Time (s)              13.727970531210303
Epoch Time (s)               42.79671366745606
Total Train Time (s)         935.660970161669
Epoch                        21
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:06:02.290041 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #21 | Epoch Duration: 42.69540810585022
2020-01-11 13:06:02.290205 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #21 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02966624
Z variance train             0.0021563394
KL Divergence                13.241825
KL Loss                      1.3241825
QF Loss                      180.02373
VF Loss                      54.55162
Policy Loss                  -375.80896
Q Predictions Mean           371.59125
Q Predictions Std            397.37744
Q Predictions Max            1032.819
Q Predictions Min            -8.794551
V Predictions Mean           377.06165
V Predictions Std            399.97034
V Predictions Max            1024.7158
V Predictions Min            -0.75126624
Log Pis Mean                 -0.5353912
Log Pis Std                  2.0798564
Log Pis Max                  7.6666894
Log Pis Min                  -5.1779675
Policy mu Mean               0.10783839
Policy mu Std                0.83395123
Policy mu Max                2.8468683
Policy mu Min                -2.6395855
Policy log std Mean          -0.38594317
Policy log std Std           0.29998636
Policy log std Max           0.014181465
Policy log std Min           -1.5055356
Z mean eval                  0.021659968
Z variance eval              0.00258008
total_rewards                [189.41315298 187.15664612 382.15430205 193.58525399 208.25155179
 195.67557439 446.17192004 449.63432253 242.35154597 398.35030619]
total_rewards_mean           289.27445760550074
total_rewards_std            108.60031278189629
total_rewards_max            449.63432253369666
total_rewards_min            187.15664612486543
Number of train steps total  23000
Number of env steps total    117000
Number of rollouts total     0
Train Time (s)               26.9258065498434
(Previous) Eval Time (s)     3.7233209861442447
Sample Time (s)              14.221943406388164
Epoch Time (s)               44.87107094237581
Total Train Time (s)         979.6713189501315
Epoch                        22
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:06:46.304441 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #22 | Epoch Duration: 44.01405668258667
2020-01-11 13:06:46.304744 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #22 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023783162
Z variance train             0.0031657952
KL Divergence                12.3429985
KL Loss                      1.2342999
QF Loss                      322.06335
VF Loss                      99.9649
Policy Loss                  -384.3465
Q Predictions Mean           379.66156
Q Predictions Std            396.3462
Q Predictions Max            1095.1401
Q Predictions Min            -8.678114
V Predictions Mean           380.94943
V Predictions Std            393.4533
V Predictions Max            1099.2142
V Predictions Min            0.6983266
Log Pis Mean                 -0.14323518
Log Pis Std                  2.256481
Log Pis Max                  7.5280504
Log Pis Min                  -4.308327
Policy mu Mean               -0.0155652175
Policy mu Std                0.87308496
Policy mu Max                2.955018
Policy mu Min                -2.8195434
Policy log std Mean          -0.45718512
Policy log std Std           0.35639915
Policy log std Max           -0.03354229
Policy log std Min           -1.660883
Z mean eval                  0.01013872
Z variance eval              0.0037015039
total_rewards                [485.21488956 441.43792771 475.43153246 375.51760576 397.05457901
 437.34324544 264.67343081 278.68000786 451.7006364  485.9107145 ]
total_rewards_mean           409.2964569514247
total_rewards_std            76.74135966207751
total_rewards_max            485.91071450355787
total_rewards_min            264.67343081492174
Number of train steps total  24000
Number of env steps total    122000
Number of rollouts total     0
Train Time (s)               25.761256170924753
(Previous) Eval Time (s)     2.8659618669189513
Sample Time (s)              13.49283909238875
Epoch Time (s)               42.12005713023245
Total Train Time (s)         1023.0091504384764
Epoch                        23
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:07:29.644504 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #23 | Epoch Duration: 43.33953237533569
2020-01-11 13:07:29.644772 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #23 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014051551
Z variance train             0.0031679422
KL Divergence                12.129549
KL Loss                      1.2129549
QF Loss                      325.2149
VF Loss                      102.777115
Policy Loss                  -418.06052
Q Predictions Mean           414.45218
Q Predictions Std            415.25665
Q Predictions Max            1135.9943
Q Predictions Min            -2.3129935
V Predictions Mean           416.83582
V Predictions Std            417.38696
V Predictions Max            1134.7812
V Predictions Min            -1.424007
Log Pis Mean                 0.011192933
Log Pis Std                  2.4713197
Log Pis Max                  8.606705
Log Pis Min                  -3.471467
Policy mu Mean               0.1428458
Policy mu Std                0.9314835
Policy mu Max                2.622358
Policy mu Min                -2.8447485
Policy log std Mean          -0.4497211
Policy log std Std           0.35308692
Policy log std Max           0.20044456
Policy log std Min           -1.8652624
Z mean eval                  0.035847142
Z variance eval              0.002973244
total_rewards                [412.42310335 292.73986884 415.02652339 424.58517589 488.33923322
 434.53569571 481.19536013 454.13288659 454.5544152  492.94652385]
total_rewards_mean           435.0478786181002
total_rewards_std            55.082292430456086
total_rewards_max            492.94652385425377
total_rewards_min            292.73986883512936
Number of train steps total  25000
Number of env steps total    127000
Number of rollouts total     0
Train Time (s)               27.344634288921952
(Previous) Eval Time (s)     4.085182229988277
Sample Time (s)              14.44962946139276
Epoch Time (s)               45.87944598030299
Total Train Time (s)         1068.8794096778147
Epoch                        24
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:08:15.517103 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #24 | Epoch Duration: 45.87209701538086
2020-01-11 13:08:15.517399 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #24 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028866794
Z variance train             0.0026620238
KL Divergence                12.626535
KL Loss                      1.2626536
QF Loss                      302.90125
VF Loss                      104.17258
Policy Loss                  -418.07535
Q Predictions Mean           417.80072
Q Predictions Std            425.34628
Q Predictions Max            1142.8862
Q Predictions Min            -3.5029252
V Predictions Mean           420.8396
V Predictions Std            426.66052
V Predictions Max            1144.0044
V Predictions Min            -2.6834755
Log Pis Mean                 -0.12952906
Log Pis Std                  2.495735
Log Pis Max                  8.489162
Log Pis Min                  -6.271227
Policy mu Mean               0.123733126
Policy mu Std                0.935847
Policy mu Max                2.937101
Policy mu Min                -2.6373858
Policy log std Mean          -0.4151806
Policy log std Std           0.34521705
Policy log std Max           0.026608273
Policy log std Min           -1.8963623
Z mean eval                  0.026491841
Z variance eval              0.0029971413
total_rewards                [323.91488207 441.19055695 436.23891715 510.89046534 538.62799241
 367.85954807 378.54348041 388.52653895 490.19254286 292.59147114]
total_rewards_mean           416.8576395357192
total_rewards_std            76.6601590108277
total_rewards_max            538.627992410678
total_rewards_min            292.5914711433811
Number of train steps total  26000
Number of env steps total    132000
Number of rollouts total     0
Train Time (s)               28.732640233822167
(Previous) Eval Time (s)     4.077575876843184
Sample Time (s)              14.60029983241111
Epoch Time (s)               47.41051594307646
Total Train Time (s)         1116.2920385063626
Epoch                        25
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:09:02.929282 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #25 | Epoch Duration: 47.41166424751282
2020-01-11 13:09:02.929482 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #25 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025184939
Z variance train             0.002761394
KL Divergence                12.510846
KL Loss                      1.2510847
QF Loss                      271.78195
VF Loss                      186.71962
Policy Loss                  -420.95444
Q Predictions Mean           416.15952
Q Predictions Std            425.74136
Q Predictions Max            1160.7803
Q Predictions Min            -2.8319514
V Predictions Mean           416.07452
V Predictions Std            427.49347
V Predictions Max            1169.7275
V Predictions Min            -2.1866875
Log Pis Mean                 0.43747795
Log Pis Std                  2.7410274
Log Pis Max                  9.955855
Log Pis Min                  -4.377689
Policy mu Mean               0.020199962
Policy mu Std                1.0356315
Policy mu Max                2.964546
Policy mu Min                -2.640071
Policy log std Mean          -0.4783528
Policy log std Std           0.3781115
Policy log std Max           -0.0032541752
Policy log std Min           -2.0046253
Z mean eval                  0.02694326
Z variance eval              0.0028904458
total_rewards                [288.87709281 310.68846854 447.64043081 283.08849752 298.682763
 317.53122367 519.01855478 307.73968218 301.34684038 540.27316151]
total_rewards_mean           361.4886715198163
total_rewards_std            95.17573532847778
total_rewards_max            540.2731615090534
total_rewards_min            283.0884975192184
Number of train steps total  27000
Number of env steps total    137000
Number of rollouts total     0
Train Time (s)               25.84621139196679
(Previous) Eval Time (s)     4.078456501010805
Sample Time (s)              13.975061425939202
Epoch Time (s)               43.8997293189168
Total Train Time (s)         1159.6137187369168
Epoch                        26
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:09:46.251494 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #26 | Epoch Duration: 43.321837425231934
2020-01-11 13:09:46.251695 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #26 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036034774
Z variance train             0.003061121
KL Divergence                12.22676
KL Loss                      1.222676
QF Loss                      1505.104
VF Loss                      130.27061
Policy Loss                  -468.06525
Q Predictions Mean           460.70425
Q Predictions Std            458.08734
Q Predictions Max            1257.3331
Q Predictions Min            -0.58698964
V Predictions Mean           464.43546
V Predictions Std            459.70526
V Predictions Max            1256.7776
V Predictions Min            -8.557641
Log Pis Mean                 0.6284655
Log Pis Std                  3.087498
Log Pis Max                  10.939497
Log Pis Min                  -5.9614773
Policy mu Mean               -0.07390814
Policy mu Std                1.1144462
Policy mu Max                3.0222447
Policy mu Min                -3.4201126
Policy log std Mean          -0.46530595
Policy log std Std           0.35047063
Policy log std Max           -0.0912116
Policy log std Min           -1.8455901
Z mean eval                  0.055180263
Z variance eval              0.0020371783
total_rewards                [459.49868185 549.38909226 386.80683831 409.78220097 315.56632808
 387.40320291 401.43986782 487.27098208 383.53438488 410.83553108]
total_rewards_mean           419.15271102435224
total_rewards_std            61.44365598141152
total_rewards_max            549.3890922641725
total_rewards_min            315.56632807862445
Number of train steps total  28000
Number of env steps total    142000
Number of rollouts total     0
Train Time (s)               26.344206786248833
(Previous) Eval Time (s)     3.500315035227686
Sample Time (s)              13.699444547761232
Epoch Time (s)               43.54396636923775
Total Train Time (s)         1203.3170140138827
Epoch                        27
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:10:29.956835 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #27 | Epoch Duration: 43.704957485198975
2020-01-11 13:10:29.957029 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #27 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012850856
Z variance train             0.002078609
KL Divergence                13.014717
KL Loss                      1.3014717
QF Loss                      503.40115
VF Loss                      193.3071
Policy Loss                  -497.66885
Q Predictions Mean           489.3649
Q Predictions Std            460.66983
Q Predictions Max            1308.1028
Q Predictions Min            -3.807507
V Predictions Mean           490.25998
V Predictions Std            460.5629
V Predictions Max            1305.8947
V Predictions Min            -1.0062952
Log Pis Mean                 0.29993632
Log Pis Std                  2.4716413
Log Pis Max                  11.40276
Log Pis Min                  -3.6597877
Policy mu Mean               -0.112412214
Policy mu Std                0.99785644
Policy mu Max                2.6913042
Policy mu Min                -2.8485994
Policy log std Mean          -0.44356546
Policy log std Std           0.3306295
Policy log std Max           -0.06285056
Policy log std Min           -1.6305707
Z mean eval                  0.0077746883
Z variance eval              0.0016220752
total_rewards                [465.86796645 437.78376461 387.79869889 459.7113705  451.195643
 532.31198741 447.67778323 409.33115117 451.09795333 382.61854136]
total_rewards_mean           442.5394859945818
total_rewards_std            40.96981316731252
total_rewards_max            532.3119874057277
total_rewards_min            382.61854136206125
Number of train steps total  29000
Number of env steps total    147000
Number of rollouts total     0
Train Time (s)               28.31896388484165
(Previous) Eval Time (s)     3.6610762630589306
Sample Time (s)              14.07119760895148
Epoch Time (s)               46.05123775685206
Total Train Time (s)         1249.453625710681
Epoch                        28
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:11:16.092489 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #28 | Epoch Duration: 46.13531255722046
2020-01-11 13:11:16.092653 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #28 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008634341
Z variance train             0.0015317093
KL Divergence                13.837461
KL Loss                      1.3837461
QF Loss                      380.9655
VF Loss                      77.44176
Policy Loss                  -484.24942
Q Predictions Mean           479.00995
Q Predictions Std            475.6788
Q Predictions Max            1312.8416
Q Predictions Min            -6.9235334
V Predictions Mean           485.3715
V Predictions Std            480.01352
V Predictions Max            1351.8522
V Predictions Min            -3.4814966
Log Pis Mean                 0.0739788
Log Pis Std                  2.3493538
Log Pis Max                  11.169815
Log Pis Min                  -4.45555
Policy mu Mean               0.026036054
Policy mu Std                0.93832016
Policy mu Max                2.6313546
Policy mu Min                -2.8339243
Policy log std Mean          -0.48197982
Policy log std Std           0.3713602
Policy log std Max           -0.08946999
Policy log std Min           -1.8907413
Z mean eval                  0.038437948
Z variance eval              0.0021964344
total_rewards                [278.79714469 573.35359657 407.95782178 501.54948001 448.64784929
 456.4233972  369.67420605 531.33677024 517.44134523 452.33171416]
total_rewards_mean           453.7513325209958
total_rewards_std            81.53248419179998
total_rewards_max            573.3535965719005
total_rewards_min            278.79714468634745
Number of train steps total  30000
Number of env steps total    152000
Number of rollouts total     0
Train Time (s)               27.116965042892843
(Previous) Eval Time (s)     3.74489339068532
Sample Time (s)              14.060370961669832
Epoch Time (s)               44.922229395247996
Total Train Time (s)         1294.362741889432
Epoch                        29
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:12:01.006678 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #29 | Epoch Duration: 44.91384482383728
2020-01-11 13:12:01.006969 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #29 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037064575
Z variance train             0.00218954
KL Divergence                12.978675
KL Loss                      1.2978675
QF Loss                      1055.0471
VF Loss                      190.95793
Policy Loss                  -465.48444
Q Predictions Mean           468.38455
Q Predictions Std            472.93936
Q Predictions Max            1352.0895
Q Predictions Min            -15.300528
V Predictions Mean           466.88016
V Predictions Std            469.198
V Predictions Max            1350.7434
V Predictions Min            -2.885346
Log Pis Mean                 0.11674349
Log Pis Std                  2.5184312
Log Pis Max                  8.135425
Log Pis Min                  -4.766385
Policy mu Mean               -0.10150671
Policy mu Std                0.9640639
Policy mu Max                2.4565396
Policy mu Min                -2.7191756
Policy log std Mean          -0.47512683
Policy log std Std           0.356667
Policy log std Max           0.039265558
Policy log std Min           -1.7330028
Z mean eval                  0.01662395
Z variance eval              0.008971082
total_rewards                [466.96679405 475.61489669 409.65942695 414.52617366 417.53978115
 410.95747292 464.82345057 459.98978074 450.63681688 453.12122541]
total_rewards_mean           442.383581903672
total_rewards_std            24.813934983934107
total_rewards_max            475.61489668863965
total_rewards_min            409.6594269540095
Number of train steps total  31000
Number of env steps total    157000
Number of rollouts total     0
Train Time (s)               28.46138303494081
(Previous) Eval Time (s)     3.736237217672169
Sample Time (s)              14.738916301168501
Epoch Time (s)               46.93653655378148
Total Train Time (s)         1341.5989631265402
Epoch                        30
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:12:48.242717 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #30 | Epoch Duration: 47.23549461364746
2020-01-11 13:12:48.242998 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #30 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023321202
Z variance train             0.0048621846
KL Divergence                10.898432
KL Loss                      1.0898432
QF Loss                      572.102
VF Loss                      143.09
Policy Loss                  -490.04318
Q Predictions Mean           486.0548
Q Predictions Std            488.73032
Q Predictions Max            1434.5762
Q Predictions Min            -4.513134
V Predictions Mean           487.84747
V Predictions Std            488.73108
V Predictions Max            1427.4701
V Predictions Min            -0.16421926
Log Pis Mean                 -0.14118859
Log Pis Std                  2.3945127
Log Pis Max                  7.06086
Log Pis Min                  -4.249814
Policy mu Mean               0.019764572
Policy mu Std                0.9285854
Policy mu Max                3.1089263
Policy mu Min                -3.026549
Policy log std Mean          -0.44187632
Policy log std Std           0.3244678
Policy log std Max           0.16797046
Policy log std Min           -1.7018704
Z mean eval                  0.027504444
Z variance eval              0.003322777
total_rewards                [569.16081679 560.73674209 602.59949283 545.89986509 575.21703071
 574.68854984 604.99823862 588.71426023 636.19971378 587.51198965]
total_rewards_mean           584.5726699620267
total_rewards_std            24.330640250494483
total_rewards_max            636.1997137766397
total_rewards_min            545.8998650889084
Number of train steps total  32000
Number of env steps total    162000
Number of rollouts total     0
Train Time (s)               27.851302972063422
(Previous) Eval Time (s)     4.034929053392261
Sample Time (s)              14.320357601158321
Epoch Time (s)               46.206589626614004
Total Train Time (s)         1388.3827348658815
Epoch                        31
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:13:35.028371 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #31 | Epoch Duration: 46.78511691093445
2020-01-11 13:13:35.028685 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #31 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028115904
Z variance train             0.0032979038
KL Divergence                11.925158
KL Loss                      1.1925157
QF Loss                      2438.6672
VF Loss                      90.40698
Policy Loss                  -529.61707
Q Predictions Mean           527.6529
Q Predictions Std            485.47855
Q Predictions Max            1420.0397
Q Predictions Min            0.75420386
V Predictions Mean           529.1121
V Predictions Std            486.2328
V Predictions Max            1435.6826
V Predictions Min            1.3568108
Log Pis Mean                 -0.13457507
Log Pis Std                  2.3257184
Log Pis Max                  7.2289
Log Pis Min                  -3.8216012
Policy mu Mean               -0.025249846
Policy mu Std                0.9114778
Policy mu Max                2.6297312
Policy mu Min                -3.351066
Policy log std Mean          -0.42880294
Policy log std Std           0.31418636
Policy log std Max           0.18684293
Policy log std Min           -1.438113
Z mean eval                  0.023242855
Z variance eval              0.0033805943
total_rewards                [579.06711945 565.46891865 570.77944339 530.53292068 505.44749427
 583.38668885 490.27273921 595.55321276 495.35721957 522.4677034 ]
total_rewards_mean           543.8333460220763
total_rewards_std            37.417321593738095
total_rewards_max            595.5532127562102
total_rewards_min            490.2727392093328
Number of train steps total  33000
Number of env steps total    167000
Number of rollouts total     0
Train Time (s)               27.88914395403117
(Previous) Eval Time (s)     4.613156035076827
Sample Time (s)              15.290813599713147
Epoch Time (s)               47.79311358882114
Total Train Time (s)         1435.8336076107807
Epoch                        32
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:14:22.477881 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #32 | Epoch Duration: 47.44896697998047
2020-01-11 13:14:22.478083 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #32 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023370128
Z variance train             0.0033848598
KL Divergence                11.92062
KL Loss                      1.192062
QF Loss                      439.05768
VF Loss                      93.60521
Policy Loss                  -517.95795
Q Predictions Mean           517.5522
Q Predictions Std            479.75037
Q Predictions Max            1408.6149
Q Predictions Min            -1.4733632
V Predictions Mean           519.6797
V Predictions Std            478.14343
V Predictions Max            1401.0028
V Predictions Min            -1.353454
Log Pis Mean                 -0.13203532
Log Pis Std                  2.3721309
Log Pis Max                  8.436514
Log Pis Min                  -8.480138
Policy mu Mean               0.03234349
Policy mu Std                0.88291585
Policy mu Max                2.5594065
Policy mu Min                -3.0887172
Policy log std Mean          -0.4939328
Policy log std Std           0.36006775
Policy log std Max           0.07632786
Policy log std Min           -1.9891741
Z mean eval                  0.034168635
Z variance eval              0.0041574547
total_rewards                [494.21826042 585.20252424 495.35588832 488.5537814  591.63356025
 543.36563508 544.39785696 576.37419316 546.36943493 522.31427151]
total_rewards_mean           538.7785406292955
total_rewards_std            36.24535304438596
total_rewards_max            591.6335602486108
total_rewards_min            488.5537814029403
Number of train steps total  34000
Number of env steps total    172000
Number of rollouts total     0
Train Time (s)               25.98423590697348
(Previous) Eval Time (s)     4.268728481605649
Sample Time (s)              14.798188443761319
Epoch Time (s)               45.05115283234045
Total Train Time (s)         1480.5828813565895
Epoch                        33
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:15:07.231276 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #33 | Epoch Duration: 44.753018617630005
2020-01-11 13:15:07.231521 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #33 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033557296
Z variance train             0.004155421
KL Divergence                11.371932
KL Loss                      1.1371932
QF Loss                      390.07874
VF Loss                      160.9448
Policy Loss                  -519.5617
Q Predictions Mean           520.59985
Q Predictions Std            495.22574
Q Predictions Max            1414.1788
Q Predictions Min            2.9517992
V Predictions Mean           522.6564
V Predictions Std            494.58508
V Predictions Max            1418.241
V Predictions Min            1.3037977
Log Pis Mean                 0.15239947
Log Pis Std                  2.63717
Log Pis Max                  8.756683
Log Pis Min                  -4.650184
Policy mu Mean               0.10008844
Policy mu Std                0.988865
Policy mu Max                3.348257
Policy mu Min                -3.135351
Policy log std Mean          -0.4622122
Policy log std Std           0.31372714
Policy log std Max           0.25171983
Policy log std Min           -1.5460846
Z mean eval                  0.01281474
Z variance eval              0.004071056
total_rewards                [585.0978726  604.6464912  559.8824098  628.11434418 533.44542528
 559.08934898 573.96785295 532.70578648 554.1279401  566.31769255]
total_rewards_mean           569.7395164128328
total_rewards_std            28.345462342006808
total_rewards_max            628.1143441771289
total_rewards_min            532.7057864843389
Number of train steps total  35000
Number of env steps total    177000
Number of rollouts total     0
Train Time (s)               27.893071432132274
(Previous) Eval Time (s)     3.9703202680684626
Sample Time (s)              14.595870247110724
Epoch Time (s)               46.45926194731146
Total Train Time (s)         1527.1209403104149
Epoch                        34
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:15:53.768562 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #34 | Epoch Duration: 46.536837339401245
2020-01-11 13:15:53.768749 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #34 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014432535
Z variance train             0.0040643644
KL Divergence                11.311966
KL Loss                      1.1311966
QF Loss                      597.3484
VF Loss                      267.66644
Policy Loss                  -510.9062
Q Predictions Mean           507.46097
Q Predictions Std            483.04742
Q Predictions Max            1350.6487
Q Predictions Min            -17.294813
V Predictions Mean           510.07153
V Predictions Std            483.50195
V Predictions Max            1348.3734
V Predictions Min            -16.895695
Log Pis Mean                 -0.16625094
Log Pis Std                  2.3825514
Log Pis Max                  9.238575
Log Pis Min                  -4.698095
Policy mu Mean               0.09368058
Policy mu Std                0.85889953
Policy mu Max                3.6176672
Policy mu Min                -2.887853
Policy log std Mean          -0.47843495
Policy log std Std           0.3394715
Policy log std Max           0.23913395
Policy log std Min           -1.5488743
Z mean eval                  0.021307167
Z variance eval              0.0041198255
total_rewards                [494.76814946 484.69828352 585.58506676 579.61594988 517.80398238
 624.41407791 528.30098516 472.27787354 612.79172586 572.49275679]
total_rewards_mean           547.2748851265757
total_rewards_std            51.88289709887493
total_rewards_max            624.414077910271
total_rewards_min            472.27787354312505
Number of train steps total  36000
Number of env steps total    182000
Number of rollouts total     0
Train Time (s)               26.131383549422026
(Previous) Eval Time (s)     4.0476192510686815
Sample Time (s)              15.197633587755263
Epoch Time (s)               45.37663638824597
Total Train Time (s)         1572.859065681696
Epoch                        35
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:16:39.507551 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #35 | Epoch Duration: 45.73866605758667
2020-01-11 13:16:39.507735 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #35 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021000773
Z variance train             0.0041219033
KL Divergence                11.251633
KL Loss                      1.1251633
QF Loss                      763.9186
VF Loss                      532.12683
Policy Loss                  -595.70856
Q Predictions Mean           589.8623
Q Predictions Std            478.44553
Q Predictions Max            1342.0907
Q Predictions Min            -1.8343524
V Predictions Mean           599.0412
V Predictions Std            481.62515
V Predictions Max            1340.7057
V Predictions Min            -1.1121916
Log Pis Mean                 0.21934888
Log Pis Std                  2.4039617
Log Pis Max                  10.365986
Log Pis Min                  -3.984906
Policy mu Mean               0.09980184
Policy mu Std                0.9643656
Policy mu Max                2.7131484
Policy mu Min                -3.4103935
Policy log std Mean          -0.5138587
Policy log std Std           0.32911798
Policy log std Max           -0.047321767
Policy log std Min           -1.5618036
Z mean eval                  0.090470135
Z variance eval              0.0035901815
total_rewards                [545.3278321  440.23148985 390.63740118 455.00862074 487.32827615
 384.90929181 320.7463865  459.17569614 620.25875068 388.14332311]
total_rewards_mean           449.1767068259993
total_rewards_std            82.43799295311018
total_rewards_max            620.2587506755044
total_rewards_min            320.746386496249
Number of train steps total  37000
Number of env steps total    187000
Number of rollouts total     0
Train Time (s)               28.027905622962862
(Previous) Eval Time (s)     4.409385928884149
Sample Time (s)              14.480240107979625
Epoch Time (s)               46.917531659826636
Total Train Time (s)         1619.3480082508177
Epoch                        36
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:17:25.996723 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #36 | Epoch Duration: 46.48878860473633
2020-01-11 13:17:25.996899 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #36 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09236379
Z variance train             0.0035692782
KL Divergence                12.055751
KL Loss                      1.2055751
QF Loss                      555.5335
VF Loss                      81.344986
Policy Loss                  -560.7245
Q Predictions Mean           561.0303
Q Predictions Std            504.24197
Q Predictions Max            1412.8945
Q Predictions Min            0.27267772
V Predictions Mean           561.54736
V Predictions Std            504.58395
V Predictions Max            1407.0508
V Predictions Min            -3.7067316
Log Pis Mean                 -0.106391266
Log Pis Std                  2.1844819
Log Pis Max                  5.8438673
Log Pis Min                  -4.4212284
Policy mu Mean               0.012656282
Policy mu Std                0.88072115
Policy mu Max                2.6034734
Policy mu Min                -2.474374
Policy log std Mean          -0.4769772
Policy log std Std           0.3134988
Policy log std Max           0.10926212
Policy log std Min           -1.52477
Z mean eval                  0.03618317
Z variance eval              0.002759031
total_rewards                [606.22363691 635.89011096 622.24465032 609.31210375 629.42319876
 651.74039132 607.69891563 635.01935373 635.45405759 647.93697352]
total_rewards_mean           628.0943392488349
total_rewards_std            15.488122139140517
total_rewards_max            651.740391324938
total_rewards_min            606.2236369086104
Number of train steps total  38000
Number of env steps total    192000
Number of rollouts total     0
Train Time (s)               29.56445282883942
(Previous) Eval Time (s)     3.9803637582808733
Sample Time (s)              14.502237536944449
Epoch Time (s)               48.04705412406474
Total Train Time (s)         1668.295399365481
Epoch                        37
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:18:14.948043 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #37 | Epoch Duration: 48.95096778869629
2020-01-11 13:18:14.948341 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #37 | Started Training: True
