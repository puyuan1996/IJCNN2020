---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0024144803
Z variance train             0.6934786
KL Divergence                0.14880577
KL Loss                      0.014880577
QF Loss                      53.90004
VF Loss                      28.658463
Policy Loss                  -5.315317
Q Predictions Mean           -0.00078928855
Q Predictions Std            0.0015531532
Q Predictions Max            0.0036849699
Q Predictions Min            -0.004792961
V Predictions Mean           -4.723155e-06
V Predictions Std            0.0016326411
V Predictions Max            0.0052334135
V Predictions Min            -0.0043206974
Log Pis Mean                 -5.335787
Log Pis Std                  0.63713086
Log Pis Max                  -3.371165
Log Pis Min                  -6.8524017
Policy mu Mean               0.00091914076
Policy mu Std                0.002134621
Policy mu Max                0.005435868
Policy mu Min                -0.004109341
Policy log std Mean          8.958782e-05
Policy log std Std           0.0014303765
Policy log std Max           0.0047853193
Policy log std Min           -0.0036587105
Z mean eval                  0.08586492
Z variance eval              0.18214989
total_rewards                [  -3.61142271  -17.86015753    7.55359408  -12.76993245   -6.24304622
 -195.66754076 -296.80962361   -2.48111762  -37.36885156  -18.108698  ]
total_rewards_mean           -58.33667963833004
total_rewards_std            97.29938355651312
total_rewards_max            7.553594082402999
total_rewards_min            -296.8096236145036
Number of train steps total  1000
Number of env steps total    7000
Number of rollouts total     0
Train Time (s)               41.94763231603429
(Previous) Eval Time (s)     0
Sample Time (s)              25.409461858216673
Epoch Time (s)               67.35709417425096
Total Train Time (s)         75.06225500162691
Epoch                        0
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:30:33.279151 UTC | [2020_01_10_11_29_18] Iteration #0 | Epoch Duration: 75.06601643562317
2020-01-10 11:30:33.279356 UTC | [2020_01_10_11_29_18] Iteration #0 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.084154546
Z variance train             0.18753143
KL Divergence                2.1883454
KL Loss                      0.21883455
QF Loss                      40.614227
VF Loss                      2.4316475
Policy Loss                  -10.049331
Q Predictions Mean           4.4469066
Q Predictions Std            8.976899
Q Predictions Max            35.58304
Q Predictions Min            -32.078465
V Predictions Mean           9.715765
V Predictions Std            8.73597
V Predictions Max            40.744686
V Predictions Min            -23.599014
Log Pis Mean                 -5.2217755
Log Pis Std                  0.6770199
Log Pis Max                  -3.1011343
Log Pis Min                  -8.605711
Policy mu Mean               0.04129806
Policy mu Std                0.15440018
Policy mu Max                0.4831882
Policy mu Min                -0.42090192
Policy log std Mean          -0.27021554
Policy log std Std           0.03195905
Policy log std Max           -0.18585289
Policy log std Min           -0.3823989
Z mean eval                  0.08118663
Z variance eval              0.038939018
total_rewards                [ 39.03961654  23.81084212 156.49072706  70.5650514  212.24588702
  42.48785432 174.78166473 214.44007897 108.54383697  53.7838106 ]
total_rewards_mean           109.61893697271603
total_rewards_std            70.32629914234911
total_rewards_max            214.4400789726244
total_rewards_min            23.810842120927212
Number of train steps total  2000
Number of env steps total    12000
Number of rollouts total     0
Train Time (s)               40.95247269794345
(Previous) Eval Time (s)     7.708421305753291
Sample Time (s)              19.755818807985634
Epoch Time (s)               68.41671281168237
Total Train Time (s)         157.61887453543022
Epoch                        1
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:31:55.836562 UTC | [2020_01_10_11_29_18] Iteration #1 | Epoch Duration: 82.55706024169922
2020-01-10 11:31:55.836749 UTC | [2020_01_10_11_29_18] Iteration #1 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.079996616
Z variance train             0.040764302
KL Divergence                5.6675367
KL Loss                      0.5667537
QF Loss                      105.31844
VF Loss                      12.172832
Policy Loss                  -21.854212
Q Predictions Mean           18.131613
Q Predictions Std            14.018639
Q Predictions Max            46.025013
Q Predictions Min            -21.639387
V Predictions Mean           23.3998
V Predictions Std            13.478981
V Predictions Max            52.378574
V Predictions Min            -20.055086
Log Pis Mean                 -3.9245462
Log Pis Std                  1.3258061
Log Pis Max                  -0.6815011
Log Pis Min                  -10.515726
Policy mu Mean               0.035709687
Policy mu Std                0.22056988
Policy mu Max                0.56854254
Policy mu Min                -0.7324796
Policy log std Mean          -0.633201
Policy log std Std           0.101329
Policy log std Max           -0.38188007
Policy log std Min           -0.90800107
Z mean eval                  0.09570542
Z variance eval              0.020894838
total_rewards                [212.92567042 168.80317975  11.08997531 279.50509597 197.23959084
 203.6471909   53.47523445  95.12200266 230.92696489  44.93596025]
total_rewards_mean           149.76708654463215
total_rewards_std            86.83667025316103
total_rewards_max            279.50509596845274
total_rewards_min            11.089975313721911
Number of train steps total  3000
Number of env steps total    17000
Number of rollouts total     0
Train Time (s)               41.93233691016212
(Previous) Eval Time (s)     21.848494059871882
Sample Time (s)              21.7635663500987
Epoch Time (s)               85.5443973201327
Total Train Time (s)         244.5892755324021
Epoch                        2
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:33:22.809533 UTC | [2020_01_10_11_29_18] Iteration #2 | Epoch Duration: 86.97264075279236
2020-01-10 11:33:22.809706 UTC | [2020_01_10_11_29_18] Iteration #2 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.097685255
Z variance train             0.021473903
KL Divergence                7.280383
KL Loss                      0.7280383
QF Loss                      143.38605
VF Loss                      26.03009
Policy Loss                  -38.400723
Q Predictions Mean           33.563705
Q Predictions Std            17.54115
Q Predictions Max            88.19368
Q Predictions Min            -35.078884
V Predictions Mean           41.17906
V Predictions Std            16.261513
V Predictions Max            91.66943
V Predictions Min            -20.04874
Log Pis Mean                 -3.414616
Log Pis Std                  1.5623848
Log Pis Max                  -0.16297798
Log Pis Min                  -8.677931
Policy mu Mean               -0.008089332
Policy mu Std                0.265815
Policy mu Max                1.027027
Policy mu Min                -0.8253619
Policy log std Mean          -0.71997684
Policy log std Std           0.10667041
Policy log std Max           -0.44662598
Policy log std Min           -1.0200765
Z mean eval                  0.097382404
Z variance eval              0.014536353
total_rewards                [216.71615628   5.90617304 259.92019226 122.70388779   3.08639908
 186.48296353 252.99287718 221.13848664 100.03650033  42.95574183]
total_rewards_mean           141.19393779536472
total_rewards_std            94.76486156126363
total_rewards_max            259.9201922592563
total_rewards_min            3.0863990803694263
Number of train steps total  4000
Number of env steps total    22000
Number of rollouts total     0
Train Time (s)               43.45484367525205
(Previous) Eval Time (s)     23.276506513822824
Sample Time (s)              23.11114214733243
Epoch Time (s)               89.8424923364073
Total Train Time (s)         335.0160050354898
Epoch                        3
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:34:53.236400 UTC | [2020_01_10_11_29_18] Iteration #3 | Epoch Duration: 90.42655658721924
2020-01-10 11:34:53.236575 UTC | [2020_01_10_11_29_18] Iteration #3 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09702055
Z variance train             0.014536874
KL Divergence                8.166545
KL Loss                      0.8166545
QF Loss                      158.31564
VF Loss                      16.15624
Policy Loss                  -54.566982
Q Predictions Mean           49.648827
Q Predictions Std            23.578413
Q Predictions Max            100.529594
Q Predictions Min            -33.373558
V Predictions Mean           55.453453
V Predictions Std            21.570137
V Predictions Max            112.23432
V Predictions Min            -21.963873
Log Pis Mean                 -3.2513134
Log Pis Std                  1.42207
Log Pis Max                  0.4820536
Log Pis Min                  -8.140999
Policy mu Mean               0.011804791
Policy mu Std                0.29028836
Policy mu Max                1.3614933
Policy mu Min                -0.97217685
Policy log std Mean          -0.7166178
Policy log std Std           0.09989862
Policy log std Max           -0.41710198
Policy log std Min           -1.0267929
Z mean eval                  0.08118115
Z variance eval              0.018765334
total_rewards                [124.94569504 167.99680153  14.82701523  27.20444836 173.68512134
 130.31583116  94.32320408 114.37638008 163.2719402    6.58089668]
total_rewards_mean           101.75273336957868
total_rewards_std            60.89883576162242
total_rewards_max            173.68512133690925
total_rewards_min            6.5808966807099605
Number of train steps total  5000
Number of env steps total    27000
Number of rollouts total     0
Train Time (s)               42.51142174284905
(Previous) Eval Time (s)     23.86030938103795
Sample Time (s)              23.157217722851783
Epoch Time (s)               89.52894884673879
Total Train Time (s)         423.31196129508317
Epoch                        4
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:36:21.534664 UTC | [2020_01_10_11_29_18] Iteration #4 | Epoch Duration: 88.29793095588684
2020-01-10 11:36:21.534916 UTC | [2020_01_10_11_29_18] Iteration #4 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07858054
Z variance train             0.017390117
KL Divergence                7.714176
KL Loss                      0.7714176
QF Loss                      124.995544
VF Loss                      17.594904
Policy Loss                  -71.47335
Q Predictions Mean           66.467545
Q Predictions Std            23.980442
Q Predictions Max            108.88633
Q Predictions Min            -17.02708
V Predictions Mean           71.96976
V Predictions Std            23.370428
V Predictions Max            115.12032
V Predictions Min            -17.267118
Log Pis Mean                 -3.3606787
Log Pis Std                  1.4689583
Log Pis Max                  0.6178402
Log Pis Min                  -8.700474
Policy mu Mean               0.026010135
Policy mu Std                0.3176392
Policy mu Max                1.0396173
Policy mu Min                -1.4737839
Policy log std Mean          -0.68709517
Policy log std Std           0.10600516
Policy log std Max           -0.38582176
Policy log std Min           -1.031511
Z mean eval                  0.09299655
Z variance eval              0.012282016
total_rewards                [ 41.7892012  173.38872162  72.65540029 194.85585056   8.82356885
 156.87624805 119.85506117 114.6537966  123.29775737 155.22908348]
total_rewards_mean           116.14246891803143
total_rewards_std            56.2707842568208
total_rewards_max            194.85585056009737
total_rewards_min            8.823568845659661
Number of train steps total  6000
Number of env steps total    32000
Number of rollouts total     0
Train Time (s)               42.437660856638104
(Previous) Eval Time (s)     22.629018880892545
Sample Time (s)              21.695737233385444
Epoch Time (s)               86.76241697091609
Total Train Time (s)         513.3271943395957
Epoch                        5
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:37:51.552871 UTC | [2020_01_10_11_29_18] Iteration #5 | Epoch Duration: 90.01777863502502
2020-01-10 11:37:51.553039 UTC | [2020_01_10_11_29_18] Iteration #5 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.093020424
Z variance train             0.012336592
KL Divergence                8.635316
KL Loss                      0.8635316
QF Loss                      149.87393
VF Loss                      22.976006
Policy Loss                  -82.211044
Q Predictions Mean           79.30032
Q Predictions Std            26.201609
Q Predictions Max            137.89923
Q Predictions Min            -20.33534
V Predictions Mean           81.163376
V Predictions Std            25.967417
V Predictions Max            143.5989
V Predictions Min            -17.30918
Log Pis Mean                 -3.1694527
Log Pis Std                  1.4526522
Log Pis Max                  0.053009868
Log Pis Min                  -7.306036
Policy mu Mean               0.047741063
Policy mu Std                0.3030443
Policy mu Max                1.1074086
Policy mu Min                -0.9089904
Policy log std Mean          -0.7212284
Policy log std Std           0.13501315
Policy log std Max           -0.31957275
Policy log std Min           -1.1298664
Z mean eval                  0.11244251
Z variance eval              0.013731825
total_rewards                [ 92.12315275  66.99723853  13.18315097  16.58447626  -8.77763569
  -5.77175778  92.35874271 198.03141222 273.5372801  -20.72176253]
total_rewards_mean           71.75442975532806
total_rewards_std            92.22046214222468
total_rewards_max            273.53728010431706
total_rewards_min            -20.72176252523519
Number of train steps total  7000
Number of env steps total    37000
Number of rollouts total     0
Train Time (s)               41.79403852298856
(Previous) Eval Time (s)     25.884119543712586
Sample Time (s)              23.610769817139953
Epoch Time (s)               91.2889278838411
Total Train Time (s)         606.5004933369346
Epoch                        6
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:39:24.723621 UTC | [2020_01_10_11_29_18] Iteration #6 | Epoch Duration: 93.17045474052429
2020-01-10 11:39:24.723749 UTC | [2020_01_10_11_29_18] Iteration #6 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.11234915
Z variance train             0.013636175
KL Divergence                8.517461
KL Loss                      0.8517461
QF Loss                      193.70583
VF Loss                      34.47701
Policy Loss                  -97.529335
Q Predictions Mean           93.39235
Q Predictions Std            26.393175
Q Predictions Max            148.30307
Q Predictions Min            -29.526684
V Predictions Mean           98.10774
V Predictions Std            23.014921
V Predictions Max            147.36465
V Predictions Min            -30.45418
Log Pis Mean                 -3.51019
Log Pis Std                  1.601264
Log Pis Max                  2.9829407
Log Pis Min                  -7.76777
Policy mu Mean               0.025517637
Policy mu Std                0.3086731
Policy mu Max                1.4441999
Policy mu Min                -1.3533769
Policy log std Mean          -0.66422254
Policy log std Std           0.1383708
Policy log std Max           -0.294398
Policy log std Min           -1.2129678
Z mean eval                  0.15393494
Z variance eval              0.014594083
total_rewards                [177.55661953 177.7099339   12.75060954  26.00018331  69.12310768
  15.46203192  26.59774947  25.31845399  26.67065677 168.06288151]
total_rewards_mean           72.52522276202707
total_rewards_std            68.31447933187413
total_rewards_max            177.7099338983238
total_rewards_min            12.750609537346245
Number of train steps total  8000
Number of env steps total    42000
Number of rollouts total     0
Train Time (s)               41.767374406103045
(Previous) Eval Time (s)     27.765393247827888
Sample Time (s)              22.402830581646413
Epoch Time (s)               91.93559823557734
Total Train Time (s)         688.2820754926652
Epoch                        7
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:40:46.510311 UTC | [2020_01_10_11_29_18] Iteration #7 | Epoch Duration: 81.78640818595886
2020-01-10 11:40:46.510499 UTC | [2020_01_10_11_29_18] Iteration #7 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.15747133
Z variance train             0.014623873
KL Divergence                8.28914
KL Loss                      0.828914
QF Loss                      253.07153
VF Loss                      40.933254
Policy Loss                  -110.31749
Q Predictions Mean           105.118835
Q Predictions Std            22.628084
Q Predictions Max            158.36855
Q Predictions Min            -15.307371
V Predictions Mean           107.15573
V Predictions Std            21.24057
V Predictions Max            158.57423
V Predictions Min            1.7537948
Log Pis Mean                 -3.23326
Log Pis Std                  1.6554878
Log Pis Max                  4.7036905
Log Pis Min                  -8.67664
Policy mu Mean               0.033724464
Policy mu Std                0.32880843
Policy mu Max                1.1503272
Policy mu Min                -1.5341077
Policy log std Mean          -0.68970335
Policy log std Std           0.15303598
Policy log std Max           -0.30489272
Policy log std Min           -1.4011016
Z mean eval                  0.1713439
Z variance eval              0.012267271
total_rewards                [ -16.74807606  -72.71385687    8.48475932  -18.8049602   -11.6714893
  182.23617302  -19.78086216 -131.41710074   11.57392079  -67.68289886]
total_rewards_mean           -13.65243910490804
total_rewards_std            77.36436098246799
total_rewards_max            182.2361730242955
total_rewards_min            -131.4171007420036
Number of train steps total  9000
Number of env steps total    47000
Number of rollouts total     0
Train Time (s)               42.4183342657052
(Previous) Eval Time (s)     17.61595430225134
Sample Time (s)              23.233197431080043
Epoch Time (s)               83.26748599903658
Total Train Time (s)         783.1960941022262
Epoch                        8
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:42:21.428159 UTC | [2020_01_10_11_29_18] Iteration #8 | Epoch Duration: 94.91749715805054
2020-01-10 11:42:21.428471 UTC | [2020_01_10_11_29_18] Iteration #8 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1738297
Z variance train             0.012226596
KL Divergence                8.806581
KL Loss                      0.8806581
QF Loss                      173.26883
VF Loss                      26.401535
Policy Loss                  -122.38441
Q Predictions Mean           118.41867
Q Predictions Std            27.25536
Q Predictions Max            205.96027
Q Predictions Min            -26.327206
V Predictions Mean           121.34943
V Predictions Std            24.402155
V Predictions Max            206.1656
V Predictions Min            2.7843368
Log Pis Mean                 -3.269738
Log Pis Std                  1.6790262
Log Pis Max                  2.419748
Log Pis Min                  -8.98758
Policy mu Mean               0.042644937
Policy mu Std                0.35856578
Policy mu Max                1.2377958
Policy mu Min                -1.2166475
Policy log std Mean          -0.6633791
Policy log std Std           0.16168983
Policy log std Max           -0.32766682
Policy log std Min           -1.2968037
Z mean eval                  0.23174325
Z variance eval              0.022847997
total_rewards                [ 80.64375412 156.47452464 104.81115397 -44.80800039 -16.29194167
   0.51266205 -35.62344217 -57.24450593  16.31451685   4.20218114]
total_rewards_mean           20.899090261053182
total_rewards_std            66.86447648873806
total_rewards_max            156.4745246395613
total_rewards_min            -57.244505925143685
Number of train steps total  10000
Number of env steps total    52000
Number of rollouts total     0
Train Time (s)               42.06750686932355
(Previous) Eval Time (s)     29.265638242010027
Sample Time (s)              23.242459069471806
Epoch Time (s)               94.57560418080539
Total Train Time (s)         878.3027468640357
Epoch                        9
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:43:56.535875 UTC | [2020_01_10_11_29_18] Iteration #9 | Epoch Duration: 95.10710716247559
2020-01-10 11:43:56.536414 UTC | [2020_01_10_11_29_18] Iteration #9 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.23210268
Z variance train             0.022826318
KL Divergence                7.405852
KL Loss                      0.7405852
QF Loss                      156.88513
VF Loss                      21.611084
Policy Loss                  -136.21114
Q Predictions Mean           133.26517
Q Predictions Std            25.593943
Q Predictions Max            190.44197
Q Predictions Min            -28.040838
V Predictions Mean           135.93796
V Predictions Std            25.771141
V Predictions Max            198.71147
V Predictions Min            -55.36592
Log Pis Mean                 -3.3621523
Log Pis Std                  1.5799941
Log Pis Max                  2.6353335
Log Pis Min                  -7.2926407
Policy mu Mean               0.06998481
Policy mu Std                0.3592865
Policy mu Max                1.2836361
Policy mu Min                -1.4020433
Policy log std Mean          -0.65504193
Policy log std Std           0.16873805
Policy log std Max           -0.30829126
Policy log std Min           -1.5861433
Z mean eval                  0.28618497
Z variance eval              0.024788778
total_rewards                [ 75.58585884 167.19364608 -34.21625953 172.96372995 103.14750699
  64.10450165 100.64197768 -26.31345276 -11.98150758  88.91347787]
total_rewards_mean           70.00394791981915
total_rewards_std            70.26220766994697
total_rewards_max            172.96372994744812
total_rewards_min            -34.21625952576805
Number of train steps total  11000
Number of env steps total    57000
Number of rollouts total     0
Train Time (s)               43.638002613093704
(Previous) Eval Time (s)     29.796878900844604
Sample Time (s)              23.69858869444579
Epoch Time (s)               97.1334702083841
Total Train Time (s)         976.0743356170133
Epoch                        10
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:45:34.307405 UTC | [2020_01_10_11_29_18] Iteration #10 | Epoch Duration: 97.77072024345398
2020-01-10 11:45:34.307578 UTC | [2020_01_10_11_29_18] Iteration #10 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.2902743
Z variance train             0.024716254
KL Divergence                7.46434
KL Loss                      0.74643403
QF Loss                      209.21928
VF Loss                      34.81896
Policy Loss                  -144.74142
Q Predictions Mean           142.28201
Q Predictions Std            28.975273
Q Predictions Max            204.3434
Q Predictions Min            22.614513
V Predictions Mean           141.74942
V Predictions Std            25.81462
V Predictions Max            197.90044
V Predictions Min            18.428408
Log Pis Mean                 -2.821185
Log Pis Std                  1.8180536
Log Pis Max                  4.890857
Log Pis Min                  -7.6417837
Policy mu Mean               0.058304377
Policy mu Std                0.37320647
Policy mu Max                1.2089629
Policy mu Min                -1.3865395
Policy log std Mean          -0.70129967
Policy log std Std           0.19326517
Policy log std Max           -0.28096578
Policy log std Min           -1.6237683
Z mean eval                  0.34877467
Z variance eval              0.024136143
total_rewards                [ 140.73058597 -120.77935181   17.38112076 -117.04496851   24.30353597
 -105.19246398  -94.34727226  -34.60211874   36.79449162  -34.90702268]
total_rewards_mean           -28.766346365975117
total_rewards_std            80.27858769228631
total_rewards_max            140.7305859724772
total_rewards_min            -120.77935180796985
Number of train steps total  12000
Number of env steps total    62000
Number of rollouts total     0
Train Time (s)               42.337968851905316
(Previous) Eval Time (s)     30.433893641922623
Sample Time (s)              21.53836604207754
Epoch Time (s)               94.31022853590548
Total Train Time (s)         1066.7722508846782
Epoch                        11
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:47:05.008818 UTC | [2020_01_10_11_29_18] Iteration #11 | Epoch Duration: 90.70108103752136
2020-01-10 11:47:05.009045 UTC | [2020_01_10_11_29_18] Iteration #11 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.3491497
Z variance train             0.024130156
KL Divergence                7.73831
KL Loss                      0.773831
QF Loss                      170.58112
VF Loss                      37.422184
Policy Loss                  -158.70726
Q Predictions Mean           155.36395
Q Predictions Std            30.612694
Q Predictions Max            223.7991
Q Predictions Min            3.081449
V Predictions Mean           157.7132
V Predictions Std            28.066628
V Predictions Max            223.35106
V Predictions Min            13.377408
Log Pis Mean                 -3.2073498
Log Pis Std                  1.8728734
Log Pis Max                  2.2214649
Log Pis Min                  -9.749104
Policy mu Mean               0.0597113
Policy mu Std                0.39966744
Policy mu Max                1.5891864
Policy mu Min                -1.2297701
Policy log std Mean          -0.64647925
Policy log std Std           0.156106
Policy log std Max           -0.26495558
Policy log std Min           -1.4361825
Z mean eval                  0.37243444
Z variance eval              0.025188636
total_rewards                [  47.70208252   22.28434452   75.91644319  192.63596985  -24.32083188
  112.67793413   46.18954979  -77.04403337 -158.18882057   12.46914976]
total_rewards_mean           25.032178794585807
total_rewards_std            92.68989378697506
total_rewards_max            192.6359698522955
total_rewards_min            -158.1888205719877
Number of train steps total  13000
Number of env steps total    67000
Number of rollouts total     0
Train Time (s)               42.93488487089053
(Previous) Eval Time (s)     26.824539452791214
Sample Time (s)              23.685574740171432
Epoch Time (s)               93.44499906385317
Total Train Time (s)         1158.4785663904622
Epoch                        12
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:48:36.717456 UTC | [2020_01_10_11_29_18] Iteration #12 | Epoch Duration: 91.70818662643433
2020-01-10 11:48:36.717771 UTC | [2020_01_10_11_29_18] Iteration #12 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.37349793
Z variance train             0.025210148
KL Divergence                7.825206
KL Loss                      0.7825206
QF Loss                      279.64587
VF Loss                      44.354942
Policy Loss                  -159.47214
Q Predictions Mean           155.80093
Q Predictions Std            27.786655
Q Predictions Max            210.46185
Q Predictions Min            -0.06592418
V Predictions Mean           157.75874
V Predictions Std            25.555046
V Predictions Max            207.36833
V Predictions Min            38.621765
Log Pis Mean                 -3.1641753
Log Pis Std                  1.789181
Log Pis Max                  5.148277
Log Pis Min                  -8.73267
Policy mu Mean               0.015167862
Policy mu Std                0.3762144
Policy mu Max                1.624119
Policy mu Min                -1.4237955
Policy log std Mean          -0.6642692
Policy log std Std           0.17822991
Policy log std Max           -0.26904875
Policy log std Min           -1.4319055
Z mean eval                  0.44240564
Z variance eval              0.032603193
total_rewards                [ 73.8177181  159.3100744  -75.68088008 -18.6065478   34.13518639
 -29.21579417 -53.64244864 -61.17459    -42.52771587  70.94103462]
total_rewards_mean           5.735603694871487
total_rewards_std            72.1480674647253
total_rewards_max            159.31007439971043
total_rewards_min            -75.68088007508435
Number of train steps total  14000
Number of env steps total    72000
Number of rollouts total     0
Train Time (s)               43.050377475097775
(Previous) Eval Time (s)     25.08745794510469
Sample Time (s)              23.37562490813434
Epoch Time (s)               91.5134603283368
Total Train Time (s)         1257.307511758525
Epoch                        13
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:50:15.545689 UTC | [2020_01_10_11_29_18] Iteration #13 | Epoch Duration: 98.8276994228363
2020-01-10 11:50:15.545866 UTC | [2020_01_10_11_29_18] Iteration #13 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.56111383
Z variance train             0.02184684
KL Divergence                8.617583
KL Loss                      0.86175835
QF Loss                      148.33504
VF Loss                      23.762777
Policy Loss                  -182.71101
Q Predictions Mean           179.19565
Q Predictions Std            33.310326
Q Predictions Max            244.89433
Q Predictions Min            7.300683
V Predictions Mean           182.99847
V Predictions Std            31.336155
V Predictions Max            245.9303
V Predictions Min            1.1612954
Log Pis Mean                 -3.1835382
Log Pis Std                  1.7479823
Log Pis Max                  3.4972553
Log Pis Min                  -9.086395
Policy mu Mean               0.02440665
Policy mu Std                0.37793827
Policy mu Max                1.2369944
Policy mu Min                -1.1522565
Policy log std Mean          -0.63582164
Policy log std Std           0.18146726
Policy log std Max           -0.22858584
Policy log std Min           -1.612473
Z mean eval                  0.46967372
Z variance eval              0.031390797
total_rewards                [-24.85014994 -29.50051072  35.54891424 -32.37452424  88.12517046
  94.80116176 255.41580209  13.46339861 247.94708513 113.59761568]
total_rewards_mean           76.21739630814298
total_rewards_std            101.1250248579141
total_rewards_max            255.41580209363414
total_rewards_min            -32.374524239106556
Number of train steps total  15000
Number of env steps total    77000
Number of rollouts total     0
Train Time (s)               42.47008410701528
(Previous) Eval Time (s)     32.40145994024351
Sample Time (s)              21.677805192768574
Epoch Time (s)               96.54934924002737
Total Train Time (s)         1350.1000381466001
Epoch                        14
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:51:48.339267 UTC | [2020_01_10_11_29_18] Iteration #14 | Epoch Duration: 92.7932665348053
2020-01-10 11:51:48.339445 UTC | [2020_01_10_11_29_18] Iteration #14 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.4711538
Z variance train             0.03141492
KL Divergence                8.056667
KL Loss                      0.80566674
QF Loss                      215.78065
VF Loss                      37.738823
Policy Loss                  -181.4698
Q Predictions Mean           176.80838
Q Predictions Std            32.463318
Q Predictions Max            243.6251
Q Predictions Min            -41.385857
V Predictions Mean           180.61954
V Predictions Std            28.89392
V Predictions Max            250.11993
V Predictions Min            6.22564
Log Pis Mean                 -2.8583057
Log Pis Std                  1.8289813
Log Pis Max                  4.986202
Log Pis Min                  -8.228844
Policy mu Mean               0.08073081
Policy mu Std                0.40326238
Policy mu Max                1.6021228
Policy mu Min                -1.382188
Policy log std Mean          -0.672946
Policy log std Std           0.1764437
Policy log std Max           -0.23878245
Policy log std Min           -1.6014682
Z mean eval                  0.48363405
Z variance eval              0.030185092
total_rewards                [108.27834197  33.46405396 -48.77271374 105.33494797  40.55409239
 -21.64185304 -42.57833652 -66.00388509  79.23741158 -84.21551914]
total_rewards_mean           10.365654035105186
total_rewards_std            68.48142532107782
total_rewards_max            108.27834197148854
total_rewards_min            -84.2155191352087
Number of train steps total  16000
Number of env steps total    82000
Number of rollouts total     0
Train Time (s)               42.00510091520846
(Previous) Eval Time (s)     28.645115183200687
Sample Time (s)              21.986797441728413
Epoch Time (s)               92.63701354013756
Total Train Time (s)         1447.7133418153971
Epoch                        15
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:53:25.956189 UTC | [2020_01_10_11_29_18] Iteration #15 | Epoch Duration: 97.6165566444397
2020-01-10 11:53:25.956421 UTC | [2020_01_10_11_29_18] Iteration #15 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.48166284
Z variance train             0.030196056
KL Divergence                8.11656
KL Loss                      0.811656
QF Loss                      264.96753
VF Loss                      41.114487
Policy Loss                  -188.389
Q Predictions Mean           185.2635
Q Predictions Std            35.584694
Q Predictions Max            266.66022
Q Predictions Min            -52.73092
V Predictions Mean           187.75366
V Predictions Std            31.81742
V Predictions Max            265.0395
V Predictions Min            9.13837
Log Pis Mean                 -2.8223755
Log Pis Std                  1.9001869
Log Pis Max                  4.3815947
Log Pis Min                  -9.476381
Policy mu Mean               0.030151052
Policy mu Std                0.39381638
Policy mu Max                1.2943088
Policy mu Min                -1.7903514
Policy log std Mean          -0.6930586
Policy log std Std           0.170915
Policy log std Max           -0.29611427
Policy log std Min           -1.4909451
Z mean eval                  0.5519985
Z variance eval              0.02662448
total_rewards                [ 78.10838749  -8.70562091 125.84020255  43.89330693 -99.59982518
 238.47035851 148.33467831  12.70711123 100.50565124 -45.93530727]
total_rewards_mean           59.36189428964161
total_rewards_std            94.79718612808558
total_rewards_max            238.47035850510866
total_rewards_min            -99.59982517882295
Number of train steps total  17000
Number of env steps total    87000
Number of rollouts total     0
Train Time (s)               42.60561485076323
(Previous) Eval Time (s)     33.624394751153886
Sample Time (s)              23.40228962013498
Epoch Time (s)               99.6322992220521
Total Train Time (s)         1544.9078331068158
Epoch                        16
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:55:03.158406 UTC | [2020_01_10_11_29_18] Iteration #16 | Epoch Duration: 97.20183062553406
2020-01-10 11:55:03.158667 UTC | [2020_01_10_11_29_18] Iteration #16 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.55260986
Z variance train             0.026595736
KL Divergence                8.836222
KL Loss                      0.88362217
QF Loss                      188.12483
VF Loss                      33.033634
Policy Loss                  -206.4008
Q Predictions Mean           203.62201
Q Predictions Std            30.768534
Q Predictions Max            271.09393
Q Predictions Min            -5.216105
V Predictions Mean           206.14557
V Predictions Std            27.865923
V Predictions Max            275.75153
V Predictions Min            4.385837
Log Pis Mean                 -3.129087
Log Pis Std                  1.8813807
Log Pis Max                  10.254849
Log Pis Min                  -8.1557865
Policy mu Mean               -0.034494042
Policy mu Std                0.3911955
Policy mu Max                2.4969392
Policy mu Min                -1.4436264
Policy log std Mean          -0.66722065
Policy log std Std           0.1594499
Policy log std Max           -0.25821432
Policy log std Min           -1.4731873
Z mean eval                  0.5821016
Z variance eval              0.018483946
total_rewards                [ 83.60285923  47.13689809 -61.92376645  86.48451102 -74.49967233
 168.145109    48.38119799  69.21099399   4.81004701 162.97682438]
total_rewards_mean           53.43250019235203
total_rewards_std            77.14505212009213
total_rewards_max            168.1451089967346
total_rewards_min            -74.49967233407745
Number of train steps total  18000
Number of env steps total    92000
Number of rollouts total     0
Train Time (s)               44.067212373018265
(Previous) Eval Time (s)     31.193665243685246
Sample Time (s)              23.77910081902519
Epoch Time (s)               99.0399784357287
Total Train Time (s)         1638.5074484450743
Epoch                        17
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:56:36.752381 UTC | [2020_01_10_11_29_18] Iteration #17 | Epoch Duration: 93.59337377548218
2020-01-10 11:56:36.752809 UTC | [2020_01_10_11_29_18] Iteration #17 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.5808011
Z variance train             0.018496998
KL Divergence                9.578038
KL Loss                      0.95780385
QF Loss                      210.23947
VF Loss                      42.071545
Policy Loss                  -217.66621
Q Predictions Mean           214.755
Q Predictions Std            39.06374
Q Predictions Max            277.71964
Q Predictions Min            -2.998331
V Predictions Mean           218.50925
V Predictions Std            33.993572
V Predictions Max            281.98636
V Predictions Min            23.061113
Log Pis Mean                 -3.4197319
Log Pis Std                  1.9934385
Log Pis Max                  5.9977474
Log Pis Min                  -9.511725
Policy mu Mean               0.046280257
Policy mu Std                0.3686343
Policy mu Max                1.6753285
Policy mu Min                -1.3480147
Policy log std Mean          -0.62653536
Policy log std Std           0.1789571
Policy log std Max           -0.2187925
Policy log std Min           -1.8322059
Z mean eval                  0.6140231
Z variance eval              0.01867433
total_rewards                [ 305.93895193   24.3648363  -118.47598777  119.93565817   12.76255179
   98.17365307  127.35698367   50.72772147   13.10885761   10.88317307]
total_rewards_mean           64.47763993135956
total_rewards_std            104.84468814744677
total_rewards_max            305.9389519289266
total_rewards_min            -118.47598776964387
Number of train steps total  19000
Number of env steps total    97000
Number of rollouts total     0
Train Time (s)               42.55871244473383
(Previous) Eval Time (s)     25.746782820671797
Sample Time (s)              21.40496302070096
Epoch Time (s)               89.71045828610659
Total Train Time (s)         1722.5316238896921
Epoch                        18
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:58:00.779765 UTC | [2020_01_10_11_29_18] Iteration #18 | Epoch Duration: 84.02669382095337
2020-01-10 11:58:00.780049 UTC | [2020_01_10_11_29_18] Iteration #18 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.62144935
Z variance train             0.018824112
KL Divergence                9.526035
KL Loss                      0.9526035
QF Loss                      225.1549
VF Loss                      119.30005
Policy Loss                  -218.86913
Q Predictions Mean           213.115
Q Predictions Std            36.48779
Q Predictions Max            282.2537
Q Predictions Min            13.612248
V Predictions Mean           212.01115
V Predictions Std            33.06761
V Predictions Max            274.3258
V Predictions Min            -10.412799
Log Pis Mean                 -3.1778774
Log Pis Std                  1.8524876
Log Pis Max                  6.1141615
Log Pis Min                  -9.368843
Policy mu Mean               0.030424507
Policy mu Std                0.37243494
Policy mu Max                2.3569398
Policy mu Min                -1.3227322
Policy log std Mean          -0.64126563
Policy log std Std           0.17494425
Policy log std Max           -0.22910897
Policy log std Min           -1.6456193
Z mean eval                  0.6423134
Z variance eval              0.017224979
total_rewards                [ 54.57458208  62.95269011  78.22478831  88.19307436 -12.41438645
 158.06975679 181.37548174  19.08014013  64.56680089  46.6493665 ]
total_rewards_mean           74.1272294469004
total_rewards_std            55.35017426959731
total_rewards_max            181.37548173577997
total_rewards_min            -12.41438644692822
Number of train steps total  20000
Number of env steps total    102000
Number of rollouts total     0
Train Time (s)               42.43836935702711
(Previous) Eval Time (s)     20.062786313705146
Sample Time (s)              23.11182083422318
Epoch Time (s)               85.61297650495544
Total Train Time (s)         1813.8971067559905
Epoch                        19
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:59:32.146620 UTC | [2020_01_10_11_29_18] Iteration #19 | Epoch Duration: 91.36633563041687
2020-01-10 11:59:32.146917 UTC | [2020_01_10_11_29_18] Iteration #19 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6409076
Z variance train             0.017209485
KL Divergence                9.855478
KL Loss                      0.98554784
QF Loss                      320.94385
VF Loss                      54.607597
Policy Loss                  -226.03058
Q Predictions Mean           223.47751
Q Predictions Std            32.40623
Q Predictions Max            286.6808
Q Predictions Min            19.000866
V Predictions Mean           227.74762
V Predictions Std            28.197067
V Predictions Max            282.44992
V Predictions Min            108.32655
Log Pis Mean                 -3.0023441
Log Pis Std                  1.6924182
Log Pis Max                  4.050555
Log Pis Min                  -8.790306
Policy mu Mean               0.037761845
Policy mu Std                0.37230876
Policy mu Max                1.2262236
Policy mu Min                -1.4596652
Policy log std Mean          -0.6671747
Policy log std Std           0.16758253
Policy log std Max           -0.24041481
Policy log std Min           -1.6770552
Z mean eval                  0.63098645
Z variance eval              0.015436542
total_rewards                [406.81098574   6.74128103  43.05524513 275.19071561  44.55856717
  56.19397513   3.86931872   5.05642635 148.83659633 197.06864769]
total_rewards_mean           118.73817588929037
total_rewards_std            129.73392581537803
total_rewards_max            406.8109857383558
total_rewards_min            3.8693187210560236
Number of train steps total  21000
Number of env steps total    107000
Number of rollouts total     0
Train Time (s)               41.999625058379024
(Previous) Eval Time (s)     25.815881847869605
Sample Time (s)              22.99613581271842
Epoch Time (s)               90.81164271896705
Total Train Time (s)         1905.3160085645504
Epoch                        20
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:01:03.564646 UTC | [2020_01_10_11_29_18] Iteration #20 | Epoch Duration: 91.4175295829773
2020-01-10 12:01:03.564763 UTC | [2020_01_10_11_29_18] Iteration #20 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.62841284
Z variance train             0.015451779
KL Divergence                10.263321
KL Loss                      1.0263321
QF Loss                      217.31842
VF Loss                      52.75296
Policy Loss                  -234.14423
Q Predictions Mean           230.45503
Q Predictions Std            42.430138
Q Predictions Max            321.41553
Q Predictions Min            -7.523475
V Predictions Mean           234.48843
V Predictions Std            38.903774
V Predictions Max            314.03226
V Predictions Min            33.315506
Log Pis Mean                 -3.0696144
Log Pis Std                  1.8618168
Log Pis Max                  3.839272
Log Pis Min                  -8.644065
Policy mu Mean               0.0332094
Policy mu Std                0.36447993
Policy mu Max                1.53611
Policy mu Min                -1.6433332
Policy log std Mean          -0.6944134
Policy log std Std           0.17499587
Policy log std Max           -0.2963156
Policy log std Min           -1.6784306
Z mean eval                  0.66070735
Z variance eval              0.0140943695
total_rewards                [113.228185   118.32467598 -63.74904343 152.96718741  14.44989925
  28.19625743  44.78886306 209.81233461 154.28720012 -50.01543703]
total_rewards_mean           72.2290122412743
total_rewards_std            86.86260431648672
total_rewards_max            209.81233461078403
total_rewards_min            -63.74904342934569
Number of train steps total  22000
Number of env steps total    112000
Number of rollouts total     0
Train Time (s)               42.73854751093313
(Previous) Eval Time (s)     26.421529915183783
Sample Time (s)              23.29447517544031
Epoch Time (s)               92.45455260155722
Total Train Time (s)         2002.151331111323
Epoch                        21
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:02:40.404368 UTC | [2020_01_10_11_29_18] Iteration #21 | Epoch Duration: 96.83949637413025
2020-01-10 12:02:40.404552 UTC | [2020_01_10_11_29_18] Iteration #21 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6607293
Z variance train             0.014086773
KL Divergence                10.425506
KL Loss                      1.0425506
QF Loss                      160.57295
VF Loss                      60.05491
Policy Loss                  -239.20502
Q Predictions Mean           234.99155
Q Predictions Std            39.278477
Q Predictions Max            296.85822
Q Predictions Min            -5.6820874
V Predictions Mean           239.92294
V Predictions Std            34.64621
V Predictions Max            294.6974
V Predictions Min            24.022486
Log Pis Mean                 -3.1201549
Log Pis Std                  1.8036814
Log Pis Max                  7.335486
Log Pis Min                  -8.264122
Policy mu Mean               0.033797786
Policy mu Std                0.36472106
Policy mu Max                1.527548
Policy mu Min                -1.7991033
Policy log std Mean          -0.66189724
Policy log std Std           0.1674044
Policy log std Max           -0.27130574
Policy log std Min           -1.6343634
Z mean eval                  0.68029803
Z variance eval              0.013370262
total_rewards                [293.61121103 122.01942171 294.40439801  92.5782189  116.76889006
  39.41541961 352.46887383 128.83518957  58.21378244   7.35653904]
total_rewards_mean           150.56719441889
total_rewards_std            113.62239372555065
total_rewards_max            352.46887383021914
total_rewards_min            7.356539036538917
Number of train steps total  23000
Number of env steps total    117000
Number of rollouts total     0
Train Time (s)               42.84764027269557
(Previous) Eval Time (s)     30.806208294816315
Sample Time (s)              23.263431375380605
Epoch Time (s)               96.91727994289249
Total Train Time (s)         2091.9125587861054
Epoch                        22
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:04:10.165208 UTC | [2020_01_10_11_29_18] Iteration #22 | Epoch Duration: 89.76045274734497
2020-01-10 12:04:10.165457 UTC | [2020_01_10_11_29_18] Iteration #22 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.67786777
Z variance train             0.013332705
KL Divergence                10.833761
KL Loss                      1.0833762
QF Loss                      182.23935
VF Loss                      57.379692
Policy Loss                  -249.68849
Q Predictions Mean           247.18404
Q Predictions Std            35.193428
Q Predictions Max            314.5254
Q Predictions Min            27.69661
V Predictions Mean           251.72722
V Predictions Std            31.59467
V Predictions Max            309.34476
V Predictions Min            65.68525
Log Pis Mean                 -2.9238272
Log Pis Std                  1.8112339
Log Pis Max                  7.031165
Log Pis Min                  -9.206467
Policy mu Mean               0.03904478
Policy mu Std                0.36353305
Policy mu Max                1.3501632
Policy mu Min                -1.8066578
Policy log std Mean          -0.71088374
Policy log std Std           0.17245376
Policy log std Max           -0.3113699
Policy log std Min           -1.9655974
Z mean eval                  0.6963362
Z variance eval              0.016392682
total_rewards                [ 10.97727037 380.27865847  51.09442732 266.13566501 276.23330133
 105.17267787 204.97274804 310.78775408  92.69277035  36.59201705]
total_rewards_mean           173.4937289890366
total_rewards_std            123.72160729328995
total_rewards_max            380.2786584722119
total_rewards_min            10.977270365356905
Number of train steps total  24000
Number of env steps total    122000
Number of rollouts total     0
Train Time (s)               41.94451041193679
(Previous) Eval Time (s)     23.649125010240823
Sample Time (s)              23.261184639297426
Epoch Time (s)               88.85482006147504
Total Train Time (s)         2188.796625944786
Epoch                        23
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:05:47.050111 UTC | [2020_01_10_11_29_18] Iteration #23 | Epoch Duration: 96.88450193405151
2020-01-10 12:05:47.050286 UTC | [2020_01_10_11_29_18] Iteration #23 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6947922
Z variance train             0.016375009
KL Divergence                10.893174
KL Loss                      1.0893174
QF Loss                      278.20718
VF Loss                      47.726128
Policy Loss                  -244.8166
Q Predictions Mean           242.50848
Q Predictions Std            43.794647
Q Predictions Max            321.8191
Q Predictions Min            -30.755154
V Predictions Mean           246.24797
V Predictions Std            41.628174
V Predictions Max            324.9201
V Predictions Min            -15.284823
Log Pis Mean                 -2.8971894
Log Pis Std                  2.1243453
Log Pis Max                  6.7093544
Log Pis Min                  -9.160053
Policy mu Mean               0.09489299
Policy mu Std                0.38582155
Policy mu Max                1.907888
Policy mu Min                -1.7059349
Policy log std Mean          -0.70339787
Policy log std Std           0.16863799
Policy log std Max           -0.29338583
Policy log std Min           -1.6245134
Z mean eval                  0.7076396
Z variance eval              0.022469755
total_rewards                [209.7759641  198.59937881 108.01596261 132.32623088 169.44323067
  83.50485187  72.66867963  37.02304285 340.67252602 108.09140803]
total_rewards_mean           146.01212754782492
total_rewards_std            83.37083897087925
total_rewards_max            340.6725260193788
total_rewards_min            37.02304285394112
Number of train steps total  25000
Number of env steps total    127000
Number of rollouts total     0
Train Time (s)               42.12681542756036
(Previous) Eval Time (s)     31.678568524308503
Sample Time (s)              23.669449386186898
Epoch Time (s)               97.47483333805576
Total Train Time (s)         2277.2949207480997
Epoch                        24
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:07:15.553045 UTC | [2020_01_10_11_29_18] Iteration #24 | Epoch Duration: 88.50262641906738
2020-01-10 12:07:15.553228 UTC | [2020_01_10_11_29_18] Iteration #24 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7060782
Z variance train             0.022458162
KL Divergence                10.525508
KL Loss                      1.0525508
QF Loss                      152.73535
VF Loss                      54.956406
Policy Loss                  -256.23538
Q Predictions Mean           254.67435
Q Predictions Std            41.566837
Q Predictions Max            328.36304
Q Predictions Min            -7.012742
V Predictions Mean           252.63208
V Predictions Std            39.2826
V Predictions Max            322.70663
V Predictions Min            -25.771559
Log Pis Mean                 -3.440043
Log Pis Std                  1.7201473
Log Pis Max                  5.374433
Log Pis Min                  -10.106728
Policy mu Mean               0.045289516
Policy mu Std                0.3444385
Policy mu Max                1.3466256
Policy mu Min                -1.7848068
Policy log std Mean          -0.66884923
Policy log std Std           0.14504929
Policy log std Max           -0.31477997
Policy log std Min           -1.6506448
Z mean eval                  0.699541
Z variance eval              0.029716903
total_rewards                [ 28.86262362 180.65268079 367.73066936 283.65683874  40.27838862
 298.82978941 201.76931178  35.0143459  132.88536822  29.52367859]
total_rewards_mean           159.92036950372247
total_rewards_std            120.332399442525
total_rewards_max            367.7306693622313
total_rewards_min            28.86262362192519
Number of train steps total  26000
Number of env steps total    132000
Number of rollouts total     0
Train Time (s)               42.03285638010129
(Previous) Eval Time (s)     22.706085197161883
Sample Time (s)              23.28125256113708
Epoch Time (s)               88.02019413840026
Total Train Time (s)         2372.201105453074
Epoch                        25
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:08:50.465582 UTC | [2020_01_10_11_29_18] Iteration #25 | Epoch Duration: 94.91220188140869
2020-01-10 12:08:50.465793 UTC | [2020_01_10_11_29_18] Iteration #25 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6988093
Z variance train             0.02966485
KL Divergence                10.399943
KL Loss                      1.0399944
QF Loss                      245.24686
VF Loss                      54.01773
Policy Loss                  -257.25488
Q Predictions Mean           253.17389
Q Predictions Std            39.828495
Q Predictions Max            315.70792
Q Predictions Min            21.785505
V Predictions Mean           256.88205
V Predictions Std            35.965767
V Predictions Max            319.86145
V Predictions Min            65.5987
Log Pis Mean                 -2.8333652
Log Pis Std                  2.0681245
Log Pis Max                  8.858298
Log Pis Min                  -7.2263927
Policy mu Mean               0.05505138
Policy mu Std                0.384284
Policy mu Max                1.6004802
Policy mu Min                -1.8787606
Policy log std Mean          -0.74200976
Policy log std Std           0.18945394
Policy log std Max           -0.268166
Policy log std Min           -1.6877713
Z mean eval                  0.72349536
Z variance eval              0.02817759
total_rewards                [-30.40676564  49.79869368  16.82114612 111.00923853 -18.38963504
 336.74334219  88.74546329  33.96587873 128.73811511 205.31681223]
total_rewards_mean           92.23422892136824
total_rewards_std            106.03355339897776
total_rewards_max            336.7433421886404
total_rewards_min            -30.40676563647414
Number of train steps total  27000
Number of env steps total    137000
Number of rollouts total     0
Train Time (s)               42.029819371178746
(Previous) Eval Time (s)     29.597838831599802
Sample Time (s)              23.12324116937816
Epoch Time (s)               94.75089937215671
Total Train Time (s)         2466.839107642416
Epoch                        26
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:10:25.098467 UTC | [2020_01_10_11_29_18] Iteration #26 | Epoch Duration: 94.63246941566467
2020-01-10 12:10:25.098656 UTC | [2020_01_10_11_29_18] Iteration #26 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7276019
Z variance train             0.028113713
KL Divergence                10.769943
KL Loss                      1.0769943
QF Loss                      226.25085
VF Loss                      59.86888
Policy Loss                  -273.24957
Q Predictions Mean           270.2902
Q Predictions Std            42.124054
Q Predictions Max            344.5939
Q Predictions Min            -35.42452
V Predictions Mean           270.72412
V Predictions Std            37.508595
V Predictions Max            339.90625
V Predictions Min            20.951666
Log Pis Mean                 -3.2197626
Log Pis Std                  1.6678803
Log Pis Max                  4.838376
Log Pis Min                  -8.192707
Policy mu Mean               0.0842354
Policy mu Std                0.35011548
Policy mu Max                2.0731118
Policy mu Min                -1.5408149
Policy log std Mean          -0.67077017
Policy log std Std           0.15791681
Policy log std Max           -0.23854238
Policy log std Min           -1.6774763
Z mean eval                  0.7225674
Z variance eval              0.030946583
total_rewards                [485.83999056 141.92314533 192.24619622 117.54790745 281.14070424
  61.31339494 103.9268848  365.96791962 366.97497398 236.54584624]
total_rewards_mean           235.3426963389566
total_rewards_std            130.86414763999917
total_rewards_max            485.839990563314
total_rewards_min            61.31339494053788
Number of train steps total  28000
Number of env steps total    142000
Number of rollouts total     0
Train Time (s)               41.97725654486567
(Previous) Eval Time (s)     29.479175105225295
Sample Time (s)              23.34687578584999
Epoch Time (s)               94.80330743594095
Total Train Time (s)         2568.7100298581645
Epoch                        27
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:12:06.973118 UTC | [2020_01_10_11_29_18] Iteration #27 | Epoch Duration: 101.87434887886047
2020-01-10 12:12:06.973272 UTC | [2020_01_10_11_29_18] Iteration #27 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.72132385
Z variance train             0.03100211
KL Divergence                10.448713
KL Loss                      1.0448713
QF Loss                      170.03073
VF Loss                      54.262768
Policy Loss                  -267.26395
Q Predictions Mean           264.72842
Q Predictions Std            40.08414
Q Predictions Max            322.9986
Q Predictions Min            3.7821732
V Predictions Mean           264.93256
V Predictions Std            37.949997
V Predictions Max            320.32532
V Predictions Min            -46.09668
Log Pis Mean                 -3.3393826
Log Pis Std                  1.830078
Log Pis Max                  6.1871185
Log Pis Min                  -9.256115
Policy mu Mean               0.011011633
Policy mu Std                0.35127842
Policy mu Max                1.2313696
Policy mu Min                -2.4757109
Policy log std Mean          -0.69250727
Policy log std Std           0.15403527
Policy log std Max           -0.29162493
Policy log std Min           -1.8353578
Z mean eval                  0.73290074
Z variance eval              0.03155661
total_rewards                [249.86955506  53.58919648 340.3973542  170.80174832 107.18338044
 301.44379833 159.81681704 104.35122932 374.64233578  58.45131457]
total_rewards_mean           192.0546729525865
total_rewards_std            111.38262389701967
total_rewards_max            374.6423357784327
total_rewards_min            53.589196481211665
Number of train steps total  29000
Number of env steps total    147000
Number of rollouts total     0
Train Time (s)               42.20311307394877
(Previous) Eval Time (s)     36.54996178532019
Sample Time (s)              23.56976258335635
Epoch Time (s)               102.32283744262531
Total Train Time (s)         2670.170996611938
Epoch                        28
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:13:48.436310 UTC | [2020_01_10_11_29_18] Iteration #28 | Epoch Duration: 101.46292757987976
2020-01-10 12:13:48.436438 UTC | [2020_01_10_11_29_18] Iteration #28 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7313253
Z variance train             0.031574644
KL Divergence                10.26051
KL Loss                      1.026051
QF Loss                      191.0195
VF Loss                      29.823513
Policy Loss                  -280.10953
Q Predictions Mean           276.4453
Q Predictions Std            39.879787
Q Predictions Max            353.44424
Q Predictions Min            -22.430492
V Predictions Mean           283.09872
V Predictions Std            38.452442
V Predictions Max            356.96854
V Predictions Min            0.3496368
Log Pis Mean                 -2.917396
Log Pis Std                  1.557119
Log Pis Max                  4.824483
Log Pis Min                  -8.196852
Policy mu Mean               0.092824176
Policy mu Std                0.33600622
Policy mu Max                1.1612821
Policy mu Min                -1.3326961
Policy log std Mean          -0.7150181
Policy log std Std           0.1454945
Policy log std Max           -0.2941264
Policy log std Min           -1.7896801
Z mean eval                  0.7022566
Z variance eval              0.04016698
total_rewards                [ 87.09371614 186.3070517  182.37947925 453.62198003  99.21259636
 351.45987759 332.02219321 125.89686182 252.21748213 193.26634226]
total_rewards_mean           226.34775804830883
total_rewards_std            113.76256465147156
total_rewards_max            453.6219800276385
total_rewards_min            87.0937161372488
Number of train steps total  30000
Number of env steps total    152000
Number of rollouts total     0
Train Time (s)               43.10617480892688
(Previous) Eval Time (s)     35.689812378026545
Sample Time (s)              23.414775790646672
Epoch Time (s)               102.2107629776001
Total Train Time (s)         2773.339653384872
Epoch                        29
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:15:31.604953 UTC | [2020_01_10_11_29_18] Iteration #29 | Epoch Duration: 103.16840600967407
2020-01-10 12:15:31.605127 UTC | [2020_01_10_11_29_18] Iteration #29 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7019858
Z variance train             0.040158547
KL Divergence                10.3628235
KL Loss                      1.0362824
QF Loss                      136.43106
VF Loss                      26.790092
Policy Loss                  -278.72623
Q Predictions Mean           276.34473
Q Predictions Std            43.330524
Q Predictions Max            374.57962
Q Predictions Min            -21.963177
V Predictions Mean           277.81372
V Predictions Std            41.752144
V Predictions Max            369.023
V Predictions Min            5.810086
Log Pis Mean                 -3.2367833
Log Pis Std                  1.7285746
Log Pis Max                  5.592698
Log Pis Min                  -9.442253
Policy mu Mean               -0.008697374
Policy mu Std                0.36991277
Policy mu Max                1.6652162
Policy mu Min                -1.6068367
Policy log std Mean          -0.68116903
Policy log std Std           0.14046438
Policy log std Max           -0.303113
Policy log std Min           -1.538721
Z mean eval                  0.72966015
Z variance eval              0.03298531
total_rewards                [ 65.07986306 334.800611   563.62532318 338.37289764 212.45720966
 120.86354029 329.12341378 164.85963952 417.617453   429.72495997]
total_rewards_mean           297.65249110926436
total_rewards_std            147.255345461033
total_rewards_max            563.6253231797953
total_rewards_min            65.07986305744325
Number of train steps total  31000
Number of env steps total    157000
Number of rollouts total     0
Train Time (s)               42.82640397781506
(Previous) Eval Time (s)     36.64720108406618
Sample Time (s)              23.141990253236145
Epoch Time (s)               102.61559531511739
Total Train Time (s)         2872.930611884687
Epoch                        30
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:17:11.197813 UTC | [2020_01_10_11_29_18] Iteration #30 | Epoch Duration: 99.59248971939087
2020-01-10 12:17:11.198049 UTC | [2020_01_10_11_29_18] Iteration #30 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7319695
Z variance train             0.03293199
KL Divergence                10.651619
KL Loss                      1.065162
QF Loss                      180.36288
VF Loss                      56.2118
Policy Loss                  -297.75082
Q Predictions Mean           295.32227
Q Predictions Std            39.645115
Q Predictions Max            349.68365
Q Predictions Min            10.167252
V Predictions Mean           292.6056
V Predictions Std            38.08993
V Predictions Max            348.8303
V Predictions Min            23.959871
Log Pis Mean                 -2.9199219
Log Pis Std                  1.7053016
Log Pis Max                  2.8022795
Log Pis Min                  -8.810132
Policy mu Mean               0.106931955
Policy mu Std                0.331464
Policy mu Max                1.66621
Policy mu Min                -1.1081445
Policy log std Mean          -0.74171853
Policy log std Std           0.15326573
Policy log std Max           -0.33469442
Policy log std Min           -1.5267397
Z mean eval                  0.7133734
Z variance eval              0.03294926
total_rewards                [ 49.18688453 275.96787143  51.74459706 252.28732677  84.75689285
  37.68949155 438.8885269   67.58715001 256.05370908  82.5118497 ]
total_rewards_mean           159.66742998750172
total_rewards_std            129.6665840052653
total_rewards_max            438.8885268959074
total_rewards_min            37.68949155144052
Number of train steps total  32000
Number of env steps total    162000
Number of rollouts total     0
Train Time (s)               42.310812200885266
(Previous) Eval Time (s)     33.623826251365244
Sample Time (s)              21.193854186683893
Epoch Time (s)               97.1284926389344
Total Train Time (s)         2969.314975088928
Epoch                        31
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:18:47.584300 UTC | [2020_01_10_11_29_18] Iteration #31 | Epoch Duration: 96.38610315322876
2020-01-10 12:18:47.584466 UTC | [2020_01_10_11_29_18] Iteration #31 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.71725315
Z variance train             0.032979574
KL Divergence                10.836971
KL Loss                      1.0836972
QF Loss                      498.13834
VF Loss                      112.11821
Policy Loss                  -287.44815
Q Predictions Mean           283.9402
Q Predictions Std            54.90134
Q Predictions Max            351.73596
Q Predictions Min            -19.420033
V Predictions Mean           284.89807
V Predictions Std            48.809216
V Predictions Max            348.9771
V Predictions Min            -3.7206073
Log Pis Mean                 -2.8074598
Log Pis Std                  1.8004141
Log Pis Max                  3.9930274
Log Pis Min                  -8.842947
Policy mu Mean               0.061588082
Policy mu Std                0.35859868
Policy mu Max                1.501712
Policy mu Min                -1.5867636
Policy log std Mean          -0.74578357
Policy log std Std           0.17417154
Policy log std Max           -0.3194207
Policy log std Min           -1.8074262
Z mean eval                  0.7074178
Z variance eval              0.028462902
total_rewards                [445.63720185  84.98644238 287.28082766  56.76081424  57.66507473
 559.77902792  97.40535589 166.8606579   79.69361251  82.40331049]
total_rewards_mean           191.847232558489
total_rewards_std            170.4884598862215
total_rewards_max            559.7790279205764
total_rewards_min            56.76081424022721
Number of train steps total  33000
Number of env steps total    167000
Number of rollouts total     0
Train Time (s)               42.76653096778318
(Previous) Eval Time (s)     32.88120031775907
Sample Time (s)              21.044828531797975
Epoch Time (s)               96.69255981734022
Total Train Time (s)         3066.909513061866
Epoch                        32
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:20:25.179067 UTC | [2020_01_10_11_29_18] Iteration #32 | Epoch Duration: 97.59443044662476
2020-01-10 12:20:25.179249 UTC | [2020_01_10_11_29_18] Iteration #32 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.707729
Z variance train             0.028456355
KL Divergence                11.271204
KL Loss                      1.1271204
QF Loss                      208.15994
VF Loss                      59.67191
Policy Loss                  -288.23904
Q Predictions Mean           283.14722
Q Predictions Std            51.30198
Q Predictions Max            378.978
Q Predictions Min            -15.822192
V Predictions Mean           286.58307
V Predictions Std            43.194485
V Predictions Max            374.06485
V Predictions Min            19.28627
Log Pis Mean                 -2.921588
Log Pis Std                  2.2647214
Log Pis Max                  17.220608
Log Pis Min                  -10.72316
Policy mu Mean               0.034112245
Policy mu Std                0.368688
Policy mu Max                2.3928924
Policy mu Min                -2.8824265
Policy log std Mean          -0.7231565
Policy log std Std           0.15611292
Policy log std Max           -0.30934018
Policy log std Min           -1.6475341
Z mean eval                  0.68958753
Z variance eval              0.032059498
total_rewards                [291.12240753 174.08463633 351.83033219 255.67227383 119.43814349
 532.98345665 136.44820105 256.4249165  197.52364344 215.40346209]
total_rewards_mean           253.09314730927426
total_rewards_std            114.79204006620266
total_rewards_max            532.9834566499902
total_rewards_min            119.43814348602885
Number of train steps total  34000
Number of env steps total    172000
Number of rollouts total     0
Train Time (s)               42.359802584163845
(Previous) Eval Time (s)     33.78286147490144
Sample Time (s)              23.465542658232152
Epoch Time (s)               99.60820671729743
Total Train Time (s)         3160.941330456175
Epoch                        33
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:21:59.212085 UTC | [2020_01_10_11_29_18] Iteration #33 | Epoch Duration: 94.03271389007568
2020-01-10 12:21:59.212257 UTC | [2020_01_10_11_29_18] Iteration #33 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.688556
Z variance train             0.032019325
KL Divergence                11.26939
KL Loss                      1.126939
QF Loss                      156.59766
VF Loss                      54.654915
Policy Loss                  -278.85358
Q Predictions Mean           275.66867
Q Predictions Std            48.09465
Q Predictions Max            356.0796
Q Predictions Min            -11.894482
V Predictions Mean           282.54004
V Predictions Std            48.345947
V Predictions Max            362.69244
V Predictions Min            3.5150378
Log Pis Mean                 -3.1269224
Log Pis Std                  1.8837868
Log Pis Max                  4.4472494
Log Pis Min                  -9.644962
Policy mu Mean               0.041850455
Policy mu Std                0.3411465
Policy mu Max                1.354951
Policy mu Min                -1.0153685
Policy log std Mean          -0.73382473
Policy log std Std           0.1564052
Policy log std Max           -0.2997254
Policy log std Min           -1.6806798
Z mean eval                  0.7207992
Z variance eval              0.032697637
total_rewards                [ 45.41883392 157.73636273  83.63852334 159.30689661 236.09117029
 145.08156619 253.84808133 151.88326367 138.80061198 114.24797783]
total_rewards_mean           148.6053287899822
total_rewards_std            59.24151339238391
total_rewards_max            253.84808133138418
total_rewards_min            45.4188339248772
Number of train steps total  35000
Number of env steps total    177000
Number of rollouts total     0
Train Time (s)               42.515320766717196
(Previous) Eval Time (s)     28.207110853865743
Sample Time (s)              23.56344304792583
Epoch Time (s)               94.28587466850877
Total Train Time (s)         3252.287470223848
Epoch                        34
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:23:30.558421 UTC | [2020_01_10_11_29_18] Iteration #34 | Epoch Duration: 91.34604334831238
2020-01-10 12:23:30.558551 UTC | [2020_01_10_11_29_18] Iteration #34 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7200456
Z variance train             0.032830197
KL Divergence                11.463154
KL Loss                      1.1463155
QF Loss                      156.98453
VF Loss                      59.90489
Policy Loss                  -304.47028
Q Predictions Mean           301.0675
Q Predictions Std            48.848763
Q Predictions Max            409.3968
Q Predictions Min            2.2293832
V Predictions Mean           303.7708
V Predictions Std            44.452267
V Predictions Max            417.13766
V Predictions Min            56.98058
Log Pis Mean                 -2.933177
Log Pis Std                  1.9097427
Log Pis Max                  8.776604
Log Pis Min                  -8.393112
Policy mu Mean               0.04044021
Policy mu Std                0.3456162
Policy mu Max                1.9481208
Policy mu Min                -1.5062592
Policy log std Mean          -0.7306717
Policy log std Std           0.1704298
Policy log std Max           -0.27076524
Policy log std Min           -1.7996751
Z mean eval                  0.68225557
Z variance eval              0.039835844
total_rewards                [ 1.44545754e+02  3.78821183e+02  4.54093089e+02  9.70510011e+00
  9.44728536e+01  1.40758380e+02  1.69529956e+02 -2.75506614e-01
  1.05772637e+02  2.84717823e+02]
total_rewards_mean           178.2141268239086
total_rewards_std            142.4154305455721
total_rewards_max            454.09308900355876
total_rewards_min            -0.2755066140472966
Number of train steps total  36000
Number of env steps total    182000
Number of rollouts total     0
Train Time (s)               42.37554034590721
(Previous) Eval Time (s)     25.267008452210575
Sample Time (s)              23.34141423786059
Epoch Time (s)               90.98396303597838
Total Train Time (s)         3347.9735502870753
Epoch                        35
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:25:06.245541 UTC | [2020_01_10_11_29_18] Iteration #35 | Epoch Duration: 95.68690133094788
2020-01-10 12:25:06.245663 UTC | [2020_01_10_11_29_18] Iteration #35 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6774847
Z variance train             0.039757557
KL Divergence                11.08454
KL Loss                      1.1084541
QF Loss                      267.7276
VF Loss                      80.14373
Policy Loss                  -286.63312
Q Predictions Mean           285.75058
Q Predictions Std            52.9046
Q Predictions Max            365.43442
Q Predictions Min            -10.67489
V Predictions Mean           286.79242
V Predictions Std            48.107567
V Predictions Max            359.57507
V Predictions Min            18.165253
Log Pis Mean                 -3.0145605
Log Pis Std                  1.9138329
Log Pis Max                  4.3627863
Log Pis Min                  -8.602844
Policy mu Mean               0.023520885
Policy mu Std                0.34964085
Policy mu Max                1.7008638
Policy mu Min                -1.4533862
Policy log std Mean          -0.72424257
Policy log std Std           0.17003685
Policy log std Max           -0.32950944
Policy log std Min           -1.7630697
Z mean eval                  0.6823068
Z variance eval              0.02270605
total_rewards                [125.8220996  239.89622021 280.32793856  48.65975049  68.7347813
 492.15429971 131.76550146 427.50212833 518.24337809 122.42433448]
total_rewards_mean           245.55304322225825
total_rewards_std            167.92689180284611
total_rewards_max            518.2433780879851
total_rewards_min            48.6597504900835
Number of train steps total  37000
Number of env steps total    187000
Number of rollouts total     0
Train Time (s)               42.363003357779235
(Previous) Eval Time (s)     29.96971927303821
Sample Time (s)              23.427469889167696
Epoch Time (s)               95.76019251998514
Total Train Time (s)         3445.6275588115677
Epoch                        36
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:26:43.902739 UTC | [2020_01_10_11_29_18] Iteration #36 | Epoch Duration: 97.65698337554932
2020-01-10 12:26:43.902860 UTC | [2020_01_10_11_29_18] Iteration #36 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6825051
Z variance train             0.022700207
KL Divergence                12.423866
KL Loss                      1.2423867
QF Loss                      164.20892
VF Loss                      44.254265
Policy Loss                  -295.86606
Q Predictions Mean           292.01678
Q Predictions Std            48.52256
Q Predictions Max            367.16373
Q Predictions Min            -0.6947688
V Predictions Mean           294.2898
V Predictions Std            44.551052
V Predictions Max            365.52237
V Predictions Min            5.837964
Log Pis Mean                 -2.8586972
Log Pis Std                  1.6737444
Log Pis Max                  4.0032454
Log Pis Min                  -7.983161
Policy mu Mean               0.018788032
Policy mu Std                0.3562465
Policy mu Max                1.58985
Policy mu Min                -1.4639986
Policy log std Mean          -0.73823994
Policy log std Std           0.16024615
Policy log std Max           -0.34050772
Policy log std Min           -1.9566282
Z mean eval                  0.68471956
Z variance eval              0.022125408
total_rewards                [262.51008101 201.31837047 138.5693799  252.02550067 128.63262891
 373.76197915  53.99524862  81.53109958 326.9239477  168.78418036]
total_rewards_mean           198.80524163721205
total_rewards_std            99.04456492135007
total_rewards_max            373.76197914980304
total_rewards_min            53.9952486154527
Number of train steps total  38000
Number of env steps total    192000
Number of rollouts total     0
Train Time (s)               43.716203552205116
(Previous) Eval Time (s)     31.866259880829602
Sample Time (s)              23.446320021059364
Epoch Time (s)               99.02878345409408
Total Train Time (s)         3539.3990569035523
Epoch                        37
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:28:17.672699 UTC | [2020_01_10_11_29_18] Iteration #37 | Epoch Duration: 93.76975107192993
2020-01-10 12:28:17.672834 UTC | [2020_01_10_11_29_18] Iteration #37 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.68321115
Z variance train             0.02210517
KL Divergence                12.345873
KL Loss                      1.2345873
QF Loss                      229.1414
VF Loss                      78.48146
Policy Loss                  -315.15234
Q Predictions Mean           312.75934
Q Predictions Std            43.271828
Q Predictions Max            383.84125
Q Predictions Min            15.363487
V Predictions Mean           313.11053
V Predictions Std            42.695885
V Predictions Max            384.4304
V Predictions Min            45.432297
Log Pis Mean                 -2.609876
Log Pis Std                  1.6747459
Log Pis Max                  8.276642
Log Pis Min                  -8.633612
Policy mu Mean               0.07521592
Policy mu Std                0.34816462
Policy mu Max                1.5724653
Policy mu Min                -1.4795799
Policy log std Mean          -0.78771883
Policy log std Std           0.17395537
Policy log std Max           -0.3425918
Policy log std Min           -1.8379296
Z mean eval                  0.64536893
Z variance eval              0.024751652
total_rewards                [279.28042558 295.03648706 128.64350112 422.44410268  99.19667719
 308.01959253 398.40287952 356.820778    92.44369795 625.85528918]
total_rewards_mean           300.6143430794433
total_rewards_std            157.2784393593645
total_rewards_max            625.8552891755447
total_rewards_min            92.44369794889207
Number of train steps total  39000
Number of env steps total    197000
Number of rollouts total     0
Train Time (s)               42.69132534973323
(Previous) Eval Time (s)     26.606974316295236
Sample Time (s)              23.133220850955695
Epoch Time (s)               92.43152051698416
Total Train Time (s)         3632.9477347768843
Epoch                        38
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:29:51.223154 UTC | [2020_01_10_11_29_18] Iteration #38 | Epoch Duration: 93.55022263526917
2020-01-10 12:29:51.223313 UTC | [2020_01_10_11_29_18] Iteration #38 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6450581
Z variance train             0.024717985
KL Divergence                12.628407
KL Loss                      1.2628406
QF Loss                      198.2716
VF Loss                      42.811367
Policy Loss                  -306.482
Q Predictions Mean           304.0777
Q Predictions Std            44.539223
Q Predictions Max            380.66638
Q Predictions Min            19.307997
V Predictions Mean           303.7236
V Predictions Std            43.211185
V Predictions Max            377.32925
V Predictions Min            41.253517
Log Pis Mean                 -2.881422
Log Pis Std                  1.8218423
Log Pis Max                  4.0923095
Log Pis Min                  -8.667391
Policy mu Mean               0.09282116
Policy mu Std                0.34435278
Policy mu Max                1.3019329
Policy mu Min                -1.1549265
Policy log std Mean          -0.7425326
Policy log std Std           0.16448836
Policy log std Max           -0.32079875
Policy log std Min           -1.671832
Z mean eval                  0.65951884
Z variance eval              0.025617233
total_rewards                [597.98746242 180.99884925 637.44200894 149.42731854 165.1264254
 189.36472544 265.36142091  91.79525409 271.88420912 295.37053866]
total_rewards_mean           284.4758212766205
total_rewards_std            176.88387837307152
total_rewards_max            637.4420089366815
total_rewards_min            91.79525408684617
Number of train steps total  40000
Number of env steps total    202000
Number of rollouts total     0
Train Time (s)               43.913383753970265
(Previous) Eval Time (s)     27.725420946720988
Sample Time (s)              23.159190983511508
Epoch Time (s)               94.79799568420276
Total Train Time (s)         3730.493509177584
Epoch                        39
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:31:28.770333 UTC | [2020_01_10_11_29_18] Iteration #39 | Epoch Duration: 97.54690837860107
2020-01-10 12:31:28.770457 UTC | [2020_01_10_11_29_18] Iteration #39 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6587369
Z variance train             0.025714029
KL Divergence                12.24896
KL Loss                      1.224896
QF Loss                      210.3259
VF Loss                      60.506554
Policy Loss                  -313.738
Q Predictions Mean           310.00757
Q Predictions Std            43.780933
Q Predictions Max            408.95547
Q Predictions Min            163.08456
V Predictions Mean           314.50592
V Predictions Std            44.27265
V Predictions Max            415.7218
V Predictions Min            161.05312
Log Pis Mean                 -2.808741
Log Pis Std                  1.8662746
Log Pis Max                  6.953555
Log Pis Min                  -10.925467
Policy mu Mean               0.050253898
Policy mu Std                0.32413545
Policy mu Max                1.6064591
Policy mu Min                -1.0442255
Policy log std Mean          -0.7890434
Policy log std Std           0.17001735
Policy log std Max           -0.37017772
Policy log std Min           -2.1892188
Z mean eval                  0.63944227
Z variance eval              0.02661488
total_rewards                [365.14133659 410.73521395 154.90947363  72.85265982 286.3395126
 763.93518695 210.72871498 687.64262933 301.45654794 194.69413982]
total_rewards_mean           344.84354156146725
total_rewards_std            213.02429600092185
total_rewards_max            763.9351869509826
total_rewards_min            72.85265982439873
Number of train steps total  41000
Number of env steps total    207000
Number of rollouts total     0
Train Time (s)               44.512944580987096
(Previous) Eval Time (s)     30.47409531287849
Sample Time (s)              22.899087104015052
Epoch Time (s)               97.88612699788064
Total Train Time (s)         3828.627197431866
Epoch                        40
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:33:06.905903 UTC | [2020_01_10_11_29_18] Iteration #40 | Epoch Duration: 98.1353371143341
2020-01-10 12:33:06.906077 UTC | [2020_01_10_11_29_18] Iteration #40 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6427956
Z variance train             0.02662829
KL Divergence                12.56275
KL Loss                      1.256275
QF Loss                      586.99634
VF Loss                      36.278423
Policy Loss                  -323.1488
Q Predictions Mean           317.60446
Q Predictions Std            59.123634
Q Predictions Max            409.19672
Q Predictions Min            -10.049316
V Predictions Mean           321.98682
V Predictions Std            56.171528
V Predictions Max            409.79355
V Predictions Min            12.816392
Log Pis Mean                 -2.8088808
Log Pis Std                  2.0973175
Log Pis Max                  8.406142
Log Pis Min                  -9.259314
Policy mu Mean               0.05984819
Policy mu Std                0.3646943
Policy mu Max                1.8307046
Policy mu Min                -2.5632513
Policy log std Mean          -0.754297
Policy log std Std           0.16348493
Policy log std Max           -0.31048986
Policy log std Min           -1.756985
Z mean eval                  0.6237442
Z variance eval              0.03401792
total_rewards                [165.19401457 281.34825856 541.65672458 109.82396334 452.60784631
  92.37065006 126.57391877 240.80663699 332.06326062 409.8182665 ]
total_rewards_mean           275.2263540299444
total_rewards_std            148.32928544191319
total_rewards_max            541.6567245784474
total_rewards_min            92.37065005815779
Number of train steps total  42000
Number of env steps total    212000
Number of rollouts total     0
Train Time (s)               44.24350085109472
(Previous) Eval Time (s)     30.7230506404303
Sample Time (s)              21.687384995631874
Epoch Time (s)               96.6539364871569
Total Train Time (s)         3921.3017232781276
Epoch                        41
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:34:39.582235 UTC | [2020_01_10_11_29_18] Iteration #41 | Epoch Duration: 92.67595911026001
2020-01-10 12:34:39.582483 UTC | [2020_01_10_11_29_18] Iteration #41 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6228228
Z variance train             0.034129407
KL Divergence                12.080669
KL Loss                      1.2080669
QF Loss                      141.70715
VF Loss                      51.069794
Policy Loss                  -312.57614
Q Predictions Mean           309.0694
Q Predictions Std            59.09403
Q Predictions Max            412.35617
Q Predictions Min            -30.74404
V Predictions Mean           312.12497
V Predictions Std            53.85726
V Predictions Max            412.0637
V Predictions Min            27.908974
Log Pis Mean                 -2.7838464
Log Pis Std                  1.7823594
Log Pis Max                  2.1253686
Log Pis Min                  -9.026264
Policy mu Mean               0.04719153
Policy mu Std                0.38634545
Policy mu Max                1.2454394
Policy mu Min                -1.698406
Policy log std Mean          -0.7722693
Policy log std Std           0.15734947
Policy log std Max           -0.36075255
Policy log std Min           -1.5685724
Z mean eval                  0.629766
Z variance eval              0.02563025
total_rewards                [245.97052987 115.03522987 203.30680008 130.62680638 213.68126368
 293.60062962 162.71882413  92.68619496 625.92493942 150.32124924]
total_rewards_mean           223.38724672357534
total_rewards_std            146.43109969230957
total_rewards_max            625.9249394198887
total_rewards_min            92.68619495846906
Number of train steps total  43000
Number of env steps total    217000
Number of rollouts total     0
Train Time (s)               43.39822528511286
(Previous) Eval Time (s)     26.74482421344146
Sample Time (s)              23.747562468983233
Epoch Time (s)               93.89061196753755
Total Train Time (s)         4013.190122835804
Epoch                        42
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:36:11.471430 UTC | [2020_01_10_11_29_18] Iteration #42 | Epoch Duration: 91.88879227638245
2020-01-10 12:36:11.471600 UTC | [2020_01_10_11_29_18] Iteration #42 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6300916
Z variance train             0.02570805
KL Divergence                12.122811
KL Loss                      1.2122811
QF Loss                      181.70398
VF Loss                      104.118286
Policy Loss                  -326.29926
Q Predictions Mean           322.03064
Q Predictions Std            51.782856
Q Predictions Max            427.1607
Q Predictions Min            46.52219
V Predictions Mean           322.41528
V Predictions Std            50.752357
V Predictions Max            419.58206
V Predictions Min            40.66342
Log Pis Mean                 -2.8727102
Log Pis Std                  1.8971282
Log Pis Max                  5.4436526
Log Pis Min                  -10.474269
Policy mu Mean               0.012315597
Policy mu Std                0.34326273
Policy mu Max                1.561802
Policy mu Min                -1.2167791
Policy log std Mean          -0.7573558
Policy log std Std           0.17312862
Policy log std Max           -0.30864894
Policy log std Min           -1.8505946
Z mean eval                  0.62237895
Z variance eval              0.04245139
total_rewards                [168.1547073  248.26942081 171.41089178 954.97483909  89.86956632
 390.11809003 435.80966384 146.88461407 220.90013928 252.460885  ]
total_rewards_mean           307.88528175153004
total_rewards_std            238.25324066459157
total_rewards_max            954.9748390894081
total_rewards_min            89.86956631849125
Number of train steps total  44000
Number of env steps total    222000
Number of rollouts total     0
Train Time (s)               43.49323906796053
(Previous) Eval Time (s)     24.74277000594884
Sample Time (s)              23.275541597045958
Epoch Time (s)               91.51155067095533
Total Train Time (s)         4110.763296100777
Epoch                        43
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:37:49.047228 UTC | [2020_01_10_11_29_18] Iteration #43 | Epoch Duration: 97.57548594474792
2020-01-10 12:37:49.047439 UTC | [2020_01_10_11_29_18] Iteration #43 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.62024295
Z variance train             0.04235632
KL Divergence                11.363642
KL Loss                      1.1363642
QF Loss                      157.4249
VF Loss                      60.4946
Policy Loss                  -341.98444
Q Predictions Mean           341.3095
Q Predictions Std            46.778984
Q Predictions Max            431.67325
Q Predictions Min            203.323
V Predictions Mean           345.11517
V Predictions Std            45.597507
V Predictions Max            421.69495
V Predictions Min            211.02318
Log Pis Mean                 -2.9344187
Log Pis Std                  1.9876628
Log Pis Max                  3.6311414
Log Pis Min                  -11.725489
Policy mu Mean               0.049751304
Policy mu Std                0.35628307
Policy mu Max                1.5225923
Policy mu Min                -1.1470406
Policy log std Mean          -0.77129126
Policy log std Std           0.16869661
Policy log std Max           -0.32036865
Policy log std Min           -1.7652639
Z mean eval                  0.60462433
Z variance eval              0.042005304
total_rewards                [263.97101313 197.24644102 256.50416154 111.06678112 270.83663989
 333.40956325 731.43809411 693.46611455 190.32304339 208.66796475]
total_rewards_mean           325.69298167447675
total_rewards_std            201.52777133232811
total_rewards_max            731.4380941118962
total_rewards_min            111.06678111603856
Number of train steps total  45000
Number of env steps total    227000
Number of rollouts total     0
Train Time (s)               42.60415595397353
(Previous) Eval Time (s)     30.806436450220644
Sample Time (s)              21.853813745547086
Epoch Time (s)               95.26440614974126
Total Train Time (s)         4208.839858216699
Epoch                        44
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:39:27.127882 UTC | [2020_01_10_11_29_18] Iteration #44 | Epoch Duration: 98.08024907112122
2020-01-10 12:39:27.132152 UTC | [2020_01_10_11_29_18] Iteration #44 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6083573
Z variance train             0.042256895
KL Divergence                11.485094
KL Loss                      1.1485094
QF Loss                      127.57688
VF Loss                      21.39815
Policy Loss                  -321.4777
Q Predictions Mean           318.1988
Q Predictions Std            51.108273
Q Predictions Max            401.91367
Q Predictions Min            -33.879677
V Predictions Mean           319.07782
V Predictions Std            50.52136
V Predictions Max            400.0444
V Predictions Min            -21.769451
Log Pis Mean                 -2.8134356
Log Pis Std                  1.7205306
Log Pis Max                  2.0263638
Log Pis Min                  -6.8949394
Policy mu Mean               0.027256679
Policy mu Std                0.35829407
Policy mu Max                1.3020478
Policy mu Min                -1.3475829
Policy log std Mean          -0.77761066
Policy log std Std           0.16169637
Policy log std Max           -0.32798457
Policy log std Min           -1.517292
Z mean eval                  0.6463895
Z variance eval              0.028386254
total_rewards                [771.87083631 240.85292638 229.10617339 253.93078114  66.66772974
 477.31665682 760.99824103 187.00471448 427.6554992  147.27702897]
total_rewards_mean           356.26805874536933
total_rewards_std            235.04053181841624
total_rewards_max            771.8708363055832
total_rewards_min            66.66772974129118
Number of train steps total  46000
Number of env steps total    232000
Number of rollouts total     0
Train Time (s)               42.382834002841264
(Previous) Eval Time (s)     33.62203055387363
Sample Time (s)              23.530022946186364
Epoch Time (s)               99.53488750290126
Total Train Time (s)         4309.5635673548095
Epoch                        45
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:41:07.851023 UTC | [2020_01_10_11_29_18] Iteration #45 | Epoch Duration: 100.71872901916504
2020-01-10 12:41:07.851198 UTC | [2020_01_10_11_29_18] Iteration #45 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.64764136
Z variance train             0.028373605
KL Divergence                12.232212
KL Loss                      1.2232212
QF Loss                      161.88141
VF Loss                      42.0597
Policy Loss                  -349.03806
Q Predictions Mean           346.16635
Q Predictions Std            47.6473
Q Predictions Max            426.62903
Q Predictions Min            221.14005
V Predictions Mean           347.74097
V Predictions Std            46.77929
V Predictions Max            438.81195
V Predictions Min            226.46754
Log Pis Mean                 -2.8582277
Log Pis Std                  1.7432362
Log Pis Max                  1.672037
Log Pis Min                  -9.344346
Policy mu Mean               0.043293342
Policy mu Std                0.36978653
Policy mu Max                1.5208381
Policy mu Min                -1.2496241
Policy log std Mean          -0.7416534
Policy log std Std           0.14834855
Policy log std Max           -0.31715646
Policy log std Min           -1.2330751
Z mean eval                  0.6083155
Z variance eval              0.028922234
total_rewards                [254.11197092  51.76847255 595.84135216 438.39006351 379.12887923
 205.42160251  78.56834989 821.59490414 115.34863675 226.06116385]
total_rewards_mean           316.62353955265684
total_rewards_std            233.1304027845365
total_rewards_max            821.5949041438267
total_rewards_min            51.76847255297885
Number of train steps total  47000
Number of env steps total    237000
Number of rollouts total     0
Train Time (s)               42.7069085999392
(Previous) Eval Time (s)     34.80564552312717
Sample Time (s)              23.413371061440557
Epoch Time (s)               100.92592518450692
Total Train Time (s)         4400.557577040978
Epoch                        46
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:42:38.847177 UTC | [2020_01_10_11_29_18] Iteration #46 | Epoch Duration: 90.99583959579468
2020-01-10 12:42:38.847365 UTC | [2020_01_10_11_29_18] Iteration #46 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.60669094
Z variance train             0.02898025
KL Divergence                12.648261
KL Loss                      1.2648262
QF Loss                      183.16159
VF Loss                      25.06559
Policy Loss                  -341.7026
Q Predictions Mean           337.10263
Q Predictions Std            48.161087
Q Predictions Max            421.80176
Q Predictions Min            207.12215
V Predictions Mean           343.71304
V Predictions Std            47.697628
V Predictions Max            423.62622
V Predictions Min            204.26143
Log Pis Mean                 -2.644238
Log Pis Std                  1.9167887
Log Pis Max                  6.117564
Log Pis Min                  -8.022979
Policy mu Mean               0.033689477
Policy mu Std                0.39354083
Policy mu Max                1.3955314
Policy mu Min                -1.3081278
Policy log std Mean          -0.7742159
Policy log std Std           0.18355453
Policy log std Max           -0.28373042
Policy log std Min           -1.8736702
Z mean eval                  0.59639484
Z variance eval              0.030967802
total_rewards                [137.21954845  75.52514413 253.68601972 299.63694651 334.48356005
 179.12125031 165.48188165 625.52481785 157.70390495 495.56166151]
total_rewards_mean           272.3944735127908
total_rewards_std            164.24547583880013
total_rewards_max            625.5248178494894
total_rewards_min            75.52514412859678
Number of train steps total  48000
Number of env steps total    242000
Number of rollouts total     0
Train Time (s)               42.77933627041057
(Previous) Eval Time (s)     24.875306885689497
Sample Time (s)              22.943391020875424
Epoch Time (s)               90.59803417697549
Total Train Time (s)         4499.95592291886
Epoch                        47
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:44:18.246402 UTC | [2020_01_10_11_29_18] Iteration #47 | Epoch Duration: 99.39887118339539
2020-01-10 12:44:18.246591 UTC | [2020_01_10_11_29_18] Iteration #47 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.59423107
Z variance train             0.031101897
KL Divergence                12.501603
KL Loss                      1.2501603
QF Loss                      215.36292
VF Loss                      35.428333
Policy Loss                  -359.6228
Q Predictions Mean           355.6369
Q Predictions Std            61.676987
Q Predictions Max            449.29752
Q Predictions Min            7.70206
V Predictions Mean           359.91605
V Predictions Std            61.495472
V Predictions Max            449.70074
V Predictions Min            -2.190517
Log Pis Mean                 -2.4457169
Log Pis Std                  1.7867718
Log Pis Max                  3.7068748
Log Pis Min                  -7.9598217
Policy mu Mean               0.042331383
Policy mu Std                0.38938946
Policy mu Max                1.6324607
Policy mu Min                -2.0901487
Policy log std Mean          -0.77568406
Policy log std Std           0.17614284
Policy log std Max           -0.060568422
Policy log std Min           -1.3941767
Z mean eval                  0.6001453
Z variance eval              0.024631666
total_rewards                [120.65492622 127.75156011 180.81770112 131.54581893 758.70024015
  77.0660701  538.4476488   79.21067838 150.94276059 447.50797554]
total_rewards_mean           261.26453799371455
total_rewards_std            223.40509584483374
total_rewards_max            758.7002401509045
total_rewards_min            77.06607010145933
Number of train steps total  49000
Number of env steps total    247000
Number of rollouts total     0
Train Time (s)               43.15285096783191
(Previous) Eval Time (s)     33.67591095296666
Sample Time (s)              23.33204204775393
Epoch Time (s)               100.1608039685525
Total Train Time (s)         4599.740474799648
Epoch                        48
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:45:58.031452 UTC | [2020_01_10_11_29_18] Iteration #48 | Epoch Duration: 99.78475999832153
2020-01-10 12:45:58.031572 UTC | [2020_01_10_11_29_18] Iteration #48 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.601992
Z variance train             0.024611972
KL Divergence                13.169144
KL Loss                      1.3169144
QF Loss                      725.25854
VF Loss                      82.82019
Policy Loss                  -347.18457
Q Predictions Mean           342.2985
Q Predictions Std            62.239624
Q Predictions Max            448.85974
Q Predictions Min            -24.30034
V Predictions Mean           342.22546
V Predictions Std            62.244484
V Predictions Max            443.8778
V Predictions Min            -34.97864
Log Pis Mean                 -2.36065
Log Pis Std                  1.6671002
Log Pis Max                  4.7251577
Log Pis Min                  -7.6047816
Policy mu Mean               0.056003653
Policy mu Std                0.36553738
Policy mu Max                1.8697631
Policy mu Min                -1.2973456
Policy log std Mean          -0.7862602
Policy log std Std           0.17561446
Policy log std Max           -0.33697805
Policy log std Min           -1.7610183
Z mean eval                  0.59856445
Z variance eval              0.018670548
total_rewards                [627.54441273  -1.21993479 113.8236865   91.94689763 838.25800516
 119.34109333 199.31576096 111.84099819  67.83054006 144.65876897]
total_rewards_mean           231.3340228738294
total_rewards_std            259.7595702193388
total_rewards_max            838.2580051593773
total_rewards_min            -1.2199347873947275
Number of train steps total  50000
Number of env steps total    252000
Number of rollouts total     0
Train Time (s)               43.24134371988475
(Previous) Eval Time (s)     33.29966741614044
Sample Time (s)              23.39856150187552
Epoch Time (s)               99.93957263790071
Total Train Time (s)         4703.05958087137
Epoch                        49
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:47:41.351318 UTC | [2020_01_10_11_29_18] Iteration #49 | Epoch Duration: 103.31965470314026
2020-01-10 12:47:41.351440 UTC | [2020_01_10_11_29_18] Iteration #49 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.60183537
Z variance train             0.018750811
KL Divergence                13.505235
KL Loss                      1.3505235
QF Loss                      392.09872
VF Loss                      128.02335
Policy Loss                  -358.6189
Q Predictions Mean           354.5133
Q Predictions Std            58.197014
Q Predictions Max            462.01126
Q Predictions Min            42.96886
V Predictions Mean           352.0697
V Predictions Std            56.819134
V Predictions Max            443.561
V Predictions Min            6.318139
Log Pis Mean                 -2.5398548
Log Pis Std                  2.073607
Log Pis Max                  6.564123
Log Pis Min                  -9.984703
Policy mu Mean               0.02908214
Policy mu Std                0.38677195
Policy mu Max                1.4965698
Policy mu Min                -1.6794162
Policy log std Mean          -0.7725878
Policy log std Std           0.19921574
Policy log std Max           -0.35698932
Policy log std Min           -1.9708519
Z mean eval                  0.6005643
Z variance eval              0.021861235
total_rewards                [238.48848786  49.23138253 268.04310137  93.21655483 312.33887641
 230.59433268 159.98552931 349.06046794 266.84278188 181.2003444 ]
total_rewards_mean           214.900185921763
total_rewards_std            89.56704414410024
total_rewards_max            349.06046794144464
total_rewards_min            49.2313825303212
Number of train steps total  51000
Number of env steps total    257000
Number of rollouts total     0
Train Time (s)               42.49530510790646
(Previous) Eval Time (s)     36.679507977794856
Sample Time (s)              23.088141731917858
Epoch Time (s)               102.26295481761917
Total Train Time (s)         4798.568601734005
Epoch                        50
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:49:16.865442 UTC | [2020_01_10_11_29_18] Iteration #50 | Epoch Duration: 95.51386165618896
2020-01-10 12:49:16.865718 UTC | [2020_01_10_11_29_18] Iteration #50 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.60137224
Z variance train             0.02181464
KL Divergence                12.890913
KL Loss                      1.2890913
QF Loss                      252.33069
VF Loss                      110.76661
Policy Loss                  -367.02863
Q Predictions Mean           364.1773
Q Predictions Std            51.677547
Q Predictions Max            456.38672
Q Predictions Min            178.36217
V Predictions Mean           363.57306
V Predictions Std            52.61978
V Predictions Max            451.50922
V Predictions Min            144.66212
Log Pis Mean                 -2.3814583
Log Pis Std                  1.9106191
Log Pis Max                  5.725996
Log Pis Min                  -8.389155
Policy mu Mean               0.044321463
Policy mu Std                0.398915
Policy mu Max                1.3338403
Policy mu Min                -1.1806067
Policy log std Mean          -0.77921706
Policy log std Std           0.18149593
Policy log std Max           -0.2855115
Policy log std Min           -1.8303046
Z mean eval                  0.5702838
Z variance eval              0.027648592
total_rewards                [433.30078595  36.13352163 357.9558308  349.60841221  76.75575637
  73.74273401 399.186206    97.38656739 247.17829357 471.14192304]
total_rewards_mean           254.2390030964748
total_rewards_std            160.08558404948104
total_rewards_max            471.14192304090517
total_rewards_min            36.13352163320669
Number of train steps total  52000
Number of env steps total    262000
Number of rollouts total     0
Train Time (s)               43.17880824068561
(Previous) Eval Time (s)     29.93019180605188
Sample Time (s)              22.951348710805178
Epoch Time (s)               96.06034875754267
Total Train Time (s)         4890.675246057101
Epoch                        51
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:50:48.971676 UTC | [2020_01_10_11_29_18] Iteration #51 | Epoch Duration: 92.1057493686676
2020-01-10 12:50:48.971831 UTC | [2020_01_10_11_29_18] Iteration #51 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.5688723
Z variance train             0.027711403
KL Divergence                12.656979
KL Loss                      1.2656978
QF Loss                      273.664
VF Loss                      61.095516
Policy Loss                  -360.3365
Q Predictions Mean           355.4123
Q Predictions Std            61.042377
Q Predictions Max            469.42557
Q Predictions Min            -12.687027
V Predictions Mean           364.6031
V Predictions Std            59.88094
V Predictions Max            471.85474
V Predictions Min            -19.993153
Log Pis Mean                 -2.4896755
Log Pis Std                  1.7237102
Log Pis Max                  4.7967587
Log Pis Min                  -7.4345083
Policy mu Mean               0.0028749425
Policy mu Std                0.38301513
Policy mu Max                1.2879906
Policy mu Min                -1.4708974
Policy log std Mean          -0.7789802
Policy log std Std           0.17437656
Policy log std Max           -0.24161273
Policy log std Min           -1.5553186
Z mean eval                  0.5779501
Z variance eval              0.029973041
total_rewards                [115.65512096 922.17521125  34.03581432  83.91321762  78.14050938
  79.50723542 258.29428423 113.0943323  182.95424874  95.35778366]
total_rewards_mean           196.31277578792444
total_rewards_std            249.21777657558715
total_rewards_max            922.175211251107
total_rewards_min            34.03581432276453
Number of train steps total  53000
Number of env steps total    267000
Number of rollouts total     0
Train Time (s)               43.04568412108347
(Previous) Eval Time (s)     25.975340969860554
Sample Time (s)              23.088291932363063
Epoch Time (s)               92.10931702330709
Total Train Time (s)         4983.482297244947
Epoch                        52
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:52:21.779604 UTC | [2020_01_10_11_29_18] Iteration #52 | Epoch Duration: 92.80765342712402
2020-01-10 12:52:21.779766 UTC | [2020_01_10_11_29_18] Iteration #52 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.57766324
Z variance train             0.029891497
KL Divergence                12.64953
KL Loss                      1.264953
QF Loss                      156.25903
VF Loss                      48.618393
Policy Loss                  -361.11243
Q Predictions Mean           356.38306
Q Predictions Std            63.10603
Q Predictions Max            459.1248
Q Predictions Min            -21.604666
V Predictions Mean           360.19165
V Predictions Std            60.913845
V Predictions Max            457.34906
V Predictions Min            21.056362
Log Pis Mean                 -2.5725756
Log Pis Std                  1.711863
Log Pis Max                  4.768647
Log Pis Min                  -8.0523815
Policy mu Mean               0.06519775
Policy mu Std                0.37818512
Policy mu Max                1.7197018
Policy mu Min                -1.6293254
Policy log std Mean          -0.7871161
Policy log std Std           0.1990665
Policy log std Max           -0.05402857
Policy log std Min           -1.8402594
Z mean eval                  0.5766846
Z variance eval              0.023869745
total_rewards                [243.09167185 498.06756183 641.69470547 786.05647725 196.83896032
  60.97970242  32.35011557  38.67498779 504.34280205 266.17040907]
total_rewards_mean           326.82673936377535
total_rewards_std            252.76061710820656
total_rewards_max            786.056477250995
total_rewards_min            32.35011557217106
Number of train steps total  54000
Number of env steps total    272000
Number of rollouts total     0
Train Time (s)               42.53373920312151
(Previous) Eval Time (s)     26.673438237048686
Sample Time (s)              24.088010382838547
Epoch Time (s)               93.29518782300875
Total Train Time (s)         5076.0086905080825
Epoch                        53
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:53:54.310525 UTC | [2020_01_10_11_29_18] Iteration #53 | Epoch Duration: 92.53060173988342
2020-01-10 12:53:54.310800 UTC | [2020_01_10_11_29_18] Iteration #53 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.5763089
Z variance train             0.023858484
KL Divergence                12.913995
KL Loss                      1.2913995
QF Loss                      178.81384
VF Loss                      19.957722
Policy Loss                  -364.40567
Q Predictions Mean           361.66028
Q Predictions Std            65.607765
Q Predictions Max            479.79877
Q Predictions Min            1.0981107
V Predictions Mean           363.32227
V Predictions Std            63.63787
V Predictions Max            481.70816
V Predictions Min            30.561644
Log Pis Mean                 -2.4689894
Log Pis Std                  1.783172
Log Pis Max                  3.0954857
Log Pis Min                  -9.379496
Policy mu Mean               0.054619696
Policy mu Std                0.375377
Policy mu Max                1.3509212
Policy mu Min                -1.2761717
Policy log std Mean          -0.7964945
Policy log std Std           0.19354245
Policy log std Max           -0.31022972
Policy log std Min           -1.6435559
Z mean eval                  0.5797037
Z variance eval              0.024783485
total_rewards                [396.91754128 628.5646888  318.62675645 348.25714024 181.46535439
 243.65585968  90.44812504 255.38823748 469.17631077 321.92605846]
total_rewards_mean           325.44260725891587
total_rewards_std            143.44995911815306
total_rewards_max            628.5646887983252
total_rewards_min            90.44812503836968
Number of train steps total  55000
Number of env steps total    277000
Number of rollouts total     0
Train Time (s)               43.2517206328921
(Previous) Eval Time (s)     25.908595071174204
Sample Time (s)              23.29831336485222
Epoch Time (s)               92.45862906891853
Total Train Time (s)         5171.856876393314
Epoch                        54
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:55:30.157433 UTC | [2020_01_10_11_29_18] Iteration #54 | Epoch Duration: 95.84644746780396
2020-01-10 12:55:30.157553 UTC | [2020_01_10_11_29_18] Iteration #54 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.57931197
Z variance train             0.024881328
KL Divergence                12.716234
KL Loss                      1.2716235
QF Loss                      168.85312
VF Loss                      72.7865
Policy Loss                  -377.76172
Q Predictions Mean           375.216
Q Predictions Std            68.2138
Q Predictions Max            489.74298
Q Predictions Min            17.84941
V Predictions Mean           375.8187
V Predictions Std            65.07322
V Predictions Max            478.0569
V Predictions Min            43.50307
Log Pis Mean                 -2.478415
Log Pis Std                  1.8528917
Log Pis Max                  1.526645
Log Pis Min                  -8.225798
Policy mu Mean               0.06691
Policy mu Std                0.38813257
Policy mu Max                1.4016901
Policy mu Min                -1.5465847
Policy log std Mean          -0.78965634
Policy log std Std           0.1843598
Policy log std Max           -0.32362086
Policy log std Min           -1.3270181
Z mean eval                  0.5934184
Z variance eval              0.032547116
total_rewards                [135.49969737 234.37152873 441.76086736 322.69599694 259.42551553
  45.46132745  -9.23896106  43.61930585 702.97648301  16.36582869]
total_rewards_mean           219.2937589878125
total_rewards_std            213.8873846666128
total_rewards_max            702.9764830135101
total_rewards_min            -9.238961062064524
Number of train steps total  56000
Number of env steps total    282000
Number of rollouts total     0
Train Time (s)               42.8441856848076
(Previous) Eval Time (s)     29.296194741968066
Sample Time (s)              23.283747012726963
Epoch Time (s)               95.42412743950263
Total Train Time (s)         5269.328402292449
Epoch                        55
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:57:07.630472 UTC | [2020_01_10_11_29_18] Iteration #55 | Epoch Duration: 97.47282981872559
2020-01-10 12:57:07.630599 UTC | [2020_01_10_11_29_18] Iteration #55 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.5899176
Z variance train             0.032690376
KL Divergence                12.656334
KL Loss                      1.2656335
QF Loss                      431.9125
VF Loss                      33.99183
Policy Loss                  -374.89554
Q Predictions Mean           372.06192
Q Predictions Std            62.612053
Q Predictions Max            474.48816
Q Predictions Min            -0.06786311
V Predictions Mean           376.2313
V Predictions Std            61.889225
V Predictions Max            472.39377
V Predictions Min            -15.210261
Log Pis Mean                 -2.6113834
Log Pis Std                  1.7792879
Log Pis Max                  1.4593861
Log Pis Min                  -7.8853393
Policy mu Mean               0.029501595
Policy mu Std                0.37831178
Policy mu Max                1.3058674
Policy mu Min                -1.6444222
Policy log std Mean          -0.7773837
Policy log std Std           0.18360525
Policy log std Max           -0.2894598
Policy log std Min           -1.2886416
Z mean eval                  0.55952823
Z variance eval              0.021884868
total_rewards                [235.7469687  153.64996211 435.56629969 146.93642122 131.25824047
 112.38907644  78.17174792 249.59925017 350.1674886  455.22255076]
total_rewards_mean           234.87080060808867
total_rewards_std            129.21524928349817
total_rewards_max            455.2225507585049
total_rewards_min            78.1717479227891
Number of train steps total  57000
Number of env steps total    287000
Number of rollouts total     0
Train Time (s)               42.67708240589127
(Previous) Eval Time (s)     31.344654470216483
Sample Time (s)              23.227894335985184
Epoch Time (s)               97.24963121209294
Total Train Time (s)         5361.8995116036385
Epoch                        56
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:58:40.204585 UTC | [2020_01_10_11_29_18] Iteration #56 | Epoch Duration: 92.57387018203735
2020-01-10 12:58:40.204777 UTC | [2020_01_10_11_29_18] Iteration #56 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.55962294
Z variance train             0.021812122
KL Divergence                13.454901
KL Loss                      1.3454901
QF Loss                      261.3952
VF Loss                      55.294987
Policy Loss                  -390.01373
Q Predictions Mean           386.36948
Q Predictions Std            62.817825
Q Predictions Max            514.0148
Q Predictions Min            38.668205
V Predictions Mean           393.71954
V Predictions Std            59.73072
V Predictions Max            514.40814
V Predictions Min            192.674
Log Pis Mean                 -2.643937
Log Pis Std                  2.1839285
Log Pis Max                  6.831791
Log Pis Min                  -9.176904
Policy mu Mean               0.06840963
Policy mu Std                0.404345
Policy mu Max                2.0061834
Policy mu Min                -1.6257372
Policy log std Mean          -0.77836955
Policy log std Std           0.19035846
Policy log std Max           -0.27819458
Policy log std Min           -1.7996887
Z mean eval                  0.56803924
Z variance eval              0.02347634
total_rewards                [ 449.8396183   393.1525084    79.72598425  302.51446838  380.19450475
  846.51770826 1036.91476356  731.05259002  130.2782764    30.43485771]
total_rewards_mean           438.0625280019867
total_rewards_std            320.07451425671195
total_rewards_max            1036.9147635637948
total_rewards_min            30.43485771049971
Number of train steps total  58000
Number of env steps total    292000
Number of rollouts total     0
Train Time (s)               43.11703577358276
(Previous) Eval Time (s)     26.668649938888848
Sample Time (s)              23.00138343172148
Epoch Time (s)               92.78706914419308
Total Train Time (s)         5450.115360486787
Epoch                        57
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:00:08.421240 UTC | [2020_01_10_11_29_18] Iteration #57 | Epoch Duration: 88.21630883216858
2020-01-10 13:00:08.421412 UTC | [2020_01_10_11_29_18] Iteration #57 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.5674484
Z variance train             0.023407545
KL Divergence                13.778536
KL Loss                      1.3778536
QF Loss                      253.09297
VF Loss                      34.784325
Policy Loss                  -392.50488
Q Predictions Mean           389.09494
Q Predictions Std            71.80268
Q Predictions Max            502.6248
Q Predictions Min            17.058125
V Predictions Mean           395.01727
V Predictions Std            73.56734
V Predictions Max            508.17096
V Predictions Min            3.8045297
Log Pis Mean                 -2.1629677
Log Pis Std                  1.9369833
Log Pis Max                  7.4933934
Log Pis Min                  -8.615759
Policy mu Mean               0.049035948
Policy mu Std                0.38513744
Policy mu Max                1.5545466
Policy mu Min                -1.1510031
Policy log std Mean          -0.8415161
Policy log std Std           0.20384777
Policy log std Max           -0.31559378
Policy log std Min           -1.8716025
Z mean eval                  0.57845235
Z variance eval              0.01882937
total_rewards                [169.45349875 185.12373681  83.44345832 352.97381922  83.84408442
 434.96482623  48.95086974 462.41900589 550.25874713 304.90096683]
total_rewards_mean           267.6333013336566
total_rewards_std            169.25242027988676
total_rewards_max            550.2587471289196
total_rewards_min            48.950869736988565
Number of train steps total  59000
Number of env steps total    297000
Number of rollouts total     0
Train Time (s)               42.74073500977829
(Previous) Eval Time (s)     22.097639543935657
Sample Time (s)              21.42745214700699
Epoch Time (s)               86.26582670072094
Total Train Time (s)         5544.411117560696
Epoch                        58
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:01:42.717256 UTC | [2020_01_10_11_29_18] Iteration #58 | Epoch Duration: 94.29572558403015
2020-01-10 13:01:42.717371 UTC | [2020_01_10_11_29_18] Iteration #58 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.581512
Z variance train             0.018807288
KL Divergence                14.453303
KL Loss                      1.4453304
QF Loss                      534.7908
VF Loss                      202.09615
Policy Loss                  -375.48065
Q Predictions Mean           372.22485
Q Predictions Std            87.90036
Q Predictions Max            505.31683
Q Predictions Min            -60.03459
V Predictions Mean           372.72174
V Predictions Std            80.62158
V Predictions Max            495.24762
V Predictions Min            -7.92697
Log Pis Mean                 -2.3705463
Log Pis Std                  1.979835
Log Pis Max                  5.5975876
Log Pis Min                  -8.300686
Policy mu Mean               0.040559035
Policy mu Std                0.4078596
Policy mu Max                2.883093
Policy mu Min                -1.8467656
Policy log std Mean          -0.7861822
Policy log std Std           0.20714623
Policy log std Max           -0.03053099
Policy log std Min           -1.659848
Z mean eval                  0.59330326
Z variance eval              0.016876906
total_rewards                [711.78047591 606.47396895 759.03394227 712.26989417 121.6474985
  87.89018188 752.72706071 729.31946789 768.66855315 209.36948624]
total_rewards_mean           545.9180529676813
total_rewards_std            270.80481559894895
total_rewards_max            768.6685531534422
total_rewards_min            87.89018188049079
Number of train steps total  60000
Number of env steps total    302000
Number of rollouts total     0
Train Time (s)               42.75722050527111
(Previous) Eval Time (s)     30.127308663912117
Sample Time (s)              23.113176685292274
Epoch Time (s)               95.9977058544755
Total Train Time (s)         5640.61600519577
Epoch                        59
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:03:18.926576 UTC | [2020_01_10_11_29_18] Iteration #59 | Epoch Duration: 96.20907282829285
2020-01-10 13:03:18.926855 UTC | [2020_01_10_11_29_18] Iteration #59 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.5929028
Z variance train             0.016899297
KL Divergence                14.980248
KL Loss                      1.4980248
QF Loss                      182.04718
VF Loss                      17.572788
Policy Loss                  -406.82254
Q Predictions Mean           404.28174
Q Predictions Std            62.918552
Q Predictions Max            501.4495
Q Predictions Min            250.19066
V Predictions Mean           406.62045
V Predictions Std            62.26862
V Predictions Max            508.35678
V Predictions Min            241.65247
Log Pis Mean                 -2.3507845
Log Pis Std                  1.7584023
Log Pis Max                  2.243241
Log Pis Min                  -9.612405
Policy mu Mean               0.048151672
Policy mu Std                0.40585157
Policy mu Max                1.2751999
Policy mu Min                -1.2101939
Policy log std Mean          -0.79515064
Policy log std Std           0.19189641
Policy log std Max           -0.23403902
Policy log std Min           -1.6788483
Z mean eval                  0.58005446
Z variance eval              0.016357167
total_rewards                [406.22063083 201.73987207 851.40154695 504.36285028 302.46202128
 418.03687999 105.28960162 599.80406879 107.75578868 982.12024933]
total_rewards_mean           447.9193509824081
total_rewards_std            281.41137656003883
total_rewards_max            982.1202493296836
total_rewards_min            105.28960161878227
Number of train steps total  61000
Number of env steps total    307000
Number of rollouts total     0
Train Time (s)               43.10296164220199
(Previous) Eval Time (s)     30.338407229166478
Sample Time (s)              23.435429846402258
Epoch Time (s)               96.87679871777073
Total Train Time (s)         5740.062191078905
Epoch                        60
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:04:58.371894 UTC | [2020_01_10_11_29_18] Iteration #60 | Epoch Duration: 99.44484567642212
2020-01-10 13:04:58.372025 UTC | [2020_01_10_11_29_18] Iteration #60 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.5797218
Z variance train             0.016308373
KL Divergence                14.846342
KL Loss                      1.4846343
QF Loss                      328.5346
VF Loss                      241.25558
Policy Loss                  -397.2849
Q Predictions Mean           392.8349
Q Predictions Std            81.27157
Q Predictions Max            514.6347
Q Predictions Min            -7.8253
V Predictions Mean           396.3732
V Predictions Std            83.04223
V Predictions Max            518.94446
V Predictions Min            -7.7886214
Log Pis Mean                 -1.9618087
Log Pis Std                  1.9216273
Log Pis Max                  6.039285
Log Pis Min                  -6.741802
Policy mu Mean               0.027186584
Policy mu Std                0.4154254
Policy mu Max                2.3279786
Policy mu Min                -2.4865413
Policy log std Mean          -0.8356844
Policy log std Std           0.21169955
Policy log std Max           -0.2783976
Policy log std Min           -1.9750732
Z mean eval                  0.6014624
Z variance eval              0.015760347
total_rewards                [  95.66974591 1082.4862941    86.29829585  291.02242258  784.90335785
  131.22054969  754.05077328  132.33309203   79.30010209   95.9924399 ]
total_rewards_mean           353.32770732783905
total_rewards_std            354.9036235835256
total_rewards_max            1082.486294104736
total_rewards_min            79.30010208908848
Number of train steps total  62000
Number of env steps total    312000
Number of rollouts total     0
Train Time (s)               42.94120526313782
(Previous) Eval Time (s)     32.90620480990037
Sample Time (s)              22.868924585636705
Epoch Time (s)               98.7163346586749
Total Train Time (s)         5838.365169255529
Epoch                        61
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:06:36.678297 UTC | [2020_01_10_11_29_18] Iteration #61 | Epoch Duration: 98.30616497993469
2020-01-10 13:06:36.678471 UTC | [2020_01_10_11_29_18] Iteration #61 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6008831
Z variance train             0.01576023
KL Divergence                14.6926365
KL Loss                      1.4692637
QF Loss                      271.01263
VF Loss                      46.908623
Policy Loss                  -404.96924
Q Predictions Mean           401.4648
Q Predictions Std            77.14775
Q Predictions Max            524.9763
Q Predictions Min            -29.166195
V Predictions Mean           403.8092
V Predictions Std            74.28984
V Predictions Max            521.06494
V Predictions Min            0.74643
Log Pis Mean                 -2.0816064
Log Pis Std                  2.0822196
Log Pis Max                  6.02921
Log Pis Min                  -8.347513
Policy mu Mean               0.030156173
Policy mu Std                0.4134491
Policy mu Max                1.9361589
Policy mu Min                -1.7155024
Policy log std Mean          -0.8218611
Policy log std Std           0.20389816
Policy log std Max           -0.15621424
Policy log std Min           -1.8403003
Z mean eval                  0.5688719
Z variance eval              0.027302727
total_rewards                [225.00198049 146.54592484 765.34764259  53.45134409 182.07262852
 918.4916387  720.4465744  740.36621643 135.90488543 803.21630592]
total_rewards_mean           469.08451414067656
total_rewards_std            326.787721744943
total_rewards_max            918.4916386986552
total_rewards_min            53.451344088984314
Number of train steps total  63000
Number of env steps total    317000
Number of rollouts total     0
Train Time (s)               42.53090150374919
(Previous) Eval Time (s)     32.495819294359535
Sample Time (s)              23.594357614871114
Epoch Time (s)               98.62107841297984
Total Train Time (s)         5932.985029625241
Epoch                        62
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:08:11.302604 UTC | [2020_01_10_11_29_18] Iteration #62 | Epoch Duration: 94.6239550113678
2020-01-10 13:08:11.302891 UTC | [2020_01_10_11_29_18] Iteration #62 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.5743638
Z variance train             0.02728047
KL Divergence                14.039877
KL Loss                      1.4039878
QF Loss                      176.9914
VF Loss                      190.89383
Policy Loss                  -415.60062
Q Predictions Mean           410.21802
Q Predictions Std            73.07856
Q Predictions Max            529.9934
Q Predictions Min            -56.850582
V Predictions Mean           403.74744
V Predictions Std            69.747536
V Predictions Max            515.0743
V Predictions Min            -7.528557
Log Pis Mean                 -2.2752874
Log Pis Std                  1.9546854
Log Pis Max                  2.4105978
Log Pis Min                  -8.888292
Policy mu Mean               0.06949372
Policy mu Std                0.38705662
Policy mu Max                1.7359735
Policy mu Min                -1.1445259
Policy log std Mean          -0.8347619
Policy log std Std           0.20308347
Policy log std Max           -0.27104193
Policy log std Min           -1.5848504
Z mean eval                  0.57279205
Z variance eval              0.023685973
total_rewards                [ 602.42293532 1123.71223021  743.51875009  162.35819215  996.94757272
  873.98826242  446.0649271    82.24843131  287.92962927 1224.57964826]
total_rewards_mean           654.3770578850185
total_rewards_std            383.2397422397408
total_rewards_max            1224.5796482558599
total_rewards_min            82.24843131423441
Number of train steps total  64000
Number of env steps total    322000
Number of rollouts total     0
Train Time (s)               43.34284783434123
(Previous) Eval Time (s)     28.49843774130568
Sample Time (s)              22.944401539862156
Epoch Time (s)               94.78568711550906
Total Train Time (s)         6033.093393648975
Epoch                        63
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:09:51.409870 UTC | [2020_01_10_11_29_18] Iteration #63 | Epoch Duration: 100.10677933692932
2020-01-10 13:09:51.409993 UTC | [2020_01_10_11_29_18] Iteration #63 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.57360965
Z variance train             0.023702186
KL Divergence                14.099893
KL Loss                      1.4099892
QF Loss                      371.62366
VF Loss                      84.762024
Policy Loss                  -407.27917
Q Predictions Mean           403.23196
Q Predictions Std            71.4655
Q Predictions Max            525.3595
Q Predictions Min            36.128826
V Predictions Mean           401.31192
V Predictions Std            70.81796
V Predictions Max            519.62146
V Predictions Min            7.3570614
Log Pis Mean                 -2.4581003
Log Pis Std                  1.8454322
Log Pis Max                  5.5892024
Log Pis Min                  -10.059194
Policy mu Mean               0.042573605
Policy mu Std                0.37412438
Policy mu Max                1.57565
Policy mu Min                -1.5501109
Policy log std Mean          -0.8143508
Policy log std Std           0.19789843
Policy log std Max           -0.27468836
Policy log std Min           -2.0116713
Z mean eval                  0.57966644
Z variance eval              0.025350701
total_rewards                [   8.83344085  523.32719041  839.41864544  432.50036186  154.37791349
  737.65562834   55.36373349  641.92500575 1019.29692149  992.11009892]
total_rewards_mean           540.4808940040955
total_rewards_std            353.6641797119926
total_rewards_max            1019.296921494728
total_rewards_min            8.833440849258196
Number of train steps total  65000
Number of env steps total    327000
Number of rollouts total     0
Train Time (s)               43.00114608090371
(Previous) Eval Time (s)     33.81931017432362
Sample Time (s)              23.343395055737346
Epoch Time (s)               100.16385131096467
Total Train Time (s)         6131.824836018495
Epoch                        64
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:11:30.142208 UTC | [2020_01_10_11_29_18] Iteration #64 | Epoch Duration: 98.73212623596191
2020-01-10 13:11:30.142326 UTC | [2020_01_10_11_29_18] Iteration #64 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.57986224
Z variance train             0.025398862
KL Divergence                14.010954
KL Loss                      1.4010954
QF Loss                      277.07196
VF Loss                      44.91847
Policy Loss                  -413.10178
Q Predictions Mean           409.5349
Q Predictions Std            79.48281
Q Predictions Max            540.2314
Q Predictions Min            -22.850407
V Predictions Mean           409.47095
V Predictions Std            76.58962
V Predictions Max            535.33954
V Predictions Min            11.418265
Log Pis Mean                 -2.4449835
Log Pis Std                  1.9814613
Log Pis Max                  6.451814
Log Pis Min                  -8.638077
Policy mu Mean               -0.009847966
Policy mu Std                0.38847587
Policy mu Max                1.3215638
Policy mu Min                -1.3005273
Policy log std Mean          -0.7935034
Policy log std Std           0.20095445
Policy log std Max           -0.28037417
Policy log std Min           -1.4715792
Z mean eval                  0.5859649
Z variance eval              0.021039661
total_rewards                [ 305.48103133  319.88164357 1257.96959427  328.00966318 1028.89968868
  696.23382867  407.9634572  1128.95671489  642.70843923  960.05516289]
total_rewards_mean           707.6159223902984
total_rewards_std            346.0710105078806
total_rewards_max            1257.9695942669784
total_rewards_min            305.4810313293778
Number of train steps total  66000
Number of env steps total    332000
Number of rollouts total     0
Train Time (s)               43.99328665295616
(Previous) Eval Time (s)     32.38732562912628
Sample Time (s)              22.77809562534094
Epoch Time (s)               99.15870790742338
Total Train Time (s)         6234.907987962011
Epoch                        65
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:13:13.230544 UTC | [2020_01_10_11_29_18] Iteration #65 | Epoch Duration: 103.08807921409607
2020-01-10 13:13:13.230837 UTC | [2020_01_10_11_29_18] Iteration #65 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.58204424
Z variance train             0.021144789
KL Divergence                14.111057
KL Loss                      1.4111058
QF Loss                      241.5499
VF Loss                      134.31012
Policy Loss                  -417.6115
Q Predictions Mean           416.18414
Q Predictions Std            74.42266
Q Predictions Max            528.3281
Q Predictions Min            -3.2640488
V Predictions Mean           428.008
V Predictions Std            73.88251
V Predictions Max            543.4828
V Predictions Min            42.186047
Log Pis Mean                 -2.1731796
Log Pis Std                  1.9855208
Log Pis Max                  2.2802534
Log Pis Min                  -8.176304
Policy mu Mean               -0.013167553
Policy mu Std                0.3950261
Policy mu Max                1.0992972
Policy mu Min                -1.4169649
Policy log std Mean          -0.84490275
Policy log std Std           0.19649507
Policy log std Max           -0.30155092
Policy log std Min           -1.5155756
Z mean eval                  0.59492564
Z variance eval              0.019642826
total_rewards                [ 942.01216409 1332.60656552  428.12395712  104.50778654  790.29127647
 1280.3235702   240.96461913 1056.93509967  973.47308468 1164.68950165]
total_rewards_mean           831.3927625064625
total_rewards_std            410.9033829138328
total_rewards_max            1332.6065655227032
total_rewards_min            104.50778653547172
Number of train steps total  67000
Number of env steps total    337000
Number of rollouts total     0
Train Time (s)               43.71862444514409
(Previous) Eval Time (s)     36.31643964815885
Sample Time (s)              23.55932305427268
Epoch Time (s)               103.59438714757562
Total Train Time (s)         6334.935597892385
Epoch                        66
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:14:53.257690 UTC | [2020_01_10_11_29_18] Iteration #66 | Epoch Duration: 100.02665901184082
2020-01-10 13:14:53.257814 UTC | [2020_01_10_11_29_18] Iteration #66 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.59645474
Z variance train             0.01953902
KL Divergence                14.386349
KL Loss                      1.4386349
QF Loss                      504.7296
VF Loss                      71.59021
Policy Loss                  -425.0362
Q Predictions Mean           423.1362
Q Predictions Std            75.641914
Q Predictions Max            551.8368
Q Predictions Min            188.96715
V Predictions Mean           419.6756
V Predictions Std            73.31095
V Predictions Max            549.7439
V Predictions Min            255.04924
Log Pis Mean                 -2.1704082
Log Pis Std                  2.1107264
Log Pis Max                  8.789044
Log Pis Min                  -8.8819475
Policy mu Mean               0.021738373
Policy mu Std                0.41085988
Policy mu Max                1.8059696
Policy mu Min                -1.2439682
Policy log std Mean          -0.81253
Policy log std Std           0.19997206
Policy log std Max           -0.23594311
Policy log std Min           -1.5712485
Z mean eval                  0.59116185
Z variance eval              0.02297952
total_rewards                [ 136.34557585 1146.55468781   13.55521035  133.41464346   68.86290288
  283.70548566  372.68652959  401.55292851  732.00086371 1109.98166261]
total_rewards_mean           439.8660490432955
total_rewards_std            396.18114916443443
total_rewards_max            1146.5546878116786
total_rewards_min            13.555210349804018
Number of train steps total  68000
Number of env steps total    342000
Number of rollouts total     0
Train Time (s)               43.805099627934396
(Previous) Eval Time (s)     32.748474321793765
Sample Time (s)              23.071539564058185
Epoch Time (s)               99.62511351378635
Total Train Time (s)         6431.145124751143
Epoch                        67
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:16:29.468808 UTC | [2020_01_10_11_29_18] Iteration #67 | Epoch Duration: 96.21088910102844
2020-01-10 13:16:29.468981 UTC | [2020_01_10_11_29_18] Iteration #67 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.5916835
Z variance train             0.023026193
KL Divergence                14.41243
KL Loss                      1.441243
QF Loss                      283.59167
VF Loss                      72.38683
Policy Loss                  -395.38696
Q Predictions Mean           393.2837
Q Predictions Std            98.05458
Q Predictions Max            528.674
Q Predictions Min            -12.965261
V Predictions Mean           401.92133
V Predictions Std            97.307625
V Predictions Max            536.09454
V Predictions Min            2.7310872
Log Pis Mean                 -2.0248773
Log Pis Std                  1.9847263
Log Pis Max                  6.7842054
Log Pis Min                  -6.299762
Policy mu Mean               0.05203975
Policy mu Std                0.44230336
Policy mu Max                1.8490113
Policy mu Min                -2.8161798
Policy log std Mean          -0.8115776
Policy log std Std           0.21549709
Policy log std Max           -0.20362566
Policy log std Min           -1.6986232
Z mean eval                  0.59423286
Z variance eval              0.028973266
total_rewards                [1286.37236097  312.48851777 1306.43699085   98.58322557  303.86238841
  295.63975477  402.6069016    69.91389944 1058.39567739  287.93311131]
total_rewards_mean           542.2232828074686
total_rewards_std            455.92331337600524
total_rewards_max            1306.436990854906
total_rewards_min            69.9138994434655
Number of train steps total  69000
Number of env steps total    347000
Number of rollouts total     0
Train Time (s)               44.0551110683009
(Previous) Eval Time (s)     29.334000047761947
Sample Time (s)              21.230308779049665
Epoch Time (s)               94.61941989511251
Total Train Time (s)         6524.572740866803
Epoch                        68
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:18:02.898786 UTC | [2020_01_10_11_29_18] Iteration #68 | Epoch Duration: 93.42966890335083
2020-01-10 13:18:02.898951 UTC | [2020_01_10_11_29_18] Iteration #68 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.5956697
Z variance train             0.029012585
KL Divergence                14.296019
KL Loss                      1.4296019
QF Loss                      240.74472
VF Loss                      30.628023
Policy Loss                  -435.9499
Q Predictions Mean           432.89038
Q Predictions Std            81.19669
Q Predictions Max            561.6837
Q Predictions Min            42.247223
V Predictions Mean           437.62433
V Predictions Std            80.89622
V Predictions Max            561.7685
V Predictions Min            2.838206
Log Pis Mean                 -2.0035212
Log Pis Std                  2.0791588
Log Pis Max                  7.841863
Log Pis Min                  -9.255457
Policy mu Mean               0.037871256
Policy mu Std                0.4070833
Policy mu Max                2.021724
Policy mu Min                -1.6054889
Policy log std Mean          -0.8315193
Policy log std Std           0.22620144
Policy log std Max           -0.24623352
Policy log std Min           -2.3118005
Z mean eval                  0.6128573
Z variance eval              0.037983682
total_rewards                [ 515.58711247  849.8176937   181.27053324  610.21583903 1232.77013146
   43.29708311 1075.26691989  728.28847875   68.53433143   31.47610116]
total_rewards_mean           533.6524224247187
total_rewards_std            419.43784654717115
total_rewards_max            1232.770131464709
total_rewards_min            31.476101164621284
Number of train steps total  70000
Number of env steps total    352000
Number of rollouts total     0
Train Time (s)               43.678043889347464
(Previous) Eval Time (s)     28.14403477916494
Sample Time (s)              23.11412744782865
Epoch Time (s)               94.93620611634105
Total Train Time (s)         6632.0342029896565
Epoch                        69
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:19:50.361825 UTC | [2020_01_10_11_29_18] Iteration #69 | Epoch Duration: 107.46274662017822
2020-01-10 13:19:50.361997 UTC | [2020_01_10_11_29_18] Iteration #69 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6123447
Z variance train             0.037932828
KL Divergence                13.945443
KL Loss                      1.3945444
QF Loss                      677.7671
VF Loss                      125.48039
Policy Loss                  -435.36942
Q Predictions Mean           432.4017
Q Predictions Std            86.082695
Q Predictions Max            585.6209
Q Predictions Min            104.236855
V Predictions Mean           439.47012
V Predictions Std            85.69432
V Predictions Max            580.67633
V Predictions Min            177.64575
Log Pis Mean                 -2.2017002
Log Pis Std                  2.0278745
Log Pis Max                  7.830839
Log Pis Min                  -11.3144
Policy mu Mean               0.0040040608
Policy mu Std                0.41404787
Policy mu Max                1.5402534
Policy mu Min                -1.9258162
Policy log std Mean          -0.8165231
Policy log std Std           0.20757438
Policy log std Max           -0.29362857
Policy log std Min           -1.7989383
Z mean eval                  0.6130409
Z variance eval              0.024474207
total_rewards                [ 200.94646379 1085.42107889  515.71598755  392.00331104  607.63120105
  187.25833544  874.5053067   416.32288321  905.72201403  396.53749093]
total_rewards_mean           558.2064072616358
total_rewards_std            290.1971791769208
total_rewards_max            1085.421078889968
total_rewards_min            187.25833543725022
Number of train steps total  71000
Number of env steps total    357000
Number of rollouts total     0
Train Time (s)               67.803933726158
(Previous) Eval Time (s)     40.6703314781189
Sample Time (s)              26.44563412340358
Epoch Time (s)               134.91989932768047
Total Train Time (s)         6782.356265696697
Epoch                        70
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:22:20.688980 UTC | [2020_01_10_11_29_18] Iteration #70 | Epoch Duration: 150.32684993743896
2020-01-10 13:22:20.689146 UTC | [2020_01_10_11_29_18] Iteration #70 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.61378086
Z variance train             0.024365496
KL Divergence                14.701336
KL Loss                      1.4701337
QF Loss                      426.55594
VF Loss                      74.598206
Policy Loss                  -437.10583
Q Predictions Mean           434.8597
Q Predictions Std            91.838615
Q Predictions Max            566.1957
Q Predictions Min            -1.2834752
V Predictions Mean           441.0287
V Predictions Std            90.51459
V Predictions Max            567.31226
V Predictions Min            14.782962
Log Pis Mean                 -1.9940511
Log Pis Std                  2.0093615
Log Pis Max                  5.472698
Log Pis Min                  -7.211364
Policy mu Mean               0.016699445
Policy mu Std                0.40725592
Policy mu Max                1.2604915
Policy mu Min                -1.7972794
Policy log std Mean          -0.8563285
Policy log std Std           0.21885127
Policy log std Max           -0.22588903
Policy log std Min           -1.9187435
Z mean eval                  0.629358
Z variance eval              0.028294276
total_rewards                [ 544.79059018 1135.20065451 1168.95534986   17.72773648  177.05007347
  314.02688923  441.43987629  936.91907104  285.1009427  1464.1776184 ]
total_rewards_mean           648.5388802158125
total_rewards_std            466.25810188327915
total_rewards_max            1464.1776184024407
total_rewards_min            17.72773648326904
Number of train steps total  72000
Number of env steps total    362000
Number of rollouts total     0
Train Time (s)               66.46299004461616
(Previous) Eval Time (s)     56.07703510299325
Sample Time (s)              46.21889499435201
Epoch Time (s)               168.75892014196143
Total Train Time (s)         6945.806670234073
Epoch                        71
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:25:04.162347 UTC | [2020_01_10_11_29_18] Iteration #71 | Epoch Duration: 163.47303438186646
2020-01-10 13:25:04.162647 UTC | [2020_01_10_11_29_18] Iteration #71 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.63177276
Z variance train             0.028200647
KL Divergence                14.321929
KL Loss                      1.4321929
QF Loss                      315.06274
VF Loss                      100.506294
Policy Loss                  -435.252
Q Predictions Mean           432.25433
Q Predictions Std            91.968315
Q Predictions Max            551.2089
Q Predictions Min            -29.901606
V Predictions Mean           435.61615
V Predictions Std            89.09169
V Predictions Max            552.26324
V Predictions Min            -0.7957598
Log Pis Mean                 -1.95167
Log Pis Std                  2.1291053
Log Pis Max                  3.9131217
Log Pis Min                  -8.740898
Policy mu Mean               0.050710168
Policy mu Std                0.40265194
Policy mu Max                1.6568556
Policy mu Min                -1.3154417
Policy log std Mean          -0.8429736
Policy log std Std           0.227908
Policy log std Max           -0.2698601
Policy log std Min           -2.0439985
Z mean eval                  0.6067933
Z variance eval              0.022208858
total_rewards                [ 696.78756911 1300.4024137   -21.35876607 1308.13953164  142.32944959
  527.74328489  -10.01848779  133.70897783  -16.94591356 1129.44328114]
total_rewards_mean           519.0231340489543
total_rewards_std            527.9273477943043
total_rewards_max            1308.1395316353257
total_rewards_min            -21.358766071842318
Number of train steps total  73000
Number of env steps total    367000
Number of rollouts total     0
Train Time (s)               65.67941372981295
(Previous) Eval Time (s)     50.79080527694896
Sample Time (s)              39.36690910020843
Epoch Time (s)               155.83712810697034
Total Train Time (s)         7107.875673669856
Epoch                        72
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:27:46.207448 UTC | [2020_01_10_11_29_18] Iteration #72 | Epoch Duration: 162.04458498954773
2020-01-10 13:27:46.207618 UTC | [2020_01_10_11_29_18] Iteration #72 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6057848
Z variance train             0.022193385
KL Divergence                15.054388
KL Loss                      1.5054388
QF Loss                      245.82819
VF Loss                      111.379074
Policy Loss                  -449.34363
Q Predictions Mean           446.42114
Q Predictions Std            92.05405
Q Predictions Max            589.39813
Q Predictions Min            2.5957603
V Predictions Mean           447.80582
V Predictions Std            87.507416
V Predictions Max            587.0069
V Predictions Min            28.25685
Log Pis Mean                 -1.9477639
Log Pis Std                  2.0352473
Log Pis Max                  7.6074457
Log Pis Min                  -11.64328
Policy mu Mean               0.026246607
Policy mu Std                0.4212498
Policy mu Max                2.1117606
Policy mu Min                -2.1267233
Policy log std Mean          -0.83532953
Policy log std Std           0.22231826
Policy log std Max           -0.24865896
Policy log std Min           -2.2174542
Z mean eval                  0.62070847
Z variance eval              0.02248531
total_rewards                [1226.55549902  424.29953363  445.24811297 1052.82662254 1445.99393739
   76.52724113 1359.88305984  262.95011372  401.36340629   62.71124488]
total_rewards_mean           675.8358771422857
total_rewards_std            510.2765726381971
total_rewards_max            1445.9939373875802
total_rewards_min            62.711244883011034
Number of train steps total  74000
Number of env steps total    372000
Number of rollouts total     0
Train Time (s)               53.160542325116694
(Previous) Eval Time (s)     56.99796094279736
Sample Time (s)              37.39575906796381
Epoch Time (s)               147.55426233587787
Total Train Time (s)         7231.946303355508
Epoch                        73
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:29:50.278829 UTC | [2020_01_10_11_29_18] Iteration #73 | Epoch Duration: 124.07108426094055
2020-01-10 13:29:50.278963 UTC | [2020_01_10_11_29_18] Iteration #73 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6189149
Z variance train             0.022463491
KL Divergence                14.701147
KL Loss                      1.4701147
QF Loss                      427.8917
VF Loss                      49.111565
Policy Loss                  -454.77094
Q Predictions Mean           454.2705
Q Predictions Std            81.46287
Q Predictions Max            581.4234
Q Predictions Min            183.87096
V Predictions Mean           458.50043
V Predictions Std            81.47009
V Predictions Max            575.3412
V Predictions Min            196.34456
Log Pis Mean                 -1.8189898
Log Pis Std                  2.0619047
Log Pis Max                  4.3170867
Log Pis Min                  -9.560339
Policy mu Mean               0.044070695
Policy mu Std                0.4372663
Policy mu Max                1.7484031
Policy mu Min                -1.3647586
Policy log std Mean          -0.8440581
Policy log std Std           0.21111885
Policy log std Max           -0.16226256
Policy log std Min           -1.3926685
Z mean eval                  0.62310445
Z variance eval              0.026013255
total_rewards                [ 462.58207541  703.57277433   27.12837979  883.85212537   99.33678644
  333.35780591 1133.78401048 1032.57775101  550.85330688  599.16060017]
total_rewards_mean           582.6205615792765
total_rewards_std            350.9374837117444
total_rewards_max            1133.7840104785284
total_rewards_min            27.128379789889756
Number of train steps total  75000
Number of env steps total    377000
Number of rollouts total     0
Train Time (s)               44.0104573816061
(Previous) Eval Time (s)     33.51458112709224
Sample Time (s)              22.976180001627654
Epoch Time (s)               100.501218510326
Total Train Time (s)         7329.948734942358
Epoch                        74
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:31:28.285325 UTC | [2020_01_10_11_29_18] Iteration #74 | Epoch Duration: 98.00625777244568
2020-01-10 13:31:28.285453 UTC | [2020_01_10_11_29_18] Iteration #74 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.62278205
Z variance train             0.026059622
KL Divergence                14.889473
KL Loss                      1.4889473
QF Loss                      204.35596
VF Loss                      101.01685
Policy Loss                  -463.76202
Q Predictions Mean           459.35373
Q Predictions Std            93.256035
Q Predictions Max            603.70905
Q Predictions Min            19.24407
V Predictions Mean           467.46725
V Predictions Std            93.04896
V Predictions Max            606.6957
V Predictions Min            -16.79246
Log Pis Mean                 -1.9377598
Log Pis Std                  2.0290377
Log Pis Max                  6.437743
Log Pis Min                  -6.533754
Policy mu Mean               -0.004996507
Policy mu Std                0.43901563
Policy mu Max                3.4104257
Policy mu Min                -2.1561682
Policy log std Mean          -0.85161686
Policy log std Std           0.20615344
Policy log std Max           0.3140909
Policy log std Min           -2.0028765
Z mean eval                  0.61651397
Z variance eval              0.021881934
total_rewards                [1149.85502368  709.79315742  182.94195282  401.58133053  742.65475505
  305.99342562  359.36277021  298.0040891    64.96448431  318.38238504]
total_rewards_mean           453.35333737765893
total_rewards_std            305.6336968642098
total_rewards_max            1149.8550236775543
total_rewards_min            64.96448430658094
Number of train steps total  76000
Number of env steps total    382000
Number of rollouts total     0
Train Time (s)               42.49813649896532
(Previous) Eval Time (s)     31.019364875741303
Sample Time (s)              22.71134803351015
Epoch Time (s)               96.22884940821677
Total Train Time (s)         7426.512924859766
Epoch                        75
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:33:04.850050 UTC | [2020_01_10_11_29_18] Iteration #75 | Epoch Duration: 96.56450748443604
2020-01-10 13:33:04.850177 UTC | [2020_01_10_11_29_18] Iteration #75 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.615729
Z variance train             0.021822741
KL Divergence                14.6568575
KL Loss                      1.4656857
QF Loss                      1146.1324
VF Loss                      75.338326
Policy Loss                  -465.34537
Q Predictions Mean           463.31656
Q Predictions Std            88.09392
Q Predictions Max            601.6231
Q Predictions Min            116.63396
V Predictions Mean           462.49527
V Predictions Std            86.9241
V Predictions Max            592.56744
V Predictions Min            188.80782
Log Pis Mean                 -1.8517771
Log Pis Std                  2.181351
Log Pis Max                  12.64243
Log Pis Min                  -6.9775586
Policy mu Mean               0.055726662
Policy mu Std                0.41532224
Policy mu Max                2.382061
Policy mu Min                -1.8224959
Policy log std Mean          -0.8522183
Policy log std Std           0.22816381
Policy log std Max           -0.18903783
Policy log std Min           -2.274907
Z mean eval                  0.64437044
Z variance eval              0.018978998
total_rewards                [ 295.95831485  218.879413   1371.0946933   392.0779485   389.32262987
  593.68362849  310.22663637  591.93158922  421.33068766  934.74180807]
total_rewards_mean           551.9247349328127
total_rewards_std            335.38543441432427
total_rewards_max            1371.0946933019643
total_rewards_min            218.8794129961184
Number of train steps total  77000
Number of env steps total    387000
Number of rollouts total     0
Train Time (s)               43.24300457211211
(Previous) Eval Time (s)     31.354773780796677
Sample Time (s)              23.086199244949967
Epoch Time (s)               97.68397759785876
Total Train Time (s)         7524.609186269809
Epoch                        76
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:34:42.949218 UTC | [2020_01_10_11_29_18] Iteration #76 | Epoch Duration: 98.09894299507141
2020-01-10 13:34:42.949360 UTC | [2020_01_10_11_29_18] Iteration #76 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.64442
Z variance train             0.018959902
KL Divergence                14.924034
KL Loss                      1.4924034
QF Loss                      337.25995
VF Loss                      79.87321
Policy Loss                  -463.93536
Q Predictions Mean           460.15292
Q Predictions Std            93.38673
Q Predictions Max            589.5677
Q Predictions Min            -4.9769626
V Predictions Mean           468.90863
V Predictions Std            92.32091
V Predictions Max            596.56494
V Predictions Min            42.942947
Log Pis Mean                 -2.0536902
Log Pis Std                  1.9354709
Log Pis Max                  3.866448
Log Pis Min                  -7.943445
Policy mu Mean               0.052744254
Policy mu Std                0.40901297
Policy mu Max                2.174489
Policy mu Min                -1.630522
Policy log std Mean          -0.8318167
Policy log std Std           0.21653807
Policy log std Max           -0.2886209
Policy log std Min           -1.7405813
Z mean eval                  0.6215885
Z variance eval              0.017665911
total_rewards                [ 831.58225426  641.17759403  733.11751067 1160.26847573  776.23708975
 1087.62354768 1522.07927996  495.5860815   562.68151172  239.9192832 ]
total_rewards_mean           805.0272628489832
total_rewards_std            350.371899459605
total_rewards_max            1522.0792799617975
total_rewards_min            239.9192831971067
Number of train steps total  78000
Number of env steps total    392000
Number of rollouts total     0
Train Time (s)               42.14889509882778
(Previous) Eval Time (s)     31.76948329480365
Sample Time (s)              23.523120786994696
Epoch Time (s)               97.44149918062612
Total Train Time (s)         7621.089196049608
Epoch                        77
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:36:19.432424 UTC | [2020_01_10_11_29_18] Iteration #77 | Epoch Duration: 96.48295259475708
2020-01-10 13:36:19.432588 UTC | [2020_01_10_11_29_18] Iteration #77 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6222069
Z variance train             0.017685471
KL Divergence                15.091741
KL Loss                      1.5091741
QF Loss                      326.53018
VF Loss                      52.54132
Policy Loss                  -457.18616
Q Predictions Mean           453.22968
Q Predictions Std            90.23925
Q Predictions Max            595.6712
Q Predictions Min            257.28986
V Predictions Mean           455.9931
V Predictions Std            88.92913
V Predictions Max            603.88995
V Predictions Min            243.14386
Log Pis Mean                 -2.0214176
Log Pis Std                  2.238102
Log Pis Max                  8.765644
Log Pis Min                  -8.065003
Policy mu Mean               0.03377425
Policy mu Std                0.42647818
Policy mu Max                1.4331727
Policy mu Min                -1.7522452
Policy log std Mean          -0.82754236
Policy log std Std           0.23239459
Policy log std Max           -0.265078
Policy log std Min           -2.2966933
Z mean eval                  0.63026
Z variance eval              0.019103963
total_rewards                [ -31.50538901  353.5824132    74.38842969  270.13721231  435.11793191
 1260.79058439 1034.98540631  493.63462495  944.38992592  159.91417718]
total_rewards_mean           499.5435316849762
total_rewards_std            414.76725844078084
total_rewards_max            1260.7905843899093
total_rewards_min            -31.505389013495748
Number of train steps total  79000
Number of env steps total    397000
Number of rollouts total     0
Train Time (s)               43.21355907432735
(Previous) Eval Time (s)     30.81071024434641
Sample Time (s)              23.305296269711107
Epoch Time (s)               97.32956558838487
Total Train Time (s)         7718.54799768189
Epoch                        78
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:37:56.893439 UTC | [2020_01_10_11_29_18] Iteration #78 | Epoch Duration: 97.46072816848755
2020-01-10 13:37:56.893597 UTC | [2020_01_10_11_29_18] Iteration #78 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6300043
Z variance train             0.019110287
KL Divergence                14.592863
KL Loss                      1.4592863
QF Loss                      276.0558
VF Loss                      44.508743
Policy Loss                  -463.2743
Q Predictions Mean           458.8089
Q Predictions Std            99.48997
Q Predictions Max            594.0054
Q Predictions Min            49.855583
V Predictions Mean           463.30206
V Predictions Std            99.24518
V Predictions Max            596.7414
V Predictions Min            106.24548
Log Pis Mean                 -1.7827885
Log Pis Std                  2.2387757
Log Pis Max                  5.1511006
Log Pis Min                  -8.79206
Policy mu Mean               0.029932823
Policy mu Std                0.45921883
Policy mu Max                1.7523991
Policy mu Min                -1.8100537
Policy log std Mean          -0.83718175
Policy log std Std           0.21433981
Policy log std Max           -0.3005928
Policy log std Min           -1.871747
Z mean eval                  0.63231325
Z variance eval              0.021202473
total_rewards                [ 140.30086145 1576.78901515 1421.36322418  607.45632274  873.39394315
  262.34383195 1371.52223744 1431.57617758  157.22185819  110.99100079]
total_rewards_mean           795.2958472630752
total_rewards_std            580.4681096693539
total_rewards_max            1576.78901514867
total_rewards_min            110.99100078782598
Number of train steps total  80000
Number of env steps total    402000
Number of rollouts total     0
Train Time (s)               42.58951505506411
(Previous) Eval Time (s)     30.941624904982746
Sample Time (s)              22.806957378052175
Epoch Time (s)               96.33809733809903
Total Train Time (s)         7816.410459108185
Epoch                        79
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:39:34.756824 UTC | [2020_01_10_11_29_18] Iteration #79 | Epoch Duration: 97.86310148239136
2020-01-10 13:39:34.756996 UTC | [2020_01_10_11_29_18] Iteration #79 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.63336295
Z variance train             0.021262363
KL Divergence                14.545776
KL Loss                      1.4545777
QF Loss                      267.95398
VF Loss                      49.10968
Policy Loss                  -460.3869
Q Predictions Mean           457.54706
Q Predictions Std            109.59982
Q Predictions Max            628.3413
Q Predictions Min            -33.968407
V Predictions Mean           457.26352
V Predictions Std            108.20085
V Predictions Max            629.0517
V Predictions Min            -17.21726
Log Pis Mean                 -2.0701642
Log Pis Std                  2.0303712
Log Pis Max                  6.2116013
Log Pis Min                  -8.512477
Policy mu Mean               0.031528767
Policy mu Std                0.4341316
Policy mu Max                1.6750888
Policy mu Min                -2.1403265
Policy log std Mean          -0.8143364
Policy log std Std           0.20865439
Policy log std Max           0.15192133
Policy log std Min           -1.5097106
Z mean eval                  0.6347229
Z variance eval              0.025129665
total_rewards                [  17.55643037 1487.97194867  158.30281619 1565.72968435 1576.07288414
   40.88161527  279.54392138 1469.84334429 1493.63131784  520.35448019]
total_rewards_mean           860.9888442699151
total_rewards_std            671.1098775005935
total_rewards_max            1576.0728841439177
total_rewards_min            17.5564303727294
Number of train steps total  81000
Number of env steps total    407000
Number of rollouts total     0
Train Time (s)               43.082015350461006
(Previous) Eval Time (s)     32.466381603851914
Sample Time (s)              23.591391103342175
Epoch Time (s)               99.1397880576551
Total Train Time (s)         7918.543595015071
Epoch                        80
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:41:16.892128 UTC | [2020_01_10_11_29_18] Iteration #80 | Epoch Duration: 102.13493323326111
2020-01-10 13:41:16.892383 UTC | [2020_01_10_11_29_18] Iteration #80 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.62898076
Z variance train             0.025180265
KL Divergence                14.460474
KL Loss                      1.4460474
QF Loss                      316.4796
VF Loss                      154.30836
Policy Loss                  -480.16855
Q Predictions Mean           477.6521
Q Predictions Std            100.81321
Q Predictions Max            634.35266
Q Predictions Min            -28.258709
V Predictions Mean           488.8751
V Predictions Std            101.156586
V Predictions Max            637.4391
V Predictions Min            3.6933446
Log Pis Mean                 -2.1271262
Log Pis Std                  2.1056657
Log Pis Max                  6.6333685
Log Pis Min                  -9.167903
Policy mu Mean               -0.00074579474
Policy mu Std                0.41200006
Policy mu Max                1.6566901
Policy mu Min                -1.8382996
Policy log std Mean          -0.86462426
Policy log std Std           0.20136477
Policy log std Max           -0.28898242
Policy log std Min           -1.6695609
Z mean eval                  0.6263966
Z variance eval              0.019989341
total_rewards                [ 963.53673533    7.34370202  760.08436922 1398.6011913  1322.7651091
 1480.63857593    8.63925183   26.97962645    7.24631249  131.34543698]
total_rewards_mean           610.718031063972
total_rewards_std            607.6685093378914
total_rewards_max            1480.6385759281843
total_rewards_min            7.246312485293096
Number of train steps total  82000
Number of env steps total    412000
Number of rollouts total     0
Train Time (s)               42.58369593694806
(Previous) Eval Time (s)     35.4612657930702
Sample Time (s)              21.59672747598961
Epoch Time (s)               99.64168920600787
Total Train Time (s)         8010.776378764771
Epoch                        81
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:42:49.126155 UTC | [2020_01_10_11_29_18] Iteration #81 | Epoch Duration: 92.2336151599884
2020-01-10 13:42:49.126315 UTC | [2020_01_10_11_29_18] Iteration #81 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6253795
Z variance train             0.019947093
KL Divergence                14.605643
KL Loss                      1.4605644
QF Loss                      204.5582
VF Loss                      247.16225
Policy Loss                  -487.27634
Q Predictions Mean           483.36377
Q Predictions Std            109.33605
Q Predictions Max            641.7537
Q Predictions Min            -15.781571
V Predictions Mean           488.06842
V Predictions Std            103.05365
V Predictions Max            628.72144
V Predictions Min            21.721504
Log Pis Mean                 -1.8169358
Log Pis Std                  2.1259227
Log Pis Max                  9.413763
Log Pis Min                  -7.9026976
Policy mu Mean               0.053649306
Policy mu Std                0.40926602
Policy mu Max                1.2970933
Policy mu Min                -2.078401
Policy log std Mean          -0.8518275
Policy log std Std           0.22166678
Policy log std Max           -0.24156058
Policy log std Min           -2.1016834
Z mean eval                  0.63312685
Z variance eval              0.01777971
total_rewards                [1406.5291455  1292.96586492 1364.13906858  606.01031082 1323.21096698
 1357.31054952  548.30098179 1487.17016216 1238.741837    157.9902093 ]
total_rewards_mean           1078.2369096566545
total_rewards_std            437.85739922572293
total_rewards_max            1487.1701621572472
total_rewards_min            157.99020929618877
Number of train steps total  83000
Number of env steps total    417000
Number of rollouts total     0
Train Time (s)               43.35465427301824
(Previous) Eval Time (s)     28.052997598890215
Sample Time (s)              22.6401682831347
Epoch Time (s)               94.04782015504315
Total Train Time (s)         8110.516519276425
Epoch                        82
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:44:28.867927 UTC | [2020_01_10_11_29_18] Iteration #82 | Epoch Duration: 99.74147963523865
2020-01-10 13:44:28.868111 UTC | [2020_01_10_11_29_18] Iteration #82 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6335206
Z variance train             0.017800042
KL Divergence                14.973178
KL Loss                      1.4973178
QF Loss                      245.17302
VF Loss                      89.47563
Policy Loss                  -475.13437
Q Predictions Mean           473.66376
Q Predictions Std            104.60661
Q Predictions Max            621.2744
Q Predictions Min            29.16372
V Predictions Mean           480.74988
V Predictions Std            105.53701
V Predictions Max            630.81024
V Predictions Min            14.052986
Log Pis Mean                 -1.8537982
Log Pis Std                  2.2137806
Log Pis Max                  10.05102
Log Pis Min                  -9.058343
Policy mu Mean               0.005357301
Policy mu Std                0.4582336
Policy mu Max                2.094779
Policy mu Min                -2.2082014
Policy log std Mean          -0.8381555
Policy log std Std           0.20617872
Policy log std Max           -0.32432944
Policy log std Min           -1.6269612
Z mean eval                  0.6449893
Z variance eval              0.017261533
total_rewards                [1188.41419776 1021.09608213 1642.00578138  298.50243474  899.49177504
  208.60144187  404.08807853   99.65240963  784.45444811 1336.80533015]
total_rewards_mean           788.3111979340326
total_rewards_std            495.39295724498623
total_rewards_max            1642.0057813796209
total_rewards_min            99.65240962637995
Number of train steps total  84000
Number of env steps total    422000
Number of rollouts total     0
Train Time (s)               40.77425954071805
(Previous) Eval Time (s)     33.74640725972131
Sample Time (s)              23.346882388927042
Epoch Time (s)               97.8675491893664
Total Train Time (s)         8207.207103386987
Epoch                        83
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:46:05.560308 UTC | [2020_01_10_11_29_18] Iteration #83 | Epoch Duration: 96.692063331604
2020-01-10 13:46:05.560487 UTC | [2020_01_10_11_29_18] Iteration #83 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.64397424
Z variance train             0.017239083
KL Divergence                15.191987
KL Loss                      1.5191988
QF Loss                      329.48743
VF Loss                      98.46846
Policy Loss                  -501.89667
Q Predictions Mean           498.6952
Q Predictions Std            99.43548
Q Predictions Max            635.2786
Q Predictions Min            28.489317
V Predictions Mean           499.61267
V Predictions Std            100.03724
V Predictions Max            627.11774
V Predictions Min            56.14534
Log Pis Mean                 -1.5710036
Log Pis Std                  2.1941178
Log Pis Max                  8.030605
Log Pis Min                  -12.337389
Policy mu Mean               -0.0060775
Policy mu Std                0.43212402
Policy mu Max                1.6241827
Policy mu Min                -1.6846787
Policy log std Mean          -0.8904623
Policy log std Std           0.22378053
Policy log std Max           -0.34366935
Policy log std Min           -1.690977
Z mean eval                  0.64182484
Z variance eval              0.018163849
total_rewards                [1150.5818039   159.6932484   868.9863527  1340.87935771  361.89907874
 1536.15781628  764.47914716  413.34673118 1122.74411228 1621.52318959]
total_rewards_mean           934.0290837950155
total_rewards_std            481.06749243642287
total_rewards_max            1621.5231895904285
total_rewards_min            159.6932484030878
Number of train steps total  85000
Number of env steps total    427000
Number of rollouts total     0
Train Time (s)               40.972785704769194
(Previous) Eval Time (s)     32.57064818916842
Sample Time (s)              21.3036694615148
Epoch Time (s)               94.84710335545242
Total Train Time (s)         8301.526549740694
Epoch                        84
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:47:39.880321 UTC | [2020_01_10_11_29_18] Iteration #84 | Epoch Duration: 94.3196771144867
2020-01-10 13:47:39.880474 UTC | [2020_01_10_11_29_18] Iteration #84 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6420288
Z variance train             0.018269453
KL Divergence                14.860945
KL Loss                      1.4860945
QF Loss                      450.44223
VF Loss                      61.104774
Policy Loss                  -489.8345
Q Predictions Mean           483.14313
Q Predictions Std            116.34269
Q Predictions Max            633.6972
Q Predictions Min            -35.737957
V Predictions Mean           487.3374
V Predictions Std            110.456
V Predictions Max            631.6419
V Predictions Min            18.009985
Log Pis Mean                 -1.8526242
Log Pis Std                  2.1258667
Log Pis Max                  10.166487
Log Pis Min                  -8.005388
Policy mu Mean               -0.024804093
Policy mu Std                0.44432917
Policy mu Max                1.4119616
Policy mu Min                -1.7971327
Policy log std Mean          -0.8317423
Policy log std Std           0.21817695
Policy log std Max           -0.26382196
Policy log std Min           -2.3610983
Z mean eval                  0.65742624
Z variance eval              0.02428522
total_rewards                [ 182.0939439  1411.33766803   34.84818812  341.7688178   747.02791425
  129.57739132  515.97716309  173.07995787  870.61762671 1601.84875885]
total_rewards_mean           600.8177429933928
total_rewards_std            522.3176757017877
total_rewards_max            1601.8487588520034
total_rewards_min            34.84818811700326
Number of train steps total  86000
Number of env steps total    432000
Number of rollouts total     0
Train Time (s)               40.852053257171065
(Previous) Eval Time (s)     32.042981854174286
Sample Time (s)              22.79161852458492
Epoch Time (s)               95.68665363593027
Total Train Time (s)         8394.532414201647
Epoch                        85
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:49:12.889608 UTC | [2020_01_10_11_29_18] Iteration #85 | Epoch Duration: 93.00887966156006
2020-01-10 13:49:12.890031 UTC | [2020_01_10_11_29_18] Iteration #85 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6564463
Z variance train             0.02439916
KL Divergence                14.533876
KL Loss                      1.4533876
QF Loss                      470.0005
VF Loss                      79.61801
Policy Loss                  -499.6125
Q Predictions Mean           494.16022
Q Predictions Std            106.57363
Q Predictions Max            664.8808
Q Predictions Min            7.4501767
V Predictions Mean           503.18375
V Predictions Std            105.805695
V Predictions Max            666.7567
V Predictions Min            24.921877
Log Pis Mean                 -1.8378265
Log Pis Std                  2.1636918
Log Pis Max                  5.204999
Log Pis Min                  -7.8453827
Policy mu Mean               0.03025807
Policy mu Std                0.45763013
Policy mu Max                1.6058446
Policy mu Min                -1.3981051
Policy log std Mean          -0.8398669
Policy log std Std           0.22070472
Policy log std Max           -0.2597451
Policy log std Min           -2.0553613
Z mean eval                  0.65905887
Z variance eval              0.01907845
total_rewards                [ 939.72478873  554.15522603 1529.74147213 1600.32077432 1524.21538122
  353.03954202  448.29302331  531.44129699  706.25579897 1643.78890759]
total_rewards_mean           983.0976211315894
total_rewards_std            505.82626250518894
total_rewards_max            1643.7889075934208
total_rewards_min            353.0395420164858
Number of train steps total  87000
Number of env steps total    437000
Number of rollouts total     0
Train Time (s)               39.97988794464618
(Previous) Eval Time (s)     29.364957502111793
Sample Time (s)              21.600788657553494
Epoch Time (s)               90.94563410431147
Total Train Time (s)         8484.212495051324
Epoch                        86
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:50:42.570830 UTC | [2020_01_10_11_29_18] Iteration #86 | Epoch Duration: 89.68053817749023
2020-01-10 13:50:42.571086 UTC | [2020_01_10_11_29_18] Iteration #86 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6580287
Z variance train             0.019164868
KL Divergence                14.911757
KL Loss                      1.4911758
QF Loss                      263.30072
VF Loss                      32.01098
Policy Loss                  -496.85318
Q Predictions Mean           493.48502
Q Predictions Std            112.111855
Q Predictions Max            656.71844
Q Predictions Min            13.751064
V Predictions Mean           495.85162
V Predictions Std            110.58671
V Predictions Max            655.8231
V Predictions Min            -3.721145
Log Pis Mean                 -1.9376795
Log Pis Std                  2.134001
Log Pis Max                  3.2606401
Log Pis Min                  -8.042837
Policy mu Mean               0.008246104
Policy mu Std                0.46108422
Policy mu Max                2.050009
Policy mu Min                -2.044847
Policy log std Mean          -0.8062927
Policy log std Std           0.2036394
Policy log std Max           -0.25129223
Policy log std Min           -1.4852762
Z mean eval                  0.63352334
Z variance eval              0.022368511
total_rewards                [1485.48619017 1565.88081881  587.10812687  -24.36144325  353.48990176
 1584.18320444 1540.92874314  122.00108802  439.30456073 1539.90991922]
total_rewards_mean           919.3931109922227
total_rewards_std            643.3780161182992
total_rewards_max            1584.1832044435664
total_rewards_min            -24.361443246271683
Number of train steps total  88000
Number of env steps total    442000
Number of rollouts total     0
Train Time (s)               40.46066120499745
(Previous) Eval Time (s)     28.099619793705642
Sample Time (s)              22.904359695967287
Epoch Time (s)               91.46464069467038
Total Train Time (s)         8579.732861329801
Epoch                        87
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:52:18.091963 UTC | [2020_01_10_11_29_18] Iteration #87 | Epoch Duration: 95.52066135406494
2020-01-10 13:52:18.092182 UTC | [2020_01_10_11_29_18] Iteration #87 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.63331026
Z variance train             0.02246806
KL Divergence                13.991781
KL Loss                      1.3991781
QF Loss                      282.01837
VF Loss                      43.786903
Policy Loss                  -506.09064
Q Predictions Mean           503.26318
Q Predictions Std            108.9044
Q Predictions Max            654.78455
Q Predictions Min            -5.9092236
V Predictions Mean           507.21426
V Predictions Std            106.37098
V Predictions Max            654.4817
V Predictions Min            4.5879517
Log Pis Mean                 -1.5135955
Log Pis Std                  2.2360477
Log Pis Max                  7.2875767
Log Pis Min                  -8.224121
Policy mu Mean               0.010239065
Policy mu Std                0.4560098
Policy mu Max                1.7257475
Policy mu Min                -1.7826338
Policy log std Mean          -0.8922043
Policy log std Std           0.21460725
Policy log std Max           -0.32209486
Policy log std Min           -1.8625153
Z mean eval                  0.65522087
Z variance eval              0.0216513
total_rewards                [  30.08747282  -15.26419623 1232.03368216  140.74129647  831.30086127
 1444.41318636 -196.95347644 1200.64483794 1516.50999002  723.23152277]
total_rewards_mean           690.6745177146983
total_rewards_std            620.4140652023855
total_rewards_max            1516.509990015945
total_rewards_min            -196.95347644208485
Number of train steps total  89000
Number of env steps total    447000
Number of rollouts total     0
Train Time (s)               40.851805784739554
(Previous) Eval Time (s)     32.15538413403556
Sample Time (s)              23.42847726866603
Epoch Time (s)               96.43566718744114
Total Train Time (s)         8673.63756141672
Epoch                        88
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:53:51.998429 UTC | [2020_01_10_11_29_18] Iteration #88 | Epoch Duration: 93.90608954429626
2020-01-10 13:53:51.998615 UTC | [2020_01_10_11_29_18] Iteration #88 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.65310997
Z variance train             0.021606838
KL Divergence                13.9598255
KL Loss                      1.3959826
QF Loss                      291.53204
VF Loss                      102.0798
Policy Loss                  -517.5872
Q Predictions Mean           514.5214
Q Predictions Std            109.8692
Q Predictions Max            659.8662
Q Predictions Min            19.602283
V Predictions Mean           525.09283
V Predictions Std            110.03794
V Predictions Max            663.3272
V Predictions Min            24.27931
Log Pis Mean                 -1.9633074
Log Pis Std                  1.9148841
Log Pis Max                  3.5501196
Log Pis Min                  -8.381304
Policy mu Mean               0.012101991
Policy mu Std                0.4500457
Policy mu Max                1.4912008
Policy mu Min                -1.3745192
Policy log std Mean          -0.82756674
Policy log std Std           0.20526136
Policy log std Max           -0.20600529
Policy log std Min           -1.6812928
Z mean eval                  0.65032554
Z variance eval              0.016947847
total_rewards                [ 851.89979201 1617.96535468  218.83848457 1044.00755371 1623.40781781
  592.00885425  163.97595811   60.7718173   696.55967854 1538.63428157]
total_rewards_mean           840.8069592544147
total_rewards_std            572.793450123352
total_rewards_max            1623.407817812
total_rewards_min            60.77181729551985
Number of train steps total  90000
Number of env steps total    452000
Number of rollouts total     0
Train Time (s)               40.884676943998784
(Previous) Eval Time (s)     29.62551446305588
Sample Time (s)              23.139561308547854
Epoch Time (s)               93.64975271560252
Total Train Time (s)         8763.582585542463
Epoch                        89
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:55:21.946632 UTC | [2020_01_10_11_29_18] Iteration #89 | Epoch Duration: 89.94787621498108
2020-01-10 13:55:21.946804 UTC | [2020_01_10_11_29_18] Iteration #89 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6496197
Z variance train             0.01698213
KL Divergence                14.572191
KL Loss                      1.4572191
QF Loss                      539.15375
VF Loss                      96.39346
Policy Loss                  -508.36417
Q Predictions Mean           503.83765
Q Predictions Std            119.04292
Q Predictions Max            642.774
Q Predictions Min            1.8913151
V Predictions Mean           509.7566
V Predictions Std            120.6774
V Predictions Max            647.87634
V Predictions Min            2.6052077
Log Pis Mean                 -1.7195783
Log Pis Std                  2.3098562
Log Pis Max                  12.036615
Log Pis Min                  -10.473415
Policy mu Mean               -0.0034484467
Policy mu Std                0.45075762
Policy mu Max                2.970304
Policy mu Min                -2.1475482
Policy log std Mean          -0.88829195
Policy log std Std           0.22514293
Policy log std Max           -0.20932549
Policy log std Min           -1.971005
Z mean eval                  0.6397614
Z variance eval              0.01808599
total_rewards                [1413.0309975  1159.52772754 1310.47242177 1435.86134303  124.77673643
 1574.73453884 1444.15515659  543.34112654  289.20691159 1514.64096417]
total_rewards_mean           1080.9747923996233
total_rewards_std            518.5625886382217
total_rewards_max            1574.7345388425454
total_rewards_min            124.77673642613865
Number of train steps total  91000
Number of env steps total    457000
Number of rollouts total     0
Train Time (s)               40.57009584689513
(Previous) Eval Time (s)     25.92336608376354
Sample Time (s)              22.82626319862902
Epoch Time (s)               89.31972512928769
Total Train Time (s)         8859.823576889932
Epoch                        90
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:56:58.189708 UTC | [2020_01_10_11_29_18] Iteration #90 | Epoch Duration: 96.2427728176117
2020-01-10 13:56:58.189873 UTC | [2020_01_10_11_29_18] Iteration #90 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6401002
Z variance train             0.018062234
KL Divergence                14.44018
KL Loss                      1.444018
QF Loss                      253.82632
VF Loss                      102.24168
Policy Loss                  -505.32367
Q Predictions Mean           503.74936
Q Predictions Std            114.6258
Q Predictions Max            656.8042
Q Predictions Min            43.69146
V Predictions Mean           510.80325
V Predictions Std            113.99982
V Predictions Max            658.4505
V Predictions Min            118.67149
Log Pis Mean                 -1.8187534
Log Pis Std                  2.062505
Log Pis Max                  6.65267
Log Pis Min                  -6.289151
Policy mu Mean               0.011438839
Policy mu Std                0.45137802
Policy mu Max                1.6190861
Policy mu Min                -1.6130184
Policy log std Mean          -0.8423904
Policy log std Std           0.22984189
Policy log std Max           -0.15126112
Policy log std Min           -2.0256228
Z mean eval                  0.74644154
Z variance eval              0.013153687
total_rewards                [1605.9141777    34.04843531 1360.52384131 1076.84830392 1105.34388355
  410.52170058 1570.71330538  437.94075679  215.51624771   30.00929973]
total_rewards_mean           784.7379951991308
total_rewards_std            594.0709718743096
total_rewards_max            1605.9141776984295
total_rewards_min            30.009299732675483
Number of train steps total  92000
Number of env steps total    462000
Number of rollouts total     0
Train Time (s)               40.45806939806789
(Previous) Eval Time (s)     32.84614791627973
Sample Time (s)              22.924016903154552
Epoch Time (s)               96.22823421750218
Total Train Time (s)         8952.233506293502
Epoch                        91
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:58:30.601113 UTC | [2020_01_10_11_29_18] Iteration #91 | Epoch Duration: 92.4110963344574
2020-01-10 13:58:30.601289 UTC | [2020_01_10_11_29_18] Iteration #91 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7504572
Z variance train             0.013163352
KL Divergence                15.250284
KL Loss                      1.5250285
QF Loss                      646.57635
VF Loss                      110.761
Policy Loss                  -528.8777
Q Predictions Mean           526.4625
Q Predictions Std            115.82447
Q Predictions Max            709.1673
Q Predictions Min            23.95631
V Predictions Mean           521.227
V Predictions Std            113.38466
V Predictions Max            698.4364
V Predictions Min            53.617672
Log Pis Mean                 -1.6776809
Log Pis Std                  2.290474
Log Pis Max                  7.155173
Log Pis Min                  -8.146554
Policy mu Mean               0.043137953
Policy mu Std                0.45447195
Policy mu Max                1.7877793
Policy mu Min                -1.8176169
Policy log std Mean          -0.8676375
Policy log std Std           0.22235659
Policy log std Max           -0.26812857
Policy log std Min           -2.1118813
Z mean eval                  0.73735654
Z variance eval              0.0060748965
total_rewards                [1239.66849864  371.20657695 1589.66353471  473.64985788  123.5605672
 1550.99711164  745.69231717   99.18992191  442.1525731   736.36529231]
total_rewards_mean           737.214625151041
total_rewards_std            521.1122991816778
total_rewards_max            1589.6635347061258
total_rewards_min            99.18992190858607
Number of train steps total  93000
Number of env steps total    467000
Number of rollouts total     0
Train Time (s)               39.94973402842879
(Previous) Eval Time (s)     29.028707265853882
Sample Time (s)              21.2944003213197
Epoch Time (s)               90.27284161560237
Total Train Time (s)         9040.497627879027
Epoch                        92
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:59:58.866968 UTC | [2020_01_10_11_29_18] Iteration #92 | Epoch Duration: 88.26554107666016
2020-01-10 13:59:58.867128 UTC | [2020_01_10_11_29_18] Iteration #92 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7388698
Z variance train             0.0060660364
KL Divergence                17.355162
KL Loss                      1.7355162
QF Loss                      272.11707
VF Loss                      86.41403
Policy Loss                  -539.3107
Q Predictions Mean           534.9311
Q Predictions Std            124.117516
Q Predictions Max            692.9966
Q Predictions Min            3.1426823
V Predictions Mean           532.05725
V Predictions Std            123.78052
V Predictions Max            690.3814
V Predictions Min            -37.04696
Log Pis Mean                 -1.733794
Log Pis Std                  2.12447
Log Pis Max                  10.561098
Log Pis Min                  -6.821438
Policy mu Mean               0.03747265
Policy mu Std                0.4776889
Policy mu Max                3.6594768
Policy mu Min                -2.4646056
Policy log std Mean          -0.82473475
Policy log std Std           0.21550208
Policy log std Max           0.5129367
Policy log std Min           -1.4200304
Z mean eval                  0.7076874
Z variance eval              0.005807697
total_rewards                [ 283.62318178  -22.93215475 1451.77256311  227.03689407 -250.35458248
  274.72883826  306.52021599  544.79780125  313.20802583  401.74812306]
total_rewards_mean           353.01489061132685
total_rewards_std            422.18190981031915
total_rewards_max            1451.7725631058483
total_rewards_min            -250.3545824823622
Number of train steps total  94000
Number of env steps total    472000
Number of rollouts total     0
Train Time (s)               40.16102484893054
(Previous) Eval Time (s)     27.021161813288927
Sample Time (s)              20.849546004086733
Epoch Time (s)               88.0317326663062
Total Train Time (s)         9134.074522971641
Epoch                        93
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:01:32.445339 UTC | [2020_01_10_11_29_18] Iteration #93 | Epoch Duration: 93.57808232307434
2020-01-10 14:01:32.445467 UTC | [2020_01_10_11_29_18] Iteration #93 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.70574796
Z variance train             0.005815188
KL Divergence                17.854965
KL Loss                      1.7854966
QF Loss                      264.9276
VF Loss                      33.78529
Policy Loss                  -546.0996
Q Predictions Mean           543.6065
Q Predictions Std            110.44672
Q Predictions Max            689.9713
Q Predictions Min            285.58676
V Predictions Mean           545.84906
V Predictions Std            109.94969
V Predictions Max            697.1014
V Predictions Min            284.4102
Log Pis Mean                 -1.8548126
Log Pis Std                  2.1880372
Log Pis Max                  3.9787698
Log Pis Min                  -9.633879
Policy mu Mean               0.060252495
Policy mu Std                0.4807392
Policy mu Max                1.7178538
Policy mu Min                -1.5027484
Policy log std Mean          -0.83826554
Policy log std Std           0.21512672
Policy log std Max           -0.28452516
Policy log std Min           -1.6285398
Z mean eval                  0.7050174
Z variance eval              0.004565054
total_rewards                [1538.74659481 1422.11163905 1457.70232317 1479.0429736  1648.95412943
  194.569828   1569.04257355 1605.80174407 1600.47447084 1157.72321254]
total_rewards_mean           1367.4169489054566
total_rewards_std            412.7418324572845
total_rewards_max            1648.9541294333117
total_rewards_min            194.5698280011943
Number of train steps total  95000
Number of env steps total    477000
Number of rollouts total     0
Train Time (s)               40.42998556699604
(Previous) Eval Time (s)     32.567249432671815
Sample Time (s)              21.406754878349602
Epoch Time (s)               94.40398987801746
Total Train Time (s)         9232.186077317223
Epoch                        94
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:03:10.557872 UTC | [2020_01_10_11_29_18] Iteration #94 | Epoch Duration: 98.1123149394989
2020-01-10 14:03:10.557993 UTC | [2020_01_10_11_29_18] Iteration #94 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7094008
Z variance train             0.0045657963
KL Divergence                18.723604
KL Loss                      1.8723605
QF Loss                      604.6947
VF Loss                      141.55168
Policy Loss                  -537.80835
Q Predictions Mean           532.3574
Q Predictions Std            129.4727
Q Predictions Max            711.51544
Q Predictions Min            -53.829334
V Predictions Mean           530.93286
V Predictions Std            123.257256
V Predictions Max            705.35455
V Predictions Min            38.338577
Log Pis Mean                 -1.7229643
Log Pis Std                  2.4354687
Log Pis Max                  14.32592
Log Pis Min                  -7.1700754
Policy mu Mean               0.011747176
Policy mu Std                0.4835939
Policy mu Max                1.7152851
Policy mu Min                -1.9649825
Policy log std Mean          -0.8390488
Policy log std Std           0.23794654
Policy log std Max           -0.26528177
Policy log std Min           -2.3739755
Z mean eval                  0.78110635
Z variance eval              0.004360178
total_rewards                [ 817.48902756 1499.81262441  554.01786474  190.81663163 1062.14378836
 1576.21268666  -20.87318131 1606.36860071 1332.70806105 1377.37320742]
total_rewards_mean           999.6069311217373
total_rewards_std            559.9689449132369
total_rewards_max            1606.3686007076212
total_rewards_min            -20.873181305108414
Number of train steps total  96000
Number of env steps total    482000
Number of rollouts total     0
Train Time (s)               40.01870694477111
(Previous) Eval Time (s)     36.2753436062485
Sample Time (s)              22.87555895652622
Epoch Time (s)               99.16960950754583
Total Train Time (s)         9327.652147928718
Epoch                        95
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:04:46.026790 UTC | [2020_01_10_11_29_18] Iteration #95 | Epoch Duration: 95.46869850158691
2020-01-10 14:04:46.026932 UTC | [2020_01_10_11_29_18] Iteration #95 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7789402
Z variance train             0.0043538543
KL Divergence                18.90358
KL Loss                      1.890358
QF Loss                      220.922
VF Loss                      32.180176
Policy Loss                  -541.38965
Q Predictions Mean           539.42737
Q Predictions Std            116.08724
Q Predictions Max            690.65875
Q Predictions Min            291.80106
V Predictions Mean           541.1295
V Predictions Std            115.723656
V Predictions Max            691.995
V Predictions Min            287.93805
Log Pis Mean                 -1.7105305
Log Pis Std                  2.1032896
Log Pis Max                  4.0272045
Log Pis Min                  -9.055194
Policy mu Mean               0.021783479
Policy mu Std                0.4512863
Policy mu Max                1.5164558
Policy mu Min                -1.5130942
Policy log std Mean          -0.8507167
Policy log std Std           0.22164632
Policy log std Max           -0.16254252
Policy log std Min           -1.5398817
Z mean eval                  0.73872566
Z variance eval              0.009214339
total_rewards                [ 760.58249472  431.66578883 1565.48711399  653.50129787  994.94787933
 1549.30002572  985.65902949 1494.02909489  806.88786826  637.67367028]
total_rewards_mean           987.9734263364666
total_rewards_std            391.57557076450206
total_rewards_max            1565.4871139865293
total_rewards_min            431.66578882721547
Number of train steps total  97000
Number of env steps total    487000
Number of rollouts total     0
Train Time (s)               40.237495268229395
(Previous) Eval Time (s)     32.574203761294484
Sample Time (s)              23.14245184091851
Epoch Time (s)               95.95415087044239
Total Train Time (s)         9426.711796995252
Epoch                        96
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:06:25.091581 UTC | [2020_01_10_11_29_18] Iteration #96 | Epoch Duration: 99.0645124912262
2020-01-10 14:06:25.091779 UTC | [2020_01_10_11_29_18] Iteration #96 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7402082
Z variance train             0.009250521
KL Divergence                16.408413
KL Loss                      1.6408414
QF Loss                      259.58304
VF Loss                      44.971058
Policy Loss                  -545.06775
Q Predictions Mean           541.00256
Q Predictions Std            115.95002
Q Predictions Max            683.2146
Q Predictions Min            287.88272
V Predictions Mean           543.3899
V Predictions Std            115.35752
V Predictions Max            686.4435
V Predictions Min            282.0591
Log Pis Mean                 -1.6144602
Log Pis Std                  2.060894
Log Pis Max                  3.9812427
Log Pis Min                  -7.3571196
Policy mu Mean               0.034587815
Policy mu Std                0.4751699
Policy mu Max                2.193103
Policy mu Min                -1.8486878
Policy log std Mean          -0.8257147
Policy log std Std           0.21398419
Policy log std Max           -0.25848284
Policy log std Min           -1.3922036
Z mean eval                  0.7279135
Z variance eval              0.01130311
total_rewards                [1439.88853993 1432.53117369 1631.70881586 1648.98649223  641.36387669
 1392.8013262  1547.42851552 1462.26563625 1508.66117104 1481.7666994 ]
total_rewards_mean           1418.7402246801662
total_rewards_std            271.01779825213464
total_rewards_max            1648.986492227854
total_rewards_min            641.3638766882356
Number of train steps total  98000
Number of env steps total    492000
Number of rollouts total     0
Train Time (s)               39.74007516587153
(Previous) Eval Time (s)     35.68428791407496
Sample Time (s)              21.88622611761093
Epoch Time (s)               97.31058919755742
Total Train Time (s)         9522.886345045175
Epoch                        97
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:08:01.266341 UTC | [2020_01_10_11_29_18] Iteration #97 | Epoch Duration: 96.17429208755493
2020-01-10 14:08:01.266712 UTC | [2020_01_10_11_29_18] Iteration #97 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7268267
Z variance train             0.011262707
KL Divergence                15.916903
KL Loss                      1.5916903
QF Loss                      324.1604
VF Loss                      43.83455
Policy Loss                  -541.7519
Q Predictions Mean           539.1195
Q Predictions Std            124.975494
Q Predictions Max            708.27234
Q Predictions Min            -23.966316
V Predictions Mean           539.46533
V Predictions Std            122.85727
V Predictions Max            694.90894
V Predictions Min            -0.013401538
Log Pis Mean                 -1.4926183
Log Pis Std                  2.0946333
Log Pis Max                  7.093766
Log Pis Min                  -9.034843
Policy mu Mean               0.036292933
Policy mu Std                0.47675556
Policy mu Max                3.6006398
Policy mu Min                -1.5933297
Policy log std Mean          -0.8448026
Policy log std Std           0.21004026
Policy log std Max           -0.2703703
Policy log std Min           -1.3951671
Z mean eval                  0.70076317
Z variance eval              0.0076682093
total_rewards                [  91.65630613  284.18395728 1363.69026435  330.82113582 1593.99603067
  326.81411245  488.01559167 1619.22137227 1131.00560781  123.9049728 ]
total_rewards_mean           735.330935124269
total_rewards_std            587.6506893302204
total_rewards_max            1619.2213722736776
total_rewards_min            91.65630613280777
Number of train steps total  99000
Number of env steps total    497000
Number of rollouts total     0
Train Time (s)               39.89172417577356
(Previous) Eval Time (s)     34.5477062901482
Sample Time (s)              21.167602301109582
Epoch Time (s)               95.60703276703134
Total Train Time (s)         9612.10276089469
Epoch                        98
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:09:30.483913 UTC | [2020_01_10_11_29_18] Iteration #98 | Epoch Duration: 89.2169759273529
2020-01-10 14:09:30.484143 UTC | [2020_01_10_11_29_18] Iteration #98 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7049828
Z variance train             0.007617727
KL Divergence                16.605568
KL Loss                      1.6605568
QF Loss                      385.3203
VF Loss                      128.0872
Policy Loss                  -559.16693
Q Predictions Mean           552.8628
Q Predictions Std            125.90469
Q Predictions Max            711.80914
Q Predictions Min            -34.840908
V Predictions Mean           551.6521
V Predictions Std            121.876335
V Predictions Max            701.7481
V Predictions Min            16.642485
Log Pis Mean                 -1.54157
Log Pis Std                  2.1390426
Log Pis Max                  6.284277
Log Pis Min                  -8.665442
Policy mu Mean               0.037549283
Policy mu Std                0.46796444
Policy mu Max                1.4667453
Policy mu Min                -2.842464
Policy log std Mean          -0.8468545
Policy log std Std           0.21875198
Policy log std Max           0.102944374
Policy log std Min           -1.6238728
Z mean eval                  0.72381914
Z variance eval              0.00873167
total_rewards                [1055.10966542  252.69028234 1710.48725431  278.90936082   24.30596807
 1541.35332202  330.35081981 1456.75776111  567.30988073  619.82914157]
total_rewards_mean           783.7103456205548
total_rewards_std            578.9914639122743
total_rewards_max            1710.4872543113256
total_rewards_min            24.30596807469081
Number of train steps total  100000
Number of env steps total    502000
Number of rollouts total     0
Train Time (s)               40.17326709907502
(Previous) Eval Time (s)     28.157425900921226
Sample Time (s)              23.182414560578763
Epoch Time (s)               91.51310756057501
Total Train Time (s)         9707.64043498272
Epoch                        99
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:11:06.023039 UTC | [2020_01_10_11_29_18] Iteration #99 | Epoch Duration: 95.53873085975647
2020-01-10 14:11:06.023207 UTC | [2020_01_10_11_29_18] Iteration #99 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.72349775
Z variance train             0.008729356
KL Divergence                15.909952
KL Loss                      1.5909952
QF Loss                      460.74078
VF Loss                      64.11736
Policy Loss                  -568.3376
Q Predictions Mean           567.01337
Q Predictions Std            114.15447
Q Predictions Max            698.04956
Q Predictions Min            144.11638
V Predictions Mean           568.2827
V Predictions Std            114.872635
V Predictions Max            692.5757
V Predictions Min            81.76988
Log Pis Mean                 -1.424459
Log Pis Std                  2.2109847
Log Pis Max                  6.5519958
Log Pis Min                  -7.837801
Policy mu Mean               0.043128654
Policy mu Std                0.48010713
Policy mu Max                2.0869105
Policy mu Min                -1.7854027
Policy log std Mean          -0.88083434
Policy log std Std           0.21763408
Policy log std Max           -0.27785856
Policy log std Min           -1.7708092
Z mean eval                  0.7201672
Z variance eval              0.014410539
total_rewards                [1478.36795699  357.50237793 1382.33392128 1491.14755814  152.8259988
 1557.9973269  1621.65303707  310.41550652 1219.5893262  1160.21202442]
total_rewards_mean           1073.2045034252285
total_rewards_std            542.2533261207437
total_rewards_max            1621.653037072241
total_rewards_min            152.82599879985128
Number of train steps total  101000
Number of env steps total    507000
Number of rollouts total     0
Train Time (s)               42.74610697105527
(Previous) Eval Time (s)     32.182779530994594
Sample Time (s)              20.68429449899122
Epoch Time (s)               95.61318100104108
Total Train Time (s)         9801.914069422986
Epoch                        100
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:12:40.298127 UTC | [2020_01_10_11_29_18] Iteration #100 | Epoch Duration: 94.27479791641235
2020-01-10 14:12:40.298261 UTC | [2020_01_10_11_29_18] Iteration #100 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7196412
Z variance train             0.014470369
KL Divergence                15.198587
KL Loss                      1.5198587
QF Loss                      313.2731
VF Loss                      135.36064
Policy Loss                  -545.55286
Q Predictions Mean           544.11346
Q Predictions Std            141.26392
Q Predictions Max            710.6493
Q Predictions Min            -40.864784
V Predictions Mean           541.3107
V Predictions Std            136.51778
V Predictions Max            701.06445
V Predictions Min            11.461837
Log Pis Mean                 -1.7689117
Log Pis Std                  2.2126143
Log Pis Max                  7.123205
Log Pis Min                  -9.082283
Policy mu Mean               0.050368264
Policy mu Std                0.47171322
Policy mu Max                2.472507
Policy mu Min                -2.0310152
Policy log std Mean          -0.83836496
Policy log std Std           0.23163962
Policy log std Max           -0.24887922
Policy log std Min           -1.9800593
Z mean eval                  0.7230988
Z variance eval              0.011899083
total_rewards                [1349.82512076 1635.79515972   66.1519712    37.47576575 1460.82048657
  228.63556982  -58.78192113  375.04823225  183.70877856 1246.62047183]
total_rewards_mean           652.5299635329153
total_rewards_std            645.2812851042929
total_rewards_max            1635.7951597238784
total_rewards_min            -58.78192112696847
Number of train steps total  102000
Number of env steps total    512000
Number of rollouts total     0
Train Time (s)               43.82373698661104
(Previous) Eval Time (s)     30.844221067149192
Sample Time (s)              22.50745057919994
Epoch Time (s)               97.17540863296017
Total Train Time (s)         9895.161297259387
Epoch                        101
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:14:13.550614 UTC | [2020_01_10_11_29_18] Iteration #101 | Epoch Duration: 93.25214576721191
2020-01-10 14:14:13.550906 UTC | [2020_01_10_11_29_18] Iteration #101 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7238227
Z variance train             0.011909235
KL Divergence                15.524518
KL Loss                      1.5524518
QF Loss                      428.7279
VF Loss                      78.5062
Policy Loss                  -565.3281
Q Predictions Mean           563.8137
Q Predictions Std            123.26096
Q Predictions Max            720.15466
Q Predictions Min            223.96947
V Predictions Mean           561.0316
V Predictions Std            121.54395
V Predictions Max            721.0792
V Predictions Min            256.3112
Log Pis Mean                 -1.5067232
Log Pis Std                  2.2382307
Log Pis Max                  8.010091
Log Pis Min                  -9.059547
Policy mu Mean               -0.0063362382
Policy mu Std                0.48753995
Policy mu Max                3.0938656
Policy mu Min                -1.7881396
Policy log std Mean          -0.85551775
Policy log std Std           0.22682627
Policy log std Max           -0.014714479
Policy log std Min           -2.2473576
Z mean eval                  0.71590245
Z variance eval              0.016798276
total_rewards                [1372.66176762  961.8614807  1498.91794001   24.16544808  335.52368815
  808.73318318  401.72319775 1576.85675077 1478.4792969  1542.39516368]
total_rewards_mean           1000.131791683383
total_rewards_std            550.767546970833
total_rewards_max            1576.8567507697192
total_rewards_min            24.165448084131235
Number of train steps total  103000
Number of env steps total    517000
Number of rollouts total     0
Train Time (s)               42.66108962893486
(Previous) Eval Time (s)     26.92069889092818
Sample Time (s)              22.999502456281334
Epoch Time (s)               92.58129097614437
Total Train Time (s)         9994.664021865465
Epoch                        102
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:15:53.053694 UTC | [2020_01_10_11_29_18] Iteration #102 | Epoch Duration: 99.50261068344116
2020-01-10 14:15:53.053866 UTC | [2020_01_10_11_29_18] Iteration #102 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7150184
Z variance train             0.016858216
KL Divergence                14.86123
KL Loss                      1.486123
QF Loss                      362.85992
VF Loss                      151.22253
Policy Loss                  -569.9653
Q Predictions Mean           565.9702
Q Predictions Std            125.23845
Q Predictions Max            723.6912
Q Predictions Min            48.4262
V Predictions Mean           579.2548
V Predictions Std            121.19786
V Predictions Max            749.5482
V Predictions Min            290.59296
Log Pis Mean                 -1.7208309
Log Pis Std                  2.1708162
Log Pis Max                  7.3841805
Log Pis Min                  -7.2978945
Policy mu Mean               0.046565667
Policy mu Std                0.45151982
Policy mu Max                2.288198
Policy mu Min                -1.6230769
Policy log std Mean          -0.891106
Policy log std Std           0.2276297
Policy log std Max           -0.3561622
Policy log std Min           -2.2142835
Z mean eval                  0.70808107
Z variance eval              0.012014234
total_rewards                [ 437.84233661 1090.76465486  -37.6021264  1567.213419   1551.06702197
  431.40485677  722.33500222 1534.7511006   971.23243052   63.94415166]
total_rewards_mean           833.2952847806422
total_rewards_std            575.479286350995
total_rewards_max            1567.2134189965495
total_rewards_min            -37.602126402830734
Number of train steps total  104000
Number of env steps total    522000
Number of rollouts total     0
Train Time (s)               42.99955049203709
(Previous) Eval Time (s)     33.84177710907534
Sample Time (s)              22.66352982632816
Epoch Time (s)               99.50485742744058
Total Train Time (s)         10085.370859793387
Epoch                        103
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:17:23.765731 UTC | [2020_01_10_11_29_18] Iteration #103 | Epoch Duration: 90.71169090270996
2020-01-10 14:17:23.766017 UTC | [2020_01_10_11_29_18] Iteration #103 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7087358
Z variance train             0.011952071
KL Divergence                15.517662
KL Loss                      1.5517663
QF Loss                      383.64136
VF Loss                      133.80214
Policy Loss                  -576.34875
Q Predictions Mean           574.06506
Q Predictions Std            117.83698
Q Predictions Max            711.9137
Q Predictions Min            285.92816
V Predictions Mean           575.1919
V Predictions Std            119.48296
V Predictions Max            711.2118
V Predictions Min            246.39278
Log Pis Mean                 -1.6078659
Log Pis Std                  1.9802357
Log Pis Max                  3.3164349
Log Pis Min                  -7.8917
Policy mu Mean               0.041414127
Policy mu Std                0.48166066
Policy mu Max                1.8217165
Policy mu Min                -1.8722612
Policy log std Mean          -0.8472895
Policy log std Std           0.21720077
Policy log std Max           -0.22993408
Policy log std Min           -1.8295463
Z mean eval                  0.7221006
Z variance eval              0.010836986
total_rewards                [1506.57921683 1526.09526946 1872.33336482 1186.71230947 1564.33968908
 1467.9012715   890.71286531 1593.97402992  733.73959339  650.5229003 ]
total_rewards_mean           1299.291051007193
total_rewards_std            390.9811948343046
total_rewards_max            1872.3333648206622
total_rewards_min            650.5229003010131
Number of train steps total  105000
Number of env steps total    527000
Number of rollouts total     0
Train Time (s)               43.12081890786067
(Previous) Eval Time (s)     25.04835437471047
Sample Time (s)              23.16229229187593
Epoch Time (s)               91.33146557444707
Total Train Time (s)         10184.627702345606
Epoch                        104
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:19:03.022292 UTC | [2020_01_10_11_29_18] Iteration #104 | Epoch Duration: 99.25607204437256
2020-01-10 14:19:03.022411 UTC | [2020_01_10_11_29_18] Iteration #104 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.72296757
Z variance train             0.01083975
KL Divergence                15.850416
KL Loss                      1.5850416
QF Loss                      260.17404
VF Loss                      55.121063
Policy Loss                  -574.4517
Q Predictions Mean           570.884
Q Predictions Std            124.42819
Q Predictions Max            724.6405
Q Predictions Min            248.31213
V Predictions Mean           572.0332
V Predictions Std            123.10196
V Predictions Max            714.40607
V Predictions Min            242.69702
Log Pis Mean                 -1.3415153
Log Pis Std                  2.248623
Log Pis Max                  5.9550858
Log Pis Min                  -6.870742
Policy mu Mean               0.04608527
Policy mu Std                0.4834383
Policy mu Max                1.7917262
Policy mu Min                -1.7630935
Policy log std Mean          -0.8689645
Policy log std Std           0.22415599
Policy log std Max           -0.22887781
Policy log std Min           -1.6329473
Z mean eval                  0.70874107
Z variance eval              0.008822238
total_rewards                [  -9.0779301   706.85157512 1482.51717113 1613.71726086 1672.92216619
 1114.18015262 1287.89045958  601.04189752 1653.21900306 1624.77762534]
total_rewards_mean           1174.8039381317244
total_rewards_std            541.5749049951389
total_rewards_max            1672.9221661946651
total_rewards_min            -9.07793009602855
Number of train steps total  106000
Number of env steps total    532000
Number of rollouts total     0
Train Time (s)               43.14217770611867
(Previous) Eval Time (s)     32.97273936495185
Sample Time (s)              22.91653582220897
Epoch Time (s)               99.03145289327949
Total Train Time (s)         10282.316375046037
Epoch                        105
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:20:40.715902 UTC | [2020_01_10_11_29_18] Iteration #105 | Epoch Duration: 97.69334578514099
2020-01-10 14:20:40.716216 UTC | [2020_01_10_11_29_18] Iteration #105 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7118084
Z variance train             0.008826104
KL Divergence                15.726055
KL Loss                      1.5726055
QF Loss                      314.21393
VF Loss                      55.46984
Policy Loss                  -563.8723
Q Predictions Mean           561.05945
Q Predictions Std            134.96774
Q Predictions Max            714.7667
Q Predictions Min            -6.024025
V Predictions Mean           564.9675
V Predictions Std            133.38693
V Predictions Max            736.14636
V Predictions Min            7.5113235
Log Pis Mean                 -1.6295221
Log Pis Std                  2.1998398
Log Pis Max                  6.133517
Log Pis Min                  -7.202692
Policy mu Mean               0.050221555
Policy mu Std                0.46963444
Policy mu Max                2.270911
Policy mu Min                -1.7453512
Policy log std Mean          -0.8598181
Policy log std Std           0.20942903
Policy log std Max           -0.20870888
Policy log std Min           -1.706221
Z mean eval                  0.7314334
Z variance eval              0.008670205
total_rewards                [1576.64768302  398.3117032  1542.55289989 1217.74865352  587.23568991
 1127.00606849 1632.7169662   929.54951231  700.45602778  987.39547187]
total_rewards_mean           1069.9620676169984
total_rewards_std            408.54216259031654
total_rewards_max            1632.7169661956802
total_rewards_min            398.3117031954971
Number of train steps total  107000
Number of env steps total    537000
Number of rollouts total     0
Train Time (s)               43.176010887138546
(Previous) Eval Time (s)     31.634398530703038
Sample Time (s)              23.06351043190807
Epoch Time (s)               97.87391984974965
Total Train Time (s)         10383.014198050834
Epoch                        106
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:22:21.414121 UTC | [2020_01_10_11_29_18] Iteration #106 | Epoch Duration: 100.69772100448608
2020-01-10 14:22:21.414243 UTC | [2020_01_10_11_29_18] Iteration #106 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7312553
Z variance train             0.0086153615
KL Divergence                16.283718
KL Loss                      1.6283718
QF Loss                      369.3643
VF Loss                      183.50735
Policy Loss                  -563.564
Q Predictions Mean           561.68054
Q Predictions Std            135.8968
Q Predictions Max            717.5593
Q Predictions Min            -18.65512
V Predictions Mean           570.8661
V Predictions Std            138.94429
V Predictions Max            738.94745
V Predictions Min            2.772992
Log Pis Mean                 -1.8437387
Log Pis Std                  2.157505
Log Pis Max                  6.4230356
Log Pis Min                  -8.212818
Policy mu Mean               0.021904971
Policy mu Std                0.46686238
Policy mu Max                1.7386456
Policy mu Min                -1.9683963
Policy log std Mean          -0.8684119
Policy log std Std           0.22155133
Policy log std Max           -0.32320842
Policy log std Min           -2.040278
Z mean eval                  0.736611
Z variance eval              0.013290666
total_rewards                [ -86.39106324  491.01207657  544.30216252 1625.14385969   88.26502804
 1551.56272899 1571.04860833  798.65713223 1564.50745749  259.01008433]
total_rewards_mean           840.7118074944146
total_rewards_std            644.5079224840907
total_rewards_max            1625.143859689382
total_rewards_min            -86.39106324261384
Number of train steps total  108000
Number of env steps total    542000
Number of rollouts total     0
Train Time (s)               43.35362835926935
(Previous) Eval Time (s)     34.45797206182033
Sample Time (s)              23.357950516976416
Epoch Time (s)               101.1695509380661
Total Train Time (s)         10483.772330337204
Epoch                        107
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:24:02.174755 UTC | [2020_01_10_11_29_18] Iteration #107 | Epoch Duration: 100.76040697097778
2020-01-10 14:24:02.174929 UTC | [2020_01_10_11_29_18] Iteration #107 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.73481286
Z variance train             0.013333721
KL Divergence                15.681281
KL Loss                      1.5681281
QF Loss                      464.6231
VF Loss                      57.696022
Policy Loss                  -553.3397
Q Predictions Mean           551.8796
Q Predictions Std            143.61987
Q Predictions Max            736.91364
Q Predictions Min            -37.29815
V Predictions Mean           552.45465
V Predictions Std            142.04953
V Predictions Max            735.8474
V Predictions Min            17.765741
Log Pis Mean                 -1.8295411
Log Pis Std                  2.3408012
Log Pis Max                  4.074683
Log Pis Min                  -10.292806
Policy mu Mean               0.053657897
Policy mu Std                0.47604984
Policy mu Max                1.8118731
Policy mu Min                -1.5996269
Policy log std Mean          -0.82868874
Policy log std Std           0.21959147
Policy log std Max           -0.26700634
Policy log std Min           -1.5714718
Z mean eval                  0.73344815
Z variance eval              0.017007984
total_rewards                [1497.33301796  375.52277104 -125.1820498   -14.0849026  1663.8148098
  -55.11460427 1586.21986712  205.41245325 1466.28030249 1572.63712478]
total_rewards_mean           817.2838789762393
total_rewards_std            753.1356846777015
total_rewards_max            1663.814809795384
total_rewards_min            -125.18204979737604
Number of train steps total  109000
Number of env steps total    547000
Number of rollouts total     0
Train Time (s)               43.0887638987042
(Previous) Eval Time (s)     34.04858037363738
Sample Time (s)              23.720409811474383
Epoch Time (s)               100.85775408381596
Total Train Time (s)         10585.809917271603
Epoch                        108
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:25:44.213873 UTC | [2020_01_10_11_29_18] Iteration #108 | Epoch Duration: 102.03880858421326
2020-01-10 14:25:44.214048 UTC | [2020_01_10_11_29_18] Iteration #108 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.73120093
Z variance train             0.017003877
KL Divergence                14.713523
KL Loss                      1.4713523
QF Loss                      388.65802
VF Loss                      55.486183
Policy Loss                  -585.3483
Q Predictions Mean           583.03125
Q Predictions Std            129.40836
Q Predictions Max            733.9888
Q Predictions Min            73.50822
V Predictions Mean           582.2878
V Predictions Std            128.14038
V Predictions Max            724.0417
V Predictions Min            45.947598
Log Pis Mean                 -1.4671504
Log Pis Std                  2.283944
Log Pis Max                  5.422259
Log Pis Min                  -8.555257
Policy mu Mean               0.049430717
Policy mu Std                0.49993038
Policy mu Max                2.0990937
Policy mu Min                -1.723014
Policy log std Mean          -0.8759725
Policy log std Std           0.21886787
Policy log std Max           -0.2809394
Policy log std Min           -1.52331
Z mean eval                  0.74494207
Z variance eval              0.02093267
total_rewards                [1631.44268555 1652.57901828 1562.22428964  512.77550394  403.63067414
 1709.40487583 1072.63340494  659.01602707  113.42159286  673.90812179]
total_rewards_mean           999.1036194031446
total_rewards_std            570.1639749824583
total_rewards_max            1709.4048758254705
total_rewards_min            113.42159285981688
Number of train steps total  110000
Number of env steps total    552000
Number of rollouts total     0
Train Time (s)               43.343595313839614
(Previous) Eval Time (s)     35.22939362889156
Sample Time (s)              21.37811217829585
Epoch Time (s)               99.95110112102702
Total Train Time (s)         10686.485822277144
Epoch                        109
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:27:24.890761 UTC | [2020_01_10_11_29_18] Iteration #109 | Epoch Duration: 100.676589012146
2020-01-10 14:27:24.890894 UTC | [2020_01_10_11_29_18] Iteration #109 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.74486756
Z variance train             0.021006119
KL Divergence                14.920788
KL Loss                      1.4920788
QF Loss                      469.7276
VF Loss                      439.12323
Policy Loss                  -584.5879
Q Predictions Mean           580.84106
Q Predictions Std            135.72366
Q Predictions Max            752.6098
Q Predictions Min            38.69553
V Predictions Mean           585.26404
V Predictions Std            133.50467
V Predictions Max            752.071
V Predictions Min            236.04355
Log Pis Mean                 -1.6716077
Log Pis Std                  2.3080177
Log Pis Max                  11.873856
Log Pis Min                  -8.402195
Policy mu Mean               -0.014431466
Policy mu Std                0.46235266
Policy mu Max                1.8390155
Policy mu Min                -1.6584253
Policy log std Mean          -0.8585094
Policy log std Std           0.21490432
Policy log std Max           -0.31128305
Policy log std Min           -2.0600457
Z mean eval                  0.7437587
Z variance eval              0.017316356
total_rewards                [ 752.82811155 1040.7727056   549.57071641 1820.75309884 1043.63680566
 1709.61923505 1549.98471183  735.26137282  930.32343192  854.7569783 ]
total_rewards_mean           1098.7507167976783
total_rewards_std            417.8211599555662
total_rewards_max            1820.753098841868
total_rewards_min            549.5707164062013
Number of train steps total  111000
Number of env steps total    557000
Number of rollouts total     0
Train Time (s)               43.75107138603926
(Previous) Eval Time (s)     35.95466118725017
Sample Time (s)              23.204070317093283
Epoch Time (s)               102.90980289038271
Total Train Time (s)         10782.026269860566
Epoch                        110
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:29:00.433843 UTC | [2020_01_10_11_29_18] Iteration #110 | Epoch Duration: 95.54284691810608
2020-01-10 14:29:00.434000 UTC | [2020_01_10_11_29_18] Iteration #110 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.74507797
Z variance train             0.017354202
KL Divergence                15.329685
KL Loss                      1.5329685
QF Loss                      447.80917
VF Loss                      82.55221
Policy Loss                  -570.2937
Q Predictions Mean           569.172
Q Predictions Std            149.05103
Q Predictions Max            753.35693
Q Predictions Min            -20.626183
V Predictions Mean           575.76154
V Predictions Std            149.9598
V Predictions Max            745.88025
V Predictions Min            -17.737274
Log Pis Mean                 -1.8898681
Log Pis Std                  2.023574
Log Pis Max                  3.4036896
Log Pis Min                  -8.497547
Policy mu Mean               0.05996027
Policy mu Std                0.46853516
Policy mu Max                1.6594261
Policy mu Min                -1.6274598
Policy log std Mean          -0.8273486
Policy log std Std           0.21958046
Policy log std Max           -0.16758555
Policy log std Min           -1.5388737
Z mean eval                  0.74292314
Z variance eval              0.015443775
total_rewards                [ 865.57258993 1208.24494463 1159.13354996 1731.77306965  500.22372272
 1694.95568041 1506.14035173  684.52305156 1688.42081272  101.51757369]
total_rewards_mean           1114.050534700627
total_rewards_std            534.9592624270497
total_rewards_max            1731.773069651878
total_rewards_min            101.51757369119566
Number of train steps total  112000
Number of env steps total    562000
Number of rollouts total     0
Train Time (s)               42.713416209910065
(Previous) Eval Time (s)     28.58745595207438
Sample Time (s)              22.80473550967872
Epoch Time (s)               94.10560767166317
Total Train Time (s)         10881.96510518575
Epoch                        111
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:30:40.374381 UTC | [2020_01_10_11_29_18] Iteration #111 | Epoch Duration: 99.94027185440063
2020-01-10 14:30:40.374505 UTC | [2020_01_10_11_29_18] Iteration #111 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7423456
Z variance train             0.015448727
KL Divergence                15.913206
KL Loss                      1.5913206
QF Loss                      269.17386
VF Loss                      61.437737
Policy Loss                  -592.07574
Q Predictions Mean           589.06946
Q Predictions Std            133.56
Q Predictions Max            742.39777
Q Predictions Min            -51.660797
V Predictions Mean           596.15
V Predictions Std            132.19446
V Predictions Max            743.57416
V Predictions Min            16.686289
Log Pis Mean                 -1.617134
Log Pis Std                  2.300522
Log Pis Max                  5.07383
Log Pis Min                  -10.387196
Policy mu Mean               -0.032553054
Policy mu Std                0.49530458
Policy mu Max                1.3330733
Policy mu Min                -1.7302363
Policy log std Mean          -0.84339607
Policy log std Std           0.23718353
Policy log std Max           -0.25137404
Policy log std Min           -2.0290194
Z mean eval                  0.753445
Z variance eval              0.019824106
total_rewards                [1512.39707904  761.46475139  248.25286649  348.38183318  428.57087814
 1632.96891122  755.94685154 1599.73432314  191.33060542  518.34409594]
total_rewards_mean           799.739219550548
total_rewards_std            542.2636534749967
total_rewards_max            1632.9689112233732
total_rewards_min            191.33060542088202
Number of train steps total  113000
Number of env steps total    567000
Number of rollouts total     0
Train Time (s)               43.56157868076116
(Previous) Eval Time (s)     34.42187264608219
Sample Time (s)              23.06513234321028
Epoch Time (s)               101.04858367005363
Total Train Time (s)         10972.205712876748
Epoch                        112
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:32:10.619887 UTC | [2020_01_10_11_29_18] Iteration #112 | Epoch Duration: 90.24524450302124
2020-01-10 14:32:10.620278 UTC | [2020_01_10_11_29_18] Iteration #112 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.75525105
Z variance train             0.019950986
KL Divergence                14.729054
KL Loss                      1.4729055
QF Loss                      350.1927
VF Loss                      119.19766
Policy Loss                  -578.6427
Q Predictions Mean           576.6266
Q Predictions Std            159.51054
Q Predictions Max            757.8149
Q Predictions Min            -8.138357
V Predictions Mean           584.0845
V Predictions Std            159.20744
V Predictions Max            762.5129
V Predictions Min            3.3098314
Log Pis Mean                 -1.7415566
Log Pis Std                  2.174027
Log Pis Max                  6.002428
Log Pis Min                  -7.23187
Policy mu Mean               0.04697732
Policy mu Std                0.48020074
Policy mu Max                2.439434
Policy mu Min                -1.6295363
Policy log std Mean          -0.832121
Policy log std Std           0.22798495
Policy log std Max           -0.14855298
Policy log std Min           -1.6359617
Z mean eval                  0.72065383
Z variance eval              0.016909238
total_rewards                [1428.83450278  561.45705952 1749.36528017  776.91920266  579.57266725
 1678.94317458 1446.78218253  554.04367449  479.13212415 1645.51827625]
total_rewards_mean           1090.056814438381
total_rewards_std            512.897800423832
total_rewards_max            1749.3652801701783
total_rewards_min            479.1321241493598
Number of train steps total  114000
Number of env steps total    572000
Number of rollouts total     0
Train Time (s)               42.86150715406984
(Previous) Eval Time (s)     23.61826940998435
Sample Time (s)              23.41499432362616
Epoch Time (s)               89.89477088768035
Total Train Time (s)         11071.545002839528
Epoch                        113
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:33:49.960770 UTC | [2020_01_10_11_29_18] Iteration #113 | Epoch Duration: 99.34022378921509
2020-01-10 14:33:49.961018 UTC | [2020_01_10_11_29_18] Iteration #113 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7208806
Z variance train             0.016904708
KL Divergence                15.174742
KL Loss                      1.5174742
QF Loss                      317.69513
VF Loss                      43.216896
Policy Loss                  -583.5076
Q Predictions Mean           580.3877
Q Predictions Std            143.72542
Q Predictions Max            740.5627
Q Predictions Min            19.263033
V Predictions Mean           584.31146
V Predictions Std            142.89882
V Predictions Max            734.8006
V Predictions Min            5.901879
Log Pis Mean                 -1.6015251
Log Pis Std                  2.3639627
Log Pis Max                  6.2172194
Log Pis Min                  -7.801619
Policy mu Mean               -0.0036267235
Policy mu Std                0.4945098
Policy mu Max                1.8672873
Policy mu Min                -1.6975178
Policy log std Mean          -0.85452694
Policy log std Std           0.21695955
Policy log std Max           -0.24837366
Policy log std Min           -1.7837818
Z mean eval                  0.73791397
Z variance eval              0.013225461
total_rewards                [1532.65934354 1027.94181509 1581.47284414  743.76100717 1124.28410231
 1289.54892646   31.24534652 1521.54134812 1665.38855732 1562.88082461]
total_rewards_mean           1208.0724115283797
total_rewards_std            482.1501173987421
total_rewards_max            1665.3885573194684
total_rewards_min            31.24534652447633
Number of train steps total  115000
Number of env steps total    577000
Number of rollouts total     0
Train Time (s)               43.034927886445075
(Previous) Eval Time (s)     33.06347528100014
Sample Time (s)              23.463457999750972
Epoch Time (s)               99.56186116719618
Total Train Time (s)         11169.590331806801
Epoch                        114
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:35:28.007314 UTC | [2020_01_10_11_29_18] Iteration #114 | Epoch Duration: 98.04614973068237
2020-01-10 14:35:28.007487 UTC | [2020_01_10_11_29_18] Iteration #114 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.73720956
Z variance train             0.013231071
KL Divergence                16.105806
KL Loss                      1.6105807
QF Loss                      295.8259
VF Loss                      85.56323
Policy Loss                  -602.4538
Q Predictions Mean           597.8135
Q Predictions Std            130.48108
Q Predictions Max            753.12714
Q Predictions Min            278.32162
V Predictions Mean           601.4783
V Predictions Std            130.31737
V Predictions Max            768.21497
V Predictions Min            273.7336
Log Pis Mean                 -1.3488036
Log Pis Std                  2.1049876
Log Pis Max                  6.1636915
Log Pis Min                  -7.115236
Policy mu Mean               0.041562777
Policy mu Std                0.4843697
Policy mu Max                1.8906312
Policy mu Min                -1.9456856
Policy log std Mean          -0.8654424
Policy log std Std           0.22005802
Policy log std Max           -0.29570094
Policy log std Min           -1.6948936
Z mean eval                  0.7356843
Z variance eval              0.014797802
total_rewards                [1285.81769649 1633.74725611   41.24526548  898.20936702  741.74157432
  990.83454164 1756.73556465  606.3006017  1582.93976043 1665.62561509]
total_rewards_mean           1120.3197242930662
total_rewards_std            533.4263331044963
total_rewards_max            1756.7355646535361
total_rewards_min            41.24526547774987
Number of train steps total  116000
Number of env steps total    582000
Number of rollouts total     0
Train Time (s)               43.15435454295948
(Previous) Eval Time (s)     31.547521585132927
Sample Time (s)              23.68830835726112
Epoch Time (s)               98.39018448535353
Total Train Time (s)         11270.940696311649
Epoch                        115
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:37:09.358702 UTC | [2020_01_10_11_29_18] Iteration #115 | Epoch Duration: 101.35109114646912
2020-01-10 14:37:09.358839 UTC | [2020_01_10_11_29_18] Iteration #115 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.73369086
Z variance train             0.01479953
KL Divergence                15.991344
KL Loss                      1.5991344
QF Loss                      292.4235
VF Loss                      64.923065
Policy Loss                  -606.78705
Q Predictions Mean           605.8893
Q Predictions Std            137.60081
Q Predictions Max            766.71704
Q Predictions Min            258.9111
V Predictions Mean           611.216
V Predictions Std            137.00616
V Predictions Max            772.4256
V Predictions Min            229.68002
Log Pis Mean                 -1.6040177
Log Pis Std                  2.243267
Log Pis Max                  3.9782333
Log Pis Min                  -8.829477
Policy mu Mean               0.052402046
Policy mu Std                0.49072996
Policy mu Max                2.2833061
Policy mu Min                -1.7082144
Policy log std Mean          -0.8559948
Policy log std Std           0.22365928
Policy log std Max           -0.20448118
Policy log std Min           -1.5609057
Z mean eval                  0.74544376
Z variance eval              0.016831491
total_rewards                [1621.15482278  945.98186864 1738.19470769   24.60352492 1640.57122643
 1704.15179153 1662.4446001  1304.22583456  912.73026976  -28.30246987]
total_rewards_mean           1152.5756176528553
total_rewards_std            644.5818190929269
total_rewards_max            1738.1947076852232
total_rewards_min            -28.302469874602824
Number of train steps total  117000
Number of env steps total    587000
Number of rollouts total     0
Train Time (s)               43.06171699101105
(Previous) Eval Time (s)     34.508180934004486
Sample Time (s)              22.828469144180417
Epoch Time (s)               100.39836706919596
Total Train Time (s)         11372.191686825827
Epoch                        116
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:38:50.612477 UTC | [2020_01_10_11_29_18] Iteration #116 | Epoch Duration: 101.25332355499268
2020-01-10 14:38:50.613003 UTC | [2020_01_10_11_29_18] Iteration #116 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7449122
Z variance train             0.016774792
KL Divergence                16.16322
KL Loss                      1.6163219
QF Loss                      275.891
VF Loss                      57.593052
Policy Loss                  -592.77246
Q Predictions Mean           592.67426
Q Predictions Std            145.16463
Q Predictions Max            752.86725
Q Predictions Min            45.10272
V Predictions Mean           596.2505
V Predictions Std            145.41818
V Predictions Max            758.65247
V Predictions Min            37.215
Log Pis Mean                 -1.6495061
Log Pis Std                  2.3467367
Log Pis Max                  5.6781254
Log Pis Min                  -10.280521
Policy mu Mean               0.050864525
Policy mu Std                0.4756943
Policy mu Max                2.0703282
Policy mu Min                -1.5267097
Policy log std Mean          -0.8450172
Policy log std Std           0.22590864
Policy log std Max           -0.22260016
Policy log std Min           -1.4780476
Z mean eval                  0.763873
Z variance eval              0.020251503
total_rewards                [ 532.61226971 1481.57422001 1765.01660195 1820.2824138  1818.2918231
 1863.35828115  195.86524421  227.95444614 1683.5040477  1477.89502666]
total_rewards_mean           1286.6354374433167
total_rewards_std            651.1618409652737
total_rewards_max            1863.3582811497913
total_rewards_min            195.8652442099076
Number of train steps total  118000
Number of env steps total    592000
Number of rollouts total     0
Train Time (s)               42.996034814976156
(Previous) Eval Time (s)     35.3627871950157
Sample Time (s)              22.947315203025937
Epoch Time (s)               101.30613721301779
Total Train Time (s)         11470.6353914449
Epoch                        117
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:40:29.059899 UTC | [2020_01_10_11_29_18] Iteration #117 | Epoch Duration: 98.44660377502441
2020-01-10 14:40:29.060166 UTC | [2020_01_10_11_29_18] Iteration #117 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.76332414
Z variance train             0.020314984
KL Divergence                16.225607
KL Loss                      1.6225607
QF Loss                      342.0352
VF Loss                      96.81848
Policy Loss                  -612.1839
Q Predictions Mean           609.0864
Q Predictions Std            139.80206
Q Predictions Max            781.1086
Q Predictions Min            60.701183
V Predictions Mean           611.8774
V Predictions Std            139.11424
V Predictions Max            775.157
V Predictions Min            13.841167
Log Pis Mean                 -1.4698348
Log Pis Std                  2.2734406
Log Pis Max                  7.0148478
Log Pis Min                  -7.513421
Policy mu Mean               0.042351022
Policy mu Std                0.48941645
Policy mu Max                1.664809
Policy mu Min                -2.506474
Policy log std Mean          -0.87348115
Policy log std Std           0.22230561
Policy log std Max           -0.26911223
Policy log std Min           -1.5913546
Z mean eval                  0.756131
Z variance eval              0.013099683
total_rewards                [1183.54618417 1482.11262181  542.22725914  662.13956887 1427.78873277
 1332.3980268  1487.43062312 1248.36245075  343.28693608  930.18193242]
total_rewards_mean           1063.9474335928396
total_rewards_std            397.221017909017
total_rewards_max            1487.430623116369
total_rewards_min            343.28693607891415
Number of train steps total  119000
Number of env steps total    597000
Number of rollouts total     0
Train Time (s)               43.31393530732021
(Previous) Eval Time (s)     32.50303351134062
Sample Time (s)              22.653092198073864
Epoch Time (s)               98.47006101673469
Total Train Time (s)         11572.584924715105
Epoch                        118
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:42:11.009924 UTC | [2020_01_10_11_29_18] Iteration #118 | Epoch Duration: 101.94958186149597
2020-01-10 14:42:11.010046 UTC | [2020_01_10_11_29_18] Iteration #118 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7575697
Z variance train             0.0131370975
KL Divergence                17.059734
KL Loss                      1.7059735
QF Loss                      394.0655
VF Loss                      47.4482
Policy Loss                  -599.76556
Q Predictions Mean           596.5612
Q Predictions Std            147.62585
Q Predictions Max            774.07245
Q Predictions Min            1.9879203
V Predictions Mean           599.4491
V Predictions Std            147.22145
V Predictions Max            772.1472
V Predictions Min            14.548564
Log Pis Mean                 -1.6927073
Log Pis Std                  2.2766664
Log Pis Max                  4.8214126
Log Pis Min                  -8.512228
Policy mu Mean               0.030451179
Policy mu Std                0.48331374
Policy mu Max                1.656765
Policy mu Min                -1.4527498
Policy log std Mean          -0.85347915
Policy log std Std           0.22732876
Policy log std Max           -0.27538556
Policy log std Min           -1.7542841
Z mean eval                  0.77486765
Z variance eval              0.015911508
total_rewards                [1516.63527365 1730.55717498  805.6271082    65.52173034 1564.06811804
 1542.91678755 1070.72925999 1669.0775277  1668.40339203  504.12391634]
total_rewards_mean           1213.7660288818097
total_rewards_std            548.9036463260983
total_rewards_max            1730.5571749754697
total_rewards_min            65.52173033892
Number of train steps total  120000
Number of env steps total    602000
Number of rollouts total     0
Train Time (s)               43.415803719777614
(Previous) Eval Time (s)     35.98232764797285
Sample Time (s)              23.199341758154333
Epoch Time (s)               102.5974731259048
Total Train Time (s)         11670.537650314625
Epoch                        119
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:43:48.963410 UTC | [2020_01_10_11_29_18] Iteration #119 | Epoch Duration: 97.95327472686768
2020-01-10 14:43:48.963526 UTC | [2020_01_10_11_29_18] Iteration #119 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.77521133
Z variance train             0.015806157
KL Divergence                16.57915
KL Loss                      1.657915
QF Loss                      600.3992
VF Loss                      94.21435
Policy Loss                  -607.27606
Q Predictions Mean           605.1969
Q Predictions Std            154.22968
Q Predictions Max            787.2366
Q Predictions Min            202.57434
V Predictions Mean           606.3637
V Predictions Std            152.27386
V Predictions Max            788.1886
V Predictions Min            155.53279
Log Pis Mean                 -1.3950143
Log Pis Std                  2.6446595
Log Pis Max                  8.085905
Log Pis Min                  -7.754312
Policy mu Mean               0.041415222
Policy mu Std                0.4971662
Policy mu Max                2.5118926
Policy mu Min                -2.5662618
Policy log std Mean          -0.85661685
Policy log std Std           0.23809344
Policy log std Max           -0.25125328
Policy log std Min           -1.8597648
Z mean eval                  0.77329326
Z variance eval              0.019855637
total_rewards                [1518.28394301 1677.52170875 1508.42294317   74.62532936 1787.3928967
 1768.23253425 1762.71702009 1731.10810436  463.69853098    7.76838399]
total_rewards_mean           1229.9771394652603
total_rewards_std            700.8665489073954
total_rewards_max            1787.3928966974802
total_rewards_min            7.768383994040155
Number of train steps total  121000
Number of env steps total    607000
Number of rollouts total     0
Train Time (s)               43.815263411961496
(Previous) Eval Time (s)     31.337891394272447
Sample Time (s)              24.065389443188906
Epoch Time (s)               99.21854424942285
Total Train Time (s)         11773.738202947192
Epoch                        120
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:45:32.166178 UTC | [2020_01_10_11_29_18] Iteration #120 | Epoch Duration: 103.20255398750305
2020-01-10 14:45:32.166325 UTC | [2020_01_10_11_29_18] Iteration #120 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7718232
Z variance train             0.01983634
KL Divergence                16.054554
KL Loss                      1.6054554
QF Loss                      347.39398
VF Loss                      84.602165
Policy Loss                  -615.9524
Q Predictions Mean           613.2103
Q Predictions Std            149.08908
Q Predictions Max            772.6178
Q Predictions Min            107.58456
V Predictions Mean           618.5216
V Predictions Std            150.1498
V Predictions Max            772.06744
V Predictions Min            104.05609
Log Pis Mean                 -1.6239326
Log Pis Std                  2.2155738
Log Pis Max                  5.1613755
Log Pis Min                  -8.626193
Policy mu Mean               0.03598479
Policy mu Std                0.4740664
Policy mu Max                1.7054727
Policy mu Min                -2.2603562
Policy log std Mean          -0.8379978
Policy log std Std           0.21159902
Policy log std Max           -0.2267839
Policy log std Min           -1.4770782
Z mean eval                  0.77533287
Z variance eval              0.021993367
total_rewards                [1750.16391996  417.18648196 1457.15413968 1479.2389942   402.79654981
 1681.19436749 1364.51670939  671.75418597  128.50341325 1053.40997652]
total_rewards_mean           1040.5918738239816
total_rewards_std            561.0931136431798
total_rewards_max            1750.1639199576382
total_rewards_min            128.50341325344456
Number of train steps total  122000
Number of env steps total    612000
Number of rollouts total     0
Train Time (s)               43.889697417616844
(Previous) Eval Time (s)     35.32163784187287
Sample Time (s)              21.432764990255237
Epoch Time (s)               100.64410024974495
Total Train Time (s)         11874.663384746294
Epoch                        121
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:47:13.094862 UTC | [2020_01_10_11_29_18] Iteration #121 | Epoch Duration: 100.92837262153625
2020-01-10 14:47:13.095179 UTC | [2020_01_10_11_29_18] Iteration #121 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7750109
Z variance train             0.022041548
KL Divergence                16.593983
KL Loss                      1.6593983
QF Loss                      416.42548
VF Loss                      209.4129
Policy Loss                  -610.5354
Q Predictions Mean           608.29224
Q Predictions Std            154.45212
Q Predictions Max            781.833
Q Predictions Min            191.87756
V Predictions Mean           620.65155
V Predictions Std            152.63354
V Predictions Max            783.8921
V Predictions Min            206.35059
Log Pis Mean                 -1.5001066
Log Pis Std                  2.2170486
Log Pis Max                  4.998629
Log Pis Min                  -7.414792
Policy mu Mean               -0.0076098824
Policy mu Std                0.49632233
Policy mu Max                2.5517228
Policy mu Min                -1.8826765
Policy log std Mean          -0.83602715
Policy log std Std           0.22621061
Policy log std Max           -0.27133417
Policy log std Min           -1.638969
Z mean eval                  0.78722465
Z variance eval              0.020180391
total_rewards                [1799.38159738 1724.42292226 1498.99668561 1894.72901999  681.48187283
 1942.94940507 1849.89882047 1768.40866674 1660.67338267  124.58597194]
total_rewards_mean           1494.552834494818
total_rewards_std            572.1659252366721
total_rewards_max            1942.9494050683131
total_rewards_min            124.58597194031988
Number of train steps total  123000
Number of env steps total    617000
Number of rollouts total     0
Train Time (s)               44.02703480096534
(Previous) Eval Time (s)     35.605624604038894
Sample Time (s)              23.05218641133979
Epoch Time (s)               102.68484581634402
Total Train Time (s)         11970.153979302384
Epoch                        122
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:48:48.588792 UTC | [2020_01_10_11_29_18] Iteration #122 | Epoch Duration: 95.49340510368347
2020-01-10 14:48:48.588923 UTC | [2020_01_10_11_29_18] Iteration #122 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7859717
Z variance train             0.020178352
KL Divergence                16.466528
KL Loss                      1.6466528
QF Loss                      526.5133
VF Loss                      59.76427
Policy Loss                  -631.31036
Q Predictions Mean           628.5051
Q Predictions Std            154.07391
Q Predictions Max            822.0104
Q Predictions Min            -44.41092
V Predictions Mean           627.6358
V Predictions Std            151.88463
V Predictions Max            825.0514
V Predictions Min            -12.335024
Log Pis Mean                 -1.4575232
Log Pis Std                  2.074973
Log Pis Max                  4.290898
Log Pis Min                  -6.7949843
Policy mu Mean               0.019918758
Policy mu Std                0.5035035
Policy mu Max                2.4482226
Policy mu Min                -1.6925144
Policy log std Mean          -0.85889554
Policy log std Std           0.20820412
Policy log std Max           -0.31373024
Policy log std Min           -1.6898645
Z mean eval                  0.77218366
Z variance eval              0.014672128
total_rewards                [1589.02824393 1769.3815998   475.27107973 1598.90507921 1603.19377866
 1703.7535596  1848.66228533 1584.37674751 1647.96191341 1530.35336495]
total_rewards_mean           1535.0887652104152
total_rewards_std            364.92398977572543
total_rewards_max            1848.662285326071
total_rewards_min            475.2710797261907
Number of train steps total  124000
Number of env steps total    622000
Number of rollouts total     0
Train Time (s)               43.98722589015961
(Previous) Eval Time (s)     28.413956874981523
Sample Time (s)              22.86756350658834
Epoch Time (s)               95.26874627172947
Total Train Time (s)         12072.91015974991
Epoch                        123
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:50:31.346395 UTC | [2020_01_10_11_29_18] Iteration #123 | Epoch Duration: 102.75736212730408
2020-01-10 14:50:31.346511 UTC | [2020_01_10_11_29_18] Iteration #123 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7697995
Z variance train             0.014730868
KL Divergence                16.302788
KL Loss                      1.6302788
QF Loss                      507.94327
VF Loss                      361.587
Policy Loss                  -606.9612
Q Predictions Mean           603.09937
Q Predictions Std            158.76027
Q Predictions Max            784.6287
Q Predictions Min            65.877396
V Predictions Mean           619.8568
V Predictions Std            161.44125
V Predictions Max            793.1518
V Predictions Min            57.098877
Log Pis Mean                 -1.4427795
Log Pis Std                  2.390773
Log Pis Max                  7.172097
Log Pis Min                  -7.574261
Policy mu Mean               -0.03265764
Policy mu Std                0.50674504
Policy mu Max                1.5270507
Policy mu Min                -2.088123
Policy log std Mean          -0.86660063
Policy log std Std           0.2532698
Policy log std Max           -0.25353944
Policy log std Min           -1.9379848
Z mean eval                  0.7672572
Z variance eval              0.012759577
total_rewards                [1526.76340167 1705.42915737 1640.72877481  203.96256037 1687.03152933
 1672.89088904 1612.3214885  1574.79750406 1763.78378035 1031.72040126]
total_rewards_mean           1441.9429486757604
total_rewards_std            456.14464158938637
total_rewards_max            1763.7837803490852
total_rewards_min            203.96256036963317
Number of train steps total  125000
Number of env steps total    627000
Number of rollouts total     0
Train Time (s)               43.12710523093119
(Previous) Eval Time (s)     35.90229392098263
Sample Time (s)              23.21015107538551
Epoch Time (s)               102.23955022729933
Total Train Time (s)         12175.953871748876
Epoch                        124
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:52:14.392149 UTC | [2020_01_10_11_29_18] Iteration #124 | Epoch Duration: 103.04553532600403
2020-01-10 14:52:14.392322 UTC | [2020_01_10_11_29_18] Iteration #124 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.76864177
Z variance train             0.012744556
KL Divergence                16.13146
KL Loss                      1.6131461
QF Loss                      287.85754
VF Loss                      129.21678
Policy Loss                  -612.1092
Q Predictions Mean           609.5283
Q Predictions Std            150.27481
Q Predictions Max            780.0461
Q Predictions Min            26.650885
V Predictions Mean           619.5984
V Predictions Std            151.61182
V Predictions Max            785.558
V Predictions Min            19.574278
Log Pis Mean                 -1.6453137
Log Pis Std                  2.0393116
Log Pis Max                  3.7874033
Log Pis Min                  -6.5928006
Policy mu Mean               -0.011047533
Policy mu Std                0.4610856
Policy mu Max                1.5807517
Policy mu Min                -1.6077602
Policy log std Mean          -0.86418855
Policy log std Std           0.22014011
Policy log std Max           -0.2969158
Policy log std Min           -1.5324992
Z mean eval                  0.737028
Z variance eval              0.012273548
total_rewards                [1093.72708967  661.16519318  345.49628205 1510.00163249 1617.97604971
 1532.23860856  389.34222401  764.57464126 1788.44716552 1579.08998625]
total_rewards_mean           1128.2058872698635
total_rewards_std            519.4417752410211
total_rewards_max            1788.4471655178374
total_rewards_min            345.4962820486835
Number of train steps total  126000
Number of env steps total    632000
Number of rollouts total     0
Train Time (s)               44.0878546689637
(Previous) Eval Time (s)     36.708020070102066
Sample Time (s)              22.653188148513436
Epoch Time (s)               103.4490628875792
Total Train Time (s)         12276.351994890254
Epoch                        125
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:53:54.792874 UTC | [2020_01_10_11_29_18] Iteration #125 | Epoch Duration: 100.40035629272461
2020-01-10 14:53:54.793119 UTC | [2020_01_10_11_29_18] Iteration #125 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7373489
Z variance train             0.012230719
KL Divergence                16.52647
KL Loss                      1.652647
QF Loss                      421.0511
VF Loss                      77.014114
Policy Loss                  -626.9396
Q Predictions Mean           624.34094
Q Predictions Std            149.25781
Q Predictions Max            794.74146
Q Predictions Min            57.64386
V Predictions Mean           628.762
V Predictions Std            147.64404
V Predictions Max            791.07184
V Predictions Min            38.406498
Log Pis Mean                 -1.190036
Log Pis Std                  2.2356384
Log Pis Max                  4.928773
Log Pis Min                  -8.981066
Policy mu Mean               0.022505946
Policy mu Std                0.49988908
Policy mu Max                2.3900995
Policy mu Min                -1.6930532
Policy log std Mean          -0.86937034
Policy log std Std           0.2214029
Policy log std Max           -0.2551617
Policy log std Min           -1.6157968
Z mean eval                  0.75969034
Z variance eval              0.0113333715
total_rewards                [ 386.88082524 1636.58540142 1696.33976111 1675.22994939 1602.75786533
 1374.84955871 1709.95328486 1678.87411182 1438.4070401  1706.80733197]
total_rewards_mean           1490.668512996336
total_rewards_std            384.04883105918844
total_rewards_max            1709.953284860259
total_rewards_min            386.8808252372442
Number of train steps total  127000
Number of env steps total    637000
Number of rollouts total     0
Train Time (s)               43.84755612909794
(Previous) Eval Time (s)     33.65903961006552
Sample Time (s)              23.109743917360902
Epoch Time (s)               100.61633965652436
Total Train Time (s)         12379.958161710761
Epoch                        126
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:55:38.400437 UTC | [2020_01_10_11_29_18] Iteration #126 | Epoch Duration: 103.60717129707336
2020-01-10 14:55:38.400606 UTC | [2020_01_10_11_29_18] Iteration #126 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.75771946
Z variance train             0.011377415
KL Divergence                16.356964
KL Loss                      1.6356964
QF Loss                      348.5542
VF Loss                      186.59792
Policy Loss                  -596.1159
Q Predictions Mean           594.037
Q Predictions Std            179.33574
Q Predictions Max            832.83344
Q Predictions Min            -50.052048
V Predictions Mean           598.2571
V Predictions Std            172.985
V Predictions Max            829.662
V Predictions Min            14.670619
Log Pis Mean                 -1.2612631
Log Pis Std                  2.3711262
Log Pis Max                  10.25263
Log Pis Min                  -8.073416
Policy mu Mean               0.021648182
Policy mu Std                0.5279042
Policy mu Max                2.9850094
Policy mu Min                -2.3118353
Policy log std Mean          -0.84239054
Policy log std Std           0.22828308
Policy log std Max           -0.24576303
Policy log std Min           -1.6292348
Z mean eval                  0.7603615
Z variance eval              0.008706065
total_rewards                [ 160.97985749 1055.88529676 1780.31669974  802.03362579 1568.38221114
  428.56364663 1696.39169793   98.82724678  200.45015689 1754.34392589]
total_rewards_mean           954.6174365013794
total_rewards_std            670.0412908602308
total_rewards_max            1780.316699737298
total_rewards_min            98.82724677624228
Number of train steps total  128000
Number of env steps total    642000
Number of rollouts total     0
Train Time (s)               42.97001084499061
(Previous) Eval Time (s)     36.64961908198893
Sample Time (s)              23.443272152449936
Epoch Time (s)               103.06290207942948
Total Train Time (s)         12478.859089986887
Epoch                        127
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:57:17.303375 UTC | [2020_01_10_11_29_18] Iteration #127 | Epoch Duration: 98.90263724327087
2020-01-10 14:57:17.303548 UTC | [2020_01_10_11_29_18] Iteration #127 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.76099014
Z variance train             0.008734698
KL Divergence                16.949148
KL Loss                      1.6949148
QF Loss                      458.9239
VF Loss                      150.4103
Policy Loss                  -620.8
Q Predictions Mean           618.47815
Q Predictions Std            157.0208
Q Predictions Max            783.9331
Q Predictions Min            62.037426
V Predictions Mean           615.67993
V Predictions Std            156.7266
V Predictions Max            769.3922
V Predictions Min            -0.06136504
Log Pis Mean                 -1.4551314
Log Pis Std                  2.4207137
Log Pis Max                  5.94567
Log Pis Min                  -7.393135
Policy mu Mean               -0.057769876
Policy mu Std                0.52782434
Policy mu Max                1.8105263
Policy mu Min                -2.3167353
Policy log std Mean          -0.83413446
Policy log std Std           0.22672604
Policy log std Max           -0.07326913
Policy log std Min           -1.8096647
Z mean eval                  0.7341016
Z variance eval              0.011262102
total_rewards                [ 718.77217097  801.23107998 -176.9994327   755.29754174  230.42359688
  154.06839112  875.29475672  935.08999717 1700.92902724  641.15948994]
total_rewards_mean           663.5266619050692
total_rewards_std            487.7850865658203
total_rewards_max            1700.9290272400988
total_rewards_min            -176.99943270244168
Number of train steps total  129000
Number of env steps total    647000
Number of rollouts total     0
Train Time (s)               43.1329983798787
(Previous) Eval Time (s)     32.489093905780464
Sample Time (s)              23.104489599820226
Epoch Time (s)               98.72658188547939
Total Train Time (s)         12573.287110394333
Epoch                        128
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:58:51.732960 UTC | [2020_01_10_11_29_18] Iteration #128 | Epoch Duration: 94.42928910255432
2020-01-10 14:58:51.733094 UTC | [2020_01_10_11_29_18] Iteration #128 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.73136556
Z variance train             0.011264649
KL Divergence                16.122826
KL Loss                      1.6122826
QF Loss                      1307.0237
VF Loss                      202.62892
Policy Loss                  -628.13617
Q Predictions Mean           625.5895
Q Predictions Std            148.3623
Q Predictions Max            801.29517
Q Predictions Min            231.18195
V Predictions Mean           624.5948
V Predictions Std            145.9904
V Predictions Max            800.84015
V Predictions Min            244.57368
Log Pis Mean                 -1.4068683
Log Pis Std                  2.422989
Log Pis Max                  6.622295
Log Pis Min                  -7.039358
Policy mu Mean               0.102149874
Policy mu Std                0.5110095
Policy mu Max                2.21981
Policy mu Min                -1.61148
Policy log std Mean          -0.8479008
Policy log std Std           0.225528
Policy log std Max           -0.15587208
Policy log std Min           -1.7063606
Z mean eval                  0.77191573
Z variance eval              0.019417543
total_rewards                [ 301.88697669  480.68713338 1738.26774569  119.62633396 1889.41340972
 1451.5613433  1831.84013372 1882.66034276  320.17418236   95.4211251 ]
total_rewards_mean           1011.1538726701725
total_rewards_std            763.0424527078661
total_rewards_max            1889.4134097237918
total_rewards_min            95.4211251016791
Number of train steps total  130000
Number of env steps total    652000
Number of rollouts total     0
Train Time (s)               44.76857893355191
(Previous) Eval Time (s)     28.191566559951752
Sample Time (s)              22.971279428340495
Epoch Time (s)               95.93142492184415
Total Train Time (s)         12670.45889374381
Epoch                        129
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:00:28.907022 UTC | [2020_01_10_11_29_18] Iteration #129 | Epoch Duration: 97.17378401756287
2020-01-10 15:00:28.907219 UTC | [2020_01_10_11_29_18] Iteration #129 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7719916
Z variance train             0.019319499
KL Divergence                15.424791
KL Loss                      1.5424792
QF Loss                      455.8282
VF Loss                      94.28013
Policy Loss                  -626.0468
Q Predictions Mean           623.7605
Q Predictions Std            162.75925
Q Predictions Max            802.0617
Q Predictions Min            -2.7644928
V Predictions Mean           625.14
V Predictions Std            160.51448
V Predictions Max            793.0128
V Predictions Min            -14.24527
Log Pis Mean                 -1.6658072
Log Pis Std                  2.440874
Log Pis Max                  5.8071804
Log Pis Min                  -9.05443
Policy mu Mean               0.023322579
Policy mu Std                0.48982763
Policy mu Max                2.058493
Policy mu Min                -1.7949705
Policy log std Mean          -0.8474621
Policy log std Std           0.24584228
Policy log std Max           -0.20209205
Policy log std Min           -1.9332136
Z mean eval                  0.74338543
Z variance eval              0.019752596
total_rewards                [1837.65088187 1948.78024858 1819.72601493 1802.46930623 1779.57836038
 1923.22387889 1876.35164407 1585.67644625   13.41324588  196.61592949]
total_rewards_mean           1478.3485956568804
total_rewards_std            694.2225968492303
total_rewards_max            1948.7802485847658
total_rewards_min            13.413245875143371
Number of train steps total  131000
Number of env steps total    657000
Number of rollouts total     0
Train Time (s)               43.26722761802375
(Previous) Eval Time (s)     29.43366856314242
Sample Time (s)              22.97649941686541
Epoch Time (s)               95.67739559803158
Total Train Time (s)         12769.245411787182
Epoch                        130
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:02:07.695407 UTC | [2020_01_10_11_29_18] Iteration #130 | Epoch Duration: 98.78806662559509
2020-01-10 15:02:07.695585 UTC | [2020_01_10_11_29_18] Iteration #130 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7448776
Z variance train             0.019760435
KL Divergence                14.746018
KL Loss                      1.4746019
QF Loss                      456.36322
VF Loss                      110.41292
Policy Loss                  -641.01276
Q Predictions Mean           639.3192
Q Predictions Std            149.74203
Q Predictions Max            803.8093
Q Predictions Min            247.8824
V Predictions Mean           636.1659
V Predictions Std            148.32622
V Predictions Max            797.56335
V Predictions Min            244.34422
Log Pis Mean                 -1.362885
Log Pis Std                  2.3109696
Log Pis Max                  6.60288
Log Pis Min                  -6.988961
Policy mu Mean               0.0021226555
Policy mu Std                0.51187706
Policy mu Max                1.5437436
Policy mu Min                -2.2047074
Policy log std Mean          -0.8635658
Policy log std Std           0.24269217
Policy log std Max           -0.29094207
Policy log std Min           -2.1915696
Z mean eval                  0.7704495
Z variance eval              0.026315153
total_rewards                [1309.30948274 1807.38646132 1337.28855998  164.28479215 1680.74967527
 1495.12013959 1032.55533507 1661.09574092 1672.58332633 1680.29786535]
total_rewards_mean           1384.0671378727543
total_rewards_std            463.3031501515544
total_rewards_max            1807.3864613235176
total_rewards_min            164.2847921481037
Number of train steps total  132000
Number of env steps total    662000
Number of rollouts total     0
Train Time (s)               43.90681826882064
(Previous) Eval Time (s)     32.54406750202179
Sample Time (s)              22.958880546037108
Epoch Time (s)               99.40976631687954
Total Train Time (s)         12869.914177983068
Epoch                        131
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:03:48.369108 UTC | [2020_01_10_11_29_18] Iteration #131 | Epoch Duration: 100.67335557937622
2020-01-10 15:03:48.369390 UTC | [2020_01_10_11_29_18] Iteration #131 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7711726
Z variance train             0.026331985
KL Divergence                14.402257
KL Loss                      1.4402257
QF Loss                      484.74677
VF Loss                      77.13558
Policy Loss                  -653.7649
Q Predictions Mean           651.10223
Q Predictions Std            133.16261
Q Predictions Max            818.68304
Q Predictions Min            44.22555
V Predictions Mean           649.7932
V Predictions Std            133.31447
V Predictions Max            817.231
V Predictions Min            -0.01715362
Log Pis Mean                 -1.4812787
Log Pis Std                  2.4881835
Log Pis Max                  8.042516
Log Pis Min                  -9.149496
Policy mu Mean               0.037930913
Policy mu Std                0.5112546
Policy mu Max                2.0558858
Policy mu Min                -1.785321
Policy log std Mean          -0.8828513
Policy log std Std           0.23004338
Policy log std Max           -0.2872067
Policy log std Min           -1.9881804
Z mean eval                  0.73717535
Z variance eval              0.016830498
total_rewards                [1905.06654703  584.23845971 1795.25014602  939.15387549 1824.05638413
  959.99632531 1770.86108227  761.54249048 1693.71349614 1741.03891199]
total_rewards_mean           1397.4917718572774
total_rewards_std            490.94461659426946
total_rewards_max            1905.066547029357
total_rewards_min            584.2384597125547
Number of train steps total  133000
Number of env steps total    667000
Number of rollouts total     0
Train Time (s)               44.08678412390873
(Previous) Eval Time (s)     33.807385952211916
Sample Time (s)              23.148141824174672
Epoch Time (s)               101.04231190029532
Total Train Time (s)         12973.02625373425
Epoch                        132
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:05:31.484923 UTC | [2020_01_10_11_29_18] Iteration #132 | Epoch Duration: 103.11530590057373
2020-01-10 15:05:31.485195 UTC | [2020_01_10_11_29_18] Iteration #132 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7404777
Z variance train             0.016788425
KL Divergence                15.495609
KL Loss                      1.5495609
QF Loss                      2378.585
VF Loss                      179.88358
Policy Loss                  -637.0092
Q Predictions Mean           637.42957
Q Predictions Std            145.03497
Q Predictions Max            817.6116
Q Predictions Min            202.43211
V Predictions Mean           640.0364
V Predictions Std            145.13129
V Predictions Max            814.05023
V Predictions Min            212.937
Log Pis Mean                 -1.5751286
Log Pis Std                  2.50473
Log Pis Max                  10.764341
Log Pis Min                  -9.761092
Policy mu Mean               0.019336324
Policy mu Std                0.51100534
Policy mu Max                2.544392
Policy mu Min                -2.2528083
Policy log std Mean          -0.853528
Policy log std Std           0.22674792
Policy log std Max           -0.29929835
Policy log std Min           -1.954282
Z mean eval                  0.7495144
Z variance eval              0.017165389
total_rewards                [ 696.72973471  170.95158286  559.49513438  936.86017181 1143.33701691
 1684.09458878  601.56111744 1947.58522166  321.62683767  358.9027786 ]
total_rewards_mean           842.1144184820869
total_rewards_std            560.7534872570615
total_rewards_max            1947.5852216621076
total_rewards_min            170.9515828622891
Number of train steps total  134000
Number of env steps total    672000
Number of rollouts total     0
Train Time (s)               43.09037017310038
(Previous) Eval Time (s)     35.880137139
Sample Time (s)              23.10464441915974
Epoch Time (s)               102.07515173126012
Total Train Time (s)         13071.8099699351
Epoch                        133
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:07:10.268595 UTC | [2020_01_10_11_29_18] Iteration #133 | Epoch Duration: 98.78321862220764
2020-01-10 15:07:10.268716 UTC | [2020_01_10_11_29_18] Iteration #133 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.74821913
Z variance train             0.017141147
KL Divergence                15.351263
KL Loss                      1.5351263
QF Loss                      322.45496
VF Loss                      77.291626
Policy Loss                  -639.01746
Q Predictions Mean           635.0364
Q Predictions Std            157.98277
Q Predictions Max            820.5033
Q Predictions Min            6.2083116
V Predictions Mean           634.20795
V Predictions Std            155.45653
V Predictions Max            822.32983
V Predictions Min            -12.174139
Log Pis Mean                 -1.6496637
Log Pis Std                  2.1214304
Log Pis Max                  5.011896
Log Pis Min                  -7.4129233
Policy mu Mean               0.010763695
Policy mu Std                0.4920343
Policy mu Max                1.8588157
Policy mu Min                -1.5621009
Policy log std Mean          -0.8191839
Policy log std Std           0.22333765
Policy log std Max           -0.06048727
Policy log std Min           -1.5359201
Z mean eval                  0.7506108
Z variance eval              0.017065497
total_rewards                [  81.82328935 1238.13439747 1178.90803779 1779.81663563 1254.53172847
 1950.55324694 1644.38321252 1245.53836955 1857.43946124 1762.74200025]
total_rewards_mean           1399.3870379197263
total_rewards_std            520.1550686127573
total_rewards_max            1950.5532469370933
total_rewards_min            81.82328935019339
Number of train steps total  135000
Number of env steps total    677000
Number of rollouts total     0
Train Time (s)               42.5653832978569
(Previous) Eval Time (s)     32.58796351402998
Sample Time (s)              22.702106293756515
Epoch Time (s)               97.85545310564339
Total Train Time (s)         13167.222466539126
Epoch                        134
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:08:45.682868 UTC | [2020_01_10_11_29_18] Iteration #134 | Epoch Duration: 95.41406226158142
2020-01-10 15:08:45.682991 UTC | [2020_01_10_11_29_18] Iteration #134 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7510502
Z variance train             0.017062562
KL Divergence                15.447876
KL Loss                      1.5447876
QF Loss                      469.54608
VF Loss                      76.14015
Policy Loss                  -650.1965
Q Predictions Mean           647.1639
Q Predictions Std            151.27084
Q Predictions Max            810.769
Q Predictions Min            -22.283281
V Predictions Mean           645.8312
V Predictions Std            147.76454
V Predictions Max            802.7108
V Predictions Min            43.472458
Log Pis Mean                 -1.6747394
Log Pis Std                  2.2574527
Log Pis Max                  7.40341
Log Pis Min                  -8.484825
Policy mu Mean               0.10601607
Policy mu Std                0.50009346
Policy mu Max                2.664802
Policy mu Min                -1.880445
Policy log std Mean          -0.8448889
Policy log std Std           0.2232491
Policy log std Max           -0.24433553
Policy log std Min           -1.6948905
Z mean eval                  0.79845566
Z variance eval              0.020354526
total_rewards                [1111.22386345 1809.05090511 1890.57840431 1693.93819374 1125.27835008
 1820.79813021 1311.85576859 1106.67316137 1755.69180429 1740.7315948 ]
total_rewards_mean           1536.5820175942401
total_rewards_std            313.08184675432665
total_rewards_max            1890.578404308146
total_rewards_min            1106.6731613691584
Number of train steps total  136000
Number of env steps total    682000
Number of rollouts total     0
Train Time (s)               42.98726265085861
(Previous) Eval Time (s)     30.146318959072232
Sample Time (s)              22.705185629893094
Epoch Time (s)               95.83876723982394
Total Train Time (s)         13267.90805054456
Epoch                        135
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:10:26.370505 UTC | [2020_01_10_11_29_18] Iteration #135 | Epoch Duration: 100.6874258518219
2020-01-10 15:10:26.370625 UTC | [2020_01_10_11_29_18] Iteration #135 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7972166
Z variance train             0.020399375
KL Divergence                14.870636
KL Loss                      1.4870636
QF Loss                      1578.405
VF Loss                      107.59019
Policy Loss                  -633.5804
Q Predictions Mean           631.00854
Q Predictions Std            162.9155
Q Predictions Max            814.48676
Q Predictions Min            96.362305
V Predictions Mean           628.28973
V Predictions Std            160.96095
V Predictions Max            799.7537
V Predictions Min            211.494
Log Pis Mean                 -1.332562
Log Pis Std                  2.387593
Log Pis Max                  6.2417135
Log Pis Min                  -7.050311
Policy mu Mean               0.025484184
Policy mu Std                0.525863
Policy mu Max                2.329129
Policy mu Min                -1.6590647
Policy log std Mean          -0.85894185
Policy log std Std           0.22510736
Policy log std Max           -0.2197913
Policy log std Min           -1.6725061
Z mean eval                  0.77476263
Z variance eval              0.019329349
total_rewards                [1015.42752348 1705.50473999 1686.41914713 1729.81438608 1359.13697768
 1765.32838453  445.00439483 1622.83823723 1569.89087781 1921.0997328 ]
total_rewards_mean           1482.0464401552956
total_rewards_std            419.7549704800407
total_rewards_max            1921.0997327959333
total_rewards_min            445.00439482635835
Number of train steps total  137000
Number of env steps total    687000
Number of rollouts total     0
Train Time (s)               43.6013576136902
(Previous) Eval Time (s)     34.9947332018055
Sample Time (s)              23.07456069579348
Epoch Time (s)               101.67065151128918
Total Train Time (s)         13366.27736656228
Epoch                        136
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:12:04.741916 UTC | [2020_01_10_11_29_18] Iteration #136 | Epoch Duration: 98.37120294570923
2020-01-10 15:12:04.742037 UTC | [2020_01_10_11_29_18] Iteration #136 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.77451545
Z variance train             0.019329954
KL Divergence                14.939373
KL Loss                      1.4939374
QF Loss                      819.71954
VF Loss                      72.74488
Policy Loss                  -629.15924
Q Predictions Mean           626.2417
Q Predictions Std            166.00928
Q Predictions Max            819.9802
Q Predictions Min            192.0078
V Predictions Mean           629.60376
V Predictions Std            168.07704
V Predictions Max            828.1373
V Predictions Min            115.72148
Log Pis Mean                 -1.3888803
Log Pis Std                  2.4518392
Log Pis Max                  9.442526
Log Pis Min                  -7.666374
Policy mu Mean               0.0071995943
Policy mu Std                0.5039318
Policy mu Max                1.9437718
Policy mu Min                -1.9351621
Policy log std Mean          -0.86558723
Policy log std Std           0.23267132
Policy log std Max           -0.25247818
Policy log std Min           -2.1305664
Z mean eval                  0.7682222
Z variance eval              0.013954897
total_rewards                [-123.25344815  158.59108156 1883.60010336 1818.11885126 1711.61814675
 1858.49169858 1732.6029896  1816.02450089 1693.07613949 1744.94018696]
total_rewards_mean           1429.381025029925
total_rewards_std            711.150909069934
total_rewards_max            1883.6001033566204
total_rewards_min            -123.253448145378
Number of train steps total  138000
Number of env steps total    692000
Number of rollouts total     0
Train Time (s)               43.43277837941423
(Previous) Eval Time (s)     31.695041962899268
Sample Time (s)              23.143437332939357
Epoch Time (s)               98.27125767525285
Total Train Time (s)         13468.940809555352
Epoch                        137
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:13:47.406992 UTC | [2020_01_10_11_29_18] Iteration #137 | Epoch Duration: 102.66486263275146
2020-01-10 15:13:47.407123 UTC | [2020_01_10_11_29_18] Iteration #137 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7671596
Z variance train             0.0139291985
KL Divergence                16.021206
KL Loss                      1.6021206
QF Loss                      309.0885
VF Loss                      90.5462
Policy Loss                  -613.28864
Q Predictions Mean           608.5409
Q Predictions Std            187.62239
Q Predictions Max            813.9066
Q Predictions Min            59.022633
V Predictions Mean           610.08826
V Predictions Std            186.67204
V Predictions Max            817.5682
V Predictions Min            -0.7934631
Log Pis Mean                 -1.2128568
Log Pis Std                  2.470007
Log Pis Max                  13.500208
Log Pis Min                  -7.978924
Policy mu Mean               -0.007329152
Policy mu Std                0.5335814
Policy mu Max                2.9331083
Policy mu Min                -3.204066
Policy log std Mean          -0.84342813
Policy log std Std           0.24116638
Policy log std Max           -0.20847946
Policy log std Min           -1.8588457
Z mean eval                  0.7510514
Z variance eval              0.018790776
total_rewards                [ 853.55009309 1802.01073561   42.6083687  1226.131879   1674.19856228
 1689.80332326  273.11481022   44.35190185  645.46420981  376.41003119]
total_rewards_mean           862.764391500021
total_rewards_std            658.0748288559157
total_rewards_max            1802.010735607703
total_rewards_min            42.608368701557254
Number of train steps total  139000
Number of env steps total    697000
Number of rollouts total     0
Train Time (s)               43.757931388914585
(Previous) Eval Time (s)     36.088417396880686
Sample Time (s)              23.553311408497393
Epoch Time (s)               103.39966019429266
Total Train Time (s)         13564.700897564646
Epoch                        138
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:15:23.168348 UTC | [2020_01_10_11_29_18] Iteration #138 | Epoch Duration: 95.76113414764404
2020-01-10 15:15:23.168467 UTC | [2020_01_10_11_29_18] Iteration #138 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7505045
Z variance train             0.018850025
KL Divergence                15.609886
KL Loss                      1.5609887
QF Loss                      752.0823
VF Loss                      98.713066
Policy Loss                  -648.9109
Q Predictions Mean           645.68665
Q Predictions Std            166.05096
Q Predictions Max            812.5448
Q Predictions Min            -1.8082746
V Predictions Mean           653.56104
V Predictions Std            164.85228
V Predictions Max            821.59827
V Predictions Min            93.023705
Log Pis Mean                 -1.2907679
Log Pis Std                  2.6004333
Log Pis Max                  9.796358
Log Pis Min                  -8.218962
Policy mu Mean               0.023798978
Policy mu Std                0.52772117
Policy mu Max                1.9567506
Policy mu Min                -1.8143927
Policy log std Mean          -0.8387463
Policy log std Std           0.23158413
Policy log std Max           -0.23989192
Policy log std Min           -1.9544641
Z mean eval                  0.7879927
Z variance eval              0.015990539
total_rewards                [1002.75101673 1904.45452292 1801.98803893 2090.31824893   54.89894067
 1212.84194058 2017.73889477  277.05420516 1829.55928118 1712.75848618]
total_rewards_mean           1390.4363576042595
total_rewards_std            694.173811238819
total_rewards_max            2090.3182489256637
total_rewards_min            54.89894067049721
Number of train steps total  140000
Number of env steps total    702000
Number of rollouts total     0
Train Time (s)               45.75394514435902
(Previous) Eval Time (s)     28.449639833066612
Sample Time (s)              22.781748664565384
Epoch Time (s)               96.98533364199102
Total Train Time (s)         13661.619757789653
Epoch                        139
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:17:00.089494 UTC | [2020_01_10_11_29_18] Iteration #139 | Epoch Duration: 96.92093777656555
2020-01-10 15:17:00.089615 UTC | [2020_01_10_11_29_18] Iteration #139 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.79000235
Z variance train             0.01604138
KL Divergence                16.168488
KL Loss                      1.6168488
QF Loss                      865.8178
VF Loss                      411.2063
Policy Loss                  -641.1381
Q Predictions Mean           639.92053
Q Predictions Std            160.1829
Q Predictions Max            807.5888
Q Predictions Min            7.0768285
V Predictions Mean           650.9331
V Predictions Std            162.50606
V Predictions Max            818.6926
V Predictions Min            33.46619
Log Pis Mean                 -1.6268069
Log Pis Std                  2.570196
Log Pis Max                  11.311771
Log Pis Min                  -10.53382
Policy mu Mean               0.01622404
Policy mu Std                0.48345235
Policy mu Max                2.0309265
Policy mu Min                -2.205599
Policy log std Mean          -0.8715207
Policy log std Std           0.23403
Policy log std Max           -0.25848517
Policy log std Min           -2.3013992
Z mean eval                  0.7824904
Z variance eval              0.020597659
total_rewards                [ 503.71603191 1757.60483506 1756.04770637 1892.04869522 1107.97716038
 1920.44734755  203.2259683    96.91693845 1824.46131377 1938.64013072]
total_rewards_mean           1300.1086127730564
total_rewards_std            718.1254828209393
total_rewards_max            1938.6401307241458
total_rewards_min            96.91693845157576
Number of train steps total  141000
Number of env steps total    707000
Number of rollouts total     0
Train Time (s)               43.125086955260485
(Previous) Eval Time (s)     28.38499953597784
Sample Time (s)              23.099332628771663
Epoch Time (s)               94.60941912000999
Total Train Time (s)         13762.663744946476
Epoch                        140
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:18:41.141091 UTC | [2020_01_10_11_29_18] Iteration #140 | Epoch Duration: 101.05136275291443
2020-01-10 15:18:41.141291 UTC | [2020_01_10_11_29_18] Iteration #140 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7828718
Z variance train             0.020575985
KL Divergence                15.216721
KL Loss                      1.5216721
QF Loss                      604.202
VF Loss                      465.34024
Policy Loss                  -648.3969
Q Predictions Mean           643.5716
Q Predictions Std            168.16672
Q Predictions Max            830.97943
Q Predictions Min            78.15965
V Predictions Mean           647.1536
V Predictions Std            167.06216
V Predictions Max            828.7994
V Predictions Min            57.154316
Log Pis Mean                 -1.2533735
Log Pis Std                  2.3565946
Log Pis Max                  8.380183
Log Pis Min                  -8.069069
Policy mu Mean               0.076401845
Policy mu Std                0.49592042
Policy mu Max                1.6718451
Policy mu Min                -2.077691
Policy log std Mean          -0.88319045
Policy log std Std           0.25394964
Policy log std Max           -0.22244576
Policy log std Min           -2.1442866
Z mean eval                  0.7678109
Z variance eval              0.019569831
total_rewards                [1616.07343785 1802.63045582 1821.56085055 1781.0113958  1379.4515963
 1680.43405147 1895.70485523 1068.73735018   96.7824803   321.58068092]
total_rewards_mean           1346.3967154425065
total_rewards_std            616.3470613221325
total_rewards_max            1895.704855233675
total_rewards_min            96.78248030299716
Number of train steps total  142000
Number of env steps total    712000
Number of rollouts total     0
Train Time (s)               44.075385212898254
(Previous) Eval Time (s)     34.82667549466714
Sample Time (s)              23.177103488706052
Epoch Time (s)               102.07916419627145
Total Train Time (s)         13865.415334422141
Epoch                        141
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:20:23.893591 UTC | [2020_01_10_11_29_18] Iteration #141 | Epoch Duration: 102.7521653175354
2020-01-10 15:20:23.893710 UTC | [2020_01_10_11_29_18] Iteration #141 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7664503
Z variance train             0.019542238
KL Divergence                14.834957
KL Loss                      1.4834957
QF Loss                      332.75952
VF Loss                      104.11319
Policy Loss                  -643.30066
Q Predictions Mean           640.8214
Q Predictions Std            160.99745
Q Predictions Max            817.0899
Q Predictions Min            156.02428
V Predictions Mean           648.4517
V Predictions Std            161.06607
V Predictions Max            839.15985
V Predictions Min            173.76166
Log Pis Mean                 -1.2462032
Log Pis Std                  2.3838499
Log Pis Max                  6.04531
Log Pis Min                  -8.795362
Policy mu Mean               0.022125999
Policy mu Std                0.5085349
Policy mu Max                2.10189
Policy mu Min                -1.7627409
Policy log std Mean          -0.85831416
Policy log std Std           0.23131168
Policy log std Max           -0.29649585
Policy log std Min           -1.8123443
Z mean eval                  0.78833413
Z variance eval              0.017625999
total_rewards                [1767.58442689 2074.87388172 1870.48285148 1755.35123931 2001.21105594
  349.04948933 1744.15927573 1817.65170384 1934.83828869 1980.66746822]
total_rewards_mean           1729.5869681147512
total_rewards_std            472.650288752358
total_rewards_max            2074.873881723741
total_rewards_min            349.0494893300322
Number of train steps total  143000
Number of env steps total    717000
Number of rollouts total     0
Train Time (s)               43.347591110970825
(Previous) Eval Time (s)     35.499447411391884
Sample Time (s)              23.500669320579618
Epoch Time (s)               102.34770784294233
Total Train Time (s)         13966.933638066519
Epoch                        142
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:22:05.414973 UTC | [2020_01_10_11_29_18] Iteration #142 | Epoch Duration: 101.52114534378052
2020-01-10 15:22:05.415144 UTC | [2020_01_10_11_29_18] Iteration #142 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7883076
Z variance train             0.017621653
KL Divergence                15.229805
KL Loss                      1.5229806
QF Loss                      326.18002
VF Loss                      75.82251
Policy Loss                  -649.9876
Q Predictions Mean           647.7262
Q Predictions Std            167.28908
Q Predictions Max            835.12573
Q Predictions Min            158.16003
V Predictions Mean           649.723
V Predictions Std            168.79857
V Predictions Max            834.02765
V Predictions Min            182.57881
Log Pis Mean                 -1.2230542
Log Pis Std                  2.49446
Log Pis Max                  6.245437
Log Pis Min                  -8.737237
Policy mu Mean               0.01799946
Policy mu Std                0.53194654
Policy mu Max                2.0218923
Policy mu Min                -2.2693467
Policy log std Mean          -0.86947364
Policy log std Std           0.23512526
Policy log std Max           -0.1908192
Policy log std Min           -1.7635858
Z mean eval                  0.7574089
Z variance eval              0.017454881
total_rewards                [ 536.66439759 1828.1530116  1686.0915369   179.04490496 1779.71043495
  500.20307731 1843.17789987 1762.75264234 1807.77305546  447.62207478]
total_rewards_mean           1237.1193035766296
total_rewards_std            677.5732496789119
total_rewards_max            1843.1778998723253
total_rewards_min            179.04490495805888
Number of train steps total  144000
Number of env steps total    722000
Number of rollouts total     0
Train Time (s)               44.1729723890312
(Previous) Eval Time (s)     34.672635160852224
Sample Time (s)              22.793518857564777
Epoch Time (s)               101.6391264074482
Total Train Time (s)         14069.053794385865
Epoch                        143
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:23:47.541004 UTC | [2020_01_10_11_29_18] Iteration #143 | Epoch Duration: 102.12568664550781
2020-01-10 15:23:47.541307 UTC | [2020_01_10_11_29_18] Iteration #143 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.75602555
Z variance train             0.017455826
KL Divergence                15.140278
KL Loss                      1.5140278
QF Loss                      714.5111
VF Loss                      210.04433
Policy Loss                  -645.0982
Q Predictions Mean           642.6436
Q Predictions Std            164.81909
Q Predictions Max            847.62506
Q Predictions Min            154.60355
V Predictions Mean           653.359
V Predictions Std            161.17917
V Predictions Max            844.90314
V Predictions Min            189.55803
Log Pis Mean                 -1.480234
Log Pis Std                  2.345064
Log Pis Max                  8.085863
Log Pis Min                  -7.0410776
Policy mu Mean               0.020034237
Policy mu Std                0.522977
Policy mu Max                2.1560323
Policy mu Min                -1.9945017
Policy log std Mean          -0.85056555
Policy log std Std           0.23322426
Policy log std Max           -0.26045257
Policy log std Min           -1.995821
Z mean eval                  0.81118953
Z variance eval              0.011692437
total_rewards                [ 840.80086747 1886.57886417   77.8408135   409.82794874 1837.80672817
  180.83140968   95.29430793 1830.98876738 1397.48341798  814.39756377]
total_rewards_mean           937.185068878883
total_rewards_std            710.2832710698493
total_rewards_max            1886.5788641686481
total_rewards_min            77.84081349838817
Number of train steps total  145000
Number of env steps total    727000
Number of rollouts total     0
Train Time (s)               43.32683566212654
(Previous) Eval Time (s)     35.1589339338243
Sample Time (s)              23.15326745202765
Epoch Time (s)               101.63903704797849
Total Train Time (s)         14164.78312882362
Epoch                        144
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:25:23.270621 UTC | [2020_01_10_11_29_18] Iteration #144 | Epoch Duration: 95.72911477088928
2020-01-10 15:25:23.270743 UTC | [2020_01_10_11_29_18] Iteration #144 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8130596
Z variance train             0.0116987545
KL Divergence                16.037128
KL Loss                      1.6037129
QF Loss                      356.07477
VF Loss                      78.73397
Policy Loss                  -641.5079
Q Predictions Mean           639.3241
Q Predictions Std            188.83081
Q Predictions Max            839.3693
Q Predictions Min            228.8177
V Predictions Mean           638.65955
V Predictions Std            188.73936
V Predictions Max            833.32196
V Predictions Min            215.98433
Log Pis Mean                 -1.3897028
Log Pis Std                  2.5416481
Log Pis Max                  8.268664
Log Pis Min                  -7.927004
Policy mu Mean               0.05251776
Policy mu Std                0.5254491
Policy mu Max                2.2017806
Policy mu Min                -1.7180924
Policy log std Mean          -0.846635
Policy log std Std           0.25010335
Policy log std Max           -0.21483296
Policy log std Min           -1.8405026
Z mean eval                  0.7924221
Z variance eval              0.016219556
total_rewards                [1041.12919144 1866.26441164  459.84905374  206.97582462 1841.29414495
 1971.16918244 1905.64516826 1832.40383069  470.74462283 1861.5351264 ]
total_rewards_mean           1345.7010557009403
total_rewards_std            682.9386930968218
total_rewards_max            1971.1691824401
total_rewards_min            206.97582462173202
Number of train steps total  146000
Number of env steps total    732000
Number of rollouts total     0
Train Time (s)               45.14455399103463
(Previous) Eval Time (s)     29.24879618594423
Sample Time (s)              22.85708138719201
Epoch Time (s)               97.25043156417087
Total Train Time (s)         14266.827917535324
Epoch                        145
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:27:05.317077 UTC | [2020_01_10_11_29_18] Iteration #145 | Epoch Duration: 102.04624223709106
2020-01-10 15:27:05.317217 UTC | [2020_01_10_11_29_18] Iteration #145 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7872667
Z variance train             0.016192477
KL Divergence                14.836577
KL Loss                      1.4836577
QF Loss                      1401.3545
VF Loss                      223.6713
Policy Loss                  -653.73975
Q Predictions Mean           647.8629
Q Predictions Std            156.30632
Q Predictions Max            826.603
Q Predictions Min            74.54817
V Predictions Mean           645.08826
V Predictions Std            151.89734
V Predictions Max            813.0584
V Predictions Min            155.8058
Log Pis Mean                 -1.0789936
Log Pis Std                  2.2975721
Log Pis Max                  6.64717
Log Pis Min                  -6.882952
Policy mu Mean               0.04566938
Policy mu Std                0.5328371
Policy mu Max                1.8444982
Policy mu Min                -2.791409
Policy log std Mean          -0.86263263
Policy log std Std           0.22825554
Policy log std Max           -0.23128712
Policy log std Min           -1.8345301
Z mean eval                  0.77835244
Z variance eval              0.014602691
total_rewards                [   9.40674001 1310.75870023 1015.60008744 1133.59580697  166.92577693
 1638.2675549   566.83934469 1597.67930438 1716.32854237   -5.98966738]
total_rewards_mean           914.9412190528626
total_rewards_std            647.6863318917693
total_rewards_max            1716.3285423669827
total_rewards_min            -5.989667383843418
Number of train steps total  147000
Number of env steps total    737000
Number of rollouts total     0
Train Time (s)               44.66310979984701
(Previous) Eval Time (s)     34.04434528015554
Sample Time (s)              22.904652155935764
Epoch Time (s)               101.61210723593831
Total Train Time (s)         14368.904662691988
Epoch                        146
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:28:47.397310 UTC | [2020_01_10_11_29_18] Iteration #146 | Epoch Duration: 102.07997274398804
2020-01-10 15:28:47.397479 UTC | [2020_01_10_11_29_18] Iteration #146 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7754437
Z variance train             0.014580844
KL Divergence                15.375352
KL Loss                      1.5375352
QF Loss                      358.7603
VF Loss                      81.98072
Policy Loss                  -677.917
Q Predictions Mean           675.7527
Q Predictions Std            162.3343
Q Predictions Max            852.43994
Q Predictions Min            221.37439
V Predictions Mean           681.7905
V Predictions Std            160.61832
V Predictions Max            851.4493
V Predictions Min            224.83658
Log Pis Mean                 -1.592007
Log Pis Std                  2.4252322
Log Pis Max                  5.3884377
Log Pis Min                  -9.266261
Policy mu Mean               0.036043875
Policy mu Std                0.50129205
Policy mu Max                2.076882
Policy mu Min                -1.7622781
Policy log std Mean          -0.8753172
Policy log std Std           0.2406096
Policy log std Max           -0.29273623
Policy log std Min           -1.7803462
Z mean eval                  0.7903117
Z variance eval              0.013966775
total_rewards                [ 521.99738039  499.08556722  466.26137658  304.3563205  1722.62560727
 1285.3614225   792.11616137 1551.70001706  986.578823   1662.53094717]
total_rewards_mean           979.2613623053916
total_rewards_std            513.2477766350456
total_rewards_max            1722.6256072677213
total_rewards_min            304.35632050306253
Number of train steps total  148000
Number of env steps total    742000
Number of rollouts total     0
Train Time (s)               43.76086180424318
(Previous) Eval Time (s)     34.51195995695889
Sample Time (s)              21.76075821230188
Epoch Time (s)               100.03357997350395
Total Train Time (s)         14461.192448217887
Epoch                        147
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:30:19.686707 UTC | [2020_01_10_11_29_18] Iteration #147 | Epoch Duration: 92.28910446166992
2020-01-10 15:30:19.686842 UTC | [2020_01_10_11_29_18] Iteration #147 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7928973
Z variance train             0.013956837
KL Divergence                15.970341
KL Loss                      1.5970341
QF Loss                      560.3815
VF Loss                      217.39273
Policy Loss                  -637.15326
Q Predictions Mean           637.43555
Q Predictions Std            187.4505
Q Predictions Max            830.9428
Q Predictions Min            -22.588842
V Predictions Mean           640.61896
V Predictions Std            185.85335
V Predictions Max            838.9066
V Predictions Min            118.01717
Log Pis Mean                 -1.720896
Log Pis Std                  2.4652064
Log Pis Max                  9.988857
Log Pis Min                  -7.6505885
Policy mu Mean               -0.0450555
Policy mu Std                0.5194188
Policy mu Max                1.9844491
Policy mu Min                -2.2781231
Policy log std Mean          -0.81292444
Policy log std Std           0.2560896
Policy log std Max           -0.1548076
Policy log std Min           -2.2826834
Z mean eval                  0.7865198
Z variance eval              0.014976946
total_rewards                [1934.39923838 1730.29162685 1834.08166164  224.10742639  313.8967475
 1422.5172209  1501.46527469 1208.23121668 1423.86579758  985.8602191 ]
total_rewards_mean           1257.8716429708059
total_rewards_std            562.4144150565565
total_rewards_max            1934.3992383754423
total_rewards_min            224.10742639038364
Number of train steps total  149000
Number of env steps total    747000
Number of rollouts total     0
Train Time (s)               43.80903511727229
(Previous) Eval Time (s)     26.76724177831784
Sample Time (s)              22.878110903315246
Epoch Time (s)               93.45438779890537
Total Train Time (s)         14561.448103103321
Epoch                        148
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:31:59.944296 UTC | [2020_01_10_11_29_18] Iteration #148 | Epoch Duration: 100.25734519958496
2020-01-10 15:31:59.944471 UTC | [2020_01_10_11_29_18] Iteration #148 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7849791
Z variance train             0.014972958
KL Divergence                15.819656
KL Loss                      1.5819657
QF Loss                      468.1911
VF Loss                      115.36276
Policy Loss                  -657.7192
Q Predictions Mean           654.8427
Q Predictions Std            169.38647
Q Predictions Max            836.77966
Q Predictions Min            178.80891
V Predictions Mean           653.4507
V Predictions Std            165.22868
V Predictions Max            833.64
V Predictions Min            231.54378
Log Pis Mean                 -1.4241393
Log Pis Std                  2.2980754
Log Pis Max                  4.3631516
Log Pis Min                  -10.150463
Policy mu Mean               0.02136796
Policy mu Std                0.49855596
Policy mu Max                1.5547194
Policy mu Min                -1.8883832
Policy log std Mean          -0.85171723
Policy log std Std           0.24291614
Policy log std Max           -0.10474092
Policy log std Min           -2.200764
Z mean eval                  0.7900894
Z variance eval              0.01667674
total_rewards                [ 236.0906482  1075.42560286 2015.47840506 1911.96389983 1526.21023186
  745.10029058 1849.78749412 1880.85164398 1855.83529471 1843.17242525]
total_rewards_mean           1493.991593644492
total_rewards_std            574.0337432042007
total_rewards_max            2015.4784050594135
total_rewards_min            236.0906481981563
Number of train steps total  150000
Number of env steps total    752000
Number of rollouts total     0
Train Time (s)               43.2311931331642
(Previous) Eval Time (s)     33.56994766788557
Sample Time (s)              23.16876494931057
Epoch Time (s)               99.96990575036034
Total Train Time (s)         14663.000169609673
Epoch                        149
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:33:41.501783 UTC | [2020_01_10_11_29_18] Iteration #149 | Epoch Duration: 101.55714416503906
2020-01-10 15:33:41.502069 UTC | [2020_01_10_11_29_18] Iteration #149 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7898191
Z variance train             0.016676972
KL Divergence                15.906944
KL Loss                      1.5906944
QF Loss                      302.83615
VF Loss                      97.636734
Policy Loss                  -682.1229
Q Predictions Mean           679.58093
Q Predictions Std            160.07751
Q Predictions Max            856.7397
Q Predictions Min            -9.881156
V Predictions Mean           679.99646
V Predictions Std            156.67917
V Predictions Max            853.2845
V Predictions Min            14.441568
Log Pis Mean                 -1.240779
Log Pis Std                  2.3019845
Log Pis Max                  5.647209
Log Pis Min                  -9.386166
Policy mu Mean               0.07147399
Policy mu Std                0.50559425
Policy mu Max                1.8679218
Policy mu Min                -1.8815275
Policy log std Mean          -0.888941
Policy log std Std           0.22059439
Policy log std Max           -0.26973528
Policy log std Min           -1.886757
Z mean eval                  0.8051593
Z variance eval              0.0171399
total_rewards                [1785.94875173 1204.91167293 1817.92282982 1250.13555721  755.5814117
 1939.68007977 1828.06738096 1860.25682558 1868.07751148 1931.89221902]
total_rewards_mean           1624.2474240187541
total_rewards_std            385.34134068530057
total_rewards_max            1939.6800797657934
total_rewards_min            755.5814117001942
Number of train steps total  151000
Number of env steps total    757000
Number of rollouts total     0
Train Time (s)               42.75992409186438
(Previous) Eval Time (s)     35.156931788194925
Sample Time (s)              23.107311762403697
Epoch Time (s)               101.024167642463
Total Train Time (s)         14760.826179615222
Epoch                        150
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:35:19.328661 UTC | [2020_01_10_11_29_18] Iteration #150 | Epoch Duration: 97.82639455795288
2020-01-10 15:35:19.328832 UTC | [2020_01_10_11_29_18] Iteration #150 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8038254
Z variance train             0.017158207
KL Divergence                16.549871
KL Loss                      1.6549872
QF Loss                      597.46893
VF Loss                      155.7739
Policy Loss                  -686.8636
Q Predictions Mean           684.9717
Q Predictions Std            163.89673
Q Predictions Max            859.58594
Q Predictions Min            23.492367
V Predictions Mean           693.908
V Predictions Std            164.938
V Predictions Max            866.2808
V Predictions Min            24.71206
Log Pis Mean                 -1.0616832
Log Pis Std                  2.5025346
Log Pis Max                  8.140385
Log Pis Min                  -8.727141
Policy mu Mean               0.009454183
Policy mu Std                0.51585025
Policy mu Max                1.8106555
Policy mu Min                -1.892166
Policy log std Mean          -0.8648264
Policy log std Std           0.2307587
Policy log std Max           -0.17327201
Policy log std Min           -2.104185
Z mean eval                  0.7815925
Z variance eval              0.00932386
total_rewards                [1890.31085906 2099.38459673 1929.49400647 1112.18467668 1887.04159409
 1879.58279684 1814.85500504 1392.32547837 1787.60702135 1805.4812589 ]
total_rewards_mean           1759.8267293531414
total_rewards_std            274.22971493136674
total_rewards_max            2099.3845967321918
total_rewards_min            1112.1846766817537
Number of train steps total  152000
Number of env steps total    762000
Number of rollouts total     0
Train Time (s)               43.814448738936335
(Previous) Eval Time (s)     31.9589143586345
Sample Time (s)              23.00236051250249
Epoch Time (s)               98.77572361007333
Total Train Time (s)         14858.93155330792
Epoch                        151
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:36:57.435745 UTC | [2020_01_10_11_29_18] Iteration #151 | Epoch Duration: 98.10677909851074
2020-01-10 15:36:57.435915 UTC | [2020_01_10_11_29_18] Iteration #151 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7810833
Z variance train             0.009329202
KL Divergence                16.701273
KL Loss                      1.6701273
QF Loss                      376.31628
VF Loss                      138.23958
Policy Loss                  -683.0259
Q Predictions Mean           679.98425
Q Predictions Std            153.01779
Q Predictions Max            836.35144
Q Predictions Min            27.386562
V Predictions Mean           680.8842
V Predictions Std            151.42595
V Predictions Max            838.8561
V Predictions Min            164.03687
Log Pis Mean                 -1.358806
Log Pis Std                  2.2855184
Log Pis Max                  7.7020736
Log Pis Min                  -8.340944
Policy mu Mean               -0.0013168333
Policy mu Std                0.4998097
Policy mu Max                2.662098
Policy mu Min                -1.8554931
Policy log std Mean          -0.86987734
Policy log std Std           0.23102298
Policy log std Max           -0.24105296
Policy log std Min           -1.7742996
Z mean eval                  0.7879021
Z variance eval              0.007599745
total_rewards                [1604.87971392 1715.28972685 1828.75748731  280.86538278 1884.0830916
  873.39266927 1694.98680716 1701.78542681 1253.00367797 1664.7023658 ]
total_rewards_mean           1450.1746349464727
total_rewards_std            483.1068500070406
total_rewards_max            1884.0830916043503
total_rewards_min            280.8653827770736
Number of train steps total  153000
Number of env steps total    767000
Number of rollouts total     0
Train Time (s)               43.35627043992281
(Previous) Eval Time (s)     31.28974373266101
Sample Time (s)              22.89001091197133
Epoch Time (s)               97.53602508455515
Total Train Time (s)         14958.028181064408
Epoch                        152
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:38:36.536999 UTC | [2020_01_10_11_29_18] Iteration #152 | Epoch Duration: 99.10089635848999
2020-01-10 15:38:36.537280 UTC | [2020_01_10_11_29_18] Iteration #152 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7880588
Z variance train             0.0076169027
KL Divergence                17.540579
KL Loss                      1.7540579
QF Loss                      671.6212
VF Loss                      132.82263
Policy Loss                  -679.6461
Q Predictions Mean           675.64795
Q Predictions Std            166.60376
Q Predictions Max            845.1867
Q Predictions Min            9.222852
V Predictions Mean           679.1233
V Predictions Std            164.21382
V Predictions Max            852.6968
V Predictions Min            39.25148
Log Pis Mean                 -0.98222584
Log Pis Std                  2.6204095
Log Pis Max                  13.8453865
Log Pis Min                  -7.008607
Policy mu Mean               -0.0020714523
Policy mu Std                0.55245215
Policy mu Max                2.2328272
Policy mu Min                -2.0120976
Policy log std Mean          -0.8847975
Policy log std Std           0.24480346
Policy log std Max           -0.17408365
Policy log std Min           -2.022757
Z mean eval                  0.7946485
Z variance eval              0.018713102
total_rewards                [ 137.91838808 1980.54669503 2003.72880546  563.3686895  2100.27076612
 2064.07676178 1949.2747864   160.84901924 2056.89017469 1983.41091072]
total_rewards_mean           1500.0334997030573
total_rewards_std            802.1661858825488
total_rewards_max            2100.270766116012
total_rewards_min            137.9183880847852
Number of train steps total  154000
Number of env steps total    772000
Number of rollouts total     0
Train Time (s)               44.57575654378161
(Previous) Eval Time (s)     32.85434724204242
Sample Time (s)              22.65172302396968
Epoch Time (s)               100.08182680979371
Total Train Time (s)         15059.98938866239
Epoch                        153
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:40:18.498021 UTC | [2020_01_10_11_29_18] Iteration #153 | Epoch Duration: 101.96054935455322
2020-01-10 15:40:18.498138 UTC | [2020_01_10_11_29_18] Iteration #153 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7942934
Z variance train             0.018789595
KL Divergence                15.811502
KL Loss                      1.5811503
QF Loss                      561.46045
VF Loss                      55.741837
Policy Loss                  -688.83844
Q Predictions Mean           685.5957
Q Predictions Std            171.81352
Q Predictions Max            869.5372
Q Predictions Min            69.49304
V Predictions Mean           688.02997
V Predictions Std            170.52132
V Predictions Max            866.83655
V Predictions Min            85.34116
Log Pis Mean                 -1.3613973
Log Pis Std                  2.247028
Log Pis Max                  10.18041
Log Pis Min                  -8.097938
Policy mu Mean               0.022871515
Policy mu Std                0.5138558
Policy mu Max                1.9470587
Policy mu Min                -2.241264
Policy log std Mean          -0.8529186
Policy log std Std           0.22911756
Policy log std Max           -0.23214877
Policy log std Min           -1.9821751
Z mean eval                  0.7939075
Z variance eval              0.025420368
total_rewards                [2043.97013411 1888.50570945 2084.48692412 1132.92861188 1185.84983312
 1313.34590612 1898.38107466  199.29502375 2132.78150098 1991.4531474 ]
total_rewards_mean           1587.09978655874
total_rewards_std            589.3515463133508
total_rewards_max            2132.7815009841097
total_rewards_min            199.29502374923575
Number of train steps total  155000
Number of env steps total    777000
Number of rollouts total     0
Train Time (s)               43.69230382097885
(Previous) Eval Time (s)     34.73284105397761
Sample Time (s)              22.807380911894143
Epoch Time (s)               101.2325257868506
Total Train Time (s)         15159.263123048004
Epoch                        154
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:41:57.773158 UTC | [2020_01_10_11_29_18] Iteration #154 | Epoch Duration: 99.27493190765381
2020-01-10 15:41:57.773277 UTC | [2020_01_10_11_29_18] Iteration #154 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.796759
Z variance train             0.025447886
KL Divergence                15.8247385
KL Loss                      1.5824739
QF Loss                      304.4289
VF Loss                      138.2492
Policy Loss                  -681.3278
Q Predictions Mean           676.1078
Q Predictions Std            178.9793
Q Predictions Max            868.992
Q Predictions Min            22.982368
V Predictions Mean           671.7329
V Predictions Std            176.35689
V Predictions Max            860.5352
V Predictions Min            0.42327514
Log Pis Mean                 -1.153094
Log Pis Std                  2.2713692
Log Pis Max                  4.605525
Log Pis Min                  -6.9892545
Policy mu Mean               0.07807983
Policy mu Std                0.5204542
Policy mu Max                1.6887109
Policy mu Min                -1.7077401
Policy log std Mean          -0.8716361
Policy log std Std           0.23170051
Policy log std Max           -0.09466463
Policy log std Min           -2.1971073
Z mean eval                  0.790138
Z variance eval              0.015760068
total_rewards                [ -10.42464817 1713.91744149 1819.36551493  179.30718781  532.37161983
 1103.25022319 1212.78916136 1828.63671718 1846.3332078   -59.9419194 ]
total_rewards_mean           1016.5604506018465
total_rewards_std            753.2464307652023
total_rewards_max            1846.333207799471
total_rewards_min            -59.94191940024419
Number of train steps total  156000
Number of env steps total    782000
Number of rollouts total     0
Train Time (s)               43.43676206609234
(Previous) Eval Time (s)     32.77499662479386
Sample Time (s)              22.964704257436097
Epoch Time (s)               99.1764629483223
Total Train Time (s)         15261.486484800931
Epoch                        155
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:43:40.002006 UTC | [2020_01_10_11_29_18] Iteration #155 | Epoch Duration: 102.22859597206116
2020-01-10 15:43:40.002277 UTC | [2020_01_10_11_29_18] Iteration #155 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7913748
Z variance train             0.015735973
KL Divergence                17.00199
KL Loss                      1.700199
QF Loss                      431.63077
VF Loss                      131.8869
Policy Loss                  -670.63336
Q Predictions Mean           666.80396
Q Predictions Std            179.85547
Q Predictions Max            842.4015
Q Predictions Min            198.89468
V Predictions Mean           663.59204
V Predictions Std            177.64017
V Predictions Max            829.5434
V Predictions Min            199.76297
Log Pis Mean                 -1.4765823
Log Pis Std                  2.4310334
Log Pis Max                  11.277439
Log Pis Min                  -9.004691
Policy mu Mean               0.017677018
Policy mu Std                0.5327597
Policy mu Max                2.5514042
Policy mu Min                -2.6118567
Policy log std Mean          -0.82330567
Policy log std Std           0.23313187
Policy log std Max           -0.18258017
Policy log std Min           -1.5835376
Z mean eval                  0.79270214
Z variance eval              0.012490037
total_rewards                [1638.89423913 1848.43897174 1895.37473748 1998.94301403 2014.31090008
 1871.10370171 1843.22437725 1758.17404668 2028.58406244 1968.82883762]
total_rewards_mean           1886.5876888157945
total_rewards_std            117.19995327168299
total_rewards_max            2028.5840624400462
total_rewards_min            1638.8942391286093
Number of train steps total  157000
Number of env steps total    787000
Number of rollouts total     0
Train Time (s)               43.07751967618242
(Previous) Eval Time (s)     35.826858643908054
Sample Time (s)              22.55386745557189
Epoch Time (s)               101.45824577566236
Total Train Time (s)         15361.568955765106
Epoch                        156
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:45:20.088801 UTC | [2020_01_10_11_29_18] Iteration #156 | Epoch Duration: 100.08633756637573
2020-01-10 15:45:20.088924 UTC | [2020_01_10_11_29_18] Iteration #156 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.79100835
Z variance train             0.012488383
KL Divergence                17.2426
KL Loss                      1.72426
QF Loss                      622.3624
VF Loss                      168.98718
Policy Loss                  -679.0085
Q Predictions Mean           678.7833
Q Predictions Std            194.9143
Q Predictions Max            871.6166
Q Predictions Min            51.534245
V Predictions Mean           684.1926
V Predictions Std            192.68428
V Predictions Max            878.3089
V Predictions Min            91.17254
Log Pis Mean                 -1.3157694
Log Pis Std                  2.5298097
Log Pis Max                  12.403549
Log Pis Min                  -8.483545
Policy mu Mean               0.08742799
Policy mu Std                0.51987225
Policy mu Max                1.832788
Policy mu Min                -2.6790066
Policy log std Mean          -0.84272397
Policy log std Std           0.25277784
Policy log std Max           -0.22219676
Policy log std Min           -2.0773196
Z mean eval                  0.7995639
Z variance eval              0.015605429
total_rewards                [ 237.67560665   78.42782147   -5.57612416  312.84835604 1825.74295395
 1997.74267349 1887.19865595  634.92782339 1944.31178388 1083.58154628]
total_rewards_mean           999.6881096937148
total_rewards_std            800.640065775292
total_rewards_max            1997.7426734864734
total_rewards_min            -5.576124158195139
Number of train steps total  158000
Number of env steps total    792000
Number of rollouts total     0
Train Time (s)               43.89959443220869
(Previous) Eval Time (s)     34.4547328162007
Sample Time (s)              22.962962578050792
Epoch Time (s)               101.31728982646018
Total Train Time (s)         15457.88281132793
Epoch                        157
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:46:56.403545 UTC | [2020_01_10_11_29_18] Iteration #157 | Epoch Duration: 96.31452012062073
2020-01-10 15:46:56.403702 UTC | [2020_01_10_11_29_18] Iteration #157 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7991906
Z variance train             0.015607929
KL Divergence                17.256351
KL Loss                      1.7256352
QF Loss                      363.5566
VF Loss                      143.0741
Policy Loss                  -700.11804
Q Predictions Mean           695.2178
Q Predictions Std            162.4608
Q Predictions Max            863.99023
Q Predictions Min            196.87735
V Predictions Mean           692.1024
V Predictions Std            161.274
V Predictions Max            856.15717
V Predictions Min            191.45032
Log Pis Mean                 -1.3329647
Log Pis Std                  2.3419104
Log Pis Max                  5.685829
Log Pis Min                  -8.134514
Policy mu Mean               0.039812993
Policy mu Std                0.521475
Policy mu Max                1.5470182
Policy mu Min                -1.6650997
Policy log std Mean          -0.868042
Policy log std Std           0.23948929
Policy log std Max           -0.28564793
Policy log std Min           -1.8420529
Z mean eval                  0.7840067
Z variance eval              0.011355562
total_rewards                [1914.92538124 1968.47794161 1670.60487325 1082.95799282 1872.58963759
 1858.05226826 1978.94957718 2053.32807475   39.91830018 1726.18029249]
total_rewards_mean           1616.5984339353358
total_rewards_std            586.8814173097153
total_rewards_max            2053.3280747508506
total_rewards_min            39.918300177310314
Number of train steps total  159000
Number of env steps total    797000
Number of rollouts total     0
Train Time (s)               43.00195972574875
(Previous) Eval Time (s)     29.4517156239599
Sample Time (s)              21.79156248178333
Epoch Time (s)               94.24523783149198
Total Train Time (s)         15556.807261057664
Epoch                        158
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:48:35.329792 UTC | [2020_01_10_11_29_18] Iteration #158 | Epoch Duration: 98.92598176002502
2020-01-10 15:48:35.329914 UTC | [2020_01_10_11_29_18] Iteration #158 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7828711
Z variance train             0.011378114
KL Divergence                17.84315
KL Loss                      1.784315
QF Loss                      502.60608
VF Loss                      52.231148
Policy Loss                  -694.3741
Q Predictions Mean           692.2612
Q Predictions Std            174.91699
Q Predictions Max            862.21716
Q Predictions Min            169.62563
V Predictions Mean           696.9701
V Predictions Std            172.05104
V Predictions Max            850.9985
V Predictions Min            178.50638
Log Pis Mean                 -1.2545471
Log Pis Std                  2.3865356
Log Pis Max                  8.946351
Log Pis Min                  -7.886503
Policy mu Mean               0.035773225
Policy mu Std                0.531541
Policy mu Max                2.0213165
Policy mu Min                -1.9825671
Policy log std Mean          -0.85639
Policy log std Std           0.23149315
Policy log std Max           -0.2907605
Policy log std Min           -1.7073841
Z mean eval                  0.7937963
Z variance eval              0.014426038
total_rewards                [1150.17659977  916.52325098 1779.49630456 1813.48698875 1949.15661724
  945.66501779 1655.83117377 1847.30458741 1910.38602327 1906.55610367]
total_rewards_mean           1587.458266720225
total_rewards_std            393.74631988029034
total_rewards_max            1949.1566172401413
total_rewards_min            916.5232509750249
Number of train steps total  160000
Number of env steps total    802000
Number of rollouts total     0
Train Time (s)               43.2929062647745
(Previous) Eval Time (s)     34.13222932908684
Sample Time (s)              22.84142391802743
Epoch Time (s)               100.26655951188877
Total Train Time (s)         15657.993519560434
Epoch                        159
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:50:16.518849 UTC | [2020_01_10_11_29_18] Iteration #159 | Epoch Duration: 101.18883347511292
2020-01-10 15:50:16.519017 UTC | [2020_01_10_11_29_18] Iteration #159 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.79381937
Z variance train             0.014391802
KL Divergence                17.52151
KL Loss                      1.7521509
QF Loss                      241.54968
VF Loss                      75.59121
Policy Loss                  -690.5244
Q Predictions Mean           687.5956
Q Predictions Std            165.97314
Q Predictions Max            859.3821
Q Predictions Min            177.32077
V Predictions Mean           684.54517
V Predictions Std            165.55191
V Predictions Max            850.0627
V Predictions Min            174.0058
Log Pis Mean                 -1.4211617
Log Pis Std                  2.2323506
Log Pis Max                  5.525136
Log Pis Min                  -8.323888
Policy mu Mean               0.07292913
Policy mu Std                0.49610457
Policy mu Max                1.4970064
Policy mu Min                -1.9525045
Policy log std Mean          -0.86419046
Policy log std Std           0.23252532
Policy log std Max           -0.33172178
Policy log std Min           -1.7896241
Z mean eval                  0.8217891
Z variance eval              0.014621009
total_rewards                [ 886.76104499 1735.76683911 1986.62999068 2105.53504996 1762.90080606
 2055.45922775 1848.29936953 2039.82046887 1241.60848456 2144.47584214]
total_rewards_mean           1780.7257123650702
total_rewards_std            389.8135285473035
total_rewards_max            2144.47584213666
total_rewards_min            886.7610449930335
Number of train steps total  161000
Number of env steps total    807000
Number of rollouts total     0
Train Time (s)               43.93767635105178
(Previous) Eval Time (s)     35.05423443298787
Sample Time (s)              21.27413232019171
Epoch Time (s)               100.26604310423136
Total Train Time (s)         15754.886368097737
Epoch                        160
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:51:53.416353 UTC | [2020_01_10_11_29_18] Iteration #160 | Epoch Duration: 96.89710116386414
2020-01-10 15:51:53.416654 UTC | [2020_01_10_11_29_18] Iteration #160 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.82114565
Z variance train             0.014613268
KL Divergence                17.940292
KL Loss                      1.7940292
QF Loss                      345.337
VF Loss                      78.898285
Policy Loss                  -701.80865
Q Predictions Mean           697.74304
Q Predictions Std            175.02742
Q Predictions Max            858.8198
Q Predictions Min            202.03844
V Predictions Mean           696.7068
V Predictions Std            174.19385
V Predictions Max            861.2725
V Predictions Min            194.66791
Log Pis Mean                 -1.3242651
Log Pis Std                  2.2780032
Log Pis Max                  4.957905
Log Pis Min                  -8.201088
Policy mu Mean               0.052506015
Policy mu Std                0.4959899
Policy mu Max                1.747027
Policy mu Min                -1.7304475
Policy log std Mean          -0.87821436
Policy log std Std           0.22096525
Policy log std Max           -0.2813875
Policy log std Min           -1.8546855
Z mean eval                  0.79306686
Z variance eval              0.017830005
total_rewards                [1903.37359472 1960.60724838 1365.54564321 1985.71398108  774.75089008
   26.90341616  842.11404884 1963.20504303 2031.21119515 1007.07297625]
total_rewards_mean           1386.0498036894364
total_rewards_std            660.8747162093825
total_rewards_max            2031.211195145089
total_rewards_min            26.903416160616256
Number of train steps total  162000
Number of env steps total    812000
Number of rollouts total     0
Train Time (s)               43.65638173883781
(Previous) Eval Time (s)     31.685053640045226
Sample Time (s)              22.72189761372283
Epoch Time (s)               98.06333299260587
Total Train Time (s)         15850.735280066729
Epoch                        161
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:53:29.265011 UTC | [2020_01_10_11_29_18] Iteration #161 | Epoch Duration: 95.84818148612976
2020-01-10 15:53:29.265146 UTC | [2020_01_10_11_29_18] Iteration #161 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.79516834
Z variance train             0.017879022
KL Divergence                17.2461
KL Loss                      1.72461
QF Loss                      1122.8438
VF Loss                      149.13556
Policy Loss                  -717.3413
Q Predictions Mean           713.94934
Q Predictions Std            140.9992
Q Predictions Max            858.0532
Q Predictions Min            207.96274
V Predictions Mean           724.79785
V Predictions Std            140.55621
V Predictions Max            865.6398
V Predictions Min            231.3831
Log Pis Mean                 -1.009527
Log Pis Std                  2.4388058
Log Pis Max                  5.857549
Log Pis Min                  -10.082379
Policy mu Mean               0.04540307
Policy mu Std                0.5370334
Policy mu Max                2.4053931
Policy mu Min                -1.9120278
Policy log std Mean          -0.8836523
Policy log std Std           0.23258182
Policy log std Max           -0.17315781
Policy log std Min           -1.7564435
Z mean eval                  0.80419314
Z variance eval              0.014521554
total_rewards                [1935.34880021 1919.37087509 1951.96054272 1346.9471945  2155.36170381
 1793.77030848 2198.20185844 1921.02517089  905.33936313 1943.88301956]
total_rewards_mean           1807.120883682802
total_rewards_std            371.6265632229944
total_rewards_max            2198.201858437549
total_rewards_min            905.3393631316832
Number of train steps total  163000
Number of env steps total    817000
Number of rollouts total     0
Train Time (s)               43.56857985723764
(Previous) Eval Time (s)     29.46968322293833
Sample Time (s)              22.21068082936108
Epoch Time (s)               95.24894390953705
Total Train Time (s)         15948.28323380975
Epoch                        162
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:55:06.815640 UTC | [2020_01_10_11_29_18] Iteration #162 | Epoch Duration: 97.55038475990295
2020-01-10 15:55:06.815816 UTC | [2020_01_10_11_29_18] Iteration #162 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.80447876
Z variance train             0.014481987
KL Divergence                17.752737
KL Loss                      1.7752737
QF Loss                      573.32275
VF Loss                      192.00412
Policy Loss                  -676.19293
Q Predictions Mean           673.25183
Q Predictions Std            199.14738
Q Predictions Max            887.74243
Q Predictions Min            10.299502
V Predictions Mean           674.53723
V Predictions Std            196.78679
V Predictions Max            878.826
V Predictions Min            27.68226
Log Pis Mean                 -1.3799143
Log Pis Std                  2.2967274
Log Pis Max                  4.80815
Log Pis Min                  -9.017016
Policy mu Mean               0.059437457
Policy mu Std                0.5352007
Policy mu Max                1.8097652
Policy mu Min                -1.843125
Policy log std Mean          -0.8385531
Policy log std Std           0.252519
Policy log std Max           -0.19683766
Policy log std Min           -2.062947
Z mean eval                  0.7899036
Z variance eval              0.013188536
total_rewards                [1025.41110068 1792.43859306 1791.18330886 1643.09990713 1898.15656744
  179.99045339 2042.79841165 1882.69029761 1830.69710498 1819.7278307 ]
total_rewards_mean           1590.619357549248
total_rewards_std            537.3568528548658
total_rewards_max            2042.7984116467094
total_rewards_min            179.99045338823572
Number of train steps total  164000
Number of env steps total    822000
Number of rollouts total     0
Train Time (s)               44.276730210054666
(Previous) Eval Time (s)     31.770868605934083
Sample Time (s)              22.757469668984413
Epoch Time (s)               98.80506848497316
Total Train Time (s)         16045.541940560564
Epoch                        163
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:56:44.080890 UTC | [2020_01_10_11_29_18] Iteration #163 | Epoch Duration: 97.26492547988892
2020-01-10 15:56:44.081104 UTC | [2020_01_10_11_29_18] Iteration #163 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7889548
Z variance train             0.013173017
KL Divergence                18.24525
KL Loss                      1.8245251
QF Loss                      359.93878
VF Loss                      116.77856
Policy Loss                  -695.9949
Q Predictions Mean           692.2047
Q Predictions Std            179.49661
Q Predictions Max            880.51294
Q Predictions Min            -32.28482
V Predictions Mean           701.5121
V Predictions Std            175.95436
V Predictions Max            886.107
V Predictions Min            149.96802
Log Pis Mean                 -1.3252575
Log Pis Std                  2.7461894
Log Pis Max                  19.697079
Log Pis Min                  -9.479215
Policy mu Mean               0.014984294
Policy mu Std                0.52300483
Policy mu Max                2.349755
Policy mu Min                -2.2226167
Policy log std Mean          -0.86350596
Policy log std Std           0.24363002
Policy log std Max           -0.22572383
Policy log std Min           -2.331223
Z mean eval                  0.78909457
Z variance eval              0.012902808
total_rewards                [ 262.88068563  397.59614441 1897.92757957  370.7138458  1887.00788812
  107.45393806  633.58241609 1939.94010067  700.05720708  632.2710646 ]
total_rewards_mean           882.94308700159
total_rewards_std            692.6650009881207
total_rewards_max            1939.9401006677535
total_rewards_min            107.45393805521634
Number of train steps total  165000
Number of env steps total    827000
Number of rollouts total     0
Train Time (s)               44.99938974203542
(Previous) Eval Time (s)     30.23047690000385
Sample Time (s)              23.217739849351346
Epoch Time (s)               98.44760649139062
Total Train Time (s)         16146.671893704683
Epoch                        164
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:58:25.210964 UTC | [2020_01_10_11_29_18] Iteration #164 | Epoch Duration: 101.12970685958862
2020-01-10 15:58:25.211122 UTC | [2020_01_10_11_29_18] Iteration #164 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.788572
Z variance train             0.012913534
KL Divergence                17.998184
KL Loss                      1.7998184
QF Loss                      701.6591
VF Loss                      129.16817
Policy Loss                  -696.45483
Q Predictions Mean           693.23376
Q Predictions Std            179.2799
Q Predictions Max            872.78796
Q Predictions Min            -20.054888
V Predictions Mean           696.37744
V Predictions Std            177.91226
V Predictions Max            876.7915
V Predictions Min            -20.002209
Log Pis Mean                 -1.3984518
Log Pis Std                  2.4401417
Log Pis Max                  7.2941165
Log Pis Min                  -8.723387
Policy mu Mean               -0.014868335
Policy mu Std                0.50219375
Policy mu Max                2.2246509
Policy mu Min                -2.3264573
Policy log std Mean          -0.8764776
Policy log std Std           0.24062529
Policy log std Max           -0.17576867
Policy log std Min           -2.401998
Z mean eval                  0.8063673
Z variance eval              0.014062035
total_rewards                [1964.38315585  762.16207291 2044.50243661 2023.9318903   413.68739103
  224.75237045  194.36031159  401.53941462 1994.10952241 2046.59657874]
total_rewards_mean           1207.0025144520891
total_rewards_std            820.5560968383339
total_rewards_max            2046.5965787432801
total_rewards_min            194.36031159021556
Number of train steps total  166000
Number of env steps total    832000
Number of rollouts total     0
Train Time (s)               43.95009126421064
(Previous) Eval Time (s)     32.91234273510054
Sample Time (s)              23.299390132538974
Epoch Time (s)               100.16182413185015
Total Train Time (s)         16243.43550027255
Epoch                        165
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:00:01.975932 UTC | [2020_01_10_11_29_18] Iteration #165 | Epoch Duration: 96.7646872997284
2020-01-10 16:00:01.976088 UTC | [2020_01_10_11_29_18] Iteration #165 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.80637044
Z variance train             0.014051139
KL Divergence                18.52415
KL Loss                      1.8524151
QF Loss                      493.99585
VF Loss                      282.7101
Policy Loss                  -695.43854
Q Predictions Mean           691.4274
Q Predictions Std            185.02718
Q Predictions Max            922.5651
Q Predictions Min            46.537567
V Predictions Mean           689.2202
V Predictions Std            184.0724
V Predictions Max            916.1671
V Predictions Min            94.61955
Log Pis Mean                 -1.1892035
Log Pis Std                  2.5302837
Log Pis Max                  7.923154
Log Pis Min                  -9.367975
Policy mu Mean               0.016302496
Policy mu Std                0.5337908
Policy mu Max                2.2058275
Policy mu Min                -1.7006946
Policy log std Mean          -0.8491157
Policy log std Std           0.25267386
Policy log std Max           -0.10179788
Policy log std Min           -2.0333583
Z mean eval                  0.7908738
Z variance eval              0.011624695
total_rewards                [2019.51959611  110.3317671  1777.00781969 1149.7884387  2050.76175373
  404.20927144 2031.03166079   90.93075742 1912.08417456 1981.41557495]
total_rewards_mean           1352.7080814494977
total_rewards_std            797.2861276520077
total_rewards_max            2050.7617537299493
total_rewards_min            90.93075741700204
Number of train steps total  167000
Number of env steps total    837000
Number of rollouts total     0
Train Time (s)               44.0437055551447
(Previous) Eval Time (s)     29.514961254317313
Sample Time (s)              22.67990211257711
Epoch Time (s)               96.23856892203912
Total Train Time (s)         16340.861971078906
Epoch                        166
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:01:39.405025 UTC | [2020_01_10_11_29_18] Iteration #166 | Epoch Duration: 97.4288260936737
2020-01-10 16:01:39.405201 UTC | [2020_01_10_11_29_18] Iteration #166 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.790238
Z variance train             0.011606251
KL Divergence                17.485672
KL Loss                      1.7485672
QF Loss                      513.9016
VF Loss                      84.65891
Policy Loss                  -671.85004
Q Predictions Mean           671.05524
Q Predictions Std            197.03366
Q Predictions Max            884.2352
Q Predictions Min            53.024403
V Predictions Mean           672.2157
V Predictions Std            198.80557
V Predictions Max            876.84863
V Predictions Min            125.33022
Log Pis Mean                 -1.4657147
Log Pis Std                  2.3567212
Log Pis Max                  6.2663093
Log Pis Min                  -7.847281
Policy mu Mean               0.07975579
Policy mu Std                0.50929004
Policy mu Max                2.3717718
Policy mu Min                -1.9540056
Policy log std Mean          -0.8454026
Policy log std Std           0.24198763
Policy log std Max           -0.19774711
Policy log std Min           -1.8018373
Z mean eval                  0.8398555
Z variance eval              0.020428231
total_rewards                [  47.16571977 1969.24259192 1265.52055944 2163.05078293 2161.9476741
 1863.04406739 1793.28134426 2097.24564612 2023.08817753 2089.8441652 ]
total_rewards_mean           1747.3430728665685
total_rewards_std            620.3205989823122
total_rewards_max            2163.0507829250328
total_rewards_min            47.16571977306734
Number of train steps total  168000
Number of env steps total    842000
Number of rollouts total     0
Train Time (s)               43.553867363836616
(Previous) Eval Time (s)     30.704946242738515
Sample Time (s)              23.267759271897376
Epoch Time (s)               97.5265728784725
Total Train Time (s)         16441.344367493875
Epoch                        167
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:03:19.888573 UTC | [2020_01_10_11_29_18] Iteration #167 | Epoch Duration: 100.48324823379517
2020-01-10 16:03:19.888703 UTC | [2020_01_10_11_29_18] Iteration #167 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8414776
Z variance train             0.020394256
KL Divergence                15.965862
KL Loss                      1.5965862
QF Loss                      822.32336
VF Loss                      137.1229
Policy Loss                  -698.9334
Q Predictions Mean           697.6725
Q Predictions Std            186.23318
Q Predictions Max            895.57007
Q Predictions Min            201.99467
V Predictions Mean           703.0461
V Predictions Std            183.10847
V Predictions Max            884.58734
V Predictions Min            217.9452
Log Pis Mean                 -1.530422
Log Pis Std                  2.251757
Log Pis Max                  6.4618397
Log Pis Min                  -7.9958043
Policy mu Mean               0.026916271
Policy mu Std                0.47634497
Policy mu Max                1.7456696
Policy mu Min                -1.5696119
Policy log std Mean          -0.86434436
Policy log std Std           0.24789299
Policy log std Max           -0.20058233
Policy log std Min           -1.9271793
Z mean eval                  0.785504
Z variance eval              0.019649226
total_rewards                [2140.8516663   491.30008656 1083.49658056 2062.30343053 2029.23428377
  518.81621196 2068.14274068 2034.55745488   61.92866745 1912.08121806]
total_rewards_mean           1440.2712340731587
total_rewards_std            772.745744234948
total_rewards_max            2140.8516662953375
total_rewards_min            61.92866744671368
Number of train steps total  169000
Number of env steps total    847000
Number of rollouts total     0
Train Time (s)               43.98149510892108
(Previous) Eval Time (s)     33.66138165304437
Sample Time (s)              23.145551268476993
Epoch Time (s)               100.78842803044245
Total Train Time (s)         16532.9411001415
Epoch                        168
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:04:51.487043 UTC | [2020_01_10_11_29_18] Iteration #168 | Epoch Duration: 91.59823727607727
2020-01-10 16:04:51.487180 UTC | [2020_01_10_11_29_18] Iteration #168 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.78586733
Z variance train             0.019632364
KL Divergence                16.154543
KL Loss                      1.6154543
QF Loss                      406.74045
VF Loss                      123.003426
Policy Loss                  -693.1045
Q Predictions Mean           691.75714
Q Predictions Std            182.25816
Q Predictions Max            860.52124
Q Predictions Min            26.030876
V Predictions Mean           696.95337
V Predictions Std            184.38364
V Predictions Max            872.8577
V Predictions Min            18.479065
Log Pis Mean                 -1.3596997
Log Pis Std                  2.4372575
Log Pis Max                  7.8430996
Log Pis Min                  -12.087759
Policy mu Mean               0.008141796
Policy mu Std                0.48101977
Policy mu Max                1.8278161
Policy mu Min                -1.8690559
Policy log std Mean          -0.8814112
Policy log std Std           0.25647724
Policy log std Max           -0.20922202
Policy log std Min           -2.3618736
Z mean eval                  0.82738936
Z variance eval              0.014862852
total_rewards                [1279.30265235  494.38534425  145.63078287 1235.63596622 1931.22324111
 1943.59549761 2105.13650444 2181.30540834 1725.33642215 1461.85874624]
total_rewards_mean           1450.3410565577121
total_rewards_std            648.4474784547465
total_rewards_max            2181.3054083405596
total_rewards_min            145.63078287357982
Number of train steps total  170000
Number of env steps total    852000
Number of rollouts total     0
Train Time (s)               43.735144320875406
(Previous) Eval Time (s)     24.47093474213034
Sample Time (s)              22.45389640890062
Epoch Time (s)               90.65997547190636
Total Train Time (s)         16631.03199125221
Epoch                        169
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:06:29.579256 UTC | [2020_01_10_11_29_18] Iteration #169 | Epoch Duration: 98.0919725894928
2020-01-10 16:06:29.579391 UTC | [2020_01_10_11_29_18] Iteration #169 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.82732534
Z variance train             0.014842482
KL Divergence                16.944366
KL Loss                      1.6944367
QF Loss                      1659.8702
VF Loss                      59.283546
Policy Loss                  -730.67206
Q Predictions Mean           728.0973
Q Predictions Std            161.5276
Q Predictions Max            887.50684
Q Predictions Min            215.09465
V Predictions Mean           730.0152
V Predictions Std            161.71532
V Predictions Max            886.8988
V Predictions Min            211.34221
Log Pis Mean                 -1.2593529
Log Pis Std                  2.2875667
Log Pis Max                  5.4809256
Log Pis Min                  -7.1707344
Policy mu Mean               0.04380881
Policy mu Std                0.5327111
Policy mu Max                2.4646325
Policy mu Min                -1.9928962
Policy log std Mean          -0.8495712
Policy log std Std           0.2294954
Policy log std Max           -0.18753278
Policy log std Min           -1.7600431
Z mean eval                  0.81265926
Z variance eval              0.017306792
total_rewards                [1904.99527733  118.16425527 1606.9149265  1883.79503097 1448.58142416
  335.5637085   232.21200021 1922.85124252 1268.28024741  724.39941533]
total_rewards_mean           1144.5757528213085
total_rewards_std            690.5687739717489
total_rewards_max            1922.8512425228946
total_rewards_min            118.16425526821108
Number of train steps total  171000
Number of env steps total    857000
Number of rollouts total     0
Train Time (s)               44.05970183480531
(Previous) Eval Time (s)     31.90270448476076
Sample Time (s)              22.79554585646838
Epoch Time (s)               98.75795217603445
Total Train Time (s)         16727.45441981079
Epoch                        170
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:08:06.005942 UTC | [2020_01_10_11_29_18] Iteration #170 | Epoch Duration: 96.42642879486084
2020-01-10 16:08:06.006153 UTC | [2020_01_10_11_29_18] Iteration #170 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.81291693
Z variance train             0.017275035
KL Divergence                17.088028
KL Loss                      1.7088028
QF Loss                      426.0669
VF Loss                      72.53186
Policy Loss                  -703.58325
Q Predictions Mean           702.38855
Q Predictions Std            186.86157
Q Predictions Max            884.56274
Q Predictions Min            -4.9484076
V Predictions Mean           702.52
V Predictions Std            187.06528
V Predictions Max            881.03705
V Predictions Min            -24.324366
Log Pis Mean                 -1.4887702
Log Pis Std                  2.7549496
Log Pis Max                  9.840397
Log Pis Min                  -9.7457
Policy mu Mean               0.0081298575
Policy mu Std                0.5326899
Policy mu Max                2.1126091
Policy mu Min                -2.5144212
Policy log std Mean          -0.85890186
Policy log std Std           0.26798886
Policy log std Max           -0.108448684
Policy log std Min           -2.1702302
Z mean eval                  0.8063501
Z variance eval              0.015148205
total_rewards                [2097.87128032 1242.11095929   45.78106039 2109.35970112 2085.6537065
  870.012677   1499.86571069 1454.18380208 2015.06293941 1256.54452748]
total_rewards_mean           1467.6446364283206
total_rewards_std            629.7693173744764
total_rewards_max            2109.3597011154243
total_rewards_min            45.78106038651485
Number of train steps total  172000
Number of env steps total    862000
Number of rollouts total     0
Train Time (s)               43.68373206676915
(Previous) Eval Time (s)     29.57091706804931
Sample Time (s)              23.132016472052783
Epoch Time (s)               96.38666560687125
Total Train Time (s)         16824.03019427508
Epoch                        171
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:09:42.580476 UTC | [2020_01_10_11_29_18] Iteration #171 | Epoch Duration: 96.57417225837708
2020-01-10 16:09:42.580622 UTC | [2020_01_10_11_29_18] Iteration #171 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8095061
Z variance train             0.014898482
KL Divergence                17.376972
KL Loss                      1.7376972
QF Loss                      474.32526
VF Loss                      299.49957
Policy Loss                  -732.465
Q Predictions Mean           728.10394
Q Predictions Std            160.36838
Q Predictions Max            882.27454
Q Predictions Min            195.60643
V Predictions Mean           719.6198
V Predictions Std            154.40923
V Predictions Max            865.9157
V Predictions Min            202.53374
Log Pis Mean                 -0.8814196
Log Pis Std                  2.4441795
Log Pis Max                  7.3145304
Log Pis Min                  -7.0604835
Policy mu Mean               -0.014985777
Policy mu Std                0.5369968
Policy mu Max                2.1723032
Policy mu Min                -1.987912
Policy log std Mean          -0.9025814
Policy log std Std           0.244877
Policy log std Max           -0.25714815
Policy log std Min           -1.8637877
Z mean eval                  0.80828464
Z variance eval              0.009856262
total_rewards                [1391.16023321  379.75362524 1888.61712424 1971.72025181 2038.21984762
  688.55335979 1190.68998617 2148.62152996  429.84825761 1900.75353202]
total_rewards_mean           1402.7937747677945
total_rewards_std            656.97699892729
total_rewards_max            2148.6215299627424
total_rewards_min            379.75362524445393
Number of train steps total  173000
Number of env steps total    867000
Number of rollouts total     0
Train Time (s)               43.48479572730139
(Previous) Eval Time (s)     29.758195244241506
Sample Time (s)              23.483538545202464
Epoch Time (s)               96.72652951674536
Total Train Time (s)         16920.505576359574
Epoch                        172
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:11:19.062812 UTC | [2020_01_10_11_29_18] Iteration #172 | Epoch Duration: 96.4820671081543
2020-01-10 16:11:19.062989 UTC | [2020_01_10_11_29_18] Iteration #172 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8074619
Z variance train             0.009846536
KL Divergence                18.513874
KL Loss                      1.8513874
QF Loss                      889.0529
VF Loss                      113.99044
Policy Loss                  -708.4372
Q Predictions Mean           706.46515
Q Predictions Std            181.27731
Q Predictions Max            900.6581
Q Predictions Min            49.578327
V Predictions Mean           710.68384
V Predictions Std            175.45033
V Predictions Max            884.20435
V Predictions Min            42.530624
Log Pis Mean                 -1.2525895
Log Pis Std                  2.353248
Log Pis Max                  6.099335
Log Pis Min                  -10.110352
Policy mu Mean               -0.012500192
Policy mu Std                0.52496886
Policy mu Max                1.6774251
Policy mu Min                -2.113183
Policy log std Mean          -0.89927137
Policy log std Std           0.23667333
Policy log std Max           -0.2509429
Policy log std Min           -1.929452
Z mean eval                  0.8183775
Z variance eval              0.011531001
total_rewards                [2134.44967935 2031.22560387  324.64450047 1436.70203168 1106.90042704
 1926.44966946 1244.42674603 2164.24326274  241.49061305 2152.3804196 ]
total_rewards_mean           1476.2912953312466
total_rewards_std            701.2091469828381
total_rewards_max            2164.2432627435314
total_rewards_min            241.4906130533945
Number of train steps total  174000
Number of env steps total    872000
Number of rollouts total     0
Train Time (s)               43.97985739028081
(Previous) Eval Time (s)     29.513452311977744
Sample Time (s)              22.69378671096638
Epoch Time (s)               96.18709641322494
Total Train Time (s)         17011.274896238465
Epoch                        173
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:12:49.833722 UTC | [2020_01_10_11_29_18] Iteration #173 | Epoch Duration: 90.77057242393494
2020-01-10 16:12:49.833969 UTC | [2020_01_10_11_29_18] Iteration #173 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8200393
Z variance train             0.011495508
KL Divergence                18.113836
KL Loss                      1.8113836
QF Loss                      357.48355
VF Loss                      94.52711
Policy Loss                  -731.676
Q Predictions Mean           732.67444
Q Predictions Std            163.35396
Q Predictions Max            892.96515
Q Predictions Min            209.29083
V Predictions Mean           736.802
V Predictions Std            162.64217
V Predictions Max            897.26794
V Predictions Min            215.61188
Log Pis Mean                 -1.2453057
Log Pis Std                  2.2659016
Log Pis Max                  5.6664925
Log Pis Min                  -8.706469
Policy mu Mean               0.058442302
Policy mu Std                0.53125226
Policy mu Max                1.8506737
Policy mu Min                -1.9604193
Policy log std Mean          -0.9012984
Policy log std Std           0.23867771
Policy log std Max           -0.20144325
Policy log std Min           -2.0637736
Z mean eval                  0.7920454
Z variance eval              0.011971171
total_rewards                [2122.44958764  638.72039786  -47.70579648  -29.51028473 1492.94303803
 1062.75981731 2245.6927411  1362.57682261  269.13534039 2085.54429407]
total_rewards_mean           1120.260595779711
total_rewards_std            839.4094553347513
total_rewards_max            2245.6927410981884
total_rewards_min            -47.70579647868392
Number of train steps total  175000
Number of env steps total    877000
Number of rollouts total     0
Train Time (s)               43.203694372903556
(Previous) Eval Time (s)     24.096684590913355
Sample Time (s)              23.093861571047455
Epoch Time (s)               90.39424053486437
Total Train Time (s)         17110.91855160892
Epoch                        174
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:14:29.479223 UTC | [2020_01_10_11_29_18] Iteration #174 | Epoch Duration: 99.64507269859314
2020-01-10 16:14:29.479388 UTC | [2020_01_10_11_29_18] Iteration #174 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.79220605
Z variance train             0.011973975
KL Divergence                18.11884
KL Loss                      1.8118839
QF Loss                      441.79987
VF Loss                      124.59189
Policy Loss                  -706.9311
Q Predictions Mean           704.78503
Q Predictions Std            199.49939
Q Predictions Max            910.8249
Q Predictions Min            -60.335583
V Predictions Mean           708.5554
V Predictions Std            195.78362
V Predictions Max            905.1251
V Predictions Min            23.52854
Log Pis Mean                 -1.2994643
Log Pis Std                  2.66759
Log Pis Max                  13.669532
Log Pis Min                  -11.068846
Policy mu Mean               0.006784655
Policy mu Std                0.5254725
Policy mu Max                2.2006438
Policy mu Min                -2.8597958
Policy log std Mean          -0.877413
Policy log std Std           0.2580119
Policy log std Max           -0.25244924
Policy log std Min           -2.1861923
Z mean eval                  0.8211915
Z variance eval              0.022453686
total_rewards                [1968.30804567 2134.73915183 2297.74238741 2045.780546   2155.15388477
 2116.68472518 2178.63032712  332.85359173 2176.12639669 2375.90933897]
total_rewards_mean           1978.1928395365808
total_rewards_std            559.1468694659382
total_rewards_max            2375.9093389657046
total_rewards_min            332.85359173121657
Number of train steps total  176000
Number of env steps total    882000
Number of rollouts total     0
Train Time (s)               43.015551327262074
(Previous) Eval Time (s)     33.347285605967045
Sample Time (s)              20.589847323019058
Epoch Time (s)               96.95268425624818
Total Train Time (s)         17206.84266637033
Epoch                        175
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:16:05.406049 UTC | [2020_01_10_11_29_18] Iteration #175 | Epoch Duration: 95.92653346061707
2020-01-10 16:16:05.406226 UTC | [2020_01_10_11_29_18] Iteration #175 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8222144
Z variance train             0.022511205
KL Divergence                16.955973
KL Loss                      1.6955973
QF Loss                      801.0291
VF Loss                      190.16791
Policy Loss                  -703.37286
Q Predictions Mean           700.58685
Q Predictions Std            183.59674
Q Predictions Max            883.71674
Q Predictions Min            -11.742198
V Predictions Mean           713.49634
V Predictions Std            183.50716
V Predictions Max            892.5661
V Predictions Min            30.833067
Log Pis Mean                 -1.0100049
Log Pis Std                  2.3277333
Log Pis Max                  7.22896
Log Pis Min                  -8.126787
Policy mu Mean               0.04400267
Policy mu Std                0.5287843
Policy mu Max                2.1071281
Policy mu Min                -1.7461786
Policy log std Mean          -0.90340674
Policy log std Std           0.25185975
Policy log std Max           -0.264305
Policy log std Min           -1.7711003
Z mean eval                  0.7920062
Z variance eval              0.012017904
total_rewards                [2121.09311777 1966.47340146 2080.95110631 2130.82624017 2209.75504328
 2201.1138339  2073.54036201 1720.11522407 2087.46510944 2113.68705329]
total_rewards_mean           2070.5020491711607
total_rewards_std            133.60886565104914
total_rewards_max            2209.7550432836974
total_rewards_min            1720.1152240695592
Number of train steps total  177000
Number of env steps total    887000
Number of rollouts total     0
Train Time (s)               43.978044578805566
(Previous) Eval Time (s)     32.32089823624119
Sample Time (s)              21.536933100316674
Epoch Time (s)               97.83587591536343
Total Train Time (s)         17305.95933598373
Epoch                        176
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:17:44.528499 UTC | [2020_01_10_11_29_18] Iteration #176 | Epoch Duration: 99.12209606170654
2020-01-10 16:17:44.528786 UTC | [2020_01_10_11_29_18] Iteration #176 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7922436
Z variance train             0.012005868
KL Divergence                18.11169
KL Loss                      1.811169
QF Loss                      478.59735
VF Loss                      124.12882
Policy Loss                  -720.4397
Q Predictions Mean           717.1874
Q Predictions Std            184.29536
Q Predictions Max            896.2339
Q Predictions Min            41.55807
V Predictions Mean           714.1118
V Predictions Std            181.73996
V Predictions Max            880.8411
V Predictions Min            -4.6766315
Log Pis Mean                 -1.0554047
Log Pis Std                  2.454969
Log Pis Max                  6.3208985
Log Pis Min                  -10.056462
Policy mu Mean               -0.015437609
Policy mu Std                0.5110166
Policy mu Max                1.5563424
Policy mu Min                -1.9576595
Policy log std Mean          -0.89684844
Policy log std Std           0.24447137
Policy log std Max           -0.21552205
Policy log std Min           -2.0751894
Z mean eval                  0.7943512
Z variance eval              0.012254353
total_rewards                [1686.14123401 1888.59263276  464.21921289 2071.09337279 2122.81522586
 1328.17914915  528.7093632  2022.70637859 2196.28692203 2119.98300384]
total_rewards_mean           1642.872649512338
total_rewards_std            623.1981551153407
total_rewards_max            2196.286922028201
total_rewards_min            464.2192128921183
Number of train steps total  178000
Number of env steps total    892000
Number of rollouts total     0
Train Time (s)               44.42121811211109
(Previous) Eval Time (s)     33.60687121376395
Sample Time (s)              23.31935904547572
Epoch Time (s)               101.34744837135077
Total Train Time (s)         17399.836502173916
Epoch                        177
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:19:18.406372 UTC | [2020_01_10_11_29_18] Iteration #177 | Epoch Duration: 93.87737131118774
2020-01-10 16:19:18.406543 UTC | [2020_01_10_11_29_18] Iteration #177 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7946459
Z variance train             0.0122227315
KL Divergence                18.002628
KL Loss                      1.8002628
QF Loss                      539.5405
VF Loss                      66.60659
Policy Loss                  -712.1035
Q Predictions Mean           711.6563
Q Predictions Std            191.16037
Q Predictions Max            887.7716
Q Predictions Min            -15.73775
V Predictions Mean           712.3672
V Predictions Std            189.19345
V Predictions Max            883.37537
V Predictions Min            15.530467
Log Pis Mean                 -1.1950598
Log Pis Std                  2.4406893
Log Pis Max                  6.6356907
Log Pis Min                  -9.002065
Policy mu Mean               0.031709105
Policy mu Std                0.51605225
Policy mu Max                1.7217664
Policy mu Min                -1.7156408
Policy log std Mean          -0.8659269
Policy log std Std           0.25171348
Policy log std Max           -0.12690517
Policy log std Min           -1.9518516
Z mean eval                  0.8280967
Z variance eval              0.019692093
total_rewards                [2161.99911251 1624.47380032 1407.783096   1386.65479661 1735.82229321
  511.6747341  1982.82856064  680.50001004 1975.95210233 2142.79230862]
total_rewards_mean           1561.0480814373432
total_rewards_std            549.05682360057
total_rewards_max            2161.9991125146394
total_rewards_min            511.674734098755
Number of train steps total  179000
Number of env steps total    897000
Number of rollouts total     0
Train Time (s)               44.181741224601865
(Previous) Eval Time (s)     26.136568586807698
Sample Time (s)              22.759011543821543
Epoch Time (s)               93.0773213552311
Total Train Time (s)         17493.304509085603
Epoch                        178
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:20:51.876362 UTC | [2020_01_10_11_29_18] Iteration #178 | Epoch Duration: 93.4696843624115
2020-01-10 16:20:51.876529 UTC | [2020_01_10_11_29_18] Iteration #178 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.82451093
Z variance train             0.019691566
KL Divergence                16.468037
KL Loss                      1.6468037
QF Loss                      847.64484
VF Loss                      86.94693
Policy Loss                  -728.49805
Q Predictions Mean           727.66125
Q Predictions Std            167.27686
Q Predictions Max            912.0798
Q Predictions Min            -29.785158
V Predictions Mean           734.4667
V Predictions Std            167.2826
V Predictions Max            914.91486
V Predictions Min            -1.3325701
Log Pis Mean                 -1.1275439
Log Pis Std                  2.5850866
Log Pis Max                  9.053443
Log Pis Min                  -8.357423
Policy mu Mean               0.03274358
Policy mu Std                0.5621833
Policy mu Max                2.5088377
Policy mu Min                -2.0791636
Policy log std Mean          -0.8690927
Policy log std Std           0.23734136
Policy log std Max           -0.08105093
Policy log std Min           -1.7918589
Z mean eval                  0.8239063
Z variance eval              0.02916398
total_rewards                [1558.44680792  178.98191481  554.30631382 2077.04513716  689.86499245
  548.99186291 2223.95216646 1577.75195334 2181.64523972  952.45056854]
total_rewards_mean           1254.343695713022
total_rewards_std            723.0276741845965
total_rewards_max            2223.9521664591266
total_rewards_min            178.98191481454234
Number of train steps total  180000
Number of env steps total    902000
Number of rollouts total     0
Train Time (s)               44.021604747045785
(Previous) Eval Time (s)     26.52866347320378
Sample Time (s)              21.079445915762335
Epoch Time (s)               91.6297141360119
Total Train Time (s)         17584.79772240389
Epoch                        179
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:22:23.376420 UTC | [2020_01_10_11_29_18] Iteration #179 | Epoch Duration: 91.4997169971466
2020-01-10 16:22:23.376739 UTC | [2020_01_10_11_29_18] Iteration #179 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8228936
Z variance train             0.029275779
KL Divergence                15.640534
KL Loss                      1.5640534
QF Loss                      411.13943
VF Loss                      110.91874
Policy Loss                  -735.27496
Q Predictions Mean           732.8685
Q Predictions Std            171.20273
Q Predictions Max            893.77216
Q Predictions Min            -84.040695
V Predictions Mean           735.9104
V Predictions Std            170.18597
V Predictions Max            891.9108
V Predictions Min            7.6750107
Log Pis Mean                 -1.3947544
Log Pis Std                  2.2563343
Log Pis Max                  6.109889
Log Pis Min                  -6.69741
Policy mu Mean               0.051008046
Policy mu Std                0.52281547
Policy mu Max                2.272093
Policy mu Min                -2.0759206
Policy log std Mean          -0.85596484
Policy log std Std           0.2337229
Policy log std Max           -0.21691906
Policy log std Min           -1.8155003
Z mean eval                  0.8234377
Z variance eval              0.03550066
total_rewards                [ 643.31856535 1920.78969217  358.96002696  137.30652621 2045.76090138
 2122.05741192 1966.77181507 1963.99777454 2023.14409096 1286.08358663]
total_rewards_mean           1446.8190391205412
total_rewards_std            740.2034073307999
total_rewards_max            2122.057411923316
total_rewards_min            137.30652621230678
Number of train steps total  181000
Number of env steps total    907000
Number of rollouts total     0
Train Time (s)               43.646964664105326
(Previous) Eval Time (s)     26.398422688711435
Sample Time (s)              22.678311680443585
Epoch Time (s)               92.72369903326035
Total Train Time (s)         17682.848567662295
Epoch                        180
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:24:01.427425 UTC | [2020_01_10_11_29_18] Iteration #180 | Epoch Duration: 98.05046606063843
2020-01-10 16:24:01.427598 UTC | [2020_01_10_11_29_18] Iteration #180 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.82062006
Z variance train             0.035619073
KL Divergence                15.551406
KL Loss                      1.5551406
QF Loss                      391.217
VF Loss                      81.24094
Policy Loss                  -751.6166
Q Predictions Mean           750.1752
Q Predictions Std            179.14867
Q Predictions Max            921.79474
Q Predictions Min            34.016357
V Predictions Mean           749.8596
V Predictions Std            179.66493
V Predictions Max            921.88574
V Predictions Min            48.786472
Log Pis Mean                 -1.0967884
Log Pis Std                  2.5198743
Log Pis Max                  9.137902
Log Pis Min                  -6.7916603
Policy mu Mean               0.06219621
Policy mu Std                0.55786926
Policy mu Max                1.8646773
Policy mu Min                -2.250758
Policy log std Mean          -0.8413742
Policy log std Std           0.24193731
Policy log std Max           -0.17398608
Policy log std Min           -2.017688
Z mean eval                  0.82315445
Z variance eval              0.030421391
total_rewards                [2301.84386568 2077.6015583   255.70041247 2169.97474986 2211.42846827
 2011.69295955 1327.12915485  597.14490123 2045.38515725 2327.99055356]
total_rewards_mean           1732.5891781015714
total_rewards_std            709.1369861796078
total_rewards_max            2327.9905535639277
total_rewards_min            255.7004124676409
Number of train steps total  182000
Number of env steps total    912000
Number of rollouts total     0
Train Time (s)               44.26675941515714
(Previous) Eval Time (s)     31.724959476850927
Sample Time (s)              21.04978036787361
Epoch Time (s)               97.04149925988168
Total Train Time (s)         17779.350553118624
Epoch                        181
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:25:37.931737 UTC | [2020_01_10_11_29_18] Iteration #181 | Epoch Duration: 96.50400805473328
2020-01-10 16:25:37.931912 UTC | [2020_01_10_11_29_18] Iteration #181 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8233104
Z variance train             0.030310685
KL Divergence                15.20033
KL Loss                      1.520033
QF Loss                      385.8428
VF Loss                      44.418625
Policy Loss                  -748.21826
Q Predictions Mean           747.5665
Q Predictions Std            177.48674
Q Predictions Max            918.96375
Q Predictions Min            -7.250176
V Predictions Mean           747.72284
V Predictions Std            177.29129
V Predictions Max            905.73706
V Predictions Min            52.69295
Log Pis Mean                 -1.342356
Log Pis Std                  2.4407585
Log Pis Max                  8.415262
Log Pis Min                  -8.407339
Policy mu Mean               0.05499814
Policy mu Std                0.50153226
Policy mu Max                1.9178317
Policy mu Min                -1.8453522
Policy log std Mean          -0.8824198
Policy log std Std           0.25016147
Policy log std Max           -0.19707304
Policy log std Min           -2.436473
Z mean eval                  0.8476982
Z variance eval              0.037864387
total_rewards                [2223.44077778 2110.08516331 2144.39140157 2235.97154778 2105.55582929
 1141.0605879  2139.89780448 2306.5139558  2332.22192291 1214.55973676]
total_rewards_mean           1995.3698727586761
total_rewards_std            415.70308544694075
total_rewards_max            2332.221922911317
total_rewards_min            1141.0605879049049
Number of train steps total  183000
Number of env steps total    917000
Number of rollouts total     0
Train Time (s)               43.819368046242744
(Previous) Eval Time (s)     31.187217731960118
Sample Time (s)              22.863201359752566
Epoch Time (s)               97.86978713795543
Total Train Time (s)         17880.37126282323
Epoch                        182
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:27:18.958888 UTC | [2020_01_10_11_29_18] Iteration #182 | Epoch Duration: 101.02677297592163
2020-01-10 16:27:18.959198 UTC | [2020_01_10_11_29_18] Iteration #182 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8507718
Z variance train             0.037908323
KL Divergence                15.572891
KL Loss                      1.5572891
QF Loss                      664.7883
VF Loss                      168.18741
Policy Loss                  -727.5993
Q Predictions Mean           724.82056
Q Predictions Std            190.6009
Q Predictions Max            938.55634
Q Predictions Min            188.6109
V Predictions Mean           725.1692
V Predictions Std            188.20667
V Predictions Max            924.0318
V Predictions Min            203.42058
Log Pis Mean                 -1.1887363
Log Pis Std                  2.5055501
Log Pis Max                  6.038706
Log Pis Min                  -7.653847
Policy mu Mean               -0.015134185
Policy mu Std                0.5392454
Policy mu Max                2.5661993
Policy mu Min                -1.987187
Policy log std Mean          -0.8655064
Policy log std Std           0.26061276
Policy log std Max           -0.15568519
Policy log std Min           -1.7823329
Z mean eval                  0.8424851
Z variance eval              0.024281573
total_rewards                [2038.14349843 2043.11963803  172.67965012 2021.17005143 1485.37609564
  908.00393847  316.83773344 2264.30394343 1703.47204472 2139.16887041]
total_rewards_mean           1509.2275464131262
total_rewards_std            734.9671968172576
total_rewards_max            2264.3039434337506
total_rewards_min            172.6796501235179
Number of train steps total  184000
Number of env steps total    922000
Number of rollouts total     0
Train Time (s)               44.131707932800055
(Previous) Eval Time (s)     34.3439360470511
Sample Time (s)              22.899183842353523
Epoch Time (s)               101.37482782220468
Total Train Time (s)         17973.669098774903
Epoch                        183
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:28:52.257520 UTC | [2020_01_10_11_29_18] Iteration #183 | Epoch Duration: 93.29809951782227
2020-01-10 16:28:52.257691 UTC | [2020_01_10_11_29_18] Iteration #183 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.84741974
Z variance train             0.024100346
KL Divergence                16.22599
KL Loss                      1.622599
QF Loss                      440.7865
VF Loss                      119.610344
Policy Loss                  -735.7886
Q Predictions Mean           733.50275
Q Predictions Std            170.26114
Q Predictions Max            896.14185
Q Predictions Min            177.70497
V Predictions Mean           741.00916
V Predictions Std            171.00385
V Predictions Max            904.3109
V Predictions Min            196.69295
Log Pis Mean                 -0.9898583
Log Pis Std                  2.5296795
Log Pis Max                  7.7845774
Log Pis Min                  -8.606519
Policy mu Mean               6.412121e-05
Policy mu Std                0.53341705
Policy mu Max                1.7980133
Policy mu Min                -1.964287
Policy log std Mean          -0.8918908
Policy log std Std           0.2523145
Policy log std Max           -0.16989714
Policy log std Min           -2.4043229
Z mean eval                  0.84100056
Z variance eval              0.027722692
total_rewards                [1860.20458522 1287.31039052 2068.23292373  870.84520184  267.22676305
 2064.40471334 2222.65136629 2147.50130918 1515.23578704 1133.22290033]
total_rewards_mean           1543.6835940528142
total_rewards_std            615.5606478469267
total_rewards_max            2222.6513662921434
total_rewards_min            267.2267630534072
Number of train steps total  185000
Number of env steps total    927000
Number of rollouts total     0
Train Time (s)               44.123071976937354
(Previous) Eval Time (s)     26.26698519801721
Sample Time (s)              24.20978792756796
Epoch Time (s)               94.59984510252252
Total Train Time (s)         18067.418810911477
Epoch                        184
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:30:26.009372 UTC | [2020_01_10_11_29_18] Iteration #184 | Epoch Duration: 93.75154829025269
2020-01-10 16:30:26.009545 UTC | [2020_01_10_11_29_18] Iteration #184 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8416149
Z variance train             0.027739385
KL Divergence                16.742027
KL Loss                      1.6742028
QF Loss                      403.16098
VF Loss                      82.92573
Policy Loss                  -734.74585
Q Predictions Mean           733.4532
Q Predictions Std            186.29175
Q Predictions Max            927.9046
Q Predictions Min            210.75803
V Predictions Mean           738.5176
V Predictions Std            185.31973
V Predictions Max            929.96545
V Predictions Min            212.77818
Log Pis Mean                 -1.1439986
Log Pis Std                  2.7384315
Log Pis Max                  9.730127
Log Pis Min                  -7.963358
Policy mu Mean               0.03439627
Policy mu Std                0.55989844
Policy mu Max                2.6578927
Policy mu Min                -2.484107
Policy log std Mean          -0.87333107
Policy log std Std           0.24825092
Policy log std Max           -0.08976501
Policy log std Min           -1.7584177
Z mean eval                  0.83270633
Z variance eval              0.027206028
total_rewards                [2185.58799709 2260.75474248 2172.97071497 2120.09788099 1011.46915297
  897.52205512 2000.40144145 2210.92347923 2200.65095135 2170.71177118]
total_rewards_mean           1923.1090186819627
total_rewards_std            489.3055407810388
total_rewards_max            2260.7547424798818
total_rewards_min            897.5220551162404
Number of train steps total  186000
Number of env steps total    932000
Number of rollouts total     0
Train Time (s)               44.519244147930294
(Previous) Eval Time (s)     25.418416460044682
Sample Time (s)              22.712753606960177
Epoch Time (s)               92.65041421493515
Total Train Time (s)         18164.986770372372
Epoch                        185
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:32:03.583368 UTC | [2020_01_10_11_29_18] Iteration #185 | Epoch Duration: 97.57365894317627
2020-01-10 16:32:03.583639 UTC | [2020_01_10_11_29_18] Iteration #185 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8330533
Z variance train             0.027056688
KL Divergence                16.942057
KL Loss                      1.6942056
QF Loss                      541.852
VF Loss                      92.4779
Policy Loss                  -743.99066
Q Predictions Mean           741.6045
Q Predictions Std            187.02937
Q Predictions Max            934.43604
Q Predictions Min            13.236825
V Predictions Mean           746.26355
V Predictions Std            185.6082
V Predictions Max            935.2135
V Predictions Min            5.1767745
Log Pis Mean                 -1.0861491
Log Pis Std                  2.5923843
Log Pis Max                  9.134354
Log Pis Min                  -7.727783
Policy mu Mean               -0.013283571
Policy mu Std                0.5463234
Policy mu Max                1.9967295
Policy mu Min                -1.9427207
Policy log std Mean          -0.8911898
Policy log std Std           0.26965472
Policy log std Max           -0.16440034
Policy log std Min           -2.2608805
Z mean eval                  0.8358647
Z variance eval              0.026129693
total_rewards                [  42.47441537 2312.16497378 2313.07765898  650.08409216 2251.00534162
 2268.8235927   802.47084936  844.06866857 1780.40367615 2125.82202835]
total_rewards_mean           1539.039529704727
total_rewards_std            818.191619105469
total_rewards_max            2313.077658978963
total_rewards_min            42.47441537486017
Number of train steps total  187000
Number of env steps total    937000
Number of rollouts total     0
Train Time (s)               44.172661940101534
(Previous) Eval Time (s)     30.341388873755932
Sample Time (s)              23.317361538298428
Epoch Time (s)               97.8314123521559
Total Train Time (s)         18265.52330445079
Epoch                        186
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:33:44.122047 UTC | [2020_01_10_11_29_18] Iteration #186 | Epoch Duration: 100.53822612762451
2020-01-10 16:33:44.122187 UTC | [2020_01_10_11_29_18] Iteration #186 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.83604336
Z variance train             0.026242161
KL Divergence                17.33936
KL Loss                      1.733936
QF Loss                      390.84753
VF Loss                      148.46823
Policy Loss                  -747.9411
Q Predictions Mean           746.6553
Q Predictions Std            178.5746
Q Predictions Max            942.8547
Q Predictions Min            -2.0773559
V Predictions Mean           745.33057
V Predictions Std            180.1113
V Predictions Max            940.4325
V Predictions Min            26.04124
Log Pis Mean                 -1.0691938
Log Pis Std                  2.4482768
Log Pis Max                  7.5128937
Log Pis Min                  -6.5512676
Policy mu Mean               -0.011529431
Policy mu Std                0.52952653
Policy mu Max                2.182409
Policy mu Min                -1.9108782
Policy log std Mean          -0.88579226
Policy log std Std           0.2531052
Policy log std Max           -0.18381941
Policy log std Min           -2.137693
Z mean eval                  0.8223586
Z variance eval              0.03841381
total_rewards                [2319.26153639 2317.95218144 2208.26096893 2227.21210177 2261.05345926
 1962.5631169  2198.80897031 1224.99131469 2178.99840761  655.03031456]
total_rewards_mean           1955.4132371868259
total_rewards_std            531.8681675906876
total_rewards_max            2319.2615363918603
total_rewards_min            655.0303145605659
Number of train steps total  188000
Number of env steps total    942000
Number of rollouts total     0
Train Time (s)               43.97491471283138
(Previous) Eval Time (s)     33.04797622608021
Sample Time (s)              22.785338207613677
Epoch Time (s)               99.80822914652526
Total Train Time (s)         18365.46927328827
Epoch                        187
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:35:24.071957 UTC | [2020_01_10_11_29_18] Iteration #187 | Epoch Duration: 99.94962000846863
2020-01-10 16:35:24.072283 UTC | [2020_01_10_11_29_18] Iteration #187 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.82154167
Z variance train             0.038292307
KL Divergence                17.53019
KL Loss                      1.753019
QF Loss                      449.98788
VF Loss                      70.9824
Policy Loss                  -748.68176
Q Predictions Mean           746.35614
Q Predictions Std            185.20328
Q Predictions Max            932.3998
Q Predictions Min            -15.477946
V Predictions Mean           753.7028
V Predictions Std            182.22002
V Predictions Max            932.00977
V Predictions Min            20.014858
Log Pis Mean                 -1.358021
Log Pis Std                  2.516325
Log Pis Max                  5.7403593
Log Pis Min                  -8.473537
Policy mu Mean               0.056555558
Policy mu Std                0.5134969
Policy mu Max                1.784377
Policy mu Min                -1.772271
Policy log std Mean          -0.8761961
Policy log std Std           0.23841865
Policy log std Max           -0.016268253
Policy log std Min           -1.786534
Z mean eval                  0.8372687
Z variance eval              0.027741706
total_rewards                [2108.45547417  188.33652411 2051.08512246 1784.37769439 2173.34901121
 2379.60804071 1759.66584135  413.48592763 1128.51449607  348.88812731]
total_rewards_mean           1433.576625940233
total_rewards_std            798.0747067131423
total_rewards_max            2379.6080407149652
total_rewards_min            188.3365241104603
Number of train steps total  189000
Number of env steps total    947000
Number of rollouts total     0
Train Time (s)               44.81299787713215
(Previous) Eval Time (s)     33.189097200054675
Sample Time (s)              23.528137547895312
Epoch Time (s)               101.53023262508214
Total Train Time (s)         18457.22639075108
Epoch                        188
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:36:55.831553 UTC | [2020_01_10_11_29_18] Iteration #188 | Epoch Duration: 91.75908303260803
2020-01-10 16:36:55.831744 UTC | [2020_01_10_11_29_18] Iteration #188 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.83776027
Z variance train             0.027750019
KL Divergence                17.176298
KL Loss                      1.7176298
QF Loss                      299.68887
VF Loss                      107.03402
Policy Loss                  -753.9038
Q Predictions Mean           752.56323
Q Predictions Std            185.75536
Q Predictions Max            960.8414
Q Predictions Min            202.43965
V Predictions Mean           762.05896
V Predictions Std            184.69098
V Predictions Max            963.6018
V Predictions Min            208.13568
Log Pis Mean                 -1.1854222
Log Pis Std                  2.3499782
Log Pis Max                  6.0006037
Log Pis Min                  -8.470121
Policy mu Mean               -0.011045868
Policy mu Std                0.536055
Policy mu Max                1.8120435
Policy mu Min                -1.825342
Policy log std Mean          -0.86485946
Policy log std Std           0.2517661
Policy log std Max           -0.22763675
Policy log std Min           -1.7374878
Z mean eval                  0.9151514
Z variance eval              0.032987617
total_rewards                [ 884.93561289 2202.18665951 1904.15514046 2053.80193643 2046.7821674
 2005.30706865  502.2323383  1597.96159169  440.30496942 1228.34582323]
total_rewards_mean           1486.6013307990181
total_rewards_std            639.9847909181216
total_rewards_max            2202.1866595059714
total_rewards_min            440.3049694194933
Number of train steps total  190000
Number of env steps total    952000
Number of rollouts total     0
Train Time (s)               43.743010038044304
(Previous) Eval Time (s)     23.417693859897554
Sample Time (s)              22.599885079078376
Epoch Time (s)               89.76058897702023
Total Train Time (s)         18549.80312613165
Epoch                        189
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:38:28.409447 UTC | [2020_01_10_11_29_18] Iteration #189 | Epoch Duration: 92.57756662368774
2020-01-10 16:38:28.409591 UTC | [2020_01_10_11_29_18] Iteration #189 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91285974
Z variance train             0.033039916
KL Divergence                15.551871
KL Loss                      1.5551871
QF Loss                      468.92737
VF Loss                      133.199
Policy Loss                  -761.3047
Q Predictions Mean           756.1848
Q Predictions Std            185.14561
Q Predictions Max            952.7884
Q Predictions Min            66.19919
V Predictions Mean           758.0388
V Predictions Std            182.7303
V Predictions Max            947.0406
V Predictions Min            100.49631
Log Pis Mean                 -0.74890894
Log Pis Std                  2.8028831
Log Pis Max                  10.552043
Log Pis Min                  -7.1762323
Policy mu Mean               -0.0016066352
Policy mu Std                0.55658853
Policy mu Max                2.4426877
Policy mu Min                -2.2109833
Policy log std Mean          -0.9107387
Policy log std Std           0.25853547
Policy log std Max           -0.27686003
Policy log std Min           -2.1503396
Z mean eval                  0.82020235
Z variance eval              0.025222015
total_rewards                [2443.34759882 2152.32433524 1852.36701896 2127.61644731 2158.1529639
 1359.58693716  655.78510103 1981.59220807 2167.17955175 2015.78226993]
total_rewards_mean           1891.3734432148817
total_rewards_std            490.96189646907806
total_rewards_max            2443.3475988197474
total_rewards_min            655.7851010275431
Number of train steps total  191000
Number of env steps total    957000
Number of rollouts total     0
Train Time (s)               42.8312461739406
(Previous) Eval Time (s)     26.234432205092162
Sample Time (s)              22.70827299868688
Epoch Time (s)               91.77395137771964
Total Train Time (s)         18647.68445222499
Epoch                        190
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:40:06.294101 UTC | [2020_01_10_11_29_18] Iteration #190 | Epoch Duration: 97.8844084739685
2020-01-10 16:40:06.294234 UTC | [2020_01_10_11_29_18] Iteration #190 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8201578
Z variance train             0.025253076
KL Divergence                15.8066435
KL Loss                      1.5806644
QF Loss                      686.65674
VF Loss                      184.04347
Policy Loss                  -757.9797
Q Predictions Mean           756.8316
Q Predictions Std            176.55133
Q Predictions Max            941.2326
Q Predictions Min            209.49142
V Predictions Mean           751.35126
V Predictions Std            175.41986
V Predictions Max            924.4896
V Predictions Min            149.36491
Log Pis Mean                 -1.2391596
Log Pis Std                  2.4585025
Log Pis Max                  8.721571
Log Pis Min                  -7.733602
Policy mu Mean               0.032991458
Policy mu Std                0.51386654
Policy mu Max                2.35257
Policy mu Min                -1.7887774
Policy log std Mean          -0.89102924
Policy log std Std           0.24307357
Policy log std Max           -0.18811631
Policy log std Min           -1.8916087
Z mean eval                  0.82140464
Z variance eval              0.032020785
total_rewards                [2072.86849534 1368.76043804 2084.06916565 1080.81847956 2234.02875424
  694.9766483  2005.36823616 1932.51235453  431.99444615 1908.13466159]
total_rewards_mean           1581.3531679550035
total_rewards_std            610.950346459282
total_rewards_max            2234.028754239166
total_rewards_min            431.9944461450436
Number of train steps total  192000
Number of env steps total    962000
Number of rollouts total     0
Train Time (s)               44.316939142066985
(Previous) Eval Time (s)     32.344646230805665
Sample Time (s)              23.007397109642625
Epoch Time (s)               99.66898248251528
Total Train Time (s)         18745.77899020631
Epoch                        191
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:41:44.392394 UTC | [2020_01_10_11_29_18] Iteration #191 | Epoch Duration: 98.0980474948883
2020-01-10 16:41:44.392563 UTC | [2020_01_10_11_29_18] Iteration #191 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.823019
Z variance train             0.031755984
KL Divergence                15.367228
KL Loss                      1.5367228
QF Loss                      753.22327
VF Loss                      143.60963
Policy Loss                  -745.6642
Q Predictions Mean           743.51263
Q Predictions Std            191.23534
Q Predictions Max            939.99805
Q Predictions Min            194.48671
V Predictions Mean           754.44824
V Predictions Std            193.41284
V Predictions Max            951.9031
V Predictions Min            196.46411
Log Pis Mean                 -1.5506113
Log Pis Std                  2.18054
Log Pis Max                  7.6067047
Log Pis Min                  -6.2222996
Policy mu Mean               0.051255025
Policy mu Std                0.48654976
Policy mu Max                1.6509851
Policy mu Min                -1.8576055
Policy log std Mean          -0.8688822
Policy log std Std           0.25676802
Policy log std Max           -0.10568488
Policy log std Min           -2.1250415
Z mean eval                  0.8300398
Z variance eval              0.025157774
total_rewards                [ 862.71397795  612.47858395  725.37492555  570.30605496 2102.7080193
  949.524103   1806.69134979  189.3943478  2286.90787276 2130.08522829]
total_rewards_mean           1223.6184463366226
total_rewards_std            734.0704167623402
total_rewards_max            2286.907872763168
total_rewards_min            189.3943478003275
Number of train steps total  193000
Number of env steps total    967000
Number of rollouts total     0
Train Time (s)               43.68046848708764
(Previous) Eval Time (s)     30.77347004506737
Sample Time (s)              21.041380657348782
Epoch Time (s)               95.49531918950379
Total Train Time (s)         18839.286865134258
Epoch                        192
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:43:17.905095 UTC | [2020_01_10_11_29_18] Iteration #192 | Epoch Duration: 93.51240348815918
2020-01-10 16:43:17.905270 UTC | [2020_01_10_11_29_18] Iteration #192 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.83037007
Z variance train             0.025103707
KL Divergence                16.186922
KL Loss                      1.6186923
QF Loss                      461.14307
VF Loss                      93.740616
Policy Loss                  -766.29083
Q Predictions Mean           763.33716
Q Predictions Std            166.33899
Q Predictions Max            949.5153
Q Predictions Min            -31.186617
V Predictions Mean           769.5272
V Predictions Std            164.31738
V Predictions Max            954.8947
V Predictions Min            -32.81833
Log Pis Mean                 -0.9998081
Log Pis Std                  2.3939004
Log Pis Max                  6.122884
Log Pis Min                  -9.715879
Policy mu Mean               0.033503287
Policy mu Std                0.53025496
Policy mu Max                1.8003145
Policy mu Min                -2.2925138
Policy log std Mean          -0.9178641
Policy log std Std           0.22162277
Policy log std Max           -0.25716734
Policy log std Min           -2.0454826
Z mean eval                  0.8508806
Z variance eval              0.020364773
total_rewards                [ 342.93023176 2116.24499896  709.13304854 2074.50793583 1972.49070375
  -42.59282831 2242.71127707 2106.99712702  653.7172342    55.81918484]
total_rewards_mean           1223.1958913675307
total_rewards_std            907.3396003675273
total_rewards_max            2242.7112770719
total_rewards_min            -42.592828310831386
Number of train steps total  194000
Number of env steps total    972000
Number of rollouts total     0
Train Time (s)               43.75197512237355
(Previous) Eval Time (s)     28.790308681782335
Sample Time (s)              22.97027616528794
Epoch Time (s)               95.51255996944383
Total Train Time (s)         18942.095571488608
Epoch                        193
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:45:00.715893 UTC | [2020_01_10_11_29_18] Iteration #193 | Epoch Duration: 102.8104944229126
2020-01-10 16:45:00.716078 UTC | [2020_01_10_11_29_18] Iteration #193 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.85153115
Z variance train             0.020419618
KL Divergence                16.624044
KL Loss                      1.6624044
QF Loss                      613.3451
VF Loss                      157.10504
Policy Loss                  -750.6681
Q Predictions Mean           749.1965
Q Predictions Std            193.99442
Q Predictions Max            954.9857
Q Predictions Min            189.24612
V Predictions Mean           752.93506
V Predictions Std            190.43355
V Predictions Max            947.731
V Predictions Min            202.27782
Log Pis Mean                 -1.2125691
Log Pis Std                  2.4850798
Log Pis Max                  9.1597805
Log Pis Min                  -7.2222185
Policy mu Mean               0.052176163
Policy mu Std                0.5175693
Policy mu Max                2.1235614
Policy mu Min                -2.1608572
Policy log std Mean          -0.8767592
Policy log std Std           0.2771755
Policy log std Max           -0.11698645
Policy log std Min           -2.427705
Z mean eval                  0.8757254
Z variance eval              0.021119732
total_rewards                [2134.77414931  371.87649883 1398.64194846 2008.87980349  931.16617591
 2042.30540697 2221.96655985  -47.41595278 2176.64196168  578.5645551 ]
total_rewards_mean           1381.7401106821292
total_rewards_std            815.1849784595819
total_rewards_max            2221.966559852739
total_rewards_min            -47.41595278423968
Number of train steps total  195000
Number of env steps total    977000
Number of rollouts total     0
Train Time (s)               44.199739440809935
(Previous) Eval Time (s)     36.087984431069344
Sample Time (s)              22.894567275885493
Epoch Time (s)               103.18229114776477
Total Train Time (s)         19043.82440240914
Epoch                        194
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:46:42.446756 UTC | [2020_01_10_11_29_18] Iteration #194 | Epoch Duration: 101.73054361343384
2020-01-10 16:46:42.446929 UTC | [2020_01_10_11_29_18] Iteration #194 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.87636316
Z variance train             0.02116465
KL Divergence                16.44395
KL Loss                      1.6443951
QF Loss                      429.4626
VF Loss                      131.19608
Policy Loss                  -770.3442
Q Predictions Mean           767.0708
Q Predictions Std            197.7988
Q Predictions Max            948.9275
Q Predictions Min            -28.564222
V Predictions Mean           764.7025
V Predictions Std            197.28574
V Predictions Max            953.64655
V Predictions Min            -26.152975
Log Pis Mean                 -0.92363954
Log Pis Std                  2.2844722
Log Pis Max                  4.477125
Log Pis Min                  -7.719133
Policy mu Mean               0.055635933
Policy mu Std                0.5683839
Policy mu Max                2.058632
Policy mu Min                -2.0990334
Policy log std Mean          -0.8768543
Policy log std Std           0.23364939
Policy log std Max           -0.19717467
Policy log std Min           -1.9370658
Z mean eval                  0.8322071
Z variance eval              0.021494571
total_rewards                [2211.01784107 2239.45013849 2205.51123179 1182.82741273  776.02739634
 2128.06134834 1257.9106712  1254.74794816 1392.13527943 2261.39981048]
total_rewards_mean           1690.9089078018533
total_rewards_std            539.901193246028
total_rewards_max            2261.3998104769635
total_rewards_min            776.0273963361465
Number of train steps total  196000
Number of env steps total    982000
Number of rollouts total     0
Train Time (s)               43.61359832761809
(Previous) Eval Time (s)     34.635982647072524
Sample Time (s)              22.957967014983296
Epoch Time (s)               101.20754798967391
Total Train Time (s)         19138.878860082943
Epoch                        195
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:48:17.502727 UTC | [2020_01_10_11_29_18] Iteration #195 | Epoch Duration: 95.0556755065918
2020-01-10 16:48:17.502860 UTC | [2020_01_10_11_29_18] Iteration #195 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8323487
Z variance train             0.021497207
KL Divergence                16.481392
KL Loss                      1.6481392
QF Loss                      335.84576
VF Loss                      57.979713
Policy Loss                  -765.287
Q Predictions Mean           762.8284
Q Predictions Std            198.57068
Q Predictions Max            960.7666
Q Predictions Min            192.73206
V Predictions Mean           765.89514
V Predictions Std            198.05507
V Predictions Max            964.6717
V Predictions Min            200.06909
Log Pis Mean                 -0.990913
Log Pis Std                  2.641822
Log Pis Max                  11.15378
Log Pis Min                  -9.4882965
Policy mu Mean               -0.03340277
Policy mu Std                0.5435153
Policy mu Max                2.2270722
Policy mu Min                -1.865103
Policy log std Mean          -0.85908145
Policy log std Std           0.24894628
Policy log std Max           -0.19475853
Policy log std Min           -1.980139
Z mean eval                  0.8496536
Z variance eval              0.017473351
total_rewards                [2315.19658032 2101.77362603 1124.55715378    6.77093189 2119.39051839
  173.25865924 1061.18324848  248.35240048 1234.51820189 2304.8224207 ]
total_rewards_mean           1268.9823741197395
total_rewards_std            865.1569034499261
total_rewards_max            2315.196580318394
total_rewards_min            6.770931885582091
Number of train steps total  197000
Number of env steps total    987000
Number of rollouts total     0
Train Time (s)               43.53051968803629
(Previous) Eval Time (s)     28.48387475218624
Sample Time (s)              23.167978077661246
Epoch Time (s)               95.18237251788378
Total Train Time (s)         19231.165870456025
Epoch                        196
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:49:49.793680 UTC | [2020_01_10_11_29_18] Iteration #196 | Epoch Duration: 92.29069876670837
2020-01-10 16:49:49.793889 UTC | [2020_01_10_11_29_18] Iteration #196 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8492767
Z variance train             0.017448282
KL Divergence                17.19313
KL Loss                      1.719313
QF Loss                      350.99374
VF Loss                      62.349983
Policy Loss                  -783.37146
Q Predictions Mean           782.1178
Q Predictions Std            165.62259
Q Predictions Max            956.0906
Q Predictions Min            215.03912
V Predictions Mean           780.0366
V Predictions Std            163.96065
V Predictions Max            950.0315
V Predictions Min            209.24622
Log Pis Mean                 -1.323041
Log Pis Std                  2.6291368
Log Pis Max                  5.71772
Log Pis Min                  -13.529548
Policy mu Mean               0.018263107
Policy mu Std                0.5332241
Policy mu Max                2.0164478
Policy mu Min                -2.0956182
Policy log std Mean          -0.8855512
Policy log std Std           0.23091152
Policy log std Max           -0.22077644
Policy log std Min           -1.8101766
Z mean eval                  0.8738065
Z variance eval              0.027159575
total_rewards                [-125.94539191 2146.70843951  285.52654161 2168.00599396 2175.26581697
 1943.79130156 2118.47549084   12.31202455  725.97474819 2105.87118682]
total_rewards_mean           1355.5986152077407
total_rewards_std            948.126968630167
total_rewards_max            2175.2658169656424
total_rewards_min            -125.9453919093247
Number of train steps total  198000
Number of env steps total    992000
Number of rollouts total     0
Train Time (s)               44.08338510431349
(Previous) Eval Time (s)     25.591987541876733
Sample Time (s)              22.521697537507862
Epoch Time (s)               92.19707018369809
Total Train Time (s)         19327.700517369434
Epoch                        197
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:51:26.329279 UTC | [2020_01_10_11_29_18] Iteration #197 | Epoch Duration: 96.53524661064148
2020-01-10 16:51:26.329420 UTC | [2020_01_10_11_29_18] Iteration #197 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.87373334
Z variance train             0.027270507
KL Divergence                16.584412
KL Loss                      1.6584412
QF Loss                      1056.4353
VF Loss                      80.27646
Policy Loss                  -761.0303
Q Predictions Mean           758.8403
Q Predictions Std            189.51968
Q Predictions Max            947.60547
Q Predictions Min            140.20073
V Predictions Mean           763.9583
V Predictions Std            187.43684
V Predictions Max            954.29205
V Predictions Min            98.714714
Log Pis Mean                 -0.9696411
Log Pis Std                  2.524544
Log Pis Max                  11.351858
Log Pis Min                  -9.745784
Policy mu Mean               0.038135644
Policy mu Std                0.54229635
Policy mu Max                2.0569851
Policy mu Min                -1.7146895
Policy log std Mean          -0.87548435
Policy log std Std           0.25185806
Policy log std Max           -0.09009224
Policy log std Min           -2.4726033
Z mean eval                  0.87095356
Z variance eval              0.029428367
total_rewards                [2123.67537064  650.57325289 1735.10751581 2137.04003888 2227.63334727
  859.02445831 1321.92779815  628.80175537  471.71414681 2247.36944744]
total_rewards_mean           1440.28671315737
total_rewards_std            698.7749613423966
total_rewards_max            2247.3694474429662
total_rewards_min            471.7141468059552
Number of train steps total  199000
Number of env steps total    997000
Number of rollouts total     0
Train Time (s)               43.84163018595427
(Previous) Eval Time (s)     29.929934062063694
Sample Time (s)              22.78146579908207
Epoch Time (s)               96.55303004710004
Total Train Time (s)         19422.2402069089
Epoch                        198
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:53:00.875851 UTC | [2020_01_10_11_29_18] Iteration #198 | Epoch Duration: 94.54627871513367
2020-01-10 16:53:00.876216 UTC | [2020_01_10_11_29_18] Iteration #198 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8708248
Z variance train             0.02949571
KL Divergence                16.507
KL Loss                      1.6507
QF Loss                      285.59467
VF Loss                      245.75299
Policy Loss                  -778.8981
Q Predictions Mean           775.5323
Q Predictions Std            184.74785
Q Predictions Max            984.06555
Q Predictions Min            -58.930588
V Predictions Mean           785.02496
V Predictions Std            177.77386
V Predictions Max            983.9011
V Predictions Min            188.86723
Log Pis Mean                 -1.139577
Log Pis Std                  2.5024939
Log Pis Max                  13.877249
Log Pis Min                  -6.903965
Policy mu Mean               0.0035107723
Policy mu Std                0.5385376
Policy mu Max                1.7377573
Policy mu Min                -2.012005
Policy log std Mean          -0.8710858
Policy log std Std           0.24067117
Policy log std Max           -0.2700377
Policy log std Min           -2.4698675
Z mean eval                  0.8518301
Z variance eval              0.027393734
total_rewards                [2190.37979578 1337.07677247 2329.68384461 2029.99871075 2392.78355171
 1235.95504845 2430.73555146 2318.89604596 2243.84419996 2239.24899553]
total_rewards_mean           2074.86025166875
total_rewards_std            408.8072828482737
total_rewards_max            2430.7355514597657
total_rewards_min            1235.95504845229
Number of train steps total  200000
Number of env steps total    1002000
Number of rollouts total     0
Train Time (s)               44.532896908931434
(Previous) Eval Time (s)     27.922908811829984
Sample Time (s)              22.525289646349847
Epoch Time (s)               94.98109536711127
Total Train Time (s)         19521.943149664905
Epoch                        199
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:54:40.579834 UTC | [2020_01_10_11_29_18] Iteration #199 | Epoch Duration: 99.70339846611023
2020-01-10 16:54:40.580030 UTC | [2020_01_10_11_29_18] Iteration #199 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8503529
Z variance train             0.027586479
KL Divergence                16.750072
KL Loss                      1.6750072
QF Loss                      346.08118
VF Loss                      59.670235
Policy Loss                  -796.0061
Q Predictions Mean           794.94775
Q Predictions Std            168.92357
Q Predictions Max            966.51904
Q Predictions Min            214.16396
V Predictions Mean           800.10547
V Predictions Std            168.7747
V Predictions Max            963.6335
V Predictions Min            221.76717
Log Pis Mean                 -0.99271023
Log Pis Std                  2.3455415
Log Pis Max                  4.920575
Log Pis Min                  -8.02663
Policy mu Mean               -0.0032822394
Policy mu Std                0.54855055
Policy mu Max                1.9254506
Policy mu Min                -2.1342087
Policy log std Mean          -0.87475526
Policy log std Std           0.24479541
Policy log std Max           -0.23944455
Policy log std Min           -2.2695966
Z mean eval                  0.86705256
Z variance eval              0.027764332
total_rewards                [2233.12401896 2137.51320911  337.72930136 2269.46229824  464.01390477
   79.92916656  760.56502262 2332.35712938 2219.04617476 2333.83895515]
total_rewards_mean           1516.7579180914413
total_rewards_std            917.9213849107975
total_rewards_max            2333.838955151822
total_rewards_min            79.92916655538204
Number of train steps total  201000
Number of env steps total    1007000
Number of rollouts total     0
Train Time (s)               44.274569008965045
(Previous) Eval Time (s)     32.644993875175714
Sample Time (s)              23.13811236154288
Epoch Time (s)               100.05767524568364
Total Train Time (s)         19619.227710084524
Epoch                        200
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:56:17.866804 UTC | [2020_01_10_11_29_18] Iteration #200 | Epoch Duration: 97.28663682937622
2020-01-10 16:56:17.866966 UTC | [2020_01_10_11_29_18] Iteration #200 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8692026
Z variance train             0.027728092
KL Divergence                16.868366
KL Loss                      1.6868366
QF Loss                      626.33374
VF Loss                      266.90912
Policy Loss                  -757.6628
Q Predictions Mean           759.1069
Q Predictions Std            189.74498
Q Predictions Max            961.6067
Q Predictions Min            73.419914
V Predictions Mean           759.1873
V Predictions Std            191.11243
V Predictions Max            954.5217
V Predictions Min            52.53498
Log Pis Mean                 -1.2416725
Log Pis Std                  2.5143008
Log Pis Max                  10.655018
Log Pis Min                  -7.7994766
Policy mu Mean               0.025599565
Policy mu Std                0.5200362
Policy mu Max                1.98679
Policy mu Min                -1.8781664
Policy log std Mean          -0.8938885
Policy log std Std           0.27936015
Policy log std Max           -0.24604899
Policy log std Min           -2.424981
Z mean eval                  0.83528197
Z variance eval              0.025019396
total_rewards                [2130.60651796 1980.35738551 2135.80985612 2250.06885093 2285.29861069
 1999.71213302 2110.80094447 2266.31139987 2117.60034712 1744.65962053]
total_rewards_mean           2102.122566621726
total_rewards_std            154.1930601812321
total_rewards_max            2285.298610688481
total_rewards_min            1744.6596205297562
Number of train steps total  202000
Number of env steps total    1012000
Number of rollouts total     0
Train Time (s)               44.36299315420911
(Previous) Eval Time (s)     29.8737186267972
Sample Time (s)              22.347319412510842
Epoch Time (s)               96.58403119351715
Total Train Time (s)         19720.99581396114
Epoch                        201
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:57:59.636755 UTC | [2020_01_10_11_29_18] Iteration #201 | Epoch Duration: 101.76966309547424
2020-01-10 16:57:59.636889 UTC | [2020_01_10_11_29_18] Iteration #201 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8352979
Z variance train             0.024961166
KL Divergence                16.695335
KL Loss                      1.6695336
QF Loss                      862.23914
VF Loss                      90.37848
Policy Loss                  -770.987
Q Predictions Mean           767.5883
Q Predictions Std            190.30252
Q Predictions Max            960.72363
Q Predictions Min            193.8359
V Predictions Mean           770.9569
V Predictions Std            190.09294
V Predictions Max            961.4154
V Predictions Min            187.04828
Log Pis Mean                 -0.89694524
Log Pis Std                  2.6741228
Log Pis Max                  12.923387
Log Pis Min                  -9.619314
Policy mu Mean               -0.021686152
Policy mu Std                0.56064326
Policy mu Max                1.6540575
Policy mu Min                -2.0693681
Policy log std Mean          -0.87402457
Policy log std Std           0.25851017
Policy log std Max           -0.19791996
Policy log std Min           -2.4463377
Z mean eval                  0.85931647
Z variance eval              0.023176003
total_rewards                [2214.37452105 2134.39206529 2297.81002823 2053.14271191  222.17468863
 1196.13610671 2318.27306956 2165.49826397 2198.56279047  835.30777787]
total_rewards_mean           1763.5672023685481
total_rewards_std            701.9979001536386
total_rewards_max            2318.2730695594264
total_rewards_min            222.1746886269164
Number of train steps total  203000
Number of env steps total    1017000
Number of rollouts total     0
Train Time (s)               43.4136558319442
(Previous) Eval Time (s)     35.05911056417972
Sample Time (s)              22.98504052311182
Epoch Time (s)               101.45780691923574
Total Train Time (s)         19819.54017572757
Epoch                        202
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:59:38.184112 UTC | [2020_01_10_11_29_18] Iteration #202 | Epoch Duration: 98.54706525802612
2020-01-10 16:59:38.184439 UTC | [2020_01_10_11_29_18] Iteration #202 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.85943425
Z variance train             0.023110876
KL Divergence                16.743021
KL Loss                      1.6743021
QF Loss                      498.2812
VF Loss                      133.6299
Policy Loss                  -783.80225
Q Predictions Mean           781.2393
Q Predictions Std            194.09521
Q Predictions Max            958.55255
Q Predictions Min            -32.559418
V Predictions Mean           780.947
V Predictions Std            192.28967
V Predictions Max            955.451
V Predictions Min            18.874577
Log Pis Mean                 -1.0824351
Log Pis Std                  2.5475643
Log Pis Max                  7.708637
Log Pis Min                  -6.744652
Policy mu Mean               0.0052974047
Policy mu Std                0.54579604
Policy mu Max                2.3487637
Policy mu Min                -1.9507891
Policy log std Mean          -0.89846116
Policy log std Std           0.26922137
Policy log std Max           -0.19359404
Policy log std Min           -2.1983352
Z mean eval                  0.8481228
Z variance eval              0.016960192
total_rewards                [ 267.86732398 2407.84517642 2322.03447521  735.20153509 2408.52459463
 2175.64765471 2475.38811041 2278.80605643  539.78834631 2308.63983663]
total_rewards_mean           1791.974310983808
total_rewards_std            846.5366808595554
total_rewards_max            2475.3881104137386
total_rewards_min            267.86732397926335
Number of train steps total  204000
Number of env steps total    1022000
Number of rollouts total     0
Train Time (s)               43.81368706608191
(Previous) Eval Time (s)     32.148124393075705
Sample Time (s)              24.000740341376513
Epoch Time (s)               99.96255180053413
Total Train Time (s)         19914.830520651303
Epoch                        203
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:01:13.477751 UTC | [2020_01_10_11_29_18] Iteration #203 | Epoch Duration: 95.29310202598572
2020-01-10 17:01:13.477907 UTC | [2020_01_10_11_29_18] Iteration #203 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.84722745
Z variance train             0.016969109
KL Divergence                17.557228
KL Loss                      1.7557229
QF Loss                      692.1878
VF Loss                      334.69193
Policy Loss                  -778.7962
Q Predictions Mean           776.17053
Q Predictions Std            198.92215
Q Predictions Max            975.90625
Q Predictions Min            -29.613134
V Predictions Mean           776.69604
V Predictions Std            194.1922
V Predictions Max            984.2425
V Predictions Min            21.172579
Log Pis Mean                 -1.2794135
Log Pis Std                  2.5365448
Log Pis Max                  7.876634
Log Pis Min                  -8.18922
Policy mu Mean               0.054989733
Policy mu Std                0.5393419
Policy mu Max                1.8703669
Policy mu Min                -2.0407739
Policy log std Mean          -0.8684836
Policy log std Std           0.26463586
Policy log std Max           -0.14787036
Policy log std Min           -2.2208483
Z mean eval                  0.8558898
Z variance eval              0.020893006
total_rewards                [2132.27554154 2229.298609   2099.23219241 2380.57297389 2123.47369535
  731.84415445 2299.17853099 2179.4260157  2323.2234853  1337.21760642]
total_rewards_mean           1983.5742805047853
total_rewards_std            501.09678287615225
total_rewards_max            2380.5729738905416
total_rewards_min            731.8441544491498
Number of train steps total  205000
Number of env steps total    1027000
Number of rollouts total     0
Train Time (s)               44.16362281423062
(Previous) Eval Time (s)     27.478452345822006
Sample Time (s)              23.303928499575704
Epoch Time (s)               94.94600365962833
Total Train Time (s)         20011.37757786177
Epoch                        204
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:02:50.032071 UTC | [2020_01_10_11_29_18] Iteration #204 | Epoch Duration: 96.55396056175232
2020-01-10 17:02:50.032316 UTC | [2020_01_10_11_29_18] Iteration #204 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8538561
Z variance train             0.020939792
KL Divergence                17.395592
KL Loss                      1.7395592
QF Loss                      388.12015
VF Loss                      127.47038
Policy Loss                  -774.625
Q Predictions Mean           774.3384
Q Predictions Std            202.63281
Q Predictions Max            957.4981
Q Predictions Min            180.25719
V Predictions Mean           780.51624
V Predictions Std            200.84862
V Predictions Max            950.4043
V Predictions Min            209.84886
Log Pis Mean                 -1.274511
Log Pis Std                  2.5420732
Log Pis Max                  6.1052456
Log Pis Min                  -7.7369547
Policy mu Mean               -0.016424762
Policy mu Std                0.51734835
Policy mu Max                1.8024309
Policy mu Min                -2.0999434
Policy log std Mean          -0.87645
Policy log std Std           0.25872767
Policy log std Max           -0.1454674
Policy log std Min           -2.0830843
Z mean eval                  0.8584919
Z variance eval              0.024895879
total_rewards                [2304.18200896 2215.14992757 2131.17819812 1208.19173031  103.20122742
  811.09704467  765.07578516 1087.23153637  749.03137687 1748.09370247]
total_rewards_mean           1312.243253792555
total_rewards_std            710.6891026449971
total_rewards_max            2304.1820089552007
total_rewards_min            103.20122742323164
Number of train steps total  206000
Number of env steps total    1032000
Number of rollouts total     0
Train Time (s)               44.40478092525154
(Previous) Eval Time (s)     29.086145635228604
Sample Time (s)              21.563776129856706
Epoch Time (s)               95.05470269033685
Total Train Time (s)         20103.51937381318
Epoch                        205
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:04:22.175084 UTC | [2020_01_10_11_29_18] Iteration #205 | Epoch Duration: 92.14262413978577
2020-01-10 17:04:22.175223 UTC | [2020_01_10_11_29_18] Iteration #205 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8605876
Z variance train             0.024955768
KL Divergence                17.513288
KL Loss                      1.7513288
QF Loss                      745.6981
VF Loss                      174.52277
Policy Loss                  -772.1335
Q Predictions Mean           767.0116
Q Predictions Std            208.49742
Q Predictions Max            990.051
Q Predictions Min            179.45717
V Predictions Mean           766.4573
V Predictions Std            204.53856
V Predictions Max            992.9845
V Predictions Min            177.6018
Log Pis Mean                 -0.8145348
Log Pis Std                  2.8250685
Log Pis Max                  8.424366
Log Pis Min                  -7.317569
Policy mu Mean               -0.015451509
Policy mu Std                0.5971722
Policy mu Max                2.45683
Policy mu Min                -2.5413258
Policy log std Mean          -0.8571761
Policy log std Std           0.25875354
Policy log std Max           -0.1698572
Policy log std Min           -1.9721236
Z mean eval                  0.8696386
Z variance eval              0.024120513
total_rewards                [2198.40417372 2301.20951425 1285.26236767 2088.87452936  638.11056423
 2242.37698782  806.12276503 2188.20083944 2376.51461115  600.11747598]
total_rewards_mean           1672.5193828634158
total_rewards_std            710.7805982003603
total_rewards_max            2376.5146111481235
total_rewards_min            600.117475975294
Number of train steps total  207000
Number of env steps total    1037000
Number of rollouts total     0
Train Time (s)               43.61646229727194
(Previous) Eval Time (s)     26.173836105968803
Sample Time (s)              22.25908403424546
Epoch Time (s)               92.0493824374862
Total Train Time (s)         20200.620193841867
Epoch                        206
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:05:59.277498 UTC | [2020_01_10_11_29_18] Iteration #206 | Epoch Duration: 97.10217213630676
2020-01-10 17:05:59.277639 UTC | [2020_01_10_11_29_18] Iteration #206 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.86570865
Z variance train             0.024182716
KL Divergence                17.614735
KL Loss                      1.7614735
QF Loss                      520.5652
VF Loss                      100.51109
Policy Loss                  -788.34326
Q Predictions Mean           787.44525
Q Predictions Std            211.55598
Q Predictions Max            999.23016
Q Predictions Min            -5.827069
V Predictions Mean           781.0969
V Predictions Std            211.45279
V Predictions Max            982.2194
V Predictions Min            -3.5071988
Log Pis Mean                 -1.127614
Log Pis Std                  2.5938823
Log Pis Max                  7.720986
Log Pis Min                  -7.633399
Policy mu Mean               -0.0036076324
Policy mu Std                0.5501767
Policy mu Max                1.9420946
Policy mu Min                -2.1524858
Policy log std Mean          -0.85909
Policy log std Std           0.25736937
Policy log std Max           -0.19731236
Policy log std Min           -1.8281254
Z mean eval                  0.8546022
Z variance eval              0.018057492
total_rewards                [-119.33967344  482.47246832 1097.05489632 2218.50829626  202.46356651
 2538.6153641  2232.32787671 1505.5680544   646.56607664  413.7920952 ]
total_rewards_mean           1121.8029021025018
total_rewards_std            900.7089764454961
total_rewards_max            2538.615364099552
total_rewards_min            -119.33967344132793
Number of train steps total  208000
Number of env steps total    1042000
Number of rollouts total     0
Train Time (s)               44.11778813786805
(Previous) Eval Time (s)     31.22637363197282
Sample Time (s)              23.157588399015367
Epoch Time (s)               98.50175016885623
Total Train Time (s)         20295.84160805866
Epoch                        207
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:07:34.502315 UTC | [2020_01_10_11_29_18] Iteration #207 | Epoch Duration: 95.22457337379456
2020-01-10 17:07:34.502453 UTC | [2020_01_10_11_29_18] Iteration #207 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8562175
Z variance train             0.017991781
KL Divergence                17.572435
KL Loss                      1.7572435
QF Loss                      708.68445
VF Loss                      243.33377
Policy Loss                  -764.43396
Q Predictions Mean           763.04913
Q Predictions Std            207.88878
Q Predictions Max            967.5912
Q Predictions Min            -28.499838
V Predictions Mean           757.0266
V Predictions Std            202.66873
V Predictions Max            946.7449
V Predictions Min            42.03538
Log Pis Mean                 -1.1705855
Log Pis Std                  2.6172163
Log Pis Max                  8.69418
Log Pis Min                  -7.110891
Policy mu Mean               0.06346113
Policy mu Std                0.5498773
Policy mu Max                2.150466
Policy mu Min                -1.9631693
Policy log std Mean          -0.8624454
Policy log std Std           0.26891953
Policy log std Max           -0.19741082
Policy log std Min           -2.1412463
Z mean eval                  0.8770048
Z variance eval              0.021686438
total_rewards                [1330.457796    421.24134237 2280.80717011 1447.93470397 2173.11326807
  800.91197628  731.69153988  167.30749673  202.01717682  995.69631175]
total_rewards_mean           1055.1178781963931
total_rewards_std            712.2421472560015
total_rewards_max            2280.807170109501
total_rewards_min            167.3074967302211
Number of train steps total  209000
Number of env steps total    1047000
Number of rollouts total     0
Train Time (s)               43.97243489464745
(Previous) Eval Time (s)     27.948956854641438
Sample Time (s)              23.49856698838994
Epoch Time (s)               95.41995873767883
Total Train Time (s)         20384.422033764888
Epoch                        208
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:09:03.087791 UTC | [2020_01_10_11_29_18] Iteration #208 | Epoch Duration: 88.58522462844849
2020-01-10 17:09:03.087980 UTC | [2020_01_10_11_29_18] Iteration #208 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.87786436
Z variance train             0.02184004
KL Divergence                17.406837
KL Loss                      1.7406838
QF Loss                      494.03018
VF Loss                      126.59848
Policy Loss                  -774.2603
Q Predictions Mean           772.3502
Q Predictions Std            220.59499
Q Predictions Max            1003.19196
Q Predictions Min            9.918318
V Predictions Mean           773.2647
V Predictions Std            220.14937
V Predictions Max            1002.3595
V Predictions Min            73.20391
Log Pis Mean                 -0.80661666
Log Pis Std                  2.715654
Log Pis Max                  10.48205
Log Pis Min                  -6.4910593
Policy mu Mean               0.023053292
Policy mu Std                0.5629467
Policy mu Max                1.966322
Policy mu Min                -3.016637
Policy log std Mean          -0.8806575
Policy log std Std           0.27851394
Policy log std Max           -0.123826444
Policy log std Min           -1.9615557
Z mean eval                  0.89913434
Z variance eval              0.02449594
total_rewards                [1597.43963192 2135.04985766  723.12716831  475.17887708 1991.88615698
  866.2145414  1951.79552076 2272.77867452 2210.43752678 2079.72954514]
total_rewards_mean           1630.3637500541047
total_rewards_std            646.712869609906
total_rewards_max            2272.7786745171975
total_rewards_min            475.1788770826329
Number of train steps total  210000
Number of env steps total    1052000
Number of rollouts total     0
Train Time (s)               43.235582285095006
(Previous) Eval Time (s)     21.113982043229043
Sample Time (s)              22.666124031413347
Epoch Time (s)               87.0156883597374
Total Train Time (s)         20479.49311454175
Epoch                        209
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:10:38.163040 UTC | [2020_01_10_11_29_18] Iteration #209 | Epoch Duration: 95.07493257522583
2020-01-10 17:10:38.163185 UTC | [2020_01_10_11_29_18] Iteration #209 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9000393
Z variance train             0.02450542
KL Divergence                17.134277
KL Loss                      1.7134278
QF Loss                      940.71106
VF Loss                      211.91508
Policy Loss                  -807.31494
Q Predictions Mean           802.7218
Q Predictions Std            189.30914
Q Predictions Max            989.8554
Q Predictions Min            205.22984
V Predictions Mean           805.25275
V Predictions Std            185.40659
V Predictions Max            995.7153
V Predictions Min            196.11879
Log Pis Mean                 -0.4723606
Log Pis Std                  2.7006266
Log Pis Max                  6.5824323
Log Pis Min                  -8.509625
Policy mu Mean               0.0054729376
Policy mu Std                0.6010323
Policy mu Max                2.1191554
Policy mu Min                -2.0722876
Policy log std Mean          -0.9128611
Policy log std Std           0.2551179
Policy log std Max           -0.1400156
Policy log std Min           -1.8425517
Z mean eval                  0.8385714
Z variance eval              0.021999437
total_rewards                [2396.78422464 2278.51204406 2300.24925428  154.87228038 2254.62926458
  281.57270265 2204.89619208  990.62941014 2345.16151063 2471.89237587]
total_rewards_mean           1767.9199259312481
total_rewards_std            872.4390951192996
total_rewards_max            2471.8923758663577
total_rewards_min            154.87228037752965
Number of train steps total  211000
Number of env steps total    1057000
Number of rollouts total     0
Train Time (s)               43.330361693166196
(Previous) Eval Time (s)     29.172976295929402
Sample Time (s)              23.25589279877022
Epoch Time (s)               95.75923078786582
Total Train Time (s)         20575.83330826694
Epoch                        210
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:12:14.506150 UTC | [2020_01_10_11_29_18] Iteration #210 | Epoch Duration: 96.34285426139832
2020-01-10 17:12:14.506322 UTC | [2020_01_10_11_29_18] Iteration #210 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.84120214
Z variance train             0.021954065
KL Divergence                17.13454
KL Loss                      1.7134541
QF Loss                      334.16492
VF Loss                      190.54099
Policy Loss                  -799.7322
Q Predictions Mean           795.91113
Q Predictions Std            199.7164
Q Predictions Max            1030.2037
Q Predictions Min            192.52242
V Predictions Mean           790.75116
V Predictions Std            197.9279
V Predictions Max            1001.51086
V Predictions Min            191.53253
Log Pis Mean                 -0.9942947
Log Pis Std                  2.622168
Log Pis Max                  9.646489
Log Pis Min                  -6.9968624
Policy mu Mean               -0.08534539
Policy mu Std                0.5629448
Policy mu Max                2.5289922
Policy mu Min                -2.0903218
Policy log std Mean          -0.88091767
Policy log std Std           0.24954131
Policy log std Max           -0.19628924
Policy log std Min           -1.7362417
Z mean eval                  0.8569023
Z variance eval              0.01880114
total_rewards                [2191.32411729 1622.04960695  521.56749737 2302.16679718  861.50274307
 1397.54418322  -13.10256042 1763.72199735 1943.57365803  848.47917811]
total_rewards_mean           1343.8827218154584
total_rewards_std            724.454442467649
total_rewards_max            2302.1667971844313
total_rewards_min            -13.102560421467636
Number of train steps total  212000
Number of env steps total    1062000
Number of rollouts total     0
Train Time (s)               44.92342990031466
(Previous) Eval Time (s)     29.756327707786113
Sample Time (s)              22.590955233201385
Epoch Time (s)               97.27071284130216
Total Train Time (s)         20672.671914570034
Epoch                        211
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:13:51.346265 UTC | [2020_01_10_11_29_18] Iteration #211 | Epoch Duration: 96.83981800079346
2020-01-10 17:13:51.346398 UTC | [2020_01_10_11_29_18] Iteration #211 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8575385
Z variance train             0.01889054
KL Divergence                17.974998
KL Loss                      1.7974999
QF Loss                      351.0601
VF Loss                      76.6402
Policy Loss                  -810.32104
Q Predictions Mean           809.2801
Q Predictions Std            187.63708
Q Predictions Max            997.7915
Q Predictions Min            221.48093
V Predictions Mean           813.4143
V Predictions Std            183.45062
V Predictions Max            988.4895
V Predictions Min            194.12334
Log Pis Mean                 -1.3075337
Log Pis Std                  2.4123747
Log Pis Max                  7.091569
Log Pis Min                  -8.567008
Policy mu Mean               0.06804007
Policy mu Std                0.5019947
Policy mu Max                2.021645
Policy mu Min                -2.4613104
Policy log std Mean          -0.89132255
Policy log std Std           0.23860419
Policy log std Max           -0.10962838
Policy log std Min           -1.8926741
Z mean eval                  0.87487185
Z variance eval              0.016893372
total_rewards                [2333.81527653 2317.54111934 1323.445186   2252.62493049 2220.84170122
 2020.72840491 2257.58916071 1163.46638143 2225.30265834  875.78555506]
total_rewards_mean           1899.1140374028514
total_rewards_std            525.5465535239061
total_rewards_max            2333.815276527268
total_rewards_min            875.7855550595441
Number of train steps total  213000
Number of env steps total    1067000
Number of rollouts total     0
Train Time (s)               43.51174814393744
(Previous) Eval Time (s)     29.325187099166214
Sample Time (s)              22.310841735452414
Epoch Time (s)               95.14777697855607
Total Train Time (s)         20771.740700564347
Epoch                        212
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:15:30.416633 UTC | [2020_01_10_11_29_18] Iteration #212 | Epoch Duration: 99.07013416290283
2020-01-10 17:15:30.416770 UTC | [2020_01_10_11_29_18] Iteration #212 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8752926
Z variance train             0.016893426
KL Divergence                18.385921
KL Loss                      1.8385922
QF Loss                      551.1073
VF Loss                      209.19568
Policy Loss                  -816.5109
Q Predictions Mean           816.02783
Q Predictions Std            196.27985
Q Predictions Max            999.5977
Q Predictions Min            -1.5526582
V Predictions Mean           824.06335
V Predictions Std            197.33395
V Predictions Max            1014.49445
V Predictions Min            -15.682307
Log Pis Mean                 -0.95509136
Log Pis Std                  2.4713163
Log Pis Max                  7.184761
Log Pis Min                  -7.6104198
Policy mu Mean               0.018849177
Policy mu Std                0.5704248
Policy mu Max                1.9549409
Policy mu Min                -2.5303383
Policy log std Mean          -0.88204885
Policy log std Std           0.24363928
Policy log std Max           -0.19305366
Policy log std Min           -1.8615847
Z mean eval                  0.8676621
Z variance eval              0.021729905
total_rewards                [ -11.46488872 2461.31093942   43.44726724 2432.25493999 2335.77087637
 2283.15507841 2264.36756469 2227.37697768  316.85747481 1328.50312991]
total_rewards_mean           1568.1579359804405
total_rewards_std            1000.3625449678658
total_rewards_max            2461.3109394175453
total_rewards_min            -11.464888716633935
Number of train steps total  214000
Number of env steps total    1072000
Number of rollouts total     0
Train Time (s)               43.444822864141315
(Previous) Eval Time (s)     33.24728464893997
Sample Time (s)              23.875742519740015
Epoch Time (s)               100.5678500328213
Total Train Time (s)         20864.009426414967
Epoch                        213
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:17:02.691090 UTC | [2020_01_10_11_29_18] Iteration #213 | Epoch Duration: 92.27419352531433
2020-01-10 17:17:02.691316 UTC | [2020_01_10_11_29_18] Iteration #213 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.86771566
Z variance train             0.021782517
KL Divergence                18.024334
KL Loss                      1.8024334
QF Loss                      579.73376
VF Loss                      106.478836
Policy Loss                  -794.11786
Q Predictions Mean           791.51825
Q Predictions Std            204.54138
Q Predictions Max            970.7969
Q Predictions Min            10.641963
V Predictions Mean           793.10645
V Predictions Std            200.22977
V Predictions Max            976.0602
V Predictions Min            34.2193
Log Pis Mean                 -0.9430102
Log Pis Std                  2.4533648
Log Pis Max                  5.247865
Log Pis Min                  -9.691795
Policy mu Mean               0.0046067154
Policy mu Std                0.5536685
Policy mu Max                2.0970356
Policy mu Min                -3.0386858
Policy log std Mean          -0.8885197
Policy log std Std           0.24139555
Policy log std Max           -0.25682616
Policy log std Min           -1.866119
Z mean eval                  0.86873925
Z variance eval              0.01888938
total_rewards                [2314.12609845 2452.75588493 2482.56705539 2339.62902178  457.7629514
 2418.95080161 2260.79654331 2522.65567959 2309.05617062 2398.82580703]
total_rewards_mean           2195.712601412161
total_rewards_std            584.6900148394717
total_rewards_max            2522.655679590766
total_rewards_min            457.7629514045276
Number of train steps total  215000
Number of env steps total    1077000
Number of rollouts total     0
Train Time (s)               44.009057929739356
(Previous) Eval Time (s)     24.953369302209467
Sample Time (s)              22.61263095960021
Epoch Time (s)               91.57505819154903
Total Train Time (s)         20963.018757882062
Epoch                        214
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:18:41.703211 UTC | [2020_01_10_11_29_18] Iteration #214 | Epoch Duration: 99.01174092292786
2020-01-10 17:18:41.703350 UTC | [2020_01_10_11_29_18] Iteration #214 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.86954355
Z variance train             0.01886087
KL Divergence                18.16164
KL Loss                      1.816164
QF Loss                      384.54535
VF Loss                      44.555046
Policy Loss                  -821.1235
Q Predictions Mean           817.2721
Q Predictions Std            189.50131
Q Predictions Max            1001.7437
Q Predictions Min            36.541595
V Predictions Mean           820.3571
V Predictions Std            187.24167
V Predictions Max            999.9465
V Predictions Min            88.09902
Log Pis Mean                 -0.97233176
Log Pis Std                  2.2258027
Log Pis Max                  5.759777
Log Pis Min                  -6.868442
Policy mu Mean               0.00024118181
Policy mu Std                0.5560243
Policy mu Max                1.8930087
Policy mu Min                -2.19681
Policy log std Mean          -0.87613606
Policy log std Std           0.2399572
Policy log std Max           -0.156811
Policy log std Min           -2.0612864
Z mean eval                  0.86218244
Z variance eval              0.014586769
total_rewards                [ 655.67560376  603.10820796 2298.99454373  890.03759336 1444.92536737
 2394.26614625 1506.78104664  509.70803126  942.86674038 2444.75750097]
total_rewards_mean           1369.1120781674833
total_rewards_std            730.9488379054056
total_rewards_max            2444.7575009667075
total_rewards_min            509.70803126228253
Number of train steps total  216000
Number of env steps total    1082000
Number of rollouts total     0
Train Time (s)               44.01128636440262
(Previous) Eval Time (s)     32.38982365000993
Sample Time (s)              22.785553864203393
Epoch Time (s)               99.18666387861595
Total Train Time (s)         21057.357268909458
Epoch                        215
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:20:16.044910 UTC | [2020_01_10_11_29_18] Iteration #215 | Epoch Duration: 94.34144830703735
2020-01-10 17:20:16.045083 UTC | [2020_01_10_11_29_18] Iteration #215 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.86176956
Z variance train             0.0145938825
KL Divergence                18.892912
KL Loss                      1.8892912
QF Loss                      713.51074
VF Loss                      202.37285
Policy Loss                  -826.94403
Q Predictions Mean           824.24646
Q Predictions Std            188.23067
Q Predictions Max            998.9667
Q Predictions Min            178.30373
V Predictions Mean           825.8373
V Predictions Std            186.51765
V Predictions Max            999.61334
V Predictions Min            192.49861
Log Pis Mean                 -1.1171805
Log Pis Std                  2.6350791
Log Pis Max                  9.383428
Log Pis Min                  -7.824875
Policy mu Mean               0.034041423
Policy mu Std                0.52604634
Policy mu Max                2.0532534
Policy mu Min                -2.084248
Policy log std Mean          -0.89706
Policy log std Std           0.26304385
Policy log std Max           -0.1516937
Policy log std Min           -2.2473288
Z mean eval                  0.85124385
Z variance eval              0.016813964
total_rewards                [2053.50510917 2306.96984942 2389.3019897  2405.89600148 2416.36851424
  400.75920071 2282.74530011  208.62517817 2134.57788795 2189.20753333]
total_rewards_mean           1878.7956564285919
total_rewards_std            796.2605847784703
total_rewards_max            2416.3685142392815
total_rewards_min            208.62517817173796
Number of train steps total  217000
Number of env steps total    1087000
Number of rollouts total     0
Train Time (s)               44.80912807676941
(Previous) Eval Time (s)     27.544377588666975
Sample Time (s)              22.510750365443528
Epoch Time (s)               94.86425603087991
Total Train Time (s)         21151.248965569772
Epoch                        216
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:21:49.939601 UTC | [2020_01_10_11_29_18] Iteration #216 | Epoch Duration: 93.89438343048096
2020-01-10 17:21:49.939784 UTC | [2020_01_10_11_29_18] Iteration #216 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8485673
Z variance train             0.016842306
KL Divergence                18.816101
KL Loss                      1.8816102
QF Loss                      448.95642
VF Loss                      114.97094
Policy Loss                  -824.69934
Q Predictions Mean           821.1332
Q Predictions Std            182.93663
Q Predictions Max            991.35645
Q Predictions Min            195.30872
V Predictions Mean           820.53015
V Predictions Std            182.17618
V Predictions Max            988.1451
V Predictions Min            181.41684
Log Pis Mean                 -0.8350973
Log Pis Std                  2.5705333
Log Pis Max                  6.8821793
Log Pis Min                  -9.1677685
Policy mu Mean               0.052178755
Policy mu Std                0.5521415
Policy mu Max                2.2348003
Policy mu Min                -2.3422573
Policy log std Mean          -0.8936682
Policy log std Std           0.24471685
Policy log std Max           -0.1477089
Policy log std Min           -1.9770501
Z mean eval                  0.87064534
Z variance eval              0.01828434
total_rewards                [ 576.3889813   982.25500974 2099.36598421   76.89131956  597.05498363
   54.48093503  148.42730208 2314.51492286 2286.37352767  237.62374562]
total_rewards_mean           937.3376711720011
total_rewards_std            891.4427432584118
total_rewards_max            2314.5149228614923
total_rewards_min            54.480935026296926
Number of train steps total  218000
Number of env steps total    1092000
Number of rollouts total     0
Train Time (s)               44.026548066642135
(Previous) Eval Time (s)     26.574260869063437
Sample Time (s)              23.166385358199477
Epoch Time (s)               93.76719429390505
Total Train Time (s)         21237.399953423068
Epoch                        217
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:23:16.092804 UTC | [2020_01_10_11_29_18] Iteration #217 | Epoch Duration: 86.15288496017456
2020-01-10 17:23:16.092979 UTC | [2020_01_10_11_29_18] Iteration #217 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.87107104
Z variance train             0.01823892
KL Divergence                19.227793
KL Loss                      1.9227793
QF Loss                      463.99646
VF Loss                      163.031
Policy Loss                  -806.0265
Q Predictions Mean           803.3541
Q Predictions Std            207.30243
Q Predictions Max            978.34686
Q Predictions Min            32.279713
V Predictions Mean           808.8343
V Predictions Std            205.42136
V Predictions Max            990.232
V Predictions Min            177.98233
Log Pis Mean                 -1.14102
Log Pis Std                  2.5556936
Log Pis Max                  10.743835
Log Pis Min                  -8.752325
Policy mu Mean               0.021868117
Policy mu Std                0.5462067
Policy mu Max                3.1332157
Policy mu Min                -2.2235484
Policy log std Mean          -0.872188
Policy log std Std           0.25669798
Policy log std Max           -0.124161184
Policy log std Min           -1.8255267
Z mean eval                  0.8462843
Z variance eval              0.022502407
total_rewards                [ 116.4751186  2539.66114833 2027.07156313 2322.09178788   55.89367914
 2249.61239182 2347.39996699 2244.89696308 2530.0892225   930.97526306]
total_rewards_mean           1736.416710452846
total_rewards_std            932.4666258093747
total_rewards_max            2539.661148329113
total_rewards_min            55.893679138282295
Number of train steps total  219000
Number of env steps total    1097000
Number of rollouts total     0
Train Time (s)               44.272908410057425
(Previous) Eval Time (s)     18.959720156155527
Sample Time (s)              23.729876847472042
Epoch Time (s)               86.962505413685
Total Train Time (s)         21334.731614945456
Epoch                        218
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:24:53.429502 UTC | [2020_01_10_11_29_18] Iteration #218 | Epoch Duration: 97.33635067939758
2020-01-10 17:24:53.429804 UTC | [2020_01_10_11_29_18] Iteration #218 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.84608585
Z variance train             0.022464842
KL Divergence                18.56066
KL Loss                      1.856066
QF Loss                      1574.0059
VF Loss                      45.837173
Policy Loss                  -820.25354
Q Predictions Mean           819.7672
Q Predictions Std            196.55219
Q Predictions Max            1023.7689
Q Predictions Min            176.49202
V Predictions Mean           819.1829
V Predictions Std            197.70464
V Predictions Max            1015.7583
V Predictions Min            169.25082
Log Pis Mean                 -0.99607295
Log Pis Std                  2.5560062
Log Pis Max                  8.005212
Log Pis Min                  -7.1005583
Policy mu Mean               0.044721298
Policy mu Std                0.55624527
Policy mu Max                1.8942782
Policy mu Min                -1.9514288
Policy log std Mean          -0.8717854
Policy log std Std           0.25246766
Policy log std Max           -0.13137406
Policy log std Min           -1.8758824
Z mean eval                  0.8558655
Z variance eval              0.02349582
total_rewards                [1559.71244854 2419.95358614 1960.5164192  2422.46711672 2440.75456739
 1032.04334944 2337.78200058 1019.13939635 2568.23239817  409.45391728]
total_rewards_mean           1817.0055199810545
total_rewards_std            726.3260653801457
total_rewards_max            2568.232398167359
total_rewards_min            409.4539172787672
Number of train steps total  220000
Number of env steps total    1102000
Number of rollouts total     0
Train Time (s)               43.415214746724814
(Previous) Eval Time (s)     29.333285235334188
Sample Time (s)              22.95068015670404
Epoch Time (s)               95.69918013876304
Total Train Time (s)         21432.047814372927
Epoch                        219
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:26:30.745954 UTC | [2020_01_10_11_29_18] Iteration #219 | Epoch Duration: 97.31593012809753
2020-01-10 17:26:30.746135 UTC | [2020_01_10_11_29_18] Iteration #219 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8569601
Z variance train             0.023459386
KL Divergence                18.617437
KL Loss                      1.8617438
QF Loss                      455.95096
VF Loss                      316.81967
Policy Loss                  -832.0293
Q Predictions Mean           831.2067
Q Predictions Std            192.00325
Q Predictions Max            1049.7839
Q Predictions Min            89.693275
V Predictions Mean           833.02704
V Predictions Std            190.4641
V Predictions Max            1057.6406
V Predictions Min            129.84448
Log Pis Mean                 -0.8026891
Log Pis Std                  2.5332332
Log Pis Max                  7.0063715
Log Pis Min                  -9.0431185
Policy mu Mean               0.043354288
Policy mu Std                0.5779602
Policy mu Max                2.2265215
Policy mu Min                -1.7790389
Policy log std Mean          -0.8798346
Policy log std Std           0.24265638
Policy log std Max           -0.018933892
Policy log std Min           -1.7246706
Z mean eval                  0.8696844
Z variance eval              0.020926327
total_rewards                [2305.05954758 2508.03314048  110.91172041 2358.01244249 2322.26867191
 2266.9432237  2290.99353227  585.27684765 2403.18471094 2522.44703563]
total_rewards_mean           1967.313087305861
total_rewards_std            820.6123034181329
total_rewards_max            2522.44703563077
total_rewards_min            110.9117204099124
Number of train steps total  221000
Number of env steps total    1107000
Number of rollouts total     0
Train Time (s)               44.544618090149015
(Previous) Eval Time (s)     30.949814631137997
Sample Time (s)              22.650618720799685
Epoch Time (s)               98.1450514420867
Total Train Time (s)         21532.492602150887
Epoch                        220
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:28:11.194410 UTC | [2020_01_10_11_29_18] Iteration #220 | Epoch Duration: 100.44812393188477
2020-01-10 17:28:11.194630 UTC | [2020_01_10_11_29_18] Iteration #220 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.86863005
Z variance train             0.020904204
KL Divergence                18.767572
KL Loss                      1.8767573
QF Loss                      542.3109
VF Loss                      278.8384
Policy Loss                  -832.60736
Q Predictions Mean           830.54333
Q Predictions Std            185.1538
Q Predictions Max            1011.2088
Q Predictions Min            185.03772
V Predictions Mean           826.5486
V Predictions Std            185.66219
V Predictions Max            990.8824
V Predictions Min            181.60698
Log Pis Mean                 -0.8301337
Log Pis Std                  2.5882812
Log Pis Max                  12.339623
Log Pis Min                  -7.1076684
Policy mu Mean               0.033259757
Policy mu Std                0.56453687
Policy mu Max                2.3682256
Policy mu Min                -2.3261037
Policy log std Mean          -0.8913288
Policy log std Std           0.24254373
Policy log std Max           -0.10300022
Policy log std Min           -2.0039368
Z mean eval                  0.88099825
Z variance eval              0.018893462
total_rewards                [ 284.48290674  200.83689436  207.82582086 2178.85612105 2086.36979222
 2464.08998479  597.16494644  725.40997807 2346.32146722 1287.1845589 ]
total_rewards_mean           1237.854247064391
total_rewards_std            897.6977592387938
total_rewards_max            2464.0899847945207
total_rewards_min            200.83689436050634
Number of train steps total  222000
Number of env steps total    1112000
Number of rollouts total     0
Train Time (s)               44.15472645312548
(Previous) Eval Time (s)     33.25263881031424
Sample Time (s)              22.783901546150446
Epoch Time (s)               100.19126680959016
Total Train Time (s)         21624.486173627898
Epoch                        221
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:29:43.189636 UTC | [2020_01_10_11_29_18] Iteration #221 | Epoch Duration: 91.99485969543457
2020-01-10 17:29:43.189778 UTC | [2020_01_10_11_29_18] Iteration #221 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.88000345
Z variance train             0.01889449
KL Divergence                18.718536
KL Loss                      1.8718537
QF Loss                      468.59802
VF Loss                      182.61452
Policy Loss                  -820.4147
Q Predictions Mean           819.0222
Q Predictions Std            204.33693
Q Predictions Max            1009.3245
Q Predictions Min            172.66364
V Predictions Mean           823.30994
V Predictions Std            199.81332
V Predictions Max            1010.56415
V Predictions Min            181.85648
Log Pis Mean                 -0.9735639
Log Pis Std                  2.8294685
Log Pis Max                  7.881299
Log Pis Min                  -10.413624
Policy mu Mean               -0.022239178
Policy mu Std                0.55871594
Policy mu Max                2.3852825
Policy mu Min                -2.2825341
Policy log std Mean          -0.90213275
Policy log std Std           0.2759441
Policy log std Max           -0.19802308
Policy log std Min           -2.3972845
Z mean eval                  0.87903297
Z variance eval              0.020821664
total_rewards                [1534.73651304 2354.62602468 2443.67772129  580.48039068 2332.41800247
 1862.50269617  706.28074991 1824.50802817 2419.04536753 2454.44103909]
total_rewards_mean           1851.271653301635
total_rewards_std            674.4586129194075
total_rewards_max            2454.441039092653
total_rewards_min            580.4803906758832
Number of train steps total  223000
Number of env steps total    1117000
Number of rollouts total     0
Train Time (s)               43.61708918400109
(Previous) Eval Time (s)     25.055997163057327
Sample Time (s)              22.794522662181407
Epoch Time (s)               91.46760900923982
Total Train Time (s)         21721.35494798282
Epoch                        222
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:31:20.060548 UTC | [2020_01_10_11_29_18] Iteration #222 | Epoch Duration: 96.8706591129303
2020-01-10 17:31:20.060722 UTC | [2020_01_10_11_29_18] Iteration #222 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8798043
Z variance train             0.020902356
KL Divergence                18.324926
KL Loss                      1.8324927
QF Loss                      510.23
VF Loss                      171.36563
Policy Loss                  -814.31866
Q Predictions Mean           812.6723
Q Predictions Std            202.95035
Q Predictions Max            1003.6397
Q Predictions Min            170.7319
V Predictions Mean           823.3318
V Predictions Std            203.16325
V Predictions Max            1004.69165
V Predictions Min            175.77621
Log Pis Mean                 -1.0309073
Log Pis Std                  2.53224
Log Pis Max                  9.226225
Log Pis Min                  -6.7714205
Policy mu Mean               0.0009300534
Policy mu Std                0.5325685
Policy mu Max                1.9560784
Policy mu Min                -2.4625857
Policy log std Mean          -0.89951736
Policy log std Std           0.27015993
Policy log std Max           -0.12629074
Policy log std Min           -2.1762762
Z mean eval                  0.9060465
Z variance eval              0.026658276
total_rewards                [2301.55618269  786.313986   2244.3338749   807.067859   2175.87236597
  184.58749244 1813.92849842  494.62807306 2334.13418854 2432.56029216]
total_rewards_mean           1557.498281319831
total_rewards_std            837.5472084095809
total_rewards_max            2432.560292162656
total_rewards_min            184.58749244059226
Number of train steps total  224000
Number of env steps total    1122000
Number of rollouts total     0
Train Time (s)               43.34834966715425
(Previous) Eval Time (s)     30.458787343930453
Sample Time (s)              21.684392516501248
Epoch Time (s)               95.49152952758595
Total Train Time (s)         21812.146001095418
Epoch                        223
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:32:50.853155 UTC | [2020_01_10_11_29_18] Iteration #223 | Epoch Duration: 90.79230737686157
2020-01-10 17:32:50.853287 UTC | [2020_01_10_11_29_18] Iteration #223 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90984154
Z variance train             0.026688933
KL Divergence                18.104507
KL Loss                      1.8104508
QF Loss                      501.5816
VF Loss                      65.227615
Policy Loss                  -843.5523
Q Predictions Mean           841.0741
Q Predictions Std            186.88084
Q Predictions Max            1020.89246
Q Predictions Min            186.99716
V Predictions Mean           845.1444
V Predictions Std            185.5681
V Predictions Max            1037.4055
V Predictions Min            196.93788
Log Pis Mean                 -1.0679572
Log Pis Std                  2.5060003
Log Pis Max                  7.670253
Log Pis Min                  -7.284236
Policy mu Mean               0.020628233
Policy mu Std                0.56943655
Policy mu Max                2.2004552
Policy mu Min                -3.6773472
Policy log std Mean          -0.86988616
Policy log std Std           0.24126649
Policy log std Max           -0.043516576
Policy log std Min           -1.9291255
Z mean eval                  0.900993
Z variance eval              0.02163302
total_rewards                [2289.66412677  682.49737201 1606.97845765  263.88963712   58.4723091
 2220.11032725 1208.26914467 1473.6664294  2267.97089869 2326.62985075]
total_rewards_mean           1439.8148553411052
total_rewards_std            821.6159814925044
total_rewards_max            2326.62985074626
total_rewards_min            58.47230910075834
Number of train steps total  225000
Number of env steps total    1127000
Number of rollouts total     0
Train Time (s)               43.82098207203671
(Previous) Eval Time (s)     25.75937275402248
Sample Time (s)              22.627466460689902
Epoch Time (s)               92.2078212867491
Total Train Time (s)         21901.4720733501
Epoch                        224
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:34:20.183158 UTC | [2020_01_10_11_29_18] Iteration #224 | Epoch Duration: 89.32976174354553
2020-01-10 17:34:20.183329 UTC | [2020_01_10_11_29_18] Iteration #224 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9006758
Z variance train             0.021608407
KL Divergence                18.882156
KL Loss                      1.8882157
QF Loss                      592.7012
VF Loss                      95.477135
Policy Loss                  -858.226
Q Predictions Mean           858.7291
Q Predictions Std            190.8931
Q Predictions Max            1058.5183
Q Predictions Min            182.06306
V Predictions Mean           853.69574
V Predictions Std            190.17258
V Predictions Max            1048.4446
V Predictions Min            166.20805
Log Pis Mean                 -0.7840722
Log Pis Std                  2.5082676
Log Pis Max                  7.1909094
Log Pis Min                  -7.5788975
Policy mu Mean               0.034656107
Policy mu Std                0.59455144
Policy mu Max                2.3346322
Policy mu Min                -2.3654513
Policy log std Mean          -0.86711663
Policy log std Std           0.25065634
Policy log std Max           -0.10187483
Policy log std Min           -1.9574394
Z mean eval                  0.85674906
Z variance eval              0.031180471
total_rewards                [1494.54533744 2493.6975924    68.55277688  250.44135938  865.98754596
 1941.00398622 2578.99968154 2291.27278238 1540.91189832 2500.37515601]
total_rewards_mean           1602.5788116534882
total_rewards_std            887.8013265525864
total_rewards_max            2578.999681543458
total_rewards_min            68.5527768777676
Number of train steps total  226000
Number of env steps total    1132000
Number of rollouts total     0
Train Time (s)               43.36865729885176
(Previous) Eval Time (s)     22.8810579450801
Sample Time (s)              22.60395086556673
Epoch Time (s)               88.85366610949859
Total Train Time (s)         21996.707424264867
Epoch                        225
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:35:55.423734 UTC | [2020_01_10_11_29_18] Iteration #225 | Epoch Duration: 95.24022102355957
2020-01-10 17:35:55.424105 UTC | [2020_01_10_11_29_18] Iteration #225 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8560131
Z variance train             0.031129232
KL Divergence                17.491047
KL Loss                      1.7491047
QF Loss                      641.1769
VF Loss                      69.44862
Policy Loss                  -868.2585
Q Predictions Mean           866.3774
Q Predictions Std            182.74248
Q Predictions Max            1039.904
Q Predictions Min            190.84955
V Predictions Mean           868.89087
V Predictions Std            179.75941
V Predictions Max            1040.6573
V Predictions Min            192.13795
Log Pis Mean                 -1.0983318
Log Pis Std                  2.657424
Log Pis Max                  10.676818
Log Pis Min                  -12.664768
Policy mu Mean               -0.01675083
Policy mu Std                0.55174094
Policy mu Max                1.9039012
Policy mu Min                -2.240296
Policy log std Mean          -0.88449883
Policy log std Std           0.2522209
Policy log std Max           -0.14714086
Policy log std Min           -2.758845
Z mean eval                  0.881707
Z variance eval              0.02659069
total_rewards                [ 915.48649936 1152.45963691  116.61299557 2687.41958806 1532.27650987
 2560.88991876 2560.34926399  291.04364007 1598.1543141  2629.30553166]
total_rewards_mean           1604.399789835104
total_rewards_std            931.3743900962708
total_rewards_max            2687.419588059557
total_rewards_min            116.61299556903975
Number of train steps total  227000
Number of env steps total    1137000
Number of rollouts total     0
Train Time (s)               44.172176867257804
(Previous) Eval Time (s)     29.26731939986348
Sample Time (s)              21.252134968992323
Epoch Time (s)               94.69163123611361
Total Train Time (s)         22088.458595253993
Epoch                        226
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:37:27.175842 UTC | [2020_01_10_11_29_18] Iteration #226 | Epoch Duration: 91.75146842002869
2020-01-10 17:37:27.176051 UTC | [2020_01_10_11_29_18] Iteration #226 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8813168
Z variance train             0.026598414
KL Divergence                17.355865
KL Loss                      1.7355865
QF Loss                      738.77905
VF Loss                      79.02303
Policy Loss                  -827.89233
Q Predictions Mean           824.9815
Q Predictions Std            224.28079
Q Predictions Max            1024.6533
Q Predictions Min            170.16693
V Predictions Mean           831.5849
V Predictions Std            222.60013
V Predictions Max            1012.8831
V Predictions Min            179.38974
Log Pis Mean                 -1.2832243
Log Pis Std                  2.542341
Log Pis Max                  5.9377456
Log Pis Min                  -8.065206
Policy mu Mean               0.03629822
Policy mu Std                0.5328589
Policy mu Max                1.7919997
Policy mu Min                -1.7592051
Policy log std Mean          -0.85718286
Policy log std Std           0.26659435
Policy log std Max           -0.15972799
Policy log std Min           -1.9655263
Z mean eval                  0.8834575
Z variance eval              0.026657363
total_rewards                [2413.03912421  954.43371093 2005.90894467  175.93187048 2393.75998076
 2486.70043983  931.06978132  385.87083471  863.36572774  875.37407123]
total_rewards_mean           1348.5454485889466
total_rewards_std            839.2740480879906
total_rewards_max            2486.7004398285144
total_rewards_min            175.93187048198286
Number of train steps total  228000
Number of env steps total    1142000
Number of rollouts total     0
Train Time (s)               43.58777786977589
(Previous) Eval Time (s)     26.326925056055188
Sample Time (s)              21.036490559577942
Epoch Time (s)               90.95119348540902
Total Train Time (s)         22175.21326423483
Epoch                        227
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:38:53.931995 UTC | [2020_01_10_11_29_18] Iteration #227 | Epoch Duration: 86.75579166412354
2020-01-10 17:38:53.932127 UTC | [2020_01_10_11_29_18] Iteration #227 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.88092804
Z variance train             0.026649768
KL Divergence                17.358017
KL Loss                      1.7358017
QF Loss                      577.57135
VF Loss                      56.671417
Policy Loss                  -863.1718
Q Predictions Mean           859.9309
Q Predictions Std            212.23878
Q Predictions Max            1045.2789
Q Predictions Min            169.22858
V Predictions Mean           863.95667
V Predictions Std            208.8254
V Predictions Max            1042.0344
V Predictions Min            189.61388
Log Pis Mean                 -0.939301
Log Pis Std                  2.5003915
Log Pis Max                  5.978489
Log Pis Min                  -8.899183
Policy mu Mean               0.034415577
Policy mu Std                0.5466146
Policy mu Max                1.796847
Policy mu Min                -1.8458532
Policy log std Mean          -0.8909604
Policy log std Std           0.256042
Policy log std Max           -0.11364931
Policy log std Min           -1.7836089
Z mean eval                  0.92250174
Z variance eval              0.02902115
total_rewards                [ 726.96735492 2399.39083905 2155.1232598    33.16640432 2157.15059314
  345.05969218 1268.01959986 2488.86921682  390.90457829 2387.99307923]
total_rewards_mean           1435.2644617613594
total_rewards_std            936.0234692282704
total_rewards_max            2488.8692168182433
total_rewards_min            33.16640432489898
Number of train steps total  229000
Number of env steps total    1147000
Number of rollouts total     0
Train Time (s)               43.90533682098612
(Previous) Eval Time (s)     22.13129533221945
Sample Time (s)              22.974997987039387
Epoch Time (s)               89.01163014024496
Total Train Time (s)         22269.617529659066
Epoch                        228
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:40:28.340414 UTC | [2020_01_10_11_29_18] Iteration #228 | Epoch Duration: 94.40815544128418
2020-01-10 17:40:28.340598 UTC | [2020_01_10_11_29_18] Iteration #228 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9150451
Z variance train             0.02907398
KL Divergence                17.494898
KL Loss                      1.7494898
QF Loss                      520.6714
VF Loss                      131.79102
Policy Loss                  -852.5733
Q Predictions Mean           850.99994
Q Predictions Std            204.82521
Q Predictions Max            1040.638
Q Predictions Min            182.5382
V Predictions Mean           858.23834
V Predictions Std            206.03596
V Predictions Max            1038.598
V Predictions Min            190.8263
Log Pis Mean                 -0.62686723
Log Pis Std                  2.6588151
Log Pis Max                  8.419102
Log Pis Min                  -8.119925
Policy mu Mean               0.0023453766
Policy mu Std                0.5788082
Policy mu Max                2.1283808
Policy mu Min                -3.0458531
Policy log std Mean          -0.896096
Policy log std Std           0.26941016
Policy log std Max           -0.20236433
Policy log std Min           -1.9728274
Z mean eval                  0.88100994
Z variance eval              0.021272281
total_rewards                [1896.44057772 2357.26369599 2610.88228993  826.74601529  250.58929801
  656.50172708 2570.33949416  277.19934114 1381.64921278 1438.16871941]
total_rewards_mean           1426.5780371512305
total_rewards_std            863.5220471222492
total_rewards_max            2610.8822899322513
total_rewards_min            250.58929801489637
Number of train steps total  230000
Number of env steps total    1152000
Number of rollouts total     0
Train Time (s)               43.4551417469047
(Previous) Eval Time (s)     27.52759583806619
Sample Time (s)              23.10986774880439
Epoch Time (s)               94.09260533377528
Total Train Time (s)         22360.66316677723
Epoch                        229
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:41:59.393413 UTC | [2020_01_10_11_29_18] Iteration #229 | Epoch Duration: 91.0525233745575
2020-01-10 17:41:59.393876 UTC | [2020_01_10_11_29_18] Iteration #229 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8792199
Z variance train             0.021205459
KL Divergence                18.188232
KL Loss                      1.8188232
QF Loss                      407.37265
VF Loss                      164.60118
Policy Loss                  -867.3499
Q Predictions Mean           864.4013
Q Predictions Std            199.07834
Q Predictions Max            1030.4696
Q Predictions Min            119.07438
V Predictions Mean           858.2351
V Predictions Std            199.13774
V Predictions Max            1017.0067
V Predictions Min            109.792755
Log Pis Mean                 -1.0559037
Log Pis Std                  2.3324542
Log Pis Max                  7.1668215
Log Pis Min                  -6.43104
Policy mu Mean               0.007546963
Policy mu Std                0.54939187
Policy mu Max                1.9228141
Policy mu Min                -1.9101892
Policy log std Mean          -0.87723374
Policy log std Std           0.25129813
Policy log std Max           -0.10420179
Policy log std Min           -2.026728
Z mean eval                  0.8826014
Z variance eval              0.021315766
total_rewards                [2271.36538597 1779.34784298  205.04578448 2330.14854452 2394.24865813
 1782.87393365 1204.80771435 2608.66504648 2333.79217822  913.59931727]
total_rewards_mean           1782.3894406057802
total_rewards_std            740.047633163946
total_rewards_max            2608.6650464796594
total_rewards_min            205.04578448234645
Number of train steps total  231000
Number of env steps total    1157000
Number of rollouts total     0
Train Time (s)               43.831146403215826
(Previous) Eval Time (s)     24.487225000746548
Sample Time (s)              23.029108230024576
Epoch Time (s)               91.34747963398695
Total Train Time (s)         22454.918076905422
Epoch                        230
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:43:33.647251 UTC | [2020_01_10_11_29_18] Iteration #230 | Epoch Duration: 94.25312495231628
2020-01-10 17:43:33.647382 UTC | [2020_01_10_11_29_18] Iteration #230 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.88339007
Z variance train             0.021243894
KL Divergence                17.694555
KL Loss                      1.7694556
QF Loss                      601.1783
VF Loss                      134.26637
Policy Loss                  -863.7972
Q Predictions Mean           862.0023
Q Predictions Std            198.34395
Q Predictions Max            1042.3721
Q Predictions Min            207.69554
V Predictions Mean           860.4409
V Predictions Std            193.8863
V Predictions Max            1048.4908
V Predictions Min            211.56534
Log Pis Mean                 -1.1573161
Log Pis Std                  2.9811742
Log Pis Max                  10.916155
Log Pis Min                  -8.294125
Policy mu Mean               0.06550782
Policy mu Std                0.5723178
Policy mu Max                2.043843
Policy mu Min                -3.6490438
Policy log std Mean          -0.87739456
Policy log std Std           0.25376925
Policy log std Max           -0.20740598
Policy log std Min           -2.0613036
Z mean eval                  0.89263535
Z variance eval              0.016556112
total_rewards                [ -20.90264656   -9.88957836 2157.2152601  2045.94746912  922.32610282
  271.52746988 1711.96412762 2215.97474177  436.0017023  1118.48921917]
total_rewards_mean           1084.865386786083
total_rewards_std            853.0872071376386
total_rewards_max            2215.9747417717017
total_rewards_min            -20.9026465625526
Number of train steps total  232000
Number of env steps total    1162000
Number of rollouts total     0
Train Time (s)               43.468093818984926
(Previous) Eval Time (s)     27.39264646777883
Sample Time (s)              23.000957761891186
Epoch Time (s)               93.86169804865494
Total Train Time (s)         22541.990812703967
Epoch                        231
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:45:00.723402 UTC | [2020_01_10_11_29_18] Iteration #231 | Epoch Duration: 87.07590579986572
2020-01-10 17:45:00.723575 UTC | [2020_01_10_11_29_18] Iteration #231 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89111674
Z variance train             0.016542863
KL Divergence                19.149658
KL Loss                      1.9149659
QF Loss                      418.07007
VF Loss                      63.992584
Policy Loss                  -880.5229
Q Predictions Mean           878.5386
Q Predictions Std            192.82324
Q Predictions Max            1038.0154
Q Predictions Min            159.35016
V Predictions Mean           881.3733
V Predictions Std            190.11327
V Predictions Max            1042.2797
V Predictions Min            177.0963
Log Pis Mean                 -0.80539984
Log Pis Std                  2.7202501
Log Pis Max                  6.935979
Log Pis Min                  -9.63079
Policy mu Mean               0.041887477
Policy mu Std                0.55897576
Policy mu Max                2.1261933
Policy mu Min                -2.1945374
Policy log std Mean          -0.904783
Policy log std Std           0.2595872
Policy log std Max           -0.033418834
Policy log std Min           -1.9570062
Z mean eval                  0.85750353
Z variance eval              0.024646122
total_rewards                [ 127.3063401   584.96489772   93.87344039 2441.47790129 1215.20693137
 1456.0157085  2512.57478316 2442.86824843  587.13226417  736.32499313]
total_rewards_mean           1219.774550824666
total_rewards_std            906.2981624933972
total_rewards_max            2512.574783157502
total_rewards_min            93.8734403877466
Number of train steps total  233000
Number of env steps total    1167000
Number of rollouts total     0
Train Time (s)               43.50740979006514
(Previous) Eval Time (s)     20.606611711904407
Sample Time (s)              22.558760390151292
Epoch Time (s)               86.67278189212084
Total Train Time (s)         22626.87204657495
Epoch                        232
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:46:25.609052 UTC | [2020_01_10_11_29_18] Iteration #232 | Epoch Duration: 84.88533043861389
2020-01-10 17:46:25.609265 UTC | [2020_01_10_11_29_18] Iteration #232 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.85774344
Z variance train             0.024628567
KL Divergence                18.068338
KL Loss                      1.8068339
QF Loss                      665.6352
VF Loss                      91.2374
Policy Loss                  -878.27997
Q Predictions Mean           876.2875
Q Predictions Std            185.73796
Q Predictions Max            1050.0444
Q Predictions Min            140.71066
V Predictions Mean           878.78674
V Predictions Std            185.42436
V Predictions Max            1046.403
V Predictions Min            142.33337
Log Pis Mean                 -1.0685542
Log Pis Std                  2.5174878
Log Pis Max                  11.449537
Log Pis Min                  -7.492796
Policy mu Mean               -0.00075535756
Policy mu Std                0.5500183
Policy mu Max                2.9461083
Policy mu Min                -2.709031
Policy log std Mean          -0.87020934
Policy log std Std           0.24998328
Policy log std Max           -0.22171116
Policy log std Min           -2.2769966
Z mean eval                  0.88816035
Z variance eval              0.024928877
total_rewards                [2555.65254616 2591.87132854 2500.40857021 2543.30781121 1498.98575581
 1185.80424505  590.99681274 2237.87667288 2651.62494081 2592.72606754]
total_rewards_mean           2094.9254750951886
total_rewards_std            696.1529735868144
total_rewards_max            2651.6249408142976
total_rewards_min            590.9968127440975
Number of train steps total  234000
Number of env steps total    1172000
Number of rollouts total     0
Train Time (s)               44.25983690377325
(Previous) Eval Time (s)     18.818922810722142
Sample Time (s)              21.064292758703232
Epoch Time (s)               84.14305247319862
Total Train Time (s)         22724.81442846451
Epoch                        233
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:48:03.552510 UTC | [2020_01_10_11_29_18] Iteration #233 | Epoch Duration: 97.94309759140015
2020-01-10 17:48:03.552647 UTC | [2020_01_10_11_29_18] Iteration #233 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.88939685
Z variance train             0.024965316
KL Divergence                18.428383
KL Loss                      1.8428383
QF Loss                      1996.7108
VF Loss                      173.95358
Policy Loss                  -898.5569
Q Predictions Mean           895.8142
Q Predictions Std            194.67624
Q Predictions Max            1079.6462
Q Predictions Min            188.91461
V Predictions Mean           887.76953
V Predictions Std            192.30315
V Predictions Max            1062.0507
V Predictions Min            190.14854
Log Pis Mean                 -0.7843848
Log Pis Std                  2.621522
Log Pis Max                  8.772235
Log Pis Min                  -10.566489
Policy mu Mean               -0.004022342
Policy mu Std                0.5796961
Policy mu Max                2.0972788
Policy mu Min                -2.1335151
Policy log std Mean          -0.89183843
Policy log std Std           0.24081111
Policy log std Max           -0.17161274
Policy log std Min           -1.7014885
Z mean eval                  0.8822708
Z variance eval              0.023363262
total_rewards                [2305.3565474  1375.61995383 2660.14769332 1328.5310705  2491.19519406
 1143.54813294 1792.92789657 1210.2591261   165.4686814  2560.63615362]
total_rewards_mean           1703.3690449747132
total_rewards_std            762.3010827369295
total_rewards_max            2660.1476933154267
total_rewards_min            165.46868140357458
Number of train steps total  235000
Number of env steps total    1177000
Number of rollouts total     0
Train Time (s)               43.72952382173389
(Previous) Eval Time (s)     32.61875393986702
Sample Time (s)              22.49749432783574
Epoch Time (s)               98.84577208943665
Total Train Time (s)         22819.96483088797
Epoch                        234
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:49:38.705740 UTC | [2020_01_10_11_29_18] Iteration #234 | Epoch Duration: 95.15299034118652
2020-01-10 17:49:38.705872 UTC | [2020_01_10_11_29_18] Iteration #234 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.88104934
Z variance train             0.023349572
KL Divergence                18.549911
KL Loss                      1.8549912
QF Loss                      784.2013
VF Loss                      125.46887
Policy Loss                  -873.22644
Q Predictions Mean           872.6773
Q Predictions Std            204.52255
Q Predictions Max            1102.0645
Q Predictions Min            181.00175
V Predictions Mean           874.79395
V Predictions Std            199.19852
V Predictions Max            1086.3418
V Predictions Min            188.5905
Log Pis Mean                 -0.795897
Log Pis Std                  2.9979904
Log Pis Max                  14.067406
Log Pis Min                  -9.517693
Policy mu Mean               0.0067304224
Policy mu Std                0.59094673
Policy mu Max                3.9975615
Policy mu Min                -2.4003222
Policy log std Mean          -0.916698
Policy log std Std           0.29586485
Policy log std Max           0.19604933
Policy log std Min           -2.807785
Z mean eval                  0.86331433
Z variance eval              0.015056536
total_rewards                [ 232.85396825 2443.03514696  327.3049674   466.11628017 1710.37882039
 1075.20411672 2543.85241303 2694.64291566 1537.59361983 2535.29760985]
total_rewards_mean           1556.627985826291
total_rewards_std            933.905831434426
total_rewards_max            2694.6429156551753
total_rewards_min            232.85396824702363
Number of train steps total  236000
Number of env steps total    1182000
Number of rollouts total     0
Train Time (s)               44.42243088502437
(Previous) Eval Time (s)     28.925719345919788
Sample Time (s)              22.844533738214523
Epoch Time (s)               96.19268396915868
Total Train Time (s)         22914.456202280242
Epoch                        235
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:51:13.203842 UTC | [2020_01_10_11_29_18] Iteration #235 | Epoch Duration: 94.49782371520996
2020-01-10 17:51:13.204115 UTC | [2020_01_10_11_29_18] Iteration #235 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8605668
Z variance train             0.015045458
KL Divergence                19.47642
KL Loss                      1.947642
QF Loss                      645.801
VF Loss                      1016.3132
Policy Loss                  -867.7994
Q Predictions Mean           866.14545
Q Predictions Std            223.29388
Q Predictions Max            1077.6466
Q Predictions Min            -41.94238
V Predictions Mean           874.89954
V Predictions Std            215.56517
V Predictions Max            1084.4071
V Predictions Min            53.415802
Log Pis Mean                 -0.5875114
Log Pis Std                  2.689889
Log Pis Max                  8.154019
Log Pis Min                  -6.7833614
Policy mu Mean               0.025055371
Policy mu Std                0.57969093
Policy mu Max                2.3196805
Policy mu Min                -2.249453
Policy log std Mean          -0.8886571
Policy log std Std           0.2762819
Policy log std Max           -0.112003565
Policy log std Min           -2.3959916
Z mean eval                  0.90563726
Z variance eval              0.017817816
total_rewards                [2570.77268863 1747.25071442  644.37950061   39.7743387   580.8767009
 2727.87474234  405.65701902 2593.77755064  -23.06207318 2598.26223929]
total_rewards_mean           1388.5563421358324
total_rewards_std            1105.4471283493012
total_rewards_max            2727.874742342674
total_rewards_min            -23.06207318033015
Number of train steps total  237000
Number of env steps total    1187000
Number of rollouts total     0
Train Time (s)               43.63279089797288
(Previous) Eval Time (s)     27.230595596134663
Sample Time (s)              23.41924007097259
Epoch Time (s)               94.28262656508014
Total Train Time (s)         23013.732789474074
Epoch                        236
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:52:52.485878 UTC | [2020_01_10_11_29_18] Iteration #236 | Epoch Duration: 99.28159284591675
2020-01-10 17:52:52.486174 UTC | [2020_01_10_11_29_18] Iteration #236 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9054185
Z variance train             0.017867064
KL Divergence                19.319572
KL Loss                      1.9319572
QF Loss                      416.8715
VF Loss                      138.00597
Policy Loss                  -897.5136
Q Predictions Mean           895.4044
Q Predictions Std            187.92717
Q Predictions Max            1065.8387
Q Predictions Min            162.61789
V Predictions Mean           895.2125
V Predictions Std            184.54315
V Predictions Max            1062.5903
V Predictions Min            164.22281
Log Pis Mean                 -0.87183756
Log Pis Std                  2.5387244
Log Pis Max                  9.323746
Log Pis Min                  -7.5861826
Policy mu Mean               0.019518944
Policy mu Std                0.5809388
Policy mu Max                2.3129044
Policy mu Min                -3.3171422
Policy log std Mean          -0.89604497
Policy log std Std           0.26194286
Policy log std Max           -0.034073114
Policy log std Min           -2.0172727
Z mean eval                  0.93214
Z variance eval              0.015442366
total_rewards                [2375.48787822 2482.6543083  2623.43064783 2464.95942788 2514.55512254
 2390.53113992 2472.136501   2254.70426755  819.74673169 1295.8292349 ]
total_rewards_mean           2169.403525983633
total_rewards_std            573.2143362420629
total_rewards_max            2623.4306478341696
total_rewards_min            819.746731689581
Number of train steps total  238000
Number of env steps total    1192000
Number of rollouts total     0
Train Time (s)               43.580942693166435
(Previous) Eval Time (s)     32.22929134871811
Sample Time (s)              22.663401235826313
Epoch Time (s)               98.47363527771086
Total Train Time (s)         23112.647011338267
Epoch                        237
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:54:31.400787 UTC | [2020_01_10_11_29_18] Iteration #237 | Epoch Duration: 98.91441416740417
2020-01-10 17:54:31.400930 UTC | [2020_01_10_11_29_18] Iteration #237 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9329284
Z variance train             0.015443022
KL Divergence                19.621407
KL Loss                      1.9621407
QF Loss                      771.2279
VF Loss                      568.80835
Policy Loss                  -899.5141
Q Predictions Mean           895.98553
Q Predictions Std            194.5015
Q Predictions Max            1083.1393
Q Predictions Min            -5.006978
V Predictions Mean           888.9447
V Predictions Std            188.3641
V Predictions Max            1078.4526
V Predictions Min            115.75352
Log Pis Mean                 -0.88370085
Log Pis Std                  2.694659
Log Pis Max                  11.031996
Log Pis Min                  -8.250601
Policy mu Mean               0.042753696
Policy mu Std                0.5490102
Policy mu Max                2.2725828
Policy mu Min                -2.2241051
Policy log std Mean          -0.93118465
Policy log std Std           0.283846
Policy log std Max           -0.17489737
Policy log std Min           -2.7131581
Z mean eval                  0.91906357
Z variance eval              0.01853865
total_rewards                [ 655.74709904  539.15954365 1307.45521141 2508.55649543 1104.13453169
  322.71277256  585.31313902 2551.68680547 2498.02595551 2275.38328888]
total_rewards_mean           1434.817484266512
total_rewards_std            879.2290013266265
total_rewards_max            2551.686805472669
total_rewards_min            322.71277256385713
Number of train steps total  239000
Number of env steps total    1197000
Number of rollouts total     0
Train Time (s)               44.674508763011545
(Previous) Eval Time (s)     32.66983112273738
Sample Time (s)              22.780589937232435
Epoch Time (s)               100.12492982298136
Total Train Time (s)         23202.91705151135
Epoch                        238
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:56:01.674827 UTC | [2020_01_10_11_29_18] Iteration #238 | Epoch Duration: 90.27379608154297
2020-01-10 17:56:01.674963 UTC | [2020_01_10_11_29_18] Iteration #238 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91899604
Z variance train             0.018472362
KL Divergence                19.676662
KL Loss                      1.9676663
QF Loss                      2030.3726
VF Loss                      400.61984
Policy Loss                  -901.65814
Q Predictions Mean           901.5217
Q Predictions Std            171.59967
Q Predictions Max            1070.6011
Q Predictions Min            216.27754
V Predictions Mean           906.3644
V Predictions Std            166.83386
V Predictions Max            1083.8628
V Predictions Min            214.82655
Log Pis Mean                 -0.620263
Log Pis Std                  2.648268
Log Pis Max                  11.600969
Log Pis Min                  -8.552045
Policy mu Mean               -0.026139071
Policy mu Std                0.6126466
Policy mu Max                1.966227
Policy mu Min                -2.163645
Policy log std Mean          -0.8809156
Policy log std Std           0.2609755
Policy log std Max           -0.15326107
Policy log std Min           -2.7114482
Z mean eval                  0.8723666
Z variance eval              0.030029321
total_rewards                [ 940.96129698  146.21745162 1210.81127279 2541.76673026 2518.36649311
 2433.54747449 2528.82511944 2036.01573611 2367.89253444 2515.275533  ]
total_rewards_mean           1923.967964223725
total_rewards_std            809.6337572944433
total_rewards_max            2541.7667302581094
total_rewards_min            146.2174516222049
Number of train steps total  240000
Number of env steps total    1202000
Number of rollouts total     0
Train Time (s)               43.211183215957135
(Previous) Eval Time (s)     22.818453174084425
Sample Time (s)              22.143670899793506
Epoch Time (s)               88.17330728983507
Total Train Time (s)         23295.590940945316
Epoch                        239
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:57:34.351196 UTC | [2020_01_10_11_29_18] Iteration #239 | Epoch Duration: 92.67612838745117
2020-01-10 17:57:34.351335 UTC | [2020_01_10_11_29_18] Iteration #239 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8722666
Z variance train             0.029981334
KL Divergence                18.295084
KL Loss                      1.8295084
QF Loss                      480.3689
VF Loss                      162.46661
Policy Loss                  -899.1504
Q Predictions Mean           894.9043
Q Predictions Std            199.22945
Q Predictions Max            1065.3074
Q Predictions Min            32.045227
V Predictions Mean           898.0247
V Predictions Std            198.94025
V Predictions Max            1065.7965
V Predictions Min            54.202763
Log Pis Mean                 -0.8443984
Log Pis Std                  2.801066
Log Pis Max                  8.914579
Log Pis Min                  -8.435016
Policy mu Mean               0.041399725
Policy mu Std                0.55174357
Policy mu Max                2.2130034
Policy mu Min                -3.010342
Policy log std Mean          -0.9111626
Policy log std Std           0.25919244
Policy log std Max           -0.19542015
Policy log std Min           -2.0307446
Z mean eval                  0.89708453
Z variance eval              0.022789702
total_rewards                [ -69.21730685   59.84975724   97.24890684  905.45013228 2655.18942005
  479.24032383 2074.22376623 1305.76759051  917.97535082 2546.75004191]
total_rewards_mean           1097.2477982863534
total_rewards_std            970.2521790937616
total_rewards_max            2655.1894200527613
total_rewards_min            -69.21730685236223
Number of train steps total  241000
Number of env steps total    1207000
Number of rollouts total     0
Train Time (s)               44.366687149740756
(Previous) Eval Time (s)     27.321045918855816
Sample Time (s)              22.852806973271072
Epoch Time (s)               94.54054004186764
Total Train Time (s)         23383.88272192888
Epoch                        240
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:59:02.646932 UTC | [2020_01_10_11_29_18] Iteration #240 | Epoch Duration: 88.29549384117126
2020-01-10 17:59:02.647076 UTC | [2020_01_10_11_29_18] Iteration #240 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.896352
Z variance train             0.022796804
KL Divergence                18.977676
KL Loss                      1.8977677
QF Loss                      952.56976
VF Loss                      241.61432
Policy Loss                  -899.9567
Q Predictions Mean           895.9761
Q Predictions Std            190.96022
Q Predictions Max            1072.2349
Q Predictions Min            158.33969
V Predictions Mean           892.56213
V Predictions Std            190.51767
V Predictions Max            1068.4365
V Predictions Min            177.92287
Log Pis Mean                 -0.74959004
Log Pis Std                  2.536337
Log Pis Max                  10.256533
Log Pis Min                  -7.62494
Policy mu Mean               0.039098825
Policy mu Std                0.57048255
Policy mu Max                2.7535431
Policy mu Min                -2.0319817
Policy log std Mean          -0.93101716
Policy log std Std           0.25437108
Policy log std Max           -0.11198926
Policy log std Min           -2.130566
Z mean eval                  0.8849095
Z variance eval              0.023365904
total_rewards                [2441.7944347  1879.07507541  429.38417698  118.42978849 1293.68487968
 2633.3301206  2530.0882082   854.21568002 1177.59448847 1350.09512377]
total_rewards_mean           1470.7691976311723
total_rewards_std            837.1752351396151
total_rewards_max            2633.330120597534
total_rewards_min            118.42978848923391
Number of train steps total  242000
Number of env steps total    1212000
Number of rollouts total     0
Train Time (s)               43.5203444622457
(Previous) Eval Time (s)     21.075733570382
Sample Time (s)              24.064766135066748
Epoch Time (s)               88.66084416769445
Total Train Time (s)         23476.18754224293
Epoch                        241
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:00:34.954572 UTC | [2020_01_10_11_29_18] Iteration #241 | Epoch Duration: 92.3073844909668
2020-01-10 18:00:34.954739 UTC | [2020_01_10_11_29_18] Iteration #241 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8841874
Z variance train             0.023387369
KL Divergence                18.603828
KL Loss                      1.8603829
QF Loss                      413.7849
VF Loss                      71.05379
Policy Loss                  -898.05286
Q Predictions Mean           896.37134
Q Predictions Std            216.50961
Q Predictions Max            1073.5796
Q Predictions Min            24.586798
V Predictions Mean           895.01117
V Predictions Std            214.98732
V Predictions Max            1065.7362
V Predictions Min            12.29285
Log Pis Mean                 -0.7719181
Log Pis Std                  2.4724731
Log Pis Max                  7.847105
Log Pis Min                  -8.851694
Policy mu Mean               0.08446048
Policy mu Std                0.54459405
Policy mu Max                2.1670027
Policy mu Min                -1.8239475
Policy log std Mean          -0.92285347
Policy log std Std           0.25496885
Policy log std Max           -0.06885618
Policy log std Min           -2.451601
Z mean eval                  0.9377362
Z variance eval              0.026014816
total_rewards                [1549.68983313 1129.06414679 2342.34194655 2528.7462282   923.50656955
 1249.19508343 1226.11147554 2401.47166985 2507.80571504 2652.68342695]
total_rewards_mean           1851.0616095050038
total_rewards_std            655.9530490771702
total_rewards_max            2652.683426954011
total_rewards_min            923.5065695489834
Number of train steps total  243000
Number of env steps total    1217000
Number of rollouts total     0
Train Time (s)               43.44376368727535
(Previous) Eval Time (s)     24.722019960172474
Sample Time (s)              21.059720783494413
Epoch Time (s)               89.22550443094224
Total Train Time (s)         23568.722816479858
Epoch                        242
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:02:07.492041 UTC | [2020_01_10_11_29_18] Iteration #242 | Epoch Duration: 92.53715658187866
2020-01-10 18:02:07.492208 UTC | [2020_01_10_11_29_18] Iteration #242 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9376
Z variance train             0.026045775
KL Divergence                19.129038
KL Loss                      1.9129038
QF Loss                      527.69714
VF Loss                      109.433
Policy Loss                  -903.34753
Q Predictions Mean           902.99097
Q Predictions Std            186.22928
Q Predictions Max            1091.7393
Q Predictions Min            171.32968
V Predictions Mean           904.349
V Predictions Std            185.72002
V Predictions Max            1086.6677
V Predictions Min            172.10655
Log Pis Mean                 -0.7418541
Log Pis Std                  2.8882747
Log Pis Max                  11.437509
Log Pis Min                  -8.252638
Policy mu Mean               0.016284779
Policy mu Std                0.56909114
Policy mu Max                2.1732192
Policy mu Min                -1.9642843
Policy log std Mean          -0.9011933
Policy log std Std           0.25733468
Policy log std Max           -0.22936541
Policy log std Min           -2.3041544
Z mean eval                  0.9518506
Z variance eval              0.022743631
total_rewards                [1609.04503951 2303.76926577  237.50689715 2655.74533741  368.96014358
 2503.08526301 2545.01067275 2587.43326248 2575.13340426  678.55363585]
total_rewards_mean           1806.424292177134
total_rewards_std            950.7517593403088
total_rewards_max            2655.745337414373
total_rewards_min            237.50689715118256
Number of train steps total  244000
Number of env steps total    1222000
Number of rollouts total     0
Train Time (s)               44.14030776312575
(Previous) Eval Time (s)     28.033414661418647
Sample Time (s)              22.47755234129727
Epoch Time (s)               94.65127476584166
Total Train Time (s)         23665.572107321583
Epoch                        243
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:03:44.345423 UTC | [2020_01_10_11_29_18] Iteration #243 | Epoch Duration: 96.85307049751282
2020-01-10 18:03:44.345599 UTC | [2020_01_10_11_29_18] Iteration #243 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95381385
Z variance train             0.022799036
KL Divergence                19.281319
KL Loss                      1.9281319
QF Loss                      1266.9495
VF Loss                      360.16992
Policy Loss                  -900.1751
Q Predictions Mean           899.3475
Q Predictions Std            198.33656
Q Predictions Max            1081.3646
Q Predictions Min            -3.3249884
V Predictions Mean           913.46924
V Predictions Std            198.28876
V Predictions Max            1081.5016
V Predictions Min            105.863304
Log Pis Mean                 -0.86164516
Log Pis Std                  2.5854065
Log Pis Max                  9.666864
Log Pis Min                  -7.7421236
Policy mu Mean               -0.010039198
Policy mu Std                0.5466101
Policy mu Max                1.9908916
Policy mu Min                -2.353019
Policy log std Mean          -0.9237753
Policy log std Std           0.26378345
Policy log std Max           -0.16564578
Policy log std Min           -2.0979786
Z mean eval                  0.9065889
Z variance eval              0.017811304
total_rewards                [2258.0299414  2599.80721328 2644.76830256 1974.10007903 2489.21907647
 2454.49923064 1118.21362545 2507.22999883 2460.59166688 2695.77587544]
total_rewards_mean           2320.223500998179
total_rewards_std            446.5755588560486
total_rewards_max            2695.775875444145
total_rewards_min            1118.2136254475781
Number of train steps total  245000
Number of env steps total    1227000
Number of rollouts total     0
Train Time (s)               44.27641491685063
(Previous) Eval Time (s)     30.23498564772308
Sample Time (s)              22.545873670373112
Epoch Time (s)               97.05727423494682
Total Train Time (s)         23766.958246973343
Epoch                        244
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:05:25.738349 UTC | [2020_01_10_11_29_18] Iteration #244 | Epoch Duration: 101.39257907867432
2020-01-10 18:05:25.738649 UTC | [2020_01_10_11_29_18] Iteration #244 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9080351
Z variance train             0.01776358
KL Divergence                19.609068
KL Loss                      1.9609069
QF Loss                      550.5051
VF Loss                      1655.6298
Policy Loss                  -915.96515
Q Predictions Mean           911.6581
Q Predictions Std            182.34651
Q Predictions Max            1104.9648
Q Predictions Min            -14.931857
V Predictions Mean           912.3208
V Predictions Std            165.09464
V Predictions Max            1085.7988
V Predictions Min            206.0032
Log Pis Mean                 -0.5105133
Log Pis Std                  2.6861863
Log Pis Max                  15.522942
Log Pis Min                  -8.303795
Policy mu Mean               0.0023993012
Policy mu Std                0.5801711
Policy mu Max                2.0132964
Policy mu Min                -2.2712152
Policy log std Mean          -0.94827986
Policy log std Std           0.28182828
Policy log std Max           -0.16530567
Policy log std Min           -3.1457837
Z mean eval                  0.9219203
Z variance eval              0.021291506
total_rewards                [2563.83260029  618.16103537 2375.71217033  485.48037907 2742.24297073
 2176.27394908 1279.75924472 2220.55902647 1924.49047027  899.94446515]
total_rewards_mean           1728.6456311477225
total_rewards_std            793.1706965561915
total_rewards_max            2742.2429707274187
total_rewards_min            485.4803790651844
Number of train steps total  246000
Number of env steps total    1232000
Number of rollouts total     0
Train Time (s)               43.58542022341862
(Previous) Eval Time (s)     34.57002315297723
Sample Time (s)              22.981508363969624
Epoch Time (s)               101.13695174036548
Total Train Time (s)         23862.701964930166
Epoch                        245
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:07:01.488392 UTC | [2020_01_10_11_29_18] Iteration #245 | Epoch Duration: 95.74949526786804
2020-01-10 18:07:01.488707 UTC | [2020_01_10_11_29_18] Iteration #245 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9216177
Z variance train             0.021250736
KL Divergence                18.93317
KL Loss                      1.8933171
QF Loss                      439.83804
VF Loss                      94.69494
Policy Loss                  -910.80133
Q Predictions Mean           908.6494
Q Predictions Std            187.40343
Q Predictions Max            1069.4148
Q Predictions Min            5.6341352
V Predictions Mean           909.40985
V Predictions Std            184.65363
V Predictions Max            1072.3198
V Predictions Min            71.03265
Log Pis Mean                 -1.3274256
Log Pis Std                  2.5995474
Log Pis Max                  7.016597
Log Pis Min                  -8.603763
Policy mu Mean               0.052175097
Policy mu Std                0.5270878
Policy mu Max                2.1700075
Policy mu Min                -1.7393081
Policy log std Mean          -0.890333
Policy log std Std           0.24152349
Policy log std Max           0.07888979
Policy log std Min           -2.0586805
Z mean eval                  0.91217625
Z variance eval              0.013395427
total_rewards                [2556.36242718 1410.5263209  2536.47572766 2159.19953722  334.36116037
 2525.2486542   321.67744714  738.15293907  509.79246605 2379.49579555]
total_rewards_mean           1547.1292475341193
total_rewards_std            935.0534169691233
total_rewards_max            2556.3624271793706
total_rewards_min            321.677447141091
Number of train steps total  247000
Number of env steps total    1237000
Number of rollouts total     0
Train Time (s)               44.24432435305789
(Previous) Eval Time (s)     29.182317699305713
Sample Time (s)              23.697065964341164
Epoch Time (s)               97.12370801670477
Total Train Time (s)         23951.786011513323
Epoch                        246
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:08:30.572965 UTC | [2020_01_10_11_29_18] Iteration #246 | Epoch Duration: 89.0840470790863
2020-01-10 18:08:30.573102 UTC | [2020_01_10_11_29_18] Iteration #246 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91117203
Z variance train             0.013385932
KL Divergence                20.266731
KL Loss                      2.026673
QF Loss                      342.7527
VF Loss                      81.47569
Policy Loss                  -924.9477
Q Predictions Mean           922.2589
Q Predictions Std            183.56186
Q Predictions Max            1115.3922
Q Predictions Min            177.94505
V Predictions Mean           924.9314
V Predictions Std            180.604
V Predictions Max            1113.4031
V Predictions Min            191.6724
Log Pis Mean                 -0.8787678
Log Pis Std                  2.3960977
Log Pis Max                  5.805893
Log Pis Min                  -7.8305545
Policy mu Mean               0.017899234
Policy mu Std                0.554383
Policy mu Max                1.9370772
Policy mu Min                -2.2632463
Policy log std Mean          -0.8850502
Policy log std Std           0.22635888
Policy log std Max           -0.15901452
Policy log std Min           -1.7760603
Z mean eval                  0.91374457
Z variance eval              0.015956
total_rewards                [2235.32095476 2648.6103632   617.91627966  436.4739673  2484.79542734
  212.68918484 2389.7693895   234.24830674 1890.03802581  567.32477903]
total_rewards_mean           1371.718667818061
total_rewards_std            982.2128993462138
total_rewards_max            2648.610363195034
total_rewards_min            212.6891848351136
Number of train steps total  248000
Number of env steps total    1242000
Number of rollouts total     0
Train Time (s)               44.692963644862175
(Previous) Eval Time (s)     21.142438496928662
Sample Time (s)              22.416196102742106
Epoch Time (s)               88.25159824453294
Total Train Time (s)         24044.64444577042
Epoch                        247
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:10:03.432953 UTC | [2020_01_10_11_29_18] Iteration #247 | Epoch Duration: 92.85974836349487
2020-01-10 18:10:03.433095 UTC | [2020_01_10_11_29_18] Iteration #247 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9124425
Z variance train             0.015985334
KL Divergence                19.806852
KL Loss                      1.9806852
QF Loss                      1300.6162
VF Loss                      159.48158
Policy Loss                  -900.6109
Q Predictions Mean           900.23566
Q Predictions Std            214.55794
Q Predictions Max            1079.8529
Q Predictions Min            198.73141
V Predictions Mean           902.84265
V Predictions Std            213.57126
V Predictions Max            1084.8402
V Predictions Min            192.20184
Log Pis Mean                 -0.8000438
Log Pis Std                  2.8765998
Log Pis Max                  8.367807
Log Pis Min                  -6.6090755
Policy mu Mean               0.050906595
Policy mu Std                0.60892427
Policy mu Max                2.2230744
Policy mu Min                -2.386805
Policy log std Mean          -0.8700329
Policy log std Std           0.26333225
Policy log std Max           -0.23181212
Policy log std Min           -2.1966383
Z mean eval                  0.9019952
Z variance eval              0.03301721
total_rewards                [2313.5611841  2512.08404549 1958.6798043  2188.23012622 2279.07187908
 2456.44208146 2482.02308406 2434.36608938 1161.65109114 2415.23165844]
total_rewards_mean           2220.1341043676284
total_rewards_std            386.7279728061835
total_rewards_max            2512.0840454938557
total_rewards_min            1161.6510911375208
Number of train steps total  249000
Number of env steps total    1247000
Number of rollouts total     0
Train Time (s)               45.29272564034909
(Previous) Eval Time (s)     25.750351483933628
Sample Time (s)              22.470834592357278
Epoch Time (s)               93.51391171664
Total Train Time (s)         24144.12639064621
Epoch                        248
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:11:42.919329 UTC | [2020_01_10_11_29_18] Iteration #248 | Epoch Duration: 99.48609948158264
2020-01-10 18:11:42.919554 UTC | [2020_01_10_11_29_18] Iteration #248 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9028678
Z variance train             0.03296199
KL Divergence                18.472221
KL Loss                      1.8472222
QF Loss                      258.01624
VF Loss                      99.57077
Policy Loss                  -919.7438
Q Predictions Mean           917.9511
Q Predictions Std            192.03111
Q Predictions Max            1094.097
Q Predictions Min            176.22107
V Predictions Mean           922.84705
V Predictions Std            190.87386
V Predictions Max            1100.976
V Predictions Min            192.4492
Log Pis Mean                 -1.1551175
Log Pis Std                  2.6647542
Log Pis Max                  8.817622
Log Pis Min                  -10.765357
Policy mu Mean               0.013923401
Policy mu Std                0.5357541
Policy mu Max                1.9515095
Policy mu Min                -1.8019406
Policy log std Mean          -0.91562414
Policy log std Std           0.26223102
Policy log std Max           -0.10880959
Policy log std Min           -2.3837214
Z mean eval                  0.9193591
Z variance eval              0.027738083
total_rewards                [1075.00522206 2448.54455706 1524.31029566 2687.97376753 1346.80172077
  443.43530047  591.51049381  645.61064908  368.07339787  422.51649378]
total_rewards_mean           1155.3781898091415
total_rewards_std            802.6175703215849
total_rewards_max            2687.9737675251336
total_rewards_min            368.07339786563466
Number of train steps total  250000
Number of env steps total    1252000
Number of rollouts total     0
Train Time (s)               43.97983616171405
(Previous) Eval Time (s)     31.72229368519038
Sample Time (s)              22.721793943550438
Epoch Time (s)               98.42392379045486
Total Train Time (s)         24230.33854124369
Epoch                        249
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:13:09.133861 UTC | [2020_01_10_11_29_18] Iteration #249 | Epoch Duration: 86.21414041519165
2020-01-10 18:13:09.134034 UTC | [2020_01_10_11_29_18] Iteration #249 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92101705
Z variance train             0.027702566
KL Divergence                19.266945
KL Loss                      1.9266945
QF Loss                      477.52798
VF Loss                      603.69836
Policy Loss                  -934.78375
Q Predictions Mean           931.90643
Q Predictions Std            198.3603
Q Predictions Max            1125.5251
Q Predictions Min            152.47328
V Predictions Mean           934.68115
V Predictions Std            197.3228
V Predictions Max            1146.7109
V Predictions Min            175.16376
Log Pis Mean                 -0.7877096
Log Pis Std                  2.5563955
Log Pis Max                  8.137296
Log Pis Min                  -7.430318
Policy mu Mean               -0.05596241
Policy mu Std                0.5451874
Policy mu Max                2.6916752
Policy mu Min                -2.037312
Policy log std Mean          -0.9142222
Policy log std Std           0.25831047
Policy log std Max           -0.06266546
Policy log std Min           -2.3466916
Z mean eval                  0.9261373
Z variance eval              0.025496881
total_rewards                [1292.52668963 2557.53637299 2316.37324575  981.44786652 2453.48569365
  433.52033598  608.57920081 2242.96409468 1774.35483663 1985.87169548]
total_rewards_mean           1664.6660032115883
total_rewards_std            743.6479966964883
total_rewards_max            2557.536372986733
total_rewards_min            433.52033598293195
Number of train steps total  251000
Number of env steps total    1257000
Number of rollouts total     0
Train Time (s)               43.68326479429379
(Previous) Eval Time (s)     19.51227255165577
Sample Time (s)              23.283386236988008
Epoch Time (s)               86.47892358293757
Total Train Time (s)         24324.387659187894
Epoch                        250
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:14:43.186992 UTC | [2020_01_10_11_29_18] Iteration #250 | Epoch Duration: 94.05283451080322
2020-01-10 18:14:43.187133 UTC | [2020_01_10_11_29_18] Iteration #250 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92587054
Z variance train             0.025524419
KL Divergence                19.66267
KL Loss                      1.966267
QF Loss                      609.58813
VF Loss                      86.43505
Policy Loss                  -943.0941
Q Predictions Mean           942.0885
Q Predictions Std            200.01884
Q Predictions Max            1119.8429
Q Predictions Min            205.13675
V Predictions Mean           942.6971
V Predictions Std            199.17433
V Predictions Max            1116.6045
V Predictions Min            185.89532
Log Pis Mean                 -0.78537333
Log Pis Std                  2.412094
Log Pis Max                  6.2876225
Log Pis Min                  -6.1443367
Policy mu Mean               0.0592106
Policy mu Std                0.55878395
Policy mu Max                2.4892502
Policy mu Min                -1.7433201
Policy log std Mean          -0.8993193
Policy log std Std           0.25216952
Policy log std Max           -0.11182165
Policy log std Min           -2.320285
Z mean eval                  0.91962993
Z variance eval              0.019478481
total_rewards                [2603.14680045 2436.23018937 2513.68930606  438.20222212 1585.36388479
  596.92251969 1479.87329682 2434.09904278 2668.39451372 1030.4581006 ]
total_rewards_mean           1778.637987640514
total_rewards_std            821.7935536832734
total_rewards_max            2668.3945137205874
total_rewards_min            438.2022221210112
Number of train steps total  252000
Number of env steps total    1262000
Number of rollouts total     0
Train Time (s)               44.750566742848605
(Previous) Eval Time (s)     27.08594793640077
Sample Time (s)              22.02286019967869
Epoch Time (s)               93.85937487892807
Total Train Time (s)         24423.169453597628
Epoch                        251
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:16:21.975901 UTC | [2020_01_10_11_29_18] Iteration #251 | Epoch Duration: 98.78866767883301
2020-01-10 18:16:21.976061 UTC | [2020_01_10_11_29_18] Iteration #251 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9187226
Z variance train             0.01946159
KL Divergence                20.307074
KL Loss                      2.0307074
QF Loss                      252.87167
VF Loss                      82.71675
Policy Loss                  -960.03937
Q Predictions Mean           958.87085
Q Predictions Std            151.7088
Q Predictions Max            1111.2069
Q Predictions Min            225.33897
V Predictions Mean           966.881
V Predictions Std            150.20712
V Predictions Max            1115.8556
V Predictions Min            230.86098
Log Pis Mean                 -0.52915853
Log Pis Std                  2.3910885
Log Pis Max                  5.2677627
Log Pis Min                  -6.804576
Policy mu Mean               -0.003632637
Policy mu Std                0.57526046
Policy mu Max                1.9104447
Policy mu Min                -2.0276232
Policy log std Mean          -0.90553045
Policy log std Std           0.24385656
Policy log std Max           -0.08002937
Policy log std Min           -2.1285255
Z mean eval                  0.9337858
Z variance eval              0.019926827
total_rewards                [ 114.30476285  847.01845155 1259.06032188 1136.68732923 2667.24858969
 1986.07128765 2480.70900875 2501.74552772 2434.25702493 1593.78789237]
total_rewards_mean           1702.0890196627224
total_rewards_std            810.7919391429144
total_rewards_max            2667.2485896905905
total_rewards_min            114.30476284609225
Number of train steps total  253000
Number of env steps total    1267000
Number of rollouts total     0
Train Time (s)               44.52352252602577
(Previous) Eval Time (s)     32.01495904708281
Sample Time (s)              22.969480235595256
Epoch Time (s)               99.50796180870384
Total Train Time (s)         24515.35755754728
Epoch                        252
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:17:54.165885 UTC | [2020_01_10_11_29_18] Iteration #252 | Epoch Duration: 92.1897246837616
2020-01-10 18:17:54.166022 UTC | [2020_01_10_11_29_18] Iteration #252 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93240327
Z variance train             0.01989261
KL Divergence                20.392353
KL Loss                      2.0392354
QF Loss                      613.79724
VF Loss                      178.66788
Policy Loss                  -921.3037
Q Predictions Mean           919.4608
Q Predictions Std            219.60764
Q Predictions Max            1103.1895
Q Predictions Min            100.98962
V Predictions Mean           927.1509
V Predictions Std            215.89172
V Predictions Max            1118.6201
V Predictions Min            121.51712
Log Pis Mean                 -0.89423096
Log Pis Std                  2.6322372
Log Pis Max                  9.984243
Log Pis Min                  -8.718189
Policy mu Mean               0.054332472
Policy mu Std                0.5757408
Policy mu Max                2.0857902
Policy mu Min                -1.8665531
Policy log std Mean          -0.90758824
Policy log std Std           0.28364423
Policy log std Max           -0.08395058
Policy log std Min           -2.374979
Z mean eval                  0.9268446
Z variance eval              0.016003579
total_rewards                [ 588.19181088  207.00767588 2697.71709285 2507.00982857 2841.92141099
  554.9605226  1438.81560435 2724.4707808  2644.33875477  756.79921995]
total_rewards_mean           1696.1232701650217
total_rewards_std            1030.8228983629456
total_rewards_max            2841.921410992023
total_rewards_min            207.00767587936
Number of train steps total  254000
Number of env steps total    1272000
Number of rollouts total     0
Train Time (s)               43.99752702191472
(Previous) Eval Time (s)     24.696445278357714
Sample Time (s)              22.46983346901834
Epoch Time (s)               91.16380576929078
Total Train Time (s)         24607.406490958296
Epoch                        253
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:19:26.216618 UTC | [2020_01_10_11_29_18] Iteration #253 | Epoch Duration: 92.05049538612366
2020-01-10 18:19:26.216756 UTC | [2020_01_10_11_29_18] Iteration #253 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92663765
Z variance train             0.015998822
KL Divergence                21.162594
KL Loss                      2.1162593
QF Loss                      420.75034
VF Loss                      206.64568
Policy Loss                  -940.54956
Q Predictions Mean           940.0685
Q Predictions Std            191.53304
Q Predictions Max            1114.497
Q Predictions Min            161.3369
V Predictions Mean           949.14404
V Predictions Std            191.29042
V Predictions Max            1126.7654
V Predictions Min            171.33524
Log Pis Mean                 -0.87178254
Log Pis Std                  2.4040613
Log Pis Max                  6.127784
Log Pis Min                  -7.740364
Policy mu Mean               0.03909243
Policy mu Std                0.5690222
Policy mu Max                2.222601
Policy mu Min                -2.1267154
Policy log std Mean          -0.9186193
Policy log std Std           0.2485637
Policy log std Max           -0.09907943
Policy log std Min           -1.9058853
Z mean eval                  0.93419325
Z variance eval              0.017163176
total_rewards                [1152.72120159  189.26650283  556.31565267  731.37401576 2517.98048251
 1554.9084876  2503.86757853 2518.54527524 2481.34576268  734.96989255]
total_rewards_mean           1494.1294851975597
total_rewards_std            891.7623368919226
total_rewards_max            2518.545275243402
total_rewards_min            189.26650283430877
Number of train steps total  255000
Number of env steps total    1277000
Number of rollouts total     0
Train Time (s)               43.38991688890383
(Previous) Eval Time (s)     25.58289967989549
Sample Time (s)              21.327053351327777
Epoch Time (s)               90.2998699201271
Total Train Time (s)         24699.890028201044
Epoch                        254
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:20:58.705960 UTC | [2020_01_10_11_29_18] Iteration #254 | Epoch Duration: 92.48909258842468
2020-01-10 18:20:58.706127 UTC | [2020_01_10_11_29_18] Iteration #254 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9337123
Z variance train             0.017206611
KL Divergence                21.180153
KL Loss                      2.1180153
QF Loss                      671.78894
VF Loss                      166.35237
Policy Loss                  -960.9778
Q Predictions Mean           959.7759
Q Predictions Std            180.55617
Q Predictions Max            1108.8376
Q Predictions Min            174.77707
V Predictions Mean           963.44226
V Predictions Std            180.88121
V Predictions Max            1100.4713
V Predictions Min            60.808216
Log Pis Mean                 -0.8173341
Log Pis Std                  2.6429894
Log Pis Max                  9.860577
Log Pis Min                  -10.166527
Policy mu Mean               -0.056368217
Policy mu Std                0.60466087
Policy mu Max                2.1332808
Policy mu Min                -2.350749
Policy log std Mean          -0.88832206
Policy log std Std           0.24160254
Policy log std Max           -0.18810463
Policy log std Min           -2.2137518
Z mean eval                  0.92907715
Z variance eval              0.014075479
total_rewards                [2442.7278712  2588.20079405 1719.92786323 2471.97374857 2271.03349559
 2522.40293641 2607.57038931  528.85458129 2601.33118825 2628.33561328]
total_rewards_mean           2238.2358481172414
total_rewards_std            625.4441634115872
total_rewards_max            2628.335613276167
total_rewards_min            528.854581287379
Number of train steps total  256000
Number of env steps total    1282000
Number of rollouts total     0
Train Time (s)               44.043494509067386
(Previous) Eval Time (s)     27.771882390137762
Sample Time (s)              21.17526174429804
Epoch Time (s)               92.99063864350319
Total Train Time (s)         24799.074192606844
Epoch                        255
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:22:37.896318 UTC | [2020_01_10_11_29_18] Iteration #255 | Epoch Duration: 99.19006276130676
2020-01-10 18:22:37.896460 UTC | [2020_01_10_11_29_18] Iteration #255 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92963886
Z variance train             0.014084031
KL Divergence                20.628513
KL Loss                      2.0628514
QF Loss                      738.79724
VF Loss                      317.25482
Policy Loss                  -966.77136
Q Predictions Mean           963.6897
Q Predictions Std            159.84975
Q Predictions Max            1137.6743
Q Predictions Min            156.90767
V Predictions Mean           952.8821
V Predictions Std            158.64056
V Predictions Max            1139.8123
V Predictions Min            167.62332
Log Pis Mean                 -0.6282149
Log Pis Std                  2.3992438
Log Pis Max                  9.477868
Log Pis Min                  -7.739975
Policy mu Mean               -0.016732544
Policy mu Std                0.5707315
Policy mu Max                2.911471
Policy mu Min                -2.2968214
Policy log std Mean          -0.9211639
Policy log std Std           0.22884129
Policy log std Max           -0.20035332
Policy log std Min           -1.940454
Z mean eval                  0.9129286
Z variance eval              0.017287742
total_rewards                [2388.52349783  555.61962989  886.90930699  679.77818545 2163.7927359
 2445.51972943 2447.26926657 2488.94128701 2581.7883747  2555.28938015]
total_rewards_mean           1919.343139392175
total_rewards_std            804.0733597141049
total_rewards_max            2581.788374701997
total_rewards_min            555.6196298943562
Number of train steps total  257000
Number of env steps total    1287000
Number of rollouts total     0
Train Time (s)               43.67941167904064
(Previous) Eval Time (s)     33.97105727624148
Sample Time (s)              23.101793236099184
Epoch Time (s)               100.7522621913813
Total Train Time (s)         24896.938566721044
Epoch                        256
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:24:15.762874 UTC | [2020_01_10_11_29_18] Iteration #256 | Epoch Duration: 97.8663055896759
2020-01-10 18:24:15.763051 UTC | [2020_01_10_11_29_18] Iteration #256 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.913569
Z variance train             0.017258089
KL Divergence                19.848776
KL Loss                      1.9848776
QF Loss                      1512.7922
VF Loss                      247.0185
Policy Loss                  -939.6189
Q Predictions Mean           939.55273
Q Predictions Std            196.40509
Q Predictions Max            1118.3301
Q Predictions Min            180.72778
V Predictions Mean           933.0474
V Predictions Std            197.41183
V Predictions Max            1112.305
V Predictions Min            176.64636
Log Pis Mean                 -1.1079544
Log Pis Std                  2.6193318
Log Pis Max                  9.738437
Log Pis Min                  -7.9253483
Policy mu Mean               0.00631917
Policy mu Std                0.5181371
Policy mu Max                2.292114
Policy mu Min                -2.0916803
Policy log std Mean          -0.9227214
Policy log std Std           0.27700487
Policy log std Max           0.06241578
Policy log std Min           -2.5021296
Z mean eval                  0.96857244
Z variance eval              0.019794697
total_rewards                [2060.91805391 2620.73683142  258.12748291  724.91606419 2600.98369261
   21.98152148 2060.48848886 2513.31270025 2449.90772936   53.84180742]
total_rewards_mean           1536.5214372419973
total_rewards_std            1069.191110704788
total_rewards_max            2620.736831421041
total_rewards_min            21.981521478737626
Number of train steps total  258000
Number of env steps total    1292000
Number of rollouts total     0
Train Time (s)               43.625277095939964
(Previous) Eval Time (s)     31.084841462317854
Sample Time (s)              20.953725254628807
Epoch Time (s)               95.66384381288663
Total Train Time (s)         24986.955761843827
Epoch                        257
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:25:45.782380 UTC | [2020_01_10_11_29_18] Iteration #257 | Epoch Duration: 90.01920342445374
2020-01-10 18:25:45.782519 UTC | [2020_01_10_11_29_18] Iteration #257 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9645357
Z variance train             0.019837847
KL Divergence                19.651787
KL Loss                      1.9651787
QF Loss                      2153.9487
VF Loss                      392.54166
Policy Loss                  -951.49927
Q Predictions Mean           951.4211
Q Predictions Std            192.41516
Q Predictions Max            1115.8208
Q Predictions Min            39.049263
V Predictions Mean           946.4999
V Predictions Std            187.89175
V Predictions Max            1100.6195
V Predictions Min            189.90593
Log Pis Mean                 -0.7538372
Log Pis Std                  2.7624323
Log Pis Max                  14.671516
Log Pis Min                  -7.1100698
Policy mu Mean               0.0067897835
Policy mu Std                0.5997609
Policy mu Max                2.1487074
Policy mu Min                -2.3416975
Policy log std Mean          -0.8854457
Policy log std Std           0.24412216
Policy log std Max           -0.1929161
Policy log std Min           -2.7688096
Z mean eval                  0.9247891
Z variance eval              0.022985525
total_rewards                [ 107.85566571 2691.96459285 2499.46438458 2697.61756791  551.77777048
  661.24817156  823.41948868  829.88780676 2713.20080363  652.75915036]
total_rewards_mean           1422.9195402519151
total_rewards_std            1021.3600331757727
total_rewards_max            2713.200803627997
total_rewards_min            107.85566570666592
Number of train steps total  259000
Number of env steps total    1297000
Number of rollouts total     0
Train Time (s)               43.919836160261184
(Previous) Eval Time (s)     25.440042552072555
Sample Time (s)              22.811860356945544
Epoch Time (s)               92.17173906927928
Total Train Time (s)         25074.24492461467
Epoch                        258
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:27:13.086879 UTC | [2020_01_10_11_29_18] Iteration #258 | Epoch Duration: 87.3042299747467
2020-01-10 18:27:13.087115 UTC | [2020_01_10_11_29_18] Iteration #258 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92469156
Z variance train             0.022998635
KL Divergence                19.309614
KL Loss                      1.9309615
QF Loss                      319.3115
VF Loss                      166.6386
Policy Loss                  -943.23645
Q Predictions Mean           942.8048
Q Predictions Std            174.46729
Q Predictions Max            1102.6238
Q Predictions Min            166.7287
V Predictions Mean           945.62054
V Predictions Std            173.34784
V Predictions Max            1107.006
V Predictions Min            154.36617
Log Pis Mean                 -0.8515534
Log Pis Std                  2.6054385
Log Pis Max                  7.6513214
Log Pis Min                  -8.687104
Policy mu Mean               -0.0026203892
Policy mu Std                0.5849474
Policy mu Max                2.0596676
Policy mu Min                -1.8741016
Policy log std Mean          -0.89071894
Policy log std Std           0.2396406
Policy log std Max           -0.2423529
Policy log std Min           -2.0706887
Z mean eval                  0.94540423
Z variance eval              0.01417171
total_rewards                [ -33.81295503 2461.93810987 2459.19979815  789.10016181 2457.22917571
  783.20826923 2633.60351239  846.85446095  106.84743447  574.93061137]
total_rewards_mean           1307.9098578926476
total_rewards_std            1013.5445356386781
total_rewards_max            2633.6035123869856
total_rewards_min            -33.8129550324001
Number of train steps total  260000
Number of env steps total    1302000
Number of rollouts total     0
Train Time (s)               43.53251249296591
(Previous) Eval Time (s)     20.57226249901578
Sample Time (s)              23.315632470417768
Epoch Time (s)               87.42040746239945
Total Train Time (s)         25167.85692623956
Epoch                        259
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:28:46.691307 UTC | [2020_01_10_11_29_18] Iteration #259 | Epoch Duration: 93.60402584075928
2020-01-10 18:28:46.691447 UTC | [2020_01_10_11_29_18] Iteration #259 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94470406
Z variance train             0.014184659
KL Divergence                20.877424
KL Loss                      2.0877426
QF Loss                      323.08575
VF Loss                      90.15565
Policy Loss                  -929.7596
Q Predictions Mean           927.66064
Q Predictions Std            222.33551
Q Predictions Max            1105.5834
Q Predictions Min            69.734055
V Predictions Mean           925.0516
V Predictions Std            220.52765
V Predictions Max            1105.7202
V Predictions Min            50.970776
Log Pis Mean                 -0.75803775
Log Pis Std                  2.5300817
Log Pis Max                  7.659795
Log Pis Min                  -6.8832855
Policy mu Mean               0.03828767
Policy mu Std                0.57502997
Policy mu Max                2.1603765
Policy mu Min                -2.2357814
Policy log std Mean          -0.88029647
Policy log std Std           0.24447863
Policy log std Max           -0.16052926
Policy log std Min           -2.0478234
Z mean eval                  0.94419205
Z variance eval              0.012743393
total_rewards                [ 144.65808821 1305.30347051  496.2948894  1972.65369869  649.58545606
 2522.38723814  140.79693889 1560.94526713  943.97816107 2312.99926247]
total_rewards_mean           1204.9602470570453
total_rewards_std            826.1328755428325
total_rewards_max            2522.3872381381757
total_rewards_min            140.79693889207385
Number of train steps total  261000
Number of env steps total    1307000
Number of rollouts total     0
Train Time (s)               44.43477346096188
(Previous) Eval Time (s)     26.75564347906038
Sample Time (s)              22.727235222700983
Epoch Time (s)               93.91765216272324
Total Train Time (s)         25263.570799696725
Epoch                        260
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:30:22.409445 UTC | [2020_01_10_11_29_18] Iteration #260 | Epoch Duration: 95.7178750038147
2020-01-10 18:30:22.409657 UTC | [2020_01_10_11_29_18] Iteration #260 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9464878
Z variance train             0.012735486
KL Divergence                20.694023
KL Loss                      2.0694025
QF Loss                      937.7173
VF Loss                      837.68854
Policy Loss                  -943.5527
Q Predictions Mean           940.2501
Q Predictions Std            200.02646
Q Predictions Max            1124.4886
Q Predictions Min            158.20363
V Predictions Mean           942.6738
V Predictions Std            197.96686
V Predictions Max            1117.1244
V Predictions Min            171.50311
Log Pis Mean                 -0.5014596
Log Pis Std                  3.0535486
Log Pis Max                  13.133664
Log Pis Min                  -9.400842
Policy mu Mean               0.03746968
Policy mu Std                0.61130345
Policy mu Max                3.2071514
Policy mu Min                -3.028144
Policy log std Mean          -0.91407925
Policy log std Std           0.28239232
Policy log std Max           -0.19902247
Policy log std Min           -2.7183049
Z mean eval                  0.92895687
Z variance eval              0.010551016
total_rewards                [-147.68120591 1603.5977457   630.18628288  872.50594899 2500.80597866
 2389.47987782  130.76050053 1175.50546757   71.99140611  444.81775362]
total_rewards_mean           967.1969755964847
total_rewards_std            892.3361806740733
total_rewards_max            2500.8059786636873
total_rewards_min            -147.6812059083545
Number of train steps total  262000
Number of env steps total    1312000
Number of rollouts total     0
Train Time (s)               44.17714440403506
(Previous) Eval Time (s)     28.555622389074415
Sample Time (s)              22.8635769225657
Epoch Time (s)               95.59634371567518
Total Train Time (s)         25354.28290099278
Epoch                        261
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:31:53.124494 UTC | [2020_01_10_11_29_18] Iteration #261 | Epoch Duration: 90.71462869644165
2020-01-10 18:31:53.124726 UTC | [2020_01_10_11_29_18] Iteration #261 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92732584
Z variance train             0.010577142
KL Divergence                20.942032
KL Loss                      2.0942032
QF Loss                      3300.2798
VF Loss                      104.47864
Policy Loss                  -976.7371
Q Predictions Mean           978.01953
Q Predictions Std            192.4929
Q Predictions Max            1146.6582
Q Predictions Min            163.13069
V Predictions Mean           971.84753
V Predictions Std            191.92764
V Predictions Max            1145.1598
V Predictions Min            145.9393
Log Pis Mean                 -0.5571048
Log Pis Std                  2.6249568
Log Pis Max                  7.9507656
Log Pis Min                  -9.7743225
Policy mu Mean               -0.0004738872
Policy mu Std                0.60154593
Policy mu Max                1.8952028
Policy mu Min                -2.0817175
Policy log std Mean          -0.8821291
Policy log std Std           0.24503905
Policy log std Max           0.077084005
Policy log std Min           -2.1963873
Z mean eval                  0.9326822
Z variance eval              0.013754465
total_rewards                [2594.49301204 1234.4989891  2465.24103535  762.59444394  118.02986812
 2277.18938471  474.21663223  925.31367085 1610.99450019 1286.18854359]
total_rewards_mean           1374.8760080112502
total_rewards_std            808.8076788995137
total_rewards_max            2594.4930120351755
total_rewards_min            118.02986812233905
Number of train steps total  263000
Number of env steps total    1317000
Number of rollouts total     0
Train Time (s)               44.2708736252971
(Previous) Eval Time (s)     23.673667832743376
Sample Time (s)              21.894029375631362
Epoch Time (s)               89.83857083367184
Total Train Time (s)         25444.72028798936
Epoch                        262
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:33:23.564298 UTC | [2020_01_10_11_29_18] Iteration #262 | Epoch Duration: 90.43941903114319
2020-01-10 18:33:23.564469 UTC | [2020_01_10_11_29_18] Iteration #262 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93428546
Z variance train             0.01376563
KL Divergence                20.699432
KL Loss                      2.0699432
QF Loss                      525.45734
VF Loss                      115.22263
Policy Loss                  -956.028
Q Predictions Mean           956.7289
Q Predictions Std            200.89351
Q Predictions Max            1138.3972
Q Predictions Min            192.88405
V Predictions Mean           958.9622
V Predictions Std            201.8704
V Predictions Max            1132.8909
V Predictions Min            188.52524
Log Pis Mean                 -0.7310162
Log Pis Std                  2.5784972
Log Pis Max                  7.217887
Log Pis Min                  -8.46285
Policy mu Mean               0.039701775
Policy mu Std                0.5695143
Policy mu Max                2.4059181
Policy mu Min                -2.2223506
Policy log std Mean          -0.89095104
Policy log std Std           0.257913
Policy log std Max           -0.051047802
Policy log std Min           -2.1441221
Z mean eval                  0.9558738
Z variance eval              0.015568927
total_rewards                [2519.03550789 2272.12232035 2735.40570037 1010.59598018  451.54900662
 2434.61330068 1812.21139876 1308.30305396 2605.50834983  720.86018302]
total_rewards_mean           1787.0204801656316
total_rewards_std            807.0145582710867
total_rewards_max            2735.4057003688768
total_rewards_min            451.54900661846966
Number of train steps total  264000
Number of env steps total    1322000
Number of rollouts total     0
Train Time (s)               43.47888490231708
(Previous) Eval Time (s)     24.274267981760204
Sample Time (s)              21.208811472635716
Epoch Time (s)               88.961964356713
Total Train Time (s)         25533.98789480375
Epoch                        263
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:34:52.835050 UTC | [2020_01_10_11_29_18] Iteration #263 | Epoch Duration: 89.27045941352844
2020-01-10 18:34:52.835186 UTC | [2020_01_10_11_29_18] Iteration #263 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9634039
Z variance train             0.015561241
KL Divergence                19.233187
KL Loss                      1.9233187
QF Loss                      490.02087
VF Loss                      104.37944
Policy Loss                  -965.22253
Q Predictions Mean           963.69275
Q Predictions Std            187.5489
Q Predictions Max            1118.135
Q Predictions Min            174.58406
V Predictions Mean           960.2595
V Predictions Std            183.0592
V Predictions Max            1114.647
V Predictions Min            181.32147
Log Pis Mean                 -0.8842222
Log Pis Std                  2.6570458
Log Pis Max                  15.598362
Log Pis Min                  -8.382648
Policy mu Mean               0.06276646
Policy mu Std                0.56374794
Policy mu Max                2.0834823
Policy mu Min                -3.2040026
Policy log std Mean          -0.87910503
Policy log std Std           0.23138352
Policy log std Max           -0.2084623
Policy log std Min           -2.4303427
Z mean eval                  0.95070344
Z variance eval              0.023015732
total_rewards                [2655.85440371  198.59092629  961.87585107 1157.83114282  745.02060943
 1599.15260859 2193.06266647 2622.27214192 2051.8878538  2788.48067731]
total_rewards_mean           1697.4028881421705
total_rewards_std            856.2161819818293
total_rewards_max            2788.4806773147893
total_rewards_min            198.59092629222405
Number of train steps total  265000
Number of env steps total    1327000
Number of rollouts total     0
Train Time (s)               44.35869572777301
(Previous) Eval Time (s)     24.58253273461014
Sample Time (s)              24.19558672234416
Epoch Time (s)               93.13681518472731
Total Train Time (s)         25631.893807722256
Epoch                        264
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:36:30.743741 UTC | [2020_01_10_11_29_18] Iteration #264 | Epoch Duration: 97.9084460735321
2020-01-10 18:36:30.743916 UTC | [2020_01_10_11_29_18] Iteration #264 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94887143
Z variance train             0.023013314
KL Divergence                18.706526
KL Loss                      1.8706526
QF Loss                      603.5728
VF Loss                      118.643936
Policy Loss                  -943.8726
Q Predictions Mean           942.3773
Q Predictions Std            218.38097
Q Predictions Max            1164.1794
Q Predictions Min            123.72528
V Predictions Mean           947.9617
V Predictions Std            216.90082
V Predictions Max            1164.5906
V Predictions Min            147.45773
Log Pis Mean                 -0.96819925
Log Pis Std                  2.2946687
Log Pis Max                  6.160097
Log Pis Min                  -7.904645
Policy mu Mean               0.020486556
Policy mu Std                0.5279056
Policy mu Max                2.4147959
Policy mu Min                -2.084566
Policy log std Mean          -0.9176104
Policy log std Std           0.254821
Policy log std Max           -0.032882035
Policy log std Min           -2.191576
Z mean eval                  0.9227921
Z variance eval              0.017137928
total_rewards                [2395.78462272 2279.50636368  432.90804295  115.70565115  152.53194381
  755.12226501 2598.52834393 1401.96176616  159.51529227 2673.35386289]
total_rewards_mean           1296.4918154556674
total_rewards_std            1039.7792120473475
total_rewards_max            2673.353862885961
total_rewards_min            115.70565115125082
Number of train steps total  266000
Number of env steps total    1332000
Number of rollouts total     0
Train Time (s)               43.694292126689106
(Previous) Eval Time (s)     29.35390954464674
Sample Time (s)              22.963365260511637
Epoch Time (s)               96.01156693184748
Total Train Time (s)         25720.596474386286
Epoch                        265
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:37:59.449207 UTC | [2020_01_10_11_29_18] Iteration #265 | Epoch Duration: 88.7051420211792
2020-01-10 18:37:59.449364 UTC | [2020_01_10_11_29_18] Iteration #265 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9226165
Z variance train             0.017133532
KL Divergence                18.373112
KL Loss                      1.8373111
QF Loss                      495.16205
VF Loss                      123.991646
Policy Loss                  -960.0388
Q Predictions Mean           956.83765
Q Predictions Std            217.30415
Q Predictions Max            1145.9585
Q Predictions Min            109.38711
V Predictions Mean           966.4886
V Predictions Std            212.34225
V Predictions Max            1147.021
V Predictions Min            183.19682
Log Pis Mean                 -0.6713719
Log Pis Std                  2.691452
Log Pis Max                  17.718807
Log Pis Min                  -7.390383
Policy mu Mean               -0.023513155
Policy mu Std                0.5788271
Policy mu Max                2.5320227
Policy mu Min                -2.925289
Policy log std Mean          -0.90380794
Policy log std Std           0.24884939
Policy log std Max           -0.14929211
Policy log std Min           -1.9307922
Z mean eval                  0.94614613
Z variance eval              0.014762884
total_rewards                [ 643.07358118  490.37733539  345.68451459 2723.32105769  889.77254302
 1782.60884192 2577.31046985 1758.79784505 1111.57657178  138.12517892]
total_rewards_mean           1246.0647939392252
total_rewards_std            873.1084606825488
total_rewards_max            2723.321057685056
total_rewards_min            138.12517892013796
Number of train steps total  267000
Number of env steps total    1337000
Number of rollouts total     0
Train Time (s)               43.38940903311595
(Previous) Eval Time (s)     22.04723349912092
Sample Time (s)              21.359270559623837
Epoch Time (s)               86.79591309186071
Total Train Time (s)         25804.334169705864
Epoch                        266
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:39:23.188704 UTC | [2020_01_10_11_29_18] Iteration #266 | Epoch Duration: 83.73921585083008
2020-01-10 18:39:23.188844 UTC | [2020_01_10_11_29_18] Iteration #266 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94432366
Z variance train             0.014793697
KL Divergence                18.522152
KL Loss                      1.8522152
QF Loss                      503.4223
VF Loss                      78.189
Policy Loss                  -999.08826
Q Predictions Mean           997.7302
Q Predictions Std            152.38545
Q Predictions Max            1210.8937
Q Predictions Min            151.54222
V Predictions Mean           1005.32007
V Predictions Std            152.40993
V Predictions Max            1208.788
V Predictions Min            152.80194
Log Pis Mean                 -0.6233356
Log Pis Std                  2.402554
Log Pis Max                  8.731054
Log Pis Min                  -7.001546
Policy mu Mean               -0.07519719
Policy mu Std                0.60574335
Policy mu Max                1.9220424
Policy mu Min                -2.2406707
Policy log std Mean          -0.8959317
Policy log std Std           0.22285226
Policy log std Max           -0.23195004
Policy log std Min           -2.0677445
Z mean eval                  0.9208144
Z variance eval              0.018244946
total_rewards                [ 823.55974169 2690.84914571  942.40135544 2565.23458633 2604.85788458
  821.49019102 2571.62219334 2751.24657527 1889.37305895  -24.06595661]
total_rewards_mean           1763.6568775718777
total_rewards_std            974.4563425244515
total_rewards_max            2751.246575274647
total_rewards_min            -24.065956609939207
Number of train steps total  268000
Number of env steps total    1342000
Number of rollouts total     0
Train Time (s)               44.031317736022174
(Previous) Eval Time (s)     18.990286604035646
Sample Time (s)              22.816777439322323
Epoch Time (s)               85.83838177938014
Total Train Time (s)         25899.000012631994
Epoch                        267
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:40:57.860919 UTC | [2020_01_10_11_29_18] Iteration #267 | Epoch Duration: 94.67194390296936
2020-01-10 18:40:57.861161 UTC | [2020_01_10_11_29_18] Iteration #267 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9205531
Z variance train             0.018251617
KL Divergence                17.842342
KL Loss                      1.7842343
QF Loss                      468.6369
VF Loss                      140.6037
Policy Loss                  -988.66846
Q Predictions Mean           987.32477
Q Predictions Std            187.39949
Q Predictions Max            1149.533
Q Predictions Min            74.3471
V Predictions Mean           992.82837
V Predictions Std            187.63864
V Predictions Max            1157.1497
V Predictions Min            91.99814
Log Pis Mean                 -1.1472178
Log Pis Std                  2.613087
Log Pis Max                  10.7585945
Log Pis Min                  -7.439476
Policy mu Mean               -0.024332833
Policy mu Std                0.5515559
Policy mu Max                1.9684519
Policy mu Min                -3.49617
Policy log std Mean          -0.9126048
Policy log std Std           0.25032327
Policy log std Max           -0.20582855
Policy log std Min           -2.5110595
Z mean eval                  0.9321434
Z variance eval              0.011857974
total_rewards                [2524.85556893 1588.03873532 1520.3400019  1825.00392827 2598.07496653
 2666.33442136 1740.00405901 2015.29158903 1027.70100477 2428.2258825 ]
total_rewards_mean           1993.387015763155
total_rewards_std            519.9726114339489
total_rewards_max            2666.3344213645514
total_rewards_min            1027.7010047660697
Number of train steps total  269000
Number of env steps total    1347000
Number of rollouts total     0
Train Time (s)               44.309232814237475
(Previous) Eval Time (s)     27.82358921598643
Sample Time (s)              22.615549235139042
Epoch Time (s)               94.74837126536295
Total Train Time (s)         25994.554150848184
Epoch                        268
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:42:33.416647 UTC | [2020_01_10_11_29_18] Iteration #268 | Epoch Duration: 95.5553207397461
2020-01-10 18:42:33.416784 UTC | [2020_01_10_11_29_18] Iteration #268 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9326164
Z variance train             0.0118784355
KL Divergence                19.095661
KL Loss                      1.9095662
QF Loss                      365.2617
VF Loss                      81.60096
Policy Loss                  -996.2383
Q Predictions Mean           993.00653
Q Predictions Std            182.54723
Q Predictions Max            1163.0729
Q Predictions Min            153.45593
V Predictions Mean           996.3899
V Predictions Std            181.59128
V Predictions Max            1167.0144
V Predictions Min            159.64096
Log Pis Mean                 -0.48123536
Log Pis Std                  2.5718348
Log Pis Max                  9.04331
Log Pis Min                  -7.430751
Policy mu Mean               0.000838934
Policy mu Std                0.60161793
Policy mu Max                2.5305424
Policy mu Min                -2.8946502
Policy log std Mean          -0.9075887
Policy log std Std           0.24520224
Policy log std Max           -0.011916876
Policy log std Min           -2.008493
Z mean eval                  0.91569483
Z variance eval              0.009962084
total_rewards                [1577.89610622 2768.82846181  807.56403608 1301.4339304   618.70479974
  304.26004792 2355.88166786 1953.83417874 2892.73943707  411.65548045]
total_rewards_mean           1499.2798146301925
total_rewards_std            916.737444270783
total_rewards_max            2892.7394370692205
total_rewards_min            304.26004792351534
Number of train steps total  270000
Number of env steps total    1352000
Number of rollouts total     0
Train Time (s)               43.46048985701054
(Previous) Eval Time (s)     28.630312643945217
Sample Time (s)              23.164072236511856
Epoch Time (s)               95.25487473746762
Total Train Time (s)         26086.664432577323
Epoch                        269
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:44:05.529764 UTC | [2020_01_10_11_29_18] Iteration #269 | Epoch Duration: 92.11282539367676
2020-01-10 18:44:05.530082 UTC | [2020_01_10_11_29_18] Iteration #269 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9154059
Z variance train             0.0099732755
KL Divergence                19.703657
KL Loss                      1.9703658
QF Loss                      343.25055
VF Loss                      102.45069
Policy Loss                  -1007.2534
Q Predictions Mean           1006.60254
Q Predictions Std            174.22177
Q Predictions Max            1175.1985
Q Predictions Min            127.62857
V Predictions Mean           1009.65326
V Predictions Std            173.39366
V Predictions Max            1182.9788
V Predictions Min            132.33875
Log Pis Mean                 -0.7392576
Log Pis Std                  2.38923
Log Pis Max                  4.2817125
Log Pis Min                  -7.8297644
Policy mu Mean               0.02364399
Policy mu Std                0.58382046
Policy mu Max                2.2605977
Policy mu Min                -2.1859872
Policy log std Mean          -0.91162205
Policy log std Std           0.22770855
Policy log std Max           -0.23493803
Policy log std Min           -1.9434066
Z mean eval                  0.9475452
Z variance eval              0.014102057
total_rewards                [2433.33877914 2639.40143285 2667.11901449  288.06591032 2596.06632132
 2467.91351052 2638.62108441 1242.78240152 1581.73520849 2606.6826566 ]
total_rewards_mean           2116.172631966833
total_rewards_std            770.4469331408594
total_rewards_max            2667.1190144927737
total_rewards_min            288.06591031698815
Number of train steps total  271000
Number of env steps total    1357000
Number of rollouts total     0
Train Time (s)               43.83838453888893
(Previous) Eval Time (s)     25.487997049931437
Sample Time (s)              20.475189687218517
Epoch Time (s)               89.80157127603889
Total Train Time (s)         26179.99432673119
Epoch                        270
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:45:38.860549 UTC | [2020_01_10_11_29_18] Iteration #270 | Epoch Duration: 93.33023381233215
2020-01-10 18:45:38.860686 UTC | [2020_01_10_11_29_18] Iteration #270 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94883454
Z variance train             0.014084579
KL Divergence                18.780205
KL Loss                      1.8780205
QF Loss                      1882.7743
VF Loss                      349.2344
Policy Loss                  -956.4177
Q Predictions Mean           956.60864
Q Predictions Std            218.95868
Q Predictions Max            1181.5466
Q Predictions Min            136.72832
V Predictions Mean           960.3092
V Predictions Std            218.46187
V Predictions Max            1177.2135
V Predictions Min            147.96455
Log Pis Mean                 -0.7750832
Log Pis Std                  2.9509275
Log Pis Max                  13.315318
Log Pis Min                  -8.998849
Policy mu Mean               -0.036541034
Policy mu Std                0.5705765
Policy mu Max                2.4213357
Policy mu Min                -2.5960534
Policy log std Mean          -0.9303803
Policy log std Std           0.27293918
Policy log std Max           -0.16980124
Policy log std Min           -2.5496716
Z mean eval                  0.9434292
Z variance eval              0.012295689
total_rewards                [2323.24536184 2723.81177785  808.48822585  588.66847983 2831.47568912
 1015.09909463 2676.10476001 2676.80269147  476.67871221 1034.22143331]
total_rewards_mean           1715.4596226128147
total_rewards_std            951.846252722116
total_rewards_max            2831.4756891240236
total_rewards_min            476.6787122120817
Number of train steps total  272000
Number of env steps total    1362000
Number of rollouts total     0
Train Time (s)               43.26024716813117
(Previous) Eval Time (s)     29.016444292850792
Sample Time (s)              22.997314795851707
Epoch Time (s)               95.27400625683367
Total Train Time (s)         26272.93520014314
Epoch                        271
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:47:11.803503 UTC | [2020_01_10_11_29_18] Iteration #271 | Epoch Duration: 92.94271469116211
2020-01-10 18:47:11.803644 UTC | [2020_01_10_11_29_18] Iteration #271 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94230473
Z variance train             0.012316978
KL Divergence                19.293272
KL Loss                      1.9293272
QF Loss                      600.66797
VF Loss                      217.48308
Policy Loss                  -972.85724
Q Predictions Mean           969.74817
Q Predictions Std            208.45584
Q Predictions Max            1168.6323
Q Predictions Min            -5.880096
V Predictions Mean           968.8666
V Predictions Std            204.43198
V Predictions Max            1163.2377
V Predictions Min            116.11032
Log Pis Mean                 -0.653466
Log Pis Std                  2.6227055
Log Pis Max                  8.979959
Log Pis Min                  -8.264286
Policy mu Mean               0.009965885
Policy mu Std                0.59017736
Policy mu Max                2.2081275
Policy mu Min                -2.5862637
Policy log std Mean          -0.92548454
Policy log std Std           0.2677916
Policy log std Max           -0.12490225
Policy log std Min           -2.5680885
Z mean eval                  0.9304735
Z variance eval              0.015909586
total_rewards                [1693.54642588 1395.56508933 2651.11192227 2489.78733336 2506.67018966
   29.32705681 2643.6839838  2646.54738171 1278.90413989 2654.56806262]
total_rewards_mean           1998.9711585333869
total_rewards_std            839.2938009062531
total_rewards_max            2654.56806262435
total_rewards_min            29.327056810755188
Number of train steps total  273000
Number of env steps total    1367000
Number of rollouts total     0
Train Time (s)               43.520383229944855
(Previous) Eval Time (s)     26.684928573668003
Sample Time (s)              22.96497457055375
Epoch Time (s)               93.17028637416661
Total Train Time (s)         26364.46497765137
Epoch                        272
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:48:43.336821 UTC | [2020_01_10_11_29_18] Iteration #272 | Epoch Duration: 91.53306674957275
2020-01-10 18:48:43.336983 UTC | [2020_01_10_11_29_18] Iteration #272 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9293001
Z variance train             0.015912801
KL Divergence                18.439152
KL Loss                      1.8439152
QF Loss                      2261.6113
VF Loss                      562.5493
Policy Loss                  -1021.2253
Q Predictions Mean           1019.8565
Q Predictions Std            157.62619
Q Predictions Max            1167.8247
Q Predictions Min            153.00696
V Predictions Mean           1023.8527
V Predictions Std            149.8307
V Predictions Max            1166.195
V Predictions Min            151.96242
Log Pis Mean                 -0.30931407
Log Pis Std                  2.6462672
Log Pis Max                  8.235923
Log Pis Min                  -7.6733427
Policy mu Mean               0.060279064
Policy mu Std                0.61530876
Policy mu Max                2.7325797
Policy mu Min                -2.4293969
Policy log std Mean          -0.90853286
Policy log std Std           0.24219365
Policy log std Max           -0.19720083
Policy log std Min           -2.2911234
Z mean eval                  0.95323324
Z variance eval              0.0105973715
total_rewards                [ 184.26111906  628.56613463 2677.02966728 1972.40876098 2635.93484014
 2707.32853885 2550.57496906 2628.43381373 2003.73337241  685.00175995]
total_rewards_mean           1867.3272976087792
total_rewards_std            937.7031227976355
total_rewards_max            2707.3285388510444
total_rewards_min            184.26111906397014
Number of train steps total  274000
Number of env steps total    1372000
Number of rollouts total     0
Train Time (s)               44.274552491959184
(Previous) Eval Time (s)     25.047456903383136
Sample Time (s)              22.80401453608647
Epoch Time (s)               92.12602393142879
Total Train Time (s)         26460.706566246226
Epoch                        273
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:50:19.580165 UTC | [2020_01_10_11_29_18] Iteration #273 | Epoch Duration: 96.24306011199951
2020-01-10 18:50:19.580301 UTC | [2020_01_10_11_29_18] Iteration #273 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95225286
Z variance train             0.010548504
KL Divergence                19.32928
KL Loss                      1.9329281
QF Loss                      531.8364
VF Loss                      111.86636
Policy Loss                  -980.53503
Q Predictions Mean           981.3602
Q Predictions Std            186.05504
Q Predictions Max            1156.4033
Q Predictions Min            141.2364
V Predictions Mean           975.0868
V Predictions Std            184.41197
V Predictions Max            1141.4021
V Predictions Min            139.84302
Log Pis Mean                 -0.71702087
Log Pis Std                  2.2653115
Log Pis Max                  7.116199
Log Pis Min                  -7.7510023
Policy mu Mean               -0.02485944
Policy mu Std                0.5987874
Policy mu Max                1.899954
Policy mu Min                -2.4344075
Policy log std Mean          -0.8838482
Policy log std Std           0.2212253
Policy log std Max           -0.1361013
Policy log std Min           -2.1180081
Z mean eval                  0.9689814
Z variance eval              0.010246629
total_rewards                [2781.26183681 2669.93724985 2676.10233901 2658.61703487 2787.91055375
 -130.84540478 1034.89386324 2594.27741862  462.19499706  328.22414404]
total_rewards_mean           1786.2574032459281
total_rewards_std            1144.499768285882
total_rewards_max            2787.91055374841
total_rewards_min            -130.84540478109065
Number of train steps total  275000
Number of env steps total    1377000
Number of rollouts total     0
Train Time (s)               44.59217324014753
(Previous) Eval Time (s)     29.164251725189388
Sample Time (s)              23.08970006648451
Epoch Time (s)               96.84612503182143
Total Train Time (s)         26557.37651205249
Epoch                        274
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:51:56.257496 UTC | [2020_01_10_11_29_18] Iteration #274 | Epoch Duration: 96.67708253860474
2020-01-10 18:51:56.257665 UTC | [2020_01_10_11_29_18] Iteration #274 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96793205
Z variance train             0.010248269
KL Divergence                19.842983
KL Loss                      1.9842983
QF Loss                      1042.8975
VF Loss                      123.35504
Policy Loss                  -1014.77924
Q Predictions Mean           1013.07227
Q Predictions Std            167.44263
Q Predictions Max            1194.2003
Q Predictions Min            -11.252131
V Predictions Mean           1015.05164
V Predictions Std            167.98308
V Predictions Max            1191.006
V Predictions Min            -55.51263
Log Pis Mean                 -0.77607334
Log Pis Std                  2.6511827
Log Pis Max                  9.1026945
Log Pis Min                  -7.0076046
Policy mu Mean               -0.0146991
Policy mu Std                0.5975144
Policy mu Max                2.5568109
Policy mu Min                -2.1542583
Policy log std Mean          -0.915569
Policy log std Std           0.23800749
Policy log std Max           -0.122790396
Policy log std Min           -2.2118497
Z mean eval                  0.93832433
Z variance eval              0.008589936
total_rewards                [ 252.61000646 1280.26571067   18.17187301 2598.07491804  504.49261344
  571.14727064 2578.76329607 2657.26155004 1541.06470617  110.37456788]
total_rewards_mean           1211.2226512433067
total_rewards_std            1022.8126197522176
total_rewards_max            2657.2615500406764
total_rewards_min            18.171873013618175
Number of train steps total  276000
Number of env steps total    1382000
Number of rollouts total     0
Train Time (s)               43.95149970287457
(Previous) Eval Time (s)     28.994954322930425
Sample Time (s)              23.002259652595967
Epoch Time (s)               95.94871367840096
Total Train Time (s)         26643.778683335055
Epoch                        275
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:53:22.661792 UTC | [2020_01_10_11_29_18] Iteration #275 | Epoch Duration: 86.40402245521545
2020-01-10 18:53:22.661937 UTC | [2020_01_10_11_29_18] Iteration #275 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93844116
Z variance train             0.008600822
KL Divergence                20.123268
KL Loss                      2.012327
QF Loss                      1228.5613
VF Loss                      254.25116
Policy Loss                  -982.6469
Q Predictions Mean           980.9457
Q Predictions Std            219.31558
Q Predictions Max            1167.5093
Q Predictions Min            123.90519
V Predictions Mean           985.1798
V Predictions Std            216.68507
V Predictions Max            1166.2023
V Predictions Min            116.15318
Log Pis Mean                 -0.751567
Log Pis Std                  2.861343
Log Pis Max                  14.761793
Log Pis Min                  -7.9346013
Policy mu Mean               0.042316955
Policy mu Std                0.5800097
Policy mu Max                2.4966743
Policy mu Min                -2.10688
Policy log std Mean          -0.887856
Policy log std Std           0.25389794
Policy log std Max           -0.20733815
Policy log std Min           -2.576037
Z mean eval                  0.94200075
Z variance eval              0.008478348
total_rewards                [1785.46004934 2704.27502685  181.9968056  2571.347302   2756.80611778
 2765.23636332 2684.86419048 2717.3224822    78.59847839 1123.85422628]
total_rewards_mean           1936.976104224573
total_rewards_std            1036.1096400685408
total_rewards_max            2765.236363316202
total_rewards_min            78.59847838718386
Number of train steps total  277000
Number of env steps total    1387000
Number of rollouts total     0
Train Time (s)               44.397667665965855
(Previous) Eval Time (s)     19.450022672768682
Sample Time (s)              23.074573509860784
Epoch Time (s)               86.92226384859532
Total Train Time (s)         26744.506572902203
Epoch                        276
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:55:03.397189 UTC | [2020_01_10_11_29_18] Iteration #276 | Epoch Duration: 100.73511219024658
2020-01-10 18:55:03.397452 UTC | [2020_01_10_11_29_18] Iteration #276 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9426629
Z variance train             0.008458672
KL Divergence                20.140657
KL Loss                      2.0140657
QF Loss                      339.649
VF Loss                      266.40997
Policy Loss                  -1001.8739
Q Predictions Mean           1001.5809
Q Predictions Std            186.94241
Q Predictions Max            1180.8042
Q Predictions Min            26.904745
V Predictions Mean           1011.4839
V Predictions Std            187.58131
V Predictions Max            1185.5538
V Predictions Min            57.01021
Log Pis Mean                 -0.68954724
Log Pis Std                  2.4669545
Log Pis Max                  8.590658
Log Pis Min                  -8.719303
Policy mu Mean               0.037226103
Policy mu Std                0.5670299
Policy mu Max                2.366004
Policy mu Min                -2.37865
Policy log std Mean          -0.9288068
Policy log std Std           0.24483082
Policy log std Max           -0.09965861
Policy log std Min           -2.3678932
Z mean eval                  0.975212
Z variance eval              0.011654338
total_rewards                [2820.91309763  591.66121838 2651.61914695 2252.57212987 2651.64332165
 1058.92244615 2785.7787209   543.10683958 2727.48978485 2627.77869241]
total_rewards_mean           2071.148539835801
total_rewards_std            898.2591395444858
total_rewards_max            2820.9130976259917
total_rewards_min            543.1068395769012
Number of train steps total  278000
Number of env steps total    1392000
Number of rollouts total     0
Train Time (s)               44.018148589879274
(Previous) Eval Time (s)     33.262606769800186
Sample Time (s)              23.109521156176925
Epoch Time (s)               100.39027651585639
Total Train Time (s)         26839.210916314274
Epoch                        277
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:56:38.105451 UTC | [2020_01_10_11_29_18] Iteration #277 | Epoch Duration: 94.7077944278717
2020-01-10 18:56:38.105680 UTC | [2020_01_10_11_29_18] Iteration #277 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97685033
Z variance train             0.011620333
KL Divergence                19.60622
KL Loss                      1.9606221
QF Loss                      833.19934
VF Loss                      220.43996
Policy Loss                  -1002.93933
Q Predictions Mean           1002.76654
Q Predictions Std            192.21365
Q Predictions Max            1181.2177
Q Predictions Min            123.0952
V Predictions Mean           1010.2802
V Predictions Std            195.00954
V Predictions Max            1177.8756
V Predictions Min            135.00316
Log Pis Mean                 -0.6029717
Log Pis Std                  2.5484707
Log Pis Max                  8.8570385
Log Pis Min                  -8.270632
Policy mu Mean               -0.035529483
Policy mu Std                0.5992619
Policy mu Max                2.2366753
Policy mu Min                -2.6050339
Policy log std Mean          -0.9008415
Policy log std Std           0.24241807
Policy log std Max           -0.035397828
Policy log std Min           -2.3118565
Z mean eval                  1.0045124
Z variance eval              0.00875842
total_rewards                [2802.24739162 2346.25466871 1228.6495588  2836.86709359 2702.69206318
 2804.67962786 2770.66689716  -34.95102023 2889.6861691   210.77509078]
total_rewards_mean           2055.756754058534
total_rewards_std            1090.726311580648
total_rewards_max            2889.686169103063
total_rewards_min            -34.9510202340108
Number of train steps total  279000
Number of env steps total    1397000
Number of rollouts total     0
Train Time (s)               43.529079363681376
(Previous) Eval Time (s)     27.579879069235176
Sample Time (s)              23.257108613383025
Epoch Time (s)               94.36606704629958
Total Train Time (s)         26933.045815146994
Epoch                        278
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:58:11.941718 UTC | [2020_01_10_11_29_18] Iteration #278 | Epoch Duration: 93.83587551116943
2020-01-10 18:58:11.941876 UTC | [2020_01_10_11_29_18] Iteration #278 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0030831
Z variance train             0.008759255
KL Divergence                20.547302
KL Loss                      2.0547302
QF Loss                      536.70197
VF Loss                      156.1993
Policy Loss                  -1017.3751
Q Predictions Mean           1016.9939
Q Predictions Std            190.81445
Q Predictions Max            1166.9326
Q Predictions Min            130.01904
V Predictions Mean           1020.15625
V Predictions Std            189.8864
V Predictions Max            1168.2097
V Predictions Min            120.83784
Log Pis Mean                 -0.5199565
Log Pis Std                  2.4827297
Log Pis Max                  9.660911
Log Pis Min                  -9.627758
Policy mu Mean               0.067602396
Policy mu Std                0.57184434
Policy mu Max                2.0550466
Policy mu Min                -2.6727114
Policy log std Mean          -0.92845416
Policy log std Std           0.2405949
Policy log std Max           -0.1688931
Policy log std Min           -2.1515722
Z mean eval                  0.94577473
Z variance eval              0.028657481
total_rewards                [2003.22656931 2564.19600363  991.31824376 1333.13900448 1693.52267235
 1024.02594287  132.44715645  486.46309432 2554.14289015 2599.68235189]
total_rewards_mean           1538.2163929203027
total_rewards_std            844.9688504950047
total_rewards_max            2599.6823518944766
total_rewards_min            132.44715644711994
Number of train steps total  280000
Number of env steps total    1402000
Number of rollouts total     0
Train Time (s)               44.03835219424218
(Previous) Eval Time (s)     27.04944962821901
Sample Time (s)              22.76328523643315
Epoch Time (s)               93.85108705889434
Total Train Time (s)         27022.290988056455
Epoch                        279
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:59:41.194481 UTC | [2020_01_10_11_29_18] Iteration #279 | Epoch Duration: 89.25243163108826
2020-01-10 18:59:41.194795 UTC | [2020_01_10_11_29_18] Iteration #279 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9451698
Z variance train             0.028800469
KL Divergence                19.914532
KL Loss                      1.9914532
QF Loss                      801.5321
VF Loss                      108.41115
Policy Loss                  -1010.45544
Q Predictions Mean           1008.80566
Q Predictions Std            184.88956
Q Predictions Max            1179.853
Q Predictions Min            120.86385
V Predictions Mean           1014.4144
V Predictions Std            183.86362
V Predictions Max            1172.5808
V Predictions Min            133.3744
Log Pis Mean                 -0.34507608
Log Pis Std                  2.692739
Log Pis Max                  9.06772
Log Pis Min                  -7.8685956
Policy mu Mean               0.067102805
Policy mu Std                0.6179411
Policy mu Max                1.9830567
Policy mu Min                -2.3668573
Policy log std Mean          -0.91064304
Policy log std Std           0.23507737
Policy log std Max           -0.15945858
Policy log std Min           -2.2601795
Z mean eval                  0.95221627
Z variance eval              0.016408017
total_rewards                [1940.67961746 2743.29188434 2869.02997537  541.73103473  565.42120992
 2820.70833728 2355.00936535  483.69308327 2679.92297306 2859.30289979]
total_rewards_mean           1985.8790380566284
total_rewards_std            989.6091505519838
total_rewards_max            2869.029975372916
total_rewards_min            483.6930832705614
Number of train steps total  281000
Number of env steps total    1407000
Number of rollouts total     0
Train Time (s)               44.42242037598044
(Previous) Eval Time (s)     22.450522240251303
Sample Time (s)              22.851291314233094
Epoch Time (s)               89.72423393046483
Total Train Time (s)         27116.016828984953
Epoch                        280
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:01:14.921312 UTC | [2020_01_10_11_29_18] Iteration #280 | Epoch Duration: 93.72630572319031
2020-01-10 19:01:14.921446 UTC | [2020_01_10_11_29_18] Iteration #280 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95040673
Z variance train             0.016391493
KL Divergence                20.20792
KL Loss                      2.020792
QF Loss                      853.22797
VF Loss                      339.65768
Policy Loss                  -1019.50397
Q Predictions Mean           1020.0652
Q Predictions Std            179.25986
Q Predictions Max            1165.1688
Q Predictions Min            119.864784
V Predictions Mean           1026.2815
V Predictions Std            176.85294
V Predictions Max            1168.8484
V Predictions Min            115.91247
Log Pis Mean                 -0.6917337
Log Pis Std                  2.4843636
Log Pis Max                  8.112489
Log Pis Min                  -8.011377
Policy mu Mean               -0.005224748
Policy mu Std                0.5837104
Policy mu Max                1.9574682
Policy mu Min                -2.1078892
Policy log std Mean          -0.9249683
Policy log std Std           0.25049853
Policy log std Max           -0.09848893
Policy log std Min           -2.5637555
Z mean eval                  0.9273772
Z variance eval              0.04057131
total_rewards                [2123.69888117  -61.69014873 2638.02404896 1045.01099215 2141.38667767
 2413.97132695 1513.50959175 2574.78203469 2725.02389031 2731.15443485]
total_rewards_mean           1984.4871729759616
total_rewards_std            860.3020459549621
total_rewards_max            2731.154434845847
total_rewards_min            -61.69014873417214
Number of train steps total  282000
Number of env steps total    1412000
Number of rollouts total     0
Train Time (s)               44.14432583609596
(Previous) Eval Time (s)     26.45236717304215
Sample Time (s)              22.610151897650212
Epoch Time (s)               93.20684490678832
Total Train Time (s)         27214.23189687077
Epoch                        281
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:02:53.142563 UTC | [2020_01_10_11_29_18] Iteration #281 | Epoch Duration: 98.22100329399109
2020-01-10 19:02:53.142754 UTC | [2020_01_10_11_29_18] Iteration #281 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92808926
Z variance train             0.040765367
KL Divergence                18.280079
KL Loss                      1.8280079
QF Loss                      874.59827
VF Loss                      182.6916
Policy Loss                  -1043.4955
Q Predictions Mean           1040.2141
Q Predictions Std            138.18039
Q Predictions Max            1177.2214
Q Predictions Min            124.29332
V Predictions Mean           1049.3585
V Predictions Std            138.3137
V Predictions Max            1175.8027
V Predictions Min            127.10188
Log Pis Mean                 -0.58746916
Log Pis Std                  2.4327977
Log Pis Max                  8.358949
Log Pis Min                  -7.535795
Policy mu Mean               0.04179077
Policy mu Std                0.5409194
Policy mu Max                1.8788482
Policy mu Min                -2.1817176
Policy log std Mean          -0.9653349
Policy log std Std           0.23245232
Policy log std Max           -0.0021069646
Policy log std Min           -2.388105
Z mean eval                  0.95098066
Z variance eval              0.030169804
total_rewards                [ 358.82738187 2569.42826159  442.08136598 2098.09001456 2553.87586737
 1204.83177447 1440.14660117 2671.94481374 2569.45951251   60.12051029]
total_rewards_mean           1596.8806103555685
total_rewards_std            980.8572281898348
total_rewards_max            2671.944813739438
total_rewards_min            60.12051029032866
Number of train steps total  283000
Number of env steps total    1417000
Number of rollouts total     0
Train Time (s)               44.32460323907435
(Previous) Eval Time (s)     31.466254306025803
Sample Time (s)              21.446419473271817
Epoch Time (s)               97.23727701837197
Total Train Time (s)         27301.773772282526
Epoch                        282
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:04:20.687811 UTC | [2020_01_10_11_29_18] Iteration #282 | Epoch Duration: 87.54492211341858
2020-01-10 19:04:20.687984 UTC | [2020_01_10_11_29_18] Iteration #282 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94985676
Z variance train             0.03015263
KL Divergence                18.047102
KL Loss                      1.8047103
QF Loss                      1032.4364
VF Loss                      978.38104
Policy Loss                  -1000.8624
Q Predictions Mean           999.7911
Q Predictions Std            229.54466
Q Predictions Max            1171.5293
Q Predictions Min            107.01937
V Predictions Mean           987.6339
V Predictions Std            220.7122
V Predictions Max            1155.1066
V Predictions Min            118.6139
Log Pis Mean                 -0.81652725
Log Pis Std                  2.6886349
Log Pis Max                  9.942489
Log Pis Min                  -8.171341
Policy mu Mean               0.07258156
Policy mu Std                0.56453496
Policy mu Max                2.4330497
Policy mu Min                -2.2867947
Policy log std Mean          -0.9136177
Policy log std Std           0.25971463
Policy log std Max           -0.14927179
Policy log std Min           -2.7346516
Z mean eval                  0.94749963
Z variance eval              0.025846977
total_rewards                [2371.208799    596.87259677 1744.12280195 2953.22063063 1415.92736032
 2828.36118018 1477.82994519 2843.47471861  262.10714457 1758.40627403]
total_rewards_mean           1825.1531451260648
total_rewards_std            886.8497241586116
total_rewards_max            2953.2206306313683
total_rewards_min            262.10714457251186
Number of train steps total  284000
Number of env steps total    1422000
Number of rollouts total     0
Train Time (s)               43.82965090684593
(Previous) Eval Time (s)     21.77366196596995
Sample Time (s)              23.120211089029908
Epoch Time (s)               88.72352396184579
Total Train Time (s)         27394.815720713697
Epoch                        283
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:05:53.735391 UTC | [2020_01_10_11_29_18] Iteration #283 | Epoch Duration: 93.04714512825012
2020-01-10 19:05:53.735633 UTC | [2020_01_10_11_29_18] Iteration #283 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94760334
Z variance train             0.025823113
KL Divergence                18.353983
KL Loss                      1.8353983
QF Loss                      866.2532
VF Loss                      240.96
Policy Loss                  -1009.0526
Q Predictions Mean           1009.7466
Q Predictions Std            193.47983
Q Predictions Max            1185.7048
Q Predictions Min            88.53195
V Predictions Mean           1020.48975
V Predictions Std            194.51955
V Predictions Max            1207.8035
V Predictions Min            92.152306
Log Pis Mean                 -0.6225571
Log Pis Std                  2.6213598
Log Pis Max                  9.680433
Log Pis Min                  -8.595379
Policy mu Mean               -0.03191773
Policy mu Std                0.597517
Policy mu Max                2.3805158
Policy mu Min                -2.3579497
Policy log std Mean          -0.8952201
Policy log std Std           0.24738017
Policy log std Max           -0.20080394
Policy log std Min           -2.1560006
Z mean eval                  0.9772762
Z variance eval              0.016552392
total_rewards                [2766.1623724  2339.09599336 2865.23486781 2308.75840267  270.26944944
 1712.12799598 2702.72501392 2174.96016034 1168.63280144 1934.4464581 ]
total_rewards_mean           2024.2413515471958
total_rewards_std            763.8597925577027
total_rewards_max            2865.234867814618
total_rewards_min            270.26944944195924
Number of train steps total  285000
Number of env steps total    1427000
Number of rollouts total     0
Train Time (s)               43.77955880202353
(Previous) Eval Time (s)     26.09706261800602
Sample Time (s)              22.61337239528075
Epoch Time (s)               92.4899938153103
Total Train Time (s)         27487.02645305684
Epoch                        284
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:07:25.951722 UTC | [2020_01_10_11_29_18] Iteration #284 | Epoch Duration: 92.21582770347595
2020-01-10 19:07:25.951981 UTC | [2020_01_10_11_29_18] Iteration #284 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9782747
Z variance train             0.016516756
KL Divergence                19.737776
KL Loss                      1.9737777
QF Loss                      593.82294
VF Loss                      163.3697
Policy Loss                  -1027.0021
Q Predictions Mean           1025.0977
Q Predictions Std            190.65898
Q Predictions Max            1203.1465
Q Predictions Min            119.53596
V Predictions Mean           1028.4751
V Predictions Std            190.53699
V Predictions Max            1220.5975
V Predictions Min            126.847435
Log Pis Mean                 -0.29224485
Log Pis Std                  2.5346792
Log Pis Max                  9.423054
Log Pis Min                  -6.826458
Policy mu Mean               -0.023603093
Policy mu Std                0.59490865
Policy mu Max                2.2497694
Policy mu Min                -2.1713102
Policy log std Mean          -0.9503562
Policy log std Std           0.23551376
Policy log std Max           -0.13420326
Policy log std Min           -2.0382066
Z mean eval                  0.9328227
Z variance eval              0.012968448
total_rewards                [1820.03008353 2682.06923104 1746.64723076 1252.83622193 1268.54670421
 2870.44127432 2724.51922399 1967.83015648  138.44019873 2440.22316774]
total_rewards_mean           1891.1583492724399
total_rewards_std            804.9496981940711
total_rewards_max            2870.441274322754
total_rewards_min            138.44019872705655
Number of train steps total  286000
Number of env steps total    1432000
Number of rollouts total     0
Train Time (s)               43.87781763682142
(Previous) Eval Time (s)     25.82264526002109
Sample Time (s)              23.109625845216215
Epoch Time (s)               92.81008874205872
Total Train Time (s)         27580.672134596854
Epoch                        285
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:08:59.603896 UTC | [2020_01_10_11_29_18] Iteration #285 | Epoch Duration: 93.65169835090637
2020-01-10 19:08:59.604205 UTC | [2020_01_10_11_29_18] Iteration #285 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9325961
Z variance train             0.012984233
KL Divergence                20.380013
KL Loss                      2.0380013
QF Loss                      582.6124
VF Loss                      432.45456
Policy Loss                  -1045.1055
Q Predictions Mean           1042.1903
Q Predictions Std            160.12054
Q Predictions Max            1173.1243
Q Predictions Min            62.487823
V Predictions Mean           1032.443
V Predictions Std            159.18114
V Predictions Max            1169.8453
V Predictions Min            57.465668
Log Pis Mean                 -0.3896262
Log Pis Std                  2.3226113
Log Pis Max                  7.772106
Log Pis Min                  -6.4132257
Policy mu Mean               -0.0021171533
Policy mu Std                0.58681
Policy mu Max                2.5512664
Policy mu Min                -2.300534
Policy log std Mean          -0.93488574
Policy log std Std           0.24946876
Policy log std Max           -0.22239089
Policy log std Min           -2.3321223
Z mean eval                  0.9592968
Z variance eval              0.012865108
total_rewards                [2741.69835194 2784.32261604  235.88712012 1889.48359944 2943.89291017
 2674.96226066  713.12552951 2602.84202213 1356.64886091 2356.67675951]
total_rewards_mean           2029.9540030444339
total_rewards_std            904.8594034797288
total_rewards_max            2943.8929101727126
total_rewards_min            235.88712011983984
Number of train steps total  287000
Number of env steps total    1437000
Number of rollouts total     0
Train Time (s)               43.55840447824448
(Previous) Eval Time (s)     26.66399056231603
Sample Time (s)              22.547780943103135
Epoch Time (s)               92.77017598366365
Total Train Time (s)         27673.626558731776
Epoch                        286
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:10:32.559855 UTC | [2020_01_10_11_29_18] Iteration #286 | Epoch Duration: 92.95545148849487
2020-01-10 19:10:32.560003 UTC | [2020_01_10_11_29_18] Iteration #286 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9605187
Z variance train             0.012854928
KL Divergence                20.393934
KL Loss                      2.0393934
QF Loss                      3737.3403
VF Loss                      131.0245
Policy Loss                  -1035.6615
Q Predictions Mean           1033.7388
Q Predictions Std            194.43967
Q Predictions Max            1202.2747
Q Predictions Min            97.76336
V Predictions Mean           1037.1693
V Predictions Std            185.53609
V Predictions Max            1221.6067
V Predictions Min            99.0697
Log Pis Mean                 -0.5324048
Log Pis Std                  2.666859
Log Pis Max                  11.192003
Log Pis Min                  -10.704348
Policy mu Mean               -0.031918436
Policy mu Std                0.6107289
Policy mu Max                2.5045464
Policy mu Min                -2.0449922
Policy log std Mean          -0.91657495
Policy log std Std           0.26903206
Policy log std Max           -0.23683435
Policy log std Min           -2.9735565
Z mean eval                  0.9389342
Z variance eval              0.012058941
total_rewards                [2140.32860715 2579.52686805  308.86840123 1019.23570399 2580.91364548
 1156.71340395 2532.14603106  651.25018539  957.22342963 2827.48633781]
total_rewards_mean           1675.3692613724736
total_rewards_std            897.0246404199339
total_rewards_max            2827.486337811924
total_rewards_min            308.86840122831
Number of train steps total  288000
Number of env steps total    1442000
Number of rollouts total     0
Train Time (s)               43.61511320620775
(Previous) Eval Time (s)     26.84903486026451
Sample Time (s)              23.073193260934204
Epoch Time (s)               93.53734132740647
Total Train Time (s)         27770.844779529143
Epoch                        287
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:12:09.782436 UTC | [2020_01_10_11_29_18] Iteration #287 | Epoch Duration: 97.22233247756958
2020-01-10 19:12:09.782572 UTC | [2020_01_10_11_29_18] Iteration #287 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93852615
Z variance train             0.012062758
KL Divergence                20.63174
KL Loss                      2.063174
QF Loss                      439.85406
VF Loss                      90.52831
Policy Loss                  -1053.3186
Q Predictions Mean           1052.937
Q Predictions Std            164.79668
Q Predictions Max            1238.597
Q Predictions Min            110.645355
V Predictions Mean           1051.165
V Predictions Std            165.21422
V Predictions Max            1237.5793
V Predictions Min            110.84002
Log Pis Mean                 -0.5001204
Log Pis Std                  2.4745376
Log Pis Max                  11.537804
Log Pis Min                  -7.731579
Policy mu Mean               -0.04041375
Policy mu Std                0.57575995
Policy mu Max                2.0461533
Policy mu Min                -2.36158
Policy log std Mean          -0.94133973
Policy log std Std           0.2429547
Policy log std Max           -0.22711736
Policy log std Min           -1.9096596
Z mean eval                  0.9411254
Z variance eval              0.016378542
total_rewards                [2867.59730563 2727.22957222 1845.71981839  544.2481253  2892.62179205
 2526.37443063 1098.91176018 2405.82006242 2709.75675113 2709.74163448]
total_rewards_mean           2232.802125241133
total_rewards_std            770.7539823285691
total_rewards_max            2892.6217920483095
total_rewards_min            544.2481253000205
Number of train steps total  289000
Number of env steps total    1447000
Number of rollouts total     0
Train Time (s)               44.535805696155876
(Previous) Eval Time (s)     30.53376877028495
Sample Time (s)              23.094077681191266
Epoch Time (s)               98.16365214763209
Total Train Time (s)         27873.21983607812
Epoch                        288
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:13:52.162764 UTC | [2020_01_10_11_29_18] Iteration #288 | Epoch Duration: 102.38009262084961
2020-01-10 19:13:52.162902 UTC | [2020_01_10_11_29_18] Iteration #288 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9400322
Z variance train             0.016326046
KL Divergence                20.077093
KL Loss                      2.0077093
QF Loss                      477.26804
VF Loss                      150.11377
Policy Loss                  -1050.8612
Q Predictions Mean           1049.6897
Q Predictions Std            166.72765
Q Predictions Max            1230.5646
Q Predictions Min            -7.9624248
V Predictions Mean           1044.7599
V Predictions Std            162.38548
V Predictions Max            1212.6666
V Predictions Min            101.2602
Log Pis Mean                 -0.44398886
Log Pis Std                  2.4739292
Log Pis Max                  6.776016
Log Pis Min                  -7.3980174
Policy mu Mean               0.0066303895
Policy mu Std                0.5709272
Policy mu Max                2.6333039
Policy mu Min                -1.9370426
Policy log std Mean          -0.97355926
Policy log std Std           0.23807086
Policy log std Max           -0.088354886
Policy log std Min           -2.070948
Z mean eval                  0.97691643
Z variance eval              0.012923025
total_rewards                [ 742.93149349 2636.21209659  649.88832564 1364.08223773 2560.86978944
 2771.9212138  1070.5459968  2726.9682147  2118.45229006 2532.09346747]
total_rewards_mean           1917.3965125709808
total_rewards_std            821.2128742046059
total_rewards_max            2771.9212138023668
total_rewards_min            649.8883256387692
Number of train steps total  290000
Number of env steps total    1452000
Number of rollouts total     0
Train Time (s)               43.605339963920414
(Previous) Eval Time (s)     34.749928421806544
Sample Time (s)              22.87292424822226
Epoch Time (s)               101.22819263394922
Total Train Time (s)         27967.74299445795
Epoch                        289
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:15:26.692705 UTC | [2020_01_10_11_29_18] Iteration #289 | Epoch Duration: 94.52970290184021
2020-01-10 19:15:26.692842 UTC | [2020_01_10_11_29_18] Iteration #289 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9757044
Z variance train             0.012900424
KL Divergence                20.405499
KL Loss                      2.04055
QF Loss                      788.26184
VF Loss                      124.93636
Policy Loss                  -1045.9143
Q Predictions Mean           1046.8982
Q Predictions Std            174.81805
Q Predictions Max            1197.7906
Q Predictions Min            -3.2223732
V Predictions Mean           1052.0905
V Predictions Std            173.71242
V Predictions Max            1196.4995
V Predictions Min            30.600315
Log Pis Mean                 -0.7693393
Log Pis Std                  2.552718
Log Pis Max                  6.6489935
Log Pis Min                  -7.0502596
Policy mu Mean               0.01516772
Policy mu Std                0.5503306
Policy mu Max                2.0175798
Policy mu Min                -2.0711994
Policy log std Mean          -0.9262092
Policy log std Std           0.22999346
Policy log std Max           -0.18490756
Policy log std Min           -2.0585258
Z mean eval                  0.93553936
Z variance eval              0.010173139
total_rewards                [2821.72430009 2838.14542846  843.72162965 2562.96884448 2725.51231102
 2923.99109547 2142.5456645  2932.07467059 2854.92946683 2766.3598713 ]
total_rewards_mean           2541.1973282386725
total_rewards_std            607.4626453408708
total_rewards_max            2932.074670590123
total_rewards_min            843.721629647523
Number of train steps total  291000
Number of env steps total    1457000
Number of rollouts total     0
Train Time (s)               44.06018130108714
(Previous) Eval Time (s)     28.051197906956077
Sample Time (s)              22.779105979483575
Epoch Time (s)               94.89048518752679
Total Train Time (s)         28065.837159341667
Epoch                        290
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:17:04.790084 UTC | [2020_01_10_11_29_18] Iteration #290 | Epoch Duration: 98.09713220596313
2020-01-10 19:17:04.790258 UTC | [2020_01_10_11_29_18] Iteration #290 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9356147
Z variance train             0.010176792
KL Divergence                20.790878
KL Loss                      2.079088
QF Loss                      762.85187
VF Loss                      383.413
Policy Loss                  -1022.0851
Q Predictions Mean           1019.00757
Q Predictions Std            225.43639
Q Predictions Max            1212.8928
Q Predictions Min            110.65683
V Predictions Mean           1017.4274
V Predictions Std            225.30089
V Predictions Max            1206.9705
V Predictions Min            131.65181
Log Pis Mean                 -0.44984823
Log Pis Std                  2.7159073
Log Pis Max                  14.113689
Log Pis Min                  -7.301878
Policy mu Mean               -0.037963647
Policy mu Std                0.58635235
Policy mu Max                2.3231616
Policy mu Min                -2.0490797
Policy log std Mean          -0.94326687
Policy log std Std           0.26183173
Policy log std Max           -0.069239914
Policy log std Min           -2.2761712
Z mean eval                  0.95330775
Z variance eval              0.012840757
total_rewards                [2831.80980909 2662.47721267 2469.83599198 2902.44613434 3088.37114705
 2773.82924502 2332.43457194 2867.81657501  663.39794707 2512.77556465]
total_rewards_mean           2510.5194198806066
total_rewards_std            652.3851128009046
total_rewards_max            3088.3711470494636
total_rewards_min            663.3979470693262
Number of train steps total  292000
Number of env steps total    1462000
Number of rollouts total     0
Train Time (s)               44.39307838771492
(Previous) Eval Time (s)     31.25760155171156
Sample Time (s)              22.946649810299277
Epoch Time (s)               98.59732974972576
Total Train Time (s)         28165.879444370046
Epoch                        291
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:18:44.834229 UTC | [2020_01_10_11_29_18] Iteration #291 | Epoch Duration: 100.04385018348694
2020-01-10 19:18:44.834363 UTC | [2020_01_10_11_29_18] Iteration #291 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9528454
Z variance train             0.012811713
KL Divergence                20.420898
KL Loss                      2.04209
QF Loss                      745.75024
VF Loss                      99.196625
Policy Loss                  -1049.0397
Q Predictions Mean           1048.9768
Q Predictions Std            167.42737
Q Predictions Max            1206.251
Q Predictions Min            101.27876
V Predictions Mean           1054.5596
V Predictions Std            165.37682
V Predictions Max            1224.355
V Predictions Min            91.43167
Log Pis Mean                 -0.40574312
Log Pis Std                  2.562569
Log Pis Max                  10.82444
Log Pis Min                  -6.2888374
Policy mu Mean               0.0042718886
Policy mu Std                0.5877578
Policy mu Max                3.5284219
Policy mu Min                -2.4526744
Policy log std Mean          -0.9417732
Policy log std Std           0.23845866
Policy log std Max           -0.084564924
Policy log std Min           -1.9769181
Z mean eval                  0.9300691
Z variance eval              0.009667253
total_rewards                [2821.82414624 2862.60645637 2554.47387543 1189.79453303  491.63112773
 2725.61743116 2751.1859556  1656.89782983 2706.97794694 2806.3256838 ]
total_rewards_mean           2256.733498613644
total_rewards_std            797.3652730183322
total_rewards_max            2862.6064563668906
total_rewards_min            491.63112773441446
Number of train steps total  293000
Number of env steps total    1467000
Number of rollouts total     0
Train Time (s)               43.868414212949574
(Previous) Eval Time (s)     32.70389042189345
Sample Time (s)              23.305087838321924
Epoch Time (s)               99.87739247316495
Total Train Time (s)         28260.92514146492
Epoch                        292
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:20:19.884082 UTC | [2020_01_10_11_29_18] Iteration #292 | Epoch Duration: 95.04960775375366
2020-01-10 19:20:19.884246 UTC | [2020_01_10_11_29_18] Iteration #292 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93044555
Z variance train             0.009596044
KL Divergence                20.946247
KL Loss                      2.0946248
QF Loss                      654.3844
VF Loss                      262.76794
Policy Loss                  -1056.7045
Q Predictions Mean           1054.185
Q Predictions Std            143.92729
Q Predictions Max            1177.4694
Q Predictions Min            106.42752
V Predictions Mean           1048.8901
V Predictions Std            139.83629
V Predictions Max            1166.2792
V Predictions Min            116.34995
Log Pis Mean                 -0.3779158
Log Pis Std                  2.5751195
Log Pis Max                  10.082008
Log Pis Min                  -6.1881795
Policy mu Mean               -0.054250658
Policy mu Std                0.602497
Policy mu Max                1.8224274
Policy mu Min                -2.4681501
Policy log std Mean          -0.92611635
Policy log std Std           0.2515379
Policy log std Max           -0.15565449
Policy log std Min           -2.2890491
Z mean eval                  0.9405001
Z variance eval              0.010251108
total_rewards                [ 593.56452532  405.34066679 2697.52518297 2797.43770851 2710.8163709
 2800.61446472  745.41272987 2072.50502212  390.02748333 2699.52755553]
total_rewards_mean           1791.2771710082197
total_rewards_std            1049.506319945535
total_rewards_max            2800.614464724948
total_rewards_min            390.0274833303283
Number of train steps total  294000
Number of env steps total    1472000
Number of rollouts total     0
Train Time (s)               46.195569906849414
(Previous) Eval Time (s)     27.875837991014123
Sample Time (s)              22.504565387498587
Epoch Time (s)               96.57597328536212
Total Train Time (s)         28359.13819470862
Epoch                        293
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:21:58.100158 UTC | [2020_01_10_11_29_18] Iteration #293 | Epoch Duration: 98.2157826423645
2020-01-10 19:21:58.100337 UTC | [2020_01_10_11_29_18] Iteration #293 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9397024
Z variance train             0.010255721
KL Divergence                21.17741
KL Loss                      2.117741
QF Loss                      445.51117
VF Loss                      105.94881
Policy Loss                  -1046.6184
Q Predictions Mean           1045.017
Q Predictions Std            192.031
Q Predictions Max            1227.3483
Q Predictions Min            95.666
V Predictions Mean           1042.1073
V Predictions Std            191.79953
V Predictions Max            1210.078
V Predictions Min            90.91878
Log Pis Mean                 -0.7940206
Log Pis Std                  2.54775
Log Pis Max                  12.433188
Log Pis Min                  -7.9853067
Policy mu Mean               0.03912387
Policy mu Std                0.5742818
Policy mu Max                2.273805
Policy mu Min                -3.1029124
Policy log std Mean          -0.9256835
Policy log std Std           0.22799827
Policy log std Max           -0.21000093
Policy log std Min           -1.8407078
Z mean eval                  0.9708575
Z variance eval              0.009944697
total_rewards                [2839.8674179   281.15340257 1301.13433783 2819.94081089  -87.5002493
 2909.68193468  802.06986897  101.77882074  176.32748341  277.99734865]
total_rewards_mean           1142.2451176344098
total_rewards_std            1182.270104770883
total_rewards_max            2909.6819346760403
total_rewards_min            -87.50024929537838
Number of train steps total  295000
Number of env steps total    1477000
Number of rollouts total     0
Train Time (s)               45.09090202394873
(Previous) Eval Time (s)     29.51539041241631
Sample Time (s)              22.9647588157095
Epoch Time (s)               97.57105125207454
Total Train Time (s)         28450.532999231014
Epoch                        294
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:23:29.502730 UTC | [2020_01_10_11_29_18] Iteration #294 | Epoch Duration: 91.40226912498474
2020-01-10 19:23:29.502868 UTC | [2020_01_10_11_29_18] Iteration #294 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96715707
Z variance train             0.009965414
KL Divergence                21.347311
KL Loss                      2.134731
QF Loss                      744.3925
VF Loss                      234.7584
Policy Loss                  -1017.26605
Q Predictions Mean           1016.01514
Q Predictions Std            225.10384
Q Predictions Max            1184.3214
Q Predictions Min            13.134726
V Predictions Mean           1007.5117
V Predictions Std            224.26233
V Predictions Max            1178.2515
V Predictions Min            24.973188
Log Pis Mean                 -0.6796099
Log Pis Std                  2.6984873
Log Pis Max                  10.04036
Log Pis Min                  -8.460644
Policy mu Mean               0.06999574
Policy mu Std                0.59334
Policy mu Max                2.8552372
Policy mu Min                -2.0385835
Policy log std Mean          -0.91631335
Policy log std Std           0.27000502
Policy log std Max           -0.04403341
Policy log std Min           -2.3679037
Z mean eval                  0.95177126
Z variance eval              0.015084784
total_rewards                [ 858.0491588  2865.84301949  386.97056706  390.25032138  691.0591663
 2815.70587547 1305.86563619 2560.49082198 1057.65699489  479.59834446]
total_rewards_mean           1341.1489906009583
total_rewards_std            963.3459141457428
total_rewards_max            2865.8430194869225
total_rewards_min            386.9705670621652
Number of train steps total  296000
Number of env steps total    1482000
Number of rollouts total     0
Train Time (s)               44.05543962866068
(Previous) Eval Time (s)     23.346350979991257
Sample Time (s)              22.703217974863946
Epoch Time (s)               90.10500858351588
Total Train Time (s)         28539.459267830476
Epoch                        295
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:24:58.431151 UTC | [2020_01_10_11_29_18] Iteration #295 | Epoch Duration: 88.92817950248718
2020-01-10 19:24:58.431287 UTC | [2020_01_10_11_29_18] Iteration #295 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9517946
Z variance train             0.015082109
KL Divergence                20.895573
KL Loss                      2.0895574
QF Loss                      846.56946
VF Loss                      62.939926
Policy Loss                  -1078.0754
Q Predictions Mean           1077.3953
Q Predictions Std            142.33629
Q Predictions Max            1218.2684
Q Predictions Min            178.87025
V Predictions Mean           1078.8875
V Predictions Std            140.5327
V Predictions Max            1212.2366
V Predictions Min            183.2539
Log Pis Mean                 -0.6302818
Log Pis Std                  2.2447772
Log Pis Max                  5.314316
Log Pis Min                  -8.0451145
Policy mu Mean               0.00793289
Policy mu Std                0.57395387
Policy mu Max                2.061125
Policy mu Min                -2.184755
Policy log std Mean          -0.94364905
Policy log std Std           0.22799455
Policy log std Max           -0.25811863
Policy log std Min           -2.035183
Z mean eval                  0.9476131
Z variance eval              0.018563481
total_rewards                [1061.53376639 2934.79456466 1049.26027569 2390.55201107 1250.90981072
 2847.69031173 3098.47401541 2869.08914363  738.85556285 3091.12408205]
total_rewards_mean           2133.2283544187244
total_rewards_std            930.387652241578
total_rewards_max            3098.4740154116516
total_rewards_min            738.8555628464652
Number of train steps total  297000
Number of env steps total    1487000
Number of rollouts total     0
Train Time (s)               44.185814700089395
(Previous) Eval Time (s)     22.16927949571982
Sample Time (s)              22.960004178341478
Epoch Time (s)               89.3150983741507
Total Train Time (s)         28638.389993750025
Epoch                        296
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:26:37.364890 UTC | [2020_01_10_11_29_18] Iteration #296 | Epoch Duration: 98.93350076675415
2020-01-10 19:26:37.365028 UTC | [2020_01_10_11_29_18] Iteration #296 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94810617
Z variance train             0.018592248
KL Divergence                21.110386
KL Loss                      2.1110387
QF Loss                      505.17545
VF Loss                      233.4144
Policy Loss                  -1049.4458
Q Predictions Mean           1050.8999
Q Predictions Std            216.14894
Q Predictions Max            1234.598
Q Predictions Min            133.51497
V Predictions Mean           1047.2161
V Predictions Std            216.93408
V Predictions Max            1225.7424
V Predictions Min            136.27333
Log Pis Mean                 -0.49019873
Log Pis Std                  2.3228328
Log Pis Max                  10.128645
Log Pis Min                  -6.803255
Policy mu Mean               0.012600299
Policy mu Std                0.5814232
Policy mu Max                3.1357274
Policy mu Min                -1.9524696
Policy log std Mean          -0.92786306
Policy log std Std           0.25135103
Policy log std Max           -0.124779165
Policy log std Min           -2.156296
Z mean eval                  0.95357305
Z variance eval              0.018775849
total_rewards                [ -13.11949069 1534.34274269 2040.89953485 1524.86555807  266.09517544
 1563.94076015 2783.82373653 2790.44214843   29.85609589 2749.90832395]
total_rewards_mean           1527.105458530944
total_rewards_std            1055.47152211245
total_rewards_max            2790.442148434703
total_rewards_min            -13.119490689954425
Number of train steps total  298000
Number of env steps total    1492000
Number of rollouts total     0
Train Time (s)               43.48328603012487
(Previous) Eval Time (s)     31.78742802888155
Sample Time (s)              22.92928383825347
Epoch Time (s)               98.19999789725989
Total Train Time (s)         28727.30654776655
Epoch                        297
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:28:06.284298 UTC | [2020_01_10_11_29_18] Iteration #297 | Epoch Duration: 88.91915321350098
2020-01-10 19:28:06.284486 UTC | [2020_01_10_11_29_18] Iteration #297 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.952891
Z variance train             0.018758055
KL Divergence                20.22904
KL Loss                      2.0229042
QF Loss                      435.79694
VF Loss                      61.192554
Policy Loss                  -1037.5784
Q Predictions Mean           1035.587
Q Predictions Std            208.15776
Q Predictions Max            1224.0956
Q Predictions Min            64.25853
V Predictions Mean           1037.6436
V Predictions Std            205.80019
V Predictions Max            1201.3873
V Predictions Min            59.1015
Log Pis Mean                 -0.47295994
Log Pis Std                  2.5615172
Log Pis Max                  9.211508
Log Pis Min                  -8.047762
Policy mu Mean               -0.035892513
Policy mu Std                0.57397354
Policy mu Max                2.2437873
Policy mu Min                -2.2541673
Policy log std Mean          -0.9380298
Policy log std Std           0.26258862
Policy log std Max           -0.076453865
Policy log std Min           -2.1305637
Z mean eval                  0.9175584
Z variance eval              0.017732814
total_rewards                [ -11.67350379  767.09538936 2630.0128921   715.95014065 2175.94634615
 2807.81436347 2758.52119131 2632.43254214 2783.33992421 1517.55727664]
total_rewards_mean           1877.6996562239608
total_rewards_std            998.4102116957187
total_rewards_max            2807.814363474109
total_rewards_min            -11.67350379033549
Number of train steps total  299000
Number of env steps total    1497000
Number of rollouts total     0
Train Time (s)               43.207193325739354
(Previous) Eval Time (s)     22.506323541048914
Sample Time (s)              23.19323792262003
Epoch Time (s)               88.9067547894083
Total Train Time (s)         28817.11659009196
Epoch                        298
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:29:36.098283 UTC | [2020_01_10_11_29_18] Iteration #298 | Epoch Duration: 89.81364727020264
2020-01-10 19:29:36.098493 UTC | [2020_01_10_11_29_18] Iteration #298 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9146555
Z variance train             0.01772092
KL Divergence                20.457153
KL Loss                      2.0457153
QF Loss                      546.5176
VF Loss                      85.75094
Policy Loss                  -1048.4536
Q Predictions Mean           1047.1624
Q Predictions Std            230.39604
Q Predictions Max            1229.949
Q Predictions Min            24.125881
V Predictions Mean           1049.3064
V Predictions Std            230.25757
V Predictions Max            1226.884
V Predictions Min            44.28644
Log Pis Mean                 -0.79246485
Log Pis Std                  2.4465835
Log Pis Max                  6.700923
Log Pis Min                  -6.5200834
Policy mu Mean               -0.030693248
Policy mu Std                0.581921
Policy mu Max                2.2988706
Policy mu Min                -2.1290052
Policy log std Mean          -0.9163103
Policy log std Std           0.24232358
Policy log std Max           0.033242047
Policy log std Min           -2.1085134
Z mean eval                  0.9440607
Z variance eval              0.024333552
total_rewards                [ 626.6698136  2809.64684357 2625.05668945 2269.44406213 2406.23047437
 2688.42987523 -144.97808098 2877.82125263 2605.55552915   13.89086264]
total_rewards_mean           1877.776732178541
total_rewards_std            1147.922537591863
total_rewards_max            2877.8212526321417
total_rewards_min            -144.97808097521056
Number of train steps total  300000
Number of env steps total    1502000
Number of rollouts total     0
Train Time (s)               44.066318505909294
(Previous) Eval Time (s)     23.412954179104418
Sample Time (s)              23.036919243633747
Epoch Time (s)               90.51619192864746
Total Train Time (s)         28911.693776912987
Epoch                        299
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:31:10.676940 UTC | [2020_01_10_11_29_18] Iteration #299 | Epoch Duration: 94.57829523086548
2020-01-10 19:31:10.677089 UTC | [2020_01_10_11_29_18] Iteration #299 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9434522
Z variance train             0.024414424
KL Divergence                20.397896
KL Loss                      2.0397897
QF Loss                      813.8803
VF Loss                      216.07274
Policy Loss                  -1047.899
Q Predictions Mean           1045.7559
Q Predictions Std            223.02147
Q Predictions Max            1244.464
Q Predictions Min            -57.362328
V Predictions Mean           1039.6616
V Predictions Std            220.24605
V Predictions Max            1241.9497
V Predictions Min            31.676231
Log Pis Mean                 -0.60231864
Log Pis Std                  2.4054272
Log Pis Max                  10.731195
Log Pis Min                  -8.858089
Policy mu Mean               -0.04249093
Policy mu Std                0.6090802
Policy mu Max                2.2416723
Policy mu Min                -2.324519
Policy log std Mean          -0.908524
Policy log std Std           0.25951144
Policy log std Max           0.05202484
Policy log std Min           -2.6588316
Z mean eval                  1.0025884
Z variance eval              0.017488342
total_rewards                [1731.25237425 2881.1372467  2800.9550409  1830.52356286 2764.81881977
  152.49242649  121.96614799 1175.30760211 2577.36015844 1010.93382139]
total_rewards_mean           1704.674720089124
total_rewards_std            1008.1501170225685
total_rewards_max            2881.1372466964717
total_rewards_min            121.96614799348647
Number of train steps total  301000
Number of env steps total    1507000
Number of rollouts total     0
Train Time (s)               44.44634633464739
(Previous) Eval Time (s)     27.474822886753827
Sample Time (s)              22.722334337886423
Epoch Time (s)               94.64350355928764
Total Train Time (s)         29007.781087910756
Epoch                        300
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:32:46.767339 UTC | [2020_01_10_11_29_18] Iteration #300 | Epoch Duration: 96.09013295173645
2020-01-10 19:32:46.767519 UTC | [2020_01_10_11_29_18] Iteration #300 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0022459
Z variance train             0.017444264
KL Divergence                20.88649
KL Loss                      2.088649
QF Loss                      620.4793
VF Loss                      837.4626
Policy Loss                  -1042.6085
Q Predictions Mean           1040.0565
Q Predictions Std            230.11412
Q Predictions Max            1212.3942
Q Predictions Min            7.639726
V Predictions Mean           1045.367
V Predictions Std            219.41544
V Predictions Max            1202.9906
V Predictions Min            35.357105
Log Pis Mean                 -0.15952083
Log Pis Std                  2.9465005
Log Pis Max                  13.334085
Log Pis Min                  -7.4220424
Policy mu Mean               0.016604804
Policy mu Std                0.62234783
Policy mu Max                3.1609344
Policy mu Min                -2.254821
Policy log std Mean          -0.9340806
Policy log std Std           0.27849197
Policy log std Max           -0.20870876
Policy log std Min           -2.8188996
Z mean eval                  0.94277745
Z variance eval              0.015714552
total_rewards                [  61.63184157 2824.82184524 2851.94431396    8.95495879  710.52941047
 2515.17619349 3001.53420346 2953.1737316   187.24891808 1592.97074453]
total_rewards_mean           1670.7986161196663
total_rewards_std            1238.362922872093
total_rewards_max            3001.5342034627965
total_rewards_min            8.954958786160596
Number of train steps total  302000
Number of env steps total    1512000
Number of rollouts total     0
Train Time (s)               44.83779642637819
(Previous) Eval Time (s)     28.92119137989357
Sample Time (s)              21.074035388417542
Epoch Time (s)               94.8330231946893
Total Train Time (s)         29099.16676620627
Epoch                        301
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:34:18.159653 UTC | [2020_01_10_11_29_18] Iteration #301 | Epoch Duration: 91.39199757575989
2020-01-10 19:34:18.159808 UTC | [2020_01_10_11_29_18] Iteration #301 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94305116
Z variance train             0.015712347
KL Divergence                20.868444
KL Loss                      2.0868444
QF Loss                      457.36612
VF Loss                      53.22149
Policy Loss                  -1090.9209
Q Predictions Mean           1089.8379
Q Predictions Std            132.7011
Q Predictions Max            1223.6542
Q Predictions Min            -79.79427
V Predictions Mean           1092.7579
V Predictions Std            131.37866
V Predictions Max            1217.5925
V Predictions Min            -17.27116
Log Pis Mean                 -0.39909503
Log Pis Std                  2.5325809
Log Pis Max                  9.685075
Log Pis Min                  -7.077222
Policy mu Mean               0.018662687
Policy mu Std                0.6203269
Policy mu Max                2.520713
Policy mu Min                -2.399032
Policy log std Mean          -0.9109874
Policy log std Std           0.20849119
Policy log std Max           -0.26896524
Policy log std Min           -2.0255556
Z mean eval                  0.9568409
Z variance eval              0.020825485
total_rewards                [2720.28934557 2771.63184192 2389.26067746  748.89950408  653.9825641
 2448.40502883 2245.89160714  412.33386066  833.73290503 2815.23288555]
total_rewards_mean           1803.9660220343765
total_rewards_std            952.1279124221735
total_rewards_max            2815.2328855519295
total_rewards_min            412.33386066076775
Number of train steps total  303000
Number of env steps total    1517000
Number of rollouts total     0
Train Time (s)               43.88804276101291
(Previous) Eval Time (s)     25.479925982188433
Sample Time (s)              23.101469777990133
Epoch Time (s)               92.46943852119148
Total Train Time (s)         29190.443925050087
Epoch                        302
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:35:49.438768 UTC | [2020_01_10_11_29_18] Iteration #302 | Epoch Duration: 91.2788360118866
2020-01-10 19:35:49.438908 UTC | [2020_01_10_11_29_18] Iteration #302 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95721734
Z variance train             0.020866215
KL Divergence                20.845617
KL Loss                      2.0845618
QF Loss                      631.763
VF Loss                      157.95662
Policy Loss                  -1044.1467
Q Predictions Mean           1043.7632
Q Predictions Std            240.08116
Q Predictions Max            1268.2783
Q Predictions Min            71.9105
V Predictions Mean           1052.3892
V Predictions Std            239.37337
V Predictions Max            1276.496
V Predictions Min            96.10809
Log Pis Mean                 -0.6200131
Log Pis Std                  2.7827547
Log Pis Max                  10.077234
Log Pis Min                  -9.874045
Policy mu Mean               -0.018083882
Policy mu Std                0.6171631
Policy mu Max                2.6032972
Policy mu Min                -2.1238184
Policy log std Mean          -0.8921112
Policy log std Std           0.26199162
Policy log std Max           -0.04631728
Policy log std Min           -2.3306544
Z mean eval                  0.954418
Z variance eval              0.016089179
total_rewards                [2636.42147474 2762.41091093 2807.66545599 2811.52156029 2686.22030743
 2813.14889857 2840.98101424 2757.29781608 1060.80796695 2733.34485826]
total_rewards_mean           2590.9820263470947
total_rewards_std            513.5494828913809
total_rewards_max            2840.981014242486
total_rewards_min            1060.8079669469282
Number of train steps total  304000
Number of env steps total    1522000
Number of rollouts total     0
Train Time (s)               43.75705430097878
(Previous) Eval Time (s)     24.289093339815736
Sample Time (s)              22.974579258356243
Epoch Time (s)               91.02072689915076
Total Train Time (s)         29289.884399313945
Epoch                        303
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:37:28.885790 UTC | [2020_01_10_11_29_18] Iteration #303 | Epoch Duration: 99.44674396514893
2020-01-10 19:37:28.886037 UTC | [2020_01_10_11_29_18] Iteration #303 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9547223
Z variance train             0.016096536
KL Divergence                21.20824
KL Loss                      2.120824
QF Loss                      645.57385
VF Loss                      137.27388
Policy Loss                  -1079.152
Q Predictions Mean           1079.9783
Q Predictions Std            179.22044
Q Predictions Max            1232.3127
Q Predictions Min            10.566164
V Predictions Mean           1075.4299
V Predictions Std            177.14604
V Predictions Max            1220.4312
V Predictions Min            3.762329
Log Pis Mean                 -0.24740112
Log Pis Std                  2.5078216
Log Pis Max                  8.593784
Log Pis Min                  -6.138863
Policy mu Mean               -0.0039940462
Policy mu Std                0.6116761
Policy mu Max                2.1119697
Policy mu Min                -2.1465256
Policy log std Mean          -0.94203365
Policy log std Std           0.22934324
Policy log std Max           -0.20849007
Policy log std Min           -2.159061
Z mean eval                  0.9720071
Z variance eval              0.012350747
total_rewards                [2784.91747439 1262.53882571  251.81112397 2383.88148101  587.28427867
 1146.65908905   59.93063301  983.54362552 2176.7477054  1826.88354806]
total_rewards_mean           1346.4197784779058
total_rewards_std            876.0148908635806
total_rewards_max            2784.9174743899766
total_rewards_min            59.93063300763697
Number of train steps total  305000
Number of env steps total    1527000
Number of rollouts total     0
Train Time (s)               43.91061662696302
(Previous) Eval Time (s)     32.71486452408135
Sample Time (s)              23.261619997676462
Epoch Time (s)               99.88710114872083
Total Train Time (s)         29375.732295649126
Epoch                        304
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:38:54.739524 UTC | [2020_01_10_11_29_18] Iteration #304 | Epoch Duration: 85.85327959060669
2020-01-10 19:38:54.739787 UTC | [2020_01_10_11_29_18] Iteration #304 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9705141
Z variance train             0.01235677
KL Divergence                22.010298
KL Loss                      2.2010298
QF Loss                      505.3835
VF Loss                      154.2025
Policy Loss                  -1062.8645
Q Predictions Mean           1061.5243
Q Predictions Std            208.26526
Q Predictions Max            1238.2377
Q Predictions Min            -0.15270895
V Predictions Mean           1059.5828
V Predictions Std            203.03278
V Predictions Max            1237.1404
V Predictions Min            91.959175
Log Pis Mean                 -0.37816197
Log Pis Std                  2.6175728
Log Pis Max                  11.556967
Log Pis Min                  -7.769243
Policy mu Mean               -0.08564901
Policy mu Std                0.5979876
Policy mu Max                2.2756279
Policy mu Min                -2.2783432
Policy log std Mean          -0.9123578
Policy log std Std           0.25269815
Policy log std Max           -0.17571098
Policy log std Min           -2.8463778
Z mean eval                  0.9956976
Z variance eval              0.009198903
total_rewards                [2941.37036101 2687.55349578  519.1010146  2709.52777915 2645.61168483
 2008.70342882 2878.32509868 -110.63561255 1320.84509967  327.05517602]
total_rewards_mean           1792.7457526028015
total_rewards_std            1119.3292561965927
total_rewards_max            2941.3703610147563
total_rewards_min            -110.63561254546785
Number of train steps total  306000
Number of env steps total    1532000
Number of rollouts total     0
Train Time (s)               44.05818648636341
(Previous) Eval Time (s)     18.680810189805925
Sample Time (s)              22.581548447720706
Epoch Time (s)               85.32054512389004
Total Train Time (s)         29469.338775161654
Epoch                        305
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:40:28.352249 UTC | [2020_01_10_11_29_18] Iteration #305 | Epoch Duration: 93.6122510433197
2020-01-10 19:40:28.352510 UTC | [2020_01_10_11_29_18] Iteration #305 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9956725
Z variance train             0.009193452
KL Divergence                22.931831
KL Loss                      2.293183
QF Loss                      611.10583
VF Loss                      142.62439
Policy Loss                  -1065.9965
Q Predictions Mean           1065.3484
Q Predictions Std            205.80165
Q Predictions Max            1261.512
Q Predictions Min            82.269905
V Predictions Mean           1062.1536
V Predictions Std            204.28996
V Predictions Max            1250.0372
V Predictions Min            107.863495
Log Pis Mean                 -0.50520843
Log Pis Std                  2.576617
Log Pis Max                  8.879834
Log Pis Min                  -6.8862104
Policy mu Mean               -0.024483945
Policy mu Std                0.6027392
Policy mu Max                2.1286917
Policy mu Min                -2.4490554
Policy log std Mean          -0.90712
Policy log std Std           0.24937129
Policy log std Max           -0.11405337
Policy log std Min           -2.415577
Z mean eval                  0.97843903
Z variance eval              0.021761587
total_rewards                [ 134.17714934 1533.14265431 1532.6560642  1863.99210385 2623.16891158
  656.35300435  356.90699182  357.99080277  383.980274   2412.00724055]
total_rewards_mean           1185.4375196768692
total_rewards_std            875.8986328095175
total_rewards_max            2623.1689115809922
total_rewards_min            134.17714934390844
Number of train steps total  307000
Number of env steps total    1537000
Number of rollouts total     0
Train Time (s)               43.69560321606696
(Previous) Eval Time (s)     26.972276703920215
Sample Time (s)              22.72680717287585
Epoch Time (s)               93.39468709286302
Total Train Time (s)         29552.0198371741
Epoch                        306
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:41:51.034790 UTC | [2020_01_10_11_29_18] Iteration #306 | Epoch Duration: 82.6821038722992
2020-01-10 19:41:51.034930 UTC | [2020_01_10_11_29_18] Iteration #306 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.977481
Z variance train             0.021802727
KL Divergence                21.713316
KL Loss                      2.1713316
QF Loss                      693.10254
VF Loss                      104.967735
Policy Loss                  -1055.509
Q Predictions Mean           1059.0254
Q Predictions Std            234.90823
Q Predictions Max            1298.4369
Q Predictions Min            52.288906
V Predictions Mean           1054.7292
V Predictions Std            234.75612
V Predictions Max            1300.9841
V Predictions Min            59.019886
Log Pis Mean                 -0.73855895
Log Pis Std                  2.5194485
Log Pis Max                  7.7234516
Log Pis Min                  -7.7693796
Policy mu Mean               -0.0039489926
Policy mu Std                0.5749429
Policy mu Max                2.1387997
Policy mu Min                -2.119569
Policy log std Mean          -0.90010566
Policy log std Std           0.24189945
Policy log std Max           -0.08306348
Policy log std Min           -2.0607848
Z mean eval                  0.9407756
Z variance eval              0.01717539
total_rewards                [  50.93924812 2794.91217125  395.3161938  1982.35563061  466.84193587
   39.94341272  147.7741652  2289.77002014  752.34473282 2724.49107929]
total_rewards_mean           1164.4688589825776
total_rewards_std            1086.9018084610602
total_rewards_max            2794.9121712515407
total_rewards_min            39.9434127241168
Number of train steps total  308000
Number of env steps total    1542000
Number of rollouts total     0
Train Time (s)               43.81691849604249
(Previous) Eval Time (s)     16.259464380331337
Sample Time (s)              23.45813668752089
Epoch Time (s)               83.53451956389472
Total Train Time (s)         29644.00657941168
Epoch                        307
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:43:23.023648 UTC | [2020_01_10_11_29_18] Iteration #307 | Epoch Duration: 91.98861527442932
2020-01-10 19:43:23.023789 UTC | [2020_01_10_11_29_18] Iteration #307 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94007987
Z variance train             0.017191347
KL Divergence                21.611177
KL Loss                      2.1611178
QF Loss                      475.29245
VF Loss                      125.28495
Policy Loss                  -1074.1438
Q Predictions Mean           1075.1409
Q Predictions Std            213.45909
Q Predictions Max            1250.4434
Q Predictions Min            55.900753
V Predictions Mean           1074.0619
V Predictions Std            214.80925
V Predictions Max            1255.5293
V Predictions Min            53.733017
Log Pis Mean                 -0.33089745
Log Pis Std                  2.3309612
Log Pis Max                  6.762827
Log Pis Min                  -6.349496
Policy mu Mean               0.011807976
Policy mu Std                0.5869446
Policy mu Max                1.9526801
Policy mu Min                -2.035536
Policy log std Mean          -0.9121442
Policy log std Std           0.23721291
Policy log std Max           0.0009418726
Policy log std Min           -2.1437883
Z mean eval                  0.97192556
Z variance eval              0.013321882
total_rewards                [2938.97598096 2976.76521333 2838.00236114 1144.83577409 2758.00589868
 3005.35629593 1672.65729947 2881.83067446 3031.12163057  250.75088441]
total_rewards_mean           2349.830201302937
total_rewards_std            929.4442091669544
total_rewards_max            3031.121630569006
total_rewards_min            250.75088440757625
Number of train steps total  309000
Number of env steps total    1547000
Number of rollouts total     0
Train Time (s)               43.71080312691629
(Previous) Eval Time (s)     24.713321133051068
Sample Time (s)              22.651743502821773
Epoch Time (s)               91.07586776278913
Total Train Time (s)         29736.752102782484
Epoch                        308
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:44:55.772530 UTC | [2020_01_10_11_29_18] Iteration #308 | Epoch Duration: 92.74863147735596
2020-01-10 19:44:55.772703 UTC | [2020_01_10_11_29_18] Iteration #308 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9717846
Z variance train             0.01331559
KL Divergence                21.753946
KL Loss                      2.1753948
QF Loss                      4405.287
VF Loss                      521.27716
Policy Loss                  -1067.8505
Q Predictions Mean           1068.5426
Q Predictions Std            196.57436
Q Predictions Max            1279.75
Q Predictions Min            85.56709
V Predictions Mean           1073.9579
V Predictions Std            191.60635
V Predictions Max            1265.9758
V Predictions Min            68.63926
Log Pis Mean                 -0.24399388
Log Pis Std                  3.041527
Log Pis Max                  16.450819
Log Pis Min                  -7.1741033
Policy mu Mean               -0.020989273
Policy mu Std                0.5993079
Policy mu Max                2.7699997
Policy mu Min                -3.0685432
Policy log std Mean          -0.9674709
Policy log std Std           0.2696242
Policy log std Max           -0.013686717
Policy log std Min           -2.5185826
Z mean eval                  1.0022603
Z variance eval              0.012503097
total_rewards                [2860.93115222  161.4709672  1389.09761693 2877.53281819 2122.53206684
 2759.63207311 2637.03655181 2996.65101403   39.4216803  2680.71168515]
total_rewards_mean           2052.5017625785526
total_rewards_std            1074.0350191309615
total_rewards_max            2996.651014029875
total_rewards_min            39.42168030208686
Number of train steps total  310000
Number of env steps total    1552000
Number of rollouts total     0
Train Time (s)               44.04533897526562
(Previous) Eval Time (s)     26.385841130744666
Sample Time (s)              22.545595173723996
Epoch Time (s)               92.97677527973428
Total Train Time (s)         29836.530642205384
Epoch                        309
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:46:35.561890 UTC | [2020_01_10_11_29_18] Iteration #309 | Epoch Duration: 99.78905510902405
2020-01-10 19:46:35.562062 UTC | [2020_01_10_11_29_18] Iteration #309 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9984986
Z variance train             0.012480041
KL Divergence                21.717281
KL Loss                      2.1717281
QF Loss                      728.1143
VF Loss                      247.4046
Policy Loss                  -1085.829
Q Predictions Mean           1084.3494
Q Predictions Std            198.93457
Q Predictions Max            1232.2217
Q Predictions Min            26.367702
V Predictions Mean           1094.5193
V Predictions Std            196.99382
V Predictions Max            1249.3585
V Predictions Min            16.629774
Log Pis Mean                 -0.28043944
Log Pis Std                  2.5720556
Log Pis Max                  9.275747
Log Pis Min                  -7.618055
Policy mu Mean               0.012139505
Policy mu Std                0.5993518
Policy mu Max                2.7721574
Policy mu Min                -2.371431
Policy log std Mean          -0.9346015
Policy log std Std           0.25464928
Policy log std Max           -0.07262391
Policy log std Min           -2.1987052
Z mean eval                  0.94062054
Z variance eval              0.015127766
total_rewards                [2905.26155655 2466.13235087 1611.2597421  2832.4072019  2830.94651676
 1035.5961212   354.94334956 2909.56194127  453.46663585 1115.53185206]
total_rewards_mean           1851.5107268113534
total_rewards_std            999.4207604480912
total_rewards_max            2909.561941268831
total_rewards_min            354.94334955894544
Number of train steps total  311000
Number of env steps total    1557000
Number of rollouts total     0
Train Time (s)               44.37677195016295
(Previous) Eval Time (s)     33.197892035357654
Sample Time (s)              22.454552985262126
Epoch Time (s)               100.02921697078273
Total Train Time (s)         29931.39625697583
Epoch                        310
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:48:10.433651 UTC | [2020_01_10_11_29_18] Iteration #310 | Epoch Duration: 94.87146186828613
2020-01-10 19:48:10.433793 UTC | [2020_01_10_11_29_18] Iteration #310 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94015396
Z variance train             0.015094797
KL Divergence                20.982288
KL Loss                      2.098229
QF Loss                      708.7653
VF Loss                      144.63582
Policy Loss                  -1074.4102
Q Predictions Mean           1072.6382
Q Predictions Std            183.28745
Q Predictions Max            1257.6849
Q Predictions Min            113.97964
V Predictions Mean           1077.8474
V Predictions Std            181.1321
V Predictions Max            1246.8365
V Predictions Min            119.6179
Log Pis Mean                 -0.32936272
Log Pis Std                  2.6177967
Log Pis Max                  14.330069
Log Pis Min                  -7.582866
Policy mu Mean               -0.013461563
Policy mu Std                0.5970407
Policy mu Max                2.552043
Policy mu Min                -2.6046407
Policy log std Mean          -0.93851805
Policy log std Std           0.24001798
Policy log std Max           -0.009656191
Policy log std Min           -2.1502838
Z mean eval                  0.96637094
Z variance eval              0.02093311
total_rewards                [ 137.32623576  223.33444497 2105.88968712 1760.1156836  3029.66750869
 1863.87491488  368.75106421  -34.53975549 2238.55737889   83.26155838]
total_rewards_mean           1177.6238721016864
total_rewards_std            1074.3226890087085
total_rewards_max            3029.667508694603
total_rewards_min            -34.539755489510696
Number of train steps total  312000
Number of env steps total    1562000
Number of rollouts total     0
Train Time (s)               44.70703800721094
(Previous) Eval Time (s)     28.03990739583969
Sample Time (s)              22.975892562884837
Epoch Time (s)               95.72283796593547
Total Train Time (s)         30016.57133524958
Epoch                        311
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:49:35.611462 UTC | [2020_01_10_11_29_18] Iteration #311 | Epoch Duration: 85.17756652832031
2020-01-10 19:49:35.611604 UTC | [2020_01_10_11_29_18] Iteration #311 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96547604
Z variance train             0.020951817
KL Divergence                20.430996
KL Loss                      2.0430996
QF Loss                      485.9632
VF Loss                      99.00439
Policy Loss                  -1082.9658
Q Predictions Mean           1082.1454
Q Predictions Std            216.4383
Q Predictions Max            1240.2958
Q Predictions Min            58.639984
V Predictions Mean           1081.9202
V Predictions Std            215.25844
V Predictions Max            1237.7476
V Predictions Min            66.21677
Log Pis Mean                 -0.6203344
Log Pis Std                  2.5244446
Log Pis Max                  7.574913
Log Pis Min                  -7.5646954
Policy mu Mean               -0.022613022
Policy mu Std                0.6077754
Policy mu Max                2.286029
Policy mu Min                -2.391612
Policy log std Mean          -0.9127894
Policy log std Std           0.24344322
Policy log std Max           -0.24531657
Policy log std Min           -2.2902055
Z mean eval                  0.96815956
Z variance eval              0.011789745
total_rewards                [1335.46953685 2694.90842934  994.98058899   25.7155856   377.75570856
   50.4076292  1271.37138264  471.2483745   660.2133827   588.74188193]
total_rewards_mean           847.0812500327736
total_rewards_std            750.1593690926442
total_rewards_max            2694.908429340408
total_rewards_min            25.715585602936898
Number of train steps total  313000
Number of env steps total    1567000
Number of rollouts total     0
Train Time (s)               44.81435535894707
(Previous) Eval Time (s)     17.49438887089491
Sample Time (s)              22.831020392477512
Epoch Time (s)               85.13976462231949
Total Train Time (s)         30105.926383241545
Epoch                        312
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:51:04.969650 UTC | [2020_01_10_11_29_18] Iteration #312 | Epoch Duration: 89.3579363822937
2020-01-10 19:51:04.969812 UTC | [2020_01_10_11_29_18] Iteration #312 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96771824
Z variance train             0.011799028
KL Divergence                21.215324
KL Loss                      2.1215324
QF Loss                      580.3036
VF Loss                      280.9496
Policy Loss                  -1093.2108
Q Predictions Mean           1088.3545
Q Predictions Std            176.5752
Q Predictions Max            1242.6433
Q Predictions Min            73.36576
V Predictions Mean           1081.897
V Predictions Std            174.91983
V Predictions Max            1222.163
V Predictions Min            78.231895
Log Pis Mean                 -0.20689341
Log Pis Std                  2.623849
Log Pis Max                  9.482229
Log Pis Min                  -6.777048
Policy mu Mean               -0.007913331
Policy mu Std                0.62635756
Policy mu Max                2.1679938
Policy mu Min                -2.3091202
Policy log std Mean          -0.9228833
Policy log std Std           0.25080758
Policy log std Max           -0.21641201
Policy log std Min           -2.1236563
Z mean eval                  0.95382994
Z variance eval              0.013796431
total_rewards                [2997.99645249 3150.83244813 3120.66504581 3051.3223013  3019.2821102
 3015.99160272 2865.84291388 2872.16255035 1467.43371009 2901.98235181]
total_rewards_mean           2846.3511486771763
total_rewards_std            468.7433987931681
total_rewards_max            3150.8324481268405
total_rewards_min            1467.4337100897037
Number of train steps total  314000
Number of env steps total    1572000
Number of rollouts total     0
Train Time (s)               42.83365858672187
(Previous) Eval Time (s)     21.712316296063364
Sample Time (s)              20.71752063371241
Epoch Time (s)               85.26349551649764
Total Train Time (s)         30201.799417000264
Epoch                        313
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:52:40.844799 UTC | [2020_01_10_11_29_18] Iteration #313 | Epoch Duration: 95.8748676776886
2020-01-10 19:52:40.844939 UTC | [2020_01_10_11_29_18] Iteration #313 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95142794
Z variance train             0.01377283
KL Divergence                21.1836
KL Loss                      2.11836
QF Loss                      911.0868
VF Loss                      317.11154
Policy Loss                  -1056.5792
Q Predictions Mean           1054.5978
Q Predictions Std            249.323
Q Predictions Max            1235.656
Q Predictions Min            5.623929
V Predictions Mean           1068.5427
V Predictions Std            241.54634
V Predictions Max            1240.205
V Predictions Min            26.56966
Log Pis Mean                 -0.4320609
Log Pis Std                  2.6392815
Log Pis Max                  13.443207
Log Pis Min                  -7.8004813
Policy mu Mean               -0.015206229
Policy mu Std                0.5871172
Policy mu Max                1.9863371
Policy mu Min                -2.4012527
Policy log std Mean          -0.94309664
Policy log std Std           0.27782503
Policy log std Max           0.11643058
Policy log std Min           -3.0233727
Z mean eval                  0.942087
Z variance eval              0.0107215475
total_rewards                [3056.59837162 2822.86740634  562.01473019 2539.04390465 3122.58517374
 2771.92450591 2282.95568625  288.41075056 2044.3002424  3100.01588506]
total_rewards_mean           2259.0716656706254
total_rewards_std            977.6688410837361
total_rewards_max            3122.585173735261
total_rewards_min            288.4107505608114
Number of train steps total  315000
Number of env steps total    1577000
Number of rollouts total     0
Train Time (s)               44.41999366693199
(Previous) Eval Time (s)     32.323468706104904
Sample Time (s)              22.92439979314804
Epoch Time (s)               99.66786216618493
Total Train Time (s)         30297.164398371708
Epoch                        314
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:54:16.215570 UTC | [2020_01_10_11_29_18] Iteration #314 | Epoch Duration: 95.37051653862
2020-01-10 19:54:16.215750 UTC | [2020_01_10_11_29_18] Iteration #314 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.941899
Z variance train             0.010703572
KL Divergence                20.864002
KL Loss                      2.0864003
QF Loss                      500.1386
VF Loss                      182.95409
Policy Loss                  -1075.1117
Q Predictions Mean           1073.3003
Q Predictions Std            249.6586
Q Predictions Max            1258.995
Q Predictions Min            -29.161547
V Predictions Mean           1080.5973
V Predictions Std            246.88861
V Predictions Max            1271.399
V Predictions Min            -0.5324557
Log Pis Mean                 -0.6863598
Log Pis Std                  2.7171035
Log Pis Max                  10.15629
Log Pis Min                  -10.154734
Policy mu Mean               0.0023843618
Policy mu Std                0.58184284
Policy mu Max                2.383102
Policy mu Min                -2.0563014
Policy log std Mean          -0.9283067
Policy log std Std           0.2605751
Policy log std Max           -0.07093859
Policy log std Min           -2.1767664
Z mean eval                  0.9703738
Z variance eval              0.0071105673
total_rewards                [2684.40273192 2775.99936572 2657.82743104 2861.63266127 2920.92551746
 1747.16731934 2857.81127771 2786.7513698  2875.82223304 2716.89926129]
total_rewards_mean           2688.5239168594235
total_rewards_std            324.48933111558665
total_rewards_max            2920.9255174607533
total_rewards_min            1747.1673193397146
Number of train steps total  316000
Number of env steps total    1582000
Number of rollouts total     0
Train Time (s)               44.095317034982145
(Previous) Eval Time (s)     28.02587587805465
Sample Time (s)              22.491225216537714
Epoch Time (s)               94.61241812957451
Total Train Time (s)         30394.792695014272
Epoch                        315
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:55:53.847886 UTC | [2020_01_10_11_29_18] Iteration #315 | Epoch Duration: 97.63200211524963
2020-01-10 19:55:53.848071 UTC | [2020_01_10_11_29_18] Iteration #315 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9698249
Z variance train             0.0071258238
KL Divergence                21.855389
KL Loss                      2.185539
QF Loss                      953.73724
VF Loss                      216.83229
Policy Loss                  -1096.0728
Q Predictions Mean           1096.5566
Q Predictions Std            191.26929
Q Predictions Max            1261.436
Q Predictions Min            37.981518
V Predictions Mean           1092.395
V Predictions Std            195.04695
V Predictions Max            1261.1351
V Predictions Min            30.863274
Log Pis Mean                 -0.2886577
Log Pis Std                  2.5795028
Log Pis Max                  13.113292
Log Pis Min                  -7.5162077
Policy mu Mean               0.031104691
Policy mu Std                0.6187562
Policy mu Max                2.2117097
Policy mu Min                -1.8217299
Policy log std Mean          -0.9423628
Policy log std Std           0.2639732
Policy log std Max           -0.18279904
Policy log std Min           -2.752563
Z mean eval                  0.93995476
Z variance eval              0.0129297525
total_rewards                [ 848.23038323 2477.11832449  727.3216047  2855.29030882 2789.48741004
 2742.77452523 2773.29070702 1118.42378373 3009.95558381 2832.05875129]
total_rewards_mean           2217.395138235735
total_rewards_std            877.2304172860729
total_rewards_max            3009.955583812932
total_rewards_min            727.3216046990292
Number of train steps total  317000
Number of env steps total    1587000
Number of rollouts total     0
Train Time (s)               43.65974748786539
(Previous) Eval Time (s)     31.045177564024925
Sample Time (s)              20.813923476729542
Epoch Time (s)               95.51884852861986
Total Train Time (s)         30491.864453041926
Epoch                        316
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:57:30.922018 UTC | [2020_01_10_11_29_18] Iteration #316 | Epoch Duration: 97.07379031181335
2020-01-10 19:57:30.922151 UTC | [2020_01_10_11_29_18] Iteration #316 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.940221
Z variance train             0.012930641
KL Divergence                20.96249
KL Loss                      2.096249
QF Loss                      869.0692
VF Loss                      159.11708
Policy Loss                  -1076.2079
Q Predictions Mean           1076.9982
Q Predictions Std            214.30276
Q Predictions Max            1262.3701
Q Predictions Min            13.114408
V Predictions Mean           1072.7781
V Predictions Std            212.45233
V Predictions Max            1258.2196
V Predictions Min            31.609066
Log Pis Mean                 -0.6999935
Log Pis Std                  2.4881997
Log Pis Max                  9.712428
Log Pis Min                  -7.7326527
Policy mu Mean               -0.026441969
Policy mu Std                0.5548158
Policy mu Max                2.095515
Policy mu Min                -2.1467674
Policy log std Mean          -0.92837036
Policy log std Std           0.24608734
Policy log std Max           -0.10753405
Policy log std Min           -2.3289552
Z mean eval                  0.9389385
Z variance eval              0.01763761
total_rewards                [2891.28087355 2698.19764214 1856.95892443 2876.93841199 -213.18172727
 2843.86414046  462.95820181 1011.48066047 2965.20497176 1634.3287614 ]
total_rewards_mean           1902.803086072515
total_rewards_std            1095.0869820134192
total_rewards_max            2965.2049717560094
total_rewards_min            -213.18172727350174
Number of train steps total  318000
Number of env steps total    1592000
Number of rollouts total     0
Train Time (s)               44.4945005918853
(Previous) Eval Time (s)     32.5998784978874
Sample Time (s)              23.377465839497745
Epoch Time (s)               100.47184492927045
Total Train Time (s)         30585.757947596256
Epoch                        317
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:59:04.825139 UTC | [2020_01_10_11_29_18] Iteration #317 | Epoch Duration: 93.90285563468933
2020-01-10 19:59:04.825382 UTC | [2020_01_10_11_29_18] Iteration #317 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93809336
Z variance train             0.01762459
KL Divergence                20.68261
KL Loss                      2.068261
QF Loss                      481.8992
VF Loss                      130.68137
Policy Loss                  -1088.7478
Q Predictions Mean           1087.2018
Q Predictions Std            205.2811
Q Predictions Max            1258.9958
Q Predictions Min            62.007088
V Predictions Mean           1091.8567
V Predictions Std            205.69168
V Predictions Max            1265.8384
V Predictions Min            -11.329524
Log Pis Mean                 -0.5714066
Log Pis Std                  2.5342097
Log Pis Max                  7.1128283
Log Pis Min                  -7.902711
Policy mu Mean               0.002079735
Policy mu Std                0.5687661
Policy mu Max                2.3769503
Policy mu Min                -2.0258536
Policy log std Mean          -0.9532124
Policy log std Std           0.23706172
Policy log std Max           -0.16699809
Policy log std Min           -1.989913
Z mean eval                  0.9642474
Z variance eval              0.017164681
total_rewards                [2904.4491407  2453.68254516  116.92008035 2917.90743053 2564.66488867
 2866.84024888 1262.6371304  3110.90996716 2990.69947586 3013.87037613]
total_rewards_mean           2420.2581283828413
total_rewards_std            922.1568842240868
total_rewards_max            3110.9099671582335
total_rewards_min            116.92008034937099
Number of train steps total  319000
Number of env steps total    1597000
Number of rollouts total     0
Train Time (s)               43.847409774083644
(Previous) Eval Time (s)     26.030638070311397
Sample Time (s)              23.095287471543998
Epoch Time (s)               92.97333531593904
Total Train Time (s)         30684.309269125108
Epoch                        318
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:00:43.376247 UTC | [2020_01_10_11_29_18] Iteration #318 | Epoch Duration: 98.5506682395935
2020-01-10 20:00:43.376474 UTC | [2020_01_10_11_29_18] Iteration #318 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96337575
Z variance train             0.017193183
KL Divergence                20.24545
KL Loss                      2.024545
QF Loss                      983.2722
VF Loss                      170.25363
Policy Loss                  -1092.5209
Q Predictions Mean           1093.3765
Q Predictions Std            220.26202
Q Predictions Max            1264.4999
Q Predictions Min            31.795467
V Predictions Mean           1097.1166
V Predictions Std            216.62697
V Predictions Max            1277.946
V Predictions Min            45.291134
Log Pis Mean                 -0.6531716
Log Pis Std                  2.4027276
Log Pis Max                  7.0344343
Log Pis Min                  -6.9327326
Policy mu Mean               0.033257026
Policy mu Std                0.5852027
Policy mu Max                1.9882848
Policy mu Min                -2.265668
Policy log std Mean          -0.9245341
Policy log std Std           0.22728945
Policy log std Max           -0.16597724
Policy log std Min           -1.8383106
Z mean eval                  0.97049046
Z variance eval              0.026537675
total_rewards                [ 392.24885623 3020.46924729  559.40156418 1601.53025726 1064.96983096
 2884.85078601 2301.88305422 2715.28360594  556.94716217 1166.80888544]
total_rewards_mean           1626.439324970126
total_rewards_std            974.7544668711739
total_rewards_max            3020.4692472895968
total_rewards_min            392.2488562258075
Number of train steps total  320000
Number of env steps total    1602000
Number of rollouts total     0
Train Time (s)               44.12861223705113
(Previous) Eval Time (s)     31.60772897163406
Sample Time (s)              21.198113317601383
Epoch Time (s)               96.93445452628657
Total Train Time (s)         30771.60596774891
Epoch                        319
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:02:10.680531 UTC | [2020_01_10_11_29_18] Iteration #319 | Epoch Duration: 87.30390357971191
2020-01-10 20:02:10.680673 UTC | [2020_01_10_11_29_18] Iteration #319 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97005194
Z variance train             0.026527232
KL Divergence                20.638227
KL Loss                      2.0638227
QF Loss                      661.8531
VF Loss                      173.8129
Policy Loss                  -1126.1816
Q Predictions Mean           1125.0457
Q Predictions Std            117.50967
Q Predictions Max            1263.7759
Q Predictions Min            127.085396
V Predictions Mean           1132.959
V Predictions Std            112.032326
V Predictions Max            1275.6433
V Predictions Min            126.257774
Log Pis Mean                 -0.26882058
Log Pis Std                  2.5091543
Log Pis Max                  9.884491
Log Pis Min                  -7.8989677
Policy mu Mean               0.011654999
Policy mu Std                0.6080858
Policy mu Max                2.3606353
Policy mu Min                -2.3051574
Policy log std Mean          -0.93833256
Policy log std Std           0.24257793
Policy log std Max           -0.18376309
Policy log std Min           -2.1710424
Z mean eval                  0.97227633
Z variance eval              0.0249446
total_rewards                [ 956.06501977 -148.32969518 1079.98261532 1242.83683411 2148.31064185
  825.95128792 2918.40330008 2812.3504659   187.20132371 1215.34210926]
total_rewards_mean           1323.8113902740022
total_rewards_std            967.3794386347048
total_rewards_max            2918.4033000802465
total_rewards_min            -148.32969518418923
Number of train steps total  321000
Number of env steps total    1607000
Number of rollouts total     0
Train Time (s)               43.64421787811443
(Previous) Eval Time (s)     21.976961490232497
Sample Time (s)              22.366133373230696
Epoch Time (s)               87.98731274157763
Total Train Time (s)         30862.429560353048
Epoch                        320
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:03:41.505950 UTC | [2020_01_10_11_29_18] Iteration #320 | Epoch Duration: 90.82517576217651
2020-01-10 20:03:41.506089 UTC | [2020_01_10_11_29_18] Iteration #320 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97007877
Z variance train             0.02495832
KL Divergence                20.78238
KL Loss                      2.078238
QF Loss                      812.86475
VF Loss                      178.51134
Policy Loss                  -1109.0952
Q Predictions Mean           1108.7643
Q Predictions Std            179.06555
Q Predictions Max            1294.6149
Q Predictions Min            107.12703
V Predictions Mean           1101.2666
V Predictions Std            175.01788
V Predictions Max            1285.1635
V Predictions Min            109.33272
Log Pis Mean                 -0.14632472
Log Pis Std                  2.6874464
Log Pis Max                  7.428113
Log Pis Min                  -8.565176
Policy mu Mean               -0.0085323565
Policy mu Std                0.6210446
Policy mu Max                2.2448387
Policy mu Min                -2.0728405
Policy log std Mean          -0.9327803
Policy log std Std           0.26031974
Policy log std Max           0.2053594
Policy log std Min           -2.152351
Z mean eval                  0.9610387
Z variance eval              0.02162896
total_rewards                [ -36.42775748  413.26683702  300.48475936 3015.07571648 3187.67543755
 3140.40114978 2643.64565897 3047.35712208 1249.18143253 1927.92824226]
total_rewards_mean           1888.8588598539598
total_rewards_std            1234.9580817720398
total_rewards_max            3187.675437546477
total_rewards_min            -36.42775747923579
Number of train steps total  322000
Number of env steps total    1612000
Number of rollouts total     0
Train Time (s)               43.53695178218186
(Previous) Eval Time (s)     24.814583099912852
Sample Time (s)              22.212048443965614
Epoch Time (s)               90.56358332606032
Total Train Time (s)         30951.441523661837
Epoch                        321
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:05:10.521720 UTC | [2020_01_10_11_29_18] Iteration #321 | Epoch Duration: 89.0155189037323
2020-01-10 20:05:10.521894 UTC | [2020_01_10_11_29_18] Iteration #321 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9609402
Z variance train             0.021603364
KL Divergence                19.770565
KL Loss                      1.9770565
QF Loss                      549.6636
VF Loss                      158.06827
Policy Loss                  -1099.0231
Q Predictions Mean           1096.0714
Q Predictions Std            206.66394
Q Predictions Max            1282.5464
Q Predictions Min            34.069817
V Predictions Mean           1099.9717
V Predictions Std            205.51306
V Predictions Max            1279.2307
V Predictions Min            12.600768
Log Pis Mean                 -0.32088947
Log Pis Std                  2.6047864
Log Pis Max                  9.709647
Log Pis Min                  -9.308361
Policy mu Mean               -0.010177429
Policy mu Std                0.5894469
Policy mu Max                2.2237895
Policy mu Min                -2.08964
Policy log std Mean          -0.9536638
Policy log std Std           0.23699155
Policy log std Max           -0.036358953
Policy log std Min           -2.0088437
Z mean eval                  0.97802734
Z variance eval              0.024129951
total_rewards                [ 923.24507558  651.25742696 2969.33882387  426.47506138 1164.35582728
 2989.08691398  275.23115538  131.0426614   663.84414754 3006.23199631]
total_rewards_mean           1320.0109089670152
total_rewards_std            1127.4969199259133
total_rewards_max            3006.2319963066275
total_rewards_min            131.04266140013524
Number of train steps total  323000
Number of env steps total    1617000
Number of rollouts total     0
Train Time (s)               43.99099900107831
(Previous) Eval Time (s)     23.26626699184999
Sample Time (s)              23.346697674132884
Epoch Time (s)               90.60396366706118
Total Train Time (s)         31037.242179887835
Epoch                        322
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:06:36.330110 UTC | [2020_01_10_11_29_18] Iteration #322 | Epoch Duration: 85.8080461025238
2020-01-10 20:06:36.330405 UTC | [2020_01_10_11_29_18] Iteration #322 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97768104
Z variance train             0.024202487
KL Divergence                20.7379
KL Loss                      2.07379
QF Loss                      539.5482
VF Loss                      138.85692
Policy Loss                  -1091.1403
Q Predictions Mean           1089.6176
Q Predictions Std            245.55466
Q Predictions Max            1303.9235
Q Predictions Min            14.480777
V Predictions Mean           1087.946
V Predictions Std            244.35245
V Predictions Max            1287.5411
V Predictions Min            26.637516
Log Pis Mean                 -0.31723052
Log Pis Std                  2.5598507
Log Pis Max                  7.8009977
Log Pis Min                  -8.63489
Policy mu Mean               -0.035758767
Policy mu Std                0.6183505
Policy mu Max                1.9425372
Policy mu Min                -2.2353675
Policy log std Mean          -0.9005891
Policy log std Std           0.24213158
Policy log std Max           -0.20897198
Policy log std Min           -2.2521977
Z mean eval                  0.9775419
Z variance eval              0.023391804
total_rewards                [2898.29304155 2768.24592208  264.86688634 2839.33510332 1170.66776533
 2939.40637772   83.76452905 2565.27122478  541.25532225 1079.94678233]
total_rewards_mean           1715.1052954746417
total_rewards_std            1132.9983579098755
total_rewards_max            2939.4063777224756
total_rewards_min            83.76452905429628
Number of train steps total  324000
Number of env steps total    1622000
Number of rollouts total     0
Train Time (s)               43.77578038396314
(Previous) Eval Time (s)     18.470066619105637
Sample Time (s)              22.865920587442815
Epoch Time (s)               85.11176759051159
Total Train Time (s)         31130.97945724707
Epoch                        323
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:08:10.072453 UTC | [2020_01_10_11_29_18] Iteration #323 | Epoch Duration: 93.74183320999146
2020-01-10 20:08:10.072642 UTC | [2020_01_10_11_29_18] Iteration #323 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98516977
Z variance train             0.023499865
KL Divergence                20.91073
KL Loss                      2.091073
QF Loss                      458.32037
VF Loss                      224.53001
Policy Loss                  -1127.4736
Q Predictions Mean           1128.9171
Q Predictions Std            121.72097
Q Predictions Max            1286.0151
Q Predictions Min            48.476917
V Predictions Mean           1139.1965
V Predictions Std            122.09335
V Predictions Max            1299.8042
V Predictions Min            74.12706
Log Pis Mean                 -0.5684232
Log Pis Std                  2.5101454
Log Pis Max                  8.318398
Log Pis Min                  -13.091598
Policy mu Mean               -0.016600452
Policy mu Std                0.5711788
Policy mu Max                2.3859856
Policy mu Min                -2.074955
Policy log std Mean          -0.9682928
Policy log std Std           0.2243478
Policy log std Max           -0.35575652
Policy log std Min           -2.4987426
Z mean eval                  1.0161831
Z variance eval              0.014199285
total_rewards                [2916.72804808 2858.66425525 2774.26659948 2508.56604137  586.27840307
 2833.99523589 2812.20272872   15.75251538 2908.70163742  478.58865087]
total_rewards_mean           2069.3744115540962
total_rewards_std            1132.218796526669
total_rewards_max            2916.7280480750765
total_rewards_min            15.75251538025664
Number of train steps total  325000
Number of env steps total    1627000
Number of rollouts total     0
Train Time (s)               43.48069679224864
(Previous) Eval Time (s)     27.09990515327081
Sample Time (s)              22.515300855971873
Epoch Time (s)               93.09590280149132
Total Train Time (s)         31228.461902882904
Epoch                        324
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:09:47.558344 UTC | [2020_01_10_11_29_18] Iteration #324 | Epoch Duration: 97.48556303977966
2020-01-10 20:09:47.558518 UTC | [2020_01_10_11_29_18] Iteration #324 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0189573
Z variance train             0.014241645
KL Divergence                20.920721
KL Loss                      2.0920722
QF Loss                      4091.981
VF Loss                      557.4261
Policy Loss                  -1094.8828
Q Predictions Mean           1092.6287
Q Predictions Std            259.44934
Q Predictions Max            1284.436
Q Predictions Min            20.054895
V Predictions Mean           1095.6691
V Predictions Std            256.94574
V Predictions Max            1286.8917
V Predictions Min            51.903545
Log Pis Mean                 -0.33909225
Log Pis Std                  2.900722
Log Pis Max                  14.075953
Log Pis Min                  -7.9015436
Policy mu Mean               0.060142294
Policy mu Std                0.62334436
Policy mu Max                2.2572634
Policy mu Min                -3.2286608
Policy log std Mean          -0.9222854
Policy log std Std           0.276463
Policy log std Max           -0.12637264
Policy log std Min           -2.8909137
Z mean eval                  0.9585846
Z variance eval              0.018805427
total_rewards                [2922.6123154   576.55233472 2807.87744143 1977.99828188 1230.7153574
 2061.0212068  2908.68404828 2830.39795255 2981.4862675  2992.93040681]
total_rewards_mean           2329.0275612776686
total_rewards_std            806.721228788365
total_rewards_max            2992.9304068076585
total_rewards_min            576.5523347175645
Number of train steps total  326000
Number of env steps total    1632000
Number of rollouts total     0
Train Time (s)               44.1054066689685
(Previous) Eval Time (s)     31.489307966083288
Sample Time (s)              23.213098142296076
Epoch Time (s)               98.80781277734786
Total Train Time (s)         31329.89549373975
Epoch                        325
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:11:28.994642 UTC | [2020_01_10_11_29_18] Iteration #325 | Epoch Duration: 101.43599724769592
2020-01-10 20:11:28.994776 UTC | [2020_01_10_11_29_18] Iteration #325 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95776176
Z variance train             0.018806612
KL Divergence                20.776613
KL Loss                      2.0776613
QF Loss                      1351.8721
VF Loss                      151.40625
Policy Loss                  -1113.9755
Q Predictions Mean           1113.1459
Q Predictions Std            231.10275
Q Predictions Max            1320.8694
Q Predictions Min            54.64061
V Predictions Mean           1105.5466
V Predictions Std            230.52522
V Predictions Max            1303.8838
V Predictions Min            51.089005
Log Pis Mean                 -0.3039251
Log Pis Std                  2.9309497
Log Pis Max                  15.324709
Log Pis Min                  -7.175949
Policy mu Mean               -0.009924171
Policy mu Std                0.5933708
Policy mu Max                2.3617818
Policy mu Min                -3.1277778
Policy log std Mean          -0.9735715
Policy log std Std           0.26471248
Policy log std Max           -0.18486905
Policy log std Min           -2.148311
Z mean eval                  0.9562942
Z variance eval              0.014097807
total_rewards                [2874.00348146 2794.93826294 3079.21663492 2980.16416004 3092.50038849
 3060.83134216 3096.36964933 3019.40020311 2618.68804527 2963.22455529]
total_rewards_mean           2957.9336722995927
total_rewards_std            146.82299092148935
total_rewards_max            3096.3696493266752
total_rewards_min            2618.688045266355
Number of train steps total  327000
Number of env steps total    1637000
Number of rollouts total     0
Train Time (s)               44.1095686359331
(Previous) Eval Time (s)     34.117253257893026
Sample Time (s)              21.79291389277205
Epoch Time (s)               100.01973578659818
Total Train Time (s)         31429.742258752696
Epoch                        326
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:13:08.846062 UTC | [2020_01_10_11_29_18] Iteration #326 | Epoch Duration: 99.85113215446472
2020-01-10 20:13:08.846388 UTC | [2020_01_10_11_29_18] Iteration #326 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95582134
Z variance train             0.014070561
KL Divergence                20.369492
KL Loss                      2.0369492
QF Loss                      463.95654
VF Loss                      99.38031
Policy Loss                  -1088.0784
Q Predictions Mean           1085.3372
Q Predictions Std            229.75832
Q Predictions Max            1254.9753
Q Predictions Min            39.632793
V Predictions Mean           1089.2366
V Predictions Std            229.6933
V Predictions Max            1261.8423
V Predictions Min            58.759876
Log Pis Mean                 -0.35600257
Log Pis Std                  2.6340902
Log Pis Max                  9.7263975
Log Pis Min                  -8.176493
Policy mu Mean               -0.038490005
Policy mu Std                0.57316095
Policy mu Max                2.0823362
Policy mu Min                -2.1068537
Policy log std Mean          -0.95855117
Policy log std Std           0.24423492
Policy log std Max           -0.13365853
Policy log std Min           -2.0622237
Z mean eval                  1.0034344
Z variance eval              0.015475184
total_rewards                [2986.50085578  674.20436457 2920.20948483 1803.35533262 1205.41714623
 1241.67700042 2914.38435252 2885.16775995  125.19942815 2999.37000324]
total_rewards_mean           1975.548572830831
total_rewards_std            1046.4247647002956
total_rewards_max            2999.3700032376673
total_rewards_min            125.19942815354861
Number of train steps total  328000
Number of env steps total    1642000
Number of rollouts total     0
Train Time (s)               43.93781252624467
(Previous) Eval Time (s)     33.94839628320187
Sample Time (s)              22.945596066769212
Epoch Time (s)               100.83180487621576
Total Train Time (s)         31527.149542998523
Epoch                        327
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:14:46.260199 UTC | [2020_01_10_11_29_18] Iteration #327 | Epoch Duration: 97.41359949111938
2020-01-10 20:14:46.260333 UTC | [2020_01_10_11_29_18] Iteration #327 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0019429
Z variance train             0.015437094
KL Divergence                20.461243
KL Loss                      2.0461242
QF Loss                      1603.6191
VF Loss                      318.12234
Policy Loss                  -1102.7762
Q Predictions Mean           1102.5518
Q Predictions Std            251.18513
Q Predictions Max            1301.6211
Q Predictions Min            -10.79254
V Predictions Mean           1097.0935
V Predictions Std            248.3301
V Predictions Max            1302.0408
V Predictions Min            58.92801
Log Pis Mean                 -0.53727823
Log Pis Std                  2.6584013
Log Pis Max                  10.515677
Log Pis Min                  -11.09862
Policy mu Mean               0.020065265
Policy mu Std                0.5989328
Policy mu Max                2.4083252
Policy mu Min                -1.9000937
Policy log std Mean          -0.9445677
Policy log std Std           0.26217943
Policy log std Max           -0.159064
Policy log std Min           -2.4573593
Z mean eval                  0.98859584
Z variance eval              0.015339215
total_rewards                [2787.30652749  531.70455851 1012.61983073 3064.12192545 2221.42864181
 1556.79585774 2876.46721907 3104.84414116 3062.79609153  489.66787063]
total_rewards_mean           2070.775266410829
total_rewards_std            1023.6162049293013
total_rewards_max            3104.8441411626636
total_rewards_min            489.6678706329244
Number of train steps total  329000
Number of env steps total    1647000
Number of rollouts total     0
Train Time (s)               43.41567692020908
(Previous) Eval Time (s)     30.529959538951516
Sample Time (s)              23.25935628404841
Epoch Time (s)               97.204992743209
Total Train Time (s)         31616.50445095729
Epoch                        328
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:16:15.622643 UTC | [2020_01_10_11_29_18] Iteration #328 | Epoch Duration: 89.36215686798096
2020-01-10 20:16:15.622957 UTC | [2020_01_10_11_29_18] Iteration #328 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.987358
Z variance train             0.015349207
KL Divergence                20.431005
KL Loss                      2.0431006
QF Loss                      2534.4353
VF Loss                      156.54726
Policy Loss                  -1108.1443
Q Predictions Mean           1106.2142
Q Predictions Std            224.94765
Q Predictions Max            1294.2213
Q Predictions Min            48.607147
V Predictions Mean           1110.571
V Predictions Std            220.70691
V Predictions Max            1297.3357
V Predictions Min            -5.2709208
Log Pis Mean                 -0.6117234
Log Pis Std                  2.639655
Log Pis Max                  12.652784
Log Pis Min                  -8.255221
Policy mu Mean               -0.023379957
Policy mu Std                0.57405704
Policy mu Max                2.361969
Policy mu Min                -2.5069742
Policy log std Mean          -0.94088745
Policy log std Std           0.24665326
Policy log std Max           0.17531729
Policy log std Min           -1.9303197
Z mean eval                  0.96268636
Z variance eval              0.02006555
total_rewards                [2921.76980325  851.50966715 2847.21017645 2649.23897528 2949.16815246
 2505.32857739 3046.20746551 2916.68154413  749.61007843  420.33439074]
total_rewards_mean           2185.705883077772
total_rewards_std            1005.6366070751269
total_rewards_max            3046.207465506265
total_rewards_min            420.3343907353111
Number of train steps total  330000
Number of env steps total    1652000
Number of rollouts total     0
Train Time (s)               43.849190939217806
(Previous) Eval Time (s)     22.68685861583799
Sample Time (s)              22.800980881787837
Epoch Time (s)               89.33703043684363
Total Train Time (s)         31712.04714639904
Epoch                        329
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:17:51.170702 UTC | [2020_01_10_11_29_18] Iteration #329 | Epoch Duration: 95.54752659797668
2020-01-10 20:17:51.170875 UTC | [2020_01_10_11_29_18] Iteration #329 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9623707
Z variance train             0.020061538
KL Divergence                19.20995
KL Loss                      1.920995
QF Loss                      675.89685
VF Loss                      113.61435
Policy Loss                  -1108.141
Q Predictions Mean           1107.3765
Q Predictions Std            200.73236
Q Predictions Max            1252.8081
Q Predictions Min            80.32168
V Predictions Mean           1105.2133
V Predictions Std            199.7244
V Predictions Max            1262.3035
V Predictions Min            92.15197
Log Pis Mean                 -0.19898447
Log Pis Std                  2.637661
Log Pis Max                  10.261862
Log Pis Min                  -7.457534
Policy mu Mean               -0.058655545
Policy mu Std                0.5911146
Policy mu Max                1.6901144
Policy mu Min                -2.490466
Policy log std Mean          -0.9365719
Policy log std Std           0.27482975
Policy log std Max           -0.16944438
Policy log std Min           -2.6391041
Z mean eval                  0.949217
Z variance eval              0.026384076
total_rewards                [2826.55894691 1685.82957739  799.73955907 3170.74753003   18.05895644
 1161.42819573 1856.97842509 3007.56850217 3156.84050422 2653.10768696]
total_rewards_mean           2033.6857884026401
total_rewards_std            1049.4571149120436
total_rewards_max            3170.7475300281494
total_rewards_min            18.058956440302083
Number of train steps total  331000
Number of env steps total    1657000
Number of rollouts total     0
Train Time (s)               44.05735095124692
(Previous) Eval Time (s)     28.897119224071503
Sample Time (s)              22.504167712293565
Epoch Time (s)               95.45863788761199
Total Train Time (s)         31811.24814467877
Epoch                        330
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:19:30.376465 UTC | [2020_01_10_11_29_18] Iteration #330 | Epoch Duration: 99.20547103881836
2020-01-10 20:19:30.376598 UTC | [2020_01_10_11_29_18] Iteration #330 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94959176
Z variance train             0.026434949
KL Divergence                18.764132
KL Loss                      1.8764132
QF Loss                      528.3863
VF Loss                      149.43295
Policy Loss                  -1097.8367
Q Predictions Mean           1098.577
Q Predictions Std            246.01112
Q Predictions Max            1302.8959
Q Predictions Min            37.60233
V Predictions Mean           1094.274
V Predictions Std            243.43362
V Predictions Max            1298.2959
V Predictions Min            29.82099
Log Pis Mean                 -0.60880035
Log Pis Std                  2.3295186
Log Pis Max                  6.643178
Log Pis Min                  -6.5739613
Policy mu Mean               -0.0140923355
Policy mu Std                0.59222686
Policy mu Max                2.4336267
Policy mu Min                -1.9032208
Policy log std Mean          -0.93218744
Policy log std Std           0.24848272
Policy log std Max           -0.10863626
Policy log std Min           -2.1447139
Z mean eval                  0.9514574
Z variance eval              0.024223644
total_rewards                [2908.09536049 1403.29069142  901.08087676 2927.26819042 3130.29069732
  227.4860164  3006.73467862   69.76769814 2573.27957169 3141.6229735 ]
total_rewards_mean           2028.891675477067
total_rewards_std            1184.501086773892
total_rewards_max            3141.6229734990625
total_rewards_min            69.7676981420135
Number of train steps total  332000
Number of env steps total    1662000
Number of rollouts total     0
Train Time (s)               44.02668200712651
(Previous) Eval Time (s)     32.64370946679264
Sample Time (s)              22.44732427690178
Epoch Time (s)               99.11771575082093
Total Train Time (s)         31903.339389766566
Epoch                        331
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:21:02.471005 UTC | [2020_01_10_11_29_18] Iteration #331 | Epoch Duration: 92.09429812431335
2020-01-10 20:21:02.471181 UTC | [2020_01_10_11_29_18] Iteration #331 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95343494
Z variance train             0.02420806
KL Divergence                19.099205
KL Loss                      1.9099206
QF Loss                      983.2737
VF Loss                      274.16028
Policy Loss                  -1123.1432
Q Predictions Mean           1124.163
Q Predictions Std            185.56499
Q Predictions Max            1281.6805
Q Predictions Min            47.525536
V Predictions Mean           1133.8572
V Predictions Std            186.84605
V Predictions Max            1298.8733
V Predictions Min            52.582596
Log Pis Mean                 -0.51125693
Log Pis Std                  2.709103
Log Pis Max                  11.194954
Log Pis Min                  -8.051629
Policy mu Mean               0.03641871
Policy mu Std                0.57899326
Policy mu Max                3.4094987
Policy mu Min                -2.4949188
Policy log std Mean          -0.9562659
Policy log std Std           0.26209238
Policy log std Max           0.18128026
Policy log std Min           -2.7314353
Z mean eval                  0.9322978
Z variance eval              0.01909301
total_rewards                [ 938.52080207 1623.96639696 2574.92458618 2766.15999216 1378.72794496
 2885.52046301 2338.92045553  411.76843104 1321.71502787 2929.57437717]
total_rewards_mean           1916.9798476949068
total_rewards_std            851.3757331196383
total_rewards_max            2929.5743771652333
total_rewards_min            411.76843103695126
Number of train steps total  333000
Number of env steps total    1667000
Number of rollouts total     0
Train Time (s)               43.96938246395439
(Previous) Eval Time (s)     25.620048163924366
Sample Time (s)              22.944279773626477
Epoch Time (s)               92.53371040150523
Total Train Time (s)         31998.687865370885
Epoch                        332
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:22:37.821726 UTC | [2020_01_10_11_29_18] Iteration #332 | Epoch Duration: 95.35041975975037
2020-01-10 20:22:37.821861 UTC | [2020_01_10_11_29_18] Iteration #332 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93254423
Z variance train             0.01913054
KL Divergence                19.180532
KL Loss                      1.9180533
QF Loss                      2174.5205
VF Loss                      406.26483
Policy Loss                  -1083.0726
Q Predictions Mean           1082.4102
Q Predictions Std            252.57323
Q Predictions Max            1275.0433
Q Predictions Min            -6.525875
V Predictions Mean           1083.8625
V Predictions Std            245.54868
V Predictions Max            1278.9148
V Predictions Min            48.46362
Log Pis Mean                 -0.28661582
Log Pis Std                  2.9849916
Log Pis Max                  17.872906
Log Pis Min                  -7.4781203
Policy mu Mean               -0.016002862
Policy mu Std                0.58366585
Policy mu Max                2.421866
Policy mu Min                -4.079187
Policy log std Mean          -0.963054
Policy log std Std           0.29567757
Policy log std Max           0.011543632
Policy log std Min           -2.973709
Z mean eval                  1.0376773
Z variance eval              0.023743149
total_rewards                [3264.41476552 3082.98084733 3064.26307742 3107.45151195 3100.27670288
 1162.95771728 1078.22536091 2953.80796736 1485.30613237 3022.74959032]
total_rewards_mean           2532.2433673324713
total_rewards_std            853.1975255010872
total_rewards_max            3264.4147655160505
total_rewards_min            1078.225360906967
Number of train steps total  334000
Number of env steps total    1672000
Number of rollouts total     0
Train Time (s)               43.7204030030407
(Previous) Eval Time (s)     28.436511559877545
Sample Time (s)              22.655556002166122
Epoch Time (s)               94.81247056508437
Total Train Time (s)         32095.98164271703
Epoch                        333
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:24:15.119048 UTC | [2020_01_10_11_29_18] Iteration #333 | Epoch Duration: 97.29707860946655
2020-01-10 20:24:15.119219 UTC | [2020_01_10_11_29_18] Iteration #333 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0365546
Z variance train             0.023698162
KL Divergence                19.997402
KL Loss                      1.9997402
QF Loss                      362.75098
VF Loss                      204.67966
Policy Loss                  -1083.4661
Q Predictions Mean           1084.8506
Q Predictions Std            281.0319
Q Predictions Max            1297.7643
Q Predictions Min            -3.81297
V Predictions Mean           1087.1
V Predictions Std            280.14166
V Predictions Max            1296.3785
V Predictions Min            29.524775
Log Pis Mean                 -0.19043192
Log Pis Std                  2.9165742
Log Pis Max                  14.12215
Log Pis Min                  -6.6530046
Policy mu Mean               -0.03752883
Policy mu Std                0.57423127
Policy mu Max                2.1150558
Policy mu Min                -2.0371165
Policy log std Mean          -0.9958825
Policy log std Std           0.30681878
Policy log std Max           -0.20045364
Policy log std Min           -3.417045
Z mean eval                  0.99456775
Z variance eval              0.02190276
total_rewards                [2745.53099899 2921.83874613 1178.24161157 1913.30913424 2309.48070123
 3054.88721499 1194.8447226  1343.48365593  683.88110282 2823.48250909]
total_rewards_mean           2016.8980397591527
total_rewards_std            823.6319765422486
total_rewards_max            3054.8872149876183
total_rewards_min            683.8811028248962
Number of train steps total  335000
Number of env steps total    1677000
Number of rollouts total     0
Train Time (s)               44.4656037800014
(Previous) Eval Time (s)     30.920877675060183
Sample Time (s)              22.854311361908913
Epoch Time (s)               98.2407928169705
Total Train Time (s)         32189.01165606454
Epoch                        334
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:25:48.153106 UTC | [2020_01_10_11_29_18] Iteration #334 | Epoch Duration: 93.0337541103363
2020-01-10 20:25:48.153265 UTC | [2020_01_10_11_29_18] Iteration #334 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9971113
Z variance train             0.021859836
KL Divergence                20.063816
KL Loss                      2.0063818
QF Loss                      1087.5146
VF Loss                      313.07904
Policy Loss                  -1144.4381
Q Predictions Mean           1144.2251
Q Predictions Std            197.5702
Q Predictions Max            1311.8623
Q Predictions Min            -7.151414
V Predictions Mean           1131.2532
V Predictions Std            191.49802
V Predictions Max            1293.5879
V Predictions Min            25.390196
Log Pis Mean                 -0.1972252
Log Pis Std                  2.6659307
Log Pis Max                  6.7439356
Log Pis Min                  -9.626587
Policy mu Mean               0.0112513285
Policy mu Std                0.61510646
Policy mu Max                2.293694
Policy mu Min                -2.0737808
Policy log std Mean          -0.94193447
Policy log std Std           0.24587044
Policy log std Max           -0.07761949
Policy log std Min           -2.3985527
Z mean eval                  1.0007428
Z variance eval              0.02611726
total_rewards                [2764.46982847 2988.67331818  885.3252502  3167.4375952  2941.29641992
 2561.93187159 2473.569582   1598.80058468 2541.28440681 1751.92178813]
total_rewards_mean           2367.4710645184336
total_rewards_std            689.8200242990031
total_rewards_max            3167.437595202437
total_rewards_min            885.3252502042653
Number of train steps total  336000
Number of env steps total    1682000
Number of rollouts total     0
Train Time (s)               43.7236655279994
(Previous) Eval Time (s)     25.713600063230842
Sample Time (s)              22.651112105697393
Epoch Time (s)               92.08837769692764
Total Train Time (s)         32286.1872473415
Epoch                        335
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:27:25.330649 UTC | [2020_01_10_11_29_18] Iteration #335 | Epoch Duration: 97.17725920677185
2020-01-10 20:27:25.330788 UTC | [2020_01_10_11_29_18] Iteration #335 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0018117
Z variance train             0.026079323
KL Divergence                19.952705
KL Loss                      1.9952706
QF Loss                      2075.7173
VF Loss                      205.53154
Policy Loss                  -1135.4733
Q Predictions Mean           1136.6202
Q Predictions Std            204.01476
Q Predictions Max            1310.3416
Q Predictions Min            -145.62454
V Predictions Mean           1144.956
V Predictions Std            201.6271
V Predictions Max            1317.7496
V Predictions Min            -30.840519
Log Pis Mean                 -0.2590748
Log Pis Std                  2.4196312
Log Pis Max                  7.4316845
Log Pis Min                  -8.218036
Policy mu Mean               -0.0068862583
Policy mu Std                0.58999854
Policy mu Max                2.7555015
Policy mu Min                -2.2080908
Policy log std Mean          -0.969224
Policy log std Std           0.23935582
Policy log std Max           0.3724146
Policy log std Min           -2.012408
Z mean eval                  0.9602741
Z variance eval              0.015613693
total_rewards                [  46.8730973  3218.24052971 3157.59173351 1084.45340752 2196.43110706
  484.51841239 3030.18409952 2941.04589592  605.48192854 2316.66229342]
total_rewards_mean           1908.1482504883502
total_rewards_std            1171.3139361821547
total_rewards_max            3218.2405297110886
total_rewards_min            46.873097298762374
Number of train steps total  337000
Number of env steps total    1687000
Number of rollouts total     0
Train Time (s)               43.912388507742435
(Previous) Eval Time (s)     30.802230867091566
Sample Time (s)              23.393505692016333
Epoch Time (s)               98.10812506685033
Total Train Time (s)         32378.470970124006
Epoch                        336
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:28:57.618862 UTC | [2020_01_10_11_29_18] Iteration #336 | Epoch Duration: 92.28797054290771
2020-01-10 20:28:57.619001 UTC | [2020_01_10_11_29_18] Iteration #336 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9584241
Z variance train             0.015658254
KL Divergence                20.504902
KL Loss                      2.0504901
QF Loss                      609.2456
VF Loss                      217.754
Policy Loss                  -1119.8887
Q Predictions Mean           1121.0128
Q Predictions Std            216.19362
Q Predictions Max            1310.3297
Q Predictions Min            67.48882
V Predictions Mean           1123.4603
V Predictions Std            216.28888
V Predictions Max            1303.6101
V Predictions Min            61.021015
Log Pis Mean                 0.07631309
Log Pis Std                  2.7825277
Log Pis Max                  10.601852
Log Pis Min                  -6.953473
Policy mu Mean               -0.009979899
Policy mu Std                0.66750103
Policy mu Max                2.5968888
Policy mu Min                -2.2235994
Policy log std Mean          -0.93271804
Policy log std Std           0.2607235
Policy log std Max           -0.064805925
Policy log std Min           -2.3370337
Z mean eval                  0.95165384
Z variance eval              0.018073756
total_rewards                [1053.25768389 1231.23651215 3030.68910112 3011.25612043 2504.92517442
 1769.43633212 3010.42863823 3070.91331358 3050.43421099 3105.78877581]
total_rewards_mean           2483.8365862750134
total_rewards_std            776.7502879737638
total_rewards_max            3105.7887758148554
total_rewards_min            1053.2576838869902
Number of train steps total  338000
Number of env steps total    1692000
Number of rollouts total     0
Train Time (s)               44.1940928469412
(Previous) Eval Time (s)     24.981834003701806
Sample Time (s)              23.416815544012934
Epoch Time (s)               92.59274239465594
Total Train Time (s)         32474.129503660835
Epoch                        337
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:30:33.286043 UTC | [2020_01_10_11_29_18] Iteration #337 | Epoch Duration: 95.66688776016235
2020-01-10 20:30:33.286361 UTC | [2020_01_10_11_29_18] Iteration #337 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9511987
Z variance train             0.018064415
KL Divergence                20.206905
KL Loss                      2.0206907
QF Loss                      4720.6934
VF Loss                      144.32562
Policy Loss                  -1116.6724
Q Predictions Mean           1119.0448
Q Predictions Std            214.4451
Q Predictions Max            1338.7781
Q Predictions Min            100.55478
V Predictions Mean           1116.533
V Predictions Std            216.99022
V Predictions Max            1320.5612
V Predictions Min            79.31246
Log Pis Mean                 -0.1362998
Log Pis Std                  2.9096675
Log Pis Max                  21.908628
Log Pis Min                  -7.346234
Policy mu Mean               -0.0444298
Policy mu Std                0.6202896
Policy mu Max                3.14739
Policy mu Min                -2.2766805
Policy log std Mean          -0.97903675
Policy log std Std           0.25694478
Policy log std Max           -0.1276018
Policy log std Min           -2.1933205
Z mean eval                  0.9624599
Z variance eval              0.0108932415
total_rewards                [2801.46054707 3120.33125026  356.27160493 3014.73040139 3252.00095914
 3206.76360682  273.87468516 3208.25696    2771.97346913 3329.95120747]
total_rewards_mean           2533.56146913739
total_rewards_std            1122.9432340604199
total_rewards_max            3329.9512074692175
total_rewards_min            273.8746851637278
Number of train steps total  339000
Number of env steps total    1697000
Number of rollouts total     0
Train Time (s)               45.313496690709144
(Previous) Eval Time (s)     28.055703526828438
Sample Time (s)              22.514427097979933
Epoch Time (s)               95.88362731551751
Total Train Time (s)         32570.282137640752
Epoch                        338
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:32:09.444938 UTC | [2020_01_10_11_29_18] Iteration #338 | Epoch Duration: 96.15832376480103
2020-01-10 20:32:09.445232 UTC | [2020_01_10_11_29_18] Iteration #338 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96429455
Z variance train             0.010903
KL Divergence                20.764011
KL Loss                      2.0764012
QF Loss                      487.23907
VF Loss                      81.99675
Policy Loss                  -1118.7013
Q Predictions Mean           1118.0121
Q Predictions Std            238.75375
Q Predictions Max            1333.319
Q Predictions Min            -0.48781973
V Predictions Mean           1121.5775
V Predictions Std            238.7125
V Predictions Max            1338.3461
V Predictions Min            3.0438874
Log Pis Mean                 -0.32327533
Log Pis Std                  2.4392796
Log Pis Max                  6.629867
Log Pis Min                  -9.434539
Policy mu Mean               -0.035018206
Policy mu Std                0.58834153
Policy mu Max                1.9621159
Policy mu Min                -2.3074677
Policy log std Mean          -0.94425416
Policy log std Std           0.24858631
Policy log std Max           0.020427883
Policy log std Min           -1.98085
Z mean eval                  0.9872079
Z variance eval              0.016121412
total_rewards                [2913.94450052 3085.21129347 3187.33286587 2683.7493044  2429.01185528
 -103.08788839 3094.74825806  806.60111966 2893.82103136 2870.72714947]
total_rewards_mean           2386.2059489698368
total_rewards_std            1057.6146025979795
total_rewards_max            3187.3328658669448
total_rewards_min            -103.08788839218198
Number of train steps total  340000
Number of env steps total    1702000
Number of rollouts total     0
Train Time (s)               44.416532723233104
(Previous) Eval Time (s)     28.33015474304557
Sample Time (s)              22.190089027397335
Epoch Time (s)               94.936776493676
Total Train Time (s)         32671.974060330074
Epoch                        339
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:33:51.139539 UTC | [2020_01_10_11_29_18] Iteration #339 | Epoch Duration: 101.69410920143127
2020-01-10 20:33:51.139678 UTC | [2020_01_10_11_29_18] Iteration #339 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9861115
Z variance train             0.015980015
KL Divergence                20.992865
KL Loss                      2.0992866
QF Loss                      685.6942
VF Loss                      207.78194
Policy Loss                  -1117.5433
Q Predictions Mean           1118.4159
Q Predictions Std            242.576
Q Predictions Max            1316.0382
Q Predictions Min            -24.427036
V Predictions Mean           1121.1533
V Predictions Std            241.84674
V Predictions Max            1307.4564
V Predictions Min            -8.632882
Log Pis Mean                 -0.21026534
Log Pis Std                  2.733534
Log Pis Max                  11.36023
Log Pis Min                  -6.8656464
Policy mu Mean               0.02890905
Policy mu Std                0.5939601
Policy mu Max                2.4995673
Policy mu Min                -2.5016916
Policy log std Mean          -0.9421985
Policy log std Std           0.25413987
Policy log std Max           -0.08241582
Policy log std Min           -2.3080823
Z mean eval                  1.0060754
Z variance eval              0.01626264
total_rewards                [ 422.96524114 3103.4182205   470.83363878 2939.05641261  823.50074703
 2044.36404099  607.61886574 1021.67968238 2502.16967316 1882.28041454]
total_rewards_mean           1581.7886936867783
total_rewards_std            986.0895977453436
total_rewards_max            3103.418220504646
total_rewards_min            422.96524113566164
Number of train steps total  341000
Number of env steps total    1707000
Number of rollouts total     0
Train Time (s)               44.03575142286718
(Previous) Eval Time (s)     35.0872543938458
Sample Time (s)              22.710334362462163
Epoch Time (s)               101.83334017917514
Total Train Time (s)         32763.33061082801
Epoch                        340
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:35:22.499552 UTC | [2020_01_10_11_29_18] Iteration #340 | Epoch Duration: 91.35977053642273
2020-01-10 20:35:22.499699 UTC | [2020_01_10_11_29_18] Iteration #340 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0059377
Z variance train             0.016270433
KL Divergence                20.61408
KL Loss                      2.061408
QF Loss                      654.3245
VF Loss                      256.501
Policy Loss                  -1119.3783
Q Predictions Mean           1119.8899
Q Predictions Std            230.17445
Q Predictions Max            1302.2388
Q Predictions Min            -17.128057
V Predictions Mean           1116.385
V Predictions Std            230.43597
V Predictions Max            1298.5662
V Predictions Min            0.8815259
Log Pis Mean                 -0.42569697
Log Pis Std                  2.5914228
Log Pis Max                  7.5168104
Log Pis Min                  -7.814913
Policy mu Mean               0.025400333
Policy mu Std                0.605594
Policy mu Max                2.0821657
Policy mu Min                -2.7635922
Policy log std Mean          -0.9396491
Policy log std Std           0.2493956
Policy log std Max           -0.02127409
Policy log std Min           -2.5431583
Z mean eval                  0.9720003
Z variance eval              0.012761953
total_rewards                [2656.51430303 2768.87757613  703.26329279 2948.42351673 2894.58518207
 3185.98757832 3095.17401608 2969.83962896  412.55504866 3104.66988405]
total_rewards_mean           2473.989002682859
total_rewards_std            971.7861136595426
total_rewards_max            3185.987578322062
total_rewards_min            412.55504865636544
Number of train steps total  342000
Number of env steps total    1712000
Number of rollouts total     0
Train Time (s)               44.164530782960355
(Previous) Eval Time (s)     24.613444654736668
Sample Time (s)              22.517415607813746
Epoch Time (s)               91.29539104551077
Total Train Time (s)         32856.57281703735
Epoch                        341
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:36:55.745786 UTC | [2020_01_10_11_29_18] Iteration #341 | Epoch Duration: 93.24597454071045
2020-01-10 20:36:55.745959 UTC | [2020_01_10_11_29_18] Iteration #341 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9725272
Z variance train             0.01278584
KL Divergence                21.31539
KL Loss                      2.131539
QF Loss                      603.9161
VF Loss                      156.19943
Policy Loss                  -1150.285
Q Predictions Mean           1150.8022
Q Predictions Std            193.84663
Q Predictions Max            1306.6416
Q Predictions Min            20.331964
V Predictions Mean           1151.2974
V Predictions Std            193.30865
V Predictions Max            1327.9247
V Predictions Min            20.686121
Log Pis Mean                 -0.10505377
Log Pis Std                  2.8311293
Log Pis Max                  8.964201
Log Pis Min                  -7.076169
Policy mu Mean               -0.0666455
Policy mu Std                0.63985175
Policy mu Max                2.5323288
Policy mu Min                -2.4202106
Policy log std Mean          -0.947787
Policy log std Std           0.24449459
Policy log std Max           -0.04071802
Policy log std Min           -2.0951052
Z mean eval                  0.9882976
Z variance eval              0.022556622
total_rewards                [3004.2304962  2008.49011573 2920.5492665  3003.25253092 2870.37675967
 2863.87132146 2558.52622123 2654.23958718 3062.40471103 2848.40438919]
total_rewards_mean           2779.4345399120557
total_rewards_std            296.58045502334045
total_rewards_max            3062.4047110341203
total_rewards_min            2008.4901157308802
Number of train steps total  343000
Number of env steps total    1717000
Number of rollouts total     0
Train Time (s)               43.20851659681648
(Previous) Eval Time (s)     26.56378722563386
Sample Time (s)              23.350230326410383
Epoch Time (s)               93.12253414886072
Total Train Time (s)         32955.26044904161
Epoch                        342
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:38:34.437479 UTC | [2020_01_10_11_29_18] Iteration #342 | Epoch Duration: 98.69138741493225
2020-01-10 20:38:34.437655 UTC | [2020_01_10_11_29_18] Iteration #342 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.987507
Z variance train             0.022509824
KL Divergence                20.111279
KL Loss                      2.011128
QF Loss                      673.1288
VF Loss                      127.81093
Policy Loss                  -1122.2704
Q Predictions Mean           1121.0254
Q Predictions Std            228.63487
Q Predictions Max            1298.4255
Q Predictions Min            31.985634
V Predictions Mean           1115.8845
V Predictions Std            227.57425
V Predictions Max            1288.9003
V Predictions Min            47.39665
Log Pis Mean                 -0.32225567
Log Pis Std                  2.6135297
Log Pis Max                  10.945318
Log Pis Min                  -7.2680416
Policy mu Mean               0.0017444137
Policy mu Std                0.58380437
Policy mu Max                2.0947006
Policy mu Min                -2.1170616
Policy log std Mean          -0.953918
Policy log std Std           0.25241607
Policy log std Max           -0.12694764
Policy log std Min           -2.6255143
Z mean eval                  0.9794237
Z variance eval              0.018175071
total_rewards                [2851.30618906 2864.05452051 2866.02397452  503.67522586 2874.90093563
  444.25307544 2704.70192144 2956.55249578   65.63868206 3076.02140641]
total_rewards_mean           2120.7128426715503
total_rewards_std            1175.2257350528462
total_rewards_max            3076.0214064076686
total_rewards_min            65.63868206474835
Number of train steps total  344000
Number of env steps total    1722000
Number of rollouts total     0
Train Time (s)               44.10022584395483
(Previous) Eval Time (s)     32.132395764347166
Sample Time (s)              23.331296906340867
Epoch Time (s)               99.56391851464286
Total Train Time (s)         33056.0843475759
Epoch                        343
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:40:15.265266 UTC | [2020_01_10_11_29_18] Iteration #343 | Epoch Duration: 100.8274257183075
2020-01-10 20:40:15.265630 UTC | [2020_01_10_11_29_18] Iteration #343 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9715926
Z variance train             0.018113445
KL Divergence                19.612644
KL Loss                      1.9612645
QF Loss                      931.22705
VF Loss                      375.54565
Policy Loss                  -1158.3597
Q Predictions Mean           1159.2542
Q Predictions Std            184.68008
Q Predictions Max            1329.2576
Q Predictions Min            10.929249
V Predictions Mean           1142.0381
V Predictions Std            184.70052
V Predictions Max            1320.1545
V Predictions Min            -8.550877
Log Pis Mean                 -0.0052713603
Log Pis Std                  2.4427714
Log Pis Max                  7.487483
Log Pis Min                  -7.474286
Policy mu Mean               0.039204225
Policy mu Std                0.6292854
Policy mu Max                1.9247937
Policy mu Min                -2.1291094
Policy log std Mean          -0.9506459
Policy log std Std           0.2638376
Policy log std Max           0.033684194
Policy log std Min           -3.1115537
Z mean eval                  0.96743375
Z variance eval              0.022151362
total_rewards                [ 629.69498643 3066.62394771  140.72522127  184.67824585  481.36254047
 2109.30646055   10.3534434   205.03616388  531.15515582 1560.65618562]
total_rewards_mean           891.9592351017203
total_rewards_std            966.4108482235779
total_rewards_max            3066.6239477121826
total_rewards_min            10.35344340435509
Number of train steps total  345000
Number of env steps total    1727000
Number of rollouts total     0
Train Time (s)               45.35791151272133
(Previous) Eval Time (s)     33.39562686579302
Sample Time (s)              22.966390411835164
Epoch Time (s)               101.71992879034951
Total Train Time (s)         33141.21097293636
Epoch                        344
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:41:40.394343 UTC | [2020_01_10_11_29_18] Iteration #344 | Epoch Duration: 85.12847399711609
2020-01-10 20:41:40.394520 UTC | [2020_01_10_11_29_18] Iteration #344 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9680297
Z variance train             0.022232259
KL Divergence                18.953596
KL Loss                      1.8953596
QF Loss                      586.6747
VF Loss                      103.97404
Policy Loss                  -1129.6337
Q Predictions Mean           1130.7473
Q Predictions Std            208.47449
Q Predictions Max            1317.1682
Q Predictions Min            -13.153601
V Predictions Mean           1131.8354
V Predictions Std            205.8639
V Predictions Max            1320.4589
V Predictions Min            0.772934
Log Pis Mean                 -0.104108304
Log Pis Std                  2.536368
Log Pis Max                  8.087228
Log Pis Min                  -7.8838
Policy mu Mean               0.011569507
Policy mu Std                0.6366561
Policy mu Max                2.5917177
Policy mu Min                -2.147537
Policy log std Mean          -0.93676895
Policy log std Std           0.2588753
Policy log std Max           -0.04984778
Policy log std Min           -2.348145
Z mean eval                  0.9735426
Z variance eval              0.015224567
total_rewards                [ 338.15989513  313.76107561  440.39471082 3249.04600874 1817.64690447
 2967.39939663 3081.5090216  2188.6966664  3125.77739485 1301.26528425]
total_rewards_mean           1882.3656358507749
total_rewards_std            1157.1174436278657
total_rewards_max            3249.04600873682
total_rewards_min            313.7610756095935
Number of train steps total  346000
Number of env steps total    1732000
Number of rollouts total     0
Train Time (s)               44.76612983038649
(Previous) Eval Time (s)     16.803949404973537
Sample Time (s)              20.225361959077418
Epoch Time (s)               81.79544119443744
Total Train Time (s)         33230.94773046393
Epoch                        345
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:43:10.138300 UTC | [2020_01_10_11_29_18] Iteration #345 | Epoch Duration: 89.74362015724182
2020-01-10 20:43:10.138573 UTC | [2020_01_10_11_29_18] Iteration #345 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97368014
Z variance train             0.015243006
KL Divergence                19.768364
KL Loss                      1.9768364
QF Loss                      442.11356
VF Loss                      115.84384
Policy Loss                  -1156.952
Q Predictions Mean           1156.5942
Q Predictions Std            141.74072
Q Predictions Max            1323.4213
Q Predictions Min            3.4999828
V Predictions Mean           1152.0812
V Predictions Std            141.69656
V Predictions Max            1297.357
V Predictions Min            9.161588
Log Pis Mean                 -0.23588233
Log Pis Std                  2.2342548
Log Pis Max                  6.6508656
Log Pis Min                  -5.585158
Policy mu Mean               -0.0041819587
Policy mu Std                0.61118037
Policy mu Max                2.3157065
Policy mu Min                -2.1351876
Policy log std Mean          -0.9459508
Policy log std Std           0.22149746
Policy log std Max           -0.27986348
Policy log std Min           -2.2021427
Z mean eval                  0.9555373
Z variance eval              0.02188563
total_rewards                [1869.80371762 2915.55533271 2766.12088413 2823.66105283 2815.36590269
 2877.03062705 2738.11377383 1425.5062907  2958.62780491 2692.84242688]
total_rewards_mean           2588.2627813353747
total_rewards_std            486.608417236388
total_rewards_max            2958.6278049123957
total_rewards_min            1425.5062906955122
Number of train steps total  347000
Number of env steps total    1737000
Number of rollouts total     0
Train Time (s)               43.69226015685126
(Previous) Eval Time (s)     24.751876754686236
Sample Time (s)              22.562929330393672
Epoch Time (s)               91.00706624193117
Total Train Time (s)         33328.735348333605
Epoch                        346
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:44:47.931084 UTC | [2020_01_10_11_29_18] Iteration #346 | Epoch Duration: 97.79230761528015
2020-01-10 20:44:47.931251 UTC | [2020_01_10_11_29_18] Iteration #346 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9540283
Z variance train             0.021829346
KL Divergence                19.217157
KL Loss                      1.9217157
QF Loss                      797.9192
VF Loss                      125.73801
Policy Loss                  -1132.5062
Q Predictions Mean           1129.899
Q Predictions Std            221.44193
Q Predictions Max            1357.9612
Q Predictions Min            -15.027323
V Predictions Mean           1131.6829
V Predictions Std            221.76854
V Predictions Max            1350.474
V Predictions Min            15.947915
Log Pis Mean                 -0.065444246
Log Pis Std                  2.5448184
Log Pis Max                  7.250901
Log Pis Min                  -8.456823
Policy mu Mean               0.0059438013
Policy mu Std                0.61254203
Policy mu Max                2.3451004
Policy mu Min                -2.7621548
Policy log std Mean          -0.9595802
Policy log std Std           0.23658875
Policy log std Max           -0.13801575
Policy log std Min           -1.9268107
Z mean eval                  0.9914304
Z variance eval              0.017548392
total_rewards                [1635.57674922 2780.2191879  1453.37499693  359.38451725  418.52214239
  484.84911968  482.62831181 3175.00823962 3018.4487743  3163.44338508]
total_rewards_mean           1697.1455424168944
total_rewards_std            1169.8465772075647
total_rewards_max            3175.0082396199314
total_rewards_min            359.38451724690043
Number of train steps total  348000
Number of env steps total    1742000
Number of rollouts total     0
Train Time (s)               44.08056888403371
(Previous) Eval Time (s)     31.536882432177663
Sample Time (s)              23.49665109300986
Epoch Time (s)               99.11410240922123
Total Train Time (s)         33416.50523342332
Epoch                        347
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:46:15.705631 UTC | [2020_01_10_11_29_18] Iteration #347 | Epoch Duration: 87.77425050735474
2020-01-10 20:46:15.705804 UTC | [2020_01_10_11_29_18] Iteration #347 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99196655
Z variance train             0.017545415
KL Divergence                20.164558
KL Loss                      2.016456
QF Loss                      494.0437
VF Loss                      171.39288
Policy Loss                  -1172.9395
Q Predictions Mean           1174.0419
Q Predictions Std            157.23102
Q Predictions Max            1328.8872
Q Predictions Min            70.53668
V Predictions Mean           1182.6481
V Predictions Std            156.02188
V Predictions Max            1333.0673
V Predictions Min            78.08262
Log Pis Mean                 -0.48122823
Log Pis Std                  2.4154022
Log Pis Max                  7.264434
Log Pis Min                  -8.460517
Policy mu Mean               -0.034328327
Policy mu Std                0.5856785
Policy mu Max                2.1817544
Policy mu Min                -2.2195256
Policy log std Mean          -0.9568223
Policy log std Std           0.22155353
Policy log std Max           0.0047298074
Policy log std Min           -1.9676306
Z mean eval                  0.9817316
Z variance eval              0.02057678
total_rewards                [2793.70654438 3274.00947078 1526.33504327 3492.79923153 3219.77232774
 2961.25775519 3248.31004419 3091.49216442  683.52052843 3163.36302953]
total_rewards_mean           2745.4566139468525
total_rewards_std            860.0493280475067
total_rewards_max            3492.799231526933
total_rewards_min            683.520528428306
Number of train steps total  349000
Number of env steps total    1747000
Number of rollouts total     0
Train Time (s)               43.88994551030919
(Previous) Eval Time (s)     20.196759168989956
Sample Time (s)              20.43694752175361
Epoch Time (s)               84.52365220105276
Total Train Time (s)         33512.596172742546
Epoch                        348
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:47:51.798474 UTC | [2020_01_10_11_29_18] Iteration #348 | Epoch Duration: 96.09253334999084
2020-01-10 20:47:51.798608 UTC | [2020_01_10_11_29_18] Iteration #348 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98176163
Z variance train             0.020610392
KL Divergence                20.082275
KL Loss                      2.0082276
QF Loss                      3403.8774
VF Loss                      195.60616
Policy Loss                  -1119.6721
Q Predictions Mean           1121.4869
Q Predictions Std            233.46172
Q Predictions Max            1300.7244
Q Predictions Min            22.404984
V Predictions Mean           1117.1829
V Predictions Std            233.33105
V Predictions Max            1304.476
V Predictions Min            21.08653
Log Pis Mean                 0.1900937
Log Pis Std                  2.7319136
Log Pis Max                  11.442123
Log Pis Min                  -6.59461
Policy mu Mean               -0.003459559
Policy mu Std                0.621582
Policy mu Max                2.501965
Policy mu Min                -2.090368
Policy log std Mean          -0.9961907
Policy log std Std           0.28722748
Policy log std Max           -0.019368589
Policy log std Min           -2.5976372
Z mean eval                  0.9709648
Z variance eval              0.02854206
total_rewards                [ 669.19420609  561.31573767  489.45552419  930.22558659  443.52716886
 2918.13893474  572.65938204 1125.48611912  443.94721977 3122.54825842]
total_rewards_mean           1127.649813749097
total_rewards_std            969.852942186643
total_rewards_max            3122.548258417508
total_rewards_min            443.5271688577403
Number of train steps total  350000
Number of env steps total    1752000
Number of rollouts total     0
Train Time (s)               44.3069182690233
(Previous) Eval Time (s)     31.765404608566314
Sample Time (s)              22.84620954049751
Epoch Time (s)               98.91853241808712
Total Train Time (s)         33598.06015238678
Epoch                        349
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:49:17.267742 UTC | [2020_01_10_11_29_18] Iteration #349 | Epoch Duration: 85.46897315979004
2020-01-10 20:49:17.268109 UTC | [2020_01_10_11_29_18] Iteration #349 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9702341
Z variance train             0.028421247
KL Divergence                19.716854
KL Loss                      1.9716854
QF Loss                      635.1148
VF Loss                      747.8588
Policy Loss                  -1136.4022
Q Predictions Mean           1139.1906
Q Predictions Std            241.4696
Q Predictions Max            1314.6964
Q Predictions Min            -6.3182354
V Predictions Mean           1152.033
V Predictions Std            247.29466
V Predictions Max            1336.5798
V Predictions Min            15.654065
Log Pis Mean                 -0.31160903
Log Pis Std                  2.6571615
Log Pis Max                  11.817605
Log Pis Min                  -7.1816416
Policy mu Mean               -0.004306075
Policy mu Std                0.59711456
Policy mu Max                2.324497
Policy mu Min                -2.3408942
Policy log std Mean          -0.9874173
Policy log std Std           0.26009002
Policy log std Max           -0.17769891
Policy log std Min           -2.4855313
Z mean eval                  1.0099311
Z variance eval              0.020329839
total_rewards                [2063.4718031   931.38379144 2968.01055215 3032.12360559 2627.11770421
 2304.39901842 2864.5706651  3215.42762862 3068.80846651 3058.16203002]
total_rewards_mean           2613.3475265164725
total_rewards_std            660.2334062304342
total_rewards_max            3215.427628619524
total_rewards_min            931.3837914396031
Number of train steps total  351000
Number of env steps total    1757000
Number of rollouts total     0
Train Time (s)               44.10432976996526
(Previous) Eval Time (s)     18.31556068500504
Sample Time (s)              20.709281641524285
Epoch Time (s)               83.12917209649459
Total Train Time (s)         33693.49933487689
Epoch                        350
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:50:52.708836 UTC | [2020_01_10_11_29_18] Iteration #350 | Epoch Duration: 95.44050025939941
2020-01-10 20:50:52.709008 UTC | [2020_01_10_11_29_18] Iteration #350 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0104806
Z variance train             0.020324303
KL Divergence                20.09413
KL Loss                      2.009413
QF Loss                      468.47568
VF Loss                      104.53707
Policy Loss                  -1150.8275
Q Predictions Mean           1151.4568
Q Predictions Std            226.0863
Q Predictions Max            1328.1556
Q Predictions Min            10.497399
V Predictions Mean           1149.6976
V Predictions Std            224.28017
V Predictions Max            1319.5956
V Predictions Min            14.226155
Log Pis Mean                 -0.42845017
Log Pis Std                  2.5535336
Log Pis Max                  6.9435754
Log Pis Min                  -7.8340406
Policy mu Mean               -0.008255345
Policy mu Std                0.57749474
Policy mu Max                2.258371
Policy mu Min                -1.9763666
Policy log std Mean          -0.9371488
Policy log std Std           0.24503821
Policy log std Max           -0.07508701
Policy log std Min           -2.0094712
Z mean eval                  0.97753936
Z variance eval              0.016501
total_rewards                [3041.15218663  668.49713761  209.25001139  724.39222864 3088.99210671
 1019.71706012  671.50964371 2918.86087453  126.0992187   493.42513328]
total_rewards_mean           1296.1895601318865
total_rewards_std            1152.1583855983013
total_rewards_max            3088.992106713303
total_rewards_min            126.09921869863499
Number of train steps total  352000
Number of env steps total    1762000
Number of rollouts total     0
Train Time (s)               43.69732066290453
(Previous) Eval Time (s)     30.62665167497471
Sample Time (s)              21.53902767645195
Epoch Time (s)               95.86300001433119
Total Train Time (s)         33774.01556047145
Epoch                        351
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:52:13.227427 UTC | [2020_01_10_11_29_18] Iteration #351 | Epoch Duration: 80.51829552650452
2020-01-10 20:52:13.227557 UTC | [2020_01_10_11_29_18] Iteration #351 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9749333
Z variance train             0.01654086
KL Divergence                20.472803
KL Loss                      2.0472803
QF Loss                      420.8213
VF Loss                      100.96312
Policy Loss                  -1172.762
Q Predictions Mean           1173.8591
Q Predictions Std            169.32124
Q Predictions Max            1356.0178
Q Predictions Min            25.653507
V Predictions Mean           1169.383
V Predictions Std            169.21118
V Predictions Max            1359.5958
V Predictions Min            28.661411
Log Pis Mean                 -0.16851024
Log Pis Std                  2.4163423
Log Pis Max                  7.365555
Log Pis Min                  -6.7551117
Policy mu Mean               0.04535286
Policy mu Std                0.61690795
Policy mu Max                2.9071958
Policy mu Min                -2.0306022
Policy log std Mean          -0.9396154
Policy log std Std           0.22618724
Policy log std Max           -0.007967472
Policy log std Min           -1.9914602
Z mean eval                  1.006134
Z variance eval              0.012932229
total_rewards                [ 158.22309494 2956.86050165 1051.95237581 1818.05178191  305.88321292
  786.19484555 3144.26059418 1140.59818162 3139.00119708  813.29941773]
total_rewards_mean           1531.4325203390783
total_rewards_std            1101.8579419529149
total_rewards_max            3144.260594182252
total_rewards_min            158.22309494290198
Number of train steps total  353000
Number of env steps total    1767000
Number of rollouts total     0
Train Time (s)               44.61879908712581
(Previous) Eval Time (s)     15.281763992737979
Sample Time (s)              22.947427423670888
Epoch Time (s)               82.84799050353467
Total Train Time (s)         33860.434257793706
Epoch                        352
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:53:39.653180 UTC | [2020_01_10_11_29_18] Iteration #352 | Epoch Duration: 86.42548656463623
2020-01-10 20:53:39.653386 UTC | [2020_01_10_11_29_18] Iteration #352 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0050691
Z variance train             0.012950718
KL Divergence                20.626192
KL Loss                      2.0626192
QF Loss                      1807.678
VF Loss                      95.58132
Policy Loss                  -1151.3529
Q Predictions Mean           1153.578
Q Predictions Std            175.40202
Q Predictions Max            1313.0308
Q Predictions Min            52.54113
V Predictions Mean           1152.7621
V Predictions Std            173.01787
V Predictions Max            1311.9452
V Predictions Min            64.4051
Log Pis Mean                 -0.29023284
Log Pis Std                  2.8385375
Log Pis Max                  11.991003
Log Pis Min                  -8.260401
Policy mu Mean               -0.005342989
Policy mu Std                0.6206598
Policy mu Max                2.1993842
Policy mu Min                -2.1268022
Policy log std Mean          -0.9459209
Policy log std Std           0.26233363
Policy log std Max           -0.15573788
Policy log std Min           -3.0363898
Z mean eval                  0.9865834
Z variance eval              0.018344972
total_rewards                [3057.9203605   140.54037118 3211.95101493 3135.71297864 3168.14763475
 1325.61360319 3108.98384778 3321.64088752 1118.9988716  3220.6140275 ]
total_rewards_mean           2481.0123597592424
total_rewards_std            1099.2603532250944
total_rewards_max            3321.6408875182387
total_rewards_min            140.54037118199045
Number of train steps total  354000
Number of env steps total    1772000
Number of rollouts total     0
Train Time (s)               44.393518100026995
(Previous) Eval Time (s)     18.85900485003367
Sample Time (s)              22.917145897634327
Epoch Time (s)               86.169668847695
Total Train Time (s)         33955.46837827796
Epoch                        353
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:55:14.687354 UTC | [2020_01_10_11_29_18] Iteration #353 | Epoch Duration: 95.03382420539856
2020-01-10 20:55:14.687490 UTC | [2020_01_10_11_29_18] Iteration #353 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98804873
Z variance train             0.018382935
KL Divergence                20.118544
KL Loss                      2.0118544
QF Loss                      856.97144
VF Loss                      1486.2856
Policy Loss                  -1174.554
Q Predictions Mean           1172.8423
Q Predictions Std            186.5733
Q Predictions Max            1366.2427
Q Predictions Min            17.928112
V Predictions Mean           1165.894
V Predictions Std            194.83519
V Predictions Max            1370.7533
V Predictions Min            13.550033
Log Pis Mean                 -0.1478613
Log Pis Std                  2.6100845
Log Pis Max                  8.870703
Log Pis Min                  -6.99136
Policy mu Mean               -0.05978428
Policy mu Std                0.61464053
Policy mu Max                2.091769
Policy mu Min                -2.349431
Policy log std Mean          -0.9724608
Policy log std Std           0.24666703
Policy log std Max           -0.2624398
Policy log std Min           -2.4180157
Z mean eval                  0.99986345
Z variance eval              0.01706881
total_rewards                [  -5.47693067 3025.99865722 1127.97451501  879.81909942 3111.22129609
 2104.27515883  271.30389142  468.90599495 3150.21686168   91.73774684]
total_rewards_mean           1422.5976290778258
total_rewards_std            1236.8790766518885
total_rewards_max            3150.2168616803
total_rewards_min            -5.476930666164185
Number of train steps total  355000
Number of env steps total    1777000
Number of rollouts total     0
Train Time (s)               44.17389751179144
(Previous) Eval Time (s)     27.722931607160717
Sample Time (s)              23.04053886793554
Epoch Time (s)               94.9373679868877
Total Train Time (s)         34043.52678053407
Epoch                        354
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:56:42.751273 UTC | [2020_01_10_11_29_18] Iteration #354 | Epoch Duration: 88.06366014480591
2020-01-10 20:56:42.751491 UTC | [2020_01_10_11_29_18] Iteration #354 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99955
Z variance train             0.017058399
KL Divergence                20.855413
KL Loss                      2.0855415
QF Loss                      1787.103
VF Loss                      289.569
Policy Loss                  -1149.4822
Q Predictions Mean           1149.3052
Q Predictions Std            249.04399
Q Predictions Max            1339.4069
Q Predictions Min            12.080088
V Predictions Mean           1159.3649
V Predictions Std            250.72025
V Predictions Max            1342.6145
V Predictions Min            6.6328964
Log Pis Mean                 -0.24826106
Log Pis Std                  2.577401
Log Pis Max                  7.724289
Log Pis Min                  -7.2426434
Policy mu Mean               -0.037932947
Policy mu Std                0.5985862
Policy mu Max                2.3893225
Policy mu Min                -2.1630821
Policy log std Mean          -0.9716548
Policy log std Std           0.24266578
Policy log std Max           -0.116547704
Policy log std Min           -2.0780416
Z mean eval                  1.0114782
Z variance eval              0.009657497
total_rewards                [2943.7327288  3241.76406672 1073.39503848 3255.3514743  3037.83332033
 3110.6171051  1884.60550316 1308.63332344  697.48108734 3104.60783736]
total_rewards_mean           2365.802148501709
total_rewards_std            961.6437770585678
total_rewards_max            3255.35147430472
total_rewards_min            697.481087338663
Number of train steps total  356000
Number of env steps total    1782000
Number of rollouts total     0
Train Time (s)               43.70000957418233
(Previous) Eval Time (s)     20.848978815134615
Sample Time (s)              23.45701548224315
Epoch Time (s)               88.0060038715601
Total Train Time (s)         34140.55671188235
Epoch                        355
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:58:19.783510 UTC | [2020_01_10_11_29_18] Iteration #355 | Epoch Duration: 97.03186631202698
2020-01-10 20:58:19.783646 UTC | [2020_01_10_11_29_18] Iteration #355 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0102895
Z variance train             0.00969127
KL Divergence                21.458057
KL Loss                      2.1458058
QF Loss                      670.74475
VF Loss                      321.1344
Policy Loss                  -1150.4313
Q Predictions Mean           1150.1111
Q Predictions Std            253.84889
Q Predictions Max            1336.5698
Q Predictions Min            23.813513
V Predictions Mean           1153.584
V Predictions Std            252.92474
V Predictions Max            1354.586
V Predictions Min            16.354332
Log Pis Mean                 -0.4630471
Log Pis Std                  2.8103874
Log Pis Max                  10.805505
Log Pis Min                  -9.601484
Policy mu Mean               0.024550807
Policy mu Std                0.60367835
Policy mu Max                2.3376617
Policy mu Min                -2.078549
Policy log std Mean          -0.9477139
Policy log std Std           0.29164803
Policy log std Max           -0.0010551214
Policy log std Min           -2.6058192
Z mean eval                  1.0101277
Z variance eval              0.012241071
total_rewards                [2802.28731672 1224.23024107 2849.92776712 1552.50871175 2947.38682473
  194.55314558 2956.21377709 1587.8341612  3268.76902979 2877.0783842 ]
total_rewards_mean           2226.0789359255423
total_rewards_std            963.1946540590591
total_rewards_max            3268.769029786614
total_rewards_min            194.55314558496588
Number of train steps total  357000
Number of env steps total    1787000
Number of rollouts total     0
Train Time (s)               43.96652464289218
(Previous) Eval Time (s)     29.874606611207128
Sample Time (s)              23.056931357830763
Epoch Time (s)               96.89806261193007
Total Train Time (s)         34236.115369798616
Epoch                        356
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:59:55.345950 UTC | [2020_01_10_11_29_18] Iteration #356 | Epoch Duration: 95.56219410896301
2020-01-10 20:59:55.346128 UTC | [2020_01_10_11_29_18] Iteration #356 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0112298
Z variance train             0.012237936
KL Divergence                21.73648
KL Loss                      2.173648
QF Loss                      872.35364
VF Loss                      140.99564
Policy Loss                  -1161.0692
Q Predictions Mean           1161.8931
Q Predictions Std            221.73337
Q Predictions Max            1343.0013
Q Predictions Min            -14.941768
V Predictions Mean           1160.1897
V Predictions Std            220.61917
V Predictions Max            1342.1714
V Predictions Min            0.106140316
Log Pis Mean                 -0.2794347
Log Pis Std                  2.7746212
Log Pis Max                  13.596899
Log Pis Min                  -9.388226
Policy mu Mean               0.026865374
Policy mu Std                0.62856644
Policy mu Max                2.2873282
Policy mu Min                -2.2382202
Policy log std Mean          -0.91768205
Policy log std Std           0.23606023
Policy log std Max           0.05161798
Policy log std Min           -2.023583
Z mean eval                  0.9883293
Z variance eval              0.0066601736
total_rewards                [ 657.33834495 1133.28024195 2075.0106945   362.82914975 3258.66916693
 3270.31777439 3193.62726795 1839.17370787 2248.84811609 3221.46269172]
total_rewards_mean           2126.0557156090176
total_rewards_std            1062.236366570993
total_rewards_max            3270.3177743858364
total_rewards_min            362.82914974572276
Number of train steps total  358000
Number of env steps total    1792000
Number of rollouts total     0
Train Time (s)               44.66694943001494
(Previous) Eval Time (s)     28.538495126646012
Sample Time (s)              22.555179321672767
Epoch Time (s)               95.76062387833372
Total Train Time (s)         34325.97669001063
Epoch                        357
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:01:25.210424 UTC | [2020_01_10_11_29_18] Iteration #357 | Epoch Duration: 89.86416363716125
2020-01-10 21:01:25.210578 UTC | [2020_01_10_11_29_18] Iteration #357 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9887964
Z variance train             0.0066885995
KL Divergence                22.27896
KL Loss                      2.227896
QF Loss                      864.4512
VF Loss                      164.18433
Policy Loss                  -1150.4152
Q Predictions Mean           1149.4663
Q Predictions Std            237.02962
Q Predictions Max            1320.0715
Q Predictions Min            1.6270907
V Predictions Mean           1154.553
V Predictions Std            239.67639
V Predictions Max            1332.7017
V Predictions Min            8.287566
Log Pis Mean                 0.06680177
Log Pis Std                  2.5985265
Log Pis Max                  10.738276
Log Pis Min                  -6.48865
Policy mu Mean               0.0018440657
Policy mu Std                0.6035973
Policy mu Max                2.797678
Policy mu Min                -3.1714733
Policy log std Mean          -0.9612269
Policy log std Std           0.26360008
Policy log std Max           -0.19613105
Policy log std Min           -2.862197
Z mean eval                  1.0122576
Z variance eval              0.0066611953
total_rewards                [3106.79850954 1720.06523519 2274.9342639  1565.10400649 2940.02639489
  894.41861277 2827.04847145  148.789734   1205.90798355 1800.9808862 ]
total_rewards_mean           1848.4074097974612
total_rewards_std            906.9413344908706
total_rewards_max            3106.7985095438275
total_rewards_min            148.78973399917012
Number of train steps total  359000
Number of env steps total    1797000
Number of rollouts total     0
Train Time (s)               44.13909725425765
(Previous) Eval Time (s)     22.641777355223894
Sample Time (s)              21.88691713148728
Epoch Time (s)               88.66779174096882
Total Train Time (s)         34415.04764888808
Epoch                        358
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:02:54.283628 UTC | [2020_01_10_11_29_18] Iteration #358 | Epoch Duration: 89.07292795181274
2020-01-10 21:02:54.283763 UTC | [2020_01_10_11_29_18] Iteration #358 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0143893
Z variance train             0.006652239
KL Divergence                22.066406
KL Loss                      2.2066407
QF Loss                      749.3199
VF Loss                      138.98526
Policy Loss                  -1150.1703
Q Predictions Mean           1150.7213
Q Predictions Std            245.11066
Q Predictions Max            1339.9985
Q Predictions Min            15.245283
V Predictions Mean           1143.3107
V Predictions Std            242.93657
V Predictions Max            1347.6027
V Predictions Min            33.42246
Log Pis Mean                 -0.2934167
Log Pis Std                  2.3791745
Log Pis Max                  7.3549805
Log Pis Min                  -7.4117002
Policy mu Mean               -0.0029207314
Policy mu Std                0.61415035
Policy mu Max                2.192324
Policy mu Min                -2.1349752
Policy log std Mean          -0.93986416
Policy log std Std           0.23125489
Policy log std Max           -0.18508822
Policy log std Min           -1.8241122
Z mean eval                  0.96249217
Z variance eval              0.007681337
total_rewards                [2824.09181904 2624.19967842 2920.43940107 2913.40764752 1919.64154461
 2832.45291185 2913.14717414 2797.3332176  2813.53864002 2915.26947127]
total_rewards_mean           2747.352150552958
total_rewards_std            288.7038437792531
total_rewards_max            2920.439401066964
total_rewards_min            1919.6415446119877
Number of train steps total  360000
Number of env steps total    1802000
Number of rollouts total     0
Train Time (s)               44.02947413595393
(Previous) Eval Time (s)     23.04668302508071
Sample Time (s)              22.03590623382479
Epoch Time (s)               89.11206339485943
Total Train Time (s)         34512.588763711974
Epoch                        359
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:04:31.828774 UTC | [2020_01_10_11_29_18] Iteration #359 | Epoch Duration: 97.54490184783936
2020-01-10 21:04:31.828949 UTC | [2020_01_10_11_29_18] Iteration #359 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9644064
Z variance train             0.0076843672
KL Divergence                22.063173
KL Loss                      2.2063174
QF Loss                      1799.4523
VF Loss                      1601.2246
Policy Loss                  -1160.1652
Q Predictions Mean           1160.0
Q Predictions Std            231.28435
Q Predictions Max            1327.7987
Q Predictions Min            -4.745032
V Predictions Mean           1159.3549
V Predictions Std            236.30072
V Predictions Max            1338.0789
V Predictions Min            -16.04148
Log Pis Mean                 -0.057582427
Log Pis Std                  2.6707034
Log Pis Max                  16.11507
Log Pis Min                  -6.559116
Policy mu Mean               -0.031948067
Policy mu Std                0.6038225
Policy mu Max                2.2526264
Policy mu Min                -2.135149
Policy log std Mean          -0.98999244
Policy log std Std           0.2751244
Policy log std Max           0.31935298
Policy log std Min           -2.9689326
Z mean eval                  0.9689639
Z variance eval              0.02711239
total_rewards                [2659.16579572 3116.71568433  593.20278903 3025.09706218 1929.79946072
  228.81399861  212.3412626  2828.80760202 2166.69809055 1231.4766037 ]
total_rewards_mean           1799.2118349462526
total_rewards_std            1093.2240029909117
total_rewards_max            3116.7156843325006
total_rewards_min            212.34126260462742
Number of train steps total  361000
Number of env steps total    1807000
Number of rollouts total     0
Train Time (s)               44.19461290491745
(Previous) Eval Time (s)     31.479250226169825
Sample Time (s)              23.339200797025114
Epoch Time (s)               99.01306392811239
Total Train Time (s)         34613.44767621765
Epoch                        360
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:06:12.691327 UTC | [2020_01_10_11_29_18] Iteration #360 | Epoch Duration: 100.86225271224976
2020-01-10 21:06:12.691462 UTC | [2020_01_10_11_29_18] Iteration #360 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9668128
Z variance train             0.027055528
KL Divergence                20.466763
KL Loss                      2.0466764
QF Loss                      470.38544
VF Loss                      230.70961
Policy Loss                  -1146.9868
Q Predictions Mean           1146.6304
Q Predictions Std            234.62842
Q Predictions Max            1340.2019
Q Predictions Min            14.492961
V Predictions Mean           1157.4435
V Predictions Std            236.86044
V Predictions Max            1346.8802
V Predictions Min            12.063171
Log Pis Mean                 -0.41728443
Log Pis Std                  2.6545086
Log Pis Max                  10.732298
Log Pis Min                  -8.116928
Policy mu Mean               0.025008045
Policy mu Std                0.604096
Policy mu Max                2.4176366
Policy mu Min                -2.3366947
Policy log std Mean          -0.919466
Policy log std Std           0.22069736
Policy log std Max           -0.075695574
Policy log std Min           -1.8778758
Z mean eval                  1.0097349
Z variance eval              0.019321412
total_rewards                [ 898.89089359 1126.35581284 1272.07251635  167.8728323  3371.45415352
 1032.38963212 1092.36632086 1395.37448793   70.42004591 3308.43436264]
total_rewards_mean           1373.5631058071856
total_rewards_std            1066.7632582320975
total_rewards_max            3371.454153523437
total_rewards_min            70.4200459110137
Number of train steps total  362000
Number of env steps total    1812000
Number of rollouts total     0
Train Time (s)               43.69911431521177
(Previous) Eval Time (s)     33.32818246586248
Sample Time (s)              23.141901032067835
Epoch Time (s)               100.16919781314209
Total Train Time (s)         34705.122450513765
Epoch                        361
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:07:44.368462 UTC | [2020_01_10_11_29_18] Iteration #361 | Epoch Duration: 91.67688393592834
2020-01-10 21:07:44.368602 UTC | [2020_01_10_11_29_18] Iteration #361 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0075287
Z variance train             0.019333161
KL Divergence                20.377434
KL Loss                      2.0377433
QF Loss                      669.1051
VF Loss                      342.2008
Policy Loss                  -1156.8604
Q Predictions Mean           1158.5718
Q Predictions Std            258.90018
Q Predictions Max            1349.3344
Q Predictions Min            -14.494138
V Predictions Mean           1153.2202
V Predictions Std            252.01402
V Predictions Max            1344.8615
V Predictions Min            9.539013
Log Pis Mean                 -0.10976231
Log Pis Std                  2.6734629
Log Pis Max                  9.015696
Log Pis Min                  -7.938123
Policy mu Mean               0.0040392894
Policy mu Std                0.6263701
Policy mu Max                2.6789572
Policy mu Min                -2.1401968
Policy log std Mean          -0.95184326
Policy log std Std           0.2690813
Policy log std Max           0.021003366
Policy log std Min           -2.1862605
Z mean eval                  0.971091
Z variance eval              0.012293732
total_rewards                [ -30.00870726  401.80957004 3159.92179163 -272.62227482 2974.517146
 1097.74711195 3253.57532174 3093.89142599 3086.5119118  2979.16976532]
total_rewards_mean           1974.4513062389542
total_rewards_std            1408.897663277135
total_rewards_max            3253.5753217364254
total_rewards_min            -272.62227481644453
Number of train steps total  363000
Number of env steps total    1817000
Number of rollouts total     0
Train Time (s)               43.385378372855484
(Previous) Eval Time (s)     24.835614524781704
Sample Time (s)              23.138079666066915
Epoch Time (s)               91.3590725637041
Total Train Time (s)         34802.133258902
Epoch                        362
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:09:21.383144 UTC | [2020_01_10_11_29_18] Iteration #362 | Epoch Duration: 97.01443219184875
2020-01-10 21:09:21.383320 UTC | [2020_01_10_11_29_18] Iteration #362 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97139776
Z variance train             0.012278992
KL Divergence                21.28782
KL Loss                      2.128782
QF Loss                      1007.5189
VF Loss                      182.82356
Policy Loss                  -1152.1836
Q Predictions Mean           1149.4553
Q Predictions Std            285.13083
Q Predictions Max            1349.4414
Q Predictions Min            -5.952634
V Predictions Mean           1142.4222
V Predictions Std            279.44083
V Predictions Max            1331.4014
V Predictions Min            -15.630553
Log Pis Mean                 -0.099224485
Log Pis Std                  2.7420661
Log Pis Max                  14.958281
Log Pis Min                  -7.9804163
Policy mu Mean               -0.025863333
Policy mu Std                0.6217599
Policy mu Max                3.4053512
Policy mu Min                -1.9907126
Policy log std Mean          -0.92891943
Policy log std Std           0.26490566
Policy log std Max           -0.0015279651
Policy log std Min           -2.5015612
Z mean eval                  0.9913682
Z variance eval              0.012364192
total_rewards                [3230.3355141  3227.7612715  2948.48578401 1935.33437039 3225.32759042
 1687.69288708 3192.72782863 3187.1244497  3148.88379076 3278.45911273]
total_rewards_mean           2906.213259929307
total_rewards_std            556.5900335864978
total_rewards_max            3278.459112725205
total_rewards_min            1687.692887075113
Number of train steps total  364000
Number of env steps total    1822000
Number of rollouts total     0
Train Time (s)               43.88010118575767
(Previous) Eval Time (s)     30.49070888198912
Sample Time (s)              22.384777429979295
Epoch Time (s)               96.75558749772608
Total Train Time (s)         34899.62249661144
Epoch                        363
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:10:58.877431 UTC | [2020_01_10_11_29_18] Iteration #363 | Epoch Duration: 97.49396967887878
2020-01-10 21:10:58.877624 UTC | [2020_01_10_11_29_18] Iteration #363 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99248827
Z variance train             0.01232362
KL Divergence                21.071278
KL Loss                      2.107128
QF Loss                      1004.5692
VF Loss                      78.97713
Policy Loss                  -1165.4674
Q Predictions Mean           1164.7002
Q Predictions Std            229.90558
Q Predictions Max            1344.1315
Q Predictions Min            15.688518
V Predictions Mean           1161.3718
V Predictions Std            229.93001
V Predictions Max            1340.3368
V Predictions Min            -4.420158
Log Pis Mean                 -0.27183998
Log Pis Std                  2.500378
Log Pis Max                  5.519519
Log Pis Min                  -7.388581
Policy mu Mean               -0.008344181
Policy mu Std                0.60950905
Policy mu Max                2.35274
Policy mu Min                -1.9254532
Policy log std Mean          -0.9472234
Policy log std Std           0.25958663
Policy log std Max           0.17288035
Policy log std Min           -2.070016
Z mean eval                  0.98323995
Z variance eval              0.009580921
total_rewards                [1462.8612321  3049.55837039 1115.02349716 3211.27225528 2209.13872756
 3194.73633705 1016.3518814  3110.33364794 3178.48029674  390.79247992]
total_rewards_mean           2193.8548725531823
total_rewards_std            1044.7277447056165
total_rewards_max            3211.2722552753576
total_rewards_min            390.79247991949904
Number of train steps total  365000
Number of env steps total    1827000
Number of rollouts total     0
Train Time (s)               45.48884799005464
(Previous) Eval Time (s)     31.228846594225615
Sample Time (s)              23.184064998291433
Epoch Time (s)               99.90175958257169
Total Train Time (s)         34991.96791888634
Epoch                        364
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:12:31.227452 UTC | [2020_01_10_11_29_18] Iteration #364 | Epoch Duration: 92.34969353675842
2020-01-10 21:12:31.227585 UTC | [2020_01_10_11_29_18] Iteration #364 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9842202
Z variance train             0.009565386
KL Divergence                21.721386
KL Loss                      2.1721387
QF Loss                      528.8652
VF Loss                      146.35393
Policy Loss                  -1180.0963
Q Predictions Mean           1179.627
Q Predictions Std            215.20462
Q Predictions Max            1332.0088
Q Predictions Min            30.932697
V Predictions Mean           1177.6198
V Predictions Std            214.78783
V Predictions Max            1334.4044
V Predictions Min            20.60731
Log Pis Mean                 -0.24015653
Log Pis Std                  2.3891783
Log Pis Max                  6.4179277
Log Pis Min                  -7.2455807
Policy mu Mean               -0.0060081338
Policy mu Std                0.5839364
Policy mu Max                1.9992231
Policy mu Min                -1.7817191
Policy log std Mean          -0.9731493
Policy log std Std           0.24342701
Policy log std Max           0.0075435042
Policy log std Min           -2.2754993
Z mean eval                  0.9895239
Z variance eval              0.011451306
total_rewards                [2196.73707836 2285.84054189 2646.12456031 2663.70193576 1269.0093242
 1119.75406206 1156.67933615 2672.45510012 2038.19343854  768.20716839]
total_rewards_mean           1881.6702545785283
total_rewards_std            694.9608921171421
total_rewards_max            2672.4551001228806
total_rewards_min            768.2071683935212
Number of train steps total  366000
Number of env steps total    1832000
Number of rollouts total     0
Train Time (s)               44.39825915498659
(Previous) Eval Time (s)     23.676531188189983
Sample Time (s)              23.416132521349937
Epoch Time (s)               91.49092286452651
Total Train Time (s)         35084.88431451423
Epoch                        365
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:14:04.146084 UTC | [2020_01_10_11_29_18] Iteration #365 | Epoch Duration: 92.91840052604675
2020-01-10 21:14:04.146219 UTC | [2020_01_10_11_29_18] Iteration #365 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98922336
Z variance train             0.011380708
KL Divergence                21.062416
KL Loss                      2.1062417
QF Loss                      624.0821
VF Loss                      153.33893
Policy Loss                  -1166.4037
Q Predictions Mean           1164.5432
Q Predictions Std            218.4994
Q Predictions Max            1341.4054
Q Predictions Min            39.926712
V Predictions Mean           1162.0488
V Predictions Std            216.15787
V Predictions Max            1323.749
V Predictions Min            30.787687
Log Pis Mean                 -0.16140257
Log Pis Std                  2.8626747
Log Pis Max                  17.162506
Log Pis Min                  -8.8024
Policy mu Mean               0.04889699
Policy mu Std                0.62052613
Policy mu Max                3.2885015
Policy mu Min                -2.4527607
Policy log std Mean          -0.9523093
Policy log std Std           0.23127231
Policy log std Max           -0.0074860454
Policy log std Min           -2.3378012
Z mean eval                  0.97347677
Z variance eval              0.022912761
total_rewards                [ 674.69457282 2985.09736259 2275.99265839 2912.93097861 3269.56804576
 2191.31689884 3111.66396646 2969.16937181 3007.92960906 2197.13201133]
total_rewards_mean           2559.5495475677517
total_rewards_std            733.7427067696477
total_rewards_max            3269.5680457608387
total_rewards_min            674.6945728162439
Number of train steps total  367000
Number of env steps total    1837000
Number of rollouts total     0
Train Time (s)               44.23395213764161
(Previous) Eval Time (s)     25.103752525057644
Sample Time (s)              22.110922150779516
Epoch Time (s)               91.44862681347877
Total Train Time (s)         35179.4660501685
Epoch                        366
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:15:38.731144 UTC | [2020_01_10_11_29_18] Iteration #366 | Epoch Duration: 94.58481574058533
2020-01-10 21:15:38.731306 UTC | [2020_01_10_11_29_18] Iteration #366 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9749956
Z variance train             0.022885565
KL Divergence                19.509346
KL Loss                      1.9509346
QF Loss                      1412.2505
VF Loss                      156.39035
Policy Loss                  -1161.1365
Q Predictions Mean           1163.3357
Q Predictions Std            216.55063
Q Predictions Max            1337.7346
Q Predictions Min            28.769573
V Predictions Mean           1168.1243
V Predictions Std            218.58769
V Predictions Max            1326.1145
V Predictions Min            24.71265
Log Pis Mean                 0.20333734
Log Pis Std                  2.7032704
Log Pis Max                  10.096554
Log Pis Min                  -8.7051525
Policy mu Mean               -0.027461302
Policy mu Std                0.6324044
Policy mu Max                2.0831196
Policy mu Min                -2.4393227
Policy log std Mean          -0.97197545
Policy log std Std           0.24961288
Policy log std Max           0.14074105
Policy log std Min           -2.4508135
Z mean eval                  0.9871276
Z variance eval              0.02049258
total_rewards                [3256.75486298 3330.05843437 3294.39210502 1193.7735659  1064.20827034
 1941.22735688 3412.20178708   68.86683102 3004.79234709 3114.4414504 ]
total_rewards_mean           2368.07170110763
total_rewards_std            1147.7590963809434
total_rewards_max            3412.2017870790987
total_rewards_min            68.86683102142504
Number of train steps total  368000
Number of env steps total    1842000
Number of rollouts total     0
Train Time (s)               44.083407090976834
(Previous) Eval Time (s)     28.239693936891854
Sample Time (s)              22.963171436451375
Epoch Time (s)               95.28627246432006
Total Train Time (s)         35272.40238054143
Epoch                        367
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:17:11.669857 UTC | [2020_01_10_11_29_18] Iteration #367 | Epoch Duration: 92.93843054771423
2020-01-10 21:17:11.669994 UTC | [2020_01_10_11_29_18] Iteration #367 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9854046
Z variance train             0.020452278
KL Divergence                20.081669
KL Loss                      2.008167
QF Loss                      1113.9852
VF Loss                      211.81569
Policy Loss                  -1166.9039
Q Predictions Mean           1164.9762
Q Predictions Std            220.08751
Q Predictions Max            1345.8761
Q Predictions Min            -0.04404843
V Predictions Mean           1168.6326
V Predictions Std            216.14165
V Predictions Max            1330.8741
V Predictions Min            16.044744
Log Pis Mean                 -0.4225951
Log Pis Std                  2.6876683
Log Pis Max                  8.779755
Log Pis Min                  -10.46506
Policy mu Mean               0.07927269
Policy mu Std                0.6114532
Policy mu Max                2.4750493
Policy mu Min                -2.0615616
Policy log std Mean          -0.94409895
Policy log std Std           0.25718725
Policy log std Max           0.0088889
Policy log std Min           -2.2125397
Z mean eval                  1.0021087
Z variance eval              0.020591442
total_rewards                [ -34.41242049 3039.7327545  3083.92090068 2833.02511943 3038.30601404
 3084.69129275 2850.3528317  3249.01788561 3248.29471044 2969.43520269]
total_rewards_mean           2736.2364291360423
total_rewards_std            932.9564385717842
total_rewards_max            3249.017885614321
total_rewards_min            -34.412420486364766
Number of train steps total  369000
Number of env steps total    1847000
Number of rollouts total     0
Train Time (s)               44.4317669281736
(Previous) Eval Time (s)     25.89160890970379
Sample Time (s)              22.411716116126627
Epoch Time (s)               92.73509195400402
Total Train Time (s)         35368.07112216903
Epoch                        368
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:18:47.345259 UTC | [2020_01_10_11_29_18] Iteration #368 | Epoch Duration: 95.6750955581665
2020-01-10 21:18:47.345628 UTC | [2020_01_10_11_29_18] Iteration #368 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0019782
Z variance train             0.020575244
KL Divergence                20.30368
KL Loss                      2.030368
QF Loss                      581.2317
VF Loss                      353.28497
Policy Loss                  -1173.9552
Q Predictions Mean           1171.1799
Q Predictions Std            248.0701
Q Predictions Max            1348.6802
Q Predictions Min            -13.07742
V Predictions Mean           1168.0286
V Predictions Std            248.28683
V Predictions Max            1342.175
V Predictions Min            13.835625
Log Pis Mean                 -0.046724625
Log Pis Std                  2.7391481
Log Pis Max                  12.8610525
Log Pis Min                  -7.9514723
Policy mu Mean               0.04246836
Policy mu Std                0.6052
Policy mu Max                2.8367407
Policy mu Min                -1.8606694
Policy log std Mean          -0.9650453
Policy log std Std           0.26473796
Policy log std Max           -0.15229106
Policy log std Min           -3.0236754
Z mean eval                  0.9818333
Z variance eval              0.016046267
total_rewards                [3307.79444223 1555.55337193 2099.58946794 3229.81579468 3062.3362408
 3121.02151321 3339.3783444   707.66682165 3273.52688808 2361.38355724]
total_rewards_mean           2605.8066442162008
total_rewards_std            858.0199812683053
total_rewards_max            3339.3783443963102
total_rewards_min            707.6668216460542
Number of train steps total  370000
Number of env steps total    1852000
Number of rollouts total     0
Train Time (s)               44.290584532078356
(Previous) Eval Time (s)     28.831327265128493
Sample Time (s)              22.88945600995794
Epoch Time (s)               96.01136780716479
Total Train Time (s)         35464.11841792986
Epoch                        369
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:20:23.399581 UTC | [2020_01_10_11_29_18] Iteration #369 | Epoch Duration: 96.05367851257324
2020-01-10 21:20:23.399873 UTC | [2020_01_10_11_29_18] Iteration #369 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9818838
Z variance train             0.01602418
KL Divergence                20.685852
KL Loss                      2.0685852
QF Loss                      1575.4215
VF Loss                      264.81647
Policy Loss                  -1182.8275
Q Predictions Mean           1179.6746
Q Predictions Std            219.90407
Q Predictions Max            1406.8507
Q Predictions Min            -10.792902
V Predictions Mean           1173.4298
V Predictions Std            215.17593
V Predictions Max            1388.9141
V Predictions Min            -19.725931
Log Pis Mean                 -0.30081892
Log Pis Std                  2.84233
Log Pis Max                  16.411562
Log Pis Min                  -6.5108128
Policy mu Mean               -0.014766769
Policy mu Std                0.61218214
Policy mu Max                2.6571991
Policy mu Min                -3.462468
Policy log std Mean          -0.96634495
Policy log std Std           0.24811187
Policy log std Max           -0.00631994
Policy log std Min           -2.6257246
Z mean eval                  0.9854269
Z variance eval              0.012004663
total_rewards                [3143.92966385 -110.3828069    82.93364584  905.34085211 3349.13585643
  305.05866189 2944.36071083 3166.32809623  757.49264567 2470.89347223]
total_rewards_mean           1701.5090798175274
total_rewards_std            1358.5080675591284
total_rewards_max            3349.135856434036
total_rewards_min            -110.38280689863149
Number of train steps total  371000
Number of env steps total    1857000
Number of rollouts total     0
Train Time (s)               44.178651462774724
(Previous) Eval Time (s)     28.873398600611836
Sample Time (s)              23.42894795536995
Epoch Time (s)               96.48099801875651
Total Train Time (s)         35565.58851587074
Epoch                        370
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:22:04.873003 UTC | [2020_01_10_11_29_18] Iteration #370 | Epoch Duration: 101.47291254997253
2020-01-10 21:22:04.873173 UTC | [2020_01_10_11_29_18] Iteration #370 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98486423
Z variance train             0.012016292
KL Divergence                21.48423
KL Loss                      2.148423
QF Loss                      1575.7681
VF Loss                      139.86482
Policy Loss                  -1168.0576
Q Predictions Mean           1168.0592
Q Predictions Std            287.41617
Q Predictions Max            1362.2668
Q Predictions Min            -33.466476
V Predictions Mean           1163.3705
V Predictions Std            287.74637
V Predictions Max            1366.0713
V Predictions Min            -21.397882
Log Pis Mean                 0.032878637
Log Pis Std                  2.9513595
Log Pis Max                  17.02427
Log Pis Min                  -8.790018
Policy mu Mean               0.015495047
Policy mu Std                0.6379064
Policy mu Max                2.9593332
Policy mu Min                -2.2423306
Policy log std Mean          -0.973619
Policy log std Std           0.26414067
Policy log std Max           -0.10619527
Policy log std Min           -2.7749543
Z mean eval                  1.0049479
Z variance eval              0.010529471
total_rewards                [1791.93889958 3006.28373799 3227.62727867 2913.57423536  106.75660132
 2894.44955516 3003.56449885 2987.2751709  2712.90804486    9.16108103]
total_rewards_mean           2265.3539103712023
total_rewards_std            1163.2453759068549
total_rewards_max            3227.6272786679874
total_rewards_min            9.16108103115076
Number of train steps total  372000
Number of env steps total    1862000
Number of rollouts total     0
Train Time (s)               44.06882970407605
(Previous) Eval Time (s)     33.865084529388696
Sample Time (s)              22.302722160704434
Epoch Time (s)               100.23663639416918
Total Train Time (s)         35659.38950289553
Epoch                        371
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:23:38.676523 UTC | [2020_01_10_11_29_18] Iteration #371 | Epoch Duration: 93.80322623252869
2020-01-10 21:23:38.676661 UTC | [2020_01_10_11_29_18] Iteration #371 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0040848
Z variance train             0.01051907
KL Divergence                21.48835
KL Loss                      2.148835
QF Loss                      816.0405
VF Loss                      344.6661
Policy Loss                  -1169.6661
Q Predictions Mean           1169.5369
Q Predictions Std            239.98268
Q Predictions Max            1383.4844
Q Predictions Min            -48.344395
V Predictions Mean           1160.2568
V Predictions Std            233.76065
V Predictions Max            1357.9681
V Predictions Min            -8.99698
Log Pis Mean                 0.04545643
Log Pis Std                  2.5191731
Log Pis Max                  9.628017
Log Pis Min                  -7.539407
Policy mu Mean               0.021258254
Policy mu Std                0.62511295
Policy mu Max                2.185356
Policy mu Min                -2.0140443
Policy log std Mean          -0.96840984
Policy log std Std           0.25613856
Policy log std Max           -0.17004383
Policy log std Min           -2.6975365
Z mean eval                  1.012046
Z variance eval              0.010608213
total_rewards                [3196.89225108 3139.71357765 3091.59385146 3243.91968882 1648.17058132
 2513.19115231 1526.6343536   489.85740798  861.28606724 1158.37523258]
total_rewards_mean           2086.963416402898
total_rewards_std            1014.4723516427676
total_rewards_max            3243.919688817429
total_rewards_min            489.8574079767279
Number of train steps total  373000
Number of env steps total    1867000
Number of rollouts total     0
Train Time (s)               44.99206201499328
(Previous) Eval Time (s)     27.431444344110787
Sample Time (s)              23.008250741288066
Epoch Time (s)               95.43175710039213
Total Train Time (s)         35755.80718429107
Epoch                        372
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:25:15.096510 UTC | [2020_01_10_11_29_18] Iteration #372 | Epoch Duration: 96.41974258422852
2020-01-10 21:25:15.096654 UTC | [2020_01_10_11_29_18] Iteration #372 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0118849
Z variance train             0.010621384
KL Divergence                21.735085
KL Loss                      2.1735084
QF Loss                      670.61597
VF Loss                      254.62146
Policy Loss                  -1165.1545
Q Predictions Mean           1165.3904
Q Predictions Std            263.00818
Q Predictions Max            1389.2241
Q Predictions Min            -15.264496
V Predictions Mean           1174.7887
V Predictions Std            263.27026
V Predictions Max            1397.5349
V Predictions Min            4.2931
Log Pis Mean                 -0.62985766
Log Pis Std                  2.3433688
Log Pis Max                  7.133272
Log Pis Min                  -7.216936
Policy mu Mean               -0.01268395
Policy mu Std                0.5580279
Policy mu Max                2.5747948
Policy mu Min                -1.9568803
Policy log std Mean          -0.9720809
Policy log std Std           0.25438446
Policy log std Max           -0.068341196
Policy log std Min           -2.2689605
Z mean eval                  0.9966958
Z variance eval              0.016691778
total_rewards                [3175.80701724 3111.83900255 1304.98202297    7.66925856  835.18718547
 3486.03478984   64.47674215  502.64186562 3586.15107687  506.37421888]
total_rewards_mean           1658.1163180151627
total_rewards_std            1421.3552873040717
total_rewards_max            3586.1510768728567
total_rewards_min            7.669258555662912
Number of train steps total  374000
Number of env steps total    1872000
Number of rollouts total     0
Train Time (s)               44.042221063748
(Previous) Eval Time (s)     28.419186314102262
Sample Time (s)              22.504345894325525
Epoch Time (s)               94.96575327217579
Total Train Time (s)         35844.96755156992
Epoch                        373
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:26:44.261109 UTC | [2020_01_10_11_29_18] Iteration #373 | Epoch Duration: 89.1643135547638
2020-01-10 21:26:44.261337 UTC | [2020_01_10_11_29_18] Iteration #373 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99464434
Z variance train             0.016609225
KL Divergence                21.379389
KL Loss                      2.137939
QF Loss                      1085.3032
VF Loss                      217.19577
Policy Loss                  -1171.57
Q Predictions Mean           1169.5789
Q Predictions Std            242.23296
Q Predictions Max            1364.9424
Q Predictions Min            19.407976
V Predictions Mean           1161.2075
V Predictions Std            241.17172
V Predictions Max            1349.0854
V Predictions Min            16.17738
Log Pis Mean                 -0.26876074
Log Pis Std                  2.5800836
Log Pis Max                  6.5275984
Log Pis Min                  -8.870504
Policy mu Mean               -0.04883428
Policy mu Std                0.58153164
Policy mu Max                2.2258642
Policy mu Min                -2.2194958
Policy log std Mean          -0.96230644
Policy log std Std           0.25645435
Policy log std Max           0.059996426
Policy log std Min           -2.185518
Z mean eval                  0.9785778
Z variance eval              0.014261643
total_rewards                [3123.41375401  943.16427897 1675.63581447 3235.03350428 3224.24011888
 1477.22288507 2038.34867344 3096.18301174 1110.06361783 2012.55450999]
total_rewards_mean           2193.586016868394
total_rewards_std            860.3497313765337
total_rewards_max            3235.0335042763686
total_rewards_min            943.1642789684064
Number of train steps total  375000
Number of env steps total    1877000
Number of rollouts total     0
Train Time (s)               45.07276581320912
(Previous) Eval Time (s)     22.617477627005428
Sample Time (s)              22.36936115194112
Epoch Time (s)               90.05960459215567
Total Train Time (s)         35938.81969433883
Epoch                        374
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:28:18.116779 UTC | [2020_01_10_11_29_18] Iteration #374 | Epoch Duration: 93.8552770614624
2020-01-10 21:28:18.116948 UTC | [2020_01_10_11_29_18] Iteration #374 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9792473
Z variance train             0.01428805
KL Divergence                21.472244
KL Loss                      2.1472244
QF Loss                      668.0697
VF Loss                      158.40799
Policy Loss                  -1195.0273
Q Predictions Mean           1195.336
Q Predictions Std            221.37605
Q Predictions Max            1375.2727
Q Predictions Min            24.991398
V Predictions Mean           1188.1292
V Predictions Std            221.26068
V Predictions Max            1360.7811
V Predictions Min            16.17939
Log Pis Mean                 -0.32775122
Log Pis Std                  2.580739
Log Pis Max                  7.0467553
Log Pis Min                  -7.2256246
Policy mu Mean               -0.006937473
Policy mu Std                0.5823653
Policy mu Max                1.9338824
Policy mu Min                -2.0290906
Policy log std Mean          -0.96858394
Policy log std Std           0.24869916
Policy log std Max           -0.0053957105
Policy log std Min           -2.086876
Z mean eval                  0.98294795
Z variance eval              0.012619654
total_rewards                [ 268.35888683 1158.74145466 1459.0164148  2975.73704391 3209.76485951
 3081.2687293  3298.8763399  1120.09662281 3107.41322926 3292.13833888]
total_rewards_mean           2297.1411919853226
total_rewards_std            1098.09208859768
total_rewards_max            3298.876339900463
total_rewards_min            268.35888683374327
Number of train steps total  376000
Number of env steps total    1882000
Number of rollouts total     0
Train Time (s)               44.17521271016449
(Previous) Eval Time (s)     26.412926968652755
Sample Time (s)              22.168314452283084
Epoch Time (s)               92.75645413110033
Total Train Time (s)         36030.36377296224
Epoch                        375
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:29:49.666813 UTC | [2020_01_10_11_29_18] Iteration #375 | Epoch Duration: 91.54973363876343
2020-01-10 21:29:49.666996 UTC | [2020_01_10_11_29_18] Iteration #375 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9840907
Z variance train             0.012621902
KL Divergence                22.436193
KL Loss                      2.2436194
QF Loss                      569.64496
VF Loss                      149.29568
Policy Loss                  -1178.1736
Q Predictions Mean           1180.1606
Q Predictions Std            225.3837
Q Predictions Max            1385.0519
Q Predictions Min            7.2377872
V Predictions Mean           1180.9036
V Predictions Std            224.08748
V Predictions Max            1394.5693
V Predictions Min            4.501813
Log Pis Mean                 0.026547078
Log Pis Std                  2.7531242
Log Pis Max                  11.242268
Log Pis Min                  -7.0088882
Policy mu Mean               0.06761536
Policy mu Std                0.6377921
Policy mu Max                3.4557085
Policy mu Min                -2.4321105
Policy log std Mean          -0.9505749
Policy log std Std           0.2547183
Policy log std Max           -0.017713428
Policy log std Min           -2.4471357
Z mean eval                  1.0538528
Z variance eval              0.008725907
total_rewards                [1974.61388836  170.24418049 3178.43663515 3004.47489095 3266.75843124
 3187.82006027 3190.86729319 3289.39434598 3224.95810085 3310.49499463]
total_rewards_mean           2779.8062821115823
total_rewards_std            947.6059695358383
total_rewards_max            3310.494994625784
total_rewards_min            170.24418049422783
Number of train steps total  377000
Number of env steps total    1887000
Number of rollouts total     0
Train Time (s)               44.32118490571156
(Previous) Eval Time (s)     25.20596351986751
Sample Time (s)              22.66109760478139
Epoch Time (s)               92.18824603036046
Total Train Time (s)         36128.216709772125
Epoch                        376
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:31:27.529428 UTC | [2020_01_10_11_29_18] Iteration #376 | Epoch Duration: 97.86225819587708
2020-01-10 21:31:27.529750 UTC | [2020_01_10_11_29_18] Iteration #376 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0577391
Z variance train             0.008669816
KL Divergence                22.921995
KL Loss                      2.2921996
QF Loss                      915.91406
VF Loss                      306.86322
Policy Loss                  -1209.7563
Q Predictions Mean           1210.2576
Q Predictions Std            201.2139
Q Predictions Max            1391.9266
Q Predictions Min            13.239322
V Predictions Mean           1210.5397
V Predictions Std            200.49509
V Predictions Max            1389.9723
V Predictions Min            -0.77659357
Log Pis Mean                 -0.13275224
Log Pis Std                  2.815858
Log Pis Max                  12.00736
Log Pis Min                  -11.931107
Policy mu Mean               -0.016116098
Policy mu Std                0.6030524
Policy mu Max                2.6814294
Policy mu Min                -2.6661322
Policy log std Mean          -1.0123202
Policy log std Std           0.28403953
Policy log std Max           -0.20580107
Policy log std Min           -2.9663656
Z mean eval                  1.0180459
Z variance eval              0.009049511
total_rewards                [3439.3599769   488.96833077 3325.79067168 2722.26742216 1115.85940005
  302.06271995 3081.92258388  149.44244257 2225.64941454 2828.81177024]
total_rewards_mean           1968.0134732749127
total_rewards_std            1249.8718162644782
total_rewards_max            3439.3599768982476
total_rewards_min            149.4424425689983
Number of train steps total  378000
Number of env steps total    1892000
Number of rollouts total     0
Train Time (s)               45.076147615443915
(Previous) Eval Time (s)     30.879709789995104
Sample Time (s)              20.79179272102192
Epoch Time (s)               96.74765012646094
Total Train Time (s)         36213.43875738513
Epoch                        377
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:32:52.757853 UTC | [2020_01_10_11_29_18] Iteration #377 | Epoch Duration: 85.22787356376648
2020-01-10 21:32:52.758023 UTC | [2020_01_10_11_29_18] Iteration #377 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0160524
Z variance train             0.009035515
KL Divergence                22.335127
KL Loss                      2.2335126
QF Loss                      12460.289
VF Loss                      235.96045
Policy Loss                  -1171.3646
Q Predictions Mean           1172.0525
Q Predictions Std            261.1214
Q Predictions Max            1393.7748
Q Predictions Min            8.602301
V Predictions Mean           1172.6462
V Predictions Std            259.2859
V Predictions Max            1387.7408
V Predictions Min            -27.591625
Log Pis Mean                 -0.057807595
Log Pis Std                  2.7305057
Log Pis Max                  8.609297
Log Pis Min                  -11.504623
Policy mu Mean               -0.016632047
Policy mu Std                0.6000559
Policy mu Max                2.3068979
Policy mu Min                -2.1583836
Policy log std Mean          -0.981228
Policy log std Std           0.2686624
Policy log std Max           0.019826949
Policy log std Min           -2.3218966
Z mean eval                  1.0012014
Z variance eval              0.0062112967
total_rewards                [ 221.89228579 3064.02980665  279.32402006 1161.56251249 1866.52783663
  304.26831898 1287.94849063 3431.91539573 3319.96145724 2316.46908442]
total_rewards_mean           1725.3899208644193
total_rewards_std            1204.0180023755463
total_rewards_max            3431.9153957301723
total_rewards_min            221.8922857937143
Number of train steps total  379000
Number of env steps total    1897000
Number of rollouts total     0
Train Time (s)               43.92876871628687
(Previous) Eval Time (s)     19.35971690295264
Sample Time (s)              22.32849399931729
Epoch Time (s)               85.6169796185568
Total Train Time (s)         36304.071121521294
Epoch                        378
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:34:23.396115 UTC | [2020_01_10_11_29_18] Iteration #378 | Epoch Duration: 90.63795852661133
2020-01-10 21:34:23.396266 UTC | [2020_01_10_11_29_18] Iteration #378 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0014211
Z variance train             0.006197188
KL Divergence                23.232006
KL Loss                      2.3232007
QF Loss                      985.53906
VF Loss                      875.1731
Policy Loss                  -1186.7612
Q Predictions Mean           1187.6565
Q Predictions Std            243.61261
Q Predictions Max            1386.9355
Q Predictions Min            17.039963
V Predictions Mean           1189.408
V Predictions Std            239.42583
V Predictions Max            1378.0338
V Predictions Min            3.4582381
Log Pis Mean                 -0.24852347
Log Pis Std                  2.8188682
Log Pis Max                  11.724211
Log Pis Min                  -7.452579
Policy mu Mean               0.0008866121
Policy mu Std                0.6070115
Policy mu Max                2.314786
Policy mu Min                -2.286944
Policy log std Mean          -0.9512453
Policy log std Std           0.26645342
Policy log std Max           -0.085802615
Policy log std Min           -2.657918
Z mean eval                  0.9971541
Z variance eval              0.008686827
total_rewards                [-344.36353813 1628.20633289  216.96547824  308.94559625 3230.8419594
 2460.35919862 1339.96641484 -306.6148746  2095.7963654  1379.09369838]
total_rewards_mean           1200.9196631293412
total_rewards_std            1147.4133865943331
total_rewards_max            3230.8419593968074
total_rewards_min            -344.3635381273141
Number of train steps total  380000
Number of env steps total    1902000
Number of rollouts total     0
Train Time (s)               43.732644404284656
(Previous) Eval Time (s)     24.38046592613682
Sample Time (s)              23.207284349482507
Epoch Time (s)               91.32039467990398
Total Train Time (s)         36395.33403131971
Epoch                        379
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:35:54.664920 UTC | [2020_01_10_11_29_18] Iteration #379 | Epoch Duration: 91.26853084564209
2020-01-10 21:35:54.665112 UTC | [2020_01_10_11_29_18] Iteration #379 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9985083
Z variance train             0.008683417
KL Divergence                22.136278
KL Loss                      2.2136278
QF Loss                      1427.2671
VF Loss                      214.0128
Policy Loss                  -1158.9803
Q Predictions Mean           1159.8643
Q Predictions Std            283.6776
Q Predictions Max            1353.6523
Q Predictions Min            7.559512
V Predictions Mean           1157.3909
V Predictions Std            282.01456
V Predictions Max            1351.4816
V Predictions Min            -12.399621
Log Pis Mean                 -0.0660588
Log Pis Std                  2.9920723
Log Pis Max                  14.366642
Log Pis Min                  -8.037368
Policy mu Mean               0.034630723
Policy mu Std                0.59670335
Policy mu Max                2.5225465
Policy mu Min                -2.7719257
Policy log std Mean          -0.9606535
Policy log std Std           0.2828553
Policy log std Max           0.09050232
Policy log std Min           -2.9913461
Z mean eval                  1.0111091
Z variance eval              0.0056997514
total_rewards                [ 508.22936672 3072.57437158 3055.68224811 3152.26042056 2505.42714945
 1363.75943341   30.76867749 3193.7735592  3229.37263826 2617.74157485]
total_rewards_mean           2272.9589439627807
total_rewards_std            1137.061403396154
total_rewards_max            3229.3726382600616
total_rewards_min            30.768677491571093
Number of train steps total  381000
Number of env steps total    1907000
Number of rollouts total     0
Train Time (s)               44.14087574696168
(Previous) Eval Time (s)     24.32834703894332
Sample Time (s)              23.38811583071947
Epoch Time (s)               91.85733861662447
Total Train Time (s)         36489.43804922281
Epoch                        380
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:37:28.776350 UTC | [2020_01_10_11_29_18] Iteration #380 | Epoch Duration: 94.11106610298157
2020-01-10 21:37:28.776595 UTC | [2020_01_10_11_29_18] Iteration #380 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0122578
Z variance train             0.0057102973
KL Divergence                22.89433
KL Loss                      2.289433
QF Loss                      897.6774
VF Loss                      109.15743
Policy Loss                  -1181.4763
Q Predictions Mean           1179.2139
Q Predictions Std            255.5615
Q Predictions Max            1421.9462
Q Predictions Min            -11.779818
V Predictions Mean           1179.8394
V Predictions Std            253.33687
V Predictions Max            1398.3319
V Predictions Min            7.611181
Log Pis Mean                 -0.026151955
Log Pis Std                  3.0023744
Log Pis Max                  9.580447
Log Pis Min                  -8.311718
Policy mu Mean               -0.06701174
Policy mu Std                0.60054934
Policy mu Max                2.0948353
Policy mu Min                -2.2758143
Policy log std Mean          -0.98569417
Policy log std Std           0.27017197
Policy log std Max           -0.20830107
Policy log std Min           -2.228188
Z mean eval                  0.9976743
Z variance eval              0.009267753
total_rewards                [3106.646826   3061.31829796 3160.12950117 2489.16001571 2420.40974277
  886.53525757 3235.86914284 3097.33750444 3326.48326011 2447.99933764]
total_rewards_mean           2723.188888619369
total_rewards_std            693.8696915486053
total_rewards_max            3326.4832601110065
total_rewards_min            886.5352575675946
Number of train steps total  382000
Number of env steps total    1912000
Number of rollouts total     0
Train Time (s)               44.685564005281776
(Previous) Eval Time (s)     26.58180828113109
Sample Time (s)              22.0681045493111
Epoch Time (s)               93.33547683572397
Total Train Time (s)         36587.73161218595
Epoch                        381
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:39:07.073138 UTC | [2020_01_10_11_29_18] Iteration #381 | Epoch Duration: 98.29640340805054
2020-01-10 21:39:07.073312 UTC | [2020_01_10_11_29_18] Iteration #381 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9966284
Z variance train             0.009272063
KL Divergence                22.618715
KL Loss                      2.2618716
QF Loss                      588.6818
VF Loss                      256.21277
Policy Loss                  -1174.5834
Q Predictions Mean           1172.4995
Q Predictions Std            269.85272
Q Predictions Max            1363.2808
Q Predictions Min            -3.0400977
V Predictions Mean           1174.1927
V Predictions Std            272.51447
V Predictions Max            1358.5825
V Predictions Min            -14.867079
Log Pis Mean                 -0.25618625
Log Pis Std                  2.6144166
Log Pis Max                  13.511949
Log Pis Min                  -8.343512
Policy mu Mean               -0.04957234
Policy mu Std                0.59333175
Policy mu Max                2.1107705
Policy mu Min                -3.1010249
Policy log std Mean          -0.9393643
Policy log std Std           0.25875765
Policy log std Max           -0.019893348
Policy log std Min           -2.6069694
Z mean eval                  0.9980189
Z variance eval              0.012814666
total_rewards                [3123.63024874 3026.22515154 2688.4201619  1223.07444126 3191.71182224
 2718.78415796 3013.89275798 1302.48283939  759.63773267 3169.30273977]
total_rewards_mean           2421.716205343256
total_rewards_std            892.8536812173027
total_rewards_max            3191.71182224308
total_rewards_min            759.6377326712575
Number of train steps total  383000
Number of env steps total    1917000
Number of rollouts total     0
Train Time (s)               44.16582929715514
(Previous) Eval Time (s)     31.542503271251917
Sample Time (s)              22.789904831442982
Epoch Time (s)               98.49823739985004
Total Train Time (s)         36682.31632735208
Epoch                        382
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:40:41.664168 UTC | [2020_01_10_11_29_18] Iteration #382 | Epoch Duration: 94.59070229530334
2020-01-10 21:40:41.664372 UTC | [2020_01_10_11_29_18] Iteration #382 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9936161
Z variance train             0.012774731
KL Divergence                20.025927
KL Loss                      2.0025928
QF Loss                      3192.686
VF Loss                      186.74475
Policy Loss                  -1205.0104
Q Predictions Mean           1204.0822
Q Predictions Std            220.01772
Q Predictions Max            1384.3801
Q Predictions Min            -5.542085
V Predictions Mean           1196.7542
V Predictions Std            221.27562
V Predictions Max            1373.5509
V Predictions Min            -13.432472
Log Pis Mean                 0.05549644
Log Pis Std                  2.3757935
Log Pis Max                  7.8407164
Log Pis Min                  -6.939143
Policy mu Mean               0.0029167787
Policy mu Std                0.6510351
Policy mu Max                2.0927355
Policy mu Min                -2.1665924
Policy log std Mean          -0.9313732
Policy log std Std           0.24524076
Policy log std Max           -0.14326847
Policy log std Min           -2.3440425
Z mean eval                  1.0463603
Z variance eval              0.017966807
total_rewards                [3050.04848073 1637.86294816 2365.46698836 3501.04866495 2546.68982605
 3202.20236855 3428.96933598 3338.26041302 3006.9488414  3364.5494359 ]
total_rewards_mean           2944.2047303106906
total_rewards_std            561.9811626930435
total_rewards_max            3501.0486649526483
total_rewards_min            1637.862948162664
Number of train steps total  384000
Number of env steps total    1922000
Number of rollouts total     0
Train Time (s)               43.980257000308484
(Previous) Eval Time (s)     27.634685975965112
Sample Time (s)              22.703978394158185
Epoch Time (s)               94.31892137043178
Total Train Time (s)         36781.03010984324
Epoch                        383
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:42:20.387715 UTC | [2020_01_10_11_29_18] Iteration #383 | Epoch Duration: 98.7231957912445
2020-01-10 21:42:20.387937 UTC | [2020_01_10_11_29_18] Iteration #383 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0480692
Z variance train             0.017960932
KL Divergence                19.88921
KL Loss                      1.988921
QF Loss                      760.1592
VF Loss                      244.49266
Policy Loss                  -1192.6722
Q Predictions Mean           1192.5424
Q Predictions Std            235.75444
Q Predictions Max            1362.7028
Q Predictions Min            -47.24715
V Predictions Mean           1194.5873
V Predictions Std            232.39621
V Predictions Max            1372.3503
V Predictions Min            -6.7257156
Log Pis Mean                 0.22926068
Log Pis Std                  2.5550303
Log Pis Max                  8.048164
Log Pis Min                  -5.8550186
Policy mu Mean               -0.011266958
Policy mu Std                0.6388116
Policy mu Max                2.0989704
Policy mu Min                -2.1830323
Policy log std Mean          -0.9832934
Policy log std Std           0.2570095
Policy log std Max           -0.16471654
Policy log std Min           -2.1444259
Z mean eval                  1.0024831
Z variance eval              0.017937802
total_rewards                [3323.37843038  823.96662901 2345.47023716  668.51890547  960.65196834
 3283.09648369 3330.87144634 2592.79651273 3008.95517457 3240.9448686 ]
total_rewards_mean           2357.865065628881
total_rewards_std            1056.07976205906
total_rewards_max            3330.8714463386164
total_rewards_min            668.5189054723961
Number of train steps total  385000
Number of env steps total    1927000
Number of rollouts total     0
Train Time (s)               44.071833457797766
(Previous) Eval Time (s)     32.03869583783671
Sample Time (s)              22.42228984180838
Epoch Time (s)               98.53281913744286
Total Train Time (s)         36872.424807384145
Epoch                        384
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:43:51.779216 UTC | [2020_01_10_11_29_18] Iteration #384 | Epoch Duration: 91.39111471176147
2020-01-10 21:43:51.779355 UTC | [2020_01_10_11_29_18] Iteration #384 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0035468
Z variance train             0.017933223
KL Divergence                19.503593
KL Loss                      1.9503593
QF Loss                      1288.2817
VF Loss                      458.2719
Policy Loss                  -1184.5964
Q Predictions Mean           1184.5214
Q Predictions Std            238.547
Q Predictions Max            1384.7203
Q Predictions Min            -41.947205
V Predictions Mean           1185.6189
V Predictions Std            234.90437
V Predictions Max            1366.4666
V Predictions Min            81.30318
Log Pis Mean                 0.06597736
Log Pis Std                  2.7720044
Log Pis Max                  11.467443
Log Pis Min                  -7.248025
Policy mu Mean               0.0682359
Policy mu Std                0.6360665
Policy mu Max                2.1054926
Policy mu Min                -2.3212101
Policy log std Mean          -0.9639307
Policy log std Std           0.26382744
Policy log std Max           -0.15709573
Policy log std Min           -2.9973114
Z mean eval                  0.97538817
Z variance eval              0.013717796
total_rewards                [3284.7696991  3289.03229986  139.61179602 3076.12551475 3339.8863323
 3059.86915425 3176.56837813 3419.43396082 3171.1212528  3119.05791883]
total_rewards_mean           2907.547630686868
total_rewards_std            929.324505369079
total_rewards_max            3419.4339608245245
total_rewards_min            139.6117960200835
Number of train steps total  386000
Number of env steps total    1932000
Number of rollouts total     0
Train Time (s)               44.799995756708086
(Previous) Eval Time (s)     24.896746227052063
Sample Time (s)              22.712954961229116
Epoch Time (s)               92.40969694498926
Total Train Time (s)         36972.17841540836
Epoch                        385
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:45:31.536240 UTC | [2020_01_10_11_29_18] Iteration #385 | Epoch Duration: 99.75677394866943
2020-01-10 21:45:31.536417 UTC | [2020_01_10_11_29_18] Iteration #385 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9732884
Z variance train             0.013756953
KL Divergence                20.164562
KL Loss                      2.0164564
QF Loss                      1136.7052
VF Loss                      238.63623
Policy Loss                  -1202.1267
Q Predictions Mean           1202.3413
Q Predictions Std            202.3557
Q Predictions Max            1364.3505
Q Predictions Min            -4.4514055
V Predictions Mean           1211.695
V Predictions Std            201.4701
V Predictions Max            1374.4812
V Predictions Min            -15.478664
Log Pis Mean                 -0.06266343
Log Pis Std                  2.371124
Log Pis Max                  7.615027
Log Pis Min                  -7.4661293
Policy mu Mean               -0.033882413
Policy mu Std                0.597952
Policy mu Max                2.3225152
Policy mu Min                -3.4701788
Policy log std Mean          -0.98909616
Policy log std Std           0.23250453
Policy log std Max           -0.13315487
Policy log std Min           -2.0857134
Z mean eval                  0.976848
Z variance eval              0.017695885
total_rewards                [-109.57439795 3412.97603943 3288.05638004 2096.70832662   85.21712231
 3174.66601624 3445.93226735  642.0511351  -134.66861846 3005.42541933]
total_rewards_mean           1890.6789690013272
total_rewards_std            1501.4794581760734
total_rewards_max            3445.9322673487113
total_rewards_min            -134.66861845773772
Number of train steps total  387000
Number of env steps total    1937000
Number of rollouts total     0
Train Time (s)               44.404503834433854
(Previous) Eval Time (s)     32.243569422047585
Sample Time (s)              21.403874188661575
Epoch Time (s)               98.05194744514301
Total Train Time (s)         37064.20925760269
Epoch                        386
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:47:03.572454 UTC | [2020_01_10_11_29_18] Iteration #386 | Epoch Duration: 92.0358989238739
2020-01-10 21:47:03.572641 UTC | [2020_01_10_11_29_18] Iteration #386 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97455376
Z variance train             0.017702702
KL Divergence                20.219551
KL Loss                      2.0219553
QF Loss                      1040.9291
VF Loss                      182.18994
Policy Loss                  -1175.7083
Q Predictions Mean           1174.326
Q Predictions Std            281.9058
Q Predictions Max            1359.7402
Q Predictions Min            -21.283463
V Predictions Mean           1181.7454
V Predictions Std            281.9985
V Predictions Max            1370.0194
V Predictions Min            -20.667854
Log Pis Mean                 -0.22117662
Log Pis Std                  2.4929686
Log Pis Max                  6.5926123
Log Pis Min                  -10.530066
Policy mu Mean               0.027757742
Policy mu Std                0.59661174
Policy mu Max                2.245572
Policy mu Min                -1.9248097
Policy log std Mean          -0.94440174
Policy log std Std           0.27627513
Policy log std Max           0.050019205
Policy log std Min           -2.3717542
Z mean eval                  1.0200918
Z variance eval              0.013700212
total_rewards                [2996.14853953 3343.50078453  952.33939357    6.97938253  953.79596912
 1105.42151676 3229.48666243 2913.35898056 3234.99433139 2726.19711934]
total_rewards_mean           2146.222267975662
total_rewards_std            1180.951715961581
total_rewards_max            3343.5007845276123
total_rewards_min            6.979382525706699
Number of train steps total  388000
Number of env steps total    1942000
Number of rollouts total     0
Train Time (s)               45.16460290597752
(Previous) Eval Time (s)     26.227273277007043
Sample Time (s)              22.860620848368853
Epoch Time (s)               94.25249703135341
Total Train Time (s)         37154.915310141165
Epoch                        387
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:48:34.282447 UTC | [2020_01_10_11_29_18] Iteration #387 | Epoch Duration: 90.70965433120728
2020-01-10 21:48:34.282603 UTC | [2020_01_10_11_29_18] Iteration #387 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0217099
Z variance train             0.013689624
KL Divergence                20.684326
KL Loss                      2.0684326
QF Loss                      811.6896
VF Loss                      191.22615
Policy Loss                  -1199.0536
Q Predictions Mean           1200.1357
Q Predictions Std            242.29424
Q Predictions Max            1392.1396
Q Predictions Min            32.779125
V Predictions Mean           1201.1671
V Predictions Std            244.64658
V Predictions Max            1393.8721
V Predictions Min            -12.210648
Log Pis Mean                 -0.25901896
Log Pis Std                  2.9434066
Log Pis Max                  21.92139
Log Pis Min                  -8.891579
Policy mu Mean               0.075259104
Policy mu Std                0.60564804
Policy mu Max                4.3071785
Policy mu Min                -2.5735314
Policy log std Mean          -0.9465642
Policy log std Std           0.2524686
Policy log std Max           1.2112367
Policy log std Min           -2.098302
Z mean eval                  0.9981181
Z variance eval              0.0143362135
total_rewards                [3208.75369141  315.5733796  3375.13960755 3555.13777791 3293.56926396
 2598.13663196 2239.89190354 3316.85540188  303.11278048 1172.66844975]
total_rewards_mean           2337.8838888030486
total_rewards_std            1218.7220613096165
total_rewards_max            3555.137777913215
total_rewards_min            303.1127804786207
Number of train steps total  389000
Number of env steps total    1947000
Number of rollouts total     0
Train Time (s)               45.65856668492779
(Previous) Eval Time (s)     22.68418539315462
Sample Time (s)              22.84271651133895
Epoch Time (s)               91.18546858942136
Total Train Time (s)         37252.55717008235
Epoch                        388
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:50:11.931227 UTC | [2020_01_10_11_29_18] Iteration #388 | Epoch Duration: 97.6484432220459
2020-01-10 21:50:11.931556 UTC | [2020_01_10_11_29_18] Iteration #388 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9974903
Z variance train             0.014336075
KL Divergence                20.333199
KL Loss                      2.03332
QF Loss                      918.35645
VF Loss                      1125.2173
Policy Loss                  -1188.6145
Q Predictions Mean           1186.6162
Q Predictions Std            250.42667
Q Predictions Max            1395.6633
Q Predictions Min            11.443703
V Predictions Mean           1176.9509
V Predictions Std            254.85722
V Predictions Max            1379.3944
V Predictions Min            -11.315248
Log Pis Mean                 0.13758445
Log Pis Std                  2.6519763
Log Pis Max                  8.797114
Log Pis Min                  -6.745847
Policy mu Mean               -0.02621127
Policy mu Std                0.6364
Policy mu Max                2.392086
Policy mu Min                -2.3919144
Policy log std Mean          -0.965678
Policy log std Std           0.30309984
Policy log std Max           -0.049928427
Policy log std Min           -2.9959183
Z mean eval                  1.0189216
Z variance eval              0.014110503
total_rewards                [2669.51551314 3395.86167114 2987.96801214 3339.58622603 1365.77253637
 3274.72482499  961.45166385 1088.58180357  962.58586985 3265.2273345 ]
total_rewards_mean           2331.1275455592017
total_rewards_std            1033.6469551423986
total_rewards_max            3395.861671143023
total_rewards_min            961.4516638532665
Number of train steps total  390000
Number of env steps total    1952000
Number of rollouts total     0
Train Time (s)               46.3978751427494
(Previous) Eval Time (s)     29.146867943927646
Sample Time (s)              23.58243441209197
Epoch Time (s)               99.12717749876902
Total Train Time (s)         37350.302181362174
Epoch                        389
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:51:49.680503 UTC | [2020_01_10_11_29_18] Iteration #389 | Epoch Duration: 97.74873208999634
2020-01-10 21:51:49.680642 UTC | [2020_01_10_11_29_18] Iteration #389 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0177615
Z variance train             0.014133245
KL Divergence                20.198496
KL Loss                      2.0198495
QF Loss                      553.59674
VF Loss                      156.9852
Policy Loss                  -1241.743
Q Predictions Mean           1242.7847
Q Predictions Std            225.8708
Q Predictions Max            1419.3632
Q Predictions Min            -10.263649
V Predictions Mean           1250.1133
V Predictions Std            224.47157
V Predictions Max            1413.788
V Predictions Min            18.932453
Log Pis Mean                 -0.08228184
Log Pis Std                  2.8156934
Log Pis Max                  7.6414227
Log Pis Min                  -7.711929
Policy mu Mean               -0.10736333
Policy mu Std                0.6560098
Policy mu Max                2.0550513
Policy mu Min                -2.34011
Policy log std Mean          -0.9456841
Policy log std Std           0.24477343
Policy log std Max           -0.11824131
Policy log std Min           -2.1265025
Z mean eval                  1.0582557
Z variance eval              0.0099876765
total_rewards                [3190.16330013 3275.52225671 1189.1020674   583.82641025 3208.91417516
 3017.74140508  156.24750227  399.5214558  3092.97765068  385.8022094 ]
total_rewards_mean           1849.9818432885481
total_rewards_std            1331.9142192415782
total_rewards_max            3275.5222567066517
total_rewards_min            156.24750227185817
Number of train steps total  391000
Number of env steps total    1957000
Number of rollouts total     0
Train Time (s)               44.864146099891514
(Previous) Eval Time (s)     27.768201836850494
Sample Time (s)              24.05249552289024
Epoch Time (s)               96.68484345963225
Total Train Time (s)         37443.339023468085
Epoch                        390
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:53:22.723803 UTC | [2020_01_10_11_29_18] Iteration #390 | Epoch Duration: 93.04300594329834
2020-01-10 21:53:22.724388 UTC | [2020_01_10_11_29_18] Iteration #390 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0587404
Z variance train             0.010010226
KL Divergence                21.495562
KL Loss                      2.1495562
QF Loss                      1329.0397
VF Loss                      388.75354
Policy Loss                  -1212.4309
Q Predictions Mean           1214.179
Q Predictions Std            208.23637
Q Predictions Max            1386.7584
Q Predictions Min            -10.767255
V Predictions Mean           1212.9575
V Predictions Std            207.943
V Predictions Max            1399.3011
V Predictions Min            -8.864292
Log Pis Mean                 -0.14892492
Log Pis Std                  2.9566782
Log Pis Max                  14.953586
Log Pis Min                  -10.443369
Policy mu Mean               0.031115318
Policy mu Std                0.61264026
Policy mu Max                3.0730734
Policy mu Min                -2.4810524
Policy log std Mean          -0.975598
Policy log std Std           0.26583827
Policy log std Max           -0.084840655
Policy log std Min           -2.7219925
Z mean eval                  1.0300854
Z variance eval              0.012408944
total_rewards                [2838.61982012  920.68673829 1129.48128623  311.48452975 1138.59410322
 3050.91901021 3146.63389583 3118.68140931 3199.84603691 3370.49349123]
total_rewards_mean           2222.5440321102733
total_rewards_std            1127.4919234760005
total_rewards_max            3370.4934912260496
total_rewards_min            311.4845297545809
Number of train steps total  392000
Number of env steps total    1962000
Number of rollouts total     0
Train Time (s)               44.3839470022358
(Previous) Eval Time (s)     24.12607855303213
Sample Time (s)              23.430952397640795
Epoch Time (s)               91.94097795290872
Total Train Time (s)         37540.56236021733
Epoch                        391
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:54:59.947304 UTC | [2020_01_10_11_29_18] Iteration #391 | Epoch Duration: 97.22259187698364
2020-01-10 21:54:59.947448 UTC | [2020_01_10_11_29_18] Iteration #391 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0301515
Z variance train             0.012377827
KL Divergence                21.379665
KL Loss                      2.1379666
QF Loss                      1746.4373
VF Loss                      1024.2953
Policy Loss                  -1204.2616
Q Predictions Mean           1200.8186
Q Predictions Std            276.3573
Q Predictions Max            1429.5077
Q Predictions Min            -8.336283
V Predictions Mean           1198.5288
V Predictions Std            272.00412
V Predictions Max            1419.4755
V Predictions Min            0.90473825
Log Pis Mean                 0.04562208
Log Pis Std                  2.8621495
Log Pis Max                  10.465855
Log Pis Min                  -6.2239237
Policy mu Mean               -0.048509046
Policy mu Std                0.6075469
Policy mu Max                2.1450353
Policy mu Min                -2.061233
Policy log std Mean          -0.9585575
Policy log std Std           0.27244756
Policy log std Max           -0.005596876
Policy log std Min           -2.5079484
Z mean eval                  0.99771804
Z variance eval              0.008667725
total_rewards                [ 714.9565913  2340.48154853 1327.71826019  654.58719851 3233.25180222
 3187.57789294 3463.55247365 3033.40716189 3476.10551251  786.14366157]
total_rewards_mean           2221.778210331487
total_rewards_std            1154.5998876095698
total_rewards_max            3476.105512508963
total_rewards_min            654.5871985104026
Number of train steps total  393000
Number of env steps total    1967000
Number of rollouts total     0
Train Time (s)               45.089840833097696
(Previous) Eval Time (s)     29.40746309934184
Sample Time (s)              22.760104845277965
Epoch Time (s)               97.2574087777175
Total Train Time (s)         37630.8939860384
Epoch                        392
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:56:30.287244 UTC | [2020_01_10_11_29_18] Iteration #392 | Epoch Duration: 90.3396303653717
2020-01-10 21:56:30.287617 UTC | [2020_01_10_11_29_18] Iteration #392 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9979378
Z variance train             0.008672329
KL Divergence                21.66686
KL Loss                      2.166686
QF Loss                      824.8093
VF Loss                      246.93018
Policy Loss                  -1195.0568
Q Predictions Mean           1196.5774
Q Predictions Std            230.3448
Q Predictions Max            1375.2855
Q Predictions Min            -17.458138
V Predictions Mean           1187.7649
V Predictions Std            227.49205
V Predictions Max            1354.0862
V Predictions Min            -8.409907
Log Pis Mean                 -0.3055057
Log Pis Std                  2.7984805
Log Pis Max                  10.950389
Log Pis Min                  -7.652679
Policy mu Mean               0.003969712
Policy mu Std                0.6030667
Policy mu Max                2.4001067
Policy mu Min                -2.308563
Policy log std Mean          -0.94997716
Policy log std Std           0.2611412
Policy log std Max           -0.078026
Policy log std Min           -2.1640928
Z mean eval                  1.0141603
Z variance eval              0.009574289
total_rewards                [2431.52958955 2991.67543227 1453.52049373 1847.80222814 2150.73698056
 3094.23841026 1325.36166077 2859.01629286 1833.77777229 3136.10242497]
total_rewards_mean           2312.376128540418
total_rewards_std            651.7006421894233
total_rewards_max            3136.1024249680313
total_rewards_min            1325.3616607702927
Number of train steps total  394000
Number of env steps total    1972000
Number of rollouts total     0
Train Time (s)               44.310216640122235
(Previous) Eval Time (s)     22.489398697856814
Sample Time (s)              22.041786772664636
Epoch Time (s)               88.84140211064368
Total Train Time (s)         37728.15390838729
Epoch                        393
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:58:07.545039 UTC | [2020_01_10_11_29_18] Iteration #393 | Epoch Duration: 97.2571918964386
2020-01-10 21:58:07.545185 UTC | [2020_01_10_11_29_18] Iteration #393 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0134709
Z variance train             0.009549327
KL Divergence                22.507803
KL Loss                      2.2507803
QF Loss                      715.10925
VF Loss                      491.92755
Policy Loss                  -1240.3037
Q Predictions Mean           1238.7251
Q Predictions Std            189.65419
Q Predictions Max            1474.4651
Q Predictions Min            10.760519
V Predictions Mean           1226.256
V Predictions Std            180.82799
V Predictions Max            1453.2522
V Predictions Min            13.393527
Log Pis Mean                 0.48692572
Log Pis Std                  2.8481135
Log Pis Max                  14.328732
Log Pis Min                  -6.124346
Policy mu Mean               -0.07767947
Policy mu Std                0.70266545
Policy mu Max                2.8402345
Policy mu Min                -2.429932
Policy log std Mean          -0.928192
Policy log std Std           0.249263
Policy log std Max           -0.1585077
Policy log std Min           -2.1619751
Z mean eval                  1.0018394
Z variance eval              0.009652426
total_rewards                [1423.21816847  455.65732686  900.52612022 3278.97974331 2563.84014923
  830.00760419 3417.44713488 1883.77959662 3511.10234733 3365.93152995]
total_rewards_mean           2163.0489721062886
total_rewards_std            1146.9574807924776
total_rewards_max            3511.1023473337464
total_rewards_min            455.65732685928526
Number of train steps total  395000
Number of env steps total    1977000
Number of rollouts total     0
Train Time (s)               44.677925534080714
(Previous) Eval Time (s)     30.904954346828163
Sample Time (s)              23.546681366860867
Epoch Time (s)               99.12956124776974
Total Train Time (s)         37822.16918895207
Epoch                        394
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:59:41.564134 UTC | [2020_01_10_11_29_18] Iteration #394 | Epoch Duration: 94.01883959770203
2020-01-10 21:59:41.564310 UTC | [2020_01_10_11_29_18] Iteration #394 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9999075
Z variance train             0.009628734
KL Divergence                21.734238
KL Loss                      2.1734238
QF Loss                      1187.022
VF Loss                      196.7882
Policy Loss                  -1213.6749
Q Predictions Mean           1215.0863
Q Predictions Std            238.16087
Q Predictions Max            1432.7015
Q Predictions Min            -5.8538647
V Predictions Mean           1218.9845
V Predictions Std            237.38844
V Predictions Max            1413.4252
V Predictions Min            -9.029947
Log Pis Mean                 -0.028392434
Log Pis Std                  2.9311607
Log Pis Max                  13.236345
Log Pis Min                  -7.699237
Policy mu Mean               -0.06543938
Policy mu Std                0.6542821
Policy mu Max                3.4145722
Policy mu Min                -3.0116591
Policy log std Mean          -0.95966446
Policy log std Std           0.25645116
Policy log std Max           -0.09541273
Policy log std Min           -2.2589846
Z mean eval                  0.99320334
Z variance eval              0.009493752
total_rewards                [3359.53050417 3263.37817126  463.72412896 3468.22143912 3397.54083419
 3248.53639131 3342.81564684 3343.24348902 3354.13416551 3544.67221149]
total_rewards_mean           3078.579698186794
total_rewards_std            875.559004477258
total_rewards_max            3544.672211488215
total_rewards_min            463.7241289578428
Number of train steps total  396000
Number of env steps total    1982000
Number of rollouts total     0
Train Time (s)               44.670076850336045
(Previous) Eval Time (s)     25.79396922700107
Sample Time (s)              24.283736824523658
Epoch Time (s)               94.74778290186077
Total Train Time (s)         37923.61696692463
Epoch                        395
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:01:23.020165 UTC | [2020_01_10_11_29_18] Iteration #395 | Epoch Duration: 101.45567536354065
2020-01-10 22:01:23.020420 UTC | [2020_01_10_11_29_18] Iteration #395 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9941223
Z variance train             0.009531066
KL Divergence                22.097996
KL Loss                      2.2097995
QF Loss                      1400.3531
VF Loss                      170.26506
Policy Loss                  -1202.91
Q Predictions Mean           1206.2803
Q Predictions Std            236.33017
Q Predictions Max            1396.9386
Q Predictions Min            -16.344982
V Predictions Mean           1210.83
V Predictions Std            236.2988
V Predictions Max            1411.7731
V Predictions Min            -18.579708
Log Pis Mean                 -0.0105035305
Log Pis Std                  2.529319
Log Pis Max                  8.037908
Log Pis Min                  -6.741297
Policy mu Mean               0.0127725955
Policy mu Std                0.60991615
Policy mu Max                2.6965742
Policy mu Min                -2.0489416
Policy log std Mean          -0.97924674
Policy log std Std           0.24654981
Policy log std Max           -0.15461075
Policy log std Min           -1.9980533
Z mean eval                  1.034527
Z variance eval              0.008130997
total_rewards                [1928.7690265  3133.57162362 3382.99587062 2995.50609574 3195.46663125
 3021.87292923 3258.51955709 2640.22146884 1491.77463691 2356.96269674]
total_rewards_mean           2740.566053655458
total_rewards_std            596.8435963664409
total_rewards_max            3382.9958706205102
total_rewards_min            1491.774636914925
Number of train steps total  397000
Number of env steps total    1987000
Number of rollouts total     0
Train Time (s)               44.736188457813114
(Previous) Eval Time (s)     32.50159035110846
Sample Time (s)              23.539222358260304
Epoch Time (s)               100.77700116718188
Total Train Time (s)         38021.33879962936
Epoch                        396
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:03:00.745984 UTC | [2020_01_10_11_29_18] Iteration #396 | Epoch Duration: 97.72542834281921
2020-01-10 22:03:00.746156 UTC | [2020_01_10_11_29_18] Iteration #396 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.033996
Z variance train             0.008142114
KL Divergence                22.11964
KL Loss                      2.2119641
QF Loss                      624.24915
VF Loss                      93.06322
Policy Loss                  -1219.8024
Q Predictions Mean           1220.6329
Q Predictions Std            239.94554
Q Predictions Max            1444.7063
Q Predictions Min            -20.830723
V Predictions Mean           1220.5715
V Predictions Std            237.25009
V Predictions Max            1439.0398
V Predictions Min            -13.5698185
Log Pis Mean                 -0.08172157
Log Pis Std                  2.6624625
Log Pis Max                  16.75914
Log Pis Min                  -5.5568647
Policy mu Mean               -0.026789825
Policy mu Std                0.6151483
Policy mu Max                2.2933078
Policy mu Min                -2.7056255
Policy log std Mean          -0.96253896
Policy log std Std           0.2659966
Policy log std Max           1.1285248
Policy log std Min           -2.846697
Z mean eval                  1.0396901
Z variance eval              0.0115619395
total_rewards                [3507.52699263 3277.55160246 3611.46838046  981.18110277 3449.67907441
 3389.8268543  3347.13640787 3336.28371777 3265.42326101 1938.62532995]
total_rewards_mean           3010.4702723618916
total_rewards_std            810.4182847683603
total_rewards_max            3611.468380455586
total_rewards_min            981.1811027681714
Number of train steps total  398000
Number of env steps total    1992000
Number of rollouts total     0
Train Time (s)               44.499272304121405
(Previous) Eval Time (s)     29.44977487809956
Sample Time (s)              23.464329611044377
Epoch Time (s)               97.41337679326534
Total Train Time (s)         38118.25464261975
Epoch                        397
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:04:37.665386 UTC | [2020_01_10_11_29_18] Iteration #397 | Epoch Duration: 96.9190981388092
2020-01-10 22:04:37.665548 UTC | [2020_01_10_11_29_18] Iteration #397 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0388762
Z variance train             0.011555445
KL Divergence                21.072796
KL Loss                      2.1072795
QF Loss                      786.48975
VF Loss                      156.30898
Policy Loss                  -1218.7035
Q Predictions Mean           1218.8633
Q Predictions Std            211.88173
Q Predictions Max            1383.6871
Q Predictions Min            -17.706432
V Predictions Mean           1218.2715
V Predictions Std            209.74246
V Predictions Max            1375.832
V Predictions Min            -8.772579
Log Pis Mean                 -0.1491802
Log Pis Std                  2.5475738
Log Pis Max                  7.088653
Log Pis Min                  -8.173775
Policy mu Mean               -0.0105735045
Policy mu Std                0.6218171
Policy mu Max                2.1505156
Policy mu Min                -2.1734142
Policy log std Mean          -0.96094215
Policy log std Std           0.24643442
Policy log std Max           0.016146958
Policy log std Min           -1.9944499
Z mean eval                  1.0085186
Z variance eval              0.010829376
total_rewards                [3068.09589259 3465.47087998 3451.76169777 3322.26111495 3272.70741297
 2465.56140862 3453.84210999 3468.14817567 3495.2370599  3322.17481393]
total_rewards_mean           3278.526056636833
total_rewards_std            297.93608017217554
total_rewards_max            3495.2370598972548
total_rewards_min            2465.561408616645
Number of train steps total  399000
Number of env steps total    1997000
Number of rollouts total     0
Train Time (s)               44.77272153785452
(Previous) Eval Time (s)     28.955258005298674
Sample Time (s)              23.243184277787805
Epoch Time (s)               96.971163820941
Total Train Time (s)         38222.33878881438
Epoch                        398
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:06:21.752093 UTC | [2020_01_10_11_29_18] Iteration #398 | Epoch Duration: 104.08642363548279
2020-01-10 22:06:21.752227 UTC | [2020_01_10_11_29_18] Iteration #398 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0064808
Z variance train             0.01084066
KL Divergence                21.505135
KL Loss                      2.1505134
QF Loss                      2636.6943
VF Loss                      149.06009
Policy Loss                  -1220.1337
Q Predictions Mean           1223.3865
Q Predictions Std            242.21428
Q Predictions Max            1428.9132
Q Predictions Min            -18.202742
V Predictions Mean           1220.9146
V Predictions Std            240.41336
V Predictions Max            1418.6163
V Predictions Min            -10.418034
Log Pis Mean                 0.06399959
Log Pis Std                  3.0090868
Log Pis Max                  21.279533
Log Pis Min                  -7.390612
Policy mu Mean               -0.060391888
Policy mu Std                0.6447862
Policy mu Max                3.6730962
Policy mu Min                -3.962018
Policy log std Mean          -0.95268977
Policy log std Std           0.2692767
Policy log std Max           -0.14122391
Policy log std Min           -3.0953183
Z mean eval                  0.97941065
Z variance eval              0.010321538
total_rewards                [1239.98139341 1319.4288101   202.31954971  262.68531841 2176.72063197
 3052.68714349 3245.67119209 1702.56605957 1523.60301317 2641.36650395]
total_rewards_mean           1736.7029615873457
total_rewards_std            1000.7656358882957
total_rewards_max            3245.671192092196
total_rewards_min            202.31954971292294
Number of train steps total  400000
Number of env steps total    2002000
Number of rollouts total     0
Train Time (s)               44.60062767891213
(Previous) Eval Time (s)     36.07028909679502
Sample Time (s)              23.722521550022066
Epoch Time (s)               104.39343832572922
Total Train Time (s)         38314.597985035274
Epoch                        399
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:07:54.015201 UTC | [2020_01_10_11_29_18] Iteration #399 | Epoch Duration: 92.26284718513489
2020-01-10 22:07:54.015377 UTC | [2020_01_10_11_29_18] Iteration #399 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9787687
Z variance train             0.010290138
KL Divergence                21.621803
KL Loss                      2.1621804
QF Loss                      1183.5632
VF Loss                      305.87564
Policy Loss                  -1228.324
Q Predictions Mean           1227.9604
Q Predictions Std            206.80438
Q Predictions Max            1400.6086
Q Predictions Min            -2.936857
V Predictions Mean           1221.615
V Predictions Std            208.45769
V Predictions Max            1391.9843
V Predictions Min            -13.039098
Log Pis Mean                 0.6924864
Log Pis Std                  2.9419558
Log Pis Max                  12.876481
Log Pis Min                  -6.589921
Policy mu Mean               0.04902374
Policy mu Std                0.65019697
Policy mu Max                2.8233032
Policy mu Min                -2.1930687
Policy log std Mean          -0.9989307
Policy log std Std           0.3029572
Policy log std Max           -0.053292036
Policy log std Min           -2.6645734
Z mean eval                  0.9992424
Z variance eval              0.009871302
total_rewards                [ 659.29189953 3227.36429745 3353.25465214 2960.69928158 3227.75948919
 3251.84956594 3299.83527148 3311.96075753 3108.42695747 3046.95485193]
total_rewards_mean           2944.7397024245474
total_rewards_std            770.901406308272
total_rewards_max            3353.25465214182
total_rewards_min            659.2918995283942
Number of train steps total  401000
Number of env steps total    2007000
Number of rollouts total     0
Train Time (s)               45.87982674315572
(Previous) Eval Time (s)     23.939443996641785
Sample Time (s)              22.57708001602441
Epoch Time (s)               92.39635075582191
Total Train Time (s)         38416.596586176194
Epoch                        400
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:09:36.016507 UTC | [2020_01_10_11_29_18] Iteration #400 | Epoch Duration: 102.00100827217102
2020-01-10 22:09:36.016643 UTC | [2020_01_10_11_29_18] Iteration #400 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0005414
Z variance train             0.00987226
KL Divergence                21.990547
KL Loss                      2.1990547
QF Loss                      1234.4949
VF Loss                      451.22095
Policy Loss                  -1218.7548
Q Predictions Mean           1222.6057
Q Predictions Std            242.46042
Q Predictions Max            1423.5166
Q Predictions Min            3.4018445
V Predictions Mean           1229.951
V Predictions Std            242.98227
V Predictions Max            1426.8823
V Predictions Min            -19.995201
Log Pis Mean                 -0.05096778
Log Pis Std                  2.6673193
Log Pis Max                  9.055859
Log Pis Min                  -9.342988
Policy mu Mean               -0.008614717
Policy mu Std                0.6252258
Policy mu Max                2.206358
Policy mu Min                -2.0268383
Policy log std Mean          -0.9448687
Policy log std Std           0.25185665
Policy log std Max           0.19469672
Policy log std Min           -2.3355403
Z mean eval                  1.044298
Z variance eval              0.006843698
total_rewards                [3303.517369   1787.32918472 3191.6997251  3250.04679962  149.66274424
 1235.72286441 3307.96660925 3491.25660674 1342.21306548 2443.54008671]
total_rewards_mean           2350.2955055264238
total_rewards_std            1098.7258124254868
total_rewards_max            3491.25660673744
total_rewards_min            149.66274424171718
Number of train steps total  402000
Number of env steps total    2012000
Number of rollouts total     0
Train Time (s)               44.93747190758586
(Previous) Eval Time (s)     33.543841297738254
Sample Time (s)              23.762249037157744
Epoch Time (s)               102.24356224248186
Total Train Time (s)         38511.13659053715
Epoch                        401
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:11:10.562794 UTC | [2020_01_10_11_29_18] Iteration #401 | Epoch Duration: 94.5460410118103
2020-01-10 22:11:10.562980 UTC | [2020_01_10_11_29_18] Iteration #401 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0430763
Z variance train             0.006840507
KL Divergence                22.592566
KL Loss                      2.2592566
QF Loss                      765.7484
VF Loss                      319.6991
Policy Loss                  -1205.423
Q Predictions Mean           1205.9468
Q Predictions Std            265.06616
Q Predictions Max            1421.4293
Q Predictions Min            -41.127605
V Predictions Mean           1213.6035
V Predictions Std            260.86487
V Predictions Max            1432.4543
V Predictions Min            -32.691254
Log Pis Mean                 -0.25054842
Log Pis Std                  2.5317628
Log Pis Max                  7.0499945
Log Pis Min                  -7.7312746
Policy mu Mean               -0.04829842
Policy mu Std                0.61142147
Policy mu Max                2.527283
Policy mu Min                -2.2737963
Policy log std Mean          -0.93356895
Policy log std Std           0.25971237
Policy log std Max           -0.026561797
Policy log std Min           -2.3865275
Z mean eval                  1.0348567
Z variance eval              0.0071481257
total_rewards                [3259.85399415 3560.34002427  498.03446261 3426.75355406 3163.26266955
  950.72046635  386.50940965 3619.74420392 3464.72945149 2697.69284914]
total_rewards_mean           2502.764108518538
total_rewards_std            1268.8183556559393
total_rewards_max            3619.744203924406
total_rewards_min            386.5094096465915
Number of train steps total  403000
Number of env steps total    2017000
Number of rollouts total     0
Train Time (s)               44.071844453923404
(Previous) Eval Time (s)     25.84608118981123
Sample Time (s)              22.684954341500998
Epoch Time (s)               92.60287998523563
Total Train Time (s)         38602.93459146097
Epoch                        402
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:12:42.367817 UTC | [2020_01_10_11_29_18] Iteration #402 | Epoch Duration: 91.80469512939453
2020-01-10 22:12:42.368046 UTC | [2020_01_10_11_29_18] Iteration #402 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0391314
Z variance train             0.0070884945
KL Divergence                22.979298
KL Loss                      2.2979298
QF Loss                      1160.894
VF Loss                      394.98584
Policy Loss                  -1226.897
Q Predictions Mean           1229.1353
Q Predictions Std            231.94745
Q Predictions Max            1426.8727
Q Predictions Min            -10.1618
V Predictions Mean           1237.0007
V Predictions Std            227.6339
V Predictions Max            1432.374
V Predictions Min            3.1408615
Log Pis Mean                 0.14667659
Log Pis Std                  2.8699298
Log Pis Max                  12.757887
Log Pis Min                  -10.802064
Policy mu Mean               0.02185132
Policy mu Std                0.62557125
Policy mu Max                2.521704
Policy mu Min                -2.6228082
Policy log std Mean          -0.97894156
Policy log std Std           0.26571345
Policy log std Max           0.03284639
Policy log std Min           -2.6945972
Z mean eval                  1.0340561
Z variance eval              0.01049695
total_rewards                [3158.0286375  3470.69006589 3250.26703734 2471.20179839    5.40869707
 2972.44039489 -215.18163357 3246.06232393 2502.63466053  849.98381864]
total_rewards_mean           2171.1535800598167
total_rewards_std            1339.9678170198822
total_rewards_max            3470.6900658877266
total_rewards_min            -215.18163356833387
Number of train steps total  404000
Number of env steps total    2022000
Number of rollouts total     0
Train Time (s)               44.44815511396155
(Previous) Eval Time (s)     25.04760894132778
Sample Time (s)              22.922590575180948
Epoch Time (s)               92.41835463047028
Total Train Time (s)         38698.0909703942
Epoch                        403
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:14:17.532989 UTC | [2020_01_10_11_29_18] Iteration #403 | Epoch Duration: 95.16479563713074
2020-01-10 22:14:17.533133 UTC | [2020_01_10_11_29_18] Iteration #403 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0324439
Z variance train             0.010476723
KL Divergence                22.568789
KL Loss                      2.2568789
QF Loss                      4548.2554
VF Loss                      320.2625
Policy Loss                  -1224.2743
Q Predictions Mean           1225.634
Q Predictions Std            245.55756
Q Predictions Max            1398.6217
Q Predictions Min            -23.429161
V Predictions Mean           1220.8748
V Predictions Std            238.93579
V Predictions Max            1393.2727
V Predictions Min            -15.785513
Log Pis Mean                 -0.10771963
Log Pis Std                  2.483379
Log Pis Max                  7.14584
Log Pis Min                  -8.1999035
Policy mu Mean               0.05477162
Policy mu Std                0.6191279
Policy mu Max                2.1889496
Policy mu Min                -2.1255739
Policy log std Mean          -0.95089245
Policy log std Std           0.2622675
Policy log std Max           0.51642233
Policy log std Min           -2.930862
Z mean eval                  1.0134722
Z variance eval              0.010763628
total_rewards                [3185.33266546 2708.647012    469.35093641 3233.69803137 2759.81148294
 1600.76031598  997.56782306 3240.47749875 3431.58704646 3401.40269874]
total_rewards_mean           2502.8635511178286
total_rewards_std            1026.504042771116
total_rewards_max            3431.5870464639756
total_rewards_min            469.35093641492136
Number of train steps total  405000
Number of env steps total    2027000
Number of rollouts total     0
Train Time (s)               44.73492877697572
(Previous) Eval Time (s)     27.793816356919706
Sample Time (s)              23.005899627227336
Epoch Time (s)               95.53464476112276
Total Train Time (s)         38795.72365050111
Epoch                        404
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:15:55.170945 UTC | [2020_01_10_11_29_18] Iteration #404 | Epoch Duration: 97.63767385482788
2020-01-10 22:15:55.171151 UTC | [2020_01_10_11_29_18] Iteration #404 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0147315
Z variance train             0.010754773
KL Divergence                22.718643
KL Loss                      2.2718644
QF Loss                      789.2782
VF Loss                      128.86859
Policy Loss                  -1238.7008
Q Predictions Mean           1241.3223
Q Predictions Std            219.84724
Q Predictions Max            1424.0005
Q Predictions Min            -44.48159
V Predictions Mean           1242.1078
V Predictions Std            218.92285
V Predictions Max            1444.1554
V Predictions Min            -34.90224
Log Pis Mean                 0.06420157
Log Pis Std                  2.6748588
Log Pis Max                  7.9752083
Log Pis Min                  -7.150719
Policy mu Mean               -0.02776092
Policy mu Std                0.6200201
Policy mu Max                2.414112
Policy mu Min                -2.1328108
Policy log std Mean          -0.98166704
Policy log std Std           0.25384784
Policy log std Max           -0.0144889355
Policy log std Min           -2.0296228
Z mean eval                  1.0451066
Z variance eval              0.009220941
total_rewards                [2702.11256618 1761.53436187 2177.62593339 3330.6189175  1348.41822645
 3059.34479878 2592.20277149 3339.36056776 3324.1642491  1530.60467813]
total_rewards_mean           2516.598707064703
total_rewards_std            731.3198575663108
total_rewards_max            3339.360567764929
total_rewards_min            1348.4182264540327
Number of train steps total  406000
Number of env steps total    2032000
Number of rollouts total     0
Train Time (s)               44.264912620186806
(Previous) Eval Time (s)     29.89661500696093
Sample Time (s)              22.58040493540466
Epoch Time (s)               96.74193256255239
Total Train Time (s)         38889.54656839091
Epoch                        405
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:17:28.997858 UTC | [2020_01_10_11_29_18] Iteration #405 | Epoch Duration: 93.82655644416809
2020-01-10 22:17:28.998015 UTC | [2020_01_10_11_29_18] Iteration #405 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0459557
Z variance train             0.0092205005
KL Divergence                23.07092
KL Loss                      2.3070922
QF Loss                      785.40173
VF Loss                      184.3115
Policy Loss                  -1207.6635
Q Predictions Mean           1206.8181
Q Predictions Std            298.11548
Q Predictions Max            1399.3657
Q Predictions Min            -33.088387
V Predictions Mean           1204.3984
V Predictions Std            297.88544
V Predictions Max            1403.3004
V Predictions Min            -30.783752
Log Pis Mean                 -0.3004872
Log Pis Std                  2.6271353
Log Pis Max                  7.285507
Log Pis Min                  -8.243417
Policy mu Mean               -0.0052808803
Policy mu Std                0.6016871
Policy mu Max                2.1165714
Policy mu Min                -1.834572
Policy log std Mean          -0.9431186
Policy log std Std           0.2667439
Policy log std Max           -0.024695516
Policy log std Min           -2.2270718
Z mean eval                  0.99212515
Z variance eval              0.010973368
total_rewards                [ -53.4361906  1376.93477004 2500.01253096 3293.71069185 1434.79639792
  152.47381326 3105.08769209 3297.65063001 2398.92003191 3284.15889259]
total_rewards_mean           2079.0309260047156
total_rewards_std            1221.1542418086487
total_rewards_max            3297.650630013792
total_rewards_min            -53.4361905951924
Number of train steps total  407000
Number of env steps total    2037000
Number of rollouts total     0
Train Time (s)               45.183830039110035
(Previous) Eval Time (s)     26.980993185192347
Sample Time (s)              21.531860255636275
Epoch Time (s)               93.69668347993866
Total Train Time (s)         38984.672728236765
Epoch                        406
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:19:04.127741 UTC | [2020_01_10_11_29_18] Iteration #406 | Epoch Duration: 95.12958908081055
2020-01-10 22:19:04.127916 UTC | [2020_01_10_11_29_18] Iteration #406 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99129564
Z variance train             0.011006428
KL Divergence                22.909384
KL Loss                      2.2909384
QF Loss                      1681.8829
VF Loss                      268.274
Policy Loss                  -1233.582
Q Predictions Mean           1234.6174
Q Predictions Std            211.06836
Q Predictions Max            1402.9436
Q Predictions Min            14.052397
V Predictions Mean           1238.1195
V Predictions Std            207.62494
V Predictions Max            1399.5763
V Predictions Min            25.592567
Log Pis Mean                 0.12414083
Log Pis Std                  2.7724276
Log Pis Max                  14.042884
Log Pis Min                  -8.840129
Policy mu Mean               -0.002330307
Policy mu Std                0.61343426
Policy mu Max                2.3398542
Policy mu Min                -2.2105782
Policy log std Mean          -0.99743676
Policy log std Std           0.27185467
Policy log std Max           -0.21752965
Policy log std Min           -2.6595407
Z mean eval                  0.9863723
Z variance eval              0.010512948
total_rewards                [3172.09868601 1516.49826285 1789.69697811 3370.27472193  452.67777757
 3350.90768384 1004.02550857 3178.35277589 2174.14131258 3364.25317002]
total_rewards_mean           2337.292687736927
total_rewards_std            1043.2140649526516
total_rewards_max            3370.2747219349585
total_rewards_min            452.67777756853525
Number of train steps total  408000
Number of env steps total    2042000
Number of rollouts total     0
Train Time (s)               44.35534793417901
(Previous) Eval Time (s)     28.413666539359838
Sample Time (s)              23.573942705523223
Epoch Time (s)               96.34295717906207
Total Train Time (s)         39079.417391183786
Epoch                        407
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:20:38.876857 UTC | [2020_01_10_11_29_18] Iteration #407 | Epoch Duration: 94.7487952709198
2020-01-10 22:20:38.877036 UTC | [2020_01_10_11_29_18] Iteration #407 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98718375
Z variance train             0.010563735
KL Divergence                22.687109
KL Loss                      2.2687109
QF Loss                      751.8358
VF Loss                      121.0618
Policy Loss                  -1211.0304
Q Predictions Mean           1213.6719
Q Predictions Std            262.2185
Q Predictions Max            1399.116
Q Predictions Min            -8.851146
V Predictions Mean           1213.7578
V Predictions Std            267.36917
V Predictions Max            1389.3936
V Predictions Min            -23.315998
Log Pis Mean                 -0.22069807
Log Pis Std                  2.7958193
Log Pis Max                  11.088518
Log Pis Min                  -9.89708
Policy mu Mean               0.006029768
Policy mu Std                0.6049613
Policy mu Max                2.090333
Policy mu Min                -2.1968563
Policy log std Mean          -0.9835906
Policy log std Std           0.26455003
Policy log std Max           -0.060685933
Policy log std Min           -2.171462
Z mean eval                  1.036154
Z variance eval              0.012133339
total_rewards                [ 248.85662101 3428.9217058  1953.33260154    8.30463092 3260.80858522
  113.45123643  127.76522638 3398.03283949   35.4398476  3324.76244313]
total_rewards_mean           1589.9675737518057
total_rewards_std            1536.848667744586
total_rewards_max            3428.9217057986725
total_rewards_min            8.304630919989382
Number of train steps total  409000
Number of env steps total    2047000
Number of rollouts total     0
Train Time (s)               44.29217812418938
(Previous) Eval Time (s)     26.81926427409053
Sample Time (s)              23.30772651778534
Epoch Time (s)               94.41916891606525
Total Train Time (s)         39164.47708381899
Epoch                        408
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:22:03.939385 UTC | [2020_01_10_11_29_18] Iteration #408 | Epoch Duration: 85.06222367286682
2020-01-10 22:22:03.939523 UTC | [2020_01_10_11_29_18] Iteration #408 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0352252
Z variance train             0.012096783
KL Divergence                22.700508
KL Loss                      2.2700508
QF Loss                      2019.1926
VF Loss                      1020.0441
Policy Loss                  -1193.7141
Q Predictions Mean           1192.2932
Q Predictions Std            290.80936
Q Predictions Max            1409.2358
Q Predictions Min            -17.916248
V Predictions Mean           1189.9558
V Predictions Std            290.57346
V Predictions Max            1394.0535
V Predictions Min            -25.225893
Log Pis Mean                 -0.1654764
Log Pis Std                  3.1667936
Log Pis Max                  12.05431
Log Pis Min                  -7.0533133
Policy mu Mean               0.001200017
Policy mu Std                0.6272009
Policy mu Max                2.8894358
Policy mu Min                -2.5015726
Policy log std Mean          -0.97769547
Policy log std Std           0.32672074
Policy log std Max           -0.05188924
Policy log std Min           -2.9323988
Z mean eval                  1.0013945
Z variance eval              0.014802359
total_rewards                [3405.53652999 3294.51870902 3479.78112605 3534.90041854 2043.38917852
 3458.78529526  687.36872439 3528.75684065 1683.43182642 1811.07394069]
total_rewards_mean           2692.754258953921
total_rewards_std            986.0954535162228
total_rewards_max            3534.900418542219
total_rewards_min            687.3687243918954
Number of train steps total  410000
Number of env steps total    2052000
Number of rollouts total     0
Train Time (s)               45.26020797388628
(Previous) Eval Time (s)     17.462083054706454
Sample Time (s)              22.77302049845457
Epoch Time (s)               85.4953115270473
Total Train Time (s)         39262.88920594379
Epoch                        409
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:23:42.360594 UTC | [2020_01_10_11_29_18] Iteration #409 | Epoch Duration: 98.42096972465515
2020-01-10 22:23:42.360731 UTC | [2020_01_10_11_29_18] Iteration #409 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0051882
Z variance train             0.014867915
KL Divergence                22.394863
KL Loss                      2.2394865
QF Loss                      687.90204
VF Loss                      328.0894
Policy Loss                  -1218.6871
Q Predictions Mean           1218.7014
Q Predictions Std            290.11737
Q Predictions Max            1447.6327
Q Predictions Min            -59.684376
V Predictions Mean           1206.9471
V Predictions Std            284.49908
V Predictions Max            1425.3762
V Predictions Min            -31.604185
Log Pis Mean                 -0.39451802
Log Pis Std                  2.7362096
Log Pis Max                  10.662193
Log Pis Min                  -10.863991
Policy mu Mean               -0.048158355
Policy mu Std                0.5872182
Policy mu Max                2.5792832
Policy mu Min                -2.2343836
Policy log std Mean          -0.97218335
Policy log std Std           0.27899057
Policy log std Max           -0.090842426
Policy log std Min           -2.7635195
Z mean eval                  1.0698893
Z variance eval              0.011833856
total_rewards                [3141.91265561 3256.38770617  475.48263935 3423.70057078 2351.87924336
 3125.35191716  204.28648974 3507.06072005 1983.59348332 3203.07748379]
total_rewards_mean           2467.273290932719
total_rewards_std            1156.884927952691
total_rewards_max            3507.060720049045
total_rewards_min            204.2864897394566
Number of train steps total  411000
Number of env steps total    2057000
Number of rollouts total     0
Train Time (s)               44.244925283361226
(Previous) Eval Time (s)     30.38749522715807
Sample Time (s)              22.808611524291337
Epoch Time (s)               97.44103203481063
Total Train Time (s)         39357.49278090475
Epoch                        410
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:25:16.972712 UTC | [2020_01_10_11_29_18] Iteration #410 | Epoch Duration: 94.61187601089478
2020-01-10 22:25:16.972855 UTC | [2020_01_10_11_29_18] Iteration #410 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0737728
Z variance train             0.011801886
KL Divergence                22.762772
KL Loss                      2.2762773
QF Loss                      618.26917
VF Loss                      242.03209
Policy Loss                  -1222.9491
Q Predictions Mean           1221.8333
Q Predictions Std            266.3687
Q Predictions Max            1443.0387
Q Predictions Min            -43.40276
V Predictions Mean           1219.4663
V Predictions Std            263.43866
V Predictions Max            1430.8461
V Predictions Min            -47.333008
Log Pis Mean                 0.0014571548
Log Pis Std                  2.929271
Log Pis Max                  18.276627
Log Pis Min                  -7.740324
Policy mu Mean               -0.01337615
Policy mu Std                0.62016004
Policy mu Max                2.614517
Policy mu Min                -3.6020167
Policy log std Mean          -0.9696564
Policy log std Std           0.26764417
Policy log std Max           0.28826404
Policy log std Min           -2.6064734
Z mean eval                  0.9857704
Z variance eval              0.011828112
total_rewards                [1985.62313921 3122.40131261 3307.84104877  108.75084424 3508.58629662
 3451.86642609 2109.70181337 3248.06604142  966.15381516 3241.62170072]
total_rewards_mean           2505.061243819908
total_rewards_std            1120.7278360670248
total_rewards_max            3508.5862966174063
total_rewards_min            108.75084423704044
Number of train steps total  412000
Number of env steps total    2062000
Number of rollouts total     0
Train Time (s)               45.143051717896014
(Previous) Eval Time (s)     27.558099942281842
Sample Time (s)              23.43182055838406
Epoch Time (s)               96.13297221856192
Total Train Time (s)         39456.2327911458
Epoch                        411
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:26:55.717519 UTC | [2020_01_10_11_29_18] Iteration #411 | Epoch Duration: 98.74451088905334
2020-01-10 22:26:55.717847 UTC | [2020_01_10_11_29_18] Iteration #411 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.989199
Z variance train             0.011878781
KL Divergence                23.525063
KL Loss                      2.3525064
QF Loss                      747.9619
VF Loss                      167.46463
Policy Loss                  -1239.8489
Q Predictions Mean           1241.2406
Q Predictions Std            242.32849
Q Predictions Max            1418.5247
Q Predictions Min            -17.03059
V Predictions Mean           1231.2948
V Predictions Std            241.21538
V Predictions Max            1408.2086
V Predictions Min            -22.208582
Log Pis Mean                 -0.12446725
Log Pis Std                  2.6626184
Log Pis Max                  7.3591537
Log Pis Min                  -8.793844
Policy mu Mean               0.03665758
Policy mu Std                0.62814885
Policy mu Max                2.6401377
Policy mu Min                -2.1789532
Policy log std Mean          -0.939914
Policy log std Std           0.24476796
Policy log std Max           0.0036262274
Policy log std Min           -2.2262223
Z mean eval                  1.0479935
Z variance eval              0.010115646
total_rewards                [1681.3254162   761.43628247 3235.58697881 1140.9362274  3514.19661718
  553.11748409 3334.69351821  731.66369017  430.69379622  129.19128909]
total_rewards_mean           1551.2841299849078
total_rewards_std            1250.0316550803218
total_rewards_max            3514.196617179651
total_rewards_min            129.19128908575763
Number of train steps total  413000
Number of env steps total    2067000
Number of rollouts total     0
Train Time (s)               44.53521346626803
(Previous) Eval Time (s)     30.16933489171788
Sample Time (s)              24.117212024517357
Epoch Time (s)               98.82176038250327
Total Train Time (s)         39544.64135169657
Epoch                        412
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:28:24.134444 UTC | [2020_01_10_11_29_18] Iteration #412 | Epoch Duration: 88.41633009910583
2020-01-10 22:28:24.134757 UTC | [2020_01_10_11_29_18] Iteration #412 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0474608
Z variance train             0.010083702
KL Divergence                24.370651
KL Loss                      2.4370651
QF Loss                      569.6846
VF Loss                      236.54716
Policy Loss                  -1249.5358
Q Predictions Mean           1249.8999
Q Predictions Std            204.2069
Q Predictions Max            1446.8606
Q Predictions Min            -28.732615
V Predictions Mean           1246.3557
V Predictions Std            201.34149
V Predictions Max            1451.146
V Predictions Min            -6.8784523
Log Pis Mean                 -0.003900554
Log Pis Std                  2.7658656
Log Pis Max                  8.233318
Log Pis Min                  -8.058088
Policy mu Mean               -0.018061787
Policy mu Std                0.62799877
Policy mu Max                2.4001534
Policy mu Min                -2.382896
Policy log std Mean          -0.9602022
Policy log std Std           0.24248236
Policy log std Max           0.0013353825
Policy log std Min           -2.051086
Z mean eval                  1.0256621
Z variance eval              0.008757405
total_rewards                [2849.88575318 1990.77784112 2879.10741047 3103.22410617   91.97876469
 2016.72440347 3211.27551885 1886.67555999  176.14077515 1774.90169246]
total_rewards_mean           1998.0691825547292
total_rewards_std            1058.785818762058
total_rewards_max            3211.2755188462033
total_rewards_min            91.97876469125089
Number of train steps total  414000
Number of env steps total    2072000
Number of rollouts total     0
Train Time (s)               45.95025800913572
(Previous) Eval Time (s)     19.763649913016707
Sample Time (s)              23.553115832153708
Epoch Time (s)               89.26702375430614
Total Train Time (s)         39640.72245368501
Epoch                        413
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:30:00.220473 UTC | [2020_01_10_11_29_18] Iteration #413 | Epoch Duration: 96.0854959487915
2020-01-10 22:30:00.220632 UTC | [2020_01_10_11_29_18] Iteration #413 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0258608
Z variance train             0.008738952
KL Divergence                24.157064
KL Loss                      2.4157064
QF Loss                      708.48145
VF Loss                      170.27243
Policy Loss                  -1232.6514
Q Predictions Mean           1232.6807
Q Predictions Std            252.0977
Q Predictions Max            1478.0758
Q Predictions Min            -64.7864
V Predictions Mean           1232.3442
V Predictions Std            248.38927
V Predictions Max            1467.0239
V Predictions Min            -31.537327
Log Pis Mean                 -0.07828901
Log Pis Std                  2.6995087
Log Pis Max                  10.556365
Log Pis Min                  -7.2711105
Policy mu Mean               -0.051761575
Policy mu Std                0.60014224
Policy mu Max                2.2596512
Policy mu Min                -2.5821507
Policy log std Mean          -1.0034885
Policy log std Std           0.26160854
Policy log std Max           -0.04568684
Policy log std Min           -2.4531035
Z mean eval                  1.0338982
Z variance eval              0.0077575906
total_rewards                [2910.262665   3443.44783559 2853.37227357 3159.76029674 2947.37549214
 3276.15238591 1811.5874912  3452.28755432  987.56030437  621.9871153 ]
total_rewards_mean           2546.379341413386
total_rewards_std            979.5295506544124
total_rewards_max            3452.287554319892
total_rewards_min            621.9871153043426
Number of train steps total  415000
Number of env steps total    2077000
Number of rollouts total     0
Train Time (s)               45.3693767990917
(Previous) Eval Time (s)     26.58189322706312
Sample Time (s)              23.565447613596916
Epoch Time (s)               95.51671763975173
Total Train Time (s)         39737.53491226444
Epoch                        414
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:31:37.035818 UTC | [2020_01_10_11_29_18] Iteration #414 | Epoch Duration: 96.81506276130676
2020-01-10 22:31:37.035956 UTC | [2020_01_10_11_29_18] Iteration #414 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0312959
Z variance train             0.0077841654
KL Divergence                24.218723
KL Loss                      2.4218724
QF Loss                      5014.558
VF Loss                      483.99026
Policy Loss                  -1259.9254
Q Predictions Mean           1260.0408
Q Predictions Std            191.18842
Q Predictions Max            1440.5209
Q Predictions Min            -12.699808
V Predictions Mean           1247.7417
V Predictions Std            187.90851
V Predictions Max            1423.9653
V Predictions Min            -10.949465
Log Pis Mean                 -0.13392428
Log Pis Std                  2.7787058
Log Pis Max                  11.456217
Log Pis Min                  -7.269234
Policy mu Mean               0.0071477303
Policy mu Std                0.61871904
Policy mu Max                2.2958324
Policy mu Min                -2.304995
Policy log std Mean          -0.9591774
Policy log std Std           0.24038765
Policy log std Max           0.017386973
Policy log std Min           -2.1938348
Z mean eval                  1.0818851
Z variance eval              0.0077390433
total_rewards                [  43.9310493  3094.76832257 3381.4424537  3447.91413491  863.44207318
 3044.57614983 -326.86494198 2707.28814328 3330.11629668 3492.39047166]
total_rewards_mean           2307.900415313528
total_rewards_std            1427.4254540847828
total_rewards_max            3492.39047166214
total_rewards_min            -326.86494197508216
Number of train steps total  416000
Number of env steps total    2082000
Number of rollouts total     0
Train Time (s)               44.60875621205196
(Previous) Eval Time (s)     27.880009159911424
Sample Time (s)              20.7353726439178
Epoch Time (s)               93.22413801588118
Total Train Time (s)         39834.983604289126
Epoch                        415
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:33:14.491103 UTC | [2020_01_10_11_29_18] Iteration #415 | Epoch Duration: 97.4550313949585
2020-01-10 22:33:14.491279 UTC | [2020_01_10_11_29_18] Iteration #415 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0826495
Z variance train             0.00773132
KL Divergence                24.14346
KL Loss                      2.414346
QF Loss                      1553.5767
VF Loss                      236.08221
Policy Loss                  -1236.7117
Q Predictions Mean           1237.6553
Q Predictions Std            244.18416
Q Predictions Max            1483.1783
Q Predictions Min            -21.00411
V Predictions Mean           1243.9509
V Predictions Std            246.17834
V Predictions Max            1492.7587
V Predictions Min            -18.094728
Log Pis Mean                 -0.16560706
Log Pis Std                  2.7777658
Log Pis Max                  11.208456
Log Pis Min                  -7.56629
Policy mu Mean               -0.034636494
Policy mu Std                0.5968763
Policy mu Max                2.5430036
Policy mu Min                -2.7244256
Policy log std Mean          -0.9944286
Policy log std Std           0.27104133
Policy log std Max           -0.13200581
Policy log std Min           -2.9496384
Z mean eval                  1.0348384
Z variance eval              0.013987335
total_rewards                [3235.38584857 1579.23671918 3319.81141213 3167.1473193  3330.16839314
  993.74362901 3002.06136074 3180.94337561 3364.67856862 1218.29374239]
total_rewards_mean           2639.1470368687883
total_rewards_std            915.2230301212118
total_rewards_max            3364.6785686184894
total_rewards_min            993.7436290147666
Number of train steps total  417000
Number of env steps total    2087000
Number of rollouts total     0
Train Time (s)               45.25479345070198
(Previous) Eval Time (s)     32.110669458750635
Sample Time (s)              23.31876047886908
Epoch Time (s)               100.6842233883217
Total Train Time (s)         39932.12308773957
Epoch                        416
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:34:51.638981 UTC | [2020_01_10_11_29_18] Iteration #416 | Epoch Duration: 97.14752316474915
2020-01-10 22:34:51.639309 UTC | [2020_01_10_11_29_18] Iteration #416 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0355978
Z variance train             0.014022809
KL Divergence                22.893568
KL Loss                      2.289357
QF Loss                      1113.3567
VF Loss                      936.389
Policy Loss                  -1217.5011
Q Predictions Mean           1217.4396
Q Predictions Std            269.80273
Q Predictions Max            1470.5842
Q Predictions Min            -29.460215
V Predictions Mean           1211.0087
V Predictions Std            270.0324
V Predictions Max            1448.1427
V Predictions Min            -32.39062
Log Pis Mean                 0.26914397
Log Pis Std                  3.2417037
Log Pis Max                  15.502058
Log Pis Min                  -8.396801
Policy mu Mean               -0.052477956
Policy mu Std                0.66522706
Policy mu Max                2.613759
Policy mu Min                -2.2577322
Policy log std Mean          -0.961903
Policy log std Std           0.3274202
Policy log std Max           -0.11529046
Policy log std Min           -3.6234863
Z mean eval                  1.028744
Z variance eval              0.009470059
total_rewards                [3234.95236461 2202.70185199 3542.38445746  457.42704143 2988.01575077
  768.30317739 3304.17756073 3464.88527323 2137.11268746 2074.42104655]
total_rewards_mean           2417.4381211623354
total_rewards_std            1046.254711924305
total_rewards_max            3542.3844574635577
total_rewards_min            457.42704143054993
Number of train steps total  418000
Number of env steps total    2092000
Number of rollouts total     0
Train Time (s)               44.27523784805089
(Previous) Eval Time (s)     28.573697823099792
Sample Time (s)              23.4787191064097
Epoch Time (s)               96.32765477756038
Total Train Time (s)         40024.938061282504
Epoch                        417
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:36:24.458205 UTC | [2020_01_10_11_29_18] Iteration #417 | Epoch Duration: 92.81867384910583
2020-01-10 22:36:24.458370 UTC | [2020_01_10_11_29_18] Iteration #417 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.026193
Z variance train             0.009448031
KL Divergence                23.717937
KL Loss                      2.3717937
QF Loss                      561.66626
VF Loss                      77.55141
Policy Loss                  -1275.7756
Q Predictions Mean           1278.4928
Q Predictions Std            165.69046
Q Predictions Max            1469.6403
Q Predictions Min            40.724396
V Predictions Mean           1276.855
V Predictions Std            164.16266
V Predictions Max            1465.1865
V Predictions Min            55.13184
Log Pis Mean                 -0.24399543
Log Pis Std                  2.7471504
Log Pis Max                  7.03839
Log Pis Min                  -10.113986
Policy mu Mean               -0.017359274
Policy mu Std                0.6420698
Policy mu Max                3.0284402
Policy mu Min                -2.194507
Policy log std Mean          -0.96314967
Policy log std Std           0.22551478
Policy log std Max           -0.15050745
Policy log std Min           -1.9600143
Z mean eval                  1.0176742
Z variance eval              0.008262867
total_rewards                [2402.37265972 3379.26465552 3248.32031914 2762.24444933 2419.80625521
 3239.85721472 3442.49359689 2125.99338831 1153.10884456 3393.47679057]
total_rewards_mean           2756.6938173967974
total_rewards_std            703.3411082047018
total_rewards_max            3442.4935968943746
total_rewards_min            1153.108844556182
Number of train steps total  419000
Number of env steps total    2097000
Number of rollouts total     0
Train Time (s)               45.11924223322421
(Previous) Eval Time (s)     25.06448988476768
Sample Time (s)              23.2060383297503
Epoch Time (s)               93.3897704477422
Total Train Time (s)         40127.62929618172
Epoch                        418
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:38:07.151755 UTC | [2020_01_10_11_29_18] Iteration #418 | Epoch Duration: 102.69326591491699
2020-01-10 22:38:07.151906 UTC | [2020_01_10_11_29_18] Iteration #418 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0159556
Z variance train             0.008260893
KL Divergence                23.834673
KL Loss                      2.3834674
QF Loss                      1664.855
VF Loss                      608.33484
Policy Loss                  -1235.6527
Q Predictions Mean           1230.2649
Q Predictions Std            270.74298
Q Predictions Max            1440.2133
Q Predictions Min            -60.792645
V Predictions Mean           1230.6335
V Predictions Std            253.70517
V Predictions Max            1423.4999
V Predictions Min            -41.79991
Log Pis Mean                 0.10304212
Log Pis Std                  2.9041257
Log Pis Max                  11.964308
Log Pis Min                  -7.3643026
Policy mu Mean               0.027784247
Policy mu Std                0.63010055
Policy mu Max                3.247645
Policy mu Min                -2.1805847
Policy log std Mean          -0.9836069
Policy log std Std           0.27975595
Policy log std Max           0.016305566
Policy log std Min           -2.5021977
Z mean eval                  1.0303955
Z variance eval              0.008248588
total_rewards                [  45.81414917 2465.48710801  986.78688356 3335.08886408 1005.30738593
 3094.37146509  298.66671917 1153.97378507 1300.93724487 3367.88521006]
total_rewards_mean           1705.431881500707
total_rewards_std            1188.866526976616
total_rewards_max            3367.885210055326
total_rewards_min            45.81414917093253
Number of train steps total  420000
Number of env steps total    2102000
Number of rollouts total     0
Train Time (s)               44.697524493094534
(Previous) Eval Time (s)     34.367749891709536
Sample Time (s)              23.321374541148543
Epoch Time (s)               102.38664892595261
Total Train Time (s)         40219.04127047304
Epoch                        419
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:39:38.566481 UTC | [2020_01_10_11_29_18] Iteration #419 | Epoch Duration: 91.41445994377136
2020-01-10 22:39:38.566619 UTC | [2020_01_10_11_29_18] Iteration #419 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0321182
Z variance train             0.00824371
KL Divergence                23.542624
KL Loss                      2.3542624
QF Loss                      528.58636
VF Loss                      301.8884
Policy Loss                  -1250.1503
Q Predictions Mean           1254.1047
Q Predictions Std            247.01733
Q Predictions Max            1430.2578
Q Predictions Min            -34.20643
V Predictions Mean           1257.706
V Predictions Std            248.97858
V Predictions Max            1432.766
V Predictions Min            -34.69539
Log Pis Mean                 0.15313579
Log Pis Std                  2.6267157
Log Pis Max                  7.7022486
Log Pis Min                  -6.650197
Policy mu Mean               -0.029272914
Policy mu Std                0.6519329
Policy mu Max                2.3775668
Policy mu Min                -2.0897017
Policy log std Mean          -0.94121456
Policy log std Std           0.23756431
Policy log std Max           -0.12538034
Policy log std Min           -1.9618363
Z mean eval                  1.01289
Z variance eval              0.008246786
total_rewards                [3341.24673882 3000.9516346  1626.21735297 3483.66816955 3280.95748972
  572.32013332 2525.23058594 3250.50818049 3349.94379975 2206.83176285]
total_rewards_mean           2663.787584800393
total_rewards_std            901.0870949620412
total_rewards_max            3483.6681695480406
total_rewards_min            572.3201333232357
Number of train steps total  421000
Number of env steps total    2107000
Number of rollouts total     0
Train Time (s)               44.4648213670589
(Previous) Eval Time (s)     23.395330177154392
Sample Time (s)              22.66317068785429
Epoch Time (s)               90.52332223206758
Total Train Time (s)         40313.5960946437
Epoch                        420
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:41:13.128283 UTC | [2020_01_10_11_29_18] Iteration #420 | Epoch Duration: 94.56153225898743
2020-01-10 22:41:13.128533 UTC | [2020_01_10_11_29_18] Iteration #420 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0119569
Z variance train             0.008252574
KL Divergence                22.989716
KL Loss                      2.2989717
QF Loss                      5425.8345
VF Loss                      76.605095
Policy Loss                  -1237.6985
Q Predictions Mean           1238.523
Q Predictions Std            272.04898
Q Predictions Max            1424.6704
Q Predictions Min            -52.42644
V Predictions Mean           1238.8628
V Predictions Std            270.83307
V Predictions Max            1422.705
V Predictions Min            -57.147667
Log Pis Mean                 0.114638545
Log Pis Std                  2.375662
Log Pis Max                  9.103771
Log Pis Min                  -7.2057877
Policy mu Mean               0.0077580838
Policy mu Std                0.5830492
Policy mu Max                2.2293048
Policy mu Min                -2.130914
Policy log std Mean          -1.0010647
Policy log std Std           0.24232166
Policy log std Max           0.042651653
Policy log std Min           -2.0626082
Z mean eval                  1.0034833
Z variance eval              0.006826099
total_rewards                [3439.09231075 1767.20904925 3319.01971718 3337.00455987 3585.98426575
 3393.59357537 3366.61911542 3202.66736393 3140.79521302 3741.19828822]
total_rewards_mean           3229.318345875413
total_rewards_std            514.2983078254681
total_rewards_max            3741.1982882235457
total_rewards_min            1767.20904925136
Number of train steps total  422000
Number of env steps total    2112000
Number of rollouts total     0
Train Time (s)               45.84482550015673
(Previous) Eval Time (s)     27.433250584173948
Sample Time (s)              23.59747450845316
Epoch Time (s)               96.87555059278384
Total Train Time (s)         40418.361010619905
Epoch                        421
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:42:57.895989 UTC | [2020_01_10_11_29_18] Iteration #421 | Epoch Duration: 104.76730251312256
2020-01-10 22:42:57.896125 UTC | [2020_01_10_11_29_18] Iteration #421 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0076231
Z variance train             0.006831953
KL Divergence                24.123234
KL Loss                      2.4123235
QF Loss                      744.22076
VF Loss                      279.95956
Policy Loss                  -1267.6007
Q Predictions Mean           1270.4133
Q Predictions Std            221.86836
Q Predictions Max            1490.4502
Q Predictions Min            -34.393745
V Predictions Mean           1276.2012
V Predictions Std            226.266
V Predictions Max            1487.0244
V Predictions Min            -36.88836
Log Pis Mean                 0.45497602
Log Pis Std                  2.8994095
Log Pis Max                  10.0706835
Log Pis Min                  -7.3175254
Policy mu Mean               -0.057421554
Policy mu Std                0.6317001
Policy mu Max                2.5468056
Policy mu Min                -2.20633
Policy log std Mean          -1.0379128
Policy log std Std           0.2660076
Policy log std Max           0.013679028
Policy log std Min           -2.4234877
Z mean eval                  1.0052582
Z variance eval              0.0077488897
total_rewards                [2723.60595732 3365.03131336 3741.31283875 3569.14110606 3409.8276224
 3534.77432766 1067.25337896 3556.43463262 3553.47791388 3546.31100057]
total_rewards_mean           3206.717009157166
total_rewards_std            758.9238041398314
total_rewards_max            3741.312838745622
total_rewards_min            1067.2533789644474
Number of train steps total  423000
Number of env steps total    2117000
Number of rollouts total     0
Train Time (s)               44.82978154392913
(Previous) Eval Time (s)     35.32476619211957
Sample Time (s)              24.09856772981584
Epoch Time (s)               104.25311546586454
Total Train Time (s)         40520.069782048464
Epoch                        422
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:44:39.607703 UTC | [2020_01_10_11_29_18] Iteration #422 | Epoch Duration: 101.71147513389587
2020-01-10 22:44:39.607838 UTC | [2020_01_10_11_29_18] Iteration #422 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0034401
Z variance train             0.0077599287
KL Divergence                24.557026
KL Loss                      2.4557025
QF Loss                      715.131
VF Loss                      134.6805
Policy Loss                  -1248.4429
Q Predictions Mean           1251.3627
Q Predictions Std            238.69319
Q Predictions Max            1459.4116
Q Predictions Min            -25.977493
V Predictions Mean           1241.7291
V Predictions Std            239.08458
V Predictions Max            1447.299
V Predictions Min            -46.666916
Log Pis Mean                 0.043815166
Log Pis Std                  2.842502
Log Pis Max                  17.409136
Log Pis Min                  -8.317044
Policy mu Mean               -0.05206063
Policy mu Std                0.6296487
Policy mu Max                2.668606
Policy mu Min                -2.460095
Policy log std Mean          -1.013893
Policy log std Std           0.25681877
Policy log std Max           -0.1068486
Policy log std Min           -2.7356758
Z mean eval                  1.0255945
Z variance eval              0.011121875
total_rewards                [ 743.42797719 1073.68129269  412.46017252 3554.26761023  623.69979353
 3200.36874015 3395.0316663   388.14256423 2573.62304988  215.4750749 ]
total_rewards_mean           1618.0177941614788
total_rewards_std            1315.5540191820116
total_rewards_max            3554.267610234874
total_rewards_min            215.47507490343898
Number of train steps total  424000
Number of env steps total    2122000
Number of rollouts total     0
Train Time (s)               46.04531857930124
(Previous) Eval Time (s)     32.78287522401661
Sample Time (s)              23.392290176358074
Epoch Time (s)               102.22048397967592
Total Train Time (s)         40608.04167158762
Epoch                        423
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:46:07.583733 UTC | [2020_01_10_11_29_18] Iteration #423 | Epoch Duration: 87.97578191757202
2020-01-10 22:46:07.583908 UTC | [2020_01_10_11_29_18] Iteration #423 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0259382
Z variance train             0.011121332
KL Divergence                24.113945
KL Loss                      2.4113946
QF Loss                      1375.1587
VF Loss                      780.1207
Policy Loss                  -1251.292
Q Predictions Mean           1251.534
Q Predictions Std            219.24294
Q Predictions Max            1465.5292
Q Predictions Min            -62.37482
V Predictions Mean           1258.0049
V Predictions Std            209.83754
V Predictions Max            1467.868
V Predictions Min            -51.81044
Log Pis Mean                 0.054106187
Log Pis Std                  2.7155511
Log Pis Max                  11.883405
Log Pis Min                  -6.692524
Policy mu Mean               -0.030833816
Policy mu Std                0.6186742
Policy mu Max                3.0899875
Policy mu Min                -2.1641176
Policy log std Mean          -0.98919654
Policy log std Std           0.2733179
Policy log std Max           -0.14988148
Policy log std Min           -2.6671958
Z mean eval                  1.0038515
Z variance eval              0.010042288
total_rewards                [2209.89133923 3482.61490199  650.04949986  643.12418135 3512.04584091
 3470.90820398 3495.26382979  320.13166032  230.22578668 3590.17221242]
total_rewards_mean           2160.4427456533463
total_rewards_std            1442.7970916175564
total_rewards_max            3590.172212416715
total_rewards_min            230.22578667759262
Number of train steps total  425000
Number of env steps total    2127000
Number of rollouts total     0
Train Time (s)               46.454893433023244
(Previous) Eval Time (s)     18.537924277596176
Sample Time (s)              22.832088176626712
Epoch Time (s)               87.82490588724613
Total Train Time (s)         40702.70061707869
Epoch                        424
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:47:42.248389 UTC | [2020_01_10_11_29_18] Iteration #424 | Epoch Duration: 94.66431021690369
2020-01-10 22:47:42.248615 UTC | [2020_01_10_11_29_18] Iteration #424 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99992913
Z variance train             0.010018502
KL Divergence                23.976482
KL Loss                      2.3976483
QF Loss                      5128.1445
VF Loss                      1037.5825
Policy Loss                  -1231.4592
Q Predictions Mean           1234.8208
Q Predictions Std            282.82874
Q Predictions Max            1442.6295
Q Predictions Min            -110.99416
V Predictions Mean           1248.2181
V Predictions Std            277.40952
V Predictions Max            1452.2129
V Predictions Min            -30.782507
Log Pis Mean                 0.56299967
Log Pis Std                  2.9844203
Log Pis Max                  14.59856
Log Pis Min                  -6.6794796
Policy mu Mean               -0.061390035
Policy mu Std                0.6628267
Policy mu Max                2.2127354
Policy mu Min                -2.1996562
Policy log std Mean          -0.97462404
Policy log std Std           0.29604858
Policy log std Max           -0.14635491
Policy log std Min           -2.8948848
Z mean eval                  1.0347853
Z variance eval              0.007290247
total_rewards                [3439.95957963 3402.97181461  279.19137198 3113.18478784  283.36874516
  454.90191509 3592.58695112 1202.57618289 3250.75122114  638.52716765]
total_rewards_mean           1965.8019737108905
total_rewards_std            1419.677320665677
total_rewards_max            3592.5869511179903
total_rewards_min            279.1913719765071
Number of train steps total  426000
Number of env steps total    2132000
Number of rollouts total     0
Train Time (s)               44.34971977490932
(Previous) Eval Time (s)     25.37709432374686
Sample Time (s)              23.046606902498752
Epoch Time (s)               92.77342100115493
Total Train Time (s)         40790.18155214703
Epoch                        425
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:49:09.735788 UTC | [2020_01_10_11_29_18] Iteration #425 | Epoch Duration: 87.48701238632202
2020-01-10 22:49:09.735960 UTC | [2020_01_10_11_29_18] Iteration #425 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0339947
Z variance train             0.0072770296
KL Divergence                24.744015
KL Loss                      2.4744015
QF Loss                      1524.8696
VF Loss                      209.99905
Policy Loss                  -1255.6517
Q Predictions Mean           1255.5933
Q Predictions Std            276.37778
Q Predictions Max            1477.9346
Q Predictions Min            -71.80145
V Predictions Mean           1247.1453
V Predictions Std            273.93063
V Predictions Max            1461.9044
V Predictions Min            -59.588444
Log Pis Mean                 -0.150448
Log Pis Std                  2.6326208
Log Pis Max                  8.047585
Log Pis Min                  -9.141224
Policy mu Mean               -0.023312384
Policy mu Std                0.6218148
Policy mu Max                2.1984315
Policy mu Min                -2.1590698
Policy log std Mean          -0.96365017
Policy log std Std           0.24014805
Policy log std Max           -0.24401951
Policy log std Min           -2.3475125
Z mean eval                  1.0083063
Z variance eval              0.011251929
total_rewards                [3244.45183323 3545.25107697 3589.8440467  3426.86575067 3432.4868369
 3626.94271749  -61.84053444 1534.1465193  3598.32615693 3378.97581818]
total_rewards_mean           2931.54502219235
total_rewards_std            1159.5532650765845
total_rewards_max            3626.9427174880902
total_rewards_min            -61.840534437885665
Number of train steps total  427000
Number of env steps total    2137000
Number of rollouts total     0
Train Time (s)               44.99943253118545
(Previous) Eval Time (s)     20.090449772775173
Sample Time (s)              23.413376480340958
Epoch Time (s)               88.50325878430158
Total Train Time (s)         40892.61326274881
Epoch                        426
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:50:52.172278 UTC | [2020_01_10_11_29_18] Iteration #426 | Epoch Duration: 102.4361720085144
2020-01-10 22:50:52.172447 UTC | [2020_01_10_11_29_18] Iteration #426 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0081979
Z variance train             0.011165513
KL Divergence                22.837605
KL Loss                      2.2837605
QF Loss                      679.7871
VF Loss                      228.64078
Policy Loss                  -1259.5518
Q Predictions Mean           1261.2273
Q Predictions Std            258.11914
Q Predictions Max            1467.5787
Q Predictions Min            -96.82638
V Predictions Mean           1253.378
V Predictions Std            251.23758
V Predictions Max            1457.6455
V Predictions Min            -82.83762
Log Pis Mean                 -0.1178371
Log Pis Std                  2.5983965
Log Pis Max                  10.779191
Log Pis Min                  -8.187844
Policy mu Mean               -0.0077576553
Policy mu Std                0.5823096
Policy mu Max                2.3254948
Policy mu Min                -2.2426066
Policy log std Mean          -1.0214844
Policy log std Std           0.26785266
Policy log std Max           -0.13625127
Policy log std Min           -2.579844
Z mean eval                  1.0392597
Z variance eval              0.0075250464
total_rewards                [3450.22776214  396.75302197 3341.48514356 2189.32114329 3332.57172706
 2703.7853     3324.03369382  779.33541549 2807.64907078 3374.46173935]
total_rewards_mean           2569.962401747215
total_rewards_std            1063.7671468547207
total_rewards_max            3450.2277621392886
total_rewards_min            396.75302196929346
Number of train steps total  428000
Number of env steps total    2142000
Number of rollouts total     0
Train Time (s)               44.36522172531113
(Previous) Eval Time (s)     34.023123597726226
Sample Time (s)              21.908063852693886
Epoch Time (s)               100.29640917573124
Total Train Time (s)         40986.361736217514
Epoch                        427
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:52:25.924982 UTC | [2020_01_10_11_29_18] Iteration #427 | Epoch Duration: 93.75240516662598
2020-01-10 22:52:25.925160 UTC | [2020_01_10_11_29_18] Iteration #427 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0396518
Z variance train             0.0075268755
KL Divergence                23.644047
KL Loss                      2.3644047
QF Loss                      1104.9435
VF Loss                      440.3947
Policy Loss                  -1282.2814
Q Predictions Mean           1282.3511
Q Predictions Std            192.84608
Q Predictions Max            1499.0823
Q Predictions Min            -75.89316
V Predictions Mean           1288.5774
V Predictions Std            189.9356
V Predictions Max            1472.9363
V Predictions Min            -64.88662
Log Pis Mean                 0.34856755
Log Pis Std                  2.8220644
Log Pis Max                  13.547977
Log Pis Min                  -6.8701
Policy mu Mean               -0.054689974
Policy mu Std                0.6308437
Policy mu Max                2.6356316
Policy mu Min                -2.2081723
Policy log std Mean          -1.010876
Policy log std Std           0.25460353
Policy log std Max           -0.060376167
Policy log std Min           -2.5587368
Z mean eval                  1.0251161
Z variance eval              0.008380964
total_rewards                [3474.04863983 2120.24371414 3325.0073644  3210.26612975 3566.4644744
 1579.58874106 3399.24295184 3249.5163545    55.17765671 3439.65983474]
total_rewards_mean           2741.921586136569
total_rewards_std            1091.2320140783315
total_rewards_max            3566.464474399183
total_rewards_min            55.177656709115425
Number of train steps total  429000
Number of env steps total    2147000
Number of rollouts total     0
Train Time (s)               44.614678986836225
(Previous) Eval Time (s)     27.478872739244252
Sample Time (s)              23.47980196774006
Epoch Time (s)               95.57335369382054
Total Train Time (s)         41087.48365883622
Epoch                        428
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:54:07.050711 UTC | [2020_01_10_11_29_18] Iteration #428 | Epoch Duration: 101.12541937828064
2020-01-10 22:54:07.050885 UTC | [2020_01_10_11_29_18] Iteration #428 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0262892
Z variance train             0.00837911
KL Divergence                23.594484
KL Loss                      2.3594484
QF Loss                      588.9033
VF Loss                      108.96529
Policy Loss                  -1250.5767
Q Predictions Mean           1250.3955
Q Predictions Std            283.95886
Q Predictions Max            1461.0033
Q Predictions Min            -67.577156
V Predictions Mean           1250.6554
V Predictions Std            283.40256
V Predictions Max            1450.7021
V Predictions Min            -66.85708
Log Pis Mean                 -0.09958114
Log Pis Std                  2.6077905
Log Pis Max                  9.807378
Log Pis Min                  -7.0840187
Policy mu Mean               -0.067935556
Policy mu Std                0.6146458
Policy mu Max                2.1091223
Policy mu Min                -2.3276196
Policy log std Mean          -0.9770805
Policy log std Std           0.24647745
Policy log std Max           -0.058705032
Policy log std Min           -1.9927838
Z mean eval                  1.0785028
Z variance eval              0.012899501
total_rewards                [1102.86016425 3669.25149049 2622.48385533 2307.80621728 2693.95410885
 3360.90671916 3265.85945145 3661.26345835 -176.18791244 2090.45289992]
total_rewards_mean           2459.8650452628376
total_rewards_std            1157.5208003321457
total_rewards_max            3669.2514904889167
total_rewards_min            -176.18791243512769
Number of train steps total  430000
Number of env steps total    2152000
Number of rollouts total     0
Train Time (s)               45.07438814686611
(Previous) Eval Time (s)     33.03069460671395
Sample Time (s)              23.364302890840918
Epoch Time (s)               101.46938564442098
Total Train Time (s)         41187.30767137976
Epoch                        429
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:55:46.878202 UTC | [2020_01_10_11_29_18] Iteration #429 | Epoch Duration: 99.82717704772949
2020-01-10 22:55:46.878379 UTC | [2020_01_10_11_29_18] Iteration #429 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0776271
Z variance train             0.012942165
KL Divergence                23.647915
KL Loss                      2.3647916
QF Loss                      714.23346
VF Loss                      196.3972
Policy Loss                  -1229.6556
Q Predictions Mean           1232.5171
Q Predictions Std            286.24683
Q Predictions Max            1440.1976
Q Predictions Min            -91.04878
V Predictions Mean           1237.3241
V Predictions Std            286.1578
V Predictions Max            1444.0941
V Predictions Min            -72.60744
Log Pis Mean                 -0.020865675
Log Pis Std                  2.4383976
Log Pis Max                  6.621042
Log Pis Min                  -6.2682853
Policy mu Mean               -0.015088372
Policy mu Std                0.6115112
Policy mu Max                2.1840708
Policy mu Min                -2.1866727
Policy log std Mean          -0.9710824
Policy log std Std           0.2641129
Policy log std Max           0.02787733
Policy log std Min           -2.1691613
Z mean eval                  1.0260079
Z variance eval              0.020809675
total_rewards                [1878.28524217 2278.6881413   516.08047383 3165.72608092 3240.8796537
 3450.64177946 2080.76049229  716.4530379  2463.46347075 1769.86101662]
total_rewards_mean           2156.083938893391
total_rewards_std            947.4025199006135
total_rewards_max            3450.64177945526
total_rewards_min            516.0804738289673
Number of train steps total  431000
Number of env steps total    2157000
Number of rollouts total     0
Train Time (s)               44.49210309702903
(Previous) Eval Time (s)     31.388244224712253
Sample Time (s)              22.91866764659062
Epoch Time (s)               98.7990149683319
Total Train Time (s)         41283.1921549011
Epoch                        430
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:57:22.768838 UTC | [2020_01_10_11_29_18] Iteration #430 | Epoch Duration: 95.89032626152039
2020-01-10 22:57:22.768993 UTC | [2020_01_10_11_29_18] Iteration #430 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0228221
Z variance train             0.020805802
KL Divergence                22.358234
KL Loss                      2.2358234
QF Loss                      835.86145
VF Loss                      350.41925
Policy Loss                  -1249.212
Q Predictions Mean           1249.5566
Q Predictions Std            282.39014
Q Predictions Max            1509.3157
Q Predictions Min            -63.2219
V Predictions Mean           1238.0109
V Predictions Std            279.4227
V Predictions Max            1496.3511
V Predictions Min            -62.924213
Log Pis Mean                 0.10496138
Log Pis Std                  2.6795216
Log Pis Max                  9.318714
Log Pis Min                  -7.0852356
Policy mu Mean               0.012612013
Policy mu Std                0.64442146
Policy mu Max                3.1446836
Policy mu Min                -2.678449
Policy log std Mean          -0.9678641
Policy log std Std           0.2627672
Policy log std Max           -0.151909
Policy log std Min           -2.3076463
Z mean eval                  1.0174514
Z variance eval              0.018945167
total_rewards                [2254.52343823  275.20296911 1531.5680596  3410.95572688 2969.29327824
 3548.74647449 3272.89205533 3411.48091844 3375.9690368  1528.67792484]
total_rewards_mean           2557.9309881969853
total_rewards_std            1058.4504998529528
total_rewards_max            3548.7464744933623
total_rewards_min            275.20296910971774
Number of train steps total  432000
Number of env steps total    2162000
Number of rollouts total     0
Train Time (s)               44.71931634563953
(Previous) Eval Time (s)     28.47931223688647
Sample Time (s)              22.737080812454224
Epoch Time (s)               95.93570939498022
Total Train Time (s)         41380.300162871834
Epoch                        431
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:58:59.879607 UTC | [2020_01_10_11_29_18] Iteration #431 | Epoch Duration: 97.110511302948
2020-01-10 22:58:59.879753 UTC | [2020_01_10_11_29_18] Iteration #431 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0178797
Z variance train             0.018869746
KL Divergence                23.26145
KL Loss                      2.326145
QF Loss                      1437.4402
VF Loss                      874.88495
Policy Loss                  -1258.1871
Q Predictions Mean           1258.1428
Q Predictions Std            283.97626
Q Predictions Max            1501.631
Q Predictions Min            -60.679546
V Predictions Mean           1254.853
V Predictions Std            287.28253
V Predictions Max            1473.0947
V Predictions Min            -62.720215
Log Pis Mean                 0.21284309
Log Pis Std                  3.189821
Log Pis Max                  15.1386175
Log Pis Min                  -7.906308
Policy mu Mean               -0.030060425
Policy mu Std                0.6390767
Policy mu Max                2.0858
Policy mu Min                -2.8254135
Policy log std Mean          -1.0071188
Policy log std Std           0.28108785
Policy log std Max           0.039325356
Policy log std Min           -2.9738183
Z mean eval                  0.98458636
Z variance eval              0.014811581
total_rewards                [2647.67227793 3277.5085455  3468.86222396 1439.1348569  3515.56645514
 2443.97668891 1321.51092255 3387.40825912 3017.29805199  829.10992156]
total_rewards_mean           2534.804820358294
total_rewards_std            945.9733841230193
total_rewards_max            3515.566455137552
total_rewards_min            829.1099215587207
Number of train steps total  433000
Number of env steps total    2167000
Number of rollouts total     0
Train Time (s)               44.42767481086776
(Previous) Eval Time (s)     29.653855833224952
Sample Time (s)              22.66775797959417
Epoch Time (s)               96.74928862368688
Total Train Time (s)         41480.794494901784
Epoch                        432
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:00:40.378443 UTC | [2020_01_10_11_29_18] Iteration #432 | Epoch Duration: 100.49857902526855
2020-01-10 23:00:40.378617 UTC | [2020_01_10_11_29_18] Iteration #432 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9839166
Z variance train             0.014804679
KL Divergence                23.511887
KL Loss                      2.3511887
QF Loss                      923.4668
VF Loss                      126.51789
Policy Loss                  -1276.2572
Q Predictions Mean           1275.6138
Q Predictions Std            239.8377
Q Predictions Max            1483.4684
Q Predictions Min            -48.79349
V Predictions Mean           1272.8135
V Predictions Std            237.8621
V Predictions Max            1462.6897
V Predictions Min            -43.06632
Log Pis Mean                 0.17301066
Log Pis Std                  2.7897415
Log Pis Max                  8.90678
Log Pis Min                  -6.8992434
Policy mu Mean               -0.0118716555
Policy mu Std                0.63269204
Policy mu Max                2.9890156
Policy mu Min                -2.4434593
Policy log std Mean          -0.9987081
Policy log std Std           0.2443446
Policy log std Max           -0.191841
Policy log std Min           -2.1437867
Z mean eval                  1.0086505
Z variance eval              0.020041075
total_rewards                [ 306.70725859 3649.41953988 3630.78978524 3597.21822157 3370.79311606
 3490.89377043 3493.02980789  433.80318754  120.22776956  809.09901865]
total_rewards_mean           2290.1981475416114
total_rewards_std            1539.2203903053348
total_rewards_max            3649.419539878853
total_rewards_min            120.22776955989698
Number of train steps total  434000
Number of env steps total    2172000
Number of rollouts total     0
Train Time (s)               45.20322759822011
(Previous) Eval Time (s)     33.402903923764825
Sample Time (s)              21.94346444774419
Epoch Time (s)               100.54959596972913
Total Train Time (s)         41583.041643281
Epoch                        433
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:02:22.633738 UTC | [2020_01_10_11_29_18] Iteration #433 | Epoch Duration: 102.2549901008606
2020-01-10 23:02:22.633914 UTC | [2020_01_10_11_29_18] Iteration #433 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0042322
Z variance train             0.020032775
KL Divergence                22.67973
KL Loss                      2.267973
QF Loss                      873.6559
VF Loss                      672.3271
Policy Loss                  -1281.7527
Q Predictions Mean           1284.3937
Q Predictions Std            201.2752
Q Predictions Max            1454.9846
Q Predictions Min            -91.67554
V Predictions Mean           1281.7344
V Predictions Std            200.78607
V Predictions Max            1464.2162
V Predictions Min            -92.83805
Log Pis Mean                 0.25727978
Log Pis Std                  2.6983285
Log Pis Max                  11.200372
Log Pis Min                  -6.827755
Policy mu Mean               0.026500162
Policy mu Std                0.6138963
Policy mu Max                1.9601221
Policy mu Min                -2.0484262
Policy log std Mean          -1.0106053
Policy log std Std           0.23750734
Policy log std Max           -0.2488172
Policy log std Min           -2.9180036
Z mean eval                  0.99646884
Z variance eval              0.012119452
total_rewards                [3677.31597487 3338.33961422 3440.92190761 1444.89895347 3304.4037119
 3487.86415027  994.44204282 1994.24221701 -216.61124779 3505.22923245]
total_rewards_mean           2497.1046556833403
total_rewards_std            1289.3127521239585
total_rewards_max            3677.3159748681733
total_rewards_min            -216.61124779378997
Number of train steps total  435000
Number of env steps total    2177000
Number of rollouts total     0
Train Time (s)               44.71939647290856
(Previous) Eval Time (s)     35.10806089313701
Sample Time (s)              23.38782776147127
Epoch Time (s)               103.21528512751684
Total Train Time (s)         41681.24399541551
Epoch                        434
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:04:00.845216 UTC | [2020_01_10_11_29_18] Iteration #434 | Epoch Duration: 98.21117949485779
2020-01-10 23:04:00.845352 UTC | [2020_01_10_11_29_18] Iteration #434 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99693024
Z variance train             0.01210403
KL Divergence                24.098993
KL Loss                      2.4098995
QF Loss                      1070.0475
VF Loss                      189.36441
Policy Loss                  -1262.731
Q Predictions Mean           1266.3264
Q Predictions Std            248.68965
Q Predictions Max            1464.0286
Q Predictions Min            -55.077885
V Predictions Mean           1255.888
V Predictions Std            247.14432
V Predictions Max            1437.5571
V Predictions Min            -60.287697
Log Pis Mean                 0.42944056
Log Pis Std                  2.877785
Log Pis Max                  12.408614
Log Pis Min                  -7.748474
Policy mu Mean               0.0073125605
Policy mu Std                0.63131857
Policy mu Max                2.2376504
Policy mu Min                -2.3002365
Policy log std Mean          -1.0180149
Policy log std Std           0.2752073
Policy log std Max           -0.12785691
Policy log std Min           -2.366334
Z mean eval                  0.98547804
Z variance eval              0.009753102
total_rewards                [3453.50008768 2648.15467422 1664.38643299 1514.53962501 3590.63513238
 1029.81886689 1302.07778224  984.65620849 3713.67992409 3374.81393556]
total_rewards_mean           2327.6262669541925
total_rewards_std            1078.1413521758245
total_rewards_max            3713.6799240902837
total_rewards_min            984.6562084882439
Number of train steps total  436000
Number of env steps total    2182000
Number of rollouts total     0
Train Time (s)               44.7146858968772
(Previous) Eval Time (s)     30.103701402898878
Sample Time (s)              23.715908688958734
Epoch Time (s)               98.53429598873481
Total Train Time (s)         41778.65654805582
Epoch                        435
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:05:38.262210 UTC | [2020_01_10_11_29_18] Iteration #435 | Epoch Duration: 97.41675662994385
2020-01-10 23:05:38.262350 UTC | [2020_01_10_11_29_18] Iteration #435 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9868784
Z variance train             0.009747629
KL Divergence                23.908178
KL Loss                      2.3908179
QF Loss                      542.2276
VF Loss                      293.67712
Policy Loss                  -1241.2169
Q Predictions Mean           1243.4961
Q Predictions Std            302.04025
Q Predictions Max            1453.4816
Q Predictions Min            -63.397465
V Predictions Mean           1254.0151
V Predictions Std            305.07382
V Predictions Max            1457.3077
V Predictions Min            -80.75724
Log Pis Mean                 -0.17249739
Log Pis Std                  2.4505527
Log Pis Max                  8.052154
Log Pis Min                  -9.073278
Policy mu Mean               -0.035211496
Policy mu Std                0.5900194
Policy mu Max                1.9045514
Policy mu Min                -2.0776243
Policy log std Mean          -1.0159253
Policy log std Std           0.26114962
Policy log std Max           -0.14249063
Policy log std Min           -2.2000341
Z mean eval                  1.0261046
Z variance eval              0.009096054
total_rewards                [2.24741769e+00 1.00497359e+03 3.14690376e+02 2.52947537e+03
 3.50321406e+03 1.59053566e+03 3.41175265e+03 1.77748882e+02
 1.08785353e+03 1.12705247e+03]
total_rewards_mean           1474.954400193707
total_rewards_std            1211.6098217473264
total_rewards_max            3503.2140551056827
total_rewards_min            2.2474176924341043
Number of train steps total  437000
Number of env steps total    2187000
Number of rollouts total     0
Train Time (s)               44.61732658185065
(Previous) Eval Time (s)     28.985918242949992
Sample Time (s)              23.56793280504644
Epoch Time (s)               97.17117762984708
Total Train Time (s)         41861.14686599234
Epoch                        436
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:07:00.758438 UTC | [2020_01_10_11_29_18] Iteration #436 | Epoch Duration: 82.49597597122192
2020-01-10 23:07:00.758610 UTC | [2020_01_10_11_29_18] Iteration #436 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0261829
Z variance train             0.009130589
KL Divergence                24.437895
KL Loss                      2.4437895
QF Loss                      3321.025
VF Loss                      1549.9902
Policy Loss                  -1264.0105
Q Predictions Mean           1261.5916
Q Predictions Std            253.30814
Q Predictions Max            1470.5134
Q Predictions Min            -58.314198
V Predictions Mean           1261.5513
V Predictions Std            248.08165
V Predictions Max            1461.6779
V Predictions Min            -65.9461
Log Pis Mean                 -0.10914644
Log Pis Std                  2.7719984
Log Pis Max                  10.910594
Log Pis Min                  -8.595889
Policy mu Mean               0.028793842
Policy mu Std                0.6250961
Policy mu Max                2.8678153
Policy mu Min                -2.4433637
Policy log std Mean          -0.993274
Policy log std Std           0.2863812
Policy log std Max           -0.078775406
Policy log std Min           -2.9546804
Z mean eval                  1.0926621
Z variance eval              0.012003307
total_rewards                [3256.83525831 1663.2020606  3574.63477281 3343.35662066 3410.63095018
 3141.57243421 3270.52447351 3543.61406324 2236.80197722 3434.39093984]
total_rewards_mean           3087.556355058838
total_rewards_std            596.0669258681556
total_rewards_max            3574.634772813678
total_rewards_min            1663.202060603181
Number of train steps total  438000
Number of env steps total    2192000
Number of rollouts total     0
Train Time (s)               45.129847378935665
(Previous) Eval Time (s)     14.310475428123027
Sample Time (s)              23.136980126146227
Epoch Time (s)               82.57730293320492
Total Train Time (s)         41965.49022959778
Epoch                        437
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:08:45.105955 UTC | [2020_01_10_11_29_18] Iteration #437 | Epoch Duration: 104.34721279144287
2020-01-10 23:08:45.106133 UTC | [2020_01_10_11_29_18] Iteration #437 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0930947
Z variance train             0.0120199025
KL Divergence                24.162617
KL Loss                      2.4162617
QF Loss                      1050.6199
VF Loss                      123.70449
Policy Loss                  -1263.3125
Q Predictions Mean           1266.2701
Q Predictions Std            253.01263
Q Predictions Max            1451.0378
Q Predictions Min            -47.806274
V Predictions Mean           1264.1001
V Predictions Std            253.55719
V Predictions Max            1444.8105
V Predictions Min            -64.18352
Log Pis Mean                 0.4137351
Log Pis Std                  3.0067606
Log Pis Max                  15.915371
Log Pis Min                  -9.535988
Policy mu Mean               0.019911971
Policy mu Std                0.6390191
Policy mu Max                2.8959496
Policy mu Min                -3.0048106
Policy log std Mean          -1.0068716
Policy log std Std           0.28970596
Policy log std Max           -0.015833855
Policy log std Min           -3.0856721
Z mean eval                  1.02125
Z variance eval              0.0078000464
total_rewards                [3311.59062734 -139.60000698 3565.68828447 3330.55543629 1468.86192398
 3724.13295049 3418.48397458 3474.32763442 3601.71471725 3346.70788041]
total_rewards_mean           2910.2463422243904
total_rewards_std            1185.4967186195968
total_rewards_max            3724.1329504881764
total_rewards_min            -139.60000698474602
Number of train steps total  439000
Number of env steps total    2197000
Number of rollouts total     0
Train Time (s)               44.81038837693632
(Previous) Eval Time (s)     36.080138652119786
Sample Time (s)              23.378870802465826
Epoch Time (s)               104.26939783152193
Total Train Time (s)         42067.623752428684
Epoch                        438
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:10:27.241816 UTC | [2020_01_10_11_29_18] Iteration #438 | Epoch Duration: 102.13555812835693
2020-01-10 23:10:27.241948 UTC | [2020_01_10_11_29_18] Iteration #438 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0222822
Z variance train             0.0077769933
KL Divergence                23.879725
KL Loss                      2.3879726
QF Loss                      966.3181
VF Loss                      321.92526
Policy Loss                  -1275.2844
Q Predictions Mean           1275.0648
Q Predictions Std            253.29974
Q Predictions Max            1490.5337
Q Predictions Min            -68.499054
V Predictions Mean           1265.1599
V Predictions Std            254.45103
V Predictions Max            1463.993
V Predictions Min            -84.965385
Log Pis Mean                 0.41436902
Log Pis Std                  3.0131085
Log Pis Max                  11.988848
Log Pis Min                  -10.134317
Policy mu Mean               0.008021936
Policy mu Std                0.64527935
Policy mu Max                3.0709465
Policy mu Min                -2.5297542
Policy log std Mean          -1.0016856
Policy log std Std           0.2691481
Policy log std Max           0.18228906
Policy log std Min           -2.727842
Z mean eval                  1.0249585
Z variance eval              0.00864925
total_rewards                [3166.17353171 3310.89968602 3441.50732709  401.38277343 3119.71326861
 3294.5261737  2911.9634136  1315.68933505 3386.71368688 1199.71854177]
total_rewards_mean           2554.8287737849655
total_rewards_std            1068.9494307848142
total_rewards_max            3441.5073270865355
total_rewards_min            401.38277342684387
Number of train steps total  440000
Number of env steps total    2202000
Number of rollouts total     0
Train Time (s)               44.75789869297296
(Previous) Eval Time (s)     33.9460559762083
Sample Time (s)              23.05033613368869
Epoch Time (s)               101.75429080286995
Total Train Time (s)         42164.28432358662
Epoch                        439
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:12:03.911784 UTC | [2020_01_10_11_29_18] Iteration #439 | Epoch Duration: 96.66968607902527
2020-01-10 23:12:03.912134 UTC | [2020_01_10_11_29_18] Iteration #439 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0238266
Z variance train             0.00858671
KL Divergence                24.289482
KL Loss                      2.4289482
QF Loss                      2629.6821
VF Loss                      165.53113
Policy Loss                  -1287.0142
Q Predictions Mean           1287.0571
Q Predictions Std            232.22867
Q Predictions Max            1493.1217
Q Predictions Min            11.63565
V Predictions Mean           1290.1257
V Predictions Std            227.27272
V Predictions Max            1489.6505
V Predictions Min            -0.46665645
Log Pis Mean                 0.15406747
Log Pis Std                  2.6492262
Log Pis Max                  12.921993
Log Pis Min                  -7.1639066
Policy mu Mean               0.029583078
Policy mu Std                0.6139215
Policy mu Max                2.3409226
Policy mu Min                -2.331351
Policy log std Mean          -1.0014741
Policy log std Std           0.27978757
Policy log std Max           -0.18651003
Policy log std Min           -2.9066913
Z mean eval                  1.0448178
Z variance eval              0.009787333
total_rewards                [ 543.30466094  296.2941577    66.57414622 1139.60670043 3693.86628939
  318.03270007 3538.71831822 -349.65043376 1738.65290587 3642.11464433]
total_rewards_mean           1462.7514089413294
total_rewards_std            1515.5255728879451
total_rewards_max            3693.8662893879336
total_rewards_min            -349.6504337646089
Number of train steps total  441000
Number of env steps total    2207000
Number of rollouts total     0
Train Time (s)               44.29848473099992
(Previous) Eval Time (s)     28.861192240845412
Sample Time (s)              23.22094589099288
Epoch Time (s)               96.38062286283821
Total Train Time (s)         42255.56771579757
Epoch                        440
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:13:35.198350 UTC | [2020_01_10_11_29_18] Iteration #440 | Epoch Duration: 91.2861123085022
2020-01-10 23:13:35.198488 UTC | [2020_01_10_11_29_18] Iteration #440 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0453054
Z variance train             0.009780889
KL Divergence                23.424582
KL Loss                      2.3424582
QF Loss                      1086.5182
VF Loss                      937.2264
Policy Loss                  -1287.3578
Q Predictions Mean           1284.2827
Q Predictions Std            228.25911
Q Predictions Max            1522.4894
Q Predictions Min            -91.97098
V Predictions Mean           1277.1731
V Predictions Std            220.70361
V Predictions Max            1502.7035
V Predictions Min            -78.870255
Log Pis Mean                 0.45630658
Log Pis Std                  3.1026297
Log Pis Max                  15.817082
Log Pis Min                  -7.670451
Policy mu Mean               -0.0063682287
Policy mu Std                0.6267286
Policy mu Max                2.442068
Policy mu Min                -2.9522583
Policy log std Mean          -1.0503008
Policy log std Std           0.29586107
Policy log std Max           -0.25065345
Policy log std Min           -3.5587869
Z mean eval                  1.0542741
Z variance eval              0.008268282
total_rewards                [3522.43615476 2318.39288571  481.2897091  3314.28325074 3683.01006642
  436.42585107 3545.52035862  479.49626207  595.93451922 2079.62343878]
total_rewards_mean           2045.6412496496844
total_rewards_std            1356.015029943099
total_rewards_max            3683.0100664219494
total_rewards_min            436.4258510698054
Number of train steps total  442000
Number of env steps total    2212000
Number of rollouts total     0
Train Time (s)               45.020800373051316
(Previous) Eval Time (s)     23.766453281976283
Sample Time (s)              23.303891889750957
Epoch Time (s)               92.09114554477856
Total Train Time (s)         42347.94500974566
Epoch                        441
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:15:07.580298 UTC | [2020_01_10_11_29_18] Iteration #441 | Epoch Duration: 92.3816921710968
2020-01-10 23:15:07.580477 UTC | [2020_01_10_11_29_18] Iteration #441 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0543616
Z variance train             0.008262743
KL Divergence                23.702518
KL Loss                      2.370252
QF Loss                      792.3092
VF Loss                      275.9282
Policy Loss                  -1269.2905
Q Predictions Mean           1265.5363
Q Predictions Std            300.20963
Q Predictions Max            1474.3955
Q Predictions Min            -60.047718
V Predictions Mean           1258.1677
V Predictions Std            295.0821
V Predictions Max            1470.4397
V Predictions Min            -80.96254
Log Pis Mean                 0.23575142
Log Pis Std                  2.7298698
Log Pis Max                  11.657869
Log Pis Min                  -8.070534
Policy mu Mean               0.028770246
Policy mu Std                0.6235419
Policy mu Max                3.2537377
Policy mu Min                -3.1664047
Policy log std Mean          -1.0136201
Policy log std Std           0.26777264
Policy log std Max           0.7087434
Policy log std Min           -2.3956661
Z mean eval                  1.0551442
Z variance eval              0.011753216
total_rewards                [3393.78649921 3511.60261637 3726.6045022  3751.41999472 2498.3396769
 1599.41132707 3555.34115985 3882.57317958  202.76618427 3594.46837616]
total_rewards_mean           2971.6313516331866
total_rewards_std            1139.29381437644
total_rewards_max            3882.5731795753527
total_rewards_min            202.766184273205
Number of train steps total  443000
Number of env steps total    2217000
Number of rollouts total     0
Train Time (s)               44.69272485701367
(Previous) Eval Time (s)     24.056748853996396
Sample Time (s)              22.946891574654728
Epoch Time (s)               91.6963652856648
Total Train Time (s)         42445.32057680935
Epoch                        442
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:16:44.959556 UTC | [2020_01_10_11_29_18] Iteration #442 | Epoch Duration: 97.37894296646118
2020-01-10 23:16:44.959689 UTC | [2020_01_10_11_29_18] Iteration #442 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0587785
Z variance train             0.01174811
KL Divergence                23.257061
KL Loss                      2.3257062
QF Loss                      1944.1973
VF Loss                      888.5538
Policy Loss                  -1259.394
Q Predictions Mean           1263.1599
Q Predictions Std            270.44916
Q Predictions Max            1502.1995
Q Predictions Min            -25.70794
V Predictions Mean           1251.2499
V Predictions Std            276.8781
V Predictions Max            1490.7582
V Predictions Min            -48.4822
Log Pis Mean                 0.60052305
Log Pis Std                  3.0111527
Log Pis Max                  14.617502
Log Pis Min                  -6.045839
Policy mu Mean               -0.024852552
Policy mu Std                0.627783
Policy mu Max                2.9759817
Policy mu Min                -2.349688
Policy log std Mean          -1.0421474
Policy log std Std           0.3051404
Policy log std Max           -0.027780175
Policy log std Min           -2.8429475
Z mean eval                  1.067163
Z variance eval              0.0069310265
total_rewards                [3208.61006536 3355.00153238  498.33401404 3499.74950454 3735.17682108
 3510.11949024 3446.4158021  3705.73100582 3631.30034054 3346.66644596]
total_rewards_mean           3193.710502206922
total_rewards_std            912.0941207767539
total_rewards_max            3735.1768210838486
total_rewards_min            498.33401403946834
Number of train steps total  444000
Number of env steps total    2222000
Number of rollouts total     0
Train Time (s)               44.2032482791692
(Previous) Eval Time (s)     29.73908727709204
Sample Time (s)              23.483694029506296
Epoch Time (s)               97.42602958576754
Total Train Time (s)         42549.49487996288
Epoch                        443
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:18:29.136871 UTC | [2020_01_10_11_29_18] Iteration #443 | Epoch Duration: 104.177077293396
2020-01-10 23:18:29.137022 UTC | [2020_01_10_11_29_18] Iteration #443 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0675118
Z variance train             0.0069341958
KL Divergence                24.211754
KL Loss                      2.4211755
QF Loss                      744.3441
VF Loss                      279.84668
Policy Loss                  -1268.8514
Q Predictions Mean           1271.4358
Q Predictions Std            274.55246
Q Predictions Max            1474.9128
Q Predictions Min            -47.34504
V Predictions Mean           1280.7628
V Predictions Std            275.66443
V Predictions Max            1497.4305
V Predictions Min            -28.083508
Log Pis Mean                 0.38954994
Log Pis Std                  3.0955684
Log Pis Max                  15.373108
Log Pis Min                  -8.094318
Policy mu Mean               0.022561422
Policy mu Std                0.63466495
Policy mu Max                2.671957
Policy mu Min                -3.181082
Policy log std Mean          -1.0324233
Policy log std Std           0.26229596
Policy log std Max           -0.13457155
Policy log std Min           -2.1455162
Z mean eval                  1.0081813
Z variance eval              0.012509624
total_rewards                [3140.37269626 1698.07613744 1383.18119102 3315.05629012 3698.05351331
 2332.61285038   81.48516274 1069.94475856 -180.5980989  3294.3694355 ]
total_rewards_mean           1983.2553936432003
total_rewards_std            1321.694437292741
total_rewards_max            3698.0535133110475
total_rewards_min            -180.5980988963302
Number of train steps total  445000
Number of env steps total    2227000
Number of rollouts total     0
Train Time (s)               44.341792470775545
(Previous) Eval Time (s)     36.489883579313755
Sample Time (s)              22.854631348513067
Epoch Time (s)               103.68630739860237
Total Train Time (s)         42647.831098489
Epoch                        444
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:20:07.477540 UTC | [2020_01_10_11_29_18] Iteration #444 | Epoch Duration: 98.34040546417236
2020-01-10 23:20:07.477714 UTC | [2020_01_10_11_29_18] Iteration #444 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0097668
Z variance train             0.012513386
KL Divergence                22.998764
KL Loss                      2.2998765
QF Loss                      702.1305
VF Loss                      152.93019
Policy Loss                  -1299.7039
Q Predictions Mean           1297.4608
Q Predictions Std            236.4546
Q Predictions Max            1489.7574
Q Predictions Min            -54.105255
V Predictions Mean           1291.8601
V Predictions Std            235.65807
V Predictions Max            1478.8408
V Predictions Min            -54.829845
Log Pis Mean                 0.37517044
Log Pis Std                  2.6604004
Log Pis Max                  12.909983
Log Pis Min                  -6.9325933
Policy mu Mean               0.009896245
Policy mu Std                0.6535583
Policy mu Max                3.1286473
Policy mu Min                -2.1996305
Policy log std Mean          -0.9993057
Policy log std Std           0.26811194
Policy log std Max           -0.1038357
Policy log std Min           -2.1706238
Z mean eval                  1.0584759
Z variance eval              0.016576651
total_rewards                [3259.58157635 3673.19704973 3610.95337978 2395.03925503 1815.33138174
 3655.22665532 3568.37930981 3301.39603848  658.49620098 3458.83573419]
total_rewards_mean           2939.6436581411735
total_rewards_std            957.246891156469
total_rewards_max            3673.197049731033
total_rewards_min            658.4962009796243
Number of train steps total  446000
Number of env steps total    2232000
Number of rollouts total     0
Train Time (s)               45.33334578899667
(Previous) Eval Time (s)     31.143724895082414
Sample Time (s)              23.582607787568122
Epoch Time (s)               100.0596784716472
Total Train Time (s)         42747.74594262289
Epoch                        445
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:21:47.396735 UTC | [2020_01_10_11_29_18] Iteration #445 | Epoch Duration: 99.9188585281372
2020-01-10 23:21:47.397003 UTC | [2020_01_10_11_29_18] Iteration #445 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.054604
Z variance train             0.016581554
KL Divergence                22.460434
KL Loss                      2.2460434
QF Loss                      1272.9613
VF Loss                      346.589
Policy Loss                  -1293.1176
Q Predictions Mean           1292.7083
Q Predictions Std            241.55466
Q Predictions Max            1493.1403
Q Predictions Min            -39.511044
V Predictions Mean           1297.8767
V Predictions Std            245.55331
V Predictions Max            1497.1715
V Predictions Min            -56.805904
Log Pis Mean                 0.559549
Log Pis Std                  2.9195888
Log Pis Max                  12.7914095
Log Pis Min                  -6.025073
Policy mu Mean               -0.08104707
Policy mu Std                0.6272514
Policy mu Max                2.1131496
Policy mu Min                -2.1140008
Policy log std Mean          -1.0515311
Policy log std Std           0.29856244
Policy log std Max           -0.17895806
Policy log std Min           -2.7259257
Z mean eval                  1.040292
Z variance eval              0.014561042
total_rewards                [3556.11065548 3029.94972502 3293.1366209   711.06149824 3704.95717219
  587.80009244 2312.690207   3474.6998258  2165.35542099 3764.89512193]
total_rewards_mean           2660.065633998122
total_rewards_std            1130.259911006208
total_rewards_max            3764.8951219278997
total_rewards_min            587.8000924407869
Number of train steps total  447000
Number of env steps total    2237000
Number of rollouts total     0
Train Time (s)               44.53592817671597
(Previous) Eval Time (s)     31.002634801901877
Sample Time (s)              22.352141599170864
Epoch Time (s)               97.89070457778871
Total Train Time (s)         42840.95764572406
Epoch                        446
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:23:20.610852 UTC | [2020_01_10_11_29_18] Iteration #446 | Epoch Duration: 93.21367621421814
2020-01-10 23:23:20.610992 UTC | [2020_01_10_11_29_18] Iteration #446 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0394909
Z variance train             0.0145469215
KL Divergence                22.117184
KL Loss                      2.2117183
QF Loss                      853.3855
VF Loss                      211.66078
Policy Loss                  -1316.8448
Q Predictions Mean           1318.5378
Q Predictions Std            182.20633
Q Predictions Max            1473.2465
Q Predictions Min            14.457102
V Predictions Mean           1309.9999
V Predictions Std            181.54735
V Predictions Max            1471.146
V Predictions Min            -1.3026515
Log Pis Mean                 0.32696348
Log Pis Std                  2.5508115
Log Pis Max                  7.8488674
Log Pis Min                  -7.599288
Policy mu Mean               -0.0054156147
Policy mu Std                0.6330656
Policy mu Max                3.178652
Policy mu Min                -2.0893183
Policy log std Mean          -1.0383682
Policy log std Std           0.25710428
Policy log std Max           -0.10226637
Policy log std Min           -2.648705
Z mean eval                  1.0430311
Z variance eval              0.01224477
total_rewards                [ -21.89115052 3304.06380592  305.46766543  441.12661187 3552.05321721
 3496.45879769  727.74997966 3472.42908851 3675.81947097  148.51160909]
total_rewards_mean           1910.1789095830459
total_rewards_std            1602.5223818364057
total_rewards_max            3675.819470969682
total_rewards_min            -21.891150520807095
Number of train steps total  448000
Number of env steps total    2242000
Number of rollouts total     0
Train Time (s)               45.04440716234967
(Previous) Eval Time (s)     26.325402484741062
Sample Time (s)              23.037417736835778
Epoch Time (s)               94.40722738392651
Total Train Time (s)         42927.67397608748
Epoch                        447
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:24:47.336649 UTC | [2020_01_10_11_29_18] Iteration #447 | Epoch Duration: 86.72550320625305
2020-01-10 23:24:47.336964 UTC | [2020_01_10_11_29_18] Iteration #447 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0450534
Z variance train             0.01223612
KL Divergence                21.47729
KL Loss                      2.147729
QF Loss                      10565.422
VF Loss                      230.159
Policy Loss                  -1286.3737
Q Predictions Mean           1293.7156
Q Predictions Std            257.5073
Q Predictions Max            1522.651
Q Predictions Min            -124.51286
V Predictions Mean           1297.1741
V Predictions Std            259.01535
V Predictions Max            1528.5875
V Predictions Min            -108.666695
Log Pis Mean                 0.14286357
Log Pis Std                  2.759196
Log Pis Max                  8.577621
Log Pis Min                  -8.8453665
Policy mu Mean               0.009372531
Policy mu Std                0.6189964
Policy mu Max                2.3970745
Policy mu Min                -2.612885
Policy log std Mean          -0.9917052
Policy log std Std           0.27707705
Policy log std Max           -0.022702575
Policy log std Min           -2.8272603
Z mean eval                  1.0154829
Z variance eval              0.01871626
total_rewards                [3692.22930497 3586.43661308 3498.4997551  2233.10626848 3146.61313786
 3632.16668844 3745.69434588 3310.50850832 3669.53632099 -201.58952502]
total_rewards_mean           3031.3201418092804
total_rewards_std            1158.5321703553363
total_rewards_max            3745.6943458804635
total_rewards_min            -201.58952501763406
Number of train steps total  449000
Number of env steps total    2247000
Number of rollouts total     0
Train Time (s)               44.89594856603071
(Previous) Eval Time (s)     18.643424962181598
Sample Time (s)              22.007325547281653
Epoch Time (s)               85.54669907549396
Total Train Time (s)         43025.84591620462
Epoch                        448
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:26:25.513025 UTC | [2020_01_10_11_29_18] Iteration #448 | Epoch Duration: 98.17584776878357
2020-01-10 23:26:25.513189 UTC | [2020_01_10_11_29_18] Iteration #448 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0123427
Z variance train             0.018881693
KL Divergence                20.153112
KL Loss                      2.0153112
QF Loss                      901.5383
VF Loss                      323.3841
Policy Loss                  -1313.0537
Q Predictions Mean           1312.8712
Q Predictions Std            207.53609
Q Predictions Max            1518.1576
Q Predictions Min            -54.355362
V Predictions Mean           1305.9011
V Predictions Std            203.40161
V Predictions Max            1499.8196
V Predictions Min            -68.56254
Log Pis Mean                 0.25471923
Log Pis Std                  2.62485
Log Pis Max                  11.008965
Log Pis Min                  -7.1500316
Policy mu Mean               0.044672936
Policy mu Std                0.6042186
Policy mu Max                3.346936
Policy mu Min                -2.2521484
Policy log std Mean          -1.0412517
Policy log std Std           0.2569608
Policy log std Max           0.12620866
Policy log std Min           -2.1195734
Z mean eval                  1.0250819
Z variance eval              0.018506657
total_rewards                [ 800.01977039 2549.33080994 3517.75888485  550.0971658  1176.15032486
 3785.96918315 3422.62365746 3529.42342827 -247.10947391 3645.12810926]
total_rewards_mean           2272.9391860086034
total_rewards_std            1462.529485053018
total_rewards_max            3785.969183152131
total_rewards_min            -247.10947390766046
Number of train steps total  450000
Number of env steps total    2252000
Number of rollouts total     0
Train Time (s)               44.840991562232375
(Previous) Eval Time (s)     31.27234385861084
Sample Time (s)              23.018566691316664
Epoch Time (s)               99.13190211215988
Total Train Time (s)         43127.34532247577
Epoch                        449
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:28:07.014586 UTC | [2020_01_10_11_29_18] Iteration #449 | Epoch Duration: 101.50127339363098
2020-01-10 23:28:07.014717 UTC | [2020_01_10_11_29_18] Iteration #449 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0241206
Z variance train             0.018508935
KL Divergence                20.642073
KL Loss                      2.0642073
QF Loss                      1201.5176
VF Loss                      183.64322
Policy Loss                  -1290.7583
Q Predictions Mean           1288.5564
Q Predictions Std            251.049
Q Predictions Max            1541.3367
Q Predictions Min            -87.558495
V Predictions Mean           1291.0933
V Predictions Std            250.87874
V Predictions Max            1542.2336
V Predictions Min            -81.12934
Log Pis Mean                 0.0635843
Log Pis Std                  2.7605236
Log Pis Max                  10.05059
Log Pis Min                  -6.9586697
Policy mu Mean               -0.013145058
Policy mu Std                0.61562693
Policy mu Max                2.348292
Policy mu Min                -2.5032945
Policy log std Mean          -0.99955255
Policy log std Std           0.2524263
Policy log std Max           -0.21898353
Policy log std Min           -2.206671
Z mean eval                  1.0354227
Z variance eval              0.019083219
total_rewards                [3560.02870587 3685.09480086  226.09381571 3671.99473762  518.43494349
 3365.03721315 3770.66572078 3576.83781754 3577.21639746 2871.72276049]
total_rewards_mean           2882.3126912964703
total_rewards_std            1278.9970717393358
total_rewards_max            3770.665720776871
total_rewards_min            226.09381571134918
Number of train steps total  451000
Number of env steps total    2257000
Number of rollouts total     0
Train Time (s)               44.656637602020055
(Previous) Eval Time (s)     33.64148047193885
Sample Time (s)              23.07599542243406
Epoch Time (s)               101.37411349639297
Total Train Time (s)         43224.6116035115
Epoch                        450
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:29:44.285063 UTC | [2020_01_10_11_29_18] Iteration #450 | Epoch Duration: 97.27023816108704
2020-01-10 23:29:44.285236 UTC | [2020_01_10_11_29_18] Iteration #450 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0359862
Z variance train             0.019062385
KL Divergence                19.914068
KL Loss                      1.9914068
QF Loss                      828.651
VF Loss                      176.76564
Policy Loss                  -1289.9827
Q Predictions Mean           1291.6841
Q Predictions Std            234.31172
Q Predictions Max            1477.0599
Q Predictions Min            -147.4602
V Predictions Mean           1290.0916
V Predictions Std            231.1179
V Predictions Max            1464.2959
V Predictions Min            -119.36415
Log Pis Mean                 0.4403981
Log Pis Std                  2.468661
Log Pis Max                  13.201298
Log Pis Min                  -5.61582
Policy mu Mean               0.005197702
Policy mu Std                0.6368008
Policy mu Max                2.259092
Policy mu Min                -2.588709
Policy log std Mean          -1.0131009
Policy log std Std           0.25029662
Policy log std Max           0.5768001
Policy log std Min           -2.2611399
Z mean eval                  1.0045689
Z variance eval              0.10425357
total_rewards                [3746.29239019 3520.11932425 3609.95685061 3241.81492352 3334.12919048
 3541.31477912 3473.43033849 3477.69681405 3241.11321699 2937.51535598]
total_rewards_mean           3412.3383183684805
total_rewards_std            218.35838059167654
total_rewards_max            3746.292390194331
total_rewards_min            2937.515355975752
Number of train steps total  452000
Number of env steps total    2262000
Number of rollouts total     0
Train Time (s)               44.84281647577882
(Previous) Eval Time (s)     29.537343914154917
Sample Time (s)              23.168304837774485
Epoch Time (s)               97.54846522770822
Total Train Time (s)         43328.05979907187
Epoch                        451
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:31:27.737466 UTC | [2020_01_10_11_29_18] Iteration #451 | Epoch Duration: 103.45209884643555
2020-01-10 23:31:27.737640 UTC | [2020_01_10_11_29_18] Iteration #451 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.000981
Z variance train             0.1031036
KL Divergence                18.217741
KL Loss                      1.8217741
QF Loss                      5575.3545
VF Loss                      1317.6785
Policy Loss                  -1206.5026
Q Predictions Mean           1204.6318
Q Predictions Std            288.42606
Q Predictions Max            1414.9583
Q Predictions Min            -59.1957
V Predictions Mean           1185.7051
V Predictions Std            293.14606
V Predictions Max            1389.6128
V Predictions Min            -66.53712
Log Pis Mean                 0.41303474
Log Pis Std                  2.7603886
Log Pis Max                  13.218879
Log Pis Min                  -6.44736
Policy mu Mean               -0.00523184
Policy mu Std                0.55360067
Policy mu Max                2.4533076
Policy mu Min                -1.8790773
Policy log std Mean          -1.1074681
Policy log std Std           0.29856327
Policy log std Max           -0.091994524
Policy log std Min           -3.205943
Z mean eval                  1.0535254
Z variance eval              0.025778543
total_rewards                [3832.08368377 3035.06706081 3385.26142339 3514.55931723 3464.83098593
 1306.11877642 2387.32370557 3532.43587621  903.59143814 2431.16587746]
total_rewards_mean           2779.243814493727
total_rewards_std            953.0015972042665
total_rewards_max            3832.0836837692914
total_rewards_min            903.5914381421767
Number of train steps total  453000
Number of env steps total    2267000
Number of rollouts total     0
Train Time (s)               44.73437794530764
(Previous) Eval Time (s)     35.44072306761518
Sample Time (s)              23.52966240886599
Epoch Time (s)               103.70476342178881
Total Train Time (s)         43423.93869935954
Epoch                        452
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:33:03.626010 UTC | [2020_01_10_11_29_18] Iteration #452 | Epoch Duration: 95.88819909095764
2020-01-10 23:33:03.626298 UTC | [2020_01_10_11_29_18] Iteration #452 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0516127
Z variance train             0.025756251
KL Divergence                19.33637
KL Loss                      1.933637
QF Loss                      807.3515
VF Loss                      132.27716
Policy Loss                  -1287.1921
Q Predictions Mean           1288.56
Q Predictions Std            248.50323
Q Predictions Max            1505.7479
Q Predictions Min            -102.44079
V Predictions Mean           1288.9707
V Predictions Std            247.45125
V Predictions Max            1506.7336
V Predictions Min            -99.52395
Log Pis Mean                 0.31606054
Log Pis Std                  2.6912024
Log Pis Max                  10.086142
Log Pis Min                  -6.4934893
Policy mu Mean               -0.0134386355
Policy mu Std                0.60780525
Policy mu Max                3.3388371
Policy mu Min                -2.0588229
Policy log std Mean          -1.046999
Policy log std Std           0.26640633
Policy log std Max           -0.0691607
Policy log std Min           -2.3712523
Z mean eval                  1.033231
Z variance eval              0.021707164
total_rewards                [ 938.09849235 3600.45553563 1648.6063603  3496.10388021 3522.08080551
 3767.1838599  3168.95687795 2378.90889495 1413.17527564 3779.38635667]
total_rewards_mean           2771.2956339118914
total_rewards_std            1027.7260074916148
total_rewards_max            3779.386356667014
total_rewards_min            938.0984923536037
Number of train steps total  454000
Number of env steps total    2272000
Number of rollouts total     0
Train Time (s)               44.58044978324324
(Previous) Eval Time (s)     27.623911499977112
Sample Time (s)              23.07109095249325
Epoch Time (s)               95.2754522357136
Total Train Time (s)         43518.23839076143
Epoch                        453
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:34:37.928863 UTC | [2020_01_10_11_29_18] Iteration #453 | Epoch Duration: 94.30235052108765
2020-01-10 23:34:37.929012 UTC | [2020_01_10_11_29_18] Iteration #453 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0310593
Z variance train             0.021695135
KL Divergence                20.020344
KL Loss                      2.0020344
QF Loss                      1679.9116
VF Loss                      1140.3098
Policy Loss                  -1236.6812
Q Predictions Mean           1240.355
Q Predictions Std            301.88934
Q Predictions Max            1460.8667
Q Predictions Min            -79.04169
V Predictions Mean           1244.1912
V Predictions Std            307.77124
V Predictions Max            1469.328
V Predictions Min            -111.392784
Log Pis Mean                 0.5021589
Log Pis Std                  3.0011477
Log Pis Max                  12.79879
Log Pis Min                  -9.741034
Policy mu Mean               0.024418894
Policy mu Std                0.607213
Policy mu Max                3.115473
Policy mu Min                -2.6657372
Policy log std Mean          -1.0707936
Policy log std Std           0.3185873
Policy log std Max           -0.086179495
Policy log std Min           -2.7193809
Z mean eval                  1.0555117
Z variance eval              0.027693484
total_rewards                [ 899.69316428 2300.70682532 3351.75886425 2950.61528461 1669.53981135
 3504.89349554 3104.0921023  3328.51475041 2847.81200198 3526.73526681]
total_rewards_mean           2748.436156685514
total_rewards_std            826.9243807553044
total_rewards_max            3526.735266811931
total_rewards_min            899.6931642760098
Number of train steps total  455000
Number of env steps total    2277000
Number of rollouts total     0
Train Time (s)               44.45645831525326
(Previous) Eval Time (s)     26.650603320915252
Sample Time (s)              22.719006726052612
Epoch Time (s)               93.82606836222112
Total Train Time (s)         43615.54061360797
Epoch                        454
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:36:15.234085 UTC | [2020_01_10_11_29_18] Iteration #454 | Epoch Duration: 97.30496525764465
2020-01-10 23:36:15.234223 UTC | [2020_01_10_11_29_18] Iteration #454 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0559888
Z variance train             0.02773666
KL Divergence                19.084915
KL Loss                      1.9084915
QF Loss                      1034.2382
VF Loss                      455.8444
Policy Loss                  -1320.7736
Q Predictions Mean           1319.8235
Q Predictions Std            153.42757
Q Predictions Max            1479.2781
Q Predictions Min            -41.821552
V Predictions Mean           1315.9463
V Predictions Std            144.76303
V Predictions Max            1471.1
V Predictions Min            -31.913944
Log Pis Mean                 0.2867294
Log Pis Std                  2.9788117
Log Pis Max                  18.000263
Log Pis Min                  -7.1114473
Policy mu Mean               0.037607796
Policy mu Std                0.6174905
Policy mu Max                3.4079678
Policy mu Min                -2.253175
Policy log std Mean          -1.0725033
Policy log std Std           0.27574086
Policy log std Max           -0.22529024
Policy log std Min           -3.2306736
Z mean eval                  1.0651834
Z variance eval              0.024541385
total_rewards                [ 784.39885115  906.35636669 3301.14777143  672.05371153 3713.70743802
 3341.00611337  279.64300239 3581.07726803 3478.94325991  517.68862583]
total_rewards_mean           2057.6022408355284
total_rewards_std            1437.91632296271
total_rewards_max            3713.7074380225413
total_rewards_min            279.6430023906994
Number of train steps total  456000
Number of env steps total    2282000
Number of rollouts total     0
Train Time (s)               45.333875701762736
(Previous) Eval Time (s)     30.129266791045666
Sample Time (s)              23.169649914838374
Epoch Time (s)               98.63279240764678
Total Train Time (s)         43705.80995970592
Epoch                        455
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:37:45.508705 UTC | [2020_01_10_11_29_18] Iteration #455 | Epoch Duration: 90.27436184883118
2020-01-10 23:37:45.508884 UTC | [2020_01_10_11_29_18] Iteration #455 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0646006
Z variance train             0.024571221
KL Divergence                19.491928
KL Loss                      1.9491929
QF Loss                      1072.105
VF Loss                      2282.1104
Policy Loss                  -1338.0687
Q Predictions Mean           1338.7422
Q Predictions Std            209.61197
Q Predictions Max            1548.4917
Q Predictions Min            -82.39105
V Predictions Mean           1338.7551
V Predictions Std            198.06346
V Predictions Max            1556.2867
V Predictions Min            -83.77529
Log Pis Mean                 0.5119974
Log Pis Std                  2.537246
Log Pis Max                  13.047726
Log Pis Min                  -8.886809
Policy mu Mean               -0.023578461
Policy mu Std                0.608068
Policy mu Max                2.4949188
Policy mu Min                -3.248357
Policy log std Mean          -1.055546
Policy log std Std           0.2666052
Policy log std Max           -0.2095598
Policy log std Min           -2.646243
Z mean eval                  1.0146039
Z variance eval              0.03168559
total_rewards                [1843.91314533 3071.35047403  786.37029802 3486.59995083  316.59657193
 3551.48720696 3566.78311542  997.09598649  902.11372916  477.36429489]
total_rewards_mean           1899.9674773048641
total_rewards_std            1303.0857821362304
total_rewards_max            3566.783115422658
total_rewards_min            316.5965719256656
Number of train steps total  457000
Number of env steps total    2287000
Number of rollouts total     0
Train Time (s)               44.38765617273748
(Previous) Eval Time (s)     21.77057947590947
Sample Time (s)              22.410577590111643
Epoch Time (s)               88.5688132387586
Total Train Time (s)         43791.13881617552
Epoch                        456
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:39:10.841392 UTC | [2020_01_10_11_29_18] Iteration #456 | Epoch Duration: 85.33237361907959
2020-01-10 23:39:10.841565 UTC | [2020_01_10_11_29_18] Iteration #456 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0190537
Z variance train             0.031528823
KL Divergence                19.085983
KL Loss                      1.9085983
QF Loss                      903.9507
VF Loss                      377.92474
Policy Loss                  -1318.546
Q Predictions Mean           1319.7095
Q Predictions Std            218.13782
Q Predictions Max            1540.6797
Q Predictions Min            -34.547523
V Predictions Mean           1319.4023
V Predictions Std            217.9584
V Predictions Max            1528.7855
V Predictions Min            -46.42252
Log Pis Mean                 0.63302875
Log Pis Std                  2.9056215
Log Pis Max                  11.67482
Log Pis Min                  -8.342831
Policy mu Mean               0.07374145
Policy mu Std                0.6160256
Policy mu Max                2.8119214
Policy mu Min                -2.6043441
Policy log std Mean          -1.082343
Policy log std Std           0.27378097
Policy log std Max           -0.1923998
Policy log std Min           -2.4873524
Z mean eval                  1.0429177
Z variance eval              0.023084193
total_rewards                [3650.82156144 3471.64021495 3915.71685378 3029.40650032  717.88686518
 3280.76123226 1202.99877087 2100.18045414   75.9933676  3818.60710399]
total_rewards_mean           2526.4012924526896
total_rewards_std            1333.7220916338536
total_rewards_max            3915.7168537826055
total_rewards_min            75.9933676021591
Number of train steps total  458000
Number of env steps total    2292000
Number of rollouts total     0
Train Time (s)               44.91574815940112
(Previous) Eval Time (s)     18.53389296401292
Sample Time (s)              23.657287125475705
Epoch Time (s)               87.10692824888974
Total Train Time (s)         43891.268027525395
Epoch                        457
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:40:50.974975 UTC | [2020_01_10_11_29_18] Iteration #457 | Epoch Duration: 100.13327741622925
2020-01-10 23:40:50.975142 UTC | [2020_01_10_11_29_18] Iteration #457 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.041137
Z variance train             0.023051057
KL Divergence                20.654028
KL Loss                      2.0654027
QF Loss                      848.2999
VF Loss                      230.0078
Policy Loss                  -1299.43
Q Predictions Mean           1301.1589
Q Predictions Std            275.37814
Q Predictions Max            1545.6564
Q Predictions Min            -112.70425
V Predictions Mean           1302.1641
V Predictions Std            273.05115
V Predictions Max            1549.8599
V Predictions Min            -83.2378
Log Pis Mean                 0.2963081
Log Pis Std                  2.8695455
Log Pis Max                  11.437827
Log Pis Min                  -9.880684
Policy mu Mean               -0.05773727
Policy mu Std                0.6495738
Policy mu Max                3.0765889
Policy mu Min                -2.3659124
Policy log std Mean          -1.0138191
Policy log std Std           0.27675298
Policy log std Max           0.013237357
Policy log std Min           -2.8785253
Z mean eval                  1.0802807
Z variance eval              0.029025868
total_rewards                [1356.50996765 3329.72821965 3807.04652675 2522.74996943 3364.69278547
 3639.9654139  3508.23488852  602.09430839 3570.70305566 3752.45810991]
total_rewards_mean           2945.4183245319773
total_rewards_std            1053.6501521746338
total_rewards_max            3807.0465267516142
total_rewards_min            602.0943083852881
Number of train steps total  459000
Number of env steps total    2297000
Number of rollouts total     0
Train Time (s)               45.6335558318533
(Previous) Eval Time (s)     31.559986072126776
Sample Time (s)              23.044041469693184
Epoch Time (s)               100.23758337367326
Total Train Time (s)         43988.79570722906
Epoch                        458
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:42:28.512407 UTC | [2020_01_10_11_29_18] Iteration #458 | Epoch Duration: 97.53714108467102
2020-01-10 23:42:28.512548 UTC | [2020_01_10_11_29_18] Iteration #458 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0810063
Z variance train             0.028948808
KL Divergence                20.30812
KL Loss                      2.030812
QF Loss                      1108.5178
VF Loss                      288.0362
Policy Loss                  -1294.8616
Q Predictions Mean           1294.7744
Q Predictions Std            307.37122
Q Predictions Max            1516.4253
Q Predictions Min            -125.57156
V Predictions Mean           1286.1849
V Predictions Std            304.63388
V Predictions Max            1512.3096
V Predictions Min            -129.34184
Log Pis Mean                 0.44705772
Log Pis Std                  2.8164024
Log Pis Max                  11.869778
Log Pis Min                  -12.045315
Policy mu Mean               -0.026513115
Policy mu Std                0.6158486
Policy mu Max                2.3959436
Policy mu Min                -2.4620683
Policy log std Mean          -1.0335705
Policy log std Std           0.27828184
Policy log std Max           -0.07293224
Policy log std Min           -2.4638777
Z mean eval                  1.0233772
Z variance eval              0.019386105
total_rewards                [3275.62377158 3533.57637718 3335.61468162 1634.74147061 2080.68915068
 3537.16224668 1098.46676119 3412.87232534 2777.04371513 3433.68194562]
total_rewards_mean           2811.9472445629362
total_rewards_std            845.0656400093776
total_rewards_max            3537.1622466841163
total_rewards_min            1098.4667611907025
Number of train steps total  460000
Number of env steps total    2302000
Number of rollouts total     0
Train Time (s)               44.60228710109368
(Previous) Eval Time (s)     28.859308319631964
Sample Time (s)              23.02147223893553
Epoch Time (s)               96.48306765966117
Total Train Time (s)         44085.720115167554
Epoch                        459
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:44:05.440149 UTC | [2020_01_10_11_29_18] Iteration #459 | Epoch Duration: 96.92749810218811
2020-01-10 23:44:05.440294 UTC | [2020_01_10_11_29_18] Iteration #459 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0255277
Z variance train             0.019354569
KL Divergence                20.865046
KL Loss                      2.0865047
QF Loss                      1002.08936
VF Loss                      170.83704
Policy Loss                  -1326.5273
Q Predictions Mean           1327.0283
Q Predictions Std            269.90427
Q Predictions Max            1538.2703
Q Predictions Min            -86.17227
V Predictions Mean           1323.3647
V Predictions Std            267.1762
V Predictions Max            1520.1505
V Predictions Min            -113.65885
Log Pis Mean                 0.82299006
Log Pis Std                  2.8840392
Log Pis Max                  10.414778
Log Pis Min                  -8.666914
Policy mu Mean               -0.024106145
Policy mu Std                0.6507124
Policy mu Max                2.679208
Policy mu Min                -2.3879833
Policy log std Mean          -1.0412662
Policy log std Std           0.28099754
Policy log std Max           0.021187782
Policy log std Min           -2.206768
Z mean eval                  1.0722535
Z variance eval              0.014231598
total_rewards                [1120.61963024 1412.28627085 3562.25411457 2890.7376973  1445.86234228
  -62.97497514  677.94239904 3554.75068003 1273.84923941 2070.46323978]
total_rewards_mean           1794.5790638374988
total_rewards_std            1148.5238996313226
total_rewards_max            3562.2541145719606
total_rewards_min            -62.97497514109022
Number of train steps total  461000
Number of env steps total    2307000
Number of rollouts total     0
Train Time (s)               44.75264835031703
(Previous) Eval Time (s)     29.30347346700728
Sample Time (s)              23.12361937807873
Epoch Time (s)               97.17974119540304
Total Train Time (s)         44180.32114880625
Epoch                        460
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:45:40.047531 UTC | [2020_01_10_11_29_18] Iteration #460 | Epoch Duration: 94.60712552070618
2020-01-10 23:45:40.047709 UTC | [2020_01_10_11_29_18] Iteration #460 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0719527
Z variance train             0.014233825
KL Divergence                22.145897
KL Loss                      2.2145898
QF Loss                      1967.6995
VF Loss                      155.09372
Policy Loss                  -1337.2183
Q Predictions Mean           1335.262
Q Predictions Std            225.36914
Q Predictions Max            1515.6669
Q Predictions Min            -93.08766
V Predictions Mean           1328.8451
V Predictions Std            224.49971
V Predictions Max            1493.3105
V Predictions Min            -111.99187
Log Pis Mean                 0.20907041
Log Pis Std                  2.5215743
Log Pis Max                  7.2757683
Log Pis Min                  -7.509774
Policy mu Mean               0.03480512
Policy mu Std                0.62984115
Policy mu Max                2.3321729
Policy mu Min                -2.0707006
Policy log std Mean          -1.0079145
Policy log std Std           0.24492203
Policy log std Max           -0.04053068
Policy log std Min           -2.1164465
Z mean eval                  1.0588043
Z variance eval              0.018465927
total_rewards                [1618.6610341  3744.25887772 1859.16314197  203.54730582 3427.8222794
 3526.51632749 3782.69812246 3269.00532824 3214.5428296  3439.64644014]
total_rewards_mean           2808.5861686928038
total_rewards_std            1122.578801530985
total_rewards_max            3782.6981224604647
total_rewards_min            203.54730582390258
Number of train steps total  462000
Number of env steps total    2312000
Number of rollouts total     0
Train Time (s)               44.574008882045746
(Previous) Eval Time (s)     26.73061708919704
Sample Time (s)              22.873888600617647
Epoch Time (s)               94.17851457186043
Total Train Time (s)         44276.37093954068
Epoch                        461
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:47:16.102944 UTC | [2020_01_10_11_29_18] Iteration #461 | Epoch Duration: 96.0551028251648
2020-01-10 23:47:16.103124 UTC | [2020_01_10_11_29_18] Iteration #461 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0577891
Z variance train             0.018492417
KL Divergence                21.798983
KL Loss                      2.1798983
QF Loss                      804.38916
VF Loss                      126.20619
Policy Loss                  -1304.3202
Q Predictions Mean           1305.1362
Q Predictions Std            292.55594
Q Predictions Max            1532.4698
Q Predictions Min            -106.879875
V Predictions Mean           1307.5659
V Predictions Std            294.0443
V Predictions Max            1547.986
V Predictions Min            -110.898895
Log Pis Mean                 0.3937195
Log Pis Std                  2.5815494
Log Pis Max                  11.9179125
Log Pis Min                  -6.0362444
Policy mu Mean               -0.029152011
Policy mu Std                0.634698
Policy mu Max                2.6674666
Policy mu Min                -2.3996713
Policy log std Mean          -0.9876324
Policy log std Std           0.27199784
Policy log std Max           -0.119910955
Policy log std Min           -2.670885
Z mean eval                  1.0625718
Z variance eval              0.022341546
total_rewards                [3669.79169545 3634.97813762 3575.49974568 3337.23733027 3583.29479358
 1222.94188644 1942.08714873 3520.64997106 3607.74031565 3610.67058899]
total_rewards_mean           3170.4891613465284
total_rewards_std            814.6639056278359
total_rewards_max            3669.7916954459733
total_rewards_min            1222.9418864438449
Number of train steps total  463000
Number of env steps total    2317000
Number of rollouts total     0
Train Time (s)               44.85958897229284
(Previous) Eval Time (s)     28.606960908975452
Sample Time (s)              21.691243598237634
Epoch Time (s)               95.15779347950593
Total Train Time (s)         44377.57808626583
Epoch                        462
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:48:57.312934 UTC | [2020_01_10_11_29_18] Iteration #462 | Epoch Duration: 101.20967626571655
2020-01-10 23:48:57.313098 UTC | [2020_01_10_11_29_18] Iteration #462 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0622596
Z variance train             0.02236801
KL Divergence                21.146667
KL Loss                      2.1146667
QF Loss                      1568.9658
VF Loss                      415.07617
Policy Loss                  -1313.1957
Q Predictions Mean           1313.5685
Q Predictions Std            217.97823
Q Predictions Max            1506.3993
Q Predictions Min            -57.8042
V Predictions Mean           1326.2157
V Predictions Std            215.09726
V Predictions Max            1519.4982
V Predictions Min            -57.536545
Log Pis Mean                 0.521087
Log Pis Std                  2.954995
Log Pis Max                  12.675003
Log Pis Min                  -7.5751534
Policy mu Mean               0.0020342052
Policy mu Std                0.6532472
Policy mu Max                2.6930146
Policy mu Min                -2.1903794
Policy log std Mean          -1.04369
Policy log std Std           0.26903406
Policy log std Max           -0.18809521
Policy log std Min           -2.3927507
Z mean eval                  1.0521822
Z variance eval              0.026273226
total_rewards                [3647.11409435  843.99374277 3462.01825864 4116.50535488  733.94710831
 3717.65246332 2351.71128314 1568.10114508  596.77115529  769.85841374]
total_rewards_mean           2180.76730195192
total_rewards_std            1366.9460965082458
total_rewards_max            4116.505354882129
total_rewards_min            596.7711552898003
Number of train steps total  464000
Number of env steps total    2322000
Number of rollouts total     0
Train Time (s)               44.65404811268672
(Previous) Eval Time (s)     34.65861727623269
Sample Time (s)              24.763111881911755
Epoch Time (s)               104.07577727083117
Total Train Time (s)         44470.764147935435
Epoch                        463
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:50:30.501626 UTC | [2020_01_10_11_29_18] Iteration #463 | Epoch Duration: 93.188401222229
2020-01-10 23:50:30.501766 UTC | [2020_01_10_11_29_18] Iteration #463 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0540407
Z variance train             0.025999224
KL Divergence                20.081543
KL Loss                      2.0081544
QF Loss                      1262.9072
VF Loss                      331.86398
Policy Loss                  -1293.075
Q Predictions Mean           1295.1117
Q Predictions Std            255.00882
Q Predictions Max            1511.2242
Q Predictions Min            -72.97968
V Predictions Mean           1302.5135
V Predictions Std            254.51387
V Predictions Max            1493.0177
V Predictions Min            -71.67992
Log Pis Mean                 0.48701903
Log Pis Std                  2.860125
Log Pis Max                  9.299102
Log Pis Min                  -8.747153
Policy mu Mean               0.04828877
Policy mu Std                0.6188917
Policy mu Max                2.2789547
Policy mu Min                -2.0606875
Policy log std Mean          -1.067744
Policy log std Std           0.2563906
Policy log std Max           -0.18312204
Policy log std Min           -2.1804943
Z mean eval                  1.0494468
Z variance eval              0.021116393
total_rewards                [2349.62297876 3461.58592371 1937.58291217 2394.80816021 3165.00550143
 2247.08815129  110.58672851  637.14130304 3534.15469929 3440.8841443 ]
total_rewards_mean           2327.8460502718212
total_rewards_std            1123.331792436884
total_rewards_max            3534.1546992939075
total_rewards_min            110.58672851140501
Number of train steps total  465000
Number of env steps total    2327000
Number of rollouts total     0
Train Time (s)               45.21617953805253
(Previous) Eval Time (s)     23.770993683021516
Sample Time (s)              22.970893254037946
Epoch Time (s)               91.95806647511199
Total Train Time (s)         44566.45193270268
Epoch                        464
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:52:06.192171 UTC | [2020_01_10_11_29_18] Iteration #464 | Epoch Duration: 95.69030356407166
2020-01-10 23:52:06.192311 UTC | [2020_01_10_11_29_18] Iteration #464 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.049525
Z variance train             0.021186884
KL Divergence                21.05155
KL Loss                      2.105155
QF Loss                      690.9743
VF Loss                      120.96009
Policy Loss                  -1370.0952
Q Predictions Mean           1373.3251
Q Predictions Std            164.54756
Q Predictions Max            1533.2656
Q Predictions Min            -82.40256
V Predictions Mean           1369.9465
V Predictions Std            158.53009
V Predictions Max            1527.2882
V Predictions Min            -56.8278
Log Pis Mean                 0.7114307
Log Pis Std                  2.710136
Log Pis Max                  13.692683
Log Pis Min                  -6.524187
Policy mu Mean               -0.007794246
Policy mu Std                0.6633944
Policy mu Max                3.1810443
Policy mu Min                -2.3463118
Policy log std Mean          -1.0478957
Policy log std Std           0.24275182
Policy log std Max           -0.2538582
Policy log std Min           -2.547745
Z mean eval                  1.0305941
Z variance eval              0.018149182
total_rewards                [1533.64677541 3696.8399837  3630.60592399 3603.38383179 3725.33253679
 2138.45027118 3758.30893528 -129.54711427 3556.82334163 3616.46602997]
total_rewards_mean           2913.031051546318
total_rewards_std            1250.9769401495998
total_rewards_max            3758.308935282668
total_rewards_min            -129.54711427192106
Number of train steps total  466000
Number of env steps total    2332000
Number of rollouts total     0
Train Time (s)               45.56496442016214
(Previous) Eval Time (s)     27.50298883020878
Sample Time (s)              23.4439288075082
Epoch Time (s)               96.51188205787912
Total Train Time (s)         44669.22400470963
Epoch                        465
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:53:48.967933 UTC | [2020_01_10_11_29_18] Iteration #465 | Epoch Duration: 102.77551913261414
2020-01-10 23:53:48.968085 UTC | [2020_01_10_11_29_18] Iteration #465 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0291225
Z variance train             0.018202601
KL Divergence                21.417992
KL Loss                      2.1417992
QF Loss                      7219.949
VF Loss                      242.83505
Policy Loss                  -1293.8376
Q Predictions Mean           1295.028
Q Predictions Std            313.25674
Q Predictions Max            1530.8737
Q Predictions Min            -106.42687
V Predictions Mean           1305.3604
V Predictions Std            315.2995
V Predictions Max            1540.231
V Predictions Min            -108.21742
Log Pis Mean                 0.35380322
Log Pis Std                  2.513095
Log Pis Max                  8.259037
Log Pis Min                  -6.993352
Policy mu Mean               0.013596039
Policy mu Std                0.61451066
Policy mu Max                2.6314657
Policy mu Min                -2.1417305
Policy log std Mean          -1.0370245
Policy log std Std           0.28246003
Policy log std Max           0.040818334
Policy log std Min           -2.3405595
Z mean eval                  1.0307881
Z variance eval              0.02080815
total_rewards                [ 918.52087287 2859.18431936  828.01473332   41.35426777  376.91189381
  756.88709686  710.16971322  825.86424983  149.04266632 2263.82245171]
total_rewards_mean           972.9772265065418
total_rewards_std            853.6701090042992
total_rewards_max            2859.1843193562
total_rewards_min            41.35426777163961
Number of train steps total  467000
Number of env steps total    2337000
Number of rollouts total     0
Train Time (s)               44.17388911917806
(Previous) Eval Time (s)     33.766388283111155
Sample Time (s)              22.700907232705504
Epoch Time (s)               100.64118463499472
Total Train Time (s)         44747.056175080594
Epoch                        466
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:55:06.802931 UTC | [2020_01_10_11_29_18] Iteration #466 | Epoch Duration: 77.83474373817444
2020-01-10 23:55:06.803070 UTC | [2020_01_10_11_29_18] Iteration #466 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0289397
Z variance train             0.020655852
KL Divergence                21.643028
KL Loss                      2.1643028
QF Loss                      4708.999
VF Loss                      585.8282
Policy Loss                  -1305.721
Q Predictions Mean           1304.9551
Q Predictions Std            293.59164
Q Predictions Max            1547.8864
Q Predictions Min            -96.41819
V Predictions Mean           1312.8228
V Predictions Std            294.18057
V Predictions Max            1542.4541
V Predictions Min            -92.472725
Log Pis Mean                 0.85856855
Log Pis Std                  2.7858574
Log Pis Max                  10.912108
Log Pis Min                  -5.848942
Policy mu Mean               -0.034047402
Policy mu Std                0.6992043
Policy mu Max                2.477617
Policy mu Min                -2.4440057
Policy log std Mean          -1.0186394
Policy log std Std           0.28144082
Policy log std Max           -0.035966933
Policy log std Min           -2.4874644
Z mean eval                  1.0395315
Z variance eval              0.010973856
total_rewards                [1934.74554511 3698.62512521 3703.24385649 3701.99190347 3553.04335235
 3728.33903429 3446.5284738  3675.03729733 3410.66942716 3827.6789669 ]
total_rewards_mean           3467.9902982092544
total_rewards_std            525.8458957792409
total_rewards_max            3827.678966898314
total_rewards_min            1934.7455451059561
Number of train steps total  468000
Number of env steps total    2342000
Number of rollouts total     0
Train Time (s)               44.20139529136941
(Previous) Eval Time (s)     10.95972504094243
Sample Time (s)              21.73715472733602
Epoch Time (s)               76.89827505964786
Total Train Time (s)         44848.48156266473
Epoch                        467
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:56:48.232209 UTC | [2020_01_10_11_29_18] Iteration #467 | Epoch Duration: 101.42903518676758
2020-01-10 23:56:48.232357 UTC | [2020_01_10_11_29_18] Iteration #467 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.040024
Z variance train             0.010952192
KL Divergence                22.98748
KL Loss                      2.298748
QF Loss                      1191.2301
VF Loss                      510.87354
Policy Loss                  -1312.5865
Q Predictions Mean           1314.1235
Q Predictions Std            314.04654
Q Predictions Max            1545.5398
Q Predictions Min            -91.478775
V Predictions Mean           1313.4509
V Predictions Std            309.46072
V Predictions Max            1531.4213
V Predictions Min            -94.74369
Log Pis Mean                 0.46549964
Log Pis Std                  3.0470781
Log Pis Max                  19.021214
Log Pis Min                  -8.17108
Policy mu Mean               -0.017738398
Policy mu Std                0.6631129
Policy mu Max                3.179969
Policy mu Min                -3.779904
Policy log std Mean          -1.0323081
Policy log std Std           0.26624703
Policy log std Max           0.16980553
Policy log std Min           -2.2901073
Z mean eval                  1.0851395
Z variance eval              0.015462056
total_rewards                [3677.02992134 2708.83051537 3245.75918791 3132.34318256 3852.45458893
 3653.32102453 3493.53644252 3657.27688055 3634.92612689    9.09257111]
total_rewards_mean           3106.457044172289
total_rewards_std            1080.99431991769
total_rewards_max            3852.4545889311753
total_rewards_min            9.092571108146075
Number of train steps total  469000
Number of env steps total    2347000
Number of rollouts total     0
Train Time (s)               44.76165438303724
(Previous) Eval Time (s)     35.49023351399228
Sample Time (s)              24.052497937344015
Epoch Time (s)               104.30438583437353
Total Train Time (s)         44947.19446297269
Epoch                        468
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:58:26.954144 UTC | [2020_01_10_11_29_18] Iteration #468 | Epoch Duration: 98.72166609764099
2020-01-10 23:58:26.954336 UTC | [2020_01_10_11_29_18] Iteration #468 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.08425
Z variance train             0.01539294
KL Divergence                22.992468
KL Loss                      2.2992468
QF Loss                      1263.7178
VF Loss                      771.1271
Policy Loss                  -1319.0958
Q Predictions Mean           1321.3573
Q Predictions Std            280.86902
Q Predictions Max            1546.9167
Q Predictions Min            -96.248116
V Predictions Mean           1334.6365
V Predictions Std            274.73947
V Predictions Max            1549.3552
V Predictions Min            -101.18087
Log Pis Mean                 0.6019219
Log Pis Std                  2.9992146
Log Pis Max                  16.378155
Log Pis Min                  -8.811121
Policy mu Mean               -0.05658143
Policy mu Std                0.6450705
Policy mu Max                2.8813043
Policy mu Min                -2.4702342
Policy log std Mean          -1.0415771
Policy log std Std           0.28973815
Policy log std Max           -0.0409379
Policy log std Min           -2.4157112
Z mean eval                  1.0603775
Z variance eval              0.010618956
total_rewards                [3482.61233766 3294.1440924   200.7516614  3679.48013227 3745.0285354
 1820.55802414 3394.47247062 3171.15742161 3545.82572192 3591.71633263]
total_rewards_mean           2992.574673005421
total_rewards_std            1067.4959857124416
total_rewards_max            3745.0285354006
total_rewards_min            200.75166139813712
Number of train steps total  470000
Number of env steps total    2352000
Number of rollouts total     0
Train Time (s)               45.7365413820371
(Previous) Eval Time (s)     29.907267629168928
Sample Time (s)              23.50995015585795
Epoch Time (s)               99.15375916706398
Total Train Time (s)         45047.252185245976
Epoch                        469
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:00:07.012072 UTC | [2020_01_10_11_29_18] Iteration #469 | Epoch Duration: 100.05760550498962
2020-01-11 00:00:07.012208 UTC | [2020_01_10_11_29_18] Iteration #469 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0599129
Z variance train             0.010621072
KL Divergence                24.016588
KL Loss                      2.4016588
QF Loss                      758.0194
VF Loss                      133.25793
Policy Loss                  -1305.4681
Q Predictions Mean           1308.928
Q Predictions Std            288.0322
Q Predictions Max            1497.7128
Q Predictions Min            -107.7815
V Predictions Mean           1305.6417
V Predictions Std            287.68616
V Predictions Max            1489.5602
V Predictions Min            -94.52098
Log Pis Mean                 0.3972617
Log Pis Std                  2.724378
Log Pis Max                  14.297359
Log Pis Min                  -6.4692106
Policy mu Mean               0.033568062
Policy mu Std                0.61368203
Policy mu Max                2.1215475
Policy mu Min                -3.0707412
Policy log std Mean          -1.0441514
Policy log std Std           0.27886233
Policy log std Max           1.5148952
Policy log std Min           -2.1120806
Z mean eval                  1.0723587
Z variance eval              0.012905739
total_rewards                [3102.79965067 1620.23940566 3404.98118995 3277.3858544  3298.17473405
 3354.10152452 3539.33863136 3290.25418116 1866.10695225 3188.94217434]
total_rewards_mean           2994.2324298366284
total_rewards_std            637.633859929115
total_rewards_max            3539.338631356067
total_rewards_min            1620.2394056611486
Number of train steps total  471000
Number of env steps total    2357000
Number of rollouts total     0
Train Time (s)               44.95976662682369
(Previous) Eval Time (s)     30.81087189493701
Sample Time (s)              23.588582125492394
Epoch Time (s)               99.3592206472531
Total Train Time (s)         45148.76541477069
Epoch                        470
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:01:48.528027 UTC | [2020_01_10_11_29_18] Iteration #470 | Epoch Duration: 101.51571798324585
2020-01-11 00:01:48.528166 UTC | [2020_01_10_11_29_18] Iteration #470 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0709562
Z variance train             0.012935251
KL Divergence                23.185646
KL Loss                      2.3185647
QF Loss                      1917.8796
VF Loss                      210.37886
Policy Loss                  -1340.252
Q Predictions Mean           1341.4176
Q Predictions Std            257.91025
Q Predictions Max            1562.3881
Q Predictions Min            -111.53106
V Predictions Mean           1334.0912
V Predictions Std            257.40097
V Predictions Max            1565.4609
V Predictions Min            -118.1749
Log Pis Mean                 0.70242727
Log Pis Std                  2.5887198
Log Pis Max                  8.808468
Log Pis Min                  -5.53353
Policy mu Mean               -0.0026559168
Policy mu Std                0.6172273
Policy mu Max                2.7344532
Policy mu Min                -2.403857
Policy log std Mean          -1.0604067
Policy log std Std           0.2902827
Policy log std Max           0.093120456
Policy log std Min           -2.446559
Z mean eval                  1.0420699
Z variance eval              0.024960896
total_rewards                [3722.84186551 3513.87439767  382.90955048  428.07717239  305.8992849
 3637.48430329 3506.9362341   463.81367872 1044.19602512 1865.64507412]
total_rewards_mean           1887.167758629291
total_rewards_std            1460.5574731832826
total_rewards_max            3722.8418655129226
total_rewards_min            305.89928489652885
Number of train steps total  472000
Number of env steps total    2362000
Number of rollouts total     0
Train Time (s)               44.82575507322326
(Previous) Eval Time (s)     32.967124672140926
Sample Time (s)              23.04995295079425
Epoch Time (s)               100.84283269615844
Total Train Time (s)         45238.73074403079
Epoch                        471
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:03:18.499216 UTC | [2020_01_10_11_29_18] Iteration #471 | Epoch Duration: 89.97088885307312
2020-01-11 00:03:18.499545 UTC | [2020_01_10_11_29_18] Iteration #471 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0438769
Z variance train             0.02503182
KL Divergence                22.08521
KL Loss                      2.2085211
QF Loss                      4054.9302
VF Loss                      377.49716
Policy Loss                  -1314.6241
Q Predictions Mean           1315.5161
Q Predictions Std            258.07172
Q Predictions Max            1517.4172
Q Predictions Min            -147.07983
V Predictions Mean           1309.1656
V Predictions Std            257.7587
V Predictions Max            1503.4906
V Predictions Min            -136.8063
Log Pis Mean                 0.6234459
Log Pis Std                  2.8340275
Log Pis Max                  9.745508
Log Pis Min                  -8.265281
Policy mu Mean               0.041462556
Policy mu Std                0.67445177
Policy mu Max                2.2077866
Policy mu Min                -2.120747
Policy log std Mean          -1.0129898
Policy log std Std           0.2701249
Policy log std Max           -0.14013481
Policy log std Min           -2.4170942
Z mean eval                  1.0285101
Z variance eval              0.022833262
total_rewards                [3511.92403335 3664.14684613  322.8447476  3824.7597396  3740.88205012
   10.83326735 3937.41557827 3684.72356083 3660.0945427  2776.54859252]
total_rewards_mean           2913.417295847161
total_rewards_std            1406.87078659696
total_rewards_max            3937.4155782705566
total_rewards_min            10.833267346453287
Number of train steps total  473000
Number of env steps total    2367000
Number of rollouts total     0
Train Time (s)               43.84431274794042
(Previous) Eval Time (s)     22.094906765036285
Sample Time (s)              22.834659087937325
Epoch Time (s)               88.77387860091403
Total Train Time (s)         45333.966584626585
Epoch                        472
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:04:53.736319 UTC | [2020_01_10_11_29_18] Iteration #472 | Epoch Duration: 95.2365517616272
2020-01-11 00:04:53.736465 UTC | [2020_01_10_11_29_18] Iteration #472 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0277693
Z variance train             0.022857493
KL Divergence                22.518225
KL Loss                      2.2518225
QF Loss                      1084.2034
VF Loss                      223.1609
Policy Loss                  -1351.406
Q Predictions Mean           1354.3225
Q Predictions Std            219.93481
Q Predictions Max            1535.6509
Q Predictions Min            -110.398415
V Predictions Mean           1347.1345
V Predictions Std            219.04321
V Predictions Max            1535.2235
V Predictions Min            -131.11029
Log Pis Mean                 0.2922855
Log Pis Std                  2.7787497
Log Pis Max                  11.19049
Log Pis Min                  -6.2700377
Policy mu Mean               -0.020612098
Policy mu Std                0.6385731
Policy mu Max                3.2254868
Policy mu Min                -2.5246959
Policy log std Mean          -1.0402515
Policy log std Std           0.2407897
Policy log std Max           -0.14418685
Policy log std Min           -2.123524
Z mean eval                  1.0571493
Z variance eval              0.02759105
total_rewards                [3438.59384581 1745.13270284  816.49918086 1540.24709684 2675.74156845
 -210.67493097 3811.5964756  3370.09771843 3640.64085162 3575.59555114]
total_rewards_mean           2440.3470060637633
total_rewards_std            1322.2883674435093
total_rewards_max            3811.596475604235
total_rewards_min            -210.6749309680277
Number of train steps total  474000
Number of env steps total    2372000
Number of rollouts total     0
Train Time (s)               44.345453744288534
(Previous) Eval Time (s)     28.557374192401767
Sample Time (s)              24.222837569192052
Epoch Time (s)               97.12566550588235
Total Train Time (s)         45431.26252100291
Epoch                        473
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:06:31.039005 UTC | [2020_01_10_11_29_18] Iteration #473 | Epoch Duration: 97.30242848396301
2020-01-11 00:06:31.039156 UTC | [2020_01_10_11_29_18] Iteration #473 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.057647
Z variance train             0.027633345
KL Divergence                22.74244
KL Loss                      2.274244
QF Loss                      713.72876
VF Loss                      146.72623
Policy Loss                  -1337.4019
Q Predictions Mean           1339.1799
Q Predictions Std            239.83623
Q Predictions Max            1538.3573
Q Predictions Min            -122.58926
V Predictions Mean           1344.0769
V Predictions Std            239.57027
V Predictions Max            1547.7023
V Predictions Min            -133.0152
Log Pis Mean                 0.43085346
Log Pis Std                  2.494695
Log Pis Max                  7.495896
Log Pis Min                  -7.041323
Policy mu Mean               0.048689567
Policy mu Std                0.6335923
Policy mu Max                2.5969005
Policy mu Min                -2.7134507
Policy log std Mean          -1.0208285
Policy log std Std           0.25459084
Policy log std Max           0.4313743
Policy log std Min           -2.0459976
Z mean eval                  1.0302408
Z variance eval              0.023574525
total_rewards                [3232.62460454 3484.69723217 3384.73696636 3534.41350947 3708.2430909
 3622.09924093 1298.0378849   423.2384289  3131.50143677 3654.29043624]
total_rewards_mean           2947.3882831165115
total_rewards_std            1075.4238977300733
total_rewards_max            3708.2430908961965
total_rewards_min            423.23842890188826
Number of train steps total  475000
Number of env steps total    2377000
Number of rollouts total     0
Train Time (s)               45.42881240602583
(Previous) Eval Time (s)     28.73388205561787
Sample Time (s)              23.153998798225075
Epoch Time (s)               97.31669325986877
Total Train Time (s)         45532.73172619101
Epoch                        474
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:08:12.517592 UTC | [2020_01_10_11_29_18] Iteration #474 | Epoch Duration: 101.47832560539246
2020-01-11 00:08:12.517732 UTC | [2020_01_10_11_29_18] Iteration #474 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.02998
Z variance train             0.02358583
KL Divergence                23.333963
KL Loss                      2.3333964
QF Loss                      785.81573
VF Loss                      173.70491
Policy Loss                  -1354.7115
Q Predictions Mean           1353.7709
Q Predictions Std            228.47142
Q Predictions Max            1548.0883
Q Predictions Min            -113.29059
V Predictions Mean           1348.3922
V Predictions Std            227.07489
V Predictions Max            1537.2747
V Predictions Min            -121.22024
Log Pis Mean                 0.51450104
Log Pis Std                  2.7776618
Log Pis Max                  9.613265
Log Pis Min                  -9.004608
Policy mu Mean               -0.03364648
Policy mu Std                0.6282142
Policy mu Max                2.2978613
Policy mu Min                -2.4269426
Policy log std Mean          -1.0557622
Policy log std Std           0.2720623
Policy log std Max           -0.17704642
Policy log std Min           -2.4389567
Z mean eval                  1.0449799
Z variance eval              0.022833075
total_rewards                [3599.19817004 1596.91208765 3696.33706294 3552.77146213 3793.45303932
 3782.7265968  1760.16569697 3440.48830919 3356.91709013 1645.28109003]
total_rewards_mean           3022.4250605206184
total_rewards_std            897.1737698255109
total_rewards_max            3793.4530393235905
total_rewards_min            1596.9120876495836
Number of train steps total  476000
Number of env steps total    2382000
Number of rollouts total     0
Train Time (s)               45.75736116012558
(Previous) Eval Time (s)     32.895276435185224
Sample Time (s)              23.190623284317553
Epoch Time (s)               101.84326087962836
Total Train Time (s)         45628.235910147894
Epoch                        475
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:09:48.026582 UTC | [2020_01_10_11_29_18] Iteration #475 | Epoch Duration: 95.50873565673828
2020-01-11 00:09:48.026764 UTC | [2020_01_10_11_29_18] Iteration #475 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0436634
Z variance train             0.022850828
KL Divergence                23.484634
KL Loss                      2.3484635
QF Loss                      2987.8574
VF Loss                      254.48576
Policy Loss                  -1317.4982
Q Predictions Mean           1319.6914
Q Predictions Std            287.57556
Q Predictions Max            1568.9147
Q Predictions Min            -108.77621
V Predictions Mean           1307.5195
V Predictions Std            285.74988
V Predictions Max            1549.8977
V Predictions Min            -127.506516
Log Pis Mean                 0.73661715
Log Pis Std                  3.377959
Log Pis Max                  15.193026
Log Pis Min                  -8.059134
Policy mu Mean               -0.02254593
Policy mu Std                0.6572055
Policy mu Max                2.9789922
Policy mu Min                -2.9424608
Policy log std Mean          -1.0369138
Policy log std Std           0.28230628
Policy log std Max           -0.14700401
Policy log std Min           -2.4208503
Z mean eval                  1.0381905
Z variance eval              0.021623533
total_rewards                [3377.52183179 1111.79872194   29.86146978 3794.69984416 -298.98045379
 3488.73996682 3517.56426501 3466.98673364 1504.5089558  2508.3601169 ]
total_rewards_mean           2250.1061452074364
total_rewards_std            1470.5094695980804
total_rewards_max            3794.699844163204
total_rewards_min            -298.9804537896356
Number of train steps total  477000
Number of env steps total    2387000
Number of rollouts total     0
Train Time (s)               45.22824199218303
(Previous) Eval Time (s)     26.560485649388283
Sample Time (s)              22.545915694907308
Epoch Time (s)               94.33464333647862
Total Train Time (s)         45723.36713667074
Epoch                        476
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:11:23.162481 UTC | [2020_01_10_11_29_18] Iteration #476 | Epoch Duration: 95.13558268547058
2020-01-11 00:11:23.162650 UTC | [2020_01_10_11_29_18] Iteration #476 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.036459
Z variance train             0.021543398
KL Divergence                23.29082
KL Loss                      2.329082
QF Loss                      1075.7258
VF Loss                      293.828
Policy Loss                  -1348.1373
Q Predictions Mean           1349.4409
Q Predictions Std            242.53253
Q Predictions Max            1604.8374
Q Predictions Min            -79.25569
V Predictions Mean           1344.6118
V Predictions Std            241.65326
V Predictions Max            1586.2173
V Predictions Min            -85.87055
Log Pis Mean                 0.39715406
Log Pis Std                  2.712181
Log Pis Max                  10.434883
Log Pis Min                  -6.633705
Policy mu Mean               0.016839152
Policy mu Std                0.6172687
Policy mu Max                2.7557366
Policy mu Min                -2.1520147
Policy log std Mean          -1.0488824
Policy log std Std           0.27301037
Policy log std Max           -0.14798594
Policy log std Min           -2.6459107
Z mean eval                  1.0702608
Z variance eval              0.013157686
total_rewards                [3540.16112176 3037.39011099 4007.65034717 2425.73493739 3523.2795416
 2515.36904184 3625.81384002 3472.92980203 3768.39266372   13.35337471]
total_rewards_mean           2993.0074781254425
total_rewards_std            1107.8042355409962
total_rewards_max            4007.650347172209
total_rewards_min            13.353374709986964
Number of train steps total  478000
Number of env steps total    2392000
Number of rollouts total     0
Train Time (s)               44.48870890121907
(Previous) Eval Time (s)     27.361191228032112
Sample Time (s)              23.26051405770704
Epoch Time (s)               95.11041418695822
Total Train Time (s)         45821.08589517698
Epoch                        477
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:13:00.884180 UTC | [2020_01_10_11_29_18] Iteration #477 | Epoch Duration: 97.72140741348267
2020-01-11 00:13:00.884320 UTC | [2020_01_10_11_29_18] Iteration #477 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0690371
Z variance train             0.013121575
KL Divergence                24.129547
KL Loss                      2.4129548
QF Loss                      9656.988
VF Loss                      350.31152
Policy Loss                  -1334.1205
Q Predictions Mean           1334.4358
Q Predictions Std            210.80055
Q Predictions Max            1535.263
Q Predictions Min            -54.77991
V Predictions Mean           1335.8462
V Predictions Std            210.69939
V Predictions Max            1532.0472
V Predictions Min            -50.588463
Log Pis Mean                 0.84175515
Log Pis Std                  2.8017557
Log Pis Max                  16.614231
Log Pis Min                  -9.100693
Policy mu Mean               -0.0459581
Policy mu Std                0.643863
Policy mu Max                2.446129
Policy mu Min                -2.2351902
Policy log std Mean          -1.0422978
Policy log std Std           0.26525962
Policy log std Max           -0.24382675
Policy log std Min           -2.2741842
Z mean eval                  1.0914586
Z variance eval              0.014637542
total_rewards                [ -16.78701901 2411.55112132 2739.34310192 3789.14104082 1305.47982404
 3456.41483352 3089.55795355 3625.36792145 3570.74313609  300.62741611]
total_rewards_mean           2427.1439329807736
total_rewards_std            1339.6827882658267
total_rewards_max            3789.1410408168813
total_rewards_min            -16.787019010899623
Number of train steps total  479000
Number of env steps total    2397000
Number of rollouts total     0
Train Time (s)               44.40835274895653
(Previous) Eval Time (s)     29.97194605693221
Sample Time (s)              24.247751796152443
Epoch Time (s)               98.62805060204118
Total Train Time (s)         45914.831095093396
Epoch                        478
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:14:34.633771 UTC | [2020_01_10_11_29_18] Iteration #478 | Epoch Duration: 93.7493371963501
2020-01-11 00:14:34.633951 UTC | [2020_01_10_11_29_18] Iteration #478 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0899264
Z variance train             0.014669743
KL Divergence                24.14041
KL Loss                      2.414041
QF Loss                      716.5908
VF Loss                      120.60348
Policy Loss                  -1325.3845
Q Predictions Mean           1326.9353
Q Predictions Std            280.33575
Q Predictions Max            1531.8995
Q Predictions Min            -134.35172
V Predictions Mean           1327.5491
V Predictions Std            278.52893
V Predictions Max            1529.5721
V Predictions Min            -120.27952
Log Pis Mean                 0.6733258
Log Pis Std                  2.8185036
Log Pis Max                  10.830403
Log Pis Min                  -7.424349
Policy mu Mean               -0.025260476
Policy mu Std                0.6826045
Policy mu Max                3.4385529
Policy mu Min                -2.193567
Policy log std Mean          -1.0093505
Policy log std Std           0.25874412
Policy log std Max           -0.1089043
Policy log std Min           -2.0410805
Z mean eval                  1.0611199
Z variance eval              0.011564336
total_rewards                [1383.38311604 3552.61852443 1827.47469445 3781.1580318  3758.26562697
 3779.046399   3733.25436678  -67.76479327 3537.76534955 3796.30047614]
total_rewards_mean           2908.1501791890937
total_rewards_std            1298.9805932173915
total_rewards_max            3796.3004761373595
total_rewards_min            -67.76479326570943
Number of train steps total  480000
Number of env steps total    2402000
Number of rollouts total     0
Train Time (s)               45.23191924020648
(Previous) Eval Time (s)     25.092973184771836
Sample Time (s)              23.10949648078531
Epoch Time (s)               93.43438890576363
Total Train Time (s)         46017.39519569604
Epoch                        479
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:16:17.201985 UTC | [2020_01_10_11_29_18] Iteration #479 | Epoch Duration: 102.5679018497467
2020-01-11 00:16:17.202152 UTC | [2020_01_10_11_29_18] Iteration #479 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0685663
Z variance train             0.011579063
KL Divergence                24.482994
KL Loss                      2.4482994
QF Loss                      637.40314
VF Loss                      175.30997
Policy Loss                  -1305.125
Q Predictions Mean           1306.9324
Q Predictions Std            333.5378
Q Predictions Max            1544.655
Q Predictions Min            -159.10132
V Predictions Mean           1310.9111
V Predictions Std            328.98795
V Predictions Max            1540.584
V Predictions Min            -126.80289
Log Pis Mean                 0.36883974
Log Pis Std                  2.9058087
Log Pis Max                  11.275492
Log Pis Min                  -6.2454944
Policy mu Mean               -0.021897305
Policy mu Std                0.6061659
Policy mu Max                1.941838
Policy mu Min                -2.18857
Policy log std Mean          -1.0361841
Policy log std Std           0.28329146
Policy log std Max           -0.01156342
Policy log std Min           -2.6118312
Z mean eval                  1.0572755
Z variance eval              0.010431483
total_rewards                [3969.2569726  3779.87045801 3731.12947366 3438.27740198 1678.47250761
 1140.78201909 2178.1080377    17.94277457 3568.60716005 3005.4996871 ]
total_rewards_mean           2650.7946492371884
total_rewards_std            1270.8065582404993
total_rewards_max            3969.2569725964804
total_rewards_min            17.94277456859578
Number of train steps total  481000
Number of env steps total    2407000
Number of rollouts total     0
Train Time (s)               45.20072248764336
(Previous) Eval Time (s)     34.226209866814315
Sample Time (s)              22.157915356568992
Epoch Time (s)               101.58484771102667
Total Train Time (s)         46110.0838367925
Epoch                        480
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:17:49.894285 UTC | [2020_01_10_11_29_18] Iteration #480 | Epoch Duration: 92.69200849533081
2020-01-11 00:17:49.894423 UTC | [2020_01_10_11_29_18] Iteration #480 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0582136
Z variance train             0.010406806
KL Divergence                24.677437
KL Loss                      2.4677436
QF Loss                      901.54553
VF Loss                      134.44962
Policy Loss                  -1358.3824
Q Predictions Mean           1362.8807
Q Predictions Std            231.0855
Q Predictions Max            1577.5792
Q Predictions Min            -133.03336
V Predictions Mean           1359.8145
V Predictions Std            231.60262
V Predictions Max            1580.1218
V Predictions Min            -130.25198
Log Pis Mean                 0.63515246
Log Pis Std                  2.713573
Log Pis Max                  10.986425
Log Pis Min                  -6.701758
Policy mu Mean               -0.026615255
Policy mu Std                0.62293744
Policy mu Max                2.3048725
Policy mu Min                -2.4365857
Policy log std Mean          -1.044646
Policy log std Std           0.27892068
Policy log std Max           -0.073836386
Policy log std Min           -2.2445915
Z mean eval                  1.0442269
Z variance eval              0.00896811
total_rewards                [1046.61686255 3469.37033452 2486.36846806 3553.92667882 3470.11149283
  629.4021493  1120.38138346  263.97988069  756.36188637  135.99308774]
total_rewards_mean           1693.2512224343614
total_rewards_std            1327.6558828546943
total_rewards_max            3553.9266788178074
total_rewards_min            135.9930877406207
Number of train steps total  482000
Number of env steps total    2412000
Number of rollouts total     0
Train Time (s)               45.02077515376732
(Previous) Eval Time (s)     25.333149291109294
Sample Time (s)              23.014675157144666
Epoch Time (s)               93.36859960202128
Total Train Time (s)         46207.54494448891
Epoch                        481
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:19:27.366201 UTC | [2020_01_10_11_29_18] Iteration #481 | Epoch Duration: 97.47167587280273
2020-01-11 00:19:27.366339 UTC | [2020_01_10_11_29_18] Iteration #481 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0459557
Z variance train             0.008993521
KL Divergence                24.539486
KL Loss                      2.4539487
QF Loss                      1331.8912
VF Loss                      468.54636
Policy Loss                  -1331.2175
Q Predictions Mean           1328.5471
Q Predictions Std            286.25778
Q Predictions Max            1569.19
Q Predictions Min            -117.862526
V Predictions Mean           1332.3162
V Predictions Std            286.79904
V Predictions Max            1574.0049
V Predictions Min            -112.96632
Log Pis Mean                 1.0526866
Log Pis Std                  2.9526958
Log Pis Max                  17.139645
Log Pis Min                  -7.9611607
Policy mu Mean               0.037906148
Policy mu Std                0.6379837
Policy mu Max                3.0788558
Policy mu Min                -2.3892834
Policy log std Mean          -1.0737997
Policy log std Std           0.30797535
Policy log std Max           -0.15502459
Policy log std Min           -2.774211
Z mean eval                  1.0123396
Z variance eval              0.014642
total_rewards                [3416.29709886 3587.02484534 1681.82191638 3788.79096278 1375.10043152
   64.09305822 3657.14087907  589.36955245 3576.14542244 3631.5802418 ]
total_rewards_mean           2536.736440886136
total_rewards_std            1377.142456404098
total_rewards_max            3788.790962781452
total_rewards_min            64.09305821987712
Number of train steps total  483000
Number of env steps total    2417000
Number of rollouts total     0
Train Time (s)               44.6628753519617
(Previous) Eval Time (s)     29.435998796019703
Sample Time (s)              23.766904030926526
Epoch Time (s)               97.86577817890793
Total Train Time (s)         46302.62027053395
Epoch                        482
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:21:02.449618 UTC | [2020_01_10_11_29_18] Iteration #482 | Epoch Duration: 95.08315086364746
2020-01-11 00:21:02.449776 UTC | [2020_01_10_11_29_18] Iteration #482 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0108341
Z variance train             0.014544156
KL Divergence                23.70457
KL Loss                      2.3704572
QF Loss                      692.3833
VF Loss                      104.71062
Policy Loss                  -1349.1431
Q Predictions Mean           1352.7399
Q Predictions Std            228.67809
Q Predictions Max            1534.5016
Q Predictions Min            -140.95973
V Predictions Mean           1350.362
V Predictions Std            227.38089
V Predictions Max            1546.2203
V Predictions Min            -133.0152
Log Pis Mean                 0.5739868
Log Pis Std                  2.7913227
Log Pis Max                  10.019627
Log Pis Min                  -7.115143
Policy mu Mean               -0.02658455
Policy mu Std                0.6524605
Policy mu Max                2.541087
Policy mu Min                -2.318126
Policy log std Mean          -1.0279291
Policy log std Std           0.24927522
Policy log std Max           -0.16710335
Policy log std Min           -1.9436117
Z mean eval                  1.0753083
Z variance eval              0.012951824
total_rewards                [3604.37556835 3778.92795266  202.22212842 1876.65495965 3451.17679403
 3558.57283498 3823.33175256 3706.61242998 3654.41934627 3799.39455798]
total_rewards_mean           3145.568832487686
total_rewards_std            1122.9246450249832
total_rewards_max            3823.3317525646285
total_rewards_min            202.22212841935712
Number of train steps total  484000
Number of env steps total    2422000
Number of rollouts total     0
Train Time (s)               44.49927949765697
(Previous) Eval Time (s)     26.653139813803136
Sample Time (s)              22.842386974953115
Epoch Time (s)               93.99480628641322
Total Train Time (s)         46402.267530371435
Epoch                        483
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:22:42.099715 UTC | [2020_01_10_11_29_18] Iteration #483 | Epoch Duration: 99.64981746673584
2020-01-11 00:22:42.099853 UTC | [2020_01_10_11_29_18] Iteration #483 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0735537
Z variance train             0.012998606
KL Divergence                23.91461
KL Loss                      2.3914611
QF Loss                      2050.9058
VF Loss                      378.84012
Policy Loss                  -1335.9904
Q Predictions Mean           1333.1025
Q Predictions Std            276.43408
Q Predictions Max            1542.0724
Q Predictions Min            -144.2843
V Predictions Mean           1336.4675
V Predictions Std            269.10812
V Predictions Max            1538.4802
V Predictions Min            -131.34837
Log Pis Mean                 1.0275512
Log Pis Std                  2.8292198
Log Pis Max                  18.470905
Log Pis Min                  -6.747715
Policy mu Mean               0.0005172796
Policy mu Std                0.6505243
Policy mu Max                2.7759821
Policy mu Min                -3.3082843
Policy log std Mean          -1.0789905
Policy log std Std           0.27857134
Policy log std Max           -0.059494615
Policy log std Min           -2.4261422
Z mean eval                  1.0402727
Z variance eval              0.017168483
total_rewards                [ 619.99170188 3531.14596307 3637.72757718 3620.50292771 3727.91070814
 3001.51297136 2934.35457137 3614.00171575 3762.34274142 1037.93990164]
total_rewards_mean           2948.743077951916
total_rewards_std            1097.907699259518
total_rewards_max            3762.342741419544
total_rewards_min            619.9917018790926
Number of train steps total  485000
Number of env steps total    2427000
Number of rollouts total     0
Train Time (s)               44.95066967001185
(Previous) Eval Time (s)     32.30791948828846
Sample Time (s)              23.37419376615435
Epoch Time (s)               100.63278292445466
Total Train Time (s)         46502.749941356014
Epoch                        484
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:24:22.584948 UTC | [2020_01_10_11_29_18] Iteration #484 | Epoch Duration: 100.48497533798218
2020-01-11 00:24:22.585097 UTC | [2020_01_10_11_29_18] Iteration #484 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.039168
Z variance train             0.017086344
KL Divergence                23.623125
KL Loss                      2.3623126
QF Loss                      1303.269
VF Loss                      439.32672
Policy Loss                  -1322.849
Q Predictions Mean           1321.155
Q Predictions Std            298.9444
Q Predictions Max            1550.0593
Q Predictions Min            -141.91272
V Predictions Mean           1306.7944
V Predictions Std            291.8003
V Predictions Max            1526.2383
V Predictions Min            -131.77798
Log Pis Mean                 0.5966787
Log Pis Std                  2.7379062
Log Pis Max                  12.055608
Log Pis Min                  -6.1795015
Policy mu Mean               -0.014783279
Policy mu Std                0.6646475
Policy mu Max                2.6780658
Policy mu Min                -2.5232105
Policy log std Mean          -1.0112178
Policy log std Std           0.27287605
Policy log std Max           -0.1298672
Policy log std Min           -2.0157843
Z mean eval                  1.080171
Z variance eval              0.014700132
total_rewards                [3750.43145865  702.23139461 3728.61102227 3776.49646061 3532.24424914
 3707.39853042 3254.389171   3741.93815627 4020.27580949 2921.1673553 ]
total_rewards_mean           3313.5183607763647
total_rewards_std            918.685533827365
total_rewards_max            4020.275809489569
total_rewards_min            702.2313946137383
Number of train steps total  486000
Number of env steps total    2432000
Number of rollouts total     0
Train Time (s)               45.12848040694371
(Previous) Eval Time (s)     32.159902441781014
Sample Time (s)              23.667150634340942
Epoch Time (s)               100.95553348306566
Total Train Time (s)         46604.34873370407
Epoch                        485
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:26:04.190801 UTC | [2020_01_10_11_29_18] Iteration #485 | Epoch Duration: 101.60558915138245
2020-01-11 00:26:04.190971 UTC | [2020_01_10_11_29_18] Iteration #485 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.081166
Z variance train             0.014687544
KL Divergence                24.318502
KL Loss                      2.4318502
QF Loss                      719.67456
VF Loss                      193.66347
Policy Loss                  -1361.6266
Q Predictions Mean           1363.646
Q Predictions Std            246.41571
Q Predictions Max            1575.4716
Q Predictions Min            -129.32364
V Predictions Mean           1362.0275
V Predictions Std            244.03589
V Predictions Max            1584.2089
V Predictions Min            -128.29587
Log Pis Mean                 0.6378
Log Pis Std                  2.6210043
Log Pis Max                  10.999396
Log Pis Min                  -8.044741
Policy mu Mean               -0.0016998542
Policy mu Std                0.66731954
Policy mu Max                3.3330045
Policy mu Min                -2.1374912
Policy log std Mean          -1.0454106
Policy log std Std           0.27373812
Policy log std Max           -0.20707917
Policy log std Min           -2.2909384
Z mean eval                  1.0805119
Z variance eval              0.009695188
total_rewards                [ 220.8749532  3710.7307882  3712.18885739 3528.12809354 1497.08851009
 3663.75798089 2909.54799685 2470.91418057 3416.93115672  155.03118108]
total_rewards_mean           2528.5193698533303
total_rewards_std            1343.3903687220627
total_rewards_max            3712.188857389616
total_rewards_min            155.03118107875468
Number of train steps total  487000
Number of env steps total    2437000
Number of rollouts total     0
Train Time (s)               44.99229180300608
(Previous) Eval Time (s)     32.80970264412463
Sample Time (s)              23.485836721025407
Epoch Time (s)               101.28783116815612
Total Train Time (s)         46697.024778930936
Epoch                        486
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:27:36.875244 UTC | [2020_01_10_11_29_18] Iteration #486 | Epoch Duration: 92.68415236473083
2020-01-11 00:27:36.875379 UTC | [2020_01_10_11_29_18] Iteration #486 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0802004
Z variance train             0.009716794
KL Divergence                24.967657
KL Loss                      2.4967659
QF Loss                      554.3706
VF Loss                      104.19602
Policy Loss                  -1368.2576
Q Predictions Mean           1368.4556
Q Predictions Std            197.02272
Q Predictions Max            1585.2698
Q Predictions Min            -91.19861
V Predictions Mean           1366.0645
V Predictions Std            195.45697
V Predictions Max            1580.453
V Predictions Min            -90.979034
Log Pis Mean                 0.64475214
Log Pis Std                  2.6553204
Log Pis Max                  10.108903
Log Pis Min                  -5.9699225
Policy mu Mean               -0.05258537
Policy mu Std                0.633327
Policy mu Max                2.0398138
Policy mu Min                -2.6070478
Policy log std Mean          -1.0405743
Policy log std Std           0.27894977
Policy log std Max           0.462893
Policy log std Min           -2.4909182
Z mean eval                  1.044217
Z variance eval              0.016281996
total_rewards                [3633.97313027 1135.95281395 3719.5647217   280.66352471 2456.09389972
 3440.83505286 3784.46880337 3592.29752159 1855.37826859 3641.70138984]
total_rewards_mean           2754.092912659093
total_rewards_std            1198.4478198588918
total_rewards_max            3784.4688033706166
total_rewards_min            280.66352471356333
Number of train steps total  488000
Number of env steps total    2442000
Number of rollouts total     0
Train Time (s)               45.16212366102263
(Previous) Eval Time (s)     24.205779346171767
Sample Time (s)              23.177685391157866
Epoch Time (s)               92.54558839835227
Total Train Time (s)         46791.5463167401
Epoch                        487
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:29:11.409472 UTC | [2020_01_10_11_29_18] Iteration #487 | Epoch Duration: 94.53396725654602
2020-01-11 00:29:11.409680 UTC | [2020_01_10_11_29_18] Iteration #487 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0424335
Z variance train             0.016219938
KL Divergence                24.027706
KL Loss                      2.4027708
QF Loss                      1037.6384
VF Loss                      224.63208
Policy Loss                  -1322.1061
Q Predictions Mean           1323.9122
Q Predictions Std            300.82794
Q Predictions Max            1557.4238
Q Predictions Min            -125.354706
V Predictions Mean           1325.8604
V Predictions Std            304.19345
V Predictions Max            1560.6776
V Predictions Min            -137.5585
Log Pis Mean                 0.6269711
Log Pis Std                  2.9357836
Log Pis Max                  12.060413
Log Pis Min                  -5.7289195
Policy mu Mean               -0.049266104
Policy mu Std                0.62395555
Policy mu Max                2.3033545
Policy mu Min                -2.284547
Policy log std Mean          -1.0598384
Policy log std Std           0.30225906
Policy log std Max           0.73758733
Policy log std Min           -2.8257158
Z mean eval                  1.0813782
Z variance eval              0.014110843
total_rewards                [3584.28201131 3890.50551703 3461.63727258 3419.33692636 2568.48951487
  102.11943114  405.59349793 3481.21538814 1087.75789967 3703.00593318]
total_rewards_mean           2570.3943392209762
total_rewards_std            1391.9425766306615
total_rewards_max            3890.505517029445
total_rewards_min            102.11943114191197
Number of train steps total  489000
Number of env steps total    2447000
Number of rollouts total     0
Train Time (s)               45.12309618387371
(Previous) Eval Time (s)     26.193921140860766
Sample Time (s)              21.27261762553826
Epoch Time (s)               92.58963495027274
Total Train Time (s)         46888.64666060917
Epoch                        488
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:30:48.505121 UTC | [2020_01_10_11_29_18] Iteration #488 | Epoch Duration: 97.0952935218811
2020-01-11 00:30:48.505258 UTC | [2020_01_10_11_29_18] Iteration #488 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0809819
Z variance train             0.014066723
KL Divergence                24.15757
KL Loss                      2.415757
QF Loss                      4061.7214
VF Loss                      815.4383
Policy Loss                  -1336.027
Q Predictions Mean           1338.6323
Q Predictions Std            265.01288
Q Predictions Max            1577.9142
Q Predictions Min            -131.48442
V Predictions Mean           1347.3137
V Predictions Std            260.45837
V Predictions Max            1582.3451
V Predictions Min            -110.20282
Log Pis Mean                 0.42638668
Log Pis Std                  3.13669
Log Pis Max                  14.891623
Log Pis Min                  -7.1024227
Policy mu Mean               -0.012556173
Policy mu Std                0.6247173
Policy mu Max                2.7951357
Policy mu Min                -2.5560234
Policy log std Mean          -1.0677435
Policy log std Std           0.28176665
Policy log std Max           -0.16576266
Policy log std Min           -3.5655394
Z mean eval                  1.07307
Z variance eval              0.010510706
total_rewards                [ 266.10405503 3784.96930251  923.13690299 2135.52023146 3972.18862115
 2102.87096426 3713.78093609  655.93667202 3716.59003734 3579.84689787]
total_rewards_mean           2485.0944620718305
total_rewards_std            1382.1578544661509
total_rewards_max            3972.188621147019
total_rewards_min            266.10405502891695
Number of train steps total  490000
Number of env steps total    2452000
Number of rollouts total     0
Train Time (s)               44.55825689993799
(Previous) Eval Time (s)     30.699360470287502
Sample Time (s)              23.338452998548746
Epoch Time (s)               98.59607036877424
Total Train Time (s)         46980.772371602245
Epoch                        489
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:32:20.633933 UTC | [2020_01_10_11_29_18] Iteration #489 | Epoch Duration: 92.12857389450073
2020-01-11 00:32:20.634069 UTC | [2020_01_10_11_29_18] Iteration #489 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0740942
Z variance train             0.010514068
KL Divergence                24.388603
KL Loss                      2.4388604
QF Loss                      1157.4103
VF Loss                      477.45898
Policy Loss                  -1371.4794
Q Predictions Mean           1372.0378
Q Predictions Std            245.6658
Q Predictions Max            1570.2142
Q Predictions Min            -102.15859
V Predictions Mean           1361.7161
V Predictions Std            247.8458
V Predictions Max            1549.5498
V Predictions Min            -128.90521
Log Pis Mean                 0.67488086
Log Pis Std                  2.94868
Log Pis Max                  17.428633
Log Pis Min                  -10.145107
Policy mu Mean               -0.033472683
Policy mu Std                0.6531214
Policy mu Max                3.070787
Policy mu Min                -2.3288867
Policy log std Mean          -1.0626589
Policy log std Std           0.27597666
Policy log std Max           -0.07947457
Policy log std Min           -2.4042273
Z mean eval                  1.0968726
Z variance eval              0.009649874
total_rewards                [3683.80618277 3665.72582607 3904.48592455 3662.76907626 3857.67567865
 3547.65751688 3764.8102936  3630.96424692 3816.78358248 3913.55631917]
total_rewards_mean           3744.823464733362
total_rewards_std            118.67056567693035
total_rewards_max            3913.55631916611
total_rewards_min            3547.657516880137
Number of train steps total  491000
Number of env steps total    2457000
Number of rollouts total     0
Train Time (s)               44.34006646415219
(Previous) Eval Time (s)     24.231632485985756
Sample Time (s)              23.65986951161176
Epoch Time (s)               92.2315684617497
Total Train Time (s)         47085.063565196935
Epoch                        490
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:34:04.932036 UTC | [2020_01_10_11_29_18] Iteration #490 | Epoch Duration: 104.2978081703186
2020-01-11 00:34:04.932299 UTC | [2020_01_10_11_29_18] Iteration #490 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0992242
Z variance train             0.009640997
KL Divergence                24.903355
KL Loss                      2.4903355
QF Loss                      1140.9961
VF Loss                      954.4458
Policy Loss                  -1338.1708
Q Predictions Mean           1341.7416
Q Predictions Std            286.21072
Q Predictions Max            1575.1815
Q Predictions Min            -162.71397
V Predictions Mean           1320.9489
V Predictions Std            283.39825
V Predictions Max            1548.9062
V Predictions Min            -161.56479
Log Pis Mean                 0.36196613
Log Pis Std                  2.9247484
Log Pis Max                  15.092993
Log Pis Min                  -8.931263
Policy mu Mean               -0.021255665
Policy mu Std                0.64276385
Policy mu Max                2.9266422
Policy mu Min                -2.2609422
Policy log std Mean          -1.0326113
Policy log std Std           0.2989851
Policy log std Max           -0.17653763
Policy log std Min           -2.6732206
Z mean eval                  1.060312
Z variance eval              0.012637605
total_rewards                [1941.45886034  840.0864157  3383.50202157  521.0493974   607.38319171
    4.82431713 2862.47340179 1468.06096652  225.43866173 2723.75721346]
total_rewards_mean           1457.80344473489
total_rewards_std            1145.8729337490652
total_rewards_max            3383.5020215652335
total_rewards_min            4.824317126541211
Number of train steps total  492000
Number of env steps total    2462000
Number of rollouts total     0
Train Time (s)               44.70888490276411
(Previous) Eval Time (s)     36.297603400889784
Sample Time (s)              21.795171634759754
Epoch Time (s)               102.80165993841365
Total Train Time (s)         47166.607680221554
Epoch                        491
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:35:26.483327 UTC | [2020_01_10_11_29_18] Iteration #491 | Epoch Duration: 81.55088663101196
2020-01-11 00:35:26.483540 UTC | [2020_01_10_11_29_18] Iteration #491 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0614405
Z variance train             0.012621595
KL Divergence                24.259897
KL Loss                      2.4259899
QF Loss                      2871.5806
VF Loss                      1412.4661
Policy Loss                  -1348.1047
Q Predictions Mean           1346.512
Q Predictions Std            281.20444
Q Predictions Max            1565.9854
Q Predictions Min            -167.48102
V Predictions Mean           1338.7981
V Predictions Std            272.26923
V Predictions Max            1554.4994
V Predictions Min            -157.98087
Log Pis Mean                 0.6765158
Log Pis Std                  3.089252
Log Pis Max                  15.217222
Log Pis Min                  -6.901464
Policy mu Mean               0.006716904
Policy mu Std                0.6126135
Policy mu Max                3.9384985
Policy mu Min                -2.4610665
Policy log std Mean          -1.0870609
Policy log std Std           0.314007
Policy log std Max           0.7268534
Policy log std Min           -3.3239813
Z mean eval                  1.0709517
Z variance eval              0.012862747
total_rewards                [3579.52001562 3677.40426888 3804.16459814 1961.41845106  171.42980235
 3800.11479217  768.10572723 3626.74330196 3636.98830723 3711.68175694]
total_rewards_mean           2873.757102158154
total_rewards_std            1314.8413180272655
total_rewards_max            3804.164598143539
total_rewards_min            171.4298023456106
Number of train steps total  493000
Number of env steps total    2467000
Number of rollouts total     0
Train Time (s)               45.881087882909924
(Previous) Eval Time (s)     15.046582851093262
Sample Time (s)              23.092758209444582
Epoch Time (s)               84.02042894344777
Total Train Time (s)         47263.46468223864
Epoch                        492
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:37:03.347621 UTC | [2020_01_10_11_29_18] Iteration #492 | Epoch Duration: 96.86390614509583
2020-01-11 00:37:03.347855 UTC | [2020_01_10_11_29_18] Iteration #492 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.07044
Z variance train             0.012908089
KL Divergence                24.140179
KL Loss                      2.414018
QF Loss                      1468.0355
VF Loss                      225.38986
Policy Loss                  -1371.0078
Q Predictions Mean           1369.9269
Q Predictions Std            195.44049
Q Predictions Max            1583.7571
Q Predictions Min            -143.24763
V Predictions Mean           1379.2067
V Predictions Std            195.34454
V Predictions Max            1581.0527
V Predictions Min            -122.75505
Log Pis Mean                 0.6211206
Log Pis Std                  2.6148715
Log Pis Max                  8.8938055
Log Pis Min                  -8.54699
Policy mu Mean               0.0009570047
Policy mu Std                0.668109
Policy mu Max                3.2380297
Policy mu Min                -2.2490652
Policy log std Mean          -1.0404311
Policy log std Std           0.24464768
Policy log std Max           -0.24586433
Policy log std Min           -2.4114819
Z mean eval                  1.0373764
Z variance eval              0.010246701
total_rewards                [3826.55729612 3921.25398413 3757.63000397 3908.4219274  1006.76836223
 3798.50639877 3807.61992159 2631.71113372 3896.7332321  3798.27375458]
total_rewards_mean           3435.34760146172
total_rewards_std            887.4518060954637
total_rewards_max            3921.253984133131
total_rewards_min            1006.7683622312376
Number of train steps total  494000
Number of env steps total    2472000
Number of rollouts total     0
Train Time (s)               44.72300568502396
(Previous) Eval Time (s)     27.889803940895945
Sample Time (s)              23.27187706809491
Epoch Time (s)               95.88468669401482
Total Train Time (s)         47363.81737837801
Epoch                        493
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:38:43.704757 UTC | [2020_01_10_11_29_18] Iteration #493 | Epoch Duration: 100.35670971870422
2020-01-11 00:38:43.704927 UTC | [2020_01_10_11_29_18] Iteration #493 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0377787
Z variance train             0.010243025
KL Divergence                24.576015
KL Loss                      2.4576015
QF Loss                      1155.508
VF Loss                      299.8934
Policy Loss                  -1353.3173
Q Predictions Mean           1357.2216
Q Predictions Std            267.41467
Q Predictions Max            1572.3864
Q Predictions Min            -116.55208
V Predictions Mean           1346.3082
V Predictions Std            266.2525
V Predictions Max            1565.866
V Predictions Min            -129.44492
Log Pis Mean                 0.75501806
Log Pis Std                  3.0506308
Log Pis Max                  19.290915
Log Pis Min                  -7.856415
Policy mu Mean               -0.0046543516
Policy mu Std                0.6586018
Policy mu Max                3.013047
Policy mu Min                -2.408062
Policy log std Mean          -1.0475945
Policy log std Std           0.27824193
Policy log std Max           0.064400434
Policy log std Min           -2.3291245
Z mean eval                  1.081487
Z variance eval              0.010750918
total_rewards                [  27.34945848  809.73772039 3486.17884922 3578.60875844 3629.17237498
 3703.49091466 3540.99190676 3699.12272053 3851.99594377 3501.69790832]
total_rewards_mean           2982.8346555552625
total_rewards_std            1298.1491293046195
total_rewards_max            3851.995943765599
total_rewards_min            27.349458478344438
Number of train steps total  495000
Number of env steps total    2477000
Number of rollouts total     0
Train Time (s)               44.23606926621869
(Previous) Eval Time (s)     32.361599043011665
Sample Time (s)              22.41006314661354
Epoch Time (s)               99.0077314558439
Total Train Time (s)         47460.72296188958
Epoch                        494
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:40:20.614530 UTC | [2020_01_10_11_29_18] Iteration #494 | Epoch Duration: 96.90947246551514
2020-01-11 00:40:20.614701 UTC | [2020_01_10_11_29_18] Iteration #494 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0844008
Z variance train             0.010748906
KL Divergence                24.989285
KL Loss                      2.4989285
QF Loss                      1159.5908
VF Loss                      906.94006
Policy Loss                  -1368.6587
Q Predictions Mean           1370.5305
Q Predictions Std            257.38287
Q Predictions Max            1565.0165
Q Predictions Min            -165.68951
V Predictions Mean           1369.5178
V Predictions Std            255.91792
V Predictions Max            1560.691
V Predictions Min            -167.11089
Log Pis Mean                 0.7665217
Log Pis Std                  3.1979766
Log Pis Max                  13.5896225
Log Pis Min                  -8.872516
Policy mu Mean               -0.0056937123
Policy mu Std                0.66123194
Policy mu Max                2.7542858
Policy mu Min                -2.189562
Policy log std Mean          -1.0671015
Policy log std Std           0.27535057
Policy log std Max           -0.17335945
Policy log std Min           -2.8383992
Z mean eval                  1.0580951
Z variance eval              0.010821573
total_rewards                [3631.84898953   67.86732877 3582.71053737 3637.61201699 3393.08400622
 3380.11515318 3786.13506765   13.57986367 3642.85325487 3784.1087454 ]
total_rewards_mean           2891.9914963656956
total_rewards_std            1431.428671156164
total_rewards_max            3786.135067654801
total_rewards_min            13.579863671216632
Number of train steps total  496000
Number of env steps total    2482000
Number of rollouts total     0
Train Time (s)               44.68798556085676
(Previous) Eval Time (s)     30.263108029961586
Sample Time (s)              23.198482614476234
Epoch Time (s)               98.14957620529458
Total Train Time (s)         47557.34054159699
Epoch                        495
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:41:57.242776 UTC | [2020_01_10_11_29_18] Iteration #495 | Epoch Duration: 96.62789988517761
2020-01-11 00:41:57.243101 UTC | [2020_01_10_11_29_18] Iteration #495 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0562205
Z variance train             0.010830125
KL Divergence                24.828203
KL Loss                      2.4828203
QF Loss                      1104.6289
VF Loss                      2040.223
Policy Loss                  -1366.1732
Q Predictions Mean           1366.0979
Q Predictions Std            235.20317
Q Predictions Max            1570.1454
Q Predictions Min            -98.0416
V Predictions Mean           1354.7664
V Predictions Std            221.92583
V Predictions Max            1549.7374
V Predictions Min            -97.224976
Log Pis Mean                 0.5085922
Log Pis Std                  2.808978
Log Pis Max                  13.812888
Log Pis Min                  -7.028592
Policy mu Mean               0.027324172
Policy mu Std                0.6334372
Policy mu Max                2.4076195
Policy mu Min                -2.4080596
Policy log std Mean          -1.0576683
Policy log std Std           0.27543256
Policy log std Max           -0.110587
Policy log std Min           -3.4463997
Z mean eval                  1.0579369
Z variance eval              0.010425249
total_rewards                [3578.29486957 3509.00499926 3453.15289689 3708.52331172  335.62470615
 3520.40360024 3458.47563686 3568.93044352 3678.40083652   14.32348545]
total_rewards_mean           2882.5134786184017
total_rewards_std            1357.9735773160971
total_rewards_max            3708.523311721039
total_rewards_min            14.323485448589764
Number of train steps total  497000
Number of env steps total    2487000
Number of rollouts total     0
Train Time (s)               44.371066553052515
(Previous) Eval Time (s)     28.741161779034883
Sample Time (s)              23.272795917931944
Epoch Time (s)               96.38502425001934
Total Train Time (s)         47656.703167697415
Epoch                        496
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:43:36.608566 UTC | [2020_01_10_11_29_18] Iteration #496 | Epoch Duration: 99.3652515411377
2020-01-11 00:43:36.608705 UTC | [2020_01_10_11_29_18] Iteration #496 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0588768
Z variance train             0.010418299
KL Divergence                25.01646
KL Loss                      2.501646
QF Loss                      1293.7649
VF Loss                      428.80307
Policy Loss                  -1362.3405
Q Predictions Mean           1363.6274
Q Predictions Std            260.31915
Q Predictions Max            1559.0918
Q Predictions Min            -155.31339
V Predictions Mean           1356.8568
V Predictions Std            263.51004
V Predictions Max            1561.1
V Predictions Min            -169.66595
Log Pis Mean                 0.74038243
Log Pis Std                  3.116699
Log Pis Max                  16.136208
Log Pis Min                  -5.7407947
Policy mu Mean               -0.011774661
Policy mu Std                0.64221394
Policy mu Max                3.0755932
Policy mu Min                -2.4230433
Policy log std Mean          -1.0592711
Policy log std Std           0.27100438
Policy log std Max           -0.045785427
Policy log std Min           -2.8315752
Z mean eval                  1.0443803
Z variance eval              0.026675042
total_rewards                [1883.45150231  991.0232729  3330.93885176 3893.85408773  164.86515767
 1221.81070671  136.26374166  976.08680631 3516.757176   3511.68087691]
total_rewards_mean           1962.673217995873
total_rewards_std            1394.8730111909847
total_rewards_max            3893.854087730543
total_rewards_min            136.26374165562487
Number of train steps total  498000
Number of env steps total    2492000
Number of rollouts total     0
Train Time (s)               45.165536602027714
(Previous) Eval Time (s)     31.7211817628704
Sample Time (s)              23.513792920857668
Epoch Time (s)               100.40051128575578
Total Train Time (s)         47743.87719021784
Epoch                        497
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:45:03.787697 UTC | [2020_01_10_11_29_18] Iteration #497 | Epoch Duration: 87.17887377738953
2020-01-11 00:45:03.787889 UTC | [2020_01_10_11_29_18] Iteration #497 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0433233
Z variance train             0.026695859
KL Divergence                23.620527
KL Loss                      2.3620527
QF Loss                      767.76184
VF Loss                      157.50462
Policy Loss                  -1367.0103
Q Predictions Mean           1368.5842
Q Predictions Std            254.4132
Q Predictions Max            1595.2646
Q Predictions Min            -147.75832
V Predictions Mean           1366.9587
V Predictions Std            252.55093
V Predictions Max            1585.293
V Predictions Min            -153.02686
Log Pis Mean                 0.40809208
Log Pis Std                  2.3684428
Log Pis Max                  9.099643
Log Pis Min                  -6.0123825
Policy mu Mean               -0.020413391
Policy mu Std                0.610471
Policy mu Max                2.0414197
Policy mu Min                -2.1932342
Policy log std Mean          -1.0340617
Policy log std Std           0.25286254
Policy log std Max           0.47228003
Policy log std Min           -2.0867891
Z mean eval                  1.0842744
Z variance eval              0.016724186
total_rewards                [3740.11568757 2117.34548064 1043.82607867 3052.56384579 3817.80449368
 2183.6672048  4039.11249842 3645.06097726 3708.94834033 2426.68893176]
total_rewards_mean           2977.5133538924447
total_rewards_std            938.8039363344737
total_rewards_max            4039.112498416691
total_rewards_min            1043.8260786668484
Number of train steps total  499000
Number of env steps total    2497000
Number of rollouts total     0
Train Time (s)               45.06422455236316
(Previous) Eval Time (s)     18.499296994879842
Sample Time (s)              23.036477418150753
Epoch Time (s)               86.59999896539375
Total Train Time (s)         47837.91725478927
Epoch                        498
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:46:37.834724 UTC | [2020_01_10_11_29_18] Iteration #498 | Epoch Duration: 94.04666304588318
2020-01-11 00:46:37.834966 UTC | [2020_01_10_11_29_18] Iteration #498 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0817168
Z variance train             0.016655538
KL Divergence                24.189283
KL Loss                      2.4189284
QF Loss                      887.1675
VF Loss                      444.7964
Policy Loss                  -1319.653
Q Predictions Mean           1322.9248
Q Predictions Std            347.5508
Q Predictions Max            1546.0815
Q Predictions Min            -197.14104
V Predictions Mean           1332.8477
V Predictions Std            353.7933
V Predictions Max            1558.0002
V Predictions Min            -200.60355
Log Pis Mean                 0.7323676
Log Pis Std                  3.0024502
Log Pis Max                  14.595047
Log Pis Min                  -7.9150724
Policy mu Mean               0.03213621
Policy mu Std                0.62659156
Policy mu Max                2.9556174
Policy mu Min                -2.5213828
Policy log std Mean          -1.0697602
Policy log std Std           0.2906962
Policy log std Max           0.47017622
Policy log std Min           -2.60025
Z mean eval                  1.0545943
Z variance eval              0.021707151
total_rewards                [3759.38853999 3806.74771592 3347.61176385 3807.23777771 3974.9935351
 3863.99643126 3945.7397384  3619.45698862 3815.60865991 3594.0424747 ]
total_rewards_mean           3753.482362545292
total_rewards_std            177.75817319874466
total_rewards_max            3974.9935350992646
total_rewards_min            3347.6117638455826
Number of train steps total  500000
Number of env steps total    2502000
Number of rollouts total     0
Train Time (s)               45.09609390003607
(Previous) Eval Time (s)     25.94573384197429
Sample Time (s)              22.60268366895616
Epoch Time (s)               93.64451141096652
Total Train Time (s)         47938.645438412204
Epoch                        499
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:48:18.567562 UTC | [2020_01_10_11_29_18] Iteration #499 | Epoch Duration: 100.73242831230164
2020-01-11 00:48:18.567740 UTC | [2020_01_10_11_29_18] Iteration #499 | Started Training: True
2020-01-11 00:48:19.339926 UTC | [2020_01_10_11_29_18] Variant:
2020-01-11 00:48:19.340434 UTC | [2020_01_10_11_29_18] {
  "env_name": "Hopper-v2",
  "n_train_tasks": 1,
  "n_eval_tasks": 1,
  "latent_size": 5,
  "net_size": 300,
  "path_to_weights": null,
  "env_params": {
    "n_tasks": 2,
    "randomize_tasks": true
  },
  "algo_params": {
    "meta_batch": 1,
    "num_iterations": 500,
    "num_initial_steps": 2000,
    "num_tasks_sample": 5,
    "num_steps_prior": 400,
    "num_steps_posterior": 0,
    "num_extra_rl_steps_posterior": 600,
    "num_train_steps_per_itr": 1000,
    "num_evals": 2,
    "num_steps_per_eval": 600,
    "batch_size": 256,
    "embedding_batch_size": 20,
    "embedding_mini_batch_size": 20,
    "max_path_length": 200,
    "discount": 0.99,
    "soft_target_tau": 0.005,
    "policy_lr": 0.0003,
    "qf_lr": 0.0003,
    "vf_lr": 0.0003,
    "context_lr": 0.0003,
    "reward_scale": 5.0,
    "sparse_rewards": false,
    "kl_lambda": 0.1,
    "use_information_bottleneck": true,
    "use_next_obs_in_context": false,
    "update_post_train": 1,
    "num_exp_traj_eval": 2,
    "recurrent": true,
    "dump_eval_paths": false
  },
  "util_params": {
    "base_log_dir": "./test/train1000/H-20_inverse-seed",
    "use_gpu": true,
    "gpu_id": 1,
    "debug": false,
    "docker": false,
    "num_iterations": 1000
  }
}
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.002548047
Z variance train             0.6932094
KL Divergence                0.14910097
KL Loss                      0.014910097
QF Loss                      61.968273
VF Loss                      4.1619277
Policy Loss                  -1.9967742
Q Predictions Mean           -0.0011159198
Q Predictions Std            0.0010055336
Q Predictions Max            0.0007985224
Q Predictions Min            -0.0036676915
V Predictions Mean           -0.0064326786
V Predictions Std            0.0012013721
V Predictions Max            -0.0036854176
V Predictions Min            -0.009080635
Log Pis Mean                 -1.9825214
Log Pis Std                  0.38614535
Log Pis Max                  -0.9946431
Log Pis Min                  -2.7250185
Policy mu Mean               -0.0007236393
Policy mu Std                0.0012135297
Policy mu Max                0.0019941595
Policy mu Min                -0.0027270028
Policy log std Mean          -0.0008616333
Policy log std Std           0.0014184922
Policy log std Max           0.0025442091
Policy log std Min           -0.0030400897
Z mean eval                  0.022762287
Z variance eval              0.6356482
total_rewards                [ 52.72272451  58.7426038   69.41354343  77.93148053 107.76629929
  84.54759093  76.34710352  65.1918933   82.40579372  54.40140021]
total_rewards_mean           72.9470433250331
total_rewards_std            15.811971095951625
total_rewards_max            107.76629929365308
total_rewards_min            52.72272450866298
Number of train steps total  1000
Number of env steps total    7000
Number of rollouts total     0
Train Time (s)               42.0583142740652
(Previous) Eval Time (s)     0
Sample Time (s)              20.886008612345904
Epoch Time (s)               62.9443228864111
Total Train Time (s)         64.45370300998911
Epoch                        0
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:49:23.879883 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #0 | Epoch Duration: 64.45666432380676
2020-01-11 00:49:23.880059 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #0 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022887094
Z variance train             0.635148
KL Divergence                0.22572637
KL Loss                      0.022572637
QF Loss                      506.06702
VF Loss                      2.8911517
Policy Loss                  -16.701
Q Predictions Mean           18.158396
Q Predictions Std            16.59718
Q Predictions Max            54.855183
Q Predictions Min            -6.234274
V Predictions Mean           18.086811
V Predictions Std            14.35644
V Predictions Max            49.240757
V Predictions Min            -4.834334
Log Pis Mean                 -1.5634636
Log Pis Std                  0.99866366
Log Pis Max                  1.3440974
Log Pis Min                  -4.8751106
Policy mu Mean               0.32240462
Policy mu Std                0.374735
Policy mu Max                1.0592791
Policy mu Min                -0.1693929
Policy log std Mean          -0.19679122
Policy log std Std           0.07595349
Policy log std Max           -0.08136284
Policy log std Min           -0.37462333
Z mean eval                  0.058517367
Z variance eval              0.35631126
total_rewards                [120.42337728 129.47873469 146.80159085  83.59653297  50.91755468
  62.76436669 145.93077371  73.08406429  69.6876797   95.90883297]
total_rewards_mean           97.8593507830777
total_rewards_std            33.5633815174503
total_rewards_max            146.80159084854049
total_rewards_min            50.917554682902484
Number of train steps total  2000
Number of env steps total    12000
Number of rollouts total     0
Train Time (s)               42.57960775773972
(Previous) Eval Time (s)     1.5120530179701746
Sample Time (s)              14.555511630140245
Epoch Time (s)               58.64717240585014
Total Train Time (s)         123.30146887060255
Epoch                        1
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:50:22.731437 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #1 | Epoch Duration: 58.85111665725708
2020-01-11 00:50:22.731789 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #1 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05893644
Z variance train             0.36317673
KL Divergence                0.96696734
KL Loss                      0.096696734
QF Loss                      28.049644
VF Loss                      1.5121564
Policy Loss                  -13.847781
Q Predictions Mean           11.762515
Q Predictions Std            14.109618
Q Predictions Max            71.703316
Q Predictions Min            -4.8491035
V Predictions Mean           13.328485
V Predictions Std            13.727485
V Predictions Max            69.56121
V Predictions Min            -3.592905
Log Pis Mean                 -1.9290547
Log Pis Std                  0.6654309
Log Pis Max                  1.9169326
Log Pis Min                  -7.460696
Policy mu Mean               0.040064726
Policy mu Std                0.25760275
Policy mu Max                1.0961615
Policy mu Min                -0.38682395
Policy log std Mean          -0.16260014
Policy log std Std           0.08207769
Policy log std Max           -0.09087294
Policy log std Min           -0.47462445
Z mean eval                  0.10950021
Z variance eval              0.097213164
total_rewards                [100.48907649 132.16700251 128.97633935 170.38387411  75.08172984
 159.83186881  89.73994412  73.97779968  90.60013478  72.96219099]
total_rewards_mean           109.42099606657605
total_rewards_std            34.26881746795108
total_rewards_max            170.3838741060933
total_rewards_min            72.9621909863873
Number of train steps total  3000
Number of env steps total    17000
Number of rollouts total     0
Train Time (s)               42.57091520773247
(Previous) Eval Time (s)     1.7157774749211967
Sample Time (s)              15.712058518081903
Epoch Time (s)               59.99875120073557
Total Train Time (s)         183.67286466807127
Epoch                        2
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:51:23.101935 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #2 | Epoch Duration: 60.369953632354736
2020-01-11 00:51:23.102047 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #2 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10486176
Z variance train             0.10086483
KL Divergence                3.5600724
KL Loss                      0.35600725
QF Loss                      19.315615
VF Loss                      3.0462332
Policy Loss                  -18.567387
Q Predictions Mean           16.16924
Q Predictions Std            23.572279
Q Predictions Max            115.91734
Q Predictions Min            -6.642402
V Predictions Mean           18.725002
V Predictions Std            23.874931
V Predictions Max            115.6776
V Predictions Min            -3.8995118
Log Pis Mean                 -1.7663541
Log Pis Std                  0.8331349
Log Pis Max                  2.31276
Log Pis Min                  -3.4284008
Policy mu Mean               0.09917376
Policy mu Std                0.32215914
Policy mu Max                1.5275053
Policy mu Min                -1.262656
Policy log std Mean          -0.1904914
Policy log std Std           0.13184522
Policy log std Max           -0.099466436
Policy log std Min           -0.74706405
Z mean eval                  0.07047607
Z variance eval              0.042333808
total_rewards                [145.76088671 103.53945042 119.30520091 113.66341656 126.47024152
  96.78259321 172.18550643  85.96397325 201.07376462 106.20464617]
total_rewards_mean           127.09496797858256
total_rewards_std            34.20201690632231
total_rewards_max            201.07376462056735
total_rewards_min            85.96397324562173
Number of train steps total  4000
Number of env steps total    22000
Number of rollouts total     0
Train Time (s)               43.09359092870727
(Previous) Eval Time (s)     2.0868011177517474
Sample Time (s)              16.028693458531052
Epoch Time (s)               61.20908550499007
Total Train Time (s)         245.11072090035304
Epoch                        3
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:52:24.540558 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #3 | Epoch Duration: 61.4384081363678
2020-01-11 00:52:24.540708 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #3 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07400391
Z variance train             0.04236172
KL Divergence                5.5488276
KL Loss                      0.55488276
QF Loss                      27.015799
VF Loss                      30.77782
Policy Loss                  -32.45594
Q Predictions Mean           30.366873
Q Predictions Std            43.218124
Q Predictions Max            169.95992
Q Predictions Min            -4.6500287
V Predictions Mean           29.19679
V Predictions Std            40.677273
V Predictions Max            152.52513
V Predictions Min            -4.9441204
Log Pis Mean                 -1.6220663
Log Pis Std                  1.0235163
Log Pis Max                  2.8672104
Log Pis Min                  -3.5631115
Policy mu Mean               0.14839786
Policy mu Std                0.3670606
Policy mu Max                1.8023995
Policy mu Min                -1.7391614
Policy log std Mean          -0.2184427
Policy log std Std           0.15950717
Policy log std Max           -0.1050425
Policy log std Min           -0.8991207
Z mean eval                  0.027715374
Z variance eval              0.0335674
total_rewards                [197.30390125 204.23775632 199.43683451 210.31126133 177.81393532
 181.23983339 198.45370367 236.25698205 215.96517317 205.07742819]
total_rewards_mean           202.6096809181551
total_rewards_std            15.828943667340585
total_rewards_max            236.2569820527553
total_rewards_min            177.813935321863
Number of train steps total  5000
Number of env steps total    27000
Number of rollouts total     0
Train Time (s)               42.82674903282896
(Previous) Eval Time (s)     2.3158963546156883
Sample Time (s)              16.01842558570206
Epoch Time (s)               61.16107097314671
Total Train Time (s)         307.32772445725277
Epoch                        4
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:53:26.761048 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #4 | Epoch Duration: 62.22019696235657
2020-01-11 00:53:26.761247 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #4 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025860349
Z variance train             0.03331464
KL Divergence                6.098922
KL Loss                      0.6098922
QF Loss                      39.74733
VF Loss                      13.098613
Policy Loss                  -45.16471
Q Predictions Mean           42.980927
Q Predictions Std            56.897343
Q Predictions Max            194.1656
Q Predictions Min            -3.425336
V Predictions Mean           43.813454
V Predictions Std            55.985645
V Predictions Max            193.16939
V Predictions Min            -2.4341495
Log Pis Mean                 -1.4954481
Log Pis Std                  1.3205512
Log Pis Max                  4.1004558
Log Pis Min                  -3.8517752
Policy mu Mean               0.07069048
Policy mu Std                0.46020418
Policy mu Max                2.2708602
Policy mu Min                -1.8992499
Policy log std Mean          -0.236989
Policy log std Std           0.16578321
Policy log std Max           -0.080493174
Policy log std Min           -0.8133364
Z mean eval                  0.047725618
Z variance eval              0.01320378
total_rewards                [369.14890666 340.58758262 398.97603399 295.67474366 373.0700976
 393.16997787 364.30663646 336.76008693 340.43787218 413.41749581]
total_rewards_mean           362.55494337899484
total_rewards_std            33.34360235146826
total_rewards_max            413.4174958121909
total_rewards_min            295.67474365753475
Number of train steps total  6000
Number of env steps total    32000
Number of rollouts total     0
Train Time (s)               43.13124636141583
(Previous) Eval Time (s)     3.3748117350041866
Sample Time (s)              17.46919958665967
Epoch Time (s)               63.97525768307969
Total Train Time (s)         373.7771719088778
Epoch                        5
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:54:33.209066 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #5 | Epoch Duration: 66.44765663146973
2020-01-11 00:54:33.209246 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #5 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.044979863
Z variance train             0.013410742
KL Divergence                8.350897
KL Loss                      0.8350897
QF Loss                      64.22273
VF Loss                      17.21096
Policy Loss                  -64.273994
Q Predictions Mean           61.660507
Q Predictions Std            74.34466
Q Predictions Max            216.55466
Q Predictions Min            -7.7582755
V Predictions Mean           63.759846
V Predictions Std            76.5108
V Predictions Max            222.1864
V Predictions Min            -7.301541
Log Pis Mean                 -1.3142918
Log Pis Std                  1.2249726
Log Pis Max                  3.9138808
Log Pis Min                  -3.5331078
Policy mu Mean               0.043720786
Policy mu Std                0.55636704
Policy mu Max                2.090416
Policy mu Min                -2.2389867
Policy log std Mean          -0.26233074
Policy log std Std           0.17867605
Policy log std Max           -0.069169275
Policy log std Min           -0.86236906
Z mean eval                  0.03553063
Z variance eval              0.011980338
total_rewards                [314.38216741 299.54533748 275.58606178 262.32296204 280.72060263
 214.36916361 302.92482618 268.00119169 287.77296798 290.47275758]
total_rewards_mean           279.60980383767526
total_rewards_std            26.537020059028468
total_rewards_max            314.3821674064979
total_rewards_min            214.36916360934651
Number of train steps total  7000
Number of env steps total    37000
Number of rollouts total     0
Train Time (s)               42.82732213800773
(Previous) Eval Time (s)     5.846996225882322
Sample Time (s)              20.514299772679806
Epoch Time (s)               69.18861813656986
Total Train Time (s)         440.5761480475776
Epoch                        6
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:55:40.009297 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #6 | Epoch Duration: 66.79992771148682
2020-01-11 00:55:40.009426 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #6 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034457
Z variance train             0.011964992
KL Divergence                8.623461
KL Loss                      0.8623461
QF Loss                      41.04029
VF Loss                      8.8553505
Policy Loss                  -85.46159
Q Predictions Mean           83.38358
Q Predictions Std            96.45495
Q Predictions Max            252.06769
Q Predictions Min            -6.7994175
V Predictions Mean           85.3501
V Predictions Std            95.628654
V Predictions Max            247.50108
V Predictions Min            -3.2008386
Log Pis Mean                 -1.3348966
Log Pis Std                  1.3514802
Log Pis Max                  5.823474
Log Pis Min                  -4.177545
Policy mu Mean               0.12917165
Policy mu Std                0.55484205
Policy mu Max                2.2114766
Policy mu Min                -2.5678778
Policy log std Mean          -0.29639474
Policy log std Std           0.22165652
Policy log std Max           -0.08380723
Policy log std Min           -0.9848344
Z mean eval                  0.048027795
Z variance eval              0.0073400117
total_rewards                [213.6500319  242.20642894 243.44250746 215.33874922 232.86073225
 250.1096136  221.08293784 226.84768403 242.41641554 213.46966321]
total_rewards_mean           230.14247640130506
total_rewards_std            13.195527655169764
total_rewards_max            250.10961360176805
total_rewards_min            213.46966321377565
Number of train steps total  8000
Number of env steps total    42000
Number of rollouts total     0
Train Time (s)               42.002022413071245
(Previous) Eval Time (s)     3.4580928129144013
Sample Time (s)              16.126425464171916
Epoch Time (s)               61.58654069015756
Total Train Time (s)         502.14309348585084
Epoch                        7
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:56:41.576011 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #7 | Epoch Duration: 61.56647276878357
2020-01-11 00:56:41.576130 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #7 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.047891673
Z variance train             0.0073281974
KL Divergence                9.853132
KL Loss                      0.98531324
QF Loss                      96.52278
VF Loss                      19.320087
Policy Loss                  -101.3295
Q Predictions Mean           98.43662
Q Predictions Std            113.65965
Q Predictions Max            300.37173
Q Predictions Min            -6.643599
V Predictions Mean           102.52481
V Predictions Std            114.880035
V Predictions Max            313.06137
V Predictions Min            -2.8439052
Log Pis Mean                 -1.1712298
Log Pis Std                  1.6844753
Log Pis Max                  8.803408
Log Pis Min                  -4.2343364
Policy mu Mean               0.06873101
Policy mu Std                0.6009538
Policy mu Max                2.3460734
Policy mu Min                -2.0776641
Policy log std Mean          -0.28417635
Policy log std Std           0.19597234
Policy log std Max           -0.062410463
Policy log std Min           -0.9228201
Z mean eval                  0.02462985
Z variance eval              0.007214494
total_rewards                [266.23353425 250.58230393 253.45358468 252.28284793 256.6301473
 258.04368277 235.87313628 267.58985103 252.14290206 245.23420492]
total_rewards_mean           253.80661951566776
total_rewards_std            8.837632533874022
total_rewards_max            267.58985103002607
total_rewards_min            235.8731362791663
Number of train steps total  9000
Number of env steps total    47000
Number of rollouts total     0
Train Time (s)               42.92968117026612
(Previous) Eval Time (s)     3.437799734994769
Sample Time (s)              16.907732150517404
Epoch Time (s)               63.275213055778295
Total Train Time (s)         565.2045159833506
Epoch                        8
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:57:44.638930 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #8 | Epoch Duration: 63.06267309188843
2020-01-11 00:57:44.639088 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #8 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019653479
Z variance train             0.0072022206
KL Divergence                9.956795
KL Loss                      0.9956795
QF Loss                      70.29454
VF Loss                      36.330956
Policy Loss                  -133.07602
Q Predictions Mean           129.26112
Q Predictions Std            138.55115
Q Predictions Max            373.3022
Q Predictions Min            -6.774548
V Predictions Mean           135.57233
V Predictions Std            140.32352
V Predictions Max            381.50357
V Predictions Min            -4.1371217
Log Pis Mean                 -0.96115965
Log Pis Std                  1.889322
Log Pis Max                  7.7834625
Log Pis Min                  -4.3833323
Policy mu Mean               0.083553016
Policy mu Std                0.6447609
Policy mu Max                2.6123185
Policy mu Min                -2.416265
Policy log std Mean          -0.3257123
Policy log std Std           0.23912081
Policy log std Max           -0.06156874
Policy log std Min           -1.0364326
Z mean eval                  0.017193679
Z variance eval              0.004554008
total_rewards                [309.65117717 380.12376634 364.1604482  344.55704518 325.59720664
 332.81377106 356.69158199 362.39470187 359.75292855 363.62469933]
total_rewards_mean           349.93673263288866
total_rewards_std            20.336158843847148
total_rewards_max            380.1237663441661
total_rewards_min            309.651177168675
Number of train steps total  10000
Number of env steps total    52000
Number of rollouts total     0
Train Time (s)               43.17888479027897
(Previous) Eval Time (s)     3.225041314959526
Sample Time (s)              17.06033064983785
Epoch Time (s)               63.46425675507635
Total Train Time (s)         630.0513907331042
Epoch                        9
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:58:49.486811 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #9 | Epoch Duration: 64.8476049900055
2020-01-11 00:58:49.486935 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #9 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019715333
Z variance train             0.0046138754
KL Divergence                11.06102
KL Loss                      1.106102
QF Loss                      104.41266
VF Loss                      52.226578
Policy Loss                  -151.11108
Q Predictions Mean           148.79752
Q Predictions Std            164.16917
Q Predictions Max            423.4887
Q Predictions Min            -2.9751122
V Predictions Mean           148.30423
V Predictions Std            164.90695
V Predictions Max            427.45984
V Predictions Min            -6.171373
Log Pis Mean                 -1.1434801
Log Pis Std                  1.5307924
Log Pis Max                  5.0305557
Log Pis Min                  -4.02256
Policy mu Mean               -0.01853828
Policy mu Std                0.60299206
Policy mu Max                2.442542
Policy mu Min                -2.4818282
Policy log std Mean          -0.33414355
Policy log std Std           0.26003247
Policy log std Max           -0.011969872
Policy log std Min           -1.177952
Z mean eval                  0.0056226114
Z variance eval              0.004093374
total_rewards                [358.17657862 333.58275179 321.53208083 347.89666568 329.93307003
 319.4440957  318.47009587 316.89515403 317.88089698 321.2369409 ]
total_rewards_mean           328.5048330438315
total_rewards_std            13.476527310990608
total_rewards_max            358.17657862088817
total_rewards_min            316.8951540340466
Number of train steps total  11000
Number of env steps total    57000
Number of rollouts total     0
Train Time (s)               42.40026440797374
(Previous) Eval Time (s)     4.608173854183406
Sample Time (s)              18.563131300732493
Epoch Time (s)               65.57156956288964
Total Train Time (s)         695.3658579783514
Epoch                        10
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:59:54.802662 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #10 | Epoch Duration: 65.31561994552612
2020-01-11 00:59:54.802819 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #10 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.004177173
Z variance train             0.004110822
KL Divergence                11.411509
KL Loss                      1.1411508
QF Loss                      115.82961
VF Loss                      38.48948
Policy Loss                  -171.92084
Q Predictions Mean           168.04999
Q Predictions Std            188.14833
Q Predictions Max            515.4407
Q Predictions Min            -7.0948353
V Predictions Mean           169.02014
V Predictions Std            187.20036
V Predictions Max            506.3312
V Predictions Min            -4.64075
Log Pis Mean                 -1.0610623
Log Pis Std                  1.6859462
Log Pis Max                  7.412961
Log Pis Min                  -3.702786
Policy mu Mean               0.002376706
Policy mu Std                0.62742716
Policy mu Max                1.9044183
Policy mu Min                -2.6398509
Policy log std Mean          -0.34498277
Policy log std Std           0.26603335
Policy log std Max           -0.00861828
Policy log std Min           -1.261339
Z mean eval                  0.008595196
Z variance eval              0.004700712
total_rewards                [318.69242677 330.004348   327.88857654 313.91721521 332.89818084
 323.77125236 303.61864069 318.5439021  322.79732807 323.96827604]
total_rewards_mean           321.6100146607547
total_rewards_std            8.060595458720112
total_rewards_max            332.8981808387702
total_rewards_min            303.61864068981663
Number of train steps total  12000
Number of env steps total    62000
Number of rollouts total     0
Train Time (s)               42.61299475003034
(Previous) Eval Time (s)     4.351999145001173
Sample Time (s)              18.088790208566934
Epoch Time (s)               65.05378410359845
Total Train Time (s)         760.1459455895238
Epoch                        11
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:00:59.583084 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #11 | Epoch Duration: 64.7801263332367
2020-01-11 01:00:59.583241 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #11 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.00796102
Z variance train             0.0047122394
KL Divergence                11.2337055
KL Loss                      1.1233705
QF Loss                      174.09824
VF Loss                      46.429558
Policy Loss                  -201.77606
Q Predictions Mean           196.2266
Q Predictions Std            214.21065
Q Predictions Max            590.7081
Q Predictions Min            -8.301851
V Predictions Mean           200.75497
V Predictions Std            214.0897
V Predictions Max            590.8506
V Predictions Min            -6.8189263
Log Pis Mean                 -0.8866652
Log Pis Std                  1.9872277
Log Pis Max                  8.598951
Log Pis Min                  -4.391849
Policy mu Mean               0.02672007
Policy mu Std                0.69856054
Policy mu Max                2.7052546
Policy mu Min                -2.3910172
Policy log std Mean          -0.33899578
Policy log std Std           0.26564547
Policy log std Max           -0.061904997
Policy log std Min           -1.2303361
Z mean eval                  0.023009155
Z variance eval              0.0048040156
total_rewards                [321.21186354 334.22752287 311.28499262 298.37978252 301.47259178
 301.06766156 316.90315589 323.57170273 302.87553428 312.40766271]
total_rewards_mean           312.3402470501509
total_rewards_std            11.115281080788002
total_rewards_max            334.22752287226825
total_rewards_min            298.37978251960106
Number of train steps total  13000
Number of env steps total    67000
Number of rollouts total     0
Train Time (s)               42.70055721979588
(Previous) Eval Time (s)     4.078146122395992
Sample Time (s)              18.277465049177408
Epoch Time (s)               65.05616839136928
Total Train Time (s)         825.6071968702599
Epoch                        12
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:02:05.045340 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #12 | Epoch Duration: 65.46197390556335
2020-01-11 01:02:05.045465 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #12 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021157201
Z variance train             0.0047979853
KL Divergence                11.089777
KL Loss                      1.1089777
QF Loss                      65.02873
VF Loss                      38.960617
Policy Loss                  -216.7297
Q Predictions Mean           214.08871
Q Predictions Std            231.62047
Q Predictions Max            633.5849
Q Predictions Min            -8.622909
V Predictions Mean           214.12164
V Predictions Std            231.9639
V Predictions Max            635.4404
V Predictions Min            -6.704921
Log Pis Mean                 -1.0452847
Log Pis Std                  1.7070283
Log Pis Max                  6.8156896
Log Pis Min                  -9.342373
Policy mu Mean               0.042793225
Policy mu Std                0.65122443
Policy mu Max                2.5626895
Policy mu Min                -2.2723281
Policy log std Mean          -0.33192775
Policy log std Std           0.2589277
Policy log std Max           -0.050116338
Policy log std Min           -1.1725221
Z mean eval                  0.027454278
Z variance eval              0.0049862885
total_rewards                [316.33985367 305.83331918 306.6732994  297.32135663 316.56401804
 309.91005312 322.34220046 316.24306555 326.30590294 320.09041518]
total_rewards_mean           313.76234841742297
total_rewards_std            8.30612065872153
total_rewards_max            326.30590294313834
total_rewards_min            297.3213566347617
Number of train steps total  14000
Number of env steps total    72000
Number of rollouts total     0
Train Time (s)               42.51369256898761
(Previous) Eval Time (s)     4.4837477072142065
Sample Time (s)              18.436657233163714
Epoch Time (s)               65.43409750936553
Total Train Time (s)         891.1220230902545
Epoch                        13
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:03:10.561292 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #13 | Epoch Duration: 65.51571035385132
2020-01-11 01:03:10.561499 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #13 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02150084
Z variance train             0.005182655
KL Divergence                10.943283
KL Loss                      1.0943283
QF Loss                      142.5987
VF Loss                      91.897835
Policy Loss                  -253.1161
Q Predictions Mean           252.81216
Q Predictions Std            254.76408
Q Predictions Max            690.32605
Q Predictions Min            -3.0066097
V Predictions Mean           257.50714
V Predictions Std            256.28534
V Predictions Max            701.4594
V Predictions Min            0.21328628
Log Pis Mean                 -0.9477788
Log Pis Std                  1.930403
Log Pis Max                  11.839958
Log Pis Min                  -4.743611
Policy mu Mean               -0.12722073
Policy mu Std                0.68976307
Policy mu Max                2.0796726
Policy mu Min                -3.43344
Policy log std Mean          -0.31380036
Policy log std Std           0.23078422
Policy log std Max           -0.011995867
Policy log std Min           -1.1607724
Z mean eval                  0.0076291626
Z variance eval              0.006484343
total_rewards                [292.4840175  285.93893934 273.97912548 289.21157302 297.50649766
 292.2228503  305.66049414 303.89237116 299.94559617 309.7673239 ]
total_rewards_mean           295.06087886806716
total_rewards_std            10.06492546398778
total_rewards_max            309.76732389995806
total_rewards_min            273.97912548208956
Number of train steps total  15000
Number of env steps total    77000
Number of rollouts total     0
Train Time (s)               42.604704570025206
(Previous) Eval Time (s)     4.5651467042043805
Sample Time (s)              18.628663724288344
Epoch Time (s)               65.79851499851793
Total Train Time (s)         956.4039536528289
Epoch                        14
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:04:15.844881 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #14 | Epoch Duration: 65.2832396030426
2020-01-11 01:04:15.845009 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #14 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.007263454
Z variance train             0.0065145297
KL Divergence                10.463398
KL Loss                      1.0463399
QF Loss                      185.39587
VF Loss                      49.462566
Policy Loss                  -252.17189
Q Predictions Mean           247.90823
Q Predictions Std            264.51993
Q Predictions Max            718.3282
Q Predictions Min            -7.529051
V Predictions Mean           253.59174
V Predictions Std            265.52448
V Predictions Max            731.35645
V Predictions Min            -6.3893414
Log Pis Mean                 -0.8732405
Log Pis Std                  1.8992456
Log Pis Max                  7.3934555
Log Pis Min                  -3.5883954
Policy mu Mean               0.14157583
Policy mu Std                0.68506134
Policy mu Max                2.5583024
Policy mu Min                -2.6738505
Policy log std Mean          -0.32821652
Policy log std Std           0.23839286
Policy log std Max           -0.022610083
Policy log std Min           -1.2722038
Z mean eval                  0.013158694
Z variance eval              0.005689989
total_rewards                [259.36064029 270.65510394 266.51830064 266.33091945 274.43102303
 256.66321084 269.65086943 259.4065337  268.81410562 267.92828539]
total_rewards_mean           265.97589923300944
total_rewards_std            5.411296761412618
total_rewards_max            274.4310230336515
total_rewards_min            256.66321084120676
Number of train steps total  16000
Number of env steps total    82000
Number of rollouts total     0
Train Time (s)               42.64181221276522
(Previous) Eval Time (s)     4.04964980809018
Sample Time (s)              17.666434411425143
Epoch Time (s)               64.35789643228054
Total Train Time (s)         1020.3451589928009
Epoch                        15
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:05:19.785536 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #15 | Epoch Duration: 63.94043445587158
2020-01-11 01:05:19.785661 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #15 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012848017
Z variance train             0.005696933
KL Divergence                10.73341
KL Loss                      1.073341
QF Loss                      254.65082
VF Loss                      30.047932
Policy Loss                  -274.63397
Q Predictions Mean           272.0503
Q Predictions Std            287.7713
Q Predictions Max            802.03436
Q Predictions Min            -2.7564054
V Predictions Mean           274.78156
V Predictions Std            287.57654
V Predictions Max            792.00433
V Predictions Min            -6.0253887
Log Pis Mean                 -0.7092178
Log Pis Std                  2.2286608
Log Pis Max                  9.327732
Log Pis Min                  -5.5720096
Policy mu Mean               0.055247422
Policy mu Std                0.77890474
Policy mu Max                2.846027
Policy mu Min                -2.4330287
Policy log std Mean          -0.35381004
Policy log std Std           0.26240984
Policy log std Max           0.09881222
Policy log std Min           -1.3968091
Z mean eval                  0.02322068
Z variance eval              0.005872228
total_rewards                [268.05590162 294.33574187 296.48343454 278.75257811 298.1699824
 288.52671904 291.46725808 299.4888954  294.98455089 293.84178333]
total_rewards_mean           290.41068452879006
total_rewards_std            9.316174720432185
total_rewards_max            299.4888953962709
total_rewards_min            268.05590161997276
Number of train steps total  17000
Number of env steps total    87000
Number of rollouts total     0
Train Time (s)               43.2498856568709
(Previous) Eval Time (s)     3.6319666621275246
Sample Time (s)              17.01214822381735
Epoch Time (s)               63.894000542815775
Total Train Time (s)         1084.7287002489902
Epoch                        16
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:06:24.169846 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #16 | Epoch Duration: 64.3840913772583
2020-01-11 01:06:24.169971 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #16 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023321515
Z variance train             0.005874302
KL Divergence                10.502974
KL Loss                      1.0502974
QF Loss                      296.36237
VF Loss                      43.57106
Policy Loss                  -298.16782
Q Predictions Mean           293.5833
Q Predictions Std            297.04477
Q Predictions Max            831.0693
Q Predictions Min            -21.100256
V Predictions Mean           300.22073
V Predictions Std            298.3506
V Predictions Max            853.5384
V Predictions Min            -2.0976257
Log Pis Mean                 -0.7373284
Log Pis Std                  1.9988502
Log Pis Max                  8.322564
Log Pis Min                  -6.875156
Policy mu Mean               0.15357979
Policy mu Std                0.7340337
Policy mu Max                2.351819
Policy mu Min                -2.5824244
Policy log std Mean          -0.38545296
Policy log std Std           0.2782265
Policy log std Max           0.06499432
Policy log std Min           -1.3863828
Z mean eval                  0.02347546
Z variance eval              0.0055736676
total_rewards                [282.8674179  270.5961457  271.47834192 280.05974533 283.23563905
 263.59605744 283.50254212 281.54873084 281.99282701 286.3024242 ]
total_rewards_mean           278.51798715075563
total_rewards_std            6.965846226247192
total_rewards_max            286.30242420185607
total_rewards_min            263.59605744042847
Number of train steps total  18000
Number of env steps total    92000
Number of rollouts total     0
Train Time (s)               43.4298051581718
(Previous) Eval Time (s)     4.121852441225201
Sample Time (s)              18.071642375551164
Epoch Time (s)               65.62329997494817
Total Train Time (s)         1150.193984201178
Epoch                        17
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:07:29.635858 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #17 | Epoch Duration: 65.46579599380493
2020-01-11 01:07:29.635988 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #17 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024308793
Z variance train             0.0055724927
KL Divergence                10.541767
KL Loss                      1.0541767
QF Loss                      197.73795
VF Loss                      155.40555
Policy Loss                  -335.72876
Q Predictions Mean           329.61948
Q Predictions Std            315.82944
Q Predictions Max            873.31116
Q Predictions Min            -2.4249148
V Predictions Mean           328.1843
V Predictions Std            316.1622
V Predictions Max            871.2481
V Predictions Min            -4.150321
Log Pis Mean                 -0.36230895
Log Pis Std                  2.3730924
Log Pis Max                  9.696023
Log Pis Min                  -5.239225
Policy mu Mean               0.033301488
Policy mu Std                0.8133181
Policy mu Max                2.8396113
Policy mu Min                -2.8183136
Policy log std Mean          -0.39989066
Policy log std Std           0.28305313
Policy log std Max           -0.05030869
Policy log std Min           -1.5060626
Z mean eval                  0.019713137
Z variance eval              0.006305518
total_rewards                [284.30239035 293.36702125 292.97048538 280.69578132 286.15537921
 295.52909248 293.03984578 287.21428944 285.77833839 288.18125291]
total_rewards_mean           288.7233876520081
total_rewards_std            4.542879612101365
total_rewards_max            295.52909247616816
total_rewards_min            280.6957813194092
Number of train steps total  19000
Number of env steps total    97000
Number of rollouts total     0
Train Time (s)               42.77646773215383
(Previous) Eval Time (s)     3.9641102328896523
Sample Time (s)              17.22710641566664
Epoch Time (s)               63.967684380710125
Total Train Time (s)         1214.1884068674408
Epoch                        18
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:08:33.630801 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #18 | Epoch Duration: 63.994717597961426
2020-01-11 01:08:33.630923 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #18 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02696592
Z variance train             0.0058173137
KL Divergence                10.475346
KL Loss                      1.0475346
QF Loss                      277.68
VF Loss                      141.12659
Policy Loss                  -345.66394
Q Predictions Mean           343.20505
Q Predictions Std            332.5283
Q Predictions Max            975.2222
Q Predictions Min            -0.8510184
V Predictions Mean           340.2035
V Predictions Std            329.0069
V Predictions Max            960.6439
V Predictions Min            -2.70333
Log Pis Mean                 -0.5662482
Log Pis Std                  2.048155
Log Pis Max                  8.217749
Log Pis Min                  -6.8515987
Policy mu Mean               0.096972786
Policy mu Std                0.7836365
Policy mu Max                2.2278197
Policy mu Min                -2.8982573
Policy log std Mean          -0.37657407
Policy log std Std           0.26403475
Policy log std Max           0.06464948
Policy log std Min           -1.5372537
Z mean eval                  0.020659292
Z variance eval              0.0048986166
total_rewards                [275.84427028 265.91733685 286.33239774 289.63687267 275.31956817
 277.59687741 304.69261642 296.78971945 278.29478043 194.57269029]
total_rewards_mean           274.4997129716213
total_rewards_std            28.75076161704442
total_rewards_max            304.6926164239698
total_rewards_min            194.5726902945691
Number of train steps total  20000
Number of env steps total    102000
Number of rollouts total     0
Train Time (s)               43.12115132575855
(Previous) Eval Time (s)     3.990926319733262
Sample Time (s)              17.80968835297972
Epoch Time (s)               64.92176599847153
Total Train Time (s)         1279.2019095090218
Epoch                        19
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:09:38.645069 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #19 | Epoch Duration: 65.01405549049377
2020-01-11 01:09:38.645194 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #19 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024401035
Z variance train             0.004968148
KL Divergence                10.940388
KL Loss                      1.0940388
QF Loss                      185.27484
VF Loss                      206.8265
Policy Loss                  -331.7333
Q Predictions Mean           327.58667
Q Predictions Std            339.94287
Q Predictions Max            1011.4803
Q Predictions Min            -13.249999
V Predictions Mean           321.2171
V Predictions Std            336.9656
V Predictions Max            1000.1001
V Predictions Min            -9.95992
Log Pis Mean                 -0.8569813
Log Pis Std                  1.8362043
Log Pis Max                  6.259917
Log Pis Min                  -4.2804537
Policy mu Mean               0.117106594
Policy mu Std                0.7442459
Policy mu Max                2.6761153
Policy mu Min                -2.2155855
Policy log std Mean          -0.34907207
Policy log std Std           0.26395765
Policy log std Max           0.17088309
Policy log std Min           -1.3395658
Z mean eval                  0.017299939
Z variance eval              0.005542821
total_rewards                [264.40469911 265.92357821 290.7085007  281.80045262 278.47630878
 280.19813982 283.85104941 285.57620701 261.58545354 292.76903344]
total_rewards_mean           278.52934226459814
total_rewards_std            10.431076798622332
total_rewards_max            292.7690334405048
total_rewards_min            261.585453544754
Number of train steps total  21000
Number of env steps total    107000
Number of rollouts total     0
Train Time (s)               43.942495323717594
(Previous) Eval Time (s)     4.083001311868429
Sample Time (s)              18.243206625804305
Epoch Time (s)               66.26870326139033
Total Train Time (s)         1345.1201590532437
Epoch                        20
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:10:44.566170 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #20 | Epoch Duration: 65.92086839675903
2020-01-11 01:10:44.566349 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #20 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016440235
Z variance train             0.0055593224
KL Divergence                10.74991
KL Loss                      1.0749911
QF Loss                      251.60602
VF Loss                      118.447525
Policy Loss                  -361.59665
Q Predictions Mean           358.2473
Q Predictions Std            348.64606
Q Predictions Max            947.05975
Q Predictions Min            -4.5889792
V Predictions Mean           363.9551
V Predictions Std            350.67294
V Predictions Max            959.82446
V Predictions Min            -5.0545263
Log Pis Mean                 -0.58805996
Log Pis Std                  2.1108441
Log Pis Max                  11.827343
Log Pis Min                  -3.7716074
Policy mu Mean               -0.033167556
Policy mu Std                0.7986542
Policy mu Max                2.5205803
Policy mu Min                -2.772466
Policy log std Mean          -0.37179327
Policy log std Std           0.2603102
Policy log std Max           -0.008419022
Policy log std Min           -1.340688
Z mean eval                  0.012611553
Z variance eval              0.0053414083
total_rewards                [293.57816643 351.42041455 247.98355612 338.2973362  333.13551701
 313.51914461 321.5323016  337.34803458 343.28293376 285.03714453]
total_rewards_mean           316.51345493810055
total_rewards_std            30.60604235903329
total_rewards_max            351.4204145466951
total_rewards_min            247.98355611838804
Number of train steps total  22000
Number of env steps total    112000
Number of rollouts total     0
Train Time (s)               43.44930993625894
(Previous) Eval Time (s)     3.7349174530245364
Sample Time (s)              19.047372598666698
Epoch Time (s)               66.23159998795018
Total Train Time (s)         1411.500535596162
Epoch                        21
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:11:50.945980 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #21 | Epoch Duration: 66.3795018196106
2020-01-11 01:11:50.946102 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #21 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012303111
Z variance train             0.0053374423
KL Divergence                10.887085
KL Loss                      1.0887085
QF Loss                      268.01083
VF Loss                      157.39395
Policy Loss                  -325.09265
Q Predictions Mean           316.2039
Q Predictions Std            346.3969
Q Predictions Max            1025.7175
Q Predictions Min            -4.752026
V Predictions Mean           321.67673
V Predictions Std            347.6541
V Predictions Max            1026.1732
V Predictions Min            -2.422345
Log Pis Mean                 -0.52440673
Log Pis Std                  2.3787432
Log Pis Max                  15.150578
Log Pis Min                  -3.9567297
Policy mu Mean               0.13110405
Policy mu Std                0.83556134
Policy mu Max                3.6048112
Policy mu Min                -3.2749171
Policy log std Mean          -0.31904086
Policy log std Std           0.22796316
Policy log std Max           0.17061886
Policy log std Min           -1.2408988
Z mean eval                  0.022867128
Z variance eval              0.0050275186
total_rewards                [12.59661874 14.19190934 10.52755948 10.79421755 14.20928512 16.38787207
 16.28907679 14.11529834 15.71636841 12.24821547]
total_rewards_mean           13.707642131634397
total_rewards_std            2.0124619325157083
total_rewards_max            16.387872065399183
total_rewards_min            10.52755948468039
Number of train steps total  23000
Number of env steps total    117000
Number of rollouts total     0
Train Time (s)               44.44064091797918
(Previous) Eval Time (s)     3.882602399215102
Sample Time (s)              17.335185119882226
Epoch Time (s)               65.65842843707651
Total Train Time (s)         1473.6564297494479
Epoch                        22
---------------------------  --------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:12:53.103601 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #22 | Epoch Duration: 62.15738773345947
2020-01-11 01:12:53.103754 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #22 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02196355
Z variance train             0.0050179223
KL Divergence                10.93099
KL Loss                      1.093099
QF Loss                      3520.109
VF Loss                      175.91411
Policy Loss                  -371.9574
Q Predictions Mean           375.31052
Q Predictions Std            370.2077
Q Predictions Max            1091.3102
Q Predictions Min            -7.326226
V Predictions Mean           377.57025
V Predictions Std            368.28867
V Predictions Max            1099.5425
V Predictions Min            -5.621961
Log Pis Mean                 -0.371269
Log Pis Std                  2.2742007
Log Pis Max                  15.205375
Log Pis Min                  -4.4854193
Policy mu Mean               0.1368047
Policy mu Std                0.8686733
Policy mu Max                3.5621274
Policy mu Min                -3.8501794
Policy log std Mean          -0.40519047
Policy log std Std           0.2834194
Policy log std Max           0.04951428
Policy log std Min           -1.3782841
Z mean eval                  0.010491111
Z variance eval              0.0043520257
total_rewards                [359.17797353 353.6522251  368.1506224  333.0841053  343.3257836
 347.45914261 365.66165972 381.76445812 371.73836212 352.9181783 ]
total_rewards_mean           357.6932510812538
total_rewards_std            13.81175973149391
total_rewards_max            381.76445811518425
total_rewards_min            333.08410530492836
Number of train steps total  24000
Number of env steps total    122000
Number of rollouts total     0
Train Time (s)               42.82419019471854
(Previous) Eval Time (s)     0.3813630589284003
Sample Time (s)              17.35806670272723
Epoch Time (s)               60.56361995637417
Total Train Time (s)         1538.2163374209777
Epoch                        23
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:13:57.663674 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #23 | Epoch Duration: 64.55980396270752
2020-01-11 01:13:57.663797 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #23 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010388398
Z variance train             0.004349929
KL Divergence                11.344425
KL Loss                      1.1344426
QF Loss                      176.46466
VF Loss                      56.976315
Policy Loss                  -343.75217
Q Predictions Mean           338.94662
Q Predictions Std            373.7753
Q Predictions Max            1093.3987
Q Predictions Min            -3.6087635
V Predictions Mean           339.97263
V Predictions Std            373.03046
V Predictions Max            1117.3115
V Predictions Min            -3.670843
Log Pis Mean                 -0.39560813
Log Pis Std                  2.302365
Log Pis Max                  9.725986
Log Pis Min                  -4.67301
Policy mu Mean               0.17802875
Policy mu Std                0.83219993
Policy mu Max                3.7986562
Policy mu Min                -2.6492343
Policy log std Mean          -0.37319443
Policy log std Std           0.27556226
Policy log std Max           0.08420034
Policy log std Min           -1.4440372
Z mean eval                  0.0121588
Z variance eval              0.003605099
total_rewards                [363.33957062 345.55841822 375.44648292 364.20592721 365.52237546
 376.37051538 364.62688364 354.31723675 365.1994599  375.45798739]
total_rewards_mean           365.00448574966356
total_rewards_std            9.185439078926107
total_rewards_max            376.37051538057915
total_rewards_min            345.5584182163001
Number of train steps total  25000
Number of env steps total    127000
Number of rollouts total     0
Train Time (s)               42.873220172245055
(Previous) Eval Time (s)     4.377347290981561
Sample Time (s)              18.23577706515789
Epoch Time (s)               65.4863445283845
Total Train Time (s)         1603.749330945313
Epoch                        24
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:15:03.197231 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #24 | Epoch Duration: 65.53334093093872
2020-01-11 01:15:03.197348 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #24 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013424188
Z variance train             0.003599159
KL Divergence                11.67783
KL Loss                      1.167783
QF Loss                      304.41336
VF Loss                      270.4656
Policy Loss                  -396.14096
Q Predictions Mean           392.21356
Q Predictions Std            383.07544
Q Predictions Max            1136.7172
Q Predictions Min            -5.842915
V Predictions Mean           401.61276
V Predictions Std            382.46136
V Predictions Max            1152.9336
V Predictions Min            -4.718262
Log Pis Mean                 -0.25098112
Log Pis Std                  2.329172
Log Pis Max                  10.955662
Log Pis Min                  -4.149771
Policy mu Mean               0.14137149
Policy mu Std                0.8689306
Policy mu Max                3.3224099
Policy mu Min                -2.5204942
Policy log std Mean          -0.39824876
Policy log std Std           0.26131046
Policy log std Max           0.13104972
Policy log std Min           -1.2700903
Z mean eval                  0.018360967
Z variance eval              0.0040744725
total_rewards                [376.36206984 369.7235597  369.84126989 369.22812931 379.0296252
 336.09817916 382.99232583 378.66922193 343.9242045  348.70520543]
total_rewards_mean           365.45737907918834
total_rewards_std            15.630285335490573
total_rewards_max            382.992325834966
total_rewards_min            336.09817916381917
Number of train steps total  26000
Number of env steps total    132000
Number of rollouts total     0
Train Time (s)               42.87263482995331
(Previous) Eval Time (s)     4.424130995757878
Sample Time (s)              18.40776971913874
Epoch Time (s)               65.70453554484993
Total Train Time (s)         1669.3012054935098
Epoch                        25
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:16:08.752420 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #25 | Epoch Duration: 65.55494976043701
2020-01-11 01:16:08.752647 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #25 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018073967
Z variance train             0.0040753055
KL Divergence                11.472614
KL Loss                      1.1472615
QF Loss                      236.84164
VF Loss                      91.70015
Policy Loss                  -397.04797
Q Predictions Mean           395.0681
Q Predictions Std            388.44376
Q Predictions Max            1054.5941
Q Predictions Min            -5.3379726
V Predictions Mean           399.0752
V Predictions Std            389.52567
V Predictions Max            1056.6606
V Predictions Min            -1.7135657
Log Pis Mean                 -0.27207503
Log Pis Std                  2.3012707
Log Pis Max                  8.937049
Log Pis Min                  -4.0243096
Policy mu Mean               0.17048347
Policy mu Std                0.8546295
Policy mu Max                3.4877841
Policy mu Min                -2.8824172
Policy log std Mean          -0.4285991
Policy log std Std           0.2973985
Policy log std Max           -0.0013134629
Policy log std Min           -1.6941234
Z mean eval                  0.009314334
Z variance eval              0.0038446852
total_rewards                [269.43186593 302.18564393 314.78577019 289.30373261 377.61757431
 319.94796383 312.67575187 348.20966206 341.00000191 327.57133377]
total_rewards_mean           320.2729300412254
total_rewards_std            29.173162286724448
total_rewards_max            377.61757430906744
total_rewards_min            269.4318659318609
Number of train steps total  27000
Number of env steps total    137000
Number of rollouts total     0
Train Time (s)               43.358547064010054
(Previous) Eval Time (s)     4.274287790991366
Sample Time (s)              18.704591517802328
Epoch Time (s)               66.33742637280375
Total Train Time (s)         1735.2768317386508
Epoch                        26
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:17:14.729049 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #26 | Epoch Duration: 65.97620844841003
2020-01-11 01:17:14.729287 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #26 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008446088
Z variance train             0.0038482337
KL Divergence                11.6225395
KL Loss                      1.162254
QF Loss                      200.3642
VF Loss                      179.02805
Policy Loss                  -415.38373
Q Predictions Mean           412.51263
Q Predictions Std            407.14325
Q Predictions Max            1190.2017
Q Predictions Min            -14.627888
V Predictions Mean           422.5403
V Predictions Std            409.58002
V Predictions Max            1213.27
V Predictions Min            -2.4485767
Log Pis Mean                 -0.1793864
Log Pis Std                  2.2366238
Log Pis Max                  8.88416
Log Pis Min                  -3.4637685
Policy mu Mean               0.2356954
Policy mu Std                0.81730783
Policy mu Max                2.2448015
Policy mu Min                -3.2494135
Policy log std Mean          -0.4066583
Policy log std Std           0.2979493
Policy log std Max           0.22834975
Policy log std Min           -1.5501064
Z mean eval                  0.024121188
Z variance eval              0.0046162913
total_rewards                [336.71183709 330.76707049 329.70834326 325.40832695 325.43638118
 326.10532788 314.32546853 284.48168484 313.05673426 340.21897498]
total_rewards_mean           322.6220149472398
total_rewards_std            15.058432147832464
total_rewards_max            340.2189749804981
total_rewards_min            284.48168484460143
Number of train steps total  28000
Number of env steps total    142000
Number of rollouts total     0
Train Time (s)               43.266701120883226
(Previous) Eval Time (s)     3.9128549909219146
Sample Time (s)              17.881803908385336
Epoch Time (s)               65.06136002019048
Total Train Time (s)         1801.0194629658945
Epoch                        27
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:18:20.472398 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #27 | Epoch Duration: 65.74290537834167
2020-01-11 01:18:20.472597 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #27 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023040753
Z variance train             0.0046190647
KL Divergence                11.45462
KL Loss                      1.145462
QF Loss                      264.0789
VF Loss                      153.60533
Policy Loss                  -435.03235
Q Predictions Mean           432.5053
Q Predictions Std            401.47623
Q Predictions Max            1069.2188
Q Predictions Min            -6.7281337
V Predictions Mean           438.59656
V Predictions Std            403.3902
V Predictions Max            1065.1051
V Predictions Min            -13.89917
Log Pis Mean                 -0.21207327
Log Pis Std                  2.4121711
Log Pis Max                  11.243003
Log Pis Min                  -5.6833315
Policy mu Mean               0.13607219
Policy mu Std                0.8729267
Policy mu Max                3.2449374
Policy mu Min                -3.0896769
Policy log std Mean          -0.4171745
Policy log std Std           0.29602784
Policy log std Max           0.14364412
Policy log std Min           -1.4452734
Z mean eval                  0.020795235
Z variance eval              0.004773562
total_rewards                [245.83479647 349.12312487 344.82527294 344.31900169 316.77967834
 362.03768572 333.64007551 319.6798897  350.18912442 309.4805072 ]
total_rewards_mean           327.59091568630896
total_rewards_std            31.568744687049684
total_rewards_max            362.0376857197138
total_rewards_min            245.8347964740085
Number of train steps total  29000
Number of env steps total    147000
Number of rollouts total     0
Train Time (s)               42.66632713517174
(Previous) Eval Time (s)     4.5941848694346845
Sample Time (s)              18.509559345897287
Epoch Time (s)               65.77007135050371
Total Train Time (s)         1866.3528139744885
Epoch                        28
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:19:25.806158 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #28 | Epoch Duration: 65.33341407775879
2020-01-11 01:19:25.806273 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #28 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021097342
Z variance train             0.0047762142
KL Divergence                11.170302
KL Loss                      1.1170303
QF Loss                      222.20616
VF Loss                      92.200424
Policy Loss                  -443.78955
Q Predictions Mean           436.5593
Q Predictions Std            402.34982
Q Predictions Max            965.11334
Q Predictions Min            -10.828359
V Predictions Mean           440.0823
V Predictions Std            402.49774
V Predictions Max            981.2879
V Predictions Min            -12.890979
Log Pis Mean                 -0.31421176
Log Pis Std                  2.1970487
Log Pis Max                  9.838295
Log Pis Min                  -5.8715076
Policy mu Mean               -0.0766683
Policy mu Std                0.8606547
Policy mu Max                2.9523265
Policy mu Min                -2.8532727
Policy log std Mean          -0.42006025
Policy log std Std           0.29923454
Policy log std Max           0.15023021
Policy log std Min           -1.6329576
Z mean eval                  0.033177815
Z variance eval              0.004575518
total_rewards                [339.65857826 368.62724773 349.16373903 318.88564371 356.10387049
 345.11475775 347.09623239 347.52448898 346.1522907  341.75074047]
total_rewards_mean           346.0077589501217
total_rewards_std            11.924260870388538
total_rewards_max            368.62724772911105
total_rewards_min            318.8856437089496
Number of train steps total  30000
Number of env steps total    152000
Number of rollouts total     0
Train Time (s)               42.89284147089347
(Previous) Eval Time (s)     4.157326876185834
Sample Time (s)              18.11052758479491
Epoch Time (s)               65.16069593187422
Total Train Time (s)         1931.8717474979348
Epoch                        29
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:20:31.327135 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #29 | Epoch Duration: 65.52074837684631
2020-01-11 01:20:31.327333 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #29 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034066163
Z variance train             0.004576975
KL Divergence                11.269543
KL Loss                      1.1269543
QF Loss                      509.78662
VF Loss                      116.217636
Policy Loss                  -396.9029
Q Predictions Mean           391.86047
Q Predictions Std            407.1625
Q Predictions Max            1087.3529
Q Predictions Min            -8.4288435
V Predictions Mean           393.19647
V Predictions Std            407.7807
V Predictions Max            1108.8999
V Predictions Min            -3.1747231
Log Pis Mean                 -0.4819992
Log Pis Std                  2.072816
Log Pis Max                  5.6814356
Log Pis Min                  -5.6363173
Policy mu Mean               0.16657129
Policy mu Std                0.8034828
Policy mu Max                2.1948001
Policy mu Min                -2.8856404
Policy log std Mean          -0.3620688
Policy log std Std           0.26785338
Policy log std Max           0.1457937
Policy log std Min           -1.494106
Z mean eval                  0.037455782
Z variance eval              0.0044949586
total_rewards                [381.8219209  419.17014045 353.02803704 382.43100028 365.7486692
 309.17739773 362.16261106 352.80161634 329.55469453 347.26901122]
total_rewards_mean           360.3165098735978
total_rewards_std            28.791544630539445
total_rewards_max            419.1701404500007
total_rewards_min            309.17739772560435
Number of train steps total  31000
Number of env steps total    157000
Number of rollouts total     0
Train Time (s)               43.79511395795271
(Previous) Eval Time (s)     4.517123182769865
Sample Time (s)              18.70404778327793
Epoch Time (s)               67.0162849240005
Total Train Time (s)         1999.1007020710967
Epoch                        30
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:21:38.557338 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #30 | Epoch Duration: 67.22984719276428
2020-01-11 01:21:38.557507 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #30 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036742084
Z variance train             0.0044973777
KL Divergence                11.416101
KL Loss                      1.1416101
QF Loss                      190.81473
VF Loss                      153.68265
Policy Loss                  -413.56647
Q Predictions Mean           411.51566
Q Predictions Std            399.10898
Q Predictions Max            963.9843
Q Predictions Min            -3.1574388
V Predictions Mean           421.76578
V Predictions Std            401.32364
V Predictions Max            983.91
V Predictions Min            -2.0765688
Log Pis Mean                 -0.3439216
Log Pis Std                  2.3272324
Log Pis Max                  9.560952
Log Pis Min                  -4.6316566
Policy mu Mean               -0.085614
Policy mu Std                0.8534161
Policy mu Max                3.1161559
Policy mu Min                -3.3640237
Policy log std Mean          -0.35103193
Policy log std Std           0.2800344
Policy log std Max           0.36515826
Policy log std Min           -1.6068685
Z mean eval                  0.022849564
Z variance eval              0.004277271
total_rewards                [308.07370945 390.97161855 383.13469129 395.6529762  356.02581384
 366.12860713 332.1611618  362.64242299 304.37781659 405.52070054]
total_rewards_mean           360.4689518362753
total_rewards_std            33.854141635065936
total_rewards_max            405.5207005372041
total_rewards_min            304.37781658545117
Number of train steps total  32000
Number of env steps total    162000
Number of rollouts total     0
Train Time (s)               42.366404841654
(Previous) Eval Time (s)     4.730459088925272
Sample Time (s)              18.695763608906418
Epoch Time (s)               65.7926275394857
Total Train Time (s)         2064.970345825888
Epoch                        31
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:22:44.427120 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #31 | Epoch Duration: 65.8694703578949
2020-01-11 01:22:44.427277 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #31 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022014052
Z variance train             0.00427572
KL Divergence                11.554427
KL Loss                      1.1554427
QF Loss                      217.32831
VF Loss                      96.826515
Policy Loss                  -419.55124
Q Predictions Mean           418.00412
Q Predictions Std            400.5514
Q Predictions Max            1162.9525
Q Predictions Min            -6.8190875
V Predictions Mean           421.7068
V Predictions Std            401.6731
V Predictions Max            1160.9591
V Predictions Min            -5.119766
Log Pis Mean                 -0.28021842
Log Pis Std                  2.368799
Log Pis Max                  10.708384
Log Pis Min                  -3.788486
Policy mu Mean               -0.036941808
Policy mu Std                0.8792493
Policy mu Max                2.3263628
Policy mu Min                -3.1747613
Policy log std Mean          -0.3837631
Policy log std Std           0.2530506
Policy log std Max           0.078206986
Policy log std Min           -1.5628015
Z mean eval                  0.014279721
Z variance eval              0.0039156205
total_rewards                [382.47131262 379.92267367 382.02948728 409.61725756 399.17762698
 367.95104316 372.90148266 390.79882037 365.24134894 389.53579762]
total_rewards_mean           383.9646850864192
total_rewards_std            13.110828637360195
total_rewards_max            409.61725755955007
total_rewards_min            365.2413489401139
Number of train steps total  33000
Number of env steps total    167000
Number of rollouts total     0
Train Time (s)               42.01888927957043
(Previous) Eval Time (s)     4.807049966882914
Sample Time (s)              19.83969791326672
Epoch Time (s)               66.66563715972006
Total Train Time (s)         2131.6110398168676
Epoch                        32
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:23:51.071677 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #32 | Epoch Duration: 66.64423489570618
2020-01-11 01:23:51.071942 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #32 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015490375
Z variance train             0.0039138533
KL Divergence                11.712764
KL Loss                      1.1712765
QF Loss                      592.36523
VF Loss                      203.35706
Policy Loss                  -407.74814
Q Predictions Mean           401.45715
Q Predictions Std            394.581
Q Predictions Max            1068.9088
Q Predictions Min            -1.3291191
V Predictions Mean           401.8091
V Predictions Std            393.34888
V Predictions Max            1072.5726
V Predictions Min            1.1503882
Log Pis Mean                 -0.042437226
Log Pis Std                  2.643687
Log Pis Max                  11.696726
Log Pis Min                  -5.9207387
Policy mu Mean               0.04816881
Policy mu Std                0.94542605
Policy mu Max                2.726316
Policy mu Min                -3.2563195
Policy log std Mean          -0.4034671
Policy log std Std           0.27834386
Policy log std Max           -0.0056670904
Policy log std Min           -1.6975585
Z mean eval                  0.015896505
Z variance eval              0.005093787
total_rewards                [375.42203788 384.53691413 397.52640981 397.51400533 396.78805623
 382.18458675 389.21103519 397.74248411 410.90944237 394.00515055]
total_rewards_mean           392.5840122342171
total_rewards_std            9.537668182886387
total_rewards_max            410.90944236541134
total_rewards_min            375.42203787651187
Number of train steps total  34000
Number of env steps total    172000
Number of rollouts total     0
Train Time (s)               42.19131897203624
(Previous) Eval Time (s)     4.785404220689088
Sample Time (s)              16.980341699440032
Epoch Time (s)               63.95706489216536
Total Train Time (s)         2195.0565707888454
Epoch                        33
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:24:54.519951 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #33 | Epoch Duration: 63.44758200645447
2020-01-11 01:24:54.520287 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #33 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01696066
Z variance train             0.005122919
KL Divergence                10.771841
KL Loss                      1.0771841
QF Loss                      122.078964
VF Loss                      187.7569
Policy Loss                  -417.60117
Q Predictions Mean           413.66394
Q Predictions Std            408.04794
Q Predictions Max            1043.3536
Q Predictions Min            -3.7079365
V Predictions Mean           411.07614
V Predictions Std            403.47522
V Predictions Max            1041.7825
V Predictions Min            -5.923097
Log Pis Mean                 -0.4038285
Log Pis Std                  1.9622717
Log Pis Max                  5.9498997
Log Pis Min                  -5.0472593
Policy mu Mean               -0.047773954
Policy mu Std                0.8088772
Policy mu Max                2.0414221
Policy mu Min                -2.188765
Policy log std Mean          -0.38406196
Policy log std Std           0.27256468
Policy log std Max           0.20305385
Policy log std Min           -1.599534
Z mean eval                  0.029310826
Z variance eval              0.0050136317
total_rewards                [353.59885041 385.04522652 421.45623429 387.99667685 400.79637037
 386.62344502 420.4057478  392.2736201  385.41344623 391.4527575 ]
total_rewards_mean           392.5062375084879
total_rewards_std            18.333242351517917
total_rewards_max            421.4562342917257
total_rewards_min            353.5988504070696
Number of train steps total  35000
Number of env steps total    177000
Number of rollouts total     0
Train Time (s)               43.14977333927527
(Previous) Eval Time (s)     4.275713269133121
Sample Time (s)              18.55834493553266
Epoch Time (s)               65.98383154394105
Total Train Time (s)         2261.5589841613546
Epoch                        34
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:26:01.021782 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #34 | Epoch Duration: 66.50132632255554
2020-01-11 01:26:01.021899 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #34 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030870136
Z variance train             0.0050229
KL Divergence                10.984842
KL Loss                      1.0984843
QF Loss                      219.38127
VF Loss                      249.41397
Policy Loss                  -412.34283
Q Predictions Mean           405.84915
Q Predictions Std            413.85403
Q Predictions Max            1141.8507
Q Predictions Min            -20.765102
V Predictions Mean           422.86386
V Predictions Std            423.10263
V Predictions Max            1154.264
V Predictions Min            -0.4258219
Log Pis Mean                 -0.37957567
Log Pis Std                  2.111978
Log Pis Max                  6.6733804
Log Pis Min                  -3.3484294
Policy mu Mean               0.099910915
Policy mu Std                0.84141403
Policy mu Max                2.929663
Policy mu Min                -2.4748793
Policy log std Mean          -0.38074222
Policy log std Std           0.26308832
Policy log std Max           0.16355252
Policy log std Min           -1.5459076
Z mean eval                  0.012198259
Z variance eval              0.0051793316
total_rewards                [392.3041232  384.07907431 386.47302361 393.0075695  364.24856959
 379.80887679 372.04988173 385.99068832 403.45116972 387.44144704]
total_rewards_mean           384.8854423807226
total_rewards_std            10.454764615176925
total_rewards_max            403.4511697197776
total_rewards_min            364.24856959379775
Number of train steps total  36000
Number of env steps total    182000
Number of rollouts total     0
Train Time (s)               43.04754499020055
(Previous) Eval Time (s)     4.793000048957765
Sample Time (s)              18.740132255479693
Epoch Time (s)               66.58067729463801
Total Train Time (s)         2328.7197174169123
Epoch                        35
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:27:08.183310 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #35 | Epoch Duration: 67.16130948066711
2020-01-11 01:27:08.183474 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #35 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012346586
Z variance train             0.0051762904
KL Divergence                10.803241
KL Loss                      1.080324
QF Loss                      165.53952
VF Loss                      34.1538
Policy Loss                  -394.02686
Q Predictions Mean           390.74033
Q Predictions Std            401.54608
Q Predictions Max            1029.1688
Q Predictions Min            -3.532654
V Predictions Mean           394.60168
V Predictions Std            403.47507
V Predictions Max            1066.5175
V Predictions Min            -2.5381496
Log Pis Mean                 -0.60692286
Log Pis Std                  1.9281405
Log Pis Max                  7.8409615
Log Pis Min                  -3.2386186
Policy mu Mean               -0.03449333
Policy mu Std                0.798049
Policy mu Max                2.0453432
Policy mu Min                -3.5099893
Policy log std Mean          -0.38554403
Policy log std Std           0.28476626
Policy log std Max           0.16889864
Policy log std Min           -1.3963442
Z mean eval                  0.01639281
Z variance eval              0.004279819
total_rewards                [406.14147492 398.85871892 661.56857049 385.900505   401.21110767
 393.37145511 388.5839832  648.90923191 396.92157806 592.8935842 ]
total_rewards_mean           467.4360209488861
total_rewards_std            110.69268761724763
total_rewards_max            661.5685704909907
total_rewards_min            385.90050499701414
Number of train steps total  37000
Number of env steps total    187000
Number of rollouts total     0
Train Time (s)               42.779598681721836
(Previous) Eval Time (s)     5.373376282863319
Sample Time (s)              19.034571080934256
Epoch Time (s)               67.18754604551941
Total Train Time (s)         2395.993558176793
Epoch                        36
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:28:15.457711 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #36 | Epoch Duration: 67.27412033081055
2020-01-11 01:28:15.457832 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #36 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015972635
Z variance train             0.004286496
KL Divergence                11.21114
KL Loss                      1.121114
QF Loss                      484.65024
VF Loss                      32.854687
Policy Loss                  -423.62552
Q Predictions Mean           422.80038
Q Predictions Std            415.11343
Q Predictions Max            1200.1962
Q Predictions Min            -10.667946
V Predictions Mean           423.81946
V Predictions Std            413.9793
V Predictions Max            1229.2208
V Predictions Min            -5.620592
Log Pis Mean                 -0.46886683
Log Pis Std                  2.1875412
Log Pis Max                  10.168211
Log Pis Min                  -4.4370394
Policy mu Mean               0.003082461
Policy mu Std                0.80021036
Policy mu Max                2.188225
Policy mu Min                -3.4546778
Policy log std Mean          -0.34733215
Policy log std Std           0.2587643
Policy log std Max           0.2337728
Policy log std Min           -1.2995305
Z mean eval                  0.017378366
Z variance eval              0.005115079
total_rewards                [390.39863455 497.01759194 440.84419258 276.42217682 406.55399808
 599.75583864 370.3375303  413.9810019  296.00054116 411.52834669]
total_rewards_mean           410.28398526554247
total_rewards_std            87.95236948795386
total_rewards_max            599.7558386367057
total_rewards_min            276.4221768162628
Number of train steps total  38000
Number of env steps total    192000
Number of rollouts total     0
Train Time (s)               44.2015216499567
(Previous) Eval Time (s)     5.459710001945496
Sample Time (s)              19.394491232465953
Epoch Time (s)               69.05572288436815
Total Train Time (s)         2464.886104705278
Epoch                        37
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:29:24.351417 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #37 | Epoch Duration: 68.89349174499512
2020-01-11 01:29:24.351547 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #37 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016844984
Z variance train             0.0051322235
KL Divergence                10.953791
KL Loss                      1.0953791
QF Loss                      268.3354
VF Loss                      53.89119
Policy Loss                  -452.3595
Q Predictions Mean           452.99112
Q Predictions Std            405.2808
Q Predictions Max            1054.7072
Q Predictions Min            -2.5494182
V Predictions Mean           454.537
V Predictions Std            403.69998
V Predictions Max            1060.8036
V Predictions Min            -5.5673018
Log Pis Mean                 -0.35298654
Log Pis Std                  2.1252437
Log Pis Max                  11.451529
Log Pis Min                  -5.1811624
Policy mu Mean               -0.10830144
Policy mu Std                0.8521135
Policy mu Max                2.866182
Policy mu Min                -3.5533736
Policy log std Mean          -0.39444053
Policy log std Std           0.2662602
Policy log std Max           0.17204262
Policy log std Min           -1.3535266
Z mean eval                  0.033077955
Z variance eval              0.005003172
total_rewards                [367.84759865 338.53877988 370.27753895 365.78585932 377.88834083
 386.16449387 368.42018288 382.93723    382.19525987 377.40100642]
total_rewards_mean           371.74562906699083
total_rewards_std            12.956422302250587
total_rewards_max            386.1644938749317
total_rewards_min            338.53877988039
Number of train steps total  39000
Number of env steps total    197000
Number of rollouts total     0
Train Time (s)               44.011110371910036
(Previous) Eval Time (s)     5.2972471178509295
Sample Time (s)              19.284314948599786
Epoch Time (s)               68.59267243836075
Total Train Time (s)         2532.784919743426
Epoch                        38
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:30:32.251018 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #38 | Epoch Duration: 67.8993752002716
2020-01-11 01:30:32.251141 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #38 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03805209
Z variance train             0.0052486556
KL Divergence                10.690157
KL Loss                      1.0690157
QF Loss                      1102.9684
VF Loss                      69.85658
Policy Loss                  -460.67874
Q Predictions Mean           461.10168
Q Predictions Std            409.4876
Q Predictions Max            1210.3645
Q Predictions Min            0.1854645
V Predictions Mean           460.03412
V Predictions Std            408.08444
V Predictions Max            1214.1073
V Predictions Min            -11.740226
Log Pis Mean                 -0.79237294
Log Pis Std                  2.019434
Log Pis Max                  8.735056
Log Pis Min                  -7.1170893
Policy mu Mean               0.0858776
Policy mu Std                0.7888661
Policy mu Max                2.4005833
Policy mu Min                -2.5068622
Policy log std Mean          -0.35733438
Policy log std Std           0.24615744
Policy log std Max           0.22435059
Policy log std Min           -1.39111
Z mean eval                  0.017812507
Z variance eval              0.007672581
total_rewards                [401.11238249 434.23882319 611.63935046 400.66960735 491.71280541
 421.53712219 428.15142347 444.17344445 484.00021004 406.76321331]
total_rewards_mean           452.3998382379897
total_rewards_std            61.01510096773023
total_rewards_max            611.6393504623142
total_rewards_min            400.6696073503055
Number of train steps total  40000
Number of env steps total    202000
Number of rollouts total     0
Train Time (s)               42.33221886213869
(Previous) Eval Time (s)     4.603734041098505
Sample Time (s)              18.788677617441863
Epoch Time (s)               65.72463052067906
Total Train Time (s)         2599.225456314627
Epoch                        39
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:31:38.694951 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #39 | Epoch Duration: 66.44368386268616
2020-01-11 01:31:38.695189 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #39 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02367672
Z variance train             0.008318467
KL Divergence                9.506746
KL Loss                      0.95067465
QF Loss                      246.47699
VF Loss                      42.63679
Policy Loss                  -457.9126
Q Predictions Mean           459.77512
Q Predictions Std            418.22055
Q Predictions Max            1114.6475
Q Predictions Min            -4.3386374
V Predictions Mean           459.56775
V Predictions Std            417.99643
V Predictions Max            1153.6757
V Predictions Min            -6.454384
Log Pis Mean                 -0.6320921
Log Pis Std                  1.8204395
Log Pis Max                  5.6423984
Log Pis Min                  -4.1680336
Policy mu Mean               0.075292595
Policy mu Std                0.761617
Policy mu Max                2.417359
Policy mu Min                -2.1729543
Policy log std Mean          -0.3576784
Policy log std Std           0.24447173
Policy log std Max           0.4409817
Policy log std Min           -1.2264496
Z mean eval                  0.059397817
Z variance eval              0.0070499266
total_rewards                [398.19149179 484.87783941 411.04841987 428.54843167 405.19138922
 438.53376445 597.26722893 559.24041544 567.2654733  543.87729656]
total_rewards_mean           483.40417506480725
total_rewards_std            72.83139484053625
total_rewards_max            597.2672289337651
total_rewards_min            398.19149179234785
Number of train steps total  41000
Number of env steps total    207000
Number of rollouts total     0
Train Time (s)               43.326066293753684
(Previous) Eval Time (s)     5.322561010718346
Sample Time (s)              19.16995286522433
Epoch Time (s)               67.81858016969636
Total Train Time (s)         2667.1646085772663
Epoch                        40
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:32:46.633748 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #40 | Epoch Duration: 67.93838930130005
2020-01-11 01:32:46.633867 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #40 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019012386
Z variance train             0.005090923
KL Divergence                10.797869
KL Loss                      1.0797869
QF Loss                      124.38066
VF Loss                      199.00783
Policy Loss                  -440.0881
Q Predictions Mean           436.43164
Q Predictions Std            410.2325
Q Predictions Max            1191.7325
Q Predictions Min            -9.54427
V Predictions Mean           440.72485
V Predictions Std            410.26755
V Predictions Max            1174.2062
V Predictions Min            -0.29267353
Log Pis Mean                 -0.55720466
Log Pis Std                  2.032797
Log Pis Max                  8.507336
Log Pis Min                  -5.696212
Policy mu Mean               -0.09580483
Policy mu Std                0.8058943
Policy mu Max                2.6492672
Policy mu Min                -2.9756205
Policy log std Mean          -0.3749222
Policy log std Std           0.25677532
Policy log std Max           0.15853213
Policy log std Min           -1.5146273
Z mean eval                  0.053976722
Z variance eval              0.0049466295
total_rewards                [608.76161852 803.4775401  617.77979518 629.33987435 661.0272475
 291.51895106 620.03347267 570.73308153 771.9936988  629.82568126]
total_rewards_mean           620.4490960981659
total_rewards_std            130.03436008958286
total_rewards_max            803.4775401010229
total_rewards_min            291.5189510639785
Number of train steps total  42000
Number of env steps total    212000
Number of rollouts total     0
Train Time (s)               42.73999550007284
(Previous) Eval Time (s)     5.4421834028325975
Sample Time (s)              19.826370656490326
Epoch Time (s)               68.00854955939576
Total Train Time (s)         2737.021925165318
Epoch                        41
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:33:56.495473 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #41 | Epoch Duration: 69.86146211624146
2020-01-11 01:33:56.495759 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #41 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040383846
Z variance train             0.0044293916
KL Divergence                11.1426115
KL Loss                      1.1142612
QF Loss                      204.3457
VF Loss                      114.80572
Policy Loss                  -523.398
Q Predictions Mean           524.3642
Q Predictions Std            428.60092
Q Predictions Max            1614.7313
Q Predictions Min            -2.5425541
V Predictions Mean           522.7245
V Predictions Std            425.77777
V Predictions Max            1588.8257
V Predictions Min            -0.85931575
Log Pis Mean                 -0.52444
Log Pis Std                  1.9281267
Log Pis Max                  5.4422674
Log Pis Min                  -5.2661753
Policy mu Mean               -0.009042136
Policy mu Std                0.81807876
Policy mu Max                2.103408
Policy mu Min                -2.4905992
Policy log std Mean          -0.40534928
Policy log std Std           0.28435406
Policy log std Max           0.43396777
Policy log std Min           -1.352614
Z mean eval                  0.020607987
Z variance eval              0.0041773696
total_rewards                [568.6155951  469.34637677 538.04808062 564.6523212  511.4367804
 571.07486065 475.02212046 581.33446883 488.9499265  529.03708667]
total_rewards_mean           529.7517617192277
total_rewards_std            39.76246081849981
total_rewards_max            581.3344688257558
total_rewards_min            469.3463767695486
Number of train steps total  43000
Number of env steps total    217000
Number of rollouts total     0
Train Time (s)               43.3131401212886
(Previous) Eval Time (s)     7.29486033692956
Sample Time (s)              21.45458520296961
Epoch Time (s)               72.06258566118777
Total Train Time (s)         2807.257337898016
Epoch                        42
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:35:06.729382 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #42 | Epoch Duration: 70.23341345787048
2020-01-11 01:35:06.729503 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #42 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021637678
Z variance train             0.0040289536
KL Divergence                11.432671
KL Loss                      1.143267
QF Loss                      328.2493
VF Loss                      273.24286
Policy Loss                  -431.09616
Q Predictions Mean           429.43695
Q Predictions Std            420.74756
Q Predictions Max            1489.57
Q Predictions Min            -9.146447
V Predictions Mean           432.17892
V Predictions Std            419.8068
V Predictions Max            1483.0651
V Predictions Min            -5.229785
Log Pis Mean                 -0.42828995
Log Pis Std                  2.0277061
Log Pis Max                  7.876428
Log Pis Min                  -4.0703783
Policy mu Mean               0.12484812
Policy mu Std                0.77064246
Policy mu Max                2.7600467
Policy mu Min                -2.982549
Policy log std Mean          -0.37161538
Policy log std Std           0.27021134
Policy log std Max           0.2715634
Policy log std Min           -2.2913845
Z mean eval                  0.02251265
Z variance eval              0.005477868
total_rewards                [533.12915453 495.64047404 369.95636595 562.08528139 573.91953908
 378.79716875 566.50648756 559.52498721 630.53748102 595.54897715]
total_rewards_mean           526.5645916693504
total_rewards_std            83.13597446350968
total_rewards_max            630.5374810247309
total_rewards_min            369.95636595267786
Number of train steps total  44000
Number of env steps total    222000
Number of rollouts total     0
Train Time (s)               42.00827145203948
(Previous) Eval Time (s)     5.465478153899312
Sample Time (s)              19.003048945218325
Epoch Time (s)               66.47679855115712
Total Train Time (s)         2873.6259118942544
Epoch                        43
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:36:13.116440 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #43 | Epoch Duration: 66.38677477836609
2020-01-11 01:36:13.116738 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #43 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05459703
Z variance train             0.0056800293
KL Divergence                10.491962
KL Loss                      1.0491962
QF Loss                      3504.3213
VF Loss                      176.40524
Policy Loss                  -389.8357
Q Predictions Mean           387.48566
Q Predictions Std            402.84146
Q Predictions Max            1442.5134
Q Predictions Min            -3.588326
V Predictions Mean           381.74353
V Predictions Std            399.98965
V Predictions Max            1406.6453
V Predictions Min            -8.437162
Log Pis Mean                 -0.66773754
Log Pis Std                  2.102286
Log Pis Max                  5.6033125
Log Pis Min                  -8.6751375
Policy mu Mean               -0.03824615
Policy mu Std                0.7874558
Policy mu Max                2.2440352
Policy mu Min                -2.611044
Policy log std Mean          -0.3707004
Policy log std Std           0.27354658
Policy log std Max           0.17864418
Policy log std Min           -1.7667783
Z mean eval                  0.014595458
Z variance eval              0.005886437
total_rewards                [366.72288149 611.96081973 635.21328635 490.68794984 636.47661338
 586.76683387 579.39731204 516.43654684 585.99690034 380.70519117]
total_rewards_mean           539.0364335048553
total_rewards_std            93.69316523812634
total_rewards_max            636.4766133815468
total_rewards_min            366.7228814859793
Number of train steps total  45000
Number of env steps total    227000
Number of rollouts total     0
Train Time (s)               42.55413610767573
(Previous) Eval Time (s)     5.375203034374863
Sample Time (s)              19.60548316128552
Epoch Time (s)               67.53482230333611
Total Train Time (s)         2942.243315353524
Epoch                        44
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:37:21.721055 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #44 | Epoch Duration: 68.60411667823792
2020-01-11 01:37:21.721183 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #44 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013239351
Z variance train             0.0065051382
KL Divergence                10.1370325
KL Loss                      1.0137032
QF Loss                      331.4939
VF Loss                      108.037735
Policy Loss                  -468.75095
Q Predictions Mean           466.187
Q Predictions Std            432.64404
Q Predictions Max            1461.9604
Q Predictions Min            -2.4475808
V Predictions Mean           463.76453
V Predictions Std            433.3817
V Predictions Max            1456.8442
V Predictions Min            -26.936867
Log Pis Mean                 -0.23800129
Log Pis Std                  2.2561014
Log Pis Max                  9.924492
Log Pis Min                  -4.807066
Policy mu Mean               -0.025695294
Policy mu Std                0.8848312
Policy mu Max                2.3580494
Policy mu Min                -3.317876
Policy log std Mean          -0.3955257
Policy log std Std           0.2776526
Policy log std Max           0.093100116
Policy log std Min           -1.4028516
Z mean eval                  0.018649487
Z variance eval              0.006101871
total_rewards                [708.54141138 619.52857563 676.10103832 562.35247207 698.62746021
 626.70335938 661.53463027 682.9034354  678.16021263 645.72315724]
total_rewards_mean           656.0175752528419
total_rewards_std            41.58266688272723
total_rewards_max            708.5414113754456
total_rewards_min            562.3524720674613
Number of train steps total  46000
Number of env steps total    232000
Number of rollouts total     0
Train Time (s)               42.95045252377167
(Previous) Eval Time (s)     6.444290086161345
Sample Time (s)              21.03182444907725
Epoch Time (s)               70.42656705901027
Total Train Time (s)         3013.43760076724
Epoch                        45
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:38:32.918202 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #45 | Epoch Duration: 71.19689130783081
2020-01-11 01:38:32.918446 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #45 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020787751
Z variance train             0.0053220503
KL Divergence                10.740941
KL Loss                      1.0740942
QF Loss                      378.8359
VF Loss                      297.0876
Policy Loss                  -536.62573
Q Predictions Mean           533.54736
Q Predictions Std            435.81332
Q Predictions Max            1521.9506
Q Predictions Min            2.69051
V Predictions Mean           523.9287
V Predictions Std            430.53156
V Predictions Max            1504.2935
V Predictions Min            -4.454168
Log Pis Mean                 0.009125821
Log Pis Std                  2.65291
Log Pis Max                  9.9466305
Log Pis Min                  -5.409736
Policy mu Mean               0.005611407
Policy mu Std                0.98612523
Policy mu Max                2.7232482
Policy mu Min                -2.6837544
Policy log std Mean          -0.43062377
Policy log std Std           0.29252923
Policy log std Max           0.19533038
Policy log std Min           -1.6047186
Z mean eval                  0.028137218
Z variance eval              0.005683775
total_rewards                [518.16304025 972.92076345 579.84192284 477.74719991 540.88226656
 598.41500555 741.51916291 715.94719922 721.11223562 590.43487971]
total_rewards_mean           645.6983676019427
total_rewards_std            138.55121118801742
total_rewards_max            972.9207634492054
total_rewards_min            477.74719990943026
Number of train steps total  47000
Number of env steps total    237000
Number of rollouts total     0
Train Time (s)               43.51805628091097
(Previous) Eval Time (s)     7.214353798888624
Sample Time (s)              22.573494638316333
Epoch Time (s)               73.30590471811593
Total Train Time (s)         3085.9369737086818
Epoch                        46
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:39:45.417534 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #46 | Epoch Duration: 72.4989001750946
2020-01-11 01:39:45.417700 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #46 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030195486
Z variance train             0.0055080564
KL Divergence                10.975441
KL Loss                      1.0975441
QF Loss                      472.27707
VF Loss                      210.05711
Policy Loss                  -540.47754
Q Predictions Mean           532.2388
Q Predictions Std            430.24734
Q Predictions Max            1448.601
Q Predictions Min            -4.5036592
V Predictions Mean           537.9259
V Predictions Std            429.56866
V Predictions Max            1460.5466
V Predictions Min            -2.9120421
Log Pis Mean                 0.39252463
Log Pis Std                  2.6196055
Log Pis Max                  14.374642
Log Pis Min                  -5.5558577
Policy mu Mean               0.03934604
Policy mu Std                1.0338678
Policy mu Max                4.038772
Policy mu Min                -2.648893
Policy log std Mean          -0.43260837
Policy log std Std           0.29303268
Policy log std Max           0.07454345
Policy log std Min           -1.7602789
Z mean eval                  0.048730016
Z variance eval              0.01499032
total_rewards                [ 589.92023831 1329.11064975  637.32271838  282.28677966 1045.84427637
  724.34257967  167.40315922  783.22941219  835.9626868   396.73918496]
total_rewards_mean           679.2161685310219
total_rewards_std            332.14924233250485
total_rewards_max            1329.1106497534317
total_rewards_min            167.40315922492894
Number of train steps total  48000
Number of env steps total    242000
Number of rollouts total     0
Train Time (s)               43.31187231000513
(Previous) Eval Time (s)     6.407125893980265
Sample Time (s)              21.19112720992416
Epoch Time (s)               70.91012541390955
Total Train Time (s)         3159.8761789705604
Epoch                        47
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:40:59.358696 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #47 | Epoch Duration: 73.9407958984375
2020-01-11 01:40:59.358957 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #47 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046503954
Z variance train             0.0054527014
KL Divergence                11.10298
KL Loss                      1.110298
QF Loss                      1667.2473
VF Loss                      224.04742
Policy Loss                  -579.88257
Q Predictions Mean           576.7118
Q Predictions Std            453.02692
Q Predictions Max            1639.463
Q Predictions Min            -0.7412671
V Predictions Mean           586.45215
V Predictions Std            457.7468
V Predictions Max            1691.2654
V Predictions Min            -2.2979598
Log Pis Mean                 0.45012757
Log Pis Std                  2.6824975
Log Pis Max                  9.775463
Log Pis Min                  -5.20426
Policy mu Mean               0.0061424277
Policy mu Std                1.0938169
Policy mu Max                2.4855971
Policy mu Min                -3.0720415
Policy log std Mean          -0.44263014
Policy log std Std           0.29530647
Policy log std Max           0.18232168
Policy log std Min           -1.628538
Z mean eval                  0.05358718
Z variance eval              0.0056436933
total_rewards                [372.29314038 757.87938603 253.05631106 285.83472218 541.18715279
 238.5163676  322.13007419 436.15683945 195.79030537 236.80854972]
total_rewards_mean           363.9652848782504
total_rewards_std            164.985254890334
total_rewards_max            757.8793860330584
total_rewards_min            195.79030536767675
Number of train steps total  49000
Number of env steps total    247000
Number of rollouts total     0
Train Time (s)               41.95917961327359
(Previous) Eval Time (s)     9.437538597267121
Sample Time (s)              19.534729093313217
Epoch Time (s)               70.93144730385393
Total Train Time (s)         3227.7565030422993
Epoch                        48
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:42:07.241442 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #48 | Epoch Duration: 67.88230061531067
2020-01-11 01:42:07.241700 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #48 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04643996
Z variance train             0.0045950953
KL Divergence                11.756426
KL Loss                      1.1756426
QF Loss                      323.37314
VF Loss                      152.6953
Policy Loss                  -514.5539
Q Predictions Mean           508.51642
Q Predictions Std            461.54272
Q Predictions Max            1536.82
Q Predictions Min            -41.98949
V Predictions Mean           511.23514
V Predictions Std            461.46884
V Predictions Max            1531.987
V Predictions Min            -36.304214
Log Pis Mean                 0.43927965
Log Pis Std                  2.806144
Log Pis Max                  8.5822
Log Pis Min                  -6.733954
Policy mu Mean               -0.061805326
Policy mu Std                1.1022882
Policy mu Max                3.4245965
Policy mu Min                -2.9959457
Policy log std Mean          -0.45129105
Policy log std Std           0.29126638
Policy log std Max           0.22243416
Policy log std Min           -1.6279147
Z mean eval                  0.07849844
Z variance eval              0.012394288
total_rewards                [ 388.77034821  807.16519005  357.01592322 1264.09507853  911.02171843
  846.02693238  441.52071763  247.00320852  258.79017295  853.04693832]
total_rewards_mean           637.4456228245785
total_rewards_std            325.7330575126279
total_rewards_max            1264.0950785270875
total_rewards_min            247.00320852116124
Number of train steps total  50000
Number of env steps total    252000
Number of rollouts total     0
Train Time (s)               43.11058506788686
(Previous) Eval Time (s)     6.388174913357943
Sample Time (s)              20.36360718915239
Epoch Time (s)               69.86236717039719
Total Train Time (s)         3299.1005552900024
Epoch                        49
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:43:18.587308 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #49 | Epoch Duration: 71.3453357219696
2020-01-11 01:43:18.587582 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #49 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05075838
Z variance train             0.004244192
KL Divergence                11.826372
KL Loss                      1.1826372
QF Loss                      931.6418
VF Loss                      115.38013
Policy Loss                  -601.5735
Q Predictions Mean           596.0143
Q Predictions Std            520.1269
Q Predictions Max            1953.2009
Q Predictions Min            -21.117683
V Predictions Mean           601.6287
V Predictions Std            518.7779
V Predictions Max            1925.9829
V Predictions Min            -13.323604
Log Pis Mean                 0.74751306
Log Pis Std                  2.7845862
Log Pis Max                  8.5265465
Log Pis Min                  -4.2549
Policy mu Mean               -0.021048838
Policy mu Std                1.1002678
Policy mu Max                2.6041718
Policy mu Min                -3.1657014
Policy log std Mean          -0.4971802
Policy log std Std           0.32396236
Policy log std Max           0.013789758
Policy log std Min           -1.8346229
Z mean eval                  0.038054597
Z variance eval              0.0035410668
total_rewards                [682.2528477  709.65191543 355.06755311 548.62688516 235.0179776
 946.20177488 407.42963756 306.52928073 912.33650159 719.25856084]
total_rewards_mean           582.2372934622085
total_rewards_std            237.97430203057095
total_rewards_max            946.2017748847053
total_rewards_min            235.0179776044893
Number of train steps total  51000
Number of env steps total    257000
Number of rollouts total     0
Train Time (s)               42.898838472086936
(Previous) Eval Time (s)     7.870916659943759
Sample Time (s)              21.45716361934319
Epoch Time (s)               72.22691875137389
Total Train Time (s)         3370.8608419341035
Epoch                        50
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:44:30.348649 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #50 | Epoch Duration: 71.76088762283325
2020-01-11 01:44:30.348837 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #50 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04339506
Z variance train             0.0037733174
KL Divergence                11.945941
KL Loss                      1.1945941
QF Loss                      534.8775
VF Loss                      222.94495
Policy Loss                  -620.7114
Q Predictions Mean           611.4603
Q Predictions Std            523.6146
Q Predictions Max            1671.6443
Q Predictions Min            -12.399296
V Predictions Mean           610.2778
V Predictions Std            524.8631
V Predictions Max            1682.7603
V Predictions Min            -15.784318
Log Pis Mean                 0.8059451
Log Pis Std                  2.853865
Log Pis Max                  11.889324
Log Pis Min                  -3.6667476
Policy mu Mean               -0.07212469
Policy mu Std                1.1590445
Policy mu Max                2.7029848
Policy mu Min                -2.6691303
Policy log std Mean          -0.5151953
Policy log std Std           0.33063897
Policy log std Max           -0.018599406
Policy log std Min           -1.7486441
Z mean eval                  0.02505424
Z variance eval              0.0034503029
total_rewards                [780.90415639 766.82501725 921.74049458 650.56295117 904.50437027
 467.94276008 478.54522616 300.12325268 859.28693171 849.5831971 ]
total_rewards_mean           698.001835738366
total_rewards_std            203.70265020786007
total_rewards_max            921.7404945848211
total_rewards_min            300.12325267691295
Number of train steps total  52000
Number of env steps total    262000
Number of rollouts total     0
Train Time (s)               43.12113262200728
(Previous) Eval Time (s)     7.40466867480427
Sample Time (s)              21.0571047347039
Epoch Time (s)               71.58290603151545
Total Train Time (s)         3443.1542624835856
Epoch                        51
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:45:42.645993 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #51 | Epoch Duration: 72.2969651222229
2020-01-11 01:45:42.646290 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #51 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022944447
Z variance train             0.003494827
KL Divergence                12.025032
KL Loss                      1.2025032
QF Loss                      473.5199
VF Loss                      478.4623
Policy Loss                  -626.71515
Q Predictions Mean           631.8894
Q Predictions Std            547.8857
Q Predictions Max            1825.758
Q Predictions Min            -16.165924
V Predictions Mean           639.38086
V Predictions Std            552.4632
V Predictions Max            1829.7633
V Predictions Min            -25.423862
Log Pis Mean                 0.9600304
Log Pis Std                  2.9762418
Log Pis Max                  10.52582
Log Pis Min                  -8.189785
Policy mu Mean               -0.10347295
Policy mu Std                1.1810224
Policy mu Max                3.0531595
Policy mu Min                -2.7982228
Policy log std Mean          -0.500253
Policy log std Std           0.3258806
Policy log std Max           -0.041953117
Policy log std Min           -1.6559443
Z mean eval                  0.059672814
Z variance eval              0.0042878594
total_rewards                [ 556.161196    989.43221671 1119.53253419  771.69600447  899.58733288
  282.45963384  895.87563593 1399.63780084 2627.72974783 2259.24911534]
total_rewards_mean           1180.1361218029135
total_rewards_std            697.8349863389492
total_rewards_max            2627.729747833768
total_rewards_min            282.4596338446548
Number of train steps total  53000
Number of env steps total    267000
Number of rollouts total     0
Train Time (s)               42.30966822290793
(Previous) Eval Time (s)     8.118465370964259
Sample Time (s)              21.469003702048212
Epoch Time (s)               71.8971372959204
Total Train Time (s)         3520.2823855788447
Epoch                        52
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:46:59.774505 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #52 | Epoch Duration: 77.12799382209778
2020-01-11 01:46:59.774762 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #52 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.038049225
Z variance train             0.0034956906
KL Divergence                12.120663
KL Loss                      1.2120663
QF Loss                      1084.8611
VF Loss                      357.55792
Policy Loss                  -696.5724
Q Predictions Mean           689.6021
Q Predictions Std            563.4221
Q Predictions Max            1582.1136
Q Predictions Min            -35.32627
V Predictions Mean           707.10004
V Predictions Std            573.2688
V Predictions Max            1641.4774
V Predictions Min            -10.863659
Log Pis Mean                 0.8037851
Log Pis Std                  2.761189
Log Pis Max                  8.246693
Log Pis Min                  -3.1602516
Policy mu Mean               0.039917063
Policy mu Std                1.1551099
Policy mu Max                3.4008954
Policy mu Min                -2.9557538
Policy log std Mean          -0.5090613
Policy log std Std           0.34083295
Policy log std Max           0.10208993
Policy log std Min           -1.759429
Z mean eval                  0.05022521
Z variance eval              0.0038348634
total_rewards                [ 983.54051538  966.90815305  752.36884114  945.99800389  617.51881446
  922.6778016   335.33209455  878.35561025 1010.56688715  362.20877064]
total_rewards_mean           777.5475492107738
total_rewards_std            242.1762035938049
total_rewards_max            1010.5668871503292
total_rewards_min            335.3320945508373
Number of train steps total  54000
Number of env steps total    272000
Number of rollouts total     0
Train Time (s)               44.13091041194275
(Previous) Eval Time (s)     13.3491000700742
Sample Time (s)              21.113823090214282
Epoch Time (s)               78.59383357223123
Total Train Time (s)         3594.566183161922
Epoch                        53
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:48:14.058384 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #53 | Epoch Duration: 74.28343796730042
2020-01-11 01:48:14.058509 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #53 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1073727
Z variance train             0.0054473435
KL Divergence                10.97546
KL Loss                      1.097546
QF Loss                      942.9342
VF Loss                      249.63406
Policy Loss                  -737.9926
Q Predictions Mean           734.454
Q Predictions Std            577.8454
Q Predictions Max            1958.7648
Q Predictions Min            -15.848877
V Predictions Mean           740.06006
V Predictions Std            579.8093
V Predictions Max            1972.5173
V Predictions Min            -17.828592
Log Pis Mean                 0.9474518
Log Pis Std                  2.8247793
Log Pis Max                  11.078968
Log Pis Min                  -6.2516217
Policy mu Mean               -0.053556547
Policy mu Std                1.1781738
Policy mu Max                3.6150558
Policy mu Min                -2.8686163
Policy log std Mean          -0.531647
Policy log std Std           0.3314536
Policy log std Max           -0.06863128
Policy log std Min           -1.8571247
Z mean eval                  0.05138576
Z variance eval              0.0072341235
total_rewards                [457.98039003 465.27515089 545.37848781 586.88497589 497.19658313
 610.02448693 505.48351852 619.30778171 489.34939717 502.90373051]
total_rewards_mean           527.9784502594762
total_rewards_std            55.90282800119733
total_rewards_max            619.3077817118576
total_rewards_min            457.98039002774937
Number of train steps total  55000
Number of env steps total    277000
Number of rollouts total     0
Train Time (s)               43.65024741087109
(Previous) Eval Time (s)     9.038479373324662
Sample Time (s)              20.908439091406763
Epoch Time (s)               73.59716587560251
Total Train Time (s)         3664.9521233644336
Epoch                        54
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:49:24.446072 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #54 | Epoch Duration: 70.38745450973511
2020-01-11 01:49:24.446233 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #54 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029771924
Z variance train             0.0074648
KL Divergence                10.169283
KL Loss                      1.0169283
QF Loss                      533.63245
VF Loss                      133.06374
Policy Loss                  -705.84875
Q Predictions Mean           701.9542
Q Predictions Std            565.2017
Q Predictions Max            1699.6841
Q Predictions Min            -1.9952725
V Predictions Mean           706.74994
V Predictions Std            567.62354
V Predictions Max            1688.1678
V Predictions Min            -4.873666
Log Pis Mean                 0.7914748
Log Pis Std                  2.7301624
Log Pis Max                  9.637563
Log Pis Min                  -5.3327513
Policy mu Mean               0.12125688
Policy mu Std                1.1234244
Policy mu Max                3.0007617
Policy mu Min                -2.6847358
Policy log std Mean          -0.5255756
Policy log std Std           0.33121845
Policy log std Max           -0.082324445
Policy log std Min           -1.7125871
Z mean eval                  0.05908386
Z variance eval              0.0062494054
total_rewards                [526.85604473 492.72271741 619.88730195 482.83535122 497.5506718
 551.29486414 417.46373209 579.07101984 487.60135151 452.1125774 ]
total_rewards_mean           510.73956320873157
total_rewards_std            56.95346333540861
total_rewards_max            619.887301947679
total_rewards_min            417.4637320930365
Number of train steps total  56000
Number of env steps total    282000
Number of rollouts total     0
Train Time (s)               43.617921927943826
(Previous) Eval Time (s)     5.828533367719501
Sample Time (s)              20.905896010808647
Epoch Time (s)               70.35235130647197
Total Train Time (s)         3736.374050577637
Epoch                        55
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:50:35.869273 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #55 | Epoch Duration: 71.42291641235352
2020-01-11 01:50:35.869402 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #55 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.061803184
Z variance train             0.006157377
KL Divergence                10.801136
KL Loss                      1.0801136
QF Loss                      2695.5876
VF Loss                      335.3566
Policy Loss                  -761.19226
Q Predictions Mean           758.1697
Q Predictions Std            556.57574
Q Predictions Max            1555.98
Q Predictions Min            -0.6567638
V Predictions Mean           751.6614
V Predictions Std            552.64667
V Predictions Max            1519.6807
V Predictions Min            -3.662662
Log Pis Mean                 0.9656853
Log Pis Std                  2.6472342
Log Pis Max                  6.8063574
Log Pis Min                  -4.183958
Policy mu Mean               -0.08189752
Policy mu Std                1.1548547
Policy mu Max                2.9173834
Policy mu Min                -2.8963404
Policy log std Mean          -0.52357584
Policy log std Std           0.32245702
Policy log std Max           0.09270689
Policy log std Min           -1.9530373
Z mean eval                  0.036508787
Z variance eval              0.0050755097
total_rewards                [371.75773149 535.33024064 495.81409166 460.95973404 526.40469879
 373.24335762 508.92431839 436.0845036  554.17628058 406.77532132]
total_rewards_mean           466.9470278113305
total_rewards_std            63.92665998167695
total_rewards_max            554.1762805750345
total_rewards_min            371.75773148519494
Number of train steps total  57000
Number of env steps total    287000
Number of rollouts total     0
Train Time (s)               43.303503966890275
(Previous) Eval Time (s)     6.898853582795709
Sample Time (s)              20.8593937382102
Epoch Time (s)               71.06175128789619
Total Train Time (s)         3806.135979996063
Epoch                        56
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:51:45.635673 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #56 | Epoch Duration: 69.76613235473633
2020-01-11 01:51:45.635935 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #56 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037537005
Z variance train             0.005195045
KL Divergence                10.812719
KL Loss                      1.081272
QF Loss                      490.36517
VF Loss                      125.66441
Policy Loss                  -734.4881
Q Predictions Mean           729.8544
Q Predictions Std            548.6752
Q Predictions Max            1689.4752
Q Predictions Min            -8.379373
V Predictions Mean           734.3789
V Predictions Std            550.9119
V Predictions Max            1683.0858
V Predictions Min            -10.203993
Log Pis Mean                 0.9334167
Log Pis Std                  2.6584873
Log Pis Max                  9.361162
Log Pis Min                  -4.390871
Policy mu Mean               -0.060662974
Policy mu Std                1.1389314
Policy mu Max                3.0721538
Policy mu Min                -2.7340758
Policy log std Mean          -0.51464015
Policy log std Std           0.29890147
Policy log std Max           -0.030813873
Policy log std Min           -1.9402196
Z mean eval                  0.024642643
Z variance eval              0.004667358
total_rewards                [576.99554585 781.37434668 585.80955817 591.79158461 584.68547729
 766.72648116 369.93263952 580.85388411 432.63169147 484.53540158]
total_rewards_mean           575.5336610436764
total_rewards_std            122.63059580364097
total_rewards_max            781.3743466764749
total_rewards_min            369.9326395225681
Number of train steps total  58000
Number of env steps total    292000
Number of rollouts total     0
Train Time (s)               42.29282710608095
(Previous) Eval Time (s)     5.602990481071174
Sample Time (s)              18.356212710030377
Epoch Time (s)               66.2520302971825
Total Train Time (s)         3873.5256508444436
Epoch                        57
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:52:53.028476 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #57 | Epoch Duration: 67.39211988449097
2020-01-11 01:52:53.028658 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #57 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019519864
Z variance train             0.0050361766
KL Divergence                10.964352
KL Loss                      1.0964352
QF Loss                      2080.8867
VF Loss                      912.63086
Policy Loss                  -762.41833
Q Predictions Mean           764.2477
Q Predictions Std            575.3337
Q Predictions Max            1769.5582
Q Predictions Min            -3.4228516
V Predictions Mean           778.4732
V Predictions Std            581.5739
V Predictions Max            1794.786
V Predictions Min            -7.3335505
Log Pis Mean                 0.80075943
Log Pis Std                  2.8469162
Log Pis Max                  10.240716
Log Pis Min                  -4.3184204
Policy mu Mean               -0.13473307
Policy mu Std                1.1439345
Policy mu Max                3.2505593
Policy mu Min                -3.236443
Policy log std Mean          -0.5341778
Policy log std Std           0.33108053
Policy log std Max           -0.04474473
Policy log std Min           -1.8300227
Z mean eval                  0.021763619
Z variance eval              0.0042464943
total_rewards                [865.04726667 662.87718295 569.47031152 633.62949767 573.18266294
 694.15123053 784.38935277 593.97818494 681.17044631 561.6944697 ]
total_rewards_mean           661.9590605999352
total_rewards_std            94.63224674964502
total_rewards_max            865.0472666703323
total_rewards_min            561.694469700325
Number of train steps total  59000
Number of env steps total    297000
Number of rollouts total     0
Train Time (s)               42.66314099216834
(Previous) Eval Time (s)     6.742873886600137
Sample Time (s)              20.796192986425012
Epoch Time (s)               70.20220786519349
Total Train Time (s)         3944.7698512510397
Epoch                        58
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:54:04.272002 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #58 | Epoch Duration: 71.24321722984314
2020-01-11 01:54:04.272198 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #58 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02073061
Z variance train             0.0043066964
KL Divergence                11.477194
KL Loss                      1.1477194
QF Loss                      582.51697
VF Loss                      183.43976
Policy Loss                  -764.91064
Q Predictions Mean           761.1826
Q Predictions Std            553.6855
Q Predictions Max            1613.0693
Q Predictions Min            -20.679028
V Predictions Mean           769.1901
V Predictions Std            557.38446
V Predictions Max            1618.6171
V Predictions Min            -5.8325653
Log Pis Mean                 0.64494765
Log Pis Std                  2.5826313
Log Pis Max                  7.965987
Log Pis Min                  -4.377883
Policy mu Mean               -0.12725483
Policy mu Std                1.111802
Policy mu Max                2.608624
Policy mu Min                -2.9016714
Policy log std Mean          -0.50031453
Policy log std Std           0.28821245
Policy log std Max           -0.0004005283
Policy log std Min           -1.6954347
Z mean eval                  0.018484894
Z variance eval              0.0038876012
total_rewards                [600.49825122 763.87363423 745.95259945 890.44555268 879.91758634
 795.01825654 632.04089238 546.541682   598.70100573 817.26490898]
total_rewards_mean           727.0254369562884
total_rewards_std            117.74425438632102
total_rewards_max            890.4455526825275
total_rewards_min            546.541681999362
Number of train steps total  60000
Number of env steps total    302000
Number of rollouts total     0
Train Time (s)               42.94574713893235
(Previous) Eval Time (s)     7.783647990319878
Sample Time (s)              22.141610883641988
Epoch Time (s)               72.87100601289421
Total Train Time (s)         4017.696454625111
Epoch                        59
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:55:17.200261 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #59 | Epoch Duration: 72.92793536186218
2020-01-11 01:55:17.200393 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #59 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01905189
Z variance train             0.00428977
KL Divergence                11.54219
KL Loss                      1.154219
QF Loss                      415.66235
VF Loss                      210.73003
Policy Loss                  -748.53265
Q Predictions Mean           746.69183
Q Predictions Std            600.1531
Q Predictions Max            2138.4282
Q Predictions Min            -6.836288
V Predictions Mean           743.28296
V Predictions Std            598.92834
V Predictions Max            2157.8215
V Predictions Min            -6.7476416
Log Pis Mean                 0.3764761
Log Pis Std                  2.5450003
Log Pis Max                  10.338648
Log Pis Min                  -3.6059315
Policy mu Mean               -0.057417348
Policy mu Std                1.0792558
Policy mu Max                3.0969195
Policy mu Min                -2.8350642
Policy log std Mean          -0.49003625
Policy log std Std           0.32130125
Policy log std Max           -0.017315716
Policy log std Min           -1.7119262
Z mean eval                  0.016247878
Z variance eval              0.0039484105
total_rewards                [ 908.75090327  694.14077577  548.47281692  345.25158228 1345.48907158
  582.32184837  830.2896604   625.80137924  994.58622565  787.47569893]
total_rewards_mean           766.2579962401745
total_rewards_std            263.80582606027684
total_rewards_max            1345.4890715785039
total_rewards_min            345.251582275417
Number of train steps total  61000
Number of env steps total    307000
Number of rollouts total     0
Train Time (s)               42.505504202097654
(Previous) Eval Time (s)     7.840345115866512
Sample Time (s)              19.659861938096583
Epoch Time (s)               70.00571125606075
Total Train Time (s)         4087.741579366382
Epoch                        60
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:56:27.246506 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #60 | Epoch Duration: 70.04600095748901
2020-01-11 01:56:27.246669 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #60 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018100612
Z variance train             0.0038172256
KL Divergence                11.904249
KL Loss                      1.1904249
QF Loss                      1703.9691
VF Loss                      93.85579
Policy Loss                  -727.2735
Q Predictions Mean           719.4342
Q Predictions Std            584.40155
Q Predictions Max            1774.0101
Q Predictions Min            -25.844542
V Predictions Mean           731.10345
V Predictions Std            588.7181
V Predictions Max            1768.4963
V Predictions Min            -0.8643719
Log Pis Mean                 0.4475351
Log Pis Std                  2.5442214
Log Pis Max                  11.379923
Log Pis Min                  -4.164323
Policy mu Mean               0.057694048
Policy mu Std                1.0549483
Policy mu Max                2.9407835
Policy mu Min                -3.1402512
Policy log std Mean          -0.48117092
Policy log std Std           0.3093967
Policy log std Max           0.1247198
Policy log std Min           -1.9431708
Z mean eval                  0.034434892
Z variance eval              0.003437588
total_rewards                [514.49759574 515.56426718 514.48190938 874.61031573 604.92406532
 529.89674046 527.88293298 650.61643009 694.27699994 913.0462093 ]
total_rewards_mean           633.9797466130643
total_rewards_std            143.2500196444556
total_rewards_max            913.0462092970208
total_rewards_min            514.4819093804055
Number of train steps total  62000
Number of env steps total    312000
Number of rollouts total     0
Train Time (s)               42.20550139807165
(Previous) Eval Time (s)     7.8803599760867655
Sample Time (s)              21.31825708039105
Epoch Time (s)               71.40411845454946
Total Train Time (s)         4158.967036402319
Epoch                        61
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:57:38.473212 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #61 | Epoch Duration: 71.22641634941101
2020-01-11 01:57:38.473347 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #61 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.038147114
Z variance train             0.0038850456
KL Divergence                11.838427
KL Loss                      1.1838427
QF Loss                      659.1121
VF Loss                      149.58804
Policy Loss                  -809.0775
Q Predictions Mean           804.06104
Q Predictions Std            585.60645
Q Predictions Max            1780.0476
Q Predictions Min            -23.775124
V Predictions Mean           809.5604
V Predictions Std            588.0434
V Predictions Max            1753.6278
V Predictions Min            -16.208525
Log Pis Mean                 0.5172066
Log Pis Std                  2.4797826
Log Pis Max                  10.852245
Log Pis Min                  -4.0111017
Policy mu Mean               0.06955278
Policy mu Std                1.052825
Policy mu Max                2.850183
Policy mu Min                -4.250047
Policy log std Mean          -0.5388257
Policy log std Std           0.35281205
Policy log std Max           0.004806429
Policy log std Min           -2.7482336
Z mean eval                  0.017905148
Z variance eval              0.0034236356
total_rewards                [ 985.41305184  774.60732743  660.06315623  537.83034907  561.45300241
  496.60418395  550.58655914  835.58862639 1003.14001314 1002.03071595]
total_rewards_mean           740.7316985548944
total_rewards_std            195.63238467919658
total_rewards_max            1003.1400131358956
total_rewards_min            496.6041839549858
Number of train steps total  63000
Number of env steps total    317000
Number of rollouts total     0
Train Time (s)               43.67540021287277
(Previous) Eval Time (s)     7.702390817925334
Sample Time (s)              20.977102645672858
Epoch Time (s)               72.35489367647097
Total Train Time (s)         4232.8088939087465
Epoch                        62
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:58:52.319772 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #62 | Epoch Duration: 73.84627938270569
2020-01-11 01:58:52.320077 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #62 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018180069
Z variance train             0.0033525382
KL Divergence                12.0316925
KL Loss                      1.2031692
QF Loss                      655.12854
VF Loss                      147.04735
Policy Loss                  -739.1507
Q Predictions Mean           732.64935
Q Predictions Std            592.1326
Q Predictions Max            1846.9679
Q Predictions Min            -5.186481
V Predictions Mean           737.29846
V Predictions Std            591.10535
V Predictions Max            1846.1283
V Predictions Min            -3.1319695
Log Pis Mean                 0.27862713
Log Pis Std                  2.42697
Log Pis Max                  7.674616
Log Pis Min                  -5.0054846
Policy mu Mean               0.049420107
Policy mu Std                1.035983
Policy mu Max                2.9454668
Policy mu Min                -2.7427998
Policy log std Mean          -0.49374613
Policy log std Std           0.2980447
Policy log std Max           -0.035235137
Policy log std Min           -1.5971076
Z mean eval                  0.045041632
Z variance eval              0.0034426902
total_rewards                [591.91671121 755.33255059 665.61560729 634.32991379 566.73723407
 498.9862456  690.49576146 528.17314177 468.46047125 752.02920508]
total_rewards_mean           615.2076842091535
total_rewards_std            96.14523001229357
total_rewards_max            755.3325505888738
total_rewards_min            468.46047124548227
Number of train steps total  64000
Number of env steps total    322000
Number of rollouts total     0
Train Time (s)               42.47525670612231
(Previous) Eval Time (s)     9.193502883892506
Sample Time (s)              19.435272791888565
Epoch Time (s)               71.10403238190338
Total Train Time (s)         4302.677230370697
Epoch                        63
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:00:02.186820 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #63 | Epoch Duration: 69.86653900146484
2020-01-11 02:00:02.186943 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #63 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046181064
Z variance train             0.0036178292
KL Divergence                11.801842
KL Loss                      1.1801842
QF Loss                      1487.7129
VF Loss                      410.88535
Policy Loss                  -772.5404
Q Predictions Mean           770.49664
Q Predictions Std            572.97675
Q Predictions Max            1717.9406
Q Predictions Min            -13.655596
V Predictions Mean           758.52344
V Predictions Std            567.1267
V Predictions Max            1700.3746
V Predictions Min            -24.412294
Log Pis Mean                 0.28344947
Log Pis Std                  2.548174
Log Pis Max                  8.212121
Log Pis Min                  -6.013429
Policy mu Mean               -0.05397172
Policy mu Std                1.0525283
Policy mu Max                2.3427815
Policy mu Min                -2.9864182
Policy log std Mean          -0.5058424
Policy log std Std           0.2919222
Policy log std Max           -0.007041365
Policy log std Min           -1.6737607
Z mean eval                  0.03726891
Z variance eval              0.0040880004
total_rewards                [ 755.00651642  496.61533762  997.64539177 1010.89472259  413.33537851
  928.56292086  847.31295042  698.13162236 1007.83924499  811.85552212]
total_rewards_mean           796.7199607657512
total_rewards_std            199.872635995267
total_rewards_max            1010.894722586859
total_rewards_min            413.33537850723263
Number of train steps total  65000
Number of env steps total    327000
Number of rollouts total     0
Train Time (s)               42.47814815118909
(Previous) Eval Time (s)     7.955793725792319
Sample Time (s)              21.071499709039927
Epoch Time (s)               71.50544158602133
Total Train Time (s)         4375.28485624399
Epoch                        64
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:01:14.799223 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #64 | Epoch Duration: 72.61214113235474
2020-01-11 02:01:14.799500 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #64 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036074124
Z variance train             0.0039513605
KL Divergence                11.63406
KL Loss                      1.163406
QF Loss                      620.7426
VF Loss                      236.50793
Policy Loss                  -763.9023
Q Predictions Mean           762.35516
Q Predictions Std            585.68634
Q Predictions Max            1721.8865
Q Predictions Min            -7.2872276
V Predictions Mean           771.9797
V Predictions Std            584.771
V Predictions Max            1720.2831
V Predictions Min            -1.2464895
Log Pis Mean                 0.39974356
Log Pis Std                  2.4775002
Log Pis Max                  12.588956
Log Pis Min                  -4.735931
Policy mu Mean               0.050606146
Policy mu Std                1.0414358
Policy mu Max                2.5770261
Policy mu Min                -3.566945
Policy log std Mean          -0.5060152
Policy log std Std           0.29376736
Policy log std Max           0.03605956
Policy log std Min           -1.5727826
Z mean eval                  0.03433479
Z variance eval              0.003585225
total_rewards                [1035.78633416  616.6879893  1087.25839067  994.94112443 1020.45425214
 1143.80426927 1060.38272402  761.91011945  777.33023319 1024.24640252]
total_rewards_mean           952.2801839138967
total_rewards_std            162.68902597081166
total_rewards_max            1143.8042692724514
total_rewards_min            616.6879892955299
Number of train steps total  66000
Number of env steps total    332000
Number of rollouts total     0
Train Time (s)               43.17647615727037
(Previous) Eval Time (s)     9.062253612093627
Sample Time (s)              21.845599697437137
Epoch Time (s)               74.08432946680114
Total Train Time (s)         4450.072856804356
Epoch                        65
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:02:29.588159 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #65 | Epoch Duration: 74.78843808174133
2020-01-11 02:02:29.588375 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #65 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035556424
Z variance train             0.0034236107
KL Divergence                12.082439
KL Loss                      1.208244
QF Loss                      219.3298
VF Loss                      128.70634
Policy Loss                  -809.70483
Q Predictions Mean           807.8047
Q Predictions Std            581.57196
Q Predictions Max            1669.6296
Q Predictions Min            -4.2929068
V Predictions Mean           813.72327
V Predictions Std            585.7888
V Predictions Max            1685.5886
V Predictions Min            -8.533533
Log Pis Mean                 0.30562302
Log Pis Std                  2.45898
Log Pis Max                  7.7169204
Log Pis Min                  -5.297927
Policy mu Mean               -0.1552628
Policy mu Std                1.0210284
Policy mu Max                2.2221868
Policy mu Min                -2.916324
Policy log std Mean          -0.49456486
Policy log std Std           0.27850142
Policy log std Max           -0.014842331
Policy log std Min           -1.4856155
Z mean eval                  0.02613478
Z variance eval              0.0075381906
total_rewards                [ 508.49603697  849.24158739 1021.32664061  553.50628329  775.19109665
  717.00025117  648.02908136  722.59949571  737.32425314  800.52130692]
total_rewards_mean           733.3236033210085
total_rewards_std            138.99837014997303
total_rewards_max            1021.32664061463
total_rewards_min            508.49603697431246
Number of train steps total  67000
Number of env steps total    337000
Number of rollouts total     0
Train Time (s)               42.97422110289335
(Previous) Eval Time (s)     9.766155754216015
Sample Time (s)              21.82918842881918
Epoch Time (s)               74.56956528592855
Total Train Time (s)         4523.397885495331
Epoch                        66
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:03:42.916580 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #66 | Epoch Duration: 73.32800459861755
2020-01-11 02:03:42.916861 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #66 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035490423
Z variance train             0.005678212
KL Divergence                10.478741
KL Loss                      1.0478741
QF Loss                      457.57233
VF Loss                      151.03816
Policy Loss                  -730.70905
Q Predictions Mean           725.25806
Q Predictions Std            589.05896
Q Predictions Max            1664.8813
Q Predictions Min            -16.125698
V Predictions Mean           733.8395
V Predictions Std            593.5264
V Predictions Max            1651.889
V Predictions Min            0.6845788
Log Pis Mean                 0.2686395
Log Pis Std                  2.6151223
Log Pis Max                  11.376534
Log Pis Min                  -5.2526155
Policy mu Mean               0.10337857
Policy mu Std                1.02584
Policy mu Max                2.7468796
Policy mu Min                -3.1516361
Policy log std Mean          -0.4622363
Policy log std Std           0.26827583
Policy log std Max           0.094389856
Policy log std Min           -1.4751239
Z mean eval                  0.033058092
Z variance eval              0.0061074803
total_rewards                [ 643.02307381  169.59658385 1414.05801192  547.64252115 1015.41804612
  758.36868112  722.70138938  167.54541661  729.99304179  753.04921565]
total_rewards_mean           692.1395981389343
total_rewards_std            347.5169672972401
total_rewards_max            1414.0580119174135
total_rewards_min            167.54541661013306
Number of train steps total  68000
Number of env steps total    342000
Number of rollouts total     0
Train Time (s)               43.69151949696243
(Previous) Eval Time (s)     8.524343637749553
Sample Time (s)              21.48573051393032
Epoch Time (s)               73.7015936486423
Total Train Time (s)         4596.66237338027
Epoch                        67
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:04:56.183890 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #67 | Epoch Duration: 73.26678729057312
2020-01-11 02:04:56.184206 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #67 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04481524
Z variance train             0.0058871936
KL Divergence                10.503744
KL Loss                      1.0503744
QF Loss                      935.88916
VF Loss                      476.38654
Policy Loss                  -846.9638
Q Predictions Mean           843.7932
Q Predictions Std            593.2821
Q Predictions Max            2049.935
Q Predictions Min            -25.904577
V Predictions Mean           839.02783
V Predictions Std            588.27747
V Predictions Max            2026.2493
V Predictions Min            -21.999542
Log Pis Mean                 0.74249506
Log Pis Std                  2.5940306
Log Pis Max                  8.19388
Log Pis Min                  -5.9330688
Policy mu Mean               0.03959838
Policy mu Std                1.0702157
Policy mu Max                3.131682
Policy mu Min                -3.0454662
Policy log std Mean          -0.5328639
Policy log std Std           0.2852893
Policy log std Max           -0.033441126
Policy log std Min           -1.8585107
Z mean eval                  0.05022358
Z variance eval              0.0046612425
total_rewards                [251.69131973 779.78984143 752.96735846 223.2811189  229.93793384
 760.2468855  229.13816728 203.13660705 722.2897525  214.55503966]
total_rewards_mean           436.7034024350044
total_rewards_std            259.5165339595345
total_rewards_max            779.7898414344683
total_rewards_min            203.1366070480402
Number of train steps total  69000
Number of env steps total    347000
Number of rollouts total     0
Train Time (s)               43.290643360000104
(Previous) Eval Time (s)     8.089297455269843
Sample Time (s)              21.810953448992223
Epoch Time (s)               73.19089426426217
Total Train Time (s)         4667.766016601119
Epoch                        68
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:06:07.286766 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #68 | Epoch Duration: 71.10238814353943
2020-01-11 02:06:07.286896 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #68 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.050307103
Z variance train             0.0048055695
KL Divergence                11.178555
KL Loss                      1.1178554
QF Loss                      764.58875
VF Loss                      227.41061
Policy Loss                  -822.5513
Q Predictions Mean           814.9915
Q Predictions Std            572.6932
Q Predictions Max            1726.5073
Q Predictions Min            -4.155816
V Predictions Mean           823.18176
V Predictions Std            576.4492
V Predictions Max            1773.2762
V Predictions Min            -6.7716265
Log Pis Mean                 0.3025487
Log Pis Std                  2.367978
Log Pis Max                  6.802513
Log Pis Min                  -4.770672
Policy mu Mean               -0.11317757
Policy mu Std                1.0694596
Policy mu Max                2.4688642
Policy mu Min                -2.9194975
Policy log std Mean          -0.47904372
Policy log std Std           0.28807652
Policy log std Max           0.042658374
Policy log std Min           -1.9758279
Z mean eval                  0.045835614
Z variance eval              0.005137013
total_rewards                [ 225.23461982  752.95521547  514.97822773  177.75691874  532.54224439
  438.40654362  796.16994976  247.79814025 1373.59442883  374.37553396]
total_rewards_mean           543.3811822580284
total_rewards_std            340.56599029485017
total_rewards_max            1373.5944288315245
total_rewards_min            177.75691874180893
Number of train steps total  70000
Number of env steps total    352000
Number of rollouts total     0
Train Time (s)               42.25027904799208
(Previous) Eval Time (s)     6.00054964190349
Sample Time (s)              21.227897940203547
Epoch Time (s)               69.47872663009912
Total Train Time (s)         4738.555455287453
Epoch                        69
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:07:18.077183 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #69 | Epoch Duration: 70.79019045829773
2020-01-11 02:07:18.077303 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #69 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.054393373
Z variance train             0.0070172
KL Divergence                10.370867
KL Loss                      1.0370867
QF Loss                      2008.2406
VF Loss                      239.14557
Policy Loss                  -730.76587
Q Predictions Mean           727.8247
Q Predictions Std            589.8292
Q Predictions Max            1760.9282
Q Predictions Min            -23.202818
V Predictions Mean           734.3255
V Predictions Std            592.59174
V Predictions Max            1753.3275
V Predictions Min            -33.45547
Log Pis Mean                 0.51062787
Log Pis Std                  2.556484
Log Pis Max                  8.124647
Log Pis Min                  -4.730655
Policy mu Mean               -0.12805028
Policy mu Std                1.0808301
Policy mu Max                2.3532481
Policy mu Min                -3.1293693
Policy log std Mean          -0.444569
Policy log std Std           0.25678128
Policy log std Max           0.0077074617
Policy log std Min           -1.4185251
Z mean eval                  0.05096811
Z variance eval              0.0048668734
total_rewards                [356.9789236  215.41895583 240.28252814 218.5375553  282.65319914
 179.43600286 234.06859802 482.35681987 233.72423046 567.30966537]
total_rewards_mean           301.0766478588143
total_rewards_std            122.01465021019729
total_rewards_max            567.3096653662737
total_rewards_min            179.43600285608898
Number of train steps total  71000
Number of env steps total    357000
Number of rollouts total     0
Train Time (s)               43.368404247332364
(Previous) Eval Time (s)     7.31178283225745
Sample Time (s)              20.37146154232323
Epoch Time (s)               71.05164862191305
Total Train Time (s)         4806.529799913056
Epoch                        70
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:08:26.053314 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #70 | Epoch Duration: 67.97590255737305
2020-01-11 02:08:26.053497 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #70 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04525111
Z variance train             0.0045042755
KL Divergence                11.567408
KL Loss                      1.1567408
QF Loss                      650.1709
VF Loss                      194.84491
Policy Loss                  -896.3251
Q Predictions Mean           888.73
Q Predictions Std            551.27814
Q Predictions Max            1730.612
Q Predictions Min            -2.9423664
V Predictions Mean           893.5041
V Predictions Std            549.51025
V Predictions Max            1723.4385
V Predictions Min            -5.045106
Log Pis Mean                 0.6362314
Log Pis Std                  2.5853736
Log Pis Max                  9.035135
Log Pis Min                  -6.6629558
Policy mu Mean               -0.049078446
Policy mu Std                1.115629
Policy mu Max                2.946931
Policy mu Min                -3.2651148
Policy log std Mean          -0.4977181
Policy log std Std           0.27532613
Policy log std Max           0.02058208
Policy log std Min           -1.5328159
Z mean eval                  0.08634983
Z variance eval              0.005605404
total_rewards                [ 278.63329464  761.24230125  444.64749547  755.02059909  543.02717946
  746.70253307 1591.39616134  278.02884711  768.21260763  775.78906131]
total_rewards_mean           694.2700080362758
total_rewards_std            354.8337166370593
total_rewards_max            1591.396161341943
total_rewards_min            278.0288471085103
Number of train steps total  72000
Number of env steps total    362000
Number of rollouts total     0
Train Time (s)               42.83847885718569
(Previous) Eval Time (s)     4.235780251212418
Sample Time (s)              16.7384937396273
Epoch Time (s)               63.81275284802541
Total Train Time (s)         4874.321118475404
Epoch                        71
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:09:33.845158 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #71 | Epoch Duration: 67.79153633117676
2020-01-11 02:09:33.845288 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #71 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08407372
Z variance train             0.005872303
KL Divergence                10.721861
KL Loss                      1.0721861
QF Loss                      1047.4606
VF Loss                      225.66519
Policy Loss                  -809.41125
Q Predictions Mean           804.11523
Q Predictions Std            560.2508
Q Predictions Max            1611.2172
Q Predictions Min            1.0774643
V Predictions Mean           807.63293
V Predictions Std            559.86383
V Predictions Max            1628.7921
V Predictions Min            -4.336372
Log Pis Mean                 0.63338923
Log Pis Std                  2.655156
Log Pis Max                  9.691126
Log Pis Min                  -7.3928742
Policy mu Mean               -0.010969336
Policy mu Std                1.114284
Policy mu Max                3.3377783
Policy mu Min                -3.526079
Policy log std Mean          -0.48676848
Policy log std Std           0.2676654
Policy log std Max           -0.036610633
Policy log std Min           -2.2257454
Z mean eval                  0.055488013
Z variance eval              0.0044114213
total_rewards                [ 455.61066469  460.4107968  1255.56135227  390.16236874  991.72079135
  357.45950617  406.83123869  922.22704829  424.77794536  402.00872822]
total_rewards_mean           606.6770440579452
total_rewards_std            306.1043837251223
total_rewards_max            1255.5613522724411
total_rewards_min            357.45950617120184
Number of train steps total  73000
Number of env steps total    367000
Number of rollouts total     0
Train Time (s)               42.355293311178684
(Previous) Eval Time (s)     8.21435323683545
Sample Time (s)              21.253754848614335
Epoch Time (s)               71.82340139662847
Total Train Time (s)         4944.315466796979
Epoch                        72
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:10:43.844366 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #72 | Epoch Duration: 69.99893927574158
2020-01-11 02:10:43.844621 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #72 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07407467
Z variance train             0.0045292787
KL Divergence                11.573577
KL Loss                      1.1573577
QF Loss                      490.62503
VF Loss                      293.47632
Policy Loss                  -842.647
Q Predictions Mean           847.746
Q Predictions Std            576.8312
Q Predictions Max            1706.8049
Q Predictions Min            -11.279031
V Predictions Mean           851.4584
V Predictions Std            578.21576
V Predictions Max            1725.5819
V Predictions Min            -14.598247
Log Pis Mean                 0.59157073
Log Pis Std                  2.3001916
Log Pis Max                  6.659176
Log Pis Min                  -4.4044514
Policy mu Mean               -0.009008765
Policy mu Std                1.0719572
Policy mu Max                2.6019704
Policy mu Min                -2.7483616
Policy log std Mean          -0.48523
Policy log std Std           0.29276305
Policy log std Max           -0.0023904443
Policy log std Min           -1.8556132
Z mean eval                  0.08263227
Z variance eval              0.0072402433
total_rewards                [480.52237081 740.60675915 749.12546845 417.64674862 841.98492807
 726.38957097 459.4028502  378.08398381 335.12006501 436.82116645]
total_rewards_mean           556.5703911552737
total_rewards_std            176.3544687530306
total_rewards_max            841.9849280674939
total_rewards_min            335.12006501044556
Number of train steps total  74000
Number of env steps total    372000
Number of rollouts total     0
Train Time (s)               43.650371155235916
(Previous) Eval Time (s)     6.3896147180348635
Sample Time (s)              20.3044643397443
Epoch Time (s)               70.34445021301508
Total Train Time (s)         5015.194648811128
Epoch                        73
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:11:54.722460 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #73 | Epoch Duration: 70.87764883041382
2020-01-11 02:11:54.722583 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #73 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0846254
Z variance train             0.007106725
KL Divergence                10.709078
KL Loss                      1.0709078
QF Loss                      609.5677
VF Loss                      172.66681
Policy Loss                  -756.12225
Q Predictions Mean           752.6127
Q Predictions Std            578.1698
Q Predictions Max            1601.0547
Q Predictions Min            -8.22958
V Predictions Mean           759.5173
V Predictions Std            579.88416
V Predictions Max            1605.4803
V Predictions Min            -9.477368
Log Pis Mean                 0.5084928
Log Pis Std                  2.4816523
Log Pis Max                  11.405657
Log Pis Min                  -6.17506
Policy mu Mean               0.035986234
Policy mu Std                1.0408431
Policy mu Max                2.7448995
Policy mu Min                -2.8970592
Policy log std Mean          -0.4938394
Policy log std Std           0.29589278
Policy log std Max           0.25380838
Policy log std Min           -1.6427921
Z mean eval                  0.08438338
Z variance eval              0.005395061
total_rewards                [487.24089091 942.41897823 375.56124404 626.41581148 421.4511676
 442.68757821 380.16516821 483.3621268  449.68244806 970.46669888]
total_rewards_mean           557.9452112429635
total_rewards_std            210.17836300798135
total_rewards_max            970.4666988792179
total_rewards_min            375.56124404303625
Number of train steps total  75000
Number of env steps total    377000
Number of rollouts total     0
Train Time (s)               43.53583812061697
(Previous) Eval Time (s)     6.922599188052118
Sample Time (s)              20.08475254382938
Epoch Time (s)               70.54318985249847
Total Train Time (s)         5084.825706852134
Epoch                        74
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:13:04.358334 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #74 | Epoch Duration: 69.63561248779297
2020-01-11 02:13:04.358616 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #74 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06278984
Z variance train             0.0045866603
KL Divergence                11.965604
KL Loss                      1.1965604
QF Loss                      1098.9187
VF Loss                      194.87152
Policy Loss                  -775.99005
Q Predictions Mean           775.9873
Q Predictions Std            554.7147
Q Predictions Max            1603.035
Q Predictions Min            -18.761887
V Predictions Mean           779.61395
V Predictions Std            554.9578
V Predictions Max            1608.181
V Predictions Min            0.6285457
Log Pis Mean                 0.5434497
Log Pis Std                  2.4106581
Log Pis Max                  7.777646
Log Pis Min                  -4.9410195
Policy mu Mean               0.04875509
Policy mu Std                1.0570471
Policy mu Max                2.6378095
Policy mu Min                -2.8264177
Policy log std Mean          -0.5325782
Policy log std Std           0.294168
Policy log std Max           0.022592768
Policy log std Min           -1.6574612
Z mean eval                  0.08489192
Z variance eval              0.0060559628
total_rewards                [729.74951296 651.69576489 652.06902958 692.60945081 644.92261403
 683.83264767 707.50335929 542.73656272 684.84704149 698.59105144]
total_rewards_mean           668.8557034881671
total_rewards_std            49.178498210151226
total_rewards_max            729.7495129604099
total_rewards_min            542.7365627186465
Number of train steps total  76000
Number of env steps total    382000
Number of rollouts total     0
Train Time (s)               43.0243885810487
(Previous) Eval Time (s)     6.014767195098102
Sample Time (s)              19.79067398654297
Epoch Time (s)               68.82982976268977
Total Train Time (s)         5154.6542423856445
Epoch                        75
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:14:14.186064 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #75 | Epoch Duration: 69.82725071907043
2020-01-11 02:14:14.186181 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #75 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.053846754
Z variance train             0.005646436
KL Divergence                11.462474
KL Loss                      1.1462474
QF Loss                      997.852
VF Loss                      229.1254
Policy Loss                  -844.9715
Q Predictions Mean           843.285
Q Predictions Std            562.9115
Q Predictions Max            1630.0598
Q Predictions Min            -39.900234
V Predictions Mean           844.11896
V Predictions Std            563.36096
V Predictions Max            1649.29
V Predictions Min            -11.898061
Log Pis Mean                 0.5650058
Log Pis Std                  2.3191476
Log Pis Max                  5.888899
Log Pis Min                  -4.920047
Policy mu Mean               -0.11363808
Policy mu Std                1.0681258
Policy mu Max                2.8688672
Policy mu Min                -2.8976493
Policy log std Mean          -0.50784874
Policy log std Std           0.2857099
Policy log std Max           -0.02621381
Policy log std Min           -1.6046429
Z mean eval                  0.07692835
Z variance eval              0.009540955
total_rewards                [484.43842427 556.10492526 680.3158748  869.73273998 549.64730079
 682.67496259 605.89787811 646.96422075 655.86981806 596.10195709]
total_rewards_mean           632.7748101697073
total_rewards_std            99.24382216618855
total_rewards_max            869.7327399824322
total_rewards_min            484.43842426891854
Number of train steps total  77000
Number of env steps total    387000
Number of rollouts total     0
Train Time (s)               42.50318763311952
(Previous) Eval Time (s)     7.011967457830906
Sample Time (s)              20.629213200882077
Epoch Time (s)               70.1443682918325
Total Train Time (s)         5224.851287466474
Epoch                        76
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:15:24.385319 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #76 | Epoch Duration: 70.19902753829956
2020-01-11 02:15:24.385486 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #76 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07563272
Z variance train             0.009794169
KL Divergence                9.910524
KL Loss                      0.99105245
QF Loss                      2616.5806
VF Loss                      349.56714
Policy Loss                  -829.1537
Q Predictions Mean           830.4741
Q Predictions Std            595.9046
Q Predictions Max            1651.6664
Q Predictions Min            -16.463902
V Predictions Mean           831.13965
V Predictions Std            592.5522
V Predictions Max            1674.5314
V Predictions Min            -4.4846745
Log Pis Mean                 0.72522986
Log Pis Std                  2.6716993
Log Pis Max                  10.763218
Log Pis Min                  -3.3447537
Policy mu Mean               -0.05322659
Policy mu Std                1.0881693
Policy mu Max                2.590788
Policy mu Min                -4.5089846
Policy log std Mean          -0.52679825
Policy log std Std           0.3107898
Policy log std Max           -0.056252643
Policy log std Min           -2.0388227
Z mean eval                  0.073381245
Z variance eval              0.007808771
total_rewards                [428.92827378 476.52034635 494.85973197 623.38157752 433.76076558
 511.54464611 514.87196689 487.83928972 446.2154572  450.82981244]
total_rewards_mean           486.8751867574523
total_rewards_std            54.15696713810765
total_rewards_max            623.3815775196132
total_rewards_min            428.92827377575765
Number of train steps total  78000
Number of env steps total    392000
Number of rollouts total     0
Train Time (s)               43.033230334986
(Previous) Eval Time (s)     7.0663834903389215
Sample Time (s)              20.793897383846343
Epoch Time (s)               70.89351120917127
Total Train Time (s)         5294.601009004284
Epoch                        77
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:16:34.135478 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #77 | Epoch Duration: 69.74986219406128
2020-01-11 02:16:34.135613 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #77 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07606255
Z variance train             0.0075072413
KL Divergence                10.545633
KL Loss                      1.0545634
QF Loss                      664.80334
VF Loss                      371.45224
Policy Loss                  -815.7317
Q Predictions Mean           813.54126
Q Predictions Std            554.3286
Q Predictions Max            1632.6688
Q Predictions Min            -19.284866
V Predictions Mean           809.02136
V Predictions Std            550.2796
V Predictions Max            1643.6127
V Predictions Min            -4.2435017
Log Pis Mean                 0.6567848
Log Pis Std                  2.6621253
Log Pis Max                  7.770439
Log Pis Min                  -4.8294806
Policy mu Mean               -0.086052746
Policy mu Std                1.12746
Policy mu Max                2.654088
Policy mu Min                -3.0579388
Policy log std Mean          -0.5083656
Policy log std Std           0.29496685
Policy log std Max           0.04588303
Policy log std Min           -1.6126269
Z mean eval                  0.0760277
Z variance eval              0.006925969
total_rewards                [ 606.53449102  581.34473181  678.06063432  675.69319045  523.86415212
  684.66051204  617.15164094  713.59118689  595.78764464 1515.30463435]
total_rewards_mean           719.199281858316
total_rewards_std            270.9410408415735
total_rewards_max            1515.3046343538856
total_rewards_min            523.8641521225902
Number of train steps total  79000
Number of env steps total    397000
Number of rollouts total     0
Train Time (s)               42.844530885107815
(Previous) Eval Time (s)     5.922511498909444
Sample Time (s)              20.29340013489127
Epoch Time (s)               69.06044251890853
Total Train Time (s)         5365.7289548390545
Epoch                        78
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:17:45.265160 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #78 | Epoch Duration: 71.12945079803467
2020-01-11 02:17:45.265282 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #78 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07147203
Z variance train             0.0076006046
KL Divergence                10.382203
KL Loss                      1.0382203
QF Loss                      547.9626
VF Loss                      383.49725
Policy Loss                  -814.4439
Q Predictions Mean           813.51294
Q Predictions Std            574.0333
Q Predictions Max            1607.2373
Q Predictions Min            -8.410392
V Predictions Mean           816.49286
V Predictions Std            572.90686
V Predictions Max            1621.3291
V Predictions Min            -2.7496397
Log Pis Mean                 0.44358653
Log Pis Std                  2.6254888
Log Pis Max                  12.407385
Log Pis Min                  -5.910893
Policy mu Mean               0.066359185
Policy mu Std                1.0761173
Policy mu Max                3.1076517
Policy mu Min                -3.2084856
Policy log std Mean          -0.49854276
Policy log std Std           0.293751
Policy log std Max           0.07317169
Policy log std Min           -1.9476023
Z mean eval                  0.074356906
Z variance eval              0.007159345
total_rewards                [1356.73531134  430.56222885  485.1384349   933.56136805  886.37397789
  537.38802397 1022.93066087 1286.35829217  520.96320885 1021.54519345]
total_rewards_mean           848.1556700330481
total_rewards_std            320.91073802161793
total_rewards_max            1356.7353113394229
total_rewards_min            430.562228850969
Number of train steps total  80000
Number of env steps total    402000
Number of rollouts total     0
Train Time (s)               43.97589063504711
(Previous) Eval Time (s)     7.991287922952324
Sample Time (s)              22.155781255103648
Epoch Time (s)               74.12295981310308
Total Train Time (s)         5441.496637022123
Epoch                        79
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:19:01.034041 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #79 | Epoch Duration: 75.76866841316223
2020-01-11 02:19:01.034162 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #79 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07817339
Z variance train             0.0067781084
KL Divergence                10.749602
KL Loss                      1.0749602
QF Loss                      626.3981
VF Loss                      146.08911
Policy Loss                  -840.4053
Q Predictions Mean           837.1284
Q Predictions Std            565.4569
Q Predictions Max            1555.8015
Q Predictions Min            -1.9230813
V Predictions Mean           843.0023
V Predictions Std            566.82104
V Predictions Max            1565.6683
V Predictions Min            -2.3693972
Log Pis Mean                 0.53622675
Log Pis Std                  2.4491873
Log Pis Max                  7.424506
Log Pis Min                  -5.0975895
Policy mu Mean               0.030490397
Policy mu Std                1.0612136
Policy mu Max                2.745991
Policy mu Min                -2.9570546
Policy log std Mean          -0.49461564
Policy log std Std           0.30939105
Policy log std Max           0.08473052
Policy log std Min           -1.576283
Z mean eval                  0.0837432
Z variance eval              0.0058615864
total_rewards                [ 250.97274858 1257.83136892  233.43757688 1054.32975107  266.47038604
 1239.08382465  269.48338114  691.91886778  780.94081192  280.12269528]
total_rewards_mean           632.4591412269914
total_rewards_std            407.09104950101124
total_rewards_max            1257.831368920893
total_rewards_min            233.43757688340796
Number of train steps total  81000
Number of env steps total    407000
Number of rollouts total     0
Train Time (s)               42.90504058776423
(Previous) Eval Time (s)     9.636733668856323
Sample Time (s)              21.172030246816576
Epoch Time (s)               73.71380450343713
Total Train Time (s)         5513.665483477991
Epoch                        80
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:20:13.204139 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #80 | Epoch Duration: 72.1698842048645
2020-01-11 02:20:13.204261 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #80 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07985669
Z variance train             0.0062019536
KL Divergence                10.836882
KL Loss                      1.0836881
QF Loss                      11365.802
VF Loss                      864.3569
Policy Loss                  -858.0305
Q Predictions Mean           855.75494
Q Predictions Std            526.0996
Q Predictions Max            1549.4441
Q Predictions Min            1.3213404
V Predictions Mean           843.9171
V Predictions Std            522.16156
V Predictions Max            1517.7734
V Predictions Min            -5.258662
Log Pis Mean                 0.77443355
Log Pis Std                  2.6788845
Log Pis Max                  11.10007
Log Pis Min                  -3.9730306
Policy mu Mean               -0.224533
Policy mu Std                1.1369845
Policy mu Max                3.0890298
Policy mu Min                -2.8234081
Policy log std Mean          -0.5217313
Policy log std Std           0.2973334
Policy log std Max           0.072316006
Policy log std Min           -1.5670407
Z mean eval                  0.08378989
Z variance eval              0.00796061
total_rewards                [ 283.60985467 2805.25076766  924.26422192 1020.69451407 2422.26583141
 2120.45969436 1169.51637463  250.25583715 1962.76006306  994.73843979]
total_rewards_mean           1395.3815598718063
total_rewards_std            837.3231349055093
total_rewards_max            2805.250767655251
total_rewards_min            250.2558371500403
Number of train steps total  82000
Number of env steps total    412000
Number of rollouts total     0
Train Time (s)               43.31800524238497
(Previous) Eval Time (s)     8.092570988927037
Sample Time (s)              21.210607977584004
Epoch Time (s)               72.62118420889601
Total Train Time (s)         5594.078764966689
Epoch                        81
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:21:33.618765 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #81 | Epoch Duration: 80.4144115447998
2020-01-11 02:21:33.618889 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #81 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07525996
Z variance train             0.008183789
KL Divergence                10.224905
KL Loss                      1.0224905
QF Loss                      350.12103
VF Loss                      345.94666
Policy Loss                  -808.92114
Q Predictions Mean           809.2915
Q Predictions Std            579.1672
Q Predictions Max            1557.9044
Q Predictions Min            -14.521993
V Predictions Mean           815.25464
V Predictions Std            581.87067
V Predictions Max            1576.8175
V Predictions Min            -6.208104
Log Pis Mean                 0.51774013
Log Pis Std                  2.5808108
Log Pis Max                  8.721955
Log Pis Min                  -7.19164
Policy mu Mean               -0.08404083
Policy mu Std                1.0872178
Policy mu Max                2.8075824
Policy mu Min                -2.8427968
Policy log std Mean          -0.476149
Policy log std Std           0.2780497
Policy log std Max           0.111491695
Policy log std Min           -1.6889052
Z mean eval                  0.08372369
Z variance eval              0.008075475
total_rewards                [ 477.0073698  1305.48445356  468.6298253   518.46931239 1040.09707016
  481.16558555  549.68211123  515.99823194  530.83076935 1002.96431732]
total_rewards_mean           689.0329046593436
total_rewards_std            290.1779033094436
total_rewards_max            1305.4844535562265
total_rewards_min            468.6298253047087
Number of train steps total  83000
Number of env steps total    417000
Number of rollouts total     0
Train Time (s)               42.33343238616362
(Previous) Eval Time (s)     15.885562606155872
Sample Time (s)              22.65370687795803
Epoch Time (s)               80.87270187027752
Total Train Time (s)         5666.818074112292
Epoch                        82
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:22:46.358761 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #82 | Epoch Duration: 72.73977994918823
2020-01-11 02:22:46.358882 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #82 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07318398
Z variance train             0.008220604
KL Divergence                10.279331
KL Loss                      1.0279331
QF Loss                      654.3877
VF Loss                      200.36026
Policy Loss                  -782.6583
Q Predictions Mean           781.10547
Q Predictions Std            528.5906
Q Predictions Max            1476.8866
Q Predictions Min            -28.89534
V Predictions Mean           791.8435
V Predictions Std            533.7263
V Predictions Max            1485.9613
V Predictions Min            -0.5982418
Log Pis Mean                 0.7717764
Log Pis Std                  2.689688
Log Pis Max                  8.651131
Log Pis Min                  -3.5977492
Policy mu Mean               -0.2746691
Policy mu Std                1.1242269
Policy mu Max                2.3969278
Policy mu Min                -2.8954165
Policy log std Mean          -0.4927903
Policy log std Std           0.2695047
Policy log std Max           0.008413434
Policy log std Min           -1.5587656
Z mean eval                  0.07659356
Z variance eval              0.005724256
total_rewards                [ 142.05065773  950.38783461  151.22256688 1259.73046374 1317.41182178
  822.3269179  1784.19956208  352.64117145 1024.78847545 1261.56455017]
total_rewards_mean           906.6324021783819
total_rewards_std            517.168954945054
total_rewards_max            1784.1995620759828
total_rewards_min            142.0506577348771
Number of train steps total  84000
Number of env steps total    422000
Number of rollouts total     0
Train Time (s)               43.663142974022776
(Previous) Eval Time (s)     7.752394264098257
Sample Time (s)              21.747527410276234
Epoch Time (s)               73.16306464839727
Total Train Time (s)         5743.1964015243575
Epoch                        83
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:24:02.739661 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #83 | Epoch Duration: 76.38067436218262
2020-01-11 02:24:02.739825 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #83 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07809679
Z variance train             0.005719972
KL Divergence                11.01514
KL Loss                      1.101514
QF Loss                      518.52527
VF Loss                      347.4206
Policy Loss                  -840.63855
Q Predictions Mean           840.2038
Q Predictions Std            541.5423
Q Predictions Max            1456.065
Q Predictions Min            -1.9527448
V Predictions Mean           841.29297
V Predictions Std            539.0012
V Predictions Max            1448.1644
V Predictions Min            -9.20247
Log Pis Mean                 0.7234391
Log Pis Std                  2.605067
Log Pis Max                  9.488352
Log Pis Min                  -4.1263876
Policy mu Mean               -0.055207044
Policy mu Std                1.1384603
Policy mu Max                3.319524
Policy mu Min                -2.9492555
Policy log std Mean          -0.5159394
Policy log std Std           0.28425446
Policy log std Max           0.032348856
Policy log std Min           -1.6016064
Z mean eval                  0.092274286
Z variance eval              0.005653356
total_rewards                [1969.96885756 2867.68290182  503.65350953  510.97256796 2878.53540588
  555.34601639 1973.03543276 1058.61447505  476.77402101 1830.51639893]
total_rewards_mean           1462.5099586896747
total_rewards_std            917.376750074721
total_rewards_max            2878.5354058836574
total_rewards_min            476.77402101143406
Number of train steps total  85000
Number of env steps total    427000
Number of rollouts total     0
Train Time (s)               42.81512011727318
(Previous) Eval Time (s)     10.969756862148643
Sample Time (s)              19.661148062441498
Epoch Time (s)               73.44602504186332
Total Train Time (s)         5822.600552891381
Epoch                        84
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:25:22.143773 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #84 | Epoch Duration: 79.40383243560791
2020-01-11 02:25:22.143894 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #84 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.062197227
Z variance train             0.0038262282
KL Divergence                12.140266
KL Loss                      1.2140267
QF Loss                      441.34598
VF Loss                      148.35675
Policy Loss                  -841.2907
Q Predictions Mean           844.2277
Q Predictions Std            553.6646
Q Predictions Max            1522.0138
Q Predictions Min            -8.790832
V Predictions Mean           841.8467
V Predictions Std            553.3219
V Predictions Max            1527.8741
V Predictions Min            -11.324792
Log Pis Mean                 0.20025146
Log Pis Std                  2.251185
Log Pis Max                  8.492228
Log Pis Min                  -4.82797
Policy mu Mean               0.09620875
Policy mu Std                1.0123913
Policy mu Max                2.7854638
Policy mu Min                -2.7796574
Policy log std Mean          -0.48373178
Policy log std Std           0.28701243
Policy log std Max           0.034992084
Policy log std Min           -1.7570443
Z mean eval                  0.07785778
Z variance eval              0.010274838
total_rewards                [2685.46722044 1198.93461809  266.50564496  239.75029164 2450.81112007
  123.87149424 2378.4848385  1876.36865313  265.9550492  1891.98752957]
total_rewards_mean           1337.813645984526
total_rewards_std            986.4252633054261
total_rewards_max            2685.4672204405483
total_rewards_min            123.87149424232291
Number of train steps total  86000
Number of env steps total    432000
Number of rollouts total     0
Train Time (s)               44.58469966799021
(Previous) Eval Time (s)     16.927363275084645
Sample Time (s)              21.984452822245657
Epoch Time (s)               83.49651576532051
Total Train Time (s)         5904.997156983707
Epoch                        85
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:26:44.541466 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #85 | Epoch Duration: 82.39747953414917
2020-01-11 02:26:44.541584 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #85 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07438922
Z variance train             0.0055534495
KL Divergence                10.959752
KL Loss                      1.0959753
QF Loss                      1054.689
VF Loss                      271.85507
Policy Loss                  -882.25916
Q Predictions Mean           877.9635
Q Predictions Std            541.0446
Q Predictions Max            1525.5708
Q Predictions Min            -1.7255328
V Predictions Mean           874.8954
V Predictions Std            537.68445
V Predictions Max            1525.3914
V Predictions Min            -4.3169284
Log Pis Mean                 0.81999445
Log Pis Std                  2.825709
Log Pis Max                  9.438143
Log Pis Min                  -6.1329393
Policy mu Mean               -0.039255995
Policy mu Std                1.1637353
Policy mu Max                3.4775949
Policy mu Min                -3.2353568
Policy log std Mean          -0.5157484
Policy log std Std           0.2978254
Policy log std Max           0.054232538
Policy log std Min           -1.9794741
Z mean eval                  0.08407952
Z variance eval              0.00816845
total_rewards                [1486.03765988  787.48295044  980.44665661 1536.32200819  887.40119833
  721.2982808   805.85117175  791.91652101  746.8898113  1162.97296596]
total_rewards_mean           990.6619224255685
total_rewards_std            288.1871495010528
total_rewards_max            1536.3220081902634
total_rewards_min            721.2982807979229
Number of train steps total  87000
Number of env steps total    437000
Number of rollouts total     0
Train Time (s)               43.2687008199282
(Previous) Eval Time (s)     15.82807026989758
Sample Time (s)              20.4674113499932
Epoch Time (s)               79.56418243981898
Total Train Time (s)         5980.139142142609
Epoch                        86
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:27:59.684535 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #86 | Epoch Duration: 75.1428611278534
2020-01-11 02:27:59.684652 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #86 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.087859355
Z variance train             0.0041573234
KL Divergence                11.718875
KL Loss                      1.1718875
QF Loss                      364.71655
VF Loss                      160.38332
Policy Loss                  -776.6301
Q Predictions Mean           773.1538
Q Predictions Std            569.36005
Q Predictions Max            1511.3969
Q Predictions Min            -11.555071
V Predictions Mean           772.30884
V Predictions Std            568.2462
V Predictions Max            1504.1613
V Predictions Min            -18.076939
Log Pis Mean                 0.34040943
Log Pis Std                  2.265842
Log Pis Max                  6.37956
Log Pis Min                  -4.150757
Policy mu Mean               0.010215071
Policy mu Std                1.0412629
Policy mu Max                2.4458742
Policy mu Min                -2.7960944
Policy log std Mean          -0.4758711
Policy log std Std           0.295266
Policy log std Max           0.06670034
Policy log std Min           -2.0929608
Z mean eval                  0.06869157
Z variance eval              0.00843562
total_rewards                [1001.75315808 1015.48893086 1270.43544916  995.48901708 1349.44707114
 1283.6369411   983.42194293 1302.69111859  958.36614148 1023.58609334]
total_rewards_mean           1118.4315863764364
total_rewards_std            151.62053036057551
total_rewards_max            1349.4470711447204
total_rewards_min            958.3661414778012
Number of train steps total  88000
Number of env steps total    442000
Number of rollouts total     0
Train Time (s)               43.087815278209746
(Previous) Eval Time (s)     11.406497469171882
Sample Time (s)              21.728008545469493
Epoch Time (s)               76.22232129285112
Total Train Time (s)         6056.959188366309
Epoch                        87
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:29:16.506213 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #87 | Epoch Duration: 76.82146954536438
2020-01-11 02:29:16.506337 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #87 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06590458
Z variance train             0.008070664
KL Divergence                9.851803
KL Loss                      0.9851803
QF Loss                      646.51154
VF Loss                      585.35785
Policy Loss                  -852.40955
Q Predictions Mean           853.573
Q Predictions Std            519.30597
Q Predictions Max            1533.2286
Q Predictions Min            -26.457695
V Predictions Mean           855.6698
V Predictions Std            514.42694
V Predictions Max            1517.4089
V Predictions Min            -14.264961
Log Pis Mean                 0.69176245
Log Pis Std                  2.3372116
Log Pis Max                  10.374495
Log Pis Min                  -3.5182314
Policy mu Mean               -0.023204148
Policy mu Std                1.111132
Policy mu Max                2.9199338
Policy mu Min                -2.7486396
Policy log std Mean          -0.53687674
Policy log std Std           0.2727788
Policy log std Max           0.10541612
Policy log std Min           -1.5749769
Z mean eval                  0.072379924
Z variance eval              0.009294963
total_rewards                [1079.28531163 1144.87708544 2827.76644585 2169.34255002  755.01137812
 2094.97692177 1468.95570049 1208.51746369 1938.36759771 2417.98712029]
total_rewards_mean           1710.5087575022585
total_rewards_std            640.3713651488204
total_rewards_max            2827.766445852415
total_rewards_min            755.0113781227569
Number of train steps total  89000
Number of env steps total    447000
Number of rollouts total     0
Train Time (s)               42.95138508500531
(Previous) Eval Time (s)     12.005396197084337
Sample Time (s)              21.856923357583582
Epoch Time (s)               76.81370463967323
Total Train Time (s)         6140.474621474743
Epoch                        88
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:30:40.022529 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #88 | Epoch Duration: 83.51609992980957
2020-01-11 02:30:40.022652 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #88 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06373656
Z variance train             0.004338079
KL Divergence                11.524941
KL Loss                      1.1524942
QF Loss                      366.68817
VF Loss                      213.39696
Policy Loss                  -829.25885
Q Predictions Mean           825.905
Q Predictions Std            522.45776
Q Predictions Max            1446.3395
Q Predictions Min            -3.9249318
V Predictions Mean           820.7489
V Predictions Std            520.9961
V Predictions Max            1416.5466
V Predictions Min            -9.30418
Log Pis Mean                 0.45479393
Log Pis Std                  2.3707964
Log Pis Max                  8.099173
Log Pis Min                  -4.866109
Policy mu Mean               0.046361517
Policy mu Std                1.0724872
Policy mu Max                2.2992647
Policy mu Min                -2.7174962
Policy log std Mean          -0.5181261
Policy log std Std           0.29222086
Policy log std Max           0.07296398
Policy log std Min           -1.7790072
Z mean eval                  0.075433895
Z variance eval              0.011685731
total_rewards                [ 981.00569161 2587.33503206  642.43212643  708.14738734  754.78071664
 1397.25431469 1615.33067915 1572.66485297 1045.32975628 1827.37710485]
total_rewards_mean           1313.1657662025452
total_rewards_std            579.950521572308
total_rewards_max            2587.335032063769
total_rewards_min            642.432126429521
Number of train steps total  90000
Number of env steps total    452000
Number of rollouts total     0
Train Time (s)               43.94762178417295
(Previous) Eval Time (s)     18.70754547417164
Sample Time (s)              21.99292061617598
Epoch Time (s)               84.64808787452057
Total Train Time (s)         6222.968714368064
Epoch                        89
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:32:02.517611 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #89 | Epoch Duration: 82.49486422538757
2020-01-11 02:32:02.517729 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #89 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06645646
Z variance train             0.006121476
KL Divergence                10.83195
KL Loss                      1.0831951
QF Loss                      396.2378
VF Loss                      221.57167
Policy Loss                  -815.05115
Q Predictions Mean           813.0161
Q Predictions Std            519.8985
Q Predictions Max            1456.5355
Q Predictions Min            -9.63224
V Predictions Mean           816.5067
V Predictions Std            521.4056
V Predictions Max            1458.0303
V Predictions Min            -3.168536
Log Pis Mean                 0.5287403
Log Pis Std                  2.6982005
Log Pis Max                  12.597477
Log Pis Min                  -3.294107
Policy mu Mean               0.066447794
Policy mu Std                1.0591587
Policy mu Max                3.1456783
Policy mu Min                -3.6079166
Policy log std Mean          -0.49375677
Policy log std Std           0.27887952
Policy log std Max           0.02151519
Policy log std Min           -1.5746279
Z mean eval                  0.0915977
Z variance eval              0.0066994405
total_rewards                [888.09078783 711.81475735 834.34240553 619.33156135 612.134479
 866.99545793 906.03351132 596.50277788 930.10175026 945.02938682]
total_rewards_mean           791.0376875277365
total_rewards_std            133.77217116177036
total_rewards_max            945.0293868166809
total_rewards_min            596.5027778779734
Number of train steps total  91000
Number of env steps total    457000
Number of rollouts total     0
Train Time (s)               44.50845571793616
(Previous) Eval Time (s)     16.55406475486234
Sample Time (s)              22.038515110965818
Epoch Time (s)               83.10103558376431
Total Train Time (s)         6299.060809421353
Epoch                        90
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:33:18.611785 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #90 | Epoch Duration: 76.0939531326294
2020-01-11 02:33:18.611942 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #90 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09064506
Z variance train             0.009178711
KL Divergence                9.602316
KL Loss                      0.9602316
QF Loss                      346.9369
VF Loss                      361.00006
Policy Loss                  -863.7692
Q Predictions Mean           865.7937
Q Predictions Std            534.6764
Q Predictions Max            1454.953
Q Predictions Min            -1.5336509
V Predictions Mean           878.17487
V Predictions Std            539.3446
V Predictions Max            1470.9073
V Predictions Min            -6.712747
Log Pis Mean                 0.5681665
Log Pis Std                  2.6248677
Log Pis Max                  13.6202965
Log Pis Min                  -4.3166056
Policy mu Mean               0.05537073
Policy mu Std                1.1002884
Policy mu Max                2.8222432
Policy mu Min                -3.2349908
Policy log std Mean          -0.5109363
Policy log std Std           0.26571178
Policy log std Max           0.016927093
Policy log std Min           -1.4987526
Z mean eval                  0.07209778
Z variance eval              0.010829173
total_rewards                [1038.82883548 3189.77738464 1968.88433061 1662.5613533   907.91818183
 1522.46151362  840.16846316  798.4020062  1407.8068513  1567.21059556]
total_rewards_mean           1490.401951569755
total_rewards_std            678.6076611796652
total_rewards_max            3189.7773846404684
total_rewards_min            798.4020061975865
Number of train steps total  92000
Number of env steps total    462000
Number of rollouts total     0
Train Time (s)               43.12411726266146
(Previous) Eval Time (s)     9.546734143979847
Sample Time (s)              22.634675746317953
Epoch Time (s)               75.30552715295926
Total Train Time (s)         6380.6231299676
Epoch                        91
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:34:40.174793 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #91 | Epoch Duration: 81.56270027160645
2020-01-11 02:34:40.174916 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #91 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0821314
Z variance train             0.004098869
KL Divergence                11.628265
KL Loss                      1.1628265
QF Loss                      828.20593
VF Loss                      172.44797
Policy Loss                  -845.01666
Q Predictions Mean           839.14197
Q Predictions Std            535.3177
Q Predictions Max            1446.7283
Q Predictions Min            -9.554655
V Predictions Mean           846.5028
V Predictions Std            533.47174
V Predictions Max            1446.4811
V Predictions Min            -0.43891552
Log Pis Mean                 0.7087142
Log Pis Std                  2.5344412
Log Pis Max                  7.9218936
Log Pis Min                  -4.703148
Policy mu Mean               0.14070393
Policy mu Std                1.1047267
Policy mu Max                3.3074503
Policy mu Min                -2.8516254
Policy log std Mean          -0.5403841
Policy log std Std           0.28793904
Policy log std Max           0.10090673
Policy log std Min           -1.6426657
Z mean eval                  0.04988625
Z variance eval              0.0043405313
total_rewards                [1034.26651572  879.81374269  866.29546668  684.73033664  834.79376842
  641.49525388 1019.29614888  848.58140617  710.12033512  673.7205659 ]
total_rewards_mean           819.3113540101161
total_rewards_std            132.67030511940732
total_rewards_max            1034.266515721887
total_rewards_min            641.4952538842349
Number of train steps total  93000
Number of env steps total    467000
Number of rollouts total     0
Train Time (s)               43.6364717669785
(Previous) Eval Time (s)     15.803656504955143
Sample Time (s)              21.84518962027505
Epoch Time (s)               81.2853178922087
Total Train Time (s)         6456.0913832844235
Epoch                        92
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:35:55.646006 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #92 | Epoch Duration: 75.47098541259766
2020-01-11 02:35:55.646173 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #92 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05071615
Z variance train             0.004338151
KL Divergence                11.596242
KL Loss                      1.1596242
QF Loss                      614.833
VF Loss                      490.81915
Policy Loss                  -819.0264
Q Predictions Mean           822.3065
Q Predictions Std            539.59015
Q Predictions Max            1431.7244
Q Predictions Min            3.9166915
V Predictions Mean           803.5759
V Predictions Std            531.1361
V Predictions Max            1380.9116
V Predictions Min            1.5669364
Log Pis Mean                 0.17275776
Log Pis Std                  2.2343261
Log Pis Max                  7.3360553
Log Pis Min                  -3.8854842
Policy mu Mean               -0.09688119
Policy mu Std                0.9887089
Policy mu Max                2.5604324
Policy mu Min                -2.9692419
Policy log std Mean          -0.5175246
Policy log std Std           0.30429175
Policy log std Max           0.11511931
Policy log std Min           -1.7044398
Z mean eval                  0.06041237
Z variance eval              0.012423517
total_rewards                [ 604.37608976  583.78516831  679.86419517 1146.70916168 1634.09775689
  629.27323458  621.2728998   755.30790443  636.66510483  630.92290884]
total_rewards_mean           792.2274424291691
total_rewards_std            321.4227905048426
total_rewards_max            1634.0977568946555
total_rewards_min            583.7851683068197
Number of train steps total  94000
Number of env steps total    472000
Number of rollouts total     0
Train Time (s)               43.23126532090828
(Previous) Eval Time (s)     9.989084629807621
Sample Time (s)              22.445044276770204
Epoch Time (s)               75.6653942274861
Total Train Time (s)         6531.154161540326
Epoch                        93
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:37:10.708119 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #93 | Epoch Duration: 75.06182527542114
2020-01-11 02:37:10.708247 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #93 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06169074
Z variance train             0.012362784
KL Divergence                8.881334
KL Loss                      0.88813347
QF Loss                      711.646
VF Loss                      374.43427
Policy Loss                  -897.5359
Q Predictions Mean           892.21423
Q Predictions Std            501.73038
Q Predictions Max            1468.1407
Q Predictions Min            -28.78921
V Predictions Mean           888.40857
V Predictions Std            499.4328
V Predictions Max            1419.2875
V Predictions Min            -8.407628
Log Pis Mean                 0.4969653
Log Pis Std                  2.2953002
Log Pis Max                  8.218721
Log Pis Min                  -5.343806
Policy mu Mean               0.11122734
Policy mu Std                1.0469779
Policy mu Max                3.5444474
Policy mu Min                -2.9164965
Policy log std Mean          -0.53441006
Policy log std Std           0.28215382
Policy log std Max           -0.0029002428
Policy log std Min           -1.6009643
Z mean eval                  0.048037432
Z variance eval              0.005419706
total_rewards                [ 624.45374501  743.3675771  1005.98092315  856.76054052 1139.08638944
  896.24674273  612.05131831  904.51283612 1152.06707272 1241.8152272 ]
total_rewards_mean           917.6342372292231
total_rewards_std            207.59047532919018
total_rewards_max            1241.815227202889
total_rewards_min            612.0513183063473
Number of train steps total  95000
Number of env steps total    477000
Number of rollouts total     0
Train Time (s)               42.545531754381955
(Previous) Eval Time (s)     9.385259896051139
Sample Time (s)              22.927413284778595
Epoch Time (s)               74.85820493521169
Total Train Time (s)         6606.758070863783
Epoch                        94
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:38:26.314443 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #94 | Epoch Duration: 75.6061019897461
2020-01-11 02:38:26.314567 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #94 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.050048046
Z variance train             0.008561235
KL Divergence                9.827225
KL Loss                      0.98272246
QF Loss                      582.0092
VF Loss                      414.9017
Policy Loss                  -850.19366
Q Predictions Mean           857.60266
Q Predictions Std            490.29407
Q Predictions Max            1374.8387
Q Predictions Min            -21.310106
V Predictions Mean           855.872
V Predictions Std            488.82913
V Predictions Max            1360.2003
V Predictions Min            -3.2154818
Log Pis Mean                 0.30113044
Log Pis Std                  2.415918
Log Pis Max                  8.353859
Log Pis Min                  -5.8579264
Policy mu Mean               0.009373969
Policy mu Std                1.0164522
Policy mu Max                2.8620741
Policy mu Min                -2.7788794
Policy log std Mean          -0.51957387
Policy log std Std           0.26875383
Policy log std Max           0.001993984
Policy log std Min           -1.6327394
Z mean eval                  0.05651449
Z variance eval              0.008499295
total_rewards                [ 888.0505786   897.23711997  893.02483179 1058.44162824  783.14528936
  976.09529001  754.53485939  735.82536552  741.581092    880.91368921]
total_rewards_mean           860.884974408187
total_rewards_std            101.50012039877781
total_rewards_max            1058.441628243384
total_rewards_min            735.8253655177247
Number of train steps total  96000
Number of env steps total    482000
Number of rollouts total     0
Train Time (s)               42.64129717228934
(Previous) Eval Time (s)     10.132904177065939
Sample Time (s)              21.9816861897707
Epoch Time (s)               74.75588753912598
Total Train Time (s)         6680.786028176546
Epoch                        95
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:39:40.346966 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #95 | Epoch Duration: 74.03227710723877
2020-01-11 02:39:40.347188 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #95 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.056066662
Z variance train             0.008457044
KL Divergence                9.782387
KL Loss                      0.9782387
QF Loss                      799.6146
VF Loss                      410.42926
Policy Loss                  -892.45
Q Predictions Mean           889.1546
Q Predictions Std            504.9275
Q Predictions Max            1389.4805
Q Predictions Min            -15.357552
V Predictions Mean           889.74976
V Predictions Std            501.17636
V Predictions Max            1404.4084
V Predictions Min            -26.782486
Log Pis Mean                 0.14597663
Log Pis Std                  2.2476919
Log Pis Max                  8.719357
Log Pis Min                  -5.010097
Policy mu Mean               -0.022942342
Policy mu Std                0.97681296
Policy mu Max                2.9900358
Policy mu Min                -2.928329
Policy log std Mean          -0.5164148
Policy log std Std           0.27159703
Policy log std Max           0.019277781
Policy log std Min           -1.914066
Z mean eval                  0.03556313
Z variance eval              0.005136948
total_rewards                [ 645.3718796   868.73480942  679.30887042  601.88386427  672.88206705
  832.30403881 1037.25188439  659.73594152  648.15200404  708.36878612]
total_rewards_mean           735.3994145628128
total_rewards_std            128.58359189192126
total_rewards_max            1037.251884387625
total_rewards_min            601.8838642692402
Number of train steps total  97000
Number of env steps total    487000
Number of rollouts total     0
Train Time (s)               42.88711320981383
(Previous) Eval Time (s)     9.409027504269034
Sample Time (s)              22.073235136456788
Epoch Time (s)               74.36937585053965
Total Train Time (s)         6753.8927013748325
Epoch                        96
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:40:53.454896 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #96 | Epoch Duration: 73.10753536224365
2020-01-11 02:40:53.455063 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #96 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03870297
Z variance train             0.0052347495
KL Divergence                11.081781
KL Loss                      1.1081781
QF Loss                      338.82422
VF Loss                      131.60023
Policy Loss                  -824.87756
Q Predictions Mean           819.9968
Q Predictions Std            491.32535
Q Predictions Max            1382.4688
Q Predictions Min            -5.102368
V Predictions Mean           822.6363
V Predictions Std            490.1823
V Predictions Max            1367.639
V Predictions Min            -2.2483392
Log Pis Mean                 0.332506
Log Pis Std                  2.428286
Log Pis Max                  7.074829
Log Pis Min                  -5.284292
Policy mu Mean               -0.020718537
Policy mu Std                1.0453916
Policy mu Max                3.174648
Policy mu Min                -2.882749
Policy log std Mean          -0.5194572
Policy log std Std           0.28621995
Policy log std Max           0.119280756
Policy log std Min           -1.6213202
Z mean eval                  0.029978106
Z variance eval              0.0063004987
total_rewards                [ 863.4387382  1240.36839273  673.05732328  668.60792992  595.58696689
  653.10350296  974.41589959  710.64650563  737.46528215  476.75892805]
total_rewards_mean           759.344946940791
total_rewards_std            206.14615789650205
total_rewards_max            1240.36839273499
total_rewards_min            476.75892804940236
Number of train steps total  98000
Number of env steps total    492000
Number of rollouts total     0
Train Time (s)               43.06585217313841
(Previous) Eval Time (s)     8.146966977976263
Sample Time (s)              22.193504178896546
Epoch Time (s)               73.40632333001122
Total Train Time (s)         6826.929919871502
Epoch                        97
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:42:06.496024 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #97 | Epoch Duration: 73.0407862663269
2020-01-11 02:42:06.496251 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #97 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02953279
Z variance train             0.00626292
KL Divergence                10.6765375
KL Loss                      1.0676538
QF Loss                      542.2419
VF Loss                      164.29776
Policy Loss                  -890.2702
Q Predictions Mean           883.69116
Q Predictions Std            511.6983
Q Predictions Max            1433.2911
Q Predictions Min            -8.082176
V Predictions Mean           890.0357
V Predictions Std            514.8069
V Predictions Max            1433.7397
V Predictions Min            -9.178391
Log Pis Mean                 0.30004567
Log Pis Std                  2.5092254
Log Pis Max                  10.103424
Log Pis Min                  -6.3009543
Policy mu Mean               0.15824968
Policy mu Std                1.0386796
Policy mu Max                2.8448448
Policy mu Min                -3.179396
Policy log std Mean          -0.48885664
Policy log std Std           0.26388794
Policy log std Max           0.088588506
Policy log std Min           -1.718607
Z mean eval                  0.040725213
Z variance eval              0.006240148
total_rewards                [985.10125022 844.08589826 751.5037975  847.01042541 679.40672124
 682.45967296 847.16280869 843.58582036 818.08949385 754.1899345 ]
total_rewards_mean           805.2595822991896
total_rewards_std            86.83293296097808
total_rewards_max            985.1012502226438
total_rewards_min            679.4067212359288
Number of train steps total  99000
Number of env steps total    497000
Number of rollouts total     0
Train Time (s)               44.20221738703549
(Previous) Eval Time (s)     7.781187348999083
Sample Time (s)              22.036998245865107
Epoch Time (s)               74.02040298189968
Total Train Time (s)         6902.2492375862785
Epoch                        98
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:43:21.816343 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #98 | Epoch Duration: 75.31991600990295
2020-01-11 02:43:21.816492 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #98 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03907
Z variance train             0.006219356
KL Divergence                10.602531
KL Loss                      1.0602531
QF Loss                      638.88293
VF Loss                      298.62607
Policy Loss                  -847.19116
Q Predictions Mean           844.0597
Q Predictions Std            509.1882
Q Predictions Max            1420.9336
Q Predictions Min            -4.5733995
V Predictions Mean           852.9193
V Predictions Std            506.81644
V Predictions Max            1436.5107
V Predictions Min            -5.076937
Log Pis Mean                 0.5065868
Log Pis Std                  2.4831028
Log Pis Max                  12.871712
Log Pis Min                  -5.0606036
Policy mu Mean               0.03603145
Policy mu Std                1.0589199
Policy mu Max                3.304822
Policy mu Min                -3.2783663
Policy log std Mean          -0.5136638
Policy log std Std           0.2678577
Policy log std Max           -0.01951003
Policy log std Min           -1.4782009
Z mean eval                  0.036786802
Z variance eval              0.0071502565
total_rewards                [1004.70759388  624.12808307 1040.4295172   947.64673162  634.51269768
  987.24986286 1488.94875853  692.85848369  961.96965574 1021.30762264]
total_rewards_mean           940.3759006899451
total_rewards_std            240.66108810978753
total_rewards_max            1488.9487585329564
total_rewards_min            624.1280830686466
Number of train steps total  100000
Number of env steps total    502000
Number of rollouts total     0
Train Time (s)               43.69841403514147
(Previous) Eval Time (s)     9.080454694107175
Sample Time (s)              22.326821491122246
Epoch Time (s)               75.10569022037089
Total Train Time (s)         6978.770863451064
Epoch                        99
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:44:38.338738 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #99 | Epoch Duration: 76.52214908599854
2020-01-11 02:44:38.338864 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #99 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03186254
Z variance train             0.0066556805
KL Divergence                10.482795
KL Loss                      1.0482795
QF Loss                      321.58627
VF Loss                      78.848564
Policy Loss                  -837.373
Q Predictions Mean           834.5366
Q Predictions Std            512.2841
Q Predictions Max            1380.9802
Q Predictions Min            -21.21746
V Predictions Mean           837.359
V Predictions Std            510.83682
V Predictions Max            1371.6853
V Predictions Min            -7.4314914
Log Pis Mean                 0.14400889
Log Pis Std                  2.2385073
Log Pis Max                  10.067041
Log Pis Min                  -3.7932112
Policy mu Mean               0.050813515
Policy mu Std                0.9561721
Policy mu Max                3.0184195
Policy mu Min                -3.866268
Policy log std Mean          -0.5209928
Policy log std Std           0.2707132
Policy log std Max           -0.0053713024
Policy log std Min           -1.4661837
Z mean eval                  0.03835938
Z variance eval              0.008064957
total_rewards                [ 980.83573708  746.35998659  720.04683527  966.27167597  916.14575162
 1588.27784811  816.85351419  943.9032341   720.15175073 1096.63792591]
total_rewards_mean           949.5484259568071
total_rewards_std            244.17290220841153
total_rewards_max            1588.2778481097935
total_rewards_min            720.0468352732187
Number of train steps total  101000
Number of env steps total    507000
Number of rollouts total     0
Train Time (s)               43.385417392943054
(Previous) Eval Time (s)     10.496661074925214
Sample Time (s)              22.246849358081818
Epoch Time (s)               76.12892782595009
Total Train Time (s)         7054.83041618485
Epoch                        100
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:45:54.399355 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #100 | Epoch Duration: 76.06039905548096
2020-01-11 02:45:54.399472 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #100 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033955164
Z variance train             0.009012333
KL Divergence                9.459262
KL Loss                      0.9459262
QF Loss                      9527.208
VF Loss                      269.9297
Policy Loss                  -890.0903
Q Predictions Mean           891.5342
Q Predictions Std            476.48355
Q Predictions Max            1378.773
Q Predictions Min            -18.310232
V Predictions Mean           886.93036
V Predictions Std            473.3952
V Predictions Max            1363.6809
V Predictions Min            -6.8482256
Log Pis Mean                 0.37401426
Log Pis Std                  2.5417285
Log Pis Max                  9.417237
Log Pis Min                  -5.763912
Policy mu Mean               -0.10672316
Policy mu Std                1.057326
Policy mu Max                3.09513
Policy mu Min                -3.5064106
Policy log std Mean          -0.54143274
Policy log std Std           0.27486864
Policy log std Max           0.036209375
Policy log std Min           -1.6344925
Z mean eval                  0.03256644
Z variance eval              0.0076158186
total_rewards                [1527.58172905  822.56838539  645.15294501  849.25851095  745.53543529
 1142.86655863 1142.39619491 1458.21159365  892.50326509  787.69013741]
total_rewards_mean           1001.3764755383756
total_rewards_std            288.17938436331195
total_rewards_max            1527.5817290541543
total_rewards_min            645.1529450137984
Number of train steps total  102000
Number of env steps total    512000
Number of rollouts total     0
Train Time (s)               42.869309226982296
(Previous) Eval Time (s)     10.42788157472387
Sample Time (s)              21.301544461864978
Epoch Time (s)               74.59873526357114
Total Train Time (s)         7129.322784351651
Epoch                        101
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:47:08.895698 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #101 | Epoch Duration: 74.49612331390381
2020-01-11 02:47:08.895869 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #101 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03422216
Z variance train             0.0076147006
KL Divergence                9.910002
KL Loss                      0.9910002
QF Loss                      420.13763
VF Loss                      296.68005
Policy Loss                  -872.25995
Q Predictions Mean           867.62024
Q Predictions Std            493.32053
Q Predictions Max            1422.6672
Q Predictions Min            -9.789468
V Predictions Mean           861.47296
V Predictions Std            490.38724
V Predictions Max            1385.6737
V Predictions Min            -3.440221
Log Pis Mean                 0.36886847
Log Pis Std                  2.447817
Log Pis Max                  9.47843
Log Pis Min                  -5.5042744
Policy mu Mean               0.14907062
Policy mu Std                1.0473379
Policy mu Max                2.4261363
Policy mu Min                -3.0243206
Policy log std Mean          -0.52671707
Policy log std Std           0.28362995
Policy log std Max           0.07739884
Policy log std Min           -1.472439
Z mean eval                  0.029122597
Z variance eval              0.0075973496
total_rewards                [1064.74865537 1341.03304631  947.94754554  792.93203516  850.72893314
  935.56422746  825.2390951  1008.5341838  1465.23339321  833.43990784]
total_rewards_mean           1006.540102293284
total_rewards_std            216.07572713338578
total_rewards_max            1465.2333932127626
total_rewards_min            792.9320351624846
Number of train steps total  103000
Number of env steps total    517000
Number of rollouts total     0
Train Time (s)               43.17827918380499
(Previous) Eval Time (s)     10.324995416682214
Sample Time (s)              21.89581023203209
Epoch Time (s)               75.39908483251929
Total Train Time (s)         7204.893995701801
Epoch                        102
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:48:24.469929 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #102 | Epoch Duration: 75.57391262054443
2020-01-11 02:48:24.470129 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #102 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02953892
Z variance train             0.007595496
KL Divergence                10.046282
KL Loss                      1.0046282
QF Loss                      482.52264
VF Loss                      263.486
Policy Loss                  -838.1403
Q Predictions Mean           840.97205
Q Predictions Std            489.6428
Q Predictions Max            1340.3849
Q Predictions Min            0.954628
V Predictions Mean           829.268
V Predictions Std            482.89658
V Predictions Max            1303.9882
V Predictions Min            2.7134943
Log Pis Mean                 0.40502542
Log Pis Std                  2.4257312
Log Pis Max                  7.676505
Log Pis Min                  -4.7634735
Policy mu Mean               -0.122598924
Policy mu Std                1.00561
Policy mu Max                2.6904101
Policy mu Min                -2.8443208
Policy log std Mean          -0.5414652
Policy log std Std           0.28546003
Policy log std Max           -0.0420817
Policy log std Min           -1.6188394
Z mean eval                  0.03527776
Z variance eval              0.0077003227
total_rewards                [ 856.01018685  964.07801734 1039.04847391  968.2631601  1042.11717571
  778.41409827  960.72648634  693.44343057 1047.73905194 1009.24479774]
total_rewards_mean           935.9084878770279
total_rewards_std            114.9940159421116
total_rewards_max            1047.7390519387397
total_rewards_min            693.4434305698295
Number of train steps total  104000
Number of env steps total    522000
Number of rollouts total     0
Train Time (s)               43.59437622083351
(Previous) Eval Time (s)     10.499527094885707
Sample Time (s)              21.96394736599177
Epoch Time (s)               76.05785068171099
Total Train Time (s)         7281.908384915907
Epoch                        103
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:49:41.485014 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #103 | Epoch Duration: 77.01474332809448
2020-01-11 02:49:41.485139 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #103 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035422776
Z variance train             0.0076875724
KL Divergence                9.943687
KL Loss                      0.99436873
QF Loss                      458.1524
VF Loss                      168.41808
Policy Loss                  -937.72205
Q Predictions Mean           937.40894
Q Predictions Std            465.19797
Q Predictions Max            1398.9121
Q Predictions Min            -0.66613305
V Predictions Mean           935.5434
V Predictions Std            463.33786
V Predictions Max            1385.5276
V Predictions Min            -0.99111074
Log Pis Mean                 0.23691303
Log Pis Std                  2.1913097
Log Pis Max                  7.07755
Log Pis Min                  -6.8102694
Policy mu Mean               -0.043224707
Policy mu Std                0.98867106
Policy mu Max                2.5435195
Policy mu Min                -3.1709082
Policy log std Mean          -0.52882653
Policy log std Std           0.25974712
Policy log std Max           -0.024808764
Policy log std Min           -1.5587188
Z mean eval                  0.035154883
Z variance eval              0.0068266555
total_rewards                [ 986.35448664 1274.17096316 1675.43701167 2950.98502064 1306.90273664
 1012.60530884  591.35141579 2526.13519921 1591.32858373 1279.10585063]
total_rewards_mean           1519.437657695583
total_rewards_std            682.477756946797
total_rewards_max            2950.9850206448955
total_rewards_min            591.3514157904037
Number of train steps total  105000
Number of env steps total    527000
Number of rollouts total     0
Train Time (s)               43.81837005726993
(Previous) Eval Time (s)     11.456190486904234
Sample Time (s)              21.306195007171482
Epoch Time (s)               76.58075555134565
Total Train Time (s)         7362.6063693254255
Epoch                        104
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:51:02.184746 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #104 | Epoch Duration: 80.69951248168945
2020-01-11 02:51:02.184870 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #104 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03193574
Z variance train             0.006826273
KL Divergence                10.094388
KL Loss                      1.0094389
QF Loss                      408.5741
VF Loss                      307.40005
Policy Loss                  -866.07245
Q Predictions Mean           868.45654
Q Predictions Std            458.63303
Q Predictions Max            1336.602
Q Predictions Min            -14.577796
V Predictions Mean           865.66077
V Predictions Std            454.44077
V Predictions Max            1328.6691
V Predictions Min            -2.5471764
Log Pis Mean                 0.19896546
Log Pis Std                  2.2169979
Log Pis Max                  6.7752075
Log Pis Min                  -5.956378
Policy mu Mean               0.11326331
Policy mu Std                1.0159433
Policy mu Max                2.5427868
Policy mu Min                -2.681816
Policy log std Mean          -0.5280616
Policy log std Std           0.2773599
Policy log std Max           0.0082473755
Policy log std Min           -1.4414648
Z mean eval                  0.013395418
Z variance eval              0.007184534
total_rewards                [1256.41357951 1311.28583425 1295.54080702 1180.50243453 3262.29718007
 1036.59058102 2408.17946626  934.59700108  793.3192775   850.91177578]
total_rewards_mean           1432.963793701322
total_rewards_std            746.9614720968675
total_rewards_max            3262.2971800693813
total_rewards_min            793.3192775041913
Number of train steps total  106000
Number of env steps total    532000
Number of rollouts total     0
Train Time (s)               43.29482100578025
(Previous) Eval Time (s)     15.574693491216749
Sample Time (s)              22.224092188756913
Epoch Time (s)               81.09360668575391
Total Train Time (s)         7442.072389970534
Epoch                        105
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:52:21.652954 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #105 | Epoch Duration: 79.46796464920044
2020-01-11 02:52:21.653159 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #105 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012338148
Z variance train             0.0071994215
KL Divergence                10.038715
KL Loss                      1.0038716
QF Loss                      266.00558
VF Loss                      810.0035
Policy Loss                  -862.61487
Q Predictions Mean           864.17676
Q Predictions Std            484.07672
Q Predictions Max            1337.562
Q Predictions Min            -45.95876
V Predictions Mean           858.70465
V Predictions Std            479.24695
V Predictions Max            1318.1509
V Predictions Min            -15.614932
Log Pis Mean                 0.07668942
Log Pis Std                  2.3540707
Log Pis Max                  7.513511
Log Pis Min                  -5.6295385
Policy mu Mean               -0.03256416
Policy mu Std                0.9864061
Policy mu Max                2.4193282
Policy mu Min                -2.7719772
Policy log std Mean          -0.53139496
Policy log std Std           0.28686476
Policy log std Max           -0.04993403
Policy log std Min           -1.4390544
Z mean eval                  0.020916134
Z variance eval              0.0066600917
total_rewards                [1393.20823789 1031.19190034  661.76172812  922.24585739  860.59786839
 1151.53353215 1592.05270548  888.41328727  858.46936958  597.57473786]
total_rewards_mean           995.7049224467994
total_rewards_std            293.8030613317274
total_rewards_max            1592.0527054750137
total_rewards_min            597.5747378602423
Number of train steps total  107000
Number of env steps total    537000
Number of rollouts total     0
Train Time (s)               44.03464848967269
(Previous) Eval Time (s)     13.948791336733848
Sample Time (s)              21.962805446237326
Epoch Time (s)               79.94624527264386
Total Train Time (s)         7520.133307530079
Epoch                        106
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:53:39.714309 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #106 | Epoch Duration: 78.06100153923035
2020-01-11 02:53:39.714429 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #106 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020859292
Z variance train             0.0066570924
KL Divergence                10.272839
KL Loss                      1.0272839
QF Loss                      406.01602
VF Loss                      310.3038
Policy Loss                  -861.3779
Q Predictions Mean           863.30994
Q Predictions Std            470.50354
Q Predictions Max            1313.2578
Q Predictions Min            -10.028275
V Predictions Mean           873.61786
V Predictions Std            473.0251
V Predictions Max            1326.4734
V Predictions Min            -10.064764
Log Pis Mean                 0.29762572
Log Pis Std                  2.5694637
Log Pis Max                  10.406369
Log Pis Min                  -4.737024
Policy mu Mean               0.16069026
Policy mu Std                1.045759
Policy mu Max                3.138935
Policy mu Min                -4.3564963
Policy log std Mean          -0.5125202
Policy log std Std           0.2806665
Policy log std Max           -0.044056803
Policy log std Min           -1.5314945
Z mean eval                  0.021334395
Z variance eval              0.007875711
total_rewards                [2279.85939616 1878.53271219 2886.35276942  687.37146764 3019.04847869
 1268.84193997 1204.5769483  2616.62861048 2602.32067798  913.38132015]
total_rewards_mean           1935.6914320977944
total_rewards_std            817.9147571728013
total_rewards_max            3019.048478693208
total_rewards_min            687.3714676435926
Number of train steps total  108000
Number of env steps total    542000
Number of rollouts total     0
Train Time (s)               43.034202840644866
(Previous) Eval Time (s)     12.063308720942587
Sample Time (s)              21.4447289891541
Epoch Time (s)               76.54224055074155
Total Train Time (s)         7604.185845338274
Epoch                        107
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:55:03.772903 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #107 | Epoch Duration: 84.0583245754242
2020-01-11 02:55:03.773183 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #107 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02151261
Z variance train             0.007871085
KL Divergence                9.892562
KL Loss                      0.9892562
QF Loss                      230.7812
VF Loss                      165.49109
Policy Loss                  -917.5176
Q Predictions Mean           915.89417
Q Predictions Std            469.18484
Q Predictions Max            1345.3461
Q Predictions Min            -22.971622
V Predictions Mean           924.7075
V Predictions Std            470.11575
V Predictions Max            1370.2688
V Predictions Min            3.5600088
Log Pis Mean                 0.28952926
Log Pis Std                  2.318927
Log Pis Max                  9.7964325
Log Pis Min                  -3.9799309
Policy mu Mean               -0.026905192
Policy mu Std                1.0160519
Policy mu Max                3.630448
Policy mu Min                -2.8470669
Policy log std Mean          -0.5314774
Policy log std Std           0.2626449
Policy log std Max           -0.026597857
Policy log std Min           -1.4033513
Z mean eval                  0.026531745
Z variance eval              0.0072655813
total_rewards                [1206.84720816 1128.90202002 1006.31733126  910.90996805 1135.01679388
 1448.4286616  2312.73780527  857.00876107  889.03757998  954.64102124]
total_rewards_mean           1184.984715052872
total_rewards_std            412.6257296024006
total_rewards_max            2312.7378052673243
total_rewards_min            857.0087610740193
Number of train steps total  109000
Number of env steps total    547000
Number of rollouts total     0
Train Time (s)               43.47352684382349
(Previous) Eval Time (s)     19.57914665294811
Sample Time (s)              21.822479223832488
Epoch Time (s)               84.87515272060409
Total Train Time (s)         7682.300466590561
Epoch                        108
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:56:21.887314 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #108 | Epoch Duration: 78.11392545700073
2020-01-11 02:56:21.887478 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #108 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026088092
Z variance train             0.007269047
KL Divergence                10.200321
KL Loss                      1.0200322
QF Loss                      669.4991
VF Loss                      129.61552
Policy Loss                  -797.60315
Q Predictions Mean           796.119
Q Predictions Std            497.9863
Q Predictions Max            1315.3438
Q Predictions Min            -6.812651
V Predictions Mean           801.5554
V Predictions Std            495.45483
V Predictions Max            1309.4344
V Predictions Min            -4.032889
Log Pis Mean                 0.0022904463
Log Pis Std                  2.2379682
Log Pis Max                  9.291784
Log Pis Min                  -5.582658
Policy mu Mean               0.010161973
Policy mu Std                0.9514058
Policy mu Max                3.0831752
Policy mu Min                -2.7247825
Policy log std Mean          -0.49777594
Policy log std Std           0.2606739
Policy log std Max           -0.05916497
Policy log std Min           -1.5326514
Z mean eval                  0.015740618
Z variance eval              0.0069584474
total_rewards                [2971.90063771 2304.31247248 1694.12127593 1366.81223629 2807.20946676
 1066.84071842 2311.85622005 2054.18182335 1394.05087772 2838.46549917]
total_rewards_mean           2080.975122788515
total_rewards_std            644.8936218789262
total_rewards_max            2971.9006377105766
total_rewards_min            1066.840718420427
Number of train steps total  110000
Number of env steps total    552000
Number of rollouts total     0
Train Time (s)               43.92825767304748
(Previous) Eval Time (s)     12.817695409059525
Sample Time (s)              21.53483876027167
Epoch Time (s)               78.28079184237868
Total Train Time (s)         7770.190617640037
Epoch                        109
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:57:49.778740 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #109 | Epoch Duration: 87.89114117622375
2020-01-11 02:57:49.778862 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #109 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015965577
Z variance train             0.006961909
KL Divergence                10.287174
KL Loss                      1.0287174
QF Loss                      464.70898
VF Loss                      151.7521
Policy Loss                  -805.9113
Q Predictions Mean           804.66797
Q Predictions Std            483.2478
Q Predictions Max            1358.9646
Q Predictions Min            -1.0826839
V Predictions Mean           807.6678
V Predictions Std            482.96927
V Predictions Max            1339.7681
V Predictions Min            -0.86242366
Log Pis Mean                 0.17750105
Log Pis Std                  2.2328365
Log Pis Max                  7.624708
Log Pis Min                  -3.1776328
Policy mu Mean               -0.098821126
Policy mu Std                0.9782733
Policy mu Max                2.2891295
Policy mu Min                -2.8826394
Policy log std Mean          -0.49569854
Policy log std Std           0.26474348
Policy log std Max           0.016708821
Policy log std Min           -1.4265059
Z mean eval                  0.018434558
Z variance eval              0.0062716864
total_rewards                [1733.83320858 2219.57567158 1861.19173118 1612.47856993 1664.86293782
 1141.44794688 2755.16353168  986.527978    967.38721791  945.94533486]
total_rewards_mean           1588.8414128423397
total_rewards_std            567.6382091514529
total_rewards_max            2755.163531682489
total_rewards_min            945.9453348642047
Number of train steps total  111000
Number of env steps total    557000
Number of rollouts total     0
Train Time (s)               42.83557153912261
(Previous) Eval Time (s)     22.42779730912298
Sample Time (s)              21.336787714157254
Epoch Time (s)               86.60015656240284
Total Train Time (s)         7851.807617041748
Epoch                        110
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:59:11.396950 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #110 | Epoch Duration: 81.61799097061157
2020-01-11 02:59:11.397071 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #110 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01982671
Z variance train             0.0062737153
KL Divergence                10.577598
KL Loss                      1.0577598
QF Loss                      1495.4731
VF Loss                      438.09967
Policy Loss                  -864.2231
Q Predictions Mean           860.2267
Q Predictions Std            475.21906
Q Predictions Max            1311.9371
Q Predictions Min            -5.1929374
V Predictions Mean           865.4978
V Predictions Std            474.38547
V Predictions Max            1336.4707
V Predictions Min            1.5655917
Log Pis Mean                 0.39611652
Log Pis Std                  2.4671876
Log Pis Max                  12.536507
Log Pis Min                  -7.6453395
Policy mu Mean               0.11585939
Policy mu Std                1.0316767
Policy mu Max                3.667129
Policy mu Min                -3.1923954
Policy log std Mean          -0.5136853
Policy log std Std           0.2585013
Policy log std Max           -0.002077192
Policy log std Min           -1.3598187
Z mean eval                  0.009332173
Z variance eval              0.0060594645
total_rewards                [1102.25450225 2924.1118839  1197.5191254  2909.14033265 1081.22443696
 1239.93833931 1553.62588154 1725.31363114 1569.19202402 2740.44473699]
total_rewards_mean           1804.2764894162315
total_rewards_std            719.5667560523265
total_rewards_max            2924.111883902124
total_rewards_min            1081.2244369578918
Number of train steps total  112000
Number of env steps total    562000
Number of rollouts total     0
Train Time (s)               43.87184996297583
(Previous) Eval Time (s)     17.445390834938735
Sample Time (s)              22.003392362967134
Epoch Time (s)               83.3206331608817
Total Train Time (s)         7936.3708323123865
Epoch                        111
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:00:35.966150 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #111 | Epoch Duration: 84.5689344406128
2020-01-11 03:00:35.966458 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #111 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.009159188
Z variance train             0.0060635796
KL Divergence                10.747456
KL Loss                      1.0747455
QF Loss                      232.27219
VF Loss                      127.278595
Policy Loss                  -894.21576
Q Predictions Mean           891.03467
Q Predictions Std            464.60455
Q Predictions Max            1352.1906
Q Predictions Min            -19.036106
V Predictions Mean           891.8705
V Predictions Std            462.33978
V Predictions Max            1342.7843
V Predictions Min            3.6661859
Log Pis Mean                 0.28940976
Log Pis Std                  2.166446
Log Pis Max                  7.9675045
Log Pis Min                  -4.035242
Policy mu Mean               0.102307595
Policy mu Std                1.0097897
Policy mu Max                2.7400386
Policy mu Min                -2.7754521
Policy log std Mean          -0.5182817
Policy log std Std           0.27675402
Policy log std Max           -0.011262029
Policy log std Min           -1.4660039
Z mean eval                  0.01776765
Z variance eval              0.0052755317
total_rewards                [1280.1610762  1157.25394381 2844.07367119 1177.98410762 2819.35536703
 1237.78333994 1352.19840567 1339.3252139  1791.68345625 1826.43272957]
total_rewards_mean           1682.6251311181907
total_rewards_std            615.7327602070757
total_rewards_max            2844.0736711948875
total_rewards_min            1157.2539438091135
Number of train steps total  113000
Number of env steps total    567000
Number of rollouts total     0
Train Time (s)               44.69864692306146
(Previous) Eval Time (s)     18.69340237369761
Sample Time (s)              21.9090990354307
Epoch Time (s)               85.30114833218977
Total Train Time (s)         8020.6365438476205
Epoch                        112
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:02:00.234741 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #112 | Epoch Duration: 84.26807069778442
2020-01-11 03:02:00.234859 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #112 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018407634
Z variance train             0.005275258
KL Divergence                11.244913
KL Loss                      1.1244913
QF Loss                      678.87256
VF Loss                      109.47534
Policy Loss                  -897.3869
Q Predictions Mean           895.8819
Q Predictions Std            482.9308
Q Predictions Max            1349.5724
Q Predictions Min            1.7948343
V Predictions Mean           894.23334
V Predictions Std            482.59982
V Predictions Max            1344.5062
V Predictions Min            -5.629826
Log Pis Mean                 0.11366777
Log Pis Std                  2.2096117
Log Pis Max                  7.6718845
Log Pis Min                  -4.888321
Policy mu Mean               0.05550457
Policy mu Std                0.9748733
Policy mu Max                2.347053
Policy mu Min                -2.888776
Policy log std Mean          -0.5218956
Policy log std Std           0.26099408
Policy log std Max           -0.014642596
Policy log std Min           -1.4388491
Z mean eval                  0.018358644
Z variance eval              0.005374624
total_rewards                [2374.49061653 2996.22111123 3017.59754267 3049.7662338  1399.259823
 2147.38607984 3099.87990681 3158.85779686 2999.31585774 2989.74475017]
total_rewards_mean           2723.2519718659887
total_rewards_std            543.3971801812723
total_rewards_max            3158.857796857369
total_rewards_min            1399.2598230041144
Number of train steps total  114000
Number of env steps total    572000
Number of rollouts total     0
Train Time (s)               43.1654618778266
(Previous) Eval Time (s)     17.660112452227622
Sample Time (s)              21.600636101793498
Epoch Time (s)               82.42621043184772
Total Train Time (s)         8115.121406442951
Epoch                        113
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:03:34.721818 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #113 | Epoch Duration: 94.48686647415161
2020-01-11 03:03:34.721941 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #113 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019586787
Z variance train             0.005379309
KL Divergence                11.258402
KL Loss                      1.1258402
QF Loss                      598.19824
VF Loss                      300.99936
Policy Loss                  -934.3781
Q Predictions Mean           929.05835
Q Predictions Std            447.22318
Q Predictions Max            1331.3839
Q Predictions Min            -2.111003
V Predictions Mean           927.8808
V Predictions Std            447.8732
V Predictions Max            1326.6948
V Predictions Min            -7.7356963
Log Pis Mean                 0.25050473
Log Pis Std                  2.16281
Log Pis Max                  8.991582
Log Pis Min                  -6.9477615
Policy mu Mean               0.125546
Policy mu Std                1.0074085
Policy mu Max                3.418972
Policy mu Min                -3.6023784
Policy log std Mean          -0.54778594
Policy log std Std           0.26329577
Policy log std Max           0.008232176
Policy log std Min           -1.5664153
Z mean eval                  0.010324964
Z variance eval              0.0052880556
total_rewards                [2923.21266404 2069.68291302 1496.30047643 1604.37449501 1762.86347729
  902.65948765 1219.07948757 3100.36299412 2732.88778163 1203.80104538]
total_rewards_mean           1901.522482215664
total_rewards_std            736.3772564644499
total_rewards_max            3100.362994122949
total_rewards_min            902.6594876509547
Number of train steps total  115000
Number of env steps total    577000
Number of rollouts total     0
Train Time (s)               42.387389490846545
(Previous) Eval Time (s)     29.720524067990482
Sample Time (s)              22.145639390684664
Epoch Time (s)               94.25355294952169
Total Train Time (s)         8200.113190432545
Epoch                        114
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:04:59.714616 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #114 | Epoch Duration: 84.9925811290741
2020-01-11 03:04:59.714738 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #114 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008900023
Z variance train             0.0052945963
KL Divergence                11.322144
KL Loss                      1.1322144
QF Loss                      361.11777
VF Loss                      229.15758
Policy Loss                  -849.3372
Q Predictions Mean           848.8751
Q Predictions Std            480.70526
Q Predictions Max            1324.5669
Q Predictions Min            -10.945531
V Predictions Mean           839.1538
V Predictions Std            476.78983
V Predictions Max            1305.2507
V Predictions Min            -20.974146
Log Pis Mean                 0.14372583
Log Pis Std                  2.2313416
Log Pis Max                  7.3490415
Log Pis Min                  -4.0192537
Policy mu Mean               -0.06367258
Policy mu Std                0.9964451
Policy mu Max                3.3837495
Policy mu Min                -2.786332
Policy log std Mean          -0.49691197
Policy log std Std           0.24429448
Policy log std Max           0.07467651
Policy log std Min           -1.486157
Z mean eval                  0.022306794
Z variance eval              0.0057867886
total_rewards                [2042.81919443  619.61767837 2366.57233557 2048.03830528 3126.93931812
 1189.32934518 2659.13875493 2790.34539916 2308.8527393   937.22455908]
total_rewards_mean           2008.8877629410938
total_rewards_std            790.8446375804502
total_rewards_max            3126.9393181208657
total_rewards_min            619.6176783691832
Number of train steps total  116000
Number of env steps total    582000
Number of rollouts total     0
Train Time (s)               42.587242586072534
(Previous) Eval Time (s)     20.4593019830063
Sample Time (s)              22.738863910082728
Epoch Time (s)               85.78540847916156
Total Train Time (s)         8286.893441380933
Epoch                        115
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:06:26.501185 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #115 | Epoch Duration: 86.786301612854
2020-01-11 03:06:26.501490 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #115 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021553664
Z variance train             0.0057897456
KL Divergence                10.8916645
KL Loss                      1.0891665
QF Loss                      746.21277
VF Loss                      167.32048
Policy Loss                  -899.99084
Q Predictions Mean           898.02783
Q Predictions Std            471.95676
Q Predictions Max            1350.2007
Q Predictions Min            -9.142052
V Predictions Mean           903.39575
V Predictions Std            474.50156
V Predictions Max            1355.6964
V Predictions Min            -8.112898
Log Pis Mean                 0.029798843
Log Pis Std                  2.2187557
Log Pis Max                  8.866581
Log Pis Min                  -4.7396555
Policy mu Mean               0.09441724
Policy mu Std                0.933562
Policy mu Max                2.6736596
Policy mu Min                -2.9371421
Policy log std Mean          -0.5357308
Policy log std Std           0.26951307
Policy log std Max           0.05663824
Policy log std Min           -1.8195038
Z mean eval                  0.014313941
Z variance eval              0.0054020165
total_rewards                [3105.44298861 1839.55992882  974.88348511 1664.07149642 1020.27799219
 2014.10022984  980.82572797 3058.29155352  998.32149765 1012.23725264]
total_rewards_mean           1666.8012152762028
total_rewards_std            799.9393133199706
total_rewards_max            3105.442988605809
total_rewards_min            974.8834851071923
Number of train steps total  117000
Number of env steps total    587000
Number of rollouts total     0
Train Time (s)               44.1232552989386
(Previous) Eval Time (s)     21.45991874486208
Sample Time (s)              20.11740549793467
Epoch Time (s)               85.70057954173535
Total Train Time (s)         8369.286719972733
Epoch                        116
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:07:48.893325 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #116 | Epoch Duration: 82.39163160324097
2020-01-11 03:07:48.893445 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #116 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01504639
Z variance train             0.0054067066
KL Divergence                10.897844
KL Loss                      1.0897845
QF Loss                      1783.1138
VF Loss                      347.75992
Policy Loss                  -871.87085
Q Predictions Mean           869.4898
Q Predictions Std            468.45728
Q Predictions Max            1316.4797
Q Predictions Min            -8.807477
V Predictions Mean           865.75507
V Predictions Std            462.54996
V Predictions Max            1312.1722
V Predictions Min            -5.0263014
Log Pis Mean                 0.19503099
Log Pis Std                  2.0636559
Log Pis Max                  8.397566
Log Pis Min                  -4.452381
Policy mu Mean               0.14548306
Policy mu Std                0.97257847
Policy mu Max                3.2034838
Policy mu Min                -3.1270313
Policy log std Mean          -0.53527135
Policy log std Std           0.2604745
Policy log std Max           -0.02161032
Policy log std Min           -2.130637
Z mean eval                  0.029278543
Z variance eval              0.005377519
total_rewards                [2919.46658595 1067.89954562 1526.85425853  852.5304195  2848.36377291
 2608.16284908 2522.22612095 2909.47815839 1017.12997728   42.70609051]
total_rewards_mean           1831.4817778708934
total_rewards_std            997.8620241576375
total_rewards_max            2919.4665859458887
total_rewards_min            42.70609050868243
Number of train steps total  118000
Number of env steps total    592000
Number of rollouts total     0
Train Time (s)               43.58344871504232
(Previous) Eval Time (s)     18.150772897992283
Sample Time (s)              22.064365869387984
Epoch Time (s)               83.79858748242259
Total Train Time (s)         8455.544492685702
Epoch                        117
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:09:15.153584 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #117 | Epoch Duration: 86.26004648208618
2020-01-11 03:09:15.153706 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #117 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02632407
Z variance train             0.005327908
KL Divergence                10.786564
KL Loss                      1.0786564
QF Loss                      386.1408
VF Loss                      127.22323
Policy Loss                  -903.1289
Q Predictions Mean           907.90076
Q Predictions Std            483.5856
Q Predictions Max            1376.6078
Q Predictions Min            -7.647709
V Predictions Mean           906.8845
V Predictions Std            479.75583
V Predictions Max            1392.0396
V Predictions Min            0.9985832
Log Pis Mean                 0.37900746
Log Pis Std                  2.3332849
Log Pis Max                  10.263224
Log Pis Min                  -5.200071
Policy mu Mean               0.20322919
Policy mu Std                1.0103428
Policy mu Max                3.0899026
Policy mu Min                -2.950264
Policy log std Mean          -0.50506383
Policy log std Std           0.22996521
Policy log std Max           -0.022415668
Policy log std Min           -1.2679719
Z mean eval                  0.04483391
Z variance eval              0.0052513727
total_rewards                [2213.22350175 2374.74833274 3090.62462109 1033.10240476 3141.60182841
 3138.54699114 3177.52234683 1702.71688547 1134.68900687 3182.36980608]
total_rewards_mean           2418.914572513206
total_rewards_std            823.2011293752546
total_rewards_max            3182.3698060789525
total_rewards_min            1033.102404757067
Number of train steps total  119000
Number of env steps total    597000
Number of rollouts total     0
Train Time (s)               43.47799160890281
(Previous) Eval Time (s)     20.612011545337737
Sample Time (s)              21.299385722260922
Epoch Time (s)               85.38938887650147
Total Train Time (s)         8545.434045989998
Epoch                        118
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:10:45.048748 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #118 | Epoch Duration: 89.89493680000305
2020-01-11 03:10:45.048914 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #118 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04477506
Z variance train             0.0052537993
KL Divergence                10.742186
KL Loss                      1.0742186
QF Loss                      320.22992
VF Loss                      119.60473
Policy Loss                  -863.7044
Q Predictions Mean           866.34094
Q Predictions Std            481.55487
Q Predictions Max            1354.7422
Q Predictions Min            -31.430464
V Predictions Mean           862.2942
V Predictions Std            480.19952
V Predictions Max            1357.0385
V Predictions Min            -9.567639
Log Pis Mean                 0.16874228
Log Pis Std                  2.1063633
Log Pis Max                  5.640408
Log Pis Min                  -5.064053
Policy mu Mean               0.091890514
Policy mu Std                0.9956823
Policy mu Max                4.028026
Policy mu Min                -2.7158983
Policy log std Mean          -0.49465963
Policy log std Std           0.2539308
Policy log std Max           0.074920386
Policy log std Min           -1.4892287
Z mean eval                  0.0155886365
Z variance eval              0.005381097
total_rewards                [1464.49995511 3016.70728143  977.90385156 3009.25828014 2499.31514904
 1816.02557381 2627.71717034 1804.27316668  977.93402924 3091.23594514]
total_rewards_mean           2128.4870402488013
total_rewards_std            785.4656195597639
total_rewards_max            3091.23594514214
total_rewards_min            977.9038515588154
Number of train steps total  120000
Number of env steps total    602000
Number of rollouts total     0
Train Time (s)               42.78680397802964
(Previous) Eval Time (s)     25.11730798985809
Sample Time (s)              21.926022121682763
Epoch Time (s)               89.83013408957049
Total Train Time (s)         8633.493061858695
Epoch                        119
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:12:13.107304 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #119 | Epoch Duration: 88.05826783180237
2020-01-11 03:12:13.107426 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #119 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016521823
Z variance train             0.0051336717
KL Divergence                10.781738
KL Loss                      1.0781739
QF Loss                      233.24771
VF Loss                      196.21307
Policy Loss                  -793.4278
Q Predictions Mean           796.82263
Q Predictions Std            487.46567
Q Predictions Max            1364.6805
Q Predictions Min            -18.39848
V Predictions Mean           800.9418
V Predictions Std            489.84152
V Predictions Max            1342.9438
V Predictions Min            -1.8329842
Log Pis Mean                 -0.22203742
Log Pis Std                  2.007858
Log Pis Max                  6.6388025
Log Pis Min                  -4.8817973
Policy mu Mean               -0.025044074
Policy mu Std                0.912315
Policy mu Max                2.2699332
Policy mu Min                -3.0063365
Policy log std Mean          -0.5033366
Policy log std Std           0.26616147
Policy log std Max           0.1291318
Policy log std Min           -1.3511401
Z mean eval                  0.013675001
Z variance eval              0.0060448227
total_rewards                [ 940.4390805  3169.44273342 1287.09005203  664.25151107 3177.11889063
  915.86578869  932.9875152  2907.17832185 1207.95146624 2065.92321027]
total_rewards_mean           1726.8248569910374
total_rewards_std            958.6769242843673
total_rewards_max            3177.1188906348584
total_rewards_min            664.2515110695662
Number of train steps total  121000
Number of env steps total    607000
Number of rollouts total     0
Train Time (s)               43.667392895091325
(Previous) Eval Time (s)     23.345207260921597
Sample Time (s)              22.158184226136655
Epoch Time (s)               89.17078438214958
Total Train Time (s)         8716.230444611982
Epoch                        120
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:13:35.847895 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #120 | Epoch Duration: 82.74034976959229
2020-01-11 03:13:35.848131 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #120 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013141347
Z variance train             0.0060396716
KL Divergence                10.442179
KL Loss                      1.044218
QF Loss                      364.3593
VF Loss                      94.24179
Policy Loss                  -888.95013
Q Predictions Mean           890.58154
Q Predictions Std            479.05103
Q Predictions Max            1414.6185
Q Predictions Min            -10.964549
V Predictions Mean           889.1615
V Predictions Std            476.32266
V Predictions Max            1386.1519
V Predictions Min            -11.944525
Log Pis Mean                 0.09597408
Log Pis Std                  2.2539825
Log Pis Max                  8.529091
Log Pis Min                  -4.945195
Policy mu Mean               -0.027820444
Policy mu Std                0.95693594
Policy mu Max                3.0375488
Policy mu Min                -3.0810556
Policy log std Mean          -0.53220296
Policy log std Std           0.23741719
Policy log std Max           0.017663658
Policy log std Min           -1.4011033
Z mean eval                  0.023127714
Z variance eval              0.005321932
total_rewards                [3182.98925892 3157.17819798 2277.93318983 3137.65127022 3241.3829354
 3139.77068274 3194.37525424 2056.89941525 1676.63584563 3201.08488163]
total_rewards_mean           2826.5900931854253
total_rewards_std            556.2875407444677
total_rewards_max            3241.3829354015497
total_rewards_min            1676.635845634552
Number of train steps total  122000
Number of env steps total    612000
Number of rollouts total     0
Train Time (s)               42.89668181911111
(Previous) Eval Time (s)     16.914523052982986
Sample Time (s)              21.253439854364842
Epoch Time (s)               81.06464472645894
Total Train Time (s)         8809.72697732132
Epoch                        121
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:15:09.345565 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #121 | Epoch Duration: 93.49728035926819
2020-01-11 03:15:09.345698 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #121 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023425568
Z variance train             0.0056573832
KL Divergence                10.644291
KL Loss                      1.0644292
QF Loss                      308.20425
VF Loss                      124.727036
Policy Loss                  -912.14636
Q Predictions Mean           907.5341
Q Predictions Std            443.83948
Q Predictions Max            1329.8262
Q Predictions Min            -7.479253
V Predictions Mean           915.0797
V Predictions Std            444.612
V Predictions Max            1332.4955
V Predictions Min            -0.17290705
Log Pis Mean                 0.065672435
Log Pis Std                  2.0503678
Log Pis Max                  8.123017
Log Pis Min                  -3.6047175
Policy mu Mean               0.023063598
Policy mu Std                0.944283
Policy mu Max                2.6393955
Policy mu Min                -2.8509092
Policy log std Mean          -0.48953536
Policy log std Std           0.23553881
Policy log std Max           -0.07240376
Policy log std Min           -1.5338427
Z mean eval                  0.019010346
Z variance eval              0.005077145
total_rewards                [1896.34078271 3096.9368479  3058.76090205 3120.15994245 3093.17414928
 3072.4669895  2438.38493887 1659.11345489 3057.17457034 3044.52588618]
total_rewards_mean           2753.7038464171565
total_rewards_std            526.4319803664799
total_rewards_max            3120.1599424478845
total_rewards_min            1659.1134548854598
Number of train steps total  123000
Number of env steps total    617000
Number of rollouts total     0
Train Time (s)               42.87032354110852
(Previous) Eval Time (s)     29.346929799299687
Sample Time (s)              21.95562448631972
Epoch Time (s)               94.17287782672793
Total Train Time (s)         8904.915589998476
Epoch                        122
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:16:44.535139 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #122 | Epoch Duration: 95.18934464454651
2020-01-11 03:16:44.535261 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #122 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01875331
Z variance train             0.0050525293
KL Divergence                10.819994
KL Loss                      1.0819994
QF Loss                      229.88452
VF Loss                      271.81903
Policy Loss                  -885.7176
Q Predictions Mean           888.9238
Q Predictions Std            488.38284
Q Predictions Max            1352.8507
Q Predictions Min            -9.048462
V Predictions Mean           896.0752
V Predictions Std            489.5473
V Predictions Max            1360.2528
V Predictions Min            -10.681637
Log Pis Mean                 -0.09489505
Log Pis Std                  2.003856
Log Pis Max                  7.1348124
Log Pis Min                  -4.5093207
Policy mu Mean               0.10415077
Policy mu Std                0.92078555
Policy mu Max                2.5799417
Policy mu Min                -3.2133272
Policy log std Mean          -0.4723676
Policy log std Std           0.24462906
Policy log std Max           0.05161059
Policy log std Min           -1.358412
Z mean eval                  0.026332323
Z variance eval              0.005071006
total_rewards                [3139.0986262  2062.57108171 3046.69283872 3074.96780992 3009.79110478
 3117.59800832 3074.95012661 2859.76310106 2298.21691577 3064.53622426]
total_rewards_mean           2874.8185837350657
total_rewards_std            358.4817173495213
total_rewards_max            3139.0986262035417
total_rewards_min            2062.571081710294
Number of train steps total  124000
Number of env steps total    622000
Number of rollouts total     0
Train Time (s)               43.72837990615517
(Previous) Eval Time (s)     30.36315782321617
Sample Time (s)              22.678536923602223
Epoch Time (s)               96.77007465297356
Total Train Time (s)         9001.96009443188
Epoch                        123
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:18:21.581653 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #123 | Epoch Duration: 97.04628276824951
2020-01-11 03:18:21.581827 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #123 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026028523
Z variance train             0.0050653424
KL Divergence                10.81344
KL Loss                      1.081344
QF Loss                      872.85864
VF Loss                      207.76425
Policy Loss                  -874.44806
Q Predictions Mean           870.1821
Q Predictions Std            489.72006
Q Predictions Max            1344.8545
Q Predictions Min            -42.266747
V Predictions Mean           879.0161
V Predictions Std            491.821
V Predictions Max            1364.727
V Predictions Min            -5.4404655
Log Pis Mean                 0.084415875
Log Pis Std                  2.2725616
Log Pis Max                  10.266361
Log Pis Min                  -4.095822
Policy mu Mean               -0.054937664
Policy mu Std                0.9659764
Policy mu Max                2.9437428
Policy mu Min                -3.1355133
Policy log std Mean          -0.51683617
Policy log std Std           0.25806075
Policy log std Max           0.039902866
Policy log std Min           -1.405285
Z mean eval                  0.019047732
Z variance eval              0.004752905
total_rewards                [2059.85851195 3275.58007807 3164.71843513 1168.91201195 2482.31629396
 3120.86085594  972.93623391 3193.02433168 2044.61303161 3178.32730657]
total_rewards_mean           2466.11470907662
total_rewards_std            828.4265386402383
total_rewards_max            3275.5800780653467
total_rewards_min            972.9362339078629
Number of train steps total  125000
Number of env steps total    627000
Number of rollouts total     0
Train Time (s)               43.60309116076678
(Previous) Eval Time (s)     30.6391060850583
Sample Time (s)              22.174874181393534
Epoch Time (s)               96.41707142721862
Total Train Time (s)         9093.28955172794
Epoch                        124
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:19:52.913496 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #124 | Epoch Duration: 91.33154201507568
2020-01-11 03:19:52.913638 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #124 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018067807
Z variance train             0.0047417535
KL Divergence                11.090187
KL Loss                      1.1090187
QF Loss                      223.98943
VF Loss                      195.9376
Policy Loss                  -908.51166
Q Predictions Mean           906.2285
Q Predictions Std            477.73486
Q Predictions Max            1368.137
Q Predictions Min            -20.540705
V Predictions Mean           911.7285
V Predictions Std            478.39783
V Predictions Max            1361.1521
V Predictions Min            -7.0832014
Log Pis Mean                 0.021958256
Log Pis Std                  2.0721087
Log Pis Max                  6.210571
Log Pis Min                  -9.696642
Policy mu Mean               0.09235423
Policy mu Std                0.90348685
Policy mu Max                2.576947
Policy mu Min                -2.7626727
Policy log std Mean          -0.5267581
Policy log std Std           0.26784903
Policy log std Max           -0.084860966
Policy log std Min           -1.5678151
Z mean eval                  0.016531883
Z variance eval              0.0041854484
total_rewards                [1170.52338979 2544.96869303 3174.95157157 2814.24553772 3112.00515961
 1765.45523704 2098.95983358 2196.53610915 3130.35967851 1410.34602056]
total_rewards_mean           2341.8351230558037
total_rewards_std            694.651555162472
total_rewards_max            3174.95157156671
total_rewards_min            1170.523389792896
Number of train steps total  126000
Number of env steps total    632000
Number of rollouts total     0
Train Time (s)               43.316587889101356
(Previous) Eval Time (s)     25.55335488822311
Sample Time (s)              22.254893015138805
Epoch Time (s)               91.12483579246327
Total Train Time (s)         9180.091351644602
Epoch                        125
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:21:19.719207 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #125 | Epoch Duration: 86.80544352531433
2020-01-11 03:21:19.719428 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #125 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016538655
Z variance train             0.004180261
KL Divergence                11.385033
KL Loss                      1.1385033
QF Loss                      295.4803
VF Loss                      85.01192
Policy Loss                  -927.29553
Q Predictions Mean           928.7007
Q Predictions Std            482.29504
Q Predictions Max            1365.919
Q Predictions Min            -2.4885185
V Predictions Mean           927.9338
V Predictions Std            479.33868
V Predictions Max            1377.9886
V Predictions Min            -2.1084979
Log Pis Mean                 -0.050169773
Log Pis Std                  2.0655913
Log Pis Max                  9.454192
Log Pis Min                  -4.915715
Policy mu Mean               0.14069301
Policy mu Std                0.9051456
Policy mu Max                2.8447561
Policy mu Min                -2.6614497
Policy log std Mean          -0.5149277
Policy log std Std           0.2441572
Policy log std Max           0.05313784
Policy log std Min           -1.3542919
Z mean eval                  0.025821935
Z variance eval              0.0044102767
total_rewards                [1020.95903195 2840.84925076 3170.62537399 1734.31897912 1247.68953795
 1695.38809132 3004.33140193 3086.23530242 1463.50126551 3073.39580567]
total_rewards_mean           2233.7294040613383
total_rewards_std            827.4999757453704
total_rewards_max            3170.6253739926815
total_rewards_min            1020.9590319455764
Number of train steps total  127000
Number of env steps total    637000
Number of rollouts total     0
Train Time (s)               43.213033626787364
(Previous) Eval Time (s)     21.233695851173252
Sample Time (s)              21.533573892433196
Epoch Time (s)               85.98030337039381
Total Train Time (s)         9268.988794166595
Epoch                        126
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:22:48.618241 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #126 | Epoch Duration: 88.89864230155945
2020-01-11 03:22:48.618414 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #126 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02601635
Z variance train             0.004416878
KL Divergence                11.243332
KL Loss                      1.1243333
QF Loss                      481.03326
VF Loss                      213.8996
Policy Loss                  -936.2822
Q Predictions Mean           939.6149
Q Predictions Std            466.72714
Q Predictions Max            1388.522
Q Predictions Min            -12.934207
V Predictions Mean           937.80505
V Predictions Std            462.41235
V Predictions Max            1384.921
V Predictions Min            -6.4523
Log Pis Mean                 0.02181597
Log Pis Std                  2.1927242
Log Pis Max                  9.230028
Log Pis Min                  -4.3727283
Policy mu Mean               -0.011008185
Policy mu Std                0.9436836
Policy mu Max                3.630732
Policy mu Min                -2.8939428
Policy log std Mean          -0.5234112
Policy log std Std           0.2538065
Policy log std Max           0.005809784
Policy log std Min           -1.3941154
Z mean eval                  0.021885026
Z variance eval              0.003972023
total_rewards                [ 395.83677414 1115.50772893 1137.04956919 1376.33650586 1130.32933314
  684.38549506 3067.23877073 1314.39772277 3079.17696829 1104.03847998]
total_rewards_mean           1440.42973480762
total_rewards_std            861.4931607881505
total_rewards_max            3079.1769682931395
total_rewards_min            395.8367741372756
Number of train steps total  128000
Number of env steps total    642000
Number of rollouts total     0
Train Time (s)               44.4380087046884
(Previous) Eval Time (s)     24.151785848662257
Sample Time (s)              21.942820051684976
Epoch Time (s)               90.53261460503563
Total Train Time (s)         9351.306206384208
Epoch                        127
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:24:10.937324 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #127 | Epoch Duration: 82.31878232955933
2020-01-11 03:24:10.937459 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #127 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022385666
Z variance train             0.0039728456
KL Divergence                11.581932
KL Loss                      1.1581932
QF Loss                      337.61853
VF Loss                      138.80327
Policy Loss                  -928.5794
Q Predictions Mean           929.6049
Q Predictions Std            463.36557
Q Predictions Max            1380.3304
Q Predictions Min            -54.853703
V Predictions Mean           932.2003
V Predictions Std            462.564
V Predictions Max            1378.471
V Predictions Min            -1.4146216
Log Pis Mean                 0.038079917
Log Pis Std                  2.1939363
Log Pis Max                  10.619939
Log Pis Min                  -5.940695
Policy mu Mean               -0.032534223
Policy mu Std                0.9632284
Policy mu Max                2.5320327
Policy mu Min                -2.8970835
Policy log std Mean          -0.5173016
Policy log std Std           0.24662182
Policy log std Max           -0.014328688
Policy log std Min           -1.3462734
Z mean eval                  0.010035462
Z variance eval              0.0047996193
total_rewards                [1642.06243351 1998.01586765 1546.6549963  1472.00146718 1583.96957573
  944.26295853 2905.78692491 3171.12382749 2002.30167424  945.64352068]
total_rewards_mean           1821.1823246219797
total_rewards_std            698.8551811030178
total_rewards_max            3171.123827494433
total_rewards_min            944.2629585260503
Number of train steps total  129000
Number of env steps total    647000
Number of rollouts total     0
Train Time (s)               42.822586468886584
(Previous) Eval Time (s)     15.937729877885431
Sample Time (s)              23.217091912403703
Epoch Time (s)               81.97740825917572
Total Train Time (s)         9435.827414691914
Epoch                        128
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:25:35.460615 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #128 | Epoch Duration: 84.52305889129639
2020-01-11 03:25:35.460750 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #128 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010032657
Z variance train             0.004815782
KL Divergence                11.210521
KL Loss                      1.1210521
QF Loss                      268.32434
VF Loss                      119.14505
Policy Loss                  -909.99646
Q Predictions Mean           902.8046
Q Predictions Std            487.1875
Q Predictions Max            1371.7628
Q Predictions Min            -7.9326253
V Predictions Mean           908.5808
V Predictions Std            486.0816
V Predictions Max            1370.2372
V Predictions Min            -4.44941
Log Pis Mean                 -0.065018654
Log Pis Std                  2.0144792
Log Pis Max                  7.192321
Log Pis Min                  -4.644226
Policy mu Mean               0.055690665
Policy mu Std                0.8796369
Policy mu Max                2.3200233
Policy mu Min                -2.7617855
Policy log std Mean          -0.50131637
Policy log std Std           0.2523126
Policy log std Max           -0.017659903
Policy log std Min           -1.3631854
Z mean eval                  0.022333845
Z variance eval              0.005017449
total_rewards                [1905.20661305  858.19512285 2036.63840348 2071.27585697 1403.72474379
 2039.60894704 1494.82359542 2088.55751732 1917.72619071 1446.76816216]
total_rewards_mean           1726.2525152771782
total_rewards_std            387.6523003607804
total_rewards_max            2088.5575173216093
total_rewards_min            858.1951228490469
Number of train steps total  130000
Number of env steps total    652000
Number of rollouts total     0
Train Time (s)               43.44381337380037
(Previous) Eval Time (s)     18.483139974065125
Sample Time (s)              21.76499141473323
Epoch Time (s)               83.69194476259872
Total Train Time (s)         9519.084540211596
Epoch                        129
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:26:58.718771 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #129 | Epoch Duration: 83.25792121887207
2020-01-11 03:26:58.718899 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #129 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023064177
Z variance train             0.0050064055
KL Divergence                11.174709
KL Loss                      1.117471
QF Loss                      449.02966
VF Loss                      769.8541
Policy Loss                  -949.436
Q Predictions Mean           948.4895
Q Predictions Std            465.5671
Q Predictions Max            1364.3525
Q Predictions Min            -2.0951014
V Predictions Mean           947.0122
V Predictions Std            464.06778
V Predictions Max            1355.527
V Predictions Min            -3.3777423
Log Pis Mean                 -0.18862906
Log Pis Std                  2.1596797
Log Pis Max                  6.7634726
Log Pis Min                  -4.8181157
Policy mu Mean               0.11690769
Policy mu Std                0.9030401
Policy mu Max                2.6628978
Policy mu Min                -2.8032024
Policy log std Mean          -0.4924545
Policy log std Std           0.24410342
Policy log std Max           -0.02337867
Policy log std Min           -1.4862311
Z mean eval                  0.0060274284
Z variance eval              0.004959279
total_rewards                [1455.06953994 3137.60058899 1064.60305142  906.7802232   989.25213815
 1617.65787842 2460.18669291 2233.10935513 2731.59680184 1440.13995572]
total_rewards_mean           1803.5996225718827
total_rewards_std            745.5223542734124
total_rewards_max            3137.6005889887233
total_rewards_min            906.7802232023118
Number of train steps total  131000
Number of env steps total    657000
Number of rollouts total     0
Train Time (s)               43.24754459504038
(Previous) Eval Time (s)     18.048873665742576
Sample Time (s)              21.7079687602818
Epoch Time (s)               83.00438702106476
Total Train Time (s)         9602.94725055201
Epoch                        130
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:28:22.582909 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #130 | Epoch Duration: 83.86391162872314
2020-01-11 03:28:22.583048 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #130 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.006248002
Z variance train             0.004963183
KL Divergence                11.244337
KL Loss                      1.1244338
QF Loss                      437.4759
VF Loss                      208.02818
Policy Loss                  -956.1624
Q Predictions Mean           954.19257
Q Predictions Std            479.3369
Q Predictions Max            1386.2882
Q Predictions Min            -21.533194
V Predictions Mean           957.92224
V Predictions Std            478.10568
V Predictions Max            1373.479
V Predictions Min            -14.127425
Log Pis Mean                 0.14733304
Log Pis Std                  2.2603524
Log Pis Max                  7.193545
Log Pis Min                  -4.2711234
Policy mu Mean               -0.01362177
Policy mu Std                0.9890931
Policy mu Max                2.8479798
Policy mu Min                -3.793687
Policy log std Mean          -0.5034192
Policy log std Std           0.24896337
Policy log std Max           0.07351816
Policy log std Min           -1.6322687
Z mean eval                  0.011208505
Z variance eval              0.004066188
total_rewards                [1915.65843009  900.14480445  919.96653356 3120.34961532 2127.57003578
  934.18501492 1243.85697303 1967.8241931  2237.05338953 1744.62100275]
total_rewards_mean           1711.1229992526278
total_rewards_std            681.9374812350844
total_rewards_max            3120.349615323107
total_rewards_min            900.1448044460457
Number of train steps total  132000
Number of env steps total    662000
Number of rollouts total     0
Train Time (s)               43.03009939007461
(Previous) Eval Time (s)     18.90814090380445
Sample Time (s)              22.619101902935654
Epoch Time (s)               84.55734219681472
Total Train Time (s)         9685.896231159102
Epoch                        131
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:29:45.533133 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #131 | Epoch Duration: 82.94998145103455
2020-01-11 03:29:45.533262 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #131 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011248742
Z variance train             0.00406344
KL Divergence                11.705728
KL Loss                      1.1705728
QF Loss                      639.3622
VF Loss                      299.64337
Policy Loss                  -944.2838
Q Predictions Mean           943.12933
Q Predictions Std            484.96448
Q Predictions Max            1405.8414
Q Predictions Min            -1.8896202
V Predictions Mean           950.78687
V Predictions Std            488.6843
V Predictions Max            1431.4949
V Predictions Min            -5.475625
Log Pis Mean                 -0.006414272
Log Pis Std                  2.2672808
Log Pis Max                  9.962587
Log Pis Min                  -5.153961
Policy mu Mean               0.17147733
Policy mu Std                0.94662553
Policy mu Max                2.7794356
Policy mu Min                -3.8530514
Policy log std Mean          -0.4866493
Policy log std Std           0.25288194
Policy log std Max           0.09680456
Policy log std Min           -1.5454247
Z mean eval                  0.009164038
Z variance eval              0.003969412
total_rewards                [3092.37149444 1670.69507943 1149.02881108 1009.09640203 1614.30852723
 3037.24090071 1769.11147431 2718.84014984 3151.30026871 3177.52368692]
total_rewards_mean           2238.951679470097
total_rewards_std            833.2767654731894
total_rewards_max            3177.523686919404
total_rewards_min            1009.0964020316187
Number of train steps total  133000
Number of env steps total    667000
Number of rollouts total     0
Train Time (s)               43.11643958278
(Previous) Eval Time (s)     17.300540685188025
Sample Time (s)              21.703558780252934
Epoch Time (s)               82.12053904822096
Total Train Time (s)         9773.171482762322
Epoch                        132
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:31:12.814939 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #132 | Epoch Duration: 87.28152084350586
2020-01-11 03:31:12.815252 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #132 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.009197845
Z variance train             0.003967883
KL Divergence                11.864384
KL Loss                      1.1864384
QF Loss                      201.95215
VF Loss                      186.49745
Policy Loss                  -951.36694
Q Predictions Mean           949.99786
Q Predictions Std            480.76547
Q Predictions Max            1379.3411
Q Predictions Min            -11.420288
V Predictions Mean           953.9396
V Predictions Std            474.66605
V Predictions Max            1374.8281
V Predictions Min            -1.7494539
Log Pis Mean                 -0.0051606596
Log Pis Std                  2.2704346
Log Pis Max                  13.996532
Log Pis Min                  -9.123375
Policy mu Mean               0.054818425
Policy mu Std                0.93028665
Policy mu Max                3.8442957
Policy mu Min                -2.8181057
Policy log std Mean          -0.5049351
Policy log std Std           0.2686131
Policy log std Max           0.083738565
Policy log std Min           -2.8372371
Z mean eval                  0.01186206
Z variance eval              0.003539427
total_rewards                [1665.31637435 1122.20383789 2228.44331286 1485.076564   2527.84795348
 1784.1860496  1185.68018356 1355.44734141 2215.05897622 2634.44726225]
total_rewards_mean           1820.370785562147
total_rewards_std            522.4694139347201
total_rewards_max            2634.4472622478816
total_rewards_min            1122.2038378859122
Number of train steps total  134000
Number of env steps total    672000
Number of rollouts total     0
Train Time (s)               43.14620371395722
(Previous) Eval Time (s)     22.46123566199094
Sample Time (s)              22.038645836059004
Epoch Time (s)               87.64608521200716
Total Train Time (s)         9855.91353331739
Epoch                        133
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:32:35.556542 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #133 | Epoch Duration: 82.74106454849243
2020-01-11 03:32:35.556696 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #133 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01187591
Z variance train             0.0035434905
KL Divergence                11.849912
KL Loss                      1.1849912
QF Loss                      249.48666
VF Loss                      137.58734
Policy Loss                  -1011.4937
Q Predictions Mean           1010.96106
Q Predictions Std            418.79895
Q Predictions Max            1373.2122
Q Predictions Min            0.08203131
V Predictions Mean           1016.1256
V Predictions Std            420.04013
V Predictions Max            1376.6168
V Predictions Min            -4.81613
Log Pis Mean                 0.135379
Log Pis Std                  2.109438
Log Pis Max                  8.191335
Log Pis Min                  -5.1337914
Policy mu Mean               0.019092318
Policy mu Std                0.94287574
Policy mu Max                2.5082982
Policy mu Min                -2.8719532
Policy log std Mean          -0.5216958
Policy log std Std           0.23795582
Policy log std Max           0.0112810135
Policy log std Min           -1.3816572
Z mean eval                  0.019093387
Z variance eval              0.0036671378
total_rewards                [2006.35949339 1597.87372175 1699.0603382  1003.2682224  2026.51170861
 1819.08659847 1011.56195155 1172.68748293 2999.13024299 2166.17974847]
total_rewards_mean           1750.1719508760489
total_rewards_std            578.135764279009
total_rewards_max            2999.1302429924303
total_rewards_min            1003.2682223954278
Number of train steps total  135000
Number of env steps total    677000
Number of rollouts total     0
Train Time (s)               43.61284227576107
(Previous) Eval Time (s)     17.555986414663494
Sample Time (s)              22.32670664647594
Epoch Time (s)               83.4955353369005
Total Train Time (s)         9939.437526387628
Epoch                        134
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:33:59.081645 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #134 | Epoch Duration: 83.52483463287354
2020-01-11 03:33:59.081767 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #134 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01812284
Z variance train             0.0036631904
KL Divergence                11.605574
KL Loss                      1.1605574
QF Loss                      211.24744
VF Loss                      184.25854
Policy Loss                  -1000.222
Q Predictions Mean           997.1844
Q Predictions Std            442.50793
Q Predictions Max            1402.2571
Q Predictions Min            2.098116
V Predictions Mean           996.15967
V Predictions Std            441.78574
V Predictions Max            1390.7026
V Predictions Min            3.6819944
Log Pis Mean                 -0.013490258
Log Pis Std                  2.0870156
Log Pis Max                  9.356714
Log Pis Min                  -5.888734
Policy mu Mean               0.08983049
Policy mu Std                0.95554155
Policy mu Max                2.280906
Policy mu Min                -3.077396
Policy log std Mean          -0.4965665
Policy log std Std           0.23547433
Policy log std Max           0.09628871
Policy log std Min           -1.3854412
Z mean eval                  0.009201434
Z variance eval              0.003784772
total_rewards                [3094.48357275 1952.98964281 1659.09286578 1942.57519003 2126.3515796
 1981.70497612 2938.43859805 2382.17652517 2590.2452251  1312.14591058]
total_rewards_mean           2198.0204085986143
total_rewards_std            528.3991604649806
total_rewards_max            3094.4835727515674
total_rewards_min            1312.145910582488
Number of train steps total  136000
Number of env steps total    682000
Number of rollouts total     0
Train Time (s)               42.99251943966374
(Previous) Eval Time (s)     17.585062869358808
Sample Time (s)              21.67760471254587
Epoch Time (s)               82.25518702156842
Total Train Time (s)         10027.776517492719
Epoch                        135
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:35:27.422410 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #135 | Epoch Duration: 88.34055256843567
2020-01-11 03:35:27.422530 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #135 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008988291
Z variance train             0.0037841934
KL Divergence                11.512938
KL Loss                      1.1512938
QF Loss                      233.79416
VF Loss                      89.182526
Policy Loss                  -1003.814
Q Predictions Mean           1001.46716
Q Predictions Std            444.7154
Q Predictions Max            1408.8646
Q Predictions Min            1.4363747
V Predictions Mean           1004.0492
V Predictions Std            443.5488
V Predictions Max            1402.7987
V Predictions Min            -1.5642576
Log Pis Mean                 0.15626186
Log Pis Std                  2.0593505
Log Pis Max                  9.907537
Log Pis Min                  -3.5251317
Policy mu Mean               0.056949716
Policy mu Std                0.9198221
Policy mu Max                2.4450881
Policy mu Min                -3.052739
Policy log std Mean          -0.5148507
Policy log std Std           0.23154049
Policy log std Max           0.053203225
Policy log std Min           -1.292322
Z mean eval                  0.024176147
Z variance eval              0.0035844252
total_rewards                [1739.61474119 1443.26320524 3076.38168218 3012.44059035 1427.30082167
 1160.08067658 1421.67215965 1464.99280764 1629.02337769 1735.57118503]
total_rewards_mean           1811.034124722238
total_rewards_std            637.6519155594702
total_rewards_max            3076.3816821759274
total_rewards_min            1160.08067657747
Number of train steps total  137000
Number of env steps total    687000
Number of rollouts total     0
Train Time (s)               43.22913419920951
(Previous) Eval Time (s)     23.670192253310233
Sample Time (s)              21.482233677059412
Epoch Time (s)               88.38156012957916
Total Train Time (s)         10109.329826458823
Epoch                        136
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:36:48.981585 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #136 | Epoch Duration: 81.55891799926758
2020-01-11 03:36:48.981863 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #136 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024083165
Z variance train             0.0035812226
KL Divergence                11.741391
KL Loss                      1.1741391
QF Loss                      279.53967
VF Loss                      100.67493
Policy Loss                  -984.49713
Q Predictions Mean           983.5575
Q Predictions Std            461.49933
Q Predictions Max            1407.9127
Q Predictions Min            -8.282548
V Predictions Mean           985.66406
V Predictions Std            461.56628
V Predictions Max            1395.9998
V Predictions Min            -1.438108
Log Pis Mean                 0.02634554
Log Pis Std                  1.9916326
Log Pis Max                  8.170589
Log Pis Min                  -4.0148144
Policy mu Mean               0.06801868
Policy mu Std                0.9171049
Policy mu Max                2.6264508
Policy mu Min                -3.7046602
Policy log std Mean          -0.4901143
Policy log std Std           0.23144409
Policy log std Max           0.044644237
Policy log std Min           -1.3738716
Z mean eval                  0.02412247
Z variance eval              0.0035379112
total_rewards                [1234.1328986  2980.5072878  3073.74618845 3052.74216278 3031.67023514
 2967.03869975 2990.64641101 2279.89683771 3039.79145906 2937.04881629]
total_rewards_mean           2758.7220996604105
total_rewards_std            554.1667877603652
total_rewards_max            3073.7461884544446
total_rewards_min            1234.1328986025146
Number of train steps total  138000
Number of env steps total    692000
Number of rollouts total     0
Train Time (s)               42.73790031997487
(Previous) Eval Time (s)     16.84728933684528
Sample Time (s)              21.27467077318579
Epoch Time (s)               80.85986043000594
Total Train Time (s)         10203.946948973928
Epoch                        137
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:38:23.598166 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #137 | Epoch Duration: 94.61611008644104
2020-01-11 03:38:23.598287 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #137 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025038412
Z variance train             0.0035397192
KL Divergence                11.7114725
KL Loss                      1.1711472
QF Loss                      241.15578
VF Loss                      190.00052
Policy Loss                  -1002.22925
Q Predictions Mean           1004.21765
Q Predictions Std            439.2868
Q Predictions Max            1401.1398
Q Predictions Min            -10.146236
V Predictions Mean           1012.11633
V Predictions Std            440.03836
V Predictions Max            1412.2391
V Predictions Min            -2.8748782
Log Pis Mean                 -0.17533688
Log Pis Std                  1.9984506
Log Pis Max                  6.0413094
Log Pis Min                  -5.827075
Policy mu Mean               0.14910857
Policy mu Std                0.870928
Policy mu Max                2.6315868
Policy mu Min                -2.8731365
Policy log std Mean          -0.48648217
Policy log std Std           0.21285743
Policy log std Max           0.111813515
Policy log std Min           -1.2415456
Z mean eval                  0.017635155
Z variance eval              0.0035988204
total_rewards                [3011.36854011 2969.64433873 3089.33721543 3033.67661418 3017.31550799
 3028.58301615 3110.6953878  3022.97096923 3038.1643355  3063.79605307]
total_rewards_mean           3038.5551978184367
total_rewards_std            38.37360071535721
total_rewards_max            3110.6953877985256
total_rewards_min            2969.644338727219
Number of train steps total  139000
Number of env steps total    697000
Number of rollouts total     0
Train Time (s)               42.570394774433225
(Previous) Eval Time (s)     30.603322422597557
Sample Time (s)              22.152839807327837
Epoch Time (s)               95.32655700435862
Total Train Time (s)         10301.42495769076
Epoch                        138
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:40:01.082153 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #138 | Epoch Duration: 97.48372721672058
2020-01-11 03:40:01.082435 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #138 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018618625
Z variance train             0.003604211
KL Divergence                11.617369
KL Loss                      1.1617368
QF Loss                      350.36478
VF Loss                      272.27948
Policy Loss                  -999.9701
Q Predictions Mean           1003.4337
Q Predictions Std            448.50494
Q Predictions Max            1439.7866
Q Predictions Min            -6.3893995
V Predictions Mean           1011.23334
V Predictions Std            451.25427
V Predictions Max            1444.6997
V Predictions Min            -0.4354547
Log Pis Mean                 0.09642397
Log Pis Std                  2.3174171
Log Pis Max                  12.385471
Log Pis Min                  -5.931048
Policy mu Mean               0.14871775
Policy mu Std                0.941053
Policy mu Max                4.069145
Policy mu Min                -2.9720173
Policy log std Mean          -0.51016015
Policy log std Std           0.23675773
Policy log std Max           0.03053224
Policy log std Min           -1.5295529
Z mean eval                  0.039774932
Z variance eval              0.0039992826
total_rewards                [2552.64926471 1132.08495143 1612.34569628 2351.07806795 3138.34429823
 1964.06063551  968.36878344 1623.16882815 1242.10582412 2500.92821625]
total_rewards_mean           1908.5134566055435
total_rewards_std            676.5536395625251
total_rewards_max            3138.3442982278602
total_rewards_min            968.3687834362302
Number of train steps total  140000
Number of env steps total    702000
Number of rollouts total     0
Train Time (s)               43.33122874982655
(Previous) Eval Time (s)     32.76023043971509
Sample Time (s)              22.995913608931005
Epoch Time (s)               99.08737279847264
Total Train Time (s)         10385.705089869909
Epoch                        139
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:41:25.362518 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #139 | Epoch Duration: 84.27987360954285
2020-01-11 03:41:25.362679 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #139 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03943505
Z variance train             0.003998709
KL Divergence                11.428109
KL Loss                      1.142811
QF Loss                      274.21994
VF Loss                      134.9208
Policy Loss                  -1038.11
Q Predictions Mean           1036.7681
Q Predictions Std            456.5535
Q Predictions Max            1437.6802
Q Predictions Min            -9.199526
V Predictions Mean           1043.0066
V Predictions Std            458.7649
V Predictions Max            1453.4801
V Predictions Min            -17.541191
Log Pis Mean                 -0.084487
Log Pis Std                  1.9430639
Log Pis Max                  7.272213
Log Pis Min                  -4.2254086
Policy mu Mean               0.0710152
Policy mu Std                0.9316406
Policy mu Max                2.3644338
Policy mu Min                -3.0859132
Policy log std Mean          -0.505387
Policy log std Std           0.23503534
Policy log std Max           0.15170369
Policy log std Min           -1.3265102
Z mean eval                  0.010809677
Z variance eval              0.004572298
total_rewards                [1579.22425109 2895.74888885 2846.44245039 1126.12720027 2155.64025786
 2083.76253235 1477.21697537 1929.1919753  1355.69872819 2710.42001895]
total_rewards_mean           2015.9473278621015
total_rewards_std            607.1548627078924
total_rewards_max            2895.748888852412
total_rewards_min            1126.1272002702005
Number of train steps total  141000
Number of env steps total    707000
Number of rollouts total     0
Train Time (s)               43.219623473938555
(Previous) Eval Time (s)     17.952504062559456
Sample Time (s)              21.81598324328661
Epoch Time (s)               82.98811077978462
Total Train Time (s)         10472.947934045456
Epoch                        140
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:42:52.609835 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #140 | Epoch Duration: 87.24702596664429
2020-01-11 03:42:52.609976 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #140 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011092135
Z variance train             0.0045840037
KL Divergence                11.060213
KL Loss                      1.1060213
QF Loss                      468.05447
VF Loss                      219.29744
Policy Loss                  -1018.47577
Q Predictions Mean           1015.46936
Q Predictions Std            473.74002
Q Predictions Max            1428.9827
Q Predictions Min            -14.686026
V Predictions Mean           1015.8453
V Predictions Std            472.17932
V Predictions Max            1426.2467
V Predictions Min            -4.2831793
Log Pis Mean                 -0.053660467
Log Pis Std                  2.1696327
Log Pis Max                  9.800129
Log Pis Min                  -4.7035213
Policy mu Mean               0.23106872
Policy mu Std                0.8870803
Policy mu Max                3.916741
Policy mu Min                -3.8956578
Policy log std Mean          -0.49608037
Policy log std Std           0.23575358
Policy log std Max           -0.020592332
Policy log std Min           -1.9642699
Z mean eval                  0.009489909
Z variance eval              0.0046280497
total_rewards                [3006.10245711 3059.68222122 2998.7692553  2984.73133232 3030.94508264
 2950.71079006 2994.76892421 3017.65218637 2946.28399909 3055.9331833 ]
total_rewards_mean           3004.557943161184
total_rewards_std            36.55957322004591
total_rewards_max            3059.6822212186644
total_rewards_min            2946.2839990851558
Number of train steps total  142000
Number of env steps total    712000
Number of rollouts total     0
Train Time (s)               42.625644562765956
(Previous) Eval Time (s)     22.211178162135184
Sample Time (s)              21.65521146217361
Epoch Time (s)               86.49203418707475
Total Train Time (s)         10569.315351812635
Epoch                        141
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:44:28.977546 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #141 | Epoch Duration: 96.36745285987854
2020-01-11 03:44:28.977668 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #141 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.009425148
Z variance train             0.004623499
KL Divergence                11.108592
KL Loss                      1.1108593
QF Loss                      302.45276
VF Loss                      132.71133
Policy Loss                  -1044.1539
Q Predictions Mean           1046.0889
Q Predictions Std            443.8815
Q Predictions Max            1423.5848
Q Predictions Min            -0.3938726
V Predictions Mean           1042.8406
V Predictions Std            441.22675
V Predictions Max            1416.7711
V Predictions Min            -11.863066
Log Pis Mean                 -0.1864971
Log Pis Std                  2.3471913
Log Pis Max                  10.334478
Log Pis Min                  -7.8283815
Policy mu Mean               0.06410179
Policy mu Std                0.915819
Policy mu Max                2.6894782
Policy mu Min                -3.1810324
Policy log std Mean          -0.4761246
Policy log std Std           0.22659586
Policy log std Max           0.11286795
Policy log std Min           -1.4526131
Z mean eval                  0.017026816
Z variance eval              0.004231675
total_rewards                [ 955.67143645 3134.51927484 3075.4618355  3144.95400159 3110.44473706
 3125.76656196 3126.42131809 3071.16111368 3119.61996924 3136.50416381]
total_rewards_mean           2900.0524412219174
total_rewards_std            648.551429169628
total_rewards_max            3144.954001590973
total_rewards_min            955.6714364512459
Number of train steps total  143000
Number of env steps total    717000
Number of rollouts total     0
Train Time (s)               43.467789269052446
(Previous) Eval Time (s)     32.08636728301644
Sample Time (s)              19.762675628531724
Epoch Time (s)               95.31683218060061
Total Train Time (s)         10663.482422633562
Epoch                        142
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:46:03.146936 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #142 | Epoch Duration: 94.16917705535889
2020-01-11 03:46:03.147058 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #142 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017199852
Z variance train             0.004232922
KL Divergence                11.351509
KL Loss                      1.1351509
QF Loss                      651.13525
VF Loss                      145.23093
Policy Loss                  -1018.0499
Q Predictions Mean           1017.86005
Q Predictions Std            461.6949
Q Predictions Max            1440.0378
Q Predictions Min            -24.590204
V Predictions Mean           1018.5145
V Predictions Std            461.84967
V Predictions Max            1440.5153
V Predictions Min            -14.497813
Log Pis Mean                 0.16618216
Log Pis Std                  2.300492
Log Pis Max                  10.490443
Log Pis Min                  -6.2290516
Policy mu Mean               0.07743355
Policy mu Std                0.9466548
Policy mu Max                3.2974148
Policy mu Min                -3.5551202
Policy log std Mean          -0.49408603
Policy log std Std           0.24184747
Policy log std Max           0.07081428
Policy log std Min           -1.4849392
Z mean eval                  0.012797579
Z variance eval              0.0050264727
total_rewards                [3116.05639485 1572.6368955  3171.47438488 1514.14257655 1168.84148362
 3194.38093759 3250.79557833 1559.81871262 2110.28667425 3221.90425279]
total_rewards_mean           2388.033789097563
total_rewards_std            831.3700233079182
total_rewards_max            3250.795578325863
total_rewards_min            1168.8414836226684
Number of train steps total  144000
Number of env steps total    722000
Number of rollouts total     0
Train Time (s)               43.75540546793491
(Previous) Eval Time (s)     30.938512248918414
Sample Time (s)              21.953234632965177
Epoch Time (s)               96.6471523498185
Total Train Time (s)         10753.422592076939
Epoch                        143
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:47:33.087961 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #143 | Epoch Duration: 89.94080567359924
2020-01-11 03:47:33.088090 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #143 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012923854
Z variance train             0.0050347643
KL Divergence                10.931251
KL Loss                      1.0931251
QF Loss                      304.3889
VF Loss                      143.5704
Policy Loss                  -1018.97876
Q Predictions Mean           1020.963
Q Predictions Std            487.3524
Q Predictions Max            1441.5349
Q Predictions Min            4.2181587
V Predictions Mean           1014.3578
V Predictions Std            486.101
V Predictions Max            1420.748
V Predictions Min            -29.15026
Log Pis Mean                 -0.2697108
Log Pis Std                  1.9544184
Log Pis Max                  7.111436
Log Pis Min                  -5.7372065
Policy mu Mean               0.04913051
Policy mu Std                0.8499473
Policy mu Max                2.758507
Policy mu Min                -2.6468067
Policy log std Mean          -0.46800503
Policy log std Std           0.2383921
Policy log std Max           0.09678948
Policy log std Min           -1.6180203
Z mean eval                  0.019181453
Z variance eval              0.0046919924
total_rewards                [1044.72540869 1541.99013808 3255.18849562 2153.82125718  992.02852698
 1047.37078678 3307.00760762 1626.3748886  1021.08541694 1056.57173669]
total_rewards_mean           1704.616426320236
total_rewards_std            864.2147492720562
total_rewards_max            3307.0076076233477
total_rewards_min            992.0285269839258
Number of train steps total  145000
Number of env steps total    727000
Number of rollouts total     0
Train Time (s)               43.730216237250715
(Previous) Eval Time (s)     24.231921446043998
Sample Time (s)              22.219699557404965
Epoch Time (s)               90.18183724069968
Total Train Time (s)         10836.253681040369
Epoch                        144
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:48:55.921081 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #144 | Epoch Duration: 82.83289241790771
2020-01-11 03:48:55.921213 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #144 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019357491
Z variance train             0.004693393
KL Divergence                10.999148
KL Loss                      1.0999149
QF Loss                      311.81778
VF Loss                      105.20174
Policy Loss                  -1033.37
Q Predictions Mean           1031.6301
Q Predictions Std            461.61154
Q Predictions Max            1436.3871
Q Predictions Min            -2.825993
V Predictions Mean           1032.6289
V Predictions Std            462.1685
V Predictions Max            1440.5288
V Predictions Min            -3.215837
Log Pis Mean                 -0.06380817
Log Pis Std                  2.0243733
Log Pis Max                  7.191654
Log Pis Min                  -5.5643015
Policy mu Mean               0.15497132
Policy mu Std                0.8784283
Policy mu Max                3.0299425
Policy mu Min                -2.8644018
Policy log std Mean          -0.4897131
Policy log std Std           0.24318014
Policy log std Max           0.04280874
Policy log std Min           -1.2738167
Z mean eval                  0.016498663
Z variance eval              0.0046151825
total_rewards                [3038.44930219 3051.21382873 3089.04491643 3101.14584545 1028.73386428
 3075.48701565 3095.7282244  3086.8745831  3075.73413877 2188.7759866 ]
total_rewards_mean           2783.11877055876
total_rewards_std            642.184211939928
total_rewards_max            3101.145845447034
total_rewards_min            1028.7338642788925
Number of train steps total  146000
Number of env steps total    732000
Number of rollouts total     0
Train Time (s)               43.61115532135591
(Previous) Eval Time (s)     16.88273927103728
Sample Time (s)              21.703510316088796
Epoch Time (s)               82.19740490848199
Total Train Time (s)         10931.48963495344
Epoch                        145
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:50:31.158576 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #145 | Epoch Duration: 95.23724102973938
2020-01-11 03:50:31.158699 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #145 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016893562
Z variance train             0.0046116924
KL Divergence                11.0582485
KL Loss                      1.1058248
QF Loss                      274.9043
VF Loss                      508.45874
Policy Loss                  -958.3195
Q Predictions Mean           956.865
Q Predictions Std            520.8846
Q Predictions Max            1426.7545
Q Predictions Min            -3.4344602
V Predictions Mean           963.57837
V Predictions Std            520.76105
V Predictions Max            1440.9733
V Predictions Min            2.1867368
Log Pis Mean                 -0.3756576
Log Pis Std                  1.9979217
Log Pis Max                  9.458275
Log Pis Min                  -5.2987027
Policy mu Mean               0.106803395
Policy mu Std                0.88312745
Policy mu Max                3.3235233
Policy mu Min                -4.0102177
Policy log std Mean          -0.4605423
Policy log std Std           0.24426305
Policy log std Max           0.0052651465
Policy log std Min           -1.2271328
Z mean eval                  0.021663446
Z variance eval              0.004004711
total_rewards                [3278.50806599 3208.73613267 2839.50276832 3331.14161514 2587.80936201
 1532.06517319 3249.13902779 3247.20309782 2640.32018267 1976.16312907]
total_rewards_mean           2789.0588554666456
total_rewards_std            586.2691272605854
total_rewards_max            3331.141615139526
total_rewards_min            1532.0651731917528
Number of train steps total  147000
Number of env steps total    737000
Number of rollouts total     0
Train Time (s)               43.521247384138405
(Previous) Eval Time (s)     29.922350264154375
Sample Time (s)              21.94538125442341
Epoch Time (s)               95.38897890271619
Total Train Time (s)         11022.474953748751
Epoch                        146
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:52:02.148194 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #146 | Epoch Duration: 90.9893729686737
2020-01-11 03:52:02.148366 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #146 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021739135
Z variance train             0.0040192953
KL Divergence                11.481365
KL Loss                      1.1481365
QF Loss                      487.14606
VF Loss                      460.39386
Policy Loss                  -981.49243
Q Predictions Mean           982.4749
Q Predictions Std            473.5554
Q Predictions Max            1419.8212
Q Predictions Min            -7.3026814
V Predictions Mean           995.9305
V Predictions Std            475.8364
V Predictions Max            1424.2875
V Predictions Min            1.6469598
Log Pis Mean                 -0.19007081
Log Pis Std                  2.1011899
Log Pis Max                  9.239737
Log Pis Min                  -4.826701
Policy mu Mean               0.07341582
Policy mu Std                0.8743572
Policy mu Max                3.063546
Policy mu Min                -3.1917741
Policy log std Mean          -0.50315124
Policy log std Std           0.24101172
Policy log std Max           0.029679358
Policy log std Min           -1.5826771
Z mean eval                  0.011471862
Z variance eval              0.0042897747
total_rewards                [ 973.73997584 3095.16145388 3051.52675433 2821.96169172 2138.63462155
 3059.79213959 2204.96438409 2152.36816061 2905.3002009  2077.56363783]
total_rewards_mean           2448.1013020323776
total_rewards_std            637.1153726235752
total_rewards_max            3095.16145388049
total_rewards_min            973.739975838626
Number of train steps total  148000
Number of env steps total    742000
Number of rollouts total     0
Train Time (s)               42.92507841065526
(Previous) Eval Time (s)     25.522509552072734
Sample Time (s)              21.35905611142516
Epoch Time (s)               89.80664407415316
Total Train Time (s)         11112.10519289365
Epoch                        147
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:53:31.779144 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #147 | Epoch Duration: 89.63064932823181
2020-01-11 03:53:31.779269 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #147 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011186798
Z variance train             0.004294435
KL Divergence                11.370128
KL Loss                      1.1370128
QF Loss                      218.39868
VF Loss                      335.6153
Policy Loss                  -1046.2756
Q Predictions Mean           1047.0327
Q Predictions Std            489.4076
Q Predictions Max            1455.0201
Q Predictions Min            -12.136228
V Predictions Mean           1053.9901
V Predictions Std            488.7198
V Predictions Max            1459.9546
V Predictions Min            -15.11884
Log Pis Mean                 -0.16714706
Log Pis Std                  1.9730071
Log Pis Max                  10.252391
Log Pis Min                  -4.2645683
Policy mu Mean               0.21837695
Policy mu Std                0.8606473
Policy mu Max                3.4541883
Policy mu Min                -2.6272912
Policy log std Mean          -0.4810427
Policy log std Std           0.2318417
Policy log std Max           0.028778762
Policy log std Min           -1.3609593
Z mean eval                  0.016970556
Z variance eval              0.0055398955
total_rewards                [3139.67621189 2301.43458158 3159.44352998 3124.50745645 3202.85062129
 2483.97046427 1576.17310091 2345.88006644 2334.03729644 2640.16350332]
total_rewards_mean           2630.813683256504
total_rewards_std            502.09774730259704
total_rewards_max            3202.850621289261
total_rewards_min            1576.1731009110288
Number of train steps total  149000
Number of env steps total    747000
Number of rollouts total     0
Train Time (s)               42.916621996089816
(Previous) Eval Time (s)     25.346278976183385
Sample Time (s)              21.905965763609856
Epoch Time (s)               90.16886673588306
Total Train Time (s)         11203.868943768553
Epoch                        148
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:55:03.562932 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #148 | Epoch Duration: 91.78353762626648
2020-01-11 03:55:03.563160 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #148 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016207715
Z variance train             0.0055369954
KL Divergence                10.905507
KL Loss                      1.0905508
QF Loss                      401.8249
VF Loss                      149.61676
Policy Loss                  -1017.7733
Q Predictions Mean           1019.6193
Q Predictions Std            478.7576
Q Predictions Max            1433.7177
Q Predictions Min            -28.817745
V Predictions Mean           1022.3281
V Predictions Std            478.1501
V Predictions Max            1431.4706
V Predictions Min            -6.5549498
Log Pis Mean                 -0.05195474
Log Pis Std                  2.3872976
Log Pis Max                  10.210348
Log Pis Min                  -7.4981213
Policy mu Mean               0.14566208
Policy mu Std                0.93666846
Policy mu Max                3.0239406
Policy mu Min                -3.712756
Policy log std Mean          -0.494573
Policy log std Std           0.2488787
Policy log std Max           0.057428718
Policy log std Min           -1.8362434
Z mean eval                  0.024171198
Z variance eval              0.005798947
total_rewards                [2334.84369058 3064.28379724 3085.92488315  865.02699413 3099.0616209
 3141.09774574 3083.09182542 3106.12254914 1803.77981084 3076.85770464]
total_rewards_mean           2666.0090621798226
total_rewards_std            733.5732104977753
total_rewards_max            3141.0977457388053
total_rewards_min            865.0269941323171
Number of train steps total  150000
Number of env steps total    752000
Number of rollouts total     0
Train Time (s)               44.22759982198477
(Previous) Eval Time (s)     26.960697237867862
Sample Time (s)              21.845995467156172
Epoch Time (s)               93.0342925270088
Total Train Time (s)         11296.979360247962
Epoch                        149
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:56:36.660377 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #149 | Epoch Duration: 93.0970025062561
2020-01-11 03:56:36.660656 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #149 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024085809
Z variance train             0.0057932944
KL Divergence                10.747036
KL Loss                      1.0747036
QF Loss                      370.83163
VF Loss                      158.52295
Policy Loss                  -1025.9325
Q Predictions Mean           1023.67615
Q Predictions Std            484.17786
Q Predictions Max            1449.0764
Q Predictions Min            -10.88434
V Predictions Mean           1033.1316
V Predictions Std            484.98077
V Predictions Max            1460.6937
V Predictions Min            -16.588575
Log Pis Mean                 0.03974379
Log Pis Std                  2.458301
Log Pis Max                  11.751588
Log Pis Min                  -5.6015525
Policy mu Mean               0.14096041
Policy mu Std                0.97008103
Policy mu Max                2.9357083
Policy mu Min                -3.7566767
Policy log std Mean          -0.49419865
Policy log std Std           0.21965116
Policy log std Max           0.08317119
Policy log std Min           -1.3215543
Z mean eval                  0.013199878
Z variance eval              0.005675558
total_rewards                [3100.39576509 3086.94840283 3168.84958942 1733.23367804 2907.97263135
 3094.39658211 3148.52391059 3148.95709475 3152.17885613 3064.82757154]
total_rewards_mean           2960.628408184738
total_rewards_std            415.25095399781065
total_rewards_max            3168.8495894168445
total_rewards_min            1733.2336780377848
Number of train steps total  151000
Number of env steps total    757000
Number of rollouts total     0
Train Time (s)               43.234133118763566
(Previous) Eval Time (s)     27.023168892599642
Sample Time (s)              21.843285995535553
Epoch Time (s)               92.10058800689876
Total Train Time (s)         11393.71095726965
Epoch                        150
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:58:13.392619 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #150 | Epoch Duration: 96.73175072669983
2020-01-11 03:58:13.392779 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #150 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012357777
Z variance train             0.005675592
KL Divergence                10.592073
KL Loss                      1.0592073
QF Loss                      328.75024
VF Loss                      349.6964
Policy Loss                  -1058.135
Q Predictions Mean           1058.3613
Q Predictions Std            476.09326
Q Predictions Max            1477.2678
Q Predictions Min            3.6738741
V Predictions Mean           1045.4287
V Predictions Std            473.91788
V Predictions Max            1453.7633
V Predictions Min            -3.6215515
Log Pis Mean                 -0.071385816
Log Pis Std                  2.2283716
Log Pis Max                  7.695719
Log Pis Min                  -6.0965366
Policy mu Mean               -0.00950734
Policy mu Std                0.9375479
Policy mu Max                2.1436505
Policy mu Min                -3.1342359
Policy log std Mean          -0.4973613
Policy log std Std           0.24903008
Policy log std Max           0.0623464
Policy log std Min           -1.8945117
Z mean eval                  0.015844494
Z variance eval              0.0056343316
total_rewards                [ 705.13392875 3186.14227492 1463.47452411 2794.96530633 1550.10741194
 2760.13507032 3136.74388768 3193.89768721 1076.79784758 2578.80226923]
total_rewards_mean           2244.6200208067385
total_rewards_std            899.4527679828378
total_rewards_max            3193.897687212441
total_rewards_min            705.1339287456259
Number of train steps total  152000
Number of env steps total    762000
Number of rollouts total     0
Train Time (s)               43.87629496585578
(Previous) Eval Time (s)     31.65410443721339
Sample Time (s)              21.82111259782687
Epoch Time (s)               97.35151200089604
Total Train Time (s)         11484.423232917674
Epoch                        151
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:59:44.106165 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #151 | Epoch Duration: 90.71325635910034
2020-01-11 03:59:44.106323 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #151 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015974944
Z variance train             0.005630638
KL Divergence                10.644482
KL Loss                      1.0644482
QF Loss                      671.3484
VF Loss                      104.73347
Policy Loss                  -1088.7905
Q Predictions Mean           1087.3308
Q Predictions Std            446.312
Q Predictions Max            1465.5889
Q Predictions Min            -2.683215
V Predictions Mean           1093.5513
V Predictions Std            446.6328
V Predictions Max            1471.3145
V Predictions Min            -1.5800744
Log Pis Mean                 -0.31820285
Log Pis Std                  2.083301
Log Pis Max                  9.211004
Log Pis Min                  -5.441981
Policy mu Mean               0.034656174
Policy mu Std                0.87411165
Policy mu Max                2.6064756
Policy mu Min                -2.8889167
Policy log std Mean          -0.50080603
Policy log std Std           0.22303742
Policy log std Max           0.013228685
Policy log std Min           -1.3053303
Z mean eval                  0.03355565
Z variance eval              0.0052618063
total_rewards                [3002.44050542 3128.40084767 1211.88656194 2688.3152375  1045.91948192
 3200.63997397 1512.14976185 1603.24180715  665.20267168 2869.76101118]
total_rewards_mean           2092.7957860288043
total_rewards_std            925.8701066086854
total_rewards_max            3200.6399739724425
total_rewards_min            665.2026716806859
Number of train steps total  153000
Number of env steps total    767000
Number of rollouts total     0
Train Time (s)               43.40791953308508
(Previous) Eval Time (s)     25.01561511401087
Sample Time (s)              21.642991419881582
Epoch Time (s)               90.06652606697753
Total Train Time (s)         11571.14752927376
Epoch                        152
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:01:10.833508 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #152 | Epoch Duration: 86.72704768180847
2020-01-11 04:01:10.833695 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #152 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032687336
Z variance train             0.0052659153
KL Divergence                10.820652
KL Loss                      1.0820652
QF Loss                      472.48767
VF Loss                      103.07863
Policy Loss                  -1065.3892
Q Predictions Mean           1062.7429
Q Predictions Std            455.62738
Q Predictions Max            1463.1659
Q Predictions Min            -3.1623511
V Predictions Mean           1061.6548
V Predictions Std            454.5627
V Predictions Max            1460.2869
V Predictions Min            -3.7623694
Log Pis Mean                 -0.30539697
Log Pis Std                  2.132381
Log Pis Max                  10.716253
Log Pis Min                  -5.0906477
Policy mu Mean               -0.019812271
Policy mu Std                0.84522206
Policy mu Max                2.3501456
Policy mu Min                -3.0696635
Policy log std Mean          -0.4786038
Policy log std Std           0.20787357
Policy log std Max           0.14575335
Policy log std Min           -1.2273732
Z mean eval                  0.017138738
Z variance eval              0.0058237608
total_rewards                [1382.30585941 2297.89613012 3004.46616423 3352.29313759 3338.74474898
 1638.34014968 3297.15372471 3283.75456337 1631.69950714 3320.8524483 ]
total_rewards_mean           2654.750643351442
total_rewards_std            784.5328845244774
total_rewards_max            3352.2931375944277
total_rewards_min            1382.3058594087563
Number of train steps total  154000
Number of env steps total    772000
Number of rollouts total     0
Train Time (s)               43.04836732940748
(Previous) Eval Time (s)     21.675895079039037
Sample Time (s)              21.831825411878526
Epoch Time (s)               86.55608782032505
Total Train Time (s)         11662.4206773052
Epoch                        153
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:02:42.106800 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #153 | Epoch Duration: 91.27297139167786
2020-01-11 04:02:42.106921 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #153 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016795903
Z variance train             0.005827546
KL Divergence                10.541288
KL Loss                      1.0541289
QF Loss                      583.0129
VF Loss                      230.80258
Policy Loss                  -1007.5306
Q Predictions Mean           1006.24304
Q Predictions Std            481.919
Q Predictions Max            1457.2936
Q Predictions Min            -14.79287
V Predictions Mean           1010.3519
V Predictions Std            479.12674
V Predictions Max            1448.6647
V Predictions Min            -8.83845
Log Pis Mean                 -0.1127246
Log Pis Std                  2.4687746
Log Pis Max                  12.435488
Log Pis Min                  -5.79377
Policy mu Mean               0.07653909
Policy mu Std                0.9471691
Policy mu Max                2.6960375
Policy mu Min                -3.1258628
Policy log std Mean          -0.48832583
Policy log std Std           0.22688253
Policy log std Max           0.13000888
Policy log std Min           -1.3400016
Z mean eval                  0.016967608
Z variance eval              0.0065123714
total_rewards                [2137.64736314 3220.39781815 1182.95926282 2644.22957755 1887.9731958
 2700.02440201 3296.80579901 1568.20130172 2934.55653442 2166.52576247]
total_rewards_mean           2373.9321017096286
total_rewards_std            668.1705687223215
total_rewards_max            3296.805799010094
total_rewards_min            1182.9592628222395
Number of train steps total  155000
Number of env steps total    777000
Number of rollouts total     0
Train Time (s)               42.61492381710559
(Previous) Eval Time (s)     26.3925624191761
Sample Time (s)              22.16391668142751
Epoch Time (s)               91.1714029177092
Total Train Time (s)         11748.400055873208
Epoch                        154
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:04:08.088965 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #154 | Epoch Duration: 85.98193836212158
2020-01-11 04:04:08.089141 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #154 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015897315
Z variance train             0.006513638
KL Divergence                10.286171
KL Loss                      1.0286171
QF Loss                      1078.9443
VF Loss                      205.81447
Policy Loss                  -1040.9875
Q Predictions Mean           1040.4622
Q Predictions Std            465.40076
Q Predictions Max            1460.8315
Q Predictions Min            2.7615476
V Predictions Mean           1046.5714
V Predictions Std            468.47076
V Predictions Max            1471.7487
V Predictions Min            -3.2347066
Log Pis Mean                 -0.12111145
Log Pis Std                  2.0069795
Log Pis Max                  8.841282
Log Pis Min                  -5.2266045
Policy mu Mean               0.12025091
Policy mu Std                0.89460295
Policy mu Max                2.6430237
Policy mu Min                -2.8439417
Policy log std Mean          -0.47964287
Policy log std Std           0.23175588
Policy log std Max           0.071844965
Policy log std Min           -1.3795208
Z mean eval                  0.015494138
Z variance eval              0.0059406934
total_rewards                [3098.33610168 3040.51539474 2600.01104262 3118.09311597 1713.12356497
 3158.92617471 3059.87276372 1132.59380399 2086.78072731 3102.61926105]
total_rewards_mean           2611.087195076327
total_rewards_std            684.7858225270467
total_rewards_max            3158.926174712933
total_rewards_min            1132.5938039921589
Number of train steps total  156000
Number of env steps total    782000
Number of rollouts total     0
Train Time (s)               43.8181929923594
(Previous) Eval Time (s)     21.202825834043324
Sample Time (s)              21.89292686060071
Epoch Time (s)               86.91394568700343
Total Train Time (s)         11840.052782736719
Epoch                        155
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:05:39.746691 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #155 | Epoch Duration: 91.65734362602234
2020-01-11 04:05:39.746951 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #155 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015097859
Z variance train             0.005932113
KL Divergence                10.523132
KL Loss                      1.0523132
QF Loss                      257.12573
VF Loss                      337.77713
Policy Loss                  -1071.9141
Q Predictions Mean           1075.9263
Q Predictions Std            443.98083
Q Predictions Max            1472.5264
Q Predictions Min            -3.088762
V Predictions Mean           1083.8821
V Predictions Std            444.9534
V Predictions Max            1450.7294
V Predictions Min            -6.4878864
Log Pis Mean                 -0.028141048
Log Pis Std                  2.0922775
Log Pis Max                  7.2542305
Log Pis Min                  -6.0486665
Policy mu Mean               0.08457748
Policy mu Std                0.9117559
Policy mu Max                2.6331356
Policy mu Min                -2.9007628
Policy log std Mean          -0.49466768
Policy log std Std           0.24333693
Policy log std Max           0.14955974
Policy log std Min           -1.3493938
Z mean eval                  0.021153847
Z variance eval              0.0060089305
total_rewards                [3117.7770697  3156.96044003 3168.43094525 3203.96303646 3113.44304907
 3202.06613304 3245.15947118 3243.01970217 1425.01895509 3215.18845896]
total_rewards_mean           3009.102726094123
total_rewards_std            529.8473817388049
total_rewards_max            3245.1594711752787
total_rewards_min            1425.0189550928753
Number of train steps total  157000
Number of env steps total    787000
Number of rollouts total     0
Train Time (s)               43.56915915478021
(Previous) Eval Time (s)     25.945968315936625
Sample Time (s)              22.05579899577424
Epoch Time (s)               91.57092646649107
Total Train Time (s)         11936.721743260976
Epoch                        156
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:07:16.416882 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #156 | Epoch Duration: 96.66976690292358
2020-01-11 04:07:16.417018 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #156 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021518847
Z variance train             0.0060084895
KL Divergence                10.690662
KL Loss                      1.0690663
QF Loss                      189.67787
VF Loss                      133.26363
Policy Loss                  -1001.45624
Q Predictions Mean           994.74335
Q Predictions Std            515.2289
Q Predictions Max            1468.0166
Q Predictions Min            -9.98913
V Predictions Mean           999.4161
V Predictions Std            516.3308
V Predictions Max            1473.31
V Predictions Min            -2.7012508
Log Pis Mean                 -0.1227056
Log Pis Std                  2.161719
Log Pis Max                  10.92329
Log Pis Min                  -7.2509317
Policy mu Mean               0.06391918
Policy mu Std                0.8834997
Policy mu Max                2.716509
Policy mu Min                -3.0412862
Policy log std Mean          -0.47266617
Policy log std Std           0.2230724
Policy log std Max           0.10039437
Policy log std Min           -1.28089
Z mean eval                  0.018834185
Z variance eval              0.0062062526
total_rewards                [3131.83988417 2656.25550484 3081.42335468  682.16301262 2686.12525084
  986.48158077 3080.30299014  880.23339699 3144.13584144 3057.89509553]
total_rewards_mean           2338.685591202424
total_rewards_std            990.8548031883792
total_rewards_max            3144.1358414393985
total_rewards_min            682.1630126178899
Number of train steps total  158000
Number of env steps total    792000
Number of rollouts total     0
Train Time (s)               43.20583751285449
(Previous) Eval Time (s)     31.04459054907784
Sample Time (s)              21.506274092476815
Epoch Time (s)               95.75670215440914
Total Train Time (s)         12025.563773923088
Epoch                        157
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:08:45.266387 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #157 | Epoch Duration: 88.84910774230957
2020-01-11 04:08:45.266817 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #157 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019097168
Z variance train             0.0062200865
KL Divergence                10.642656
KL Loss                      1.0642656
QF Loss                      164.78632
VF Loss                      77.53815
Policy Loss                  -1042.8765
Q Predictions Mean           1040.7902
Q Predictions Std            493.62372
Q Predictions Max            1462.3549
Q Predictions Min            -0.92427504
V Predictions Mean           1045.4368
V Predictions Std            494.49338
V Predictions Max            1460.0416
V Predictions Min            -19.58403
Log Pis Mean                 -0.37404084
Log Pis Std                  1.9711357
Log Pis Max                  9.873651
Log Pis Min                  -5.898494
Policy mu Mean               0.021298869
Policy mu Std                0.8291714
Policy mu Max                2.4148974
Policy mu Min                -2.9523296
Policy log std Mean          -0.48379502
Policy log std Std           0.24605915
Policy log std Max           0.030391783
Policy log std Min           -1.2992945
Z mean eval                  0.021574084
Z variance eval              0.006462019
total_rewards                [1473.34053001  911.75859124 1091.30899028 2229.52591845 3110.81252282
 3118.3412587  2014.68114904 1349.09637443 3010.658434   3112.50104561]
total_rewards_mean           2142.2024814568276
total_rewards_std            854.7161719837037
total_rewards_max            3118.341258700139
total_rewards_min            911.7585912443892
Number of train steps total  159000
Number of env steps total    797000
Number of rollouts total     0
Train Time (s)               43.17101076012477
(Previous) Eval Time (s)     24.13671690924093
Sample Time (s)              19.88717635674402
Epoch Time (s)               87.19490402610973
Total Train Time (s)         12111.473239690065
Epoch                        158
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:10:11.174583 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #158 | Epoch Duration: 85.90751504898071
2020-01-11 04:10:11.174703 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #158 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020743392
Z variance train             0.0064610257
KL Divergence                10.699322
KL Loss                      1.0699322
QF Loss                      335.403
VF Loss                      213.2521
Policy Loss                  -1043.2524
Q Predictions Mean           1040.1188
Q Predictions Std            490.23206
Q Predictions Max            1480.7778
Q Predictions Min            -29.853933
V Predictions Mean           1044.6887
V Predictions Std            488.03738
V Predictions Max            1472.1849
V Predictions Min            -13.180361
Log Pis Mean                 0.0181435
Log Pis Std                  2.0305464
Log Pis Max                  7.131838
Log Pis Min                  -4.9049034
Policy mu Mean               0.07379934
Policy mu Std                0.93941873
Policy mu Max                2.6640487
Policy mu Min                -3.5879052
Policy log std Mean          -0.5016453
Policy log std Std           0.22240987
Policy log std Max           -0.053556353
Policy log std Min           -1.2821648
Z mean eval                  0.016162748
Z variance eval              0.005755045
total_rewards                [3152.53485117 3135.06652168 2051.15108084 3198.96722731 3217.00086588
 3096.34954603 1586.77957845 1006.63475609 2653.87218886 1545.41906928]
total_rewards_mean           2464.377568560147
total_rewards_std            798.4471113592342
total_rewards_max            3217.000865876136
total_rewards_min            1006.6347560933598
Number of train steps total  160000
Number of env steps total    802000
Number of rollouts total     0
Train Time (s)               43.87007615994662
(Previous) Eval Time (s)     22.84912257269025
Sample Time (s)              21.812981138937175
Epoch Time (s)               88.53217987157404
Total Train Time (s)         12201.925400424283
Epoch                        159
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:11:41.630463 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #159 | Epoch Duration: 90.45564675331116
2020-01-11 04:11:41.630654 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #159 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01586554
Z variance train             0.0057587475
KL Divergence                11.080591
KL Loss                      1.1080592
QF Loss                      14906.9
VF Loss                      174.35065
Policy Loss                  -1103.5364
Q Predictions Mean           1107.5977
Q Predictions Std            447.14154
Q Predictions Max            1495.187
Q Predictions Min            -9.096598
V Predictions Mean           1110.25
V Predictions Std            447.6911
V Predictions Max            1486.4626
V Predictions Min            -15.277824
Log Pis Mean                 -0.19726229
Log Pis Std                  2.0584707
Log Pis Max                  9.26198
Log Pis Min                  -4.1092463
Policy mu Mean               0.185017
Policy mu Std                0.87933
Policy mu Max                2.232158
Policy mu Min                -2.6713936
Policy log std Mean          -0.47270015
Policy log std Std           0.21625622
Policy log std Max           -0.0040870607
Policy log std Min           -1.14999
Z mean eval                  0.01918241
Z variance eval              0.0060319677
total_rewards                [3150.84665162 3158.12324574 1137.73930849 1084.04544205 2833.14045451
 2859.42322576 1126.1420512  1044.06409245 1024.65903283 1032.74540907]
total_rewards_mean           1845.092891372283
total_rewards_std            948.959720696187
total_rewards_max            3158.1232457425162
total_rewards_min            1024.659032827634
Number of train steps total  161000
Number of env steps total    807000
Number of rollouts total     0
Train Time (s)               43.500773537904024
(Previous) Eval Time (s)     24.772339711897075
Sample Time (s)              21.71149823674932
Epoch Time (s)               89.98461148655042
Total Train Time (s)         12284.579748063814
Epoch                        160
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:13:04.287392 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #160 | Epoch Duration: 82.65658831596375
2020-01-11 04:13:04.287558 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #160 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019153742
Z variance train             0.0060346117
KL Divergence                10.9480095
KL Loss                      1.094801
QF Loss                      243.27258
VF Loss                      84.799614
Policy Loss                  -1087.8916
Q Predictions Mean           1089.0762
Q Predictions Std            468.81674
Q Predictions Max            1489.8092
Q Predictions Min            0.20886499
V Predictions Mean           1083.9348
V Predictions Std            466.3597
V Predictions Max            1484.9088
V Predictions Min            -22.838804
Log Pis Mean                 -0.4249091
Log Pis Std                  1.9559184
Log Pis Max                  9.023376
Log Pis Min                  -5.8103576
Policy mu Mean               -0.072073095
Policy mu Std                0.86671436
Policy mu Max                3.4506793
Policy mu Min                -3.274142
Policy log std Mean          -0.4634687
Policy log std Std           0.21503507
Policy log std Max           0.006907314
Policy log std Min           -1.3607416
Z mean eval                  0.047184806
Z variance eval              0.005528112
total_rewards                [1276.25218135 1558.19245887 3158.09210058 2999.71648794 3186.54377194
 3199.9542615  3168.41383926 3155.77634813 3186.29221139 3095.09562361]
total_rewards_mean           2798.4329284574587
total_rewards_std            695.6991893337366
total_rewards_max            3199.9542615007745
total_rewards_min            1276.2521813478234
Number of train steps total  162000
Number of env steps total    812000
Number of rollouts total     0
Train Time (s)               43.173836786765605
(Previous) Eval Time (s)     17.44408835982904
Sample Time (s)              21.836771811824292
Epoch Time (s)               82.45469695841894
Total Train Time (s)         12378.170279690996
Epoch                        161
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:14:37.879769 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #161 | Epoch Duration: 93.59208559989929
2020-01-11 04:14:37.879890 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #161 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04722897
Z variance train             0.0055311783
KL Divergence                11.165332
KL Loss                      1.1165332
QF Loss                      328.46832
VF Loss                      223.22527
Policy Loss                  -1036.4052
Q Predictions Mean           1037.0627
Q Predictions Std            476.3324
Q Predictions Max            1463.0781
Q Predictions Min            -8.754802
V Predictions Mean           1030.442
V Predictions Std            472.94598
V Predictions Max            1461.278
V Predictions Min            2.1038263
Log Pis Mean                 -0.277763
Log Pis Std                  2.105821
Log Pis Max                  9.552567
Log Pis Min                  -6.41707
Policy mu Mean               -0.03277532
Policy mu Std                0.8932832
Policy mu Max                3.35522
Policy mu Min                -2.916192
Policy log std Mean          -0.48249567
Policy log std Std           0.23159349
Policy log std Max           0.19825706
Policy log std Min           -1.243653
Z mean eval                  0.01692199
Z variance eval              0.0053655272
total_rewards                [2219.53348118 1031.09597869 3182.87103617 3119.81454695 1026.50479262
 2326.1656412  1521.63582298 1051.86542396 1017.98468214 3064.43432544]
total_rewards_mean           1956.1905731331753
total_rewards_std            888.8300581609188
total_rewards_max            3182.871036167715
total_rewards_min            1017.9846821438296
Number of train steps total  163000
Number of env steps total    817000
Number of rollouts total     0
Train Time (s)               43.53184923669323
(Previous) Eval Time (s)     28.581238687969744
Sample Time (s)              21.294233612250537
Epoch Time (s)               93.40732153691351
Total Train Time (s)         12463.449300271459
Epoch                        162
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:16:03.160890 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #162 | Epoch Duration: 85.28088688850403
2020-01-11 04:16:03.161068 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #162 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017474858
Z variance train             0.0053609507
KL Divergence                11.048634
KL Loss                      1.1048634
QF Loss                      191.20561
VF Loss                      269.2465
Policy Loss                  -1073.5509
Q Predictions Mean           1073.1914
Q Predictions Std            448.93652
Q Predictions Max            1479.9916
Q Predictions Min            0.862085
V Predictions Mean           1071.4958
V Predictions Std            448.67938
V Predictions Max            1481.2994
V Predictions Min            -20.549297
Log Pis Mean                 -0.28922877
Log Pis Std                  2.0017607
Log Pis Max                  12.840002
Log Pis Min                  -5.638624
Policy mu Mean               0.14029227
Policy mu Std                0.86535776
Policy mu Max                2.6990716
Policy mu Min                -3.0901074
Policy log std Mean          -0.49535766
Policy log std Std           0.22885531
Policy log std Max           0.12663227
Policy log std Min           -1.3446778
Z mean eval                  0.017269174
Z variance eval              0.0058174427
total_rewards                [3174.14015933 1036.72355709 1117.15870247  982.36962598 1072.25709562
  876.93429922 1230.09188169 1048.83017206 3160.31676572 1705.20656186]
total_rewards_mean           1540.4028821043235
total_rewards_std            840.3508809590132
total_rewards_max            3174.1401593334654
total_rewards_min            876.934299218648
Number of train steps total  164000
Number of env steps total    822000
Number of rollouts total     0
Train Time (s)               43.422947886865586
(Previous) Eval Time (s)     20.454560759011656
Sample Time (s)              19.967677618842572
Epoch Time (s)               83.84518626471981
Total Train Time (s)         12542.088360369671
Epoch                        163
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:17:21.807054 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #163 | Epoch Duration: 78.64580082893372
2020-01-11 04:17:21.807371 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #163 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017695896
Z variance train             0.0058214767
KL Divergence                10.760764
KL Loss                      1.0760764
QF Loss                      357.26175
VF Loss                      125.805405
Policy Loss                  -1090.3892
Q Predictions Mean           1086.871
Q Predictions Std            478.33044
Q Predictions Max            1494.6412
Q Predictions Min            -11.250775
V Predictions Mean           1094.4514
V Predictions Std            480.344
V Predictions Max            1490.4608
V Predictions Min            -18.820118
Log Pis Mean                 -0.18691036
Log Pis Std                  1.9909441
Log Pis Max                  9.176651
Log Pis Min                  -4.761036
Policy mu Mean               0.17776239
Policy mu Std                0.8602442
Policy mu Max                3.028941
Policy mu Min                -2.8657956
Policy log std Mean          -0.4902725
Policy log std Std           0.24465126
Policy log std Max           0.03957981
Policy log std Min           -1.4443138
Z mean eval                  0.014438483
Z variance eval              0.0052551143
total_rewards                [2996.14974602 3032.57118852 1054.85836264 3048.57408722 2436.85045391
 2975.1600423  3070.44545955 3053.07392973 2182.64516627  996.32899824]
total_rewards_mean           2484.665743438689
total_rewards_std            783.5571086609364
total_rewards_max            3070.445459545646
total_rewards_min            996.3289982366928
Number of train steps total  165000
Number of env steps total    827000
Number of rollouts total     0
Train Time (s)               43.20369193702936
(Previous) Eval Time (s)     15.254904400091618
Sample Time (s)              20.090643444098532
Epoch Time (s)               78.54923978121951
Total Train Time (s)         12630.293569225352
Epoch                        164
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:18:50.012172 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #164 | Epoch Duration: 88.20457196235657
2020-01-11 04:18:50.012349 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #164 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014948778
Z variance train             0.0052717277
KL Divergence                10.875185
KL Loss                      1.0875186
QF Loss                      486.28568
VF Loss                      258.4567
Policy Loss                  -1080.7242
Q Predictions Mean           1073.5503
Q Predictions Std            462.66855
Q Predictions Max            1496.4242
Q Predictions Min            -9.740534
V Predictions Mean           1085.0826
V Predictions Std            462.73383
V Predictions Max            1490.2908
V Predictions Min            -9.661453
Log Pis Mean                 -0.21603058
Log Pis Std                  2.0762022
Log Pis Max                  8.917605
Log Pis Min                  -4.2159805
Policy mu Mean               0.049666945
Policy mu Std                0.88159317
Policy mu Max                3.1411655
Policy mu Min                -3.1198497
Policy log std Mean          -0.46656632
Policy log std Std           0.21682197
Policy log std Max           -0.007815152
Policy log std Min           -1.1245646
Z mean eval                  0.027283933
Z variance eval              0.0047386647
total_rewards                [3228.00614582  940.06122154 3253.72991877 2151.76348397 1253.92775905
 2688.2751031  1039.94058401 2529.79322364 3207.82495608 1015.82219267]
total_rewards_mean           2130.914458863306
total_rewards_std            933.5492834551106
total_rewards_max            3253.7299187669378
total_rewards_min            940.0612215367495
Number of train steps total  166000
Number of env steps total    832000
Number of rollouts total     0
Train Time (s)               44.81669946806505
(Previous) Eval Time (s)     24.9100103196688
Sample Time (s)              19.931480710860342
Epoch Time (s)               89.6581904985942
Total Train Time (s)         12716.578501935583
Epoch                        165
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:20:16.299597 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #165 | Epoch Duration: 86.28704524040222
2020-01-11 04:20:16.299852 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #165 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026359845
Z variance train             0.0047399085
KL Divergence                11.022781
KL Loss                      1.1022781
QF Loss                      522.68054
VF Loss                      207.54413
Policy Loss                  -1089.2797
Q Predictions Mean           1087.0911
Q Predictions Std            463.18015
Q Predictions Max            1503.7355
Q Predictions Min            -7.063956
V Predictions Mean           1085.9907
V Predictions Std            461.5964
V Predictions Max            1495.5496
V Predictions Min            -7.184633
Log Pis Mean                 -0.18497582
Log Pis Std                  2.184946
Log Pis Max                  9.368417
Log Pis Min                  -4.9701166
Policy mu Mean               0.040013682
Policy mu Std                0.90304536
Policy mu Max                3.215867
Policy mu Min                -2.8837793
Policy log std Mean          -0.4650028
Policy log std Std           0.22198531
Policy log std Max           0.0144735575
Policy log std Min           -1.2423892
Z mean eval                  0.03986969
Z variance eval              0.0047687152
total_rewards                [1505.53507481 3139.05762612 3118.09852668 3176.85793434 2142.17933098
 2172.23552779 3184.84529647 3111.84563553 1094.1449713  3176.13172824]
total_rewards_mean           2582.093165225288
total_rewards_std            753.8276015805877
total_rewards_max            3184.845296465343
total_rewards_min            1094.144971295793
Number of train steps total  167000
Number of env steps total    837000
Number of rollouts total     0
Train Time (s)               43.35423630196601
(Previous) Eval Time (s)     21.53860902506858
Sample Time (s)              21.479719023685902
Epoch Time (s)               86.3725643507205
Total Train Time (s)         12808.35942418268
Epoch                        166
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:21:48.082545 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #166 | Epoch Duration: 91.78252172470093
2020-01-11 04:21:48.082684 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #166 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039427735
Z variance train             0.0047722915
KL Divergence                10.960751
KL Loss                      1.096075
QF Loss                      483.27063
VF Loss                      231.4375
Policy Loss                  -1065.8757
Q Predictions Mean           1064.5154
Q Predictions Std            476.7044
Q Predictions Max            1476.4164
Q Predictions Min            -6.934747
V Predictions Mean           1057.0214
V Predictions Std            471.86368
V Predictions Max            1474.0331
V Predictions Min            0.5231734
Log Pis Mean                 -0.08293019
Log Pis Std                  2.110118
Log Pis Max                  11.565276
Log Pis Min                  -4.4039564
Policy mu Mean               0.010708665
Policy mu Std                0.9373979
Policy mu Max                3.8898084
Policy mu Min                -2.8123198
Policy log std Mean          -0.47344732
Policy log std Std           0.23718373
Policy log std Max           0.120042086
Policy log std Min           -1.243271
Z mean eval                  0.027015945
Z variance eval              0.0050636693
total_rewards                [2681.56874436  961.92700347 1780.11262763 2887.85092756 1502.42089898
 3184.57346305 2743.29932876 1583.76754749 1255.60957129 1788.41131507]
total_rewards_mean           2036.9541427654026
total_rewards_std            730.7896153182928
total_rewards_max            3184.5734630464026
total_rewards_min            961.9270034700306
Number of train steps total  168000
Number of env steps total    842000
Number of rollouts total     0
Train Time (s)               43.57351274881512
(Previous) Eval Time (s)     26.94834469584748
Sample Time (s)              22.69218669226393
Epoch Time (s)               93.21404413692653
Total Train Time (s)         12895.042409723625
Epoch                        167
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:23:14.768152 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #167 | Epoch Duration: 86.68530797958374
2020-01-11 04:23:14.768344 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #167 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026287366
Z variance train             0.0050605694
KL Divergence                10.937166
KL Loss                      1.0937166
QF Loss                      210.23337
VF Loss                      109.6709
Policy Loss                  -1051.5458
Q Predictions Mean           1051.319
Q Predictions Std            483.77786
Q Predictions Max            1497.9708
Q Predictions Min            -4.431429
V Predictions Mean           1053.8909
V Predictions Std            482.61984
V Predictions Max            1494.2341
V Predictions Min            0.8421779
Log Pis Mean                 -0.20271954
Log Pis Std                  2.1479726
Log Pis Max                  6.6177588
Log Pis Min                  -5.314507
Policy mu Mean               0.04869743
Policy mu Std                0.89098203
Policy mu Max                3.0599139
Policy mu Min                -2.7607672
Policy log std Mean          -0.46329507
Policy log std Std           0.22158253
Policy log std Max           0.052319944
Policy log std Min           -1.2312481
Z mean eval                  0.024118185
Z variance eval              0.004484955
total_rewards                [1184.78878329 3147.54185246 3190.76063366 1046.93327167 3174.39133195
 2312.07100902 3169.65056791  926.64143979 3203.39223917 2102.04348223]
total_rewards_mean           2345.8214611151607
total_rewards_std            925.5848959016145
total_rewards_max            3203.3922391699366
total_rewards_min            926.641439791063
Number of train steps total  169000
Number of env steps total    847000
Number of rollouts total     0
Train Time (s)               43.85123800393194
(Previous) Eval Time (s)     20.419355480000377
Sample Time (s)              21.3290260322392
Epoch Time (s)               85.59961951617151
Total Train Time (s)         12984.009724192787
Epoch                        168
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:24:43.736451 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #168 | Epoch Duration: 88.96799206733704
2020-01-11 04:24:43.736575 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #168 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023891816
Z variance train             0.004482082
KL Divergence                11.343405
KL Loss                      1.1343405
QF Loss                      896.87787
VF Loss                      102.042175
Policy Loss                  -1147.9158
Q Predictions Mean           1146.8878
Q Predictions Std            460.58362
Q Predictions Max            1523.4333
Q Predictions Min            -20.039011
V Predictions Mean           1147.1221
V Predictions Std            455.96115
V Predictions Max            1520.4669
V Predictions Min            -3.3744519
Log Pis Mean                 0.043202356
Log Pis Std                  2.227319
Log Pis Max                  10.433612
Log Pis Min                  -5.3390045
Policy mu Mean               0.075269066
Policy mu Std                0.98108804
Policy mu Max                3.2165244
Policy mu Min                -5.021955
Policy log std Mean          -0.48680827
Policy log std Std           0.24485102
Policy log std Max           0.14499933
Policy log std Min           -1.9475715
Z mean eval                  0.015636094
Z variance eval              0.0043116095
total_rewards                [3125.78480276 3058.13600804 1444.27795577 3016.6843264  3062.71923128
 3045.85254819 3028.86517411 3049.03978452 3020.34615051 3016.17186452]
total_rewards_mean           2886.7877846095407
total_rewards_std            481.82265954222186
total_rewards_max            3125.7848027640844
total_rewards_min            1444.2779557701117
Number of train steps total  170000
Number of env steps total    852000
Number of rollouts total     0
Train Time (s)               43.25531930522993
(Previous) Eval Time (s)     23.787465809844434
Sample Time (s)              21.729445522185415
Epoch Time (s)               88.77223063725978
Total Train Time (s)         13077.807430909947
Epoch                        169
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:26:17.547211 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #169 | Epoch Duration: 93.8104887008667
2020-01-11 04:26:17.547527 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #169 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014543961
Z variance train             0.0043038363
KL Divergence                11.450992
KL Loss                      1.1450992
QF Loss                      1244.1465
VF Loss                      238.31941
Policy Loss                  -1062.0813
Q Predictions Mean           1058.844
Q Predictions Std            506.64377
Q Predictions Max            1529.0067
Q Predictions Min            -7.4399805
V Predictions Mean           1071.1392
V Predictions Std            507.44855
V Predictions Max            1532.5834
V Predictions Min            -4.053999
Log Pis Mean                 0.005295597
Log Pis Std                  2.5259855
Log Pis Max                  13.126132
Log Pis Min                  -4.7994094
Policy mu Mean               0.0838235
Policy mu Std                0.9249484
Policy mu Max                3.5691488
Policy mu Min                -4.3954043
Policy log std Mean          -0.4941491
Policy log std Std           0.23915727
Policy log std Max           0.0506559
Policy log std Min           -1.738517
Z mean eval                  0.030645246
Z variance eval              0.0041733524
total_rewards                [2760.0882662  1441.55048735 3127.11022986 1163.40551226 1181.04318831
 2225.45626578  989.46332408 3148.74481835  749.08001179  977.82849568]
total_rewards_mean           1776.3770599658078
total_rewards_std            896.2003606362505
total_rewards_max            3148.7448183489523
total_rewards_min            749.0800117929714
Number of train steps total  171000
Number of env steps total    857000
Number of rollouts total     0
Train Time (s)               43.78364073485136
(Previous) Eval Time (s)     28.825447940733284
Sample Time (s)              21.560944576747715
Epoch Time (s)               94.17003325233236
Total Train Time (s)         13160.499977978878
Epoch                        170
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:27:40.237551 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #170 | Epoch Duration: 82.68975806236267
2020-01-11 04:27:40.237845 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #170 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030595506
Z variance train             0.0041582524
KL Divergence                11.492258
KL Loss                      1.1492258
QF Loss                      274.18216
VF Loss                      432.95462
Policy Loss                  -1133.1453
Q Predictions Mean           1138.5652
Q Predictions Std            445.3353
Q Predictions Max            1522.5809
Q Predictions Min            -0.75332433
V Predictions Mean           1143.6575
V Predictions Std            443.22708
V Predictions Max            1510.7693
V Predictions Min            2.2252846
Log Pis Mean                 0.27690327
Log Pis Std                  2.4308395
Log Pis Max                  11.555213
Log Pis Min                  -4.334718
Policy mu Mean               0.3081828
Policy mu Std                0.9743596
Policy mu Max                3.1612315
Policy mu Min                -3.1523962
Policy log std Mean          -0.5141817
Policy log std Std           0.22710939
Policy log std Max           0.02845788
Policy log std Min           -1.341676
Z mean eval                  0.013058448
Z variance eval              0.0035367205
total_rewards                [3147.47385682 3113.70930588 3199.06290336 3197.37945982 2146.75945946
 1032.22805703 3188.54215006 1846.83821076 1158.64750964 3175.57067589]
total_rewards_mean           2520.621158872514
total_rewards_std            848.6520165634158
total_rewards_max            3199.062903358105
total_rewards_min            1032.2280570293108
Number of train steps total  172000
Number of env steps total    862000
Number of rollouts total     0
Train Time (s)               43.390482229646295
(Previous) Eval Time (s)     17.34493371611461
Sample Time (s)              21.8650741269812
Epoch Time (s)               82.6004900727421
Total Train Time (s)         13251.218306967523
Epoch                        171
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:29:10.956725 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #171 | Epoch Duration: 90.71867728233337
2020-01-11 04:29:10.956866 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #171 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012409752
Z variance train             0.003535432
KL Divergence                12.015085
KL Loss                      1.2015085
QF Loss                      364.26056
VF Loss                      253.54362
Policy Loss                  -1084.0695
Q Predictions Mean           1081.48
Q Predictions Std            469.13684
Q Predictions Max            1503.3727
Q Predictions Min            -0.9523088
V Predictions Mean           1082.9105
V Predictions Std            466.93823
V Predictions Max            1495.9941
V Predictions Min            -0.09697199
Log Pis Mean                 -0.24915628
Log Pis Std                  2.2055554
Log Pis Max                  9.51352
Log Pis Min                  -5.5147243
Policy mu Mean               -0.013303153
Policy mu Std                0.87835824
Policy mu Max                2.9282556
Policy mu Min                -3.0398147
Policy log std Mean          -0.48611423
Policy log std Std           0.23459123
Policy log std Max           0.07568604
Policy log std Min           -1.2984104
Z mean eval                  0.017208667
Z variance eval              0.0034768
total_rewards                [2918.50019574 1164.23112875 1887.00712338 1061.99954084 3183.72295991
 1159.58062219 1054.69864401 3241.57621706 3219.88835604 3183.70630396]
total_rewards_mean           2207.4911091879544
total_rewards_std            971.3978593447333
total_rewards_max            3241.5762170597973
total_rewards_min            1054.698644014625
Number of train steps total  173000
Number of env steps total    867000
Number of rollouts total     0
Train Time (s)               43.01983445091173
(Previous) Eval Time (s)     25.462914237286896
Sample Time (s)              22.02461222652346
Epoch Time (s)               90.50736091472208
Total Train Time (s)         13338.699963479768
Epoch                        172
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:30:38.443317 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #172 | Epoch Duration: 87.48631310462952
2020-01-11 04:30:38.443582 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #172 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018216096
Z variance train             0.0034677298
KL Divergence                12.096325
KL Loss                      1.2096325
QF Loss                      327.59335
VF Loss                      576.98755
Policy Loss                  -1038.8632
Q Predictions Mean           1043.7788
Q Predictions Std            531.93713
Q Predictions Max            1505.8226
Q Predictions Min            -14.374373
V Predictions Mean           1057.9429
V Predictions Std            535.62177
V Predictions Max            1521.8615
V Predictions Min            -9.392996
Log Pis Mean                 -0.20911779
Log Pis Std                  2.2479146
Log Pis Max                  8.765524
Log Pis Min                  -4.098525
Policy mu Mean               0.008849405
Policy mu Std                0.86565596
Policy mu Max                2.7208817
Policy mu Min                -3.0189126
Policy log std Mean          -0.4834056
Policy log std Std           0.24315912
Policy log std Max           0.01140514
Policy log std Min           -1.2710018
Z mean eval                  0.020714875
Z variance eval              0.003638753
total_rewards                [3211.70181024 1705.26823133 2476.91751658 2198.7684742  3179.41058638
 2685.60158297 3250.22209027 3148.55903907 3212.40646897 3161.88342927]
total_rewards_mean           2823.0739229281626
total_rewards_std            510.9545031211403
total_rewards_max            3250.2220902738245
total_rewards_min            1705.26823132987
Number of train steps total  174000
Number of env steps total    872000
Number of rollouts total     0
Train Time (s)               43.60725907096639
(Previous) Eval Time (s)     22.44162109075114
Sample Time (s)              21.817240722477436
Epoch Time (s)               87.86612088419497
Total Train Time (s)         13432.698020420037
Epoch                        173
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:32:12.446705 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #173 | Epoch Duration: 94.00288963317871
2020-01-11 04:32:12.447002 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #173 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021336246
Z variance train             0.0036425483
KL Divergence                11.828598
KL Loss                      1.1828598
QF Loss                      206.82336
VF Loss                      73.84161
Policy Loss                  -1094.8876
Q Predictions Mean           1089.9973
Q Predictions Std            490.88452
Q Predictions Max            1537.169
Q Predictions Min            -2.156173
V Predictions Mean           1095.4993
V Predictions Std            490.04346
V Predictions Max            1535.0188
V Predictions Min            5.7632036
Log Pis Mean                 -0.29387105
Log Pis Std                  2.0265224
Log Pis Max                  8.2459955
Log Pis Min                  -4.502656
Policy mu Mean               0.053000554
Policy mu Std                0.90801907
Policy mu Max                2.965024
Policy mu Min                -2.975013
Policy log std Mean          -0.46925423
Policy log std Std           0.24170576
Policy log std Max           0.076946884
Policy log std Min           -1.248456
Z mean eval                  0.007852482
Z variance eval              0.0039916374
total_rewards                [1044.72034017 1383.07693665 2606.60359075 1047.92153869  994.92585872
 2549.49209363 3224.67159922  998.11435105 2098.43315538 2956.16614415]
total_rewards_mean           1890.4125608407103
total_rewards_std            847.7696792410626
total_rewards_max            3224.6715992225595
total_rewards_min            994.9258587216386
Number of train steps total  175000
Number of env steps total    877000
Number of rollouts total     0
Train Time (s)               43.7068099710159
(Previous) Eval Time (s)     28.578150670975447
Sample Time (s)              20.129422947764397
Epoch Time (s)               92.41438358975574
Total Train Time (s)         13516.742764104623
Epoch                        174
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:33:36.491882 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #174 | Epoch Duration: 84.04465627670288
2020-01-11 04:33:36.492101 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #174 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.007866008
Z variance train             0.003990405
KL Divergence                11.500436
KL Loss                      1.1500436
QF Loss                      142.03903
VF Loss                      164.68661
Policy Loss                  -1102.7045
Q Predictions Mean           1099.3424
Q Predictions Std            479.01013
Q Predictions Max            1517.7239
Q Predictions Min            -10.295535
V Predictions Mean           1094.7654
V Predictions Std            477.32727
V Predictions Max            1508.7552
V Predictions Min            -18.192732
Log Pis Mean                 -0.3714335
Log Pis Std                  2.0703137
Log Pis Max                  8.945351
Log Pis Min                  -6.482244
Policy mu Mean               0.03080436
Policy mu Std                0.8671009
Policy mu Max                2.063836
Policy mu Min                -3.2586467
Policy log std Mean          -0.46548748
Policy log std Std           0.22229257
Policy log std Max           0.09284818
Policy log std Min           -1.218815
Z mean eval                  0.023612123
Z variance eval              0.0054831
total_rewards                [1577.58169652 1008.78717437 3253.5974917  2229.31567766 1115.78454077
 2168.22149789 1086.21068209 2507.22700384 1031.2345398  1026.34957542]
total_rewards_mean           1700.4309880067872
total_rewards_std            753.428415865902
total_rewards_max            3253.5974916988507
total_rewards_min            1008.7871743686751
Number of train steps total  176000
Number of env steps total    882000
Number of rollouts total     0
Train Time (s)               43.82617819402367
(Previous) Eval Time (s)     20.208196403924376
Sample Time (s)              21.59503490384668
Epoch Time (s)               85.62940950179473
Total Train Time (s)         13599.347300205845
Epoch                        175
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:34:59.101810 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #175 | Epoch Duration: 82.60955548286438
2020-01-11 04:34:59.102017 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #175 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023129825
Z variance train             0.0054880534
KL Divergence                10.7192745
KL Loss                      1.0719274
QF Loss                      231.17484
VF Loss                      165.10077
Policy Loss                  -1072.91
Q Predictions Mean           1072.2332
Q Predictions Std            536.7359
Q Predictions Max            1534.0034
Q Predictions Min            1.9795264
V Predictions Mean           1068.3064
V Predictions Std            537.11774
V Predictions Max            1545.0883
V Predictions Min            -10.627943
Log Pis Mean                 -0.16179407
Log Pis Std                  2.179909
Log Pis Max                  9.260807
Log Pis Min                  -4.2287726
Policy mu Mean               0.026999759
Policy mu Std                0.88678306
Policy mu Max                3.9645977
Policy mu Min                -3.3151896
Policy log std Mean          -0.48884383
Policy log std Std           0.2261824
Policy log std Max           0.0946933
Policy log std Min           -1.2309823
Z mean eval                  0.0156162055
Z variance eval              0.0042719515
total_rewards                [ 971.75480581 1356.14336931  925.4000174  2693.4622268  2454.12309809
  934.33558655 1732.14241977 2796.44269481 1734.91638364 1619.872923  ]
total_rewards_mean           1721.8593525191168
total_rewards_std            677.980480773207
total_rewards_max            2796.4426948128594
total_rewards_min            925.4000174028434
Number of train steps total  177000
Number of env steps total    887000
Number of rollouts total     0
Train Time (s)               43.330885482952
(Previous) Eval Time (s)     17.188085650093853
Sample Time (s)              20.40018577547744
Epoch Time (s)               80.91915690852329
Total Train Time (s)         13681.247109923977
Epoch                        176
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:36:21.006807 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #176 | Epoch Duration: 81.90460515022278
2020-01-11 04:36:21.007088 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #176 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01610306
Z variance train             0.0042729587
KL Divergence                11.284621
KL Loss                      1.1284622
QF Loss                      293.89377
VF Loss                      186.26671
Policy Loss                  -1125.1768
Q Predictions Mean           1120.7163
Q Predictions Std            452.11914
Q Predictions Max            1520.8728
Q Predictions Min            1.2297016
V Predictions Mean           1117.9076
V Predictions Std            452.53458
V Predictions Max            1521.9567
V Predictions Min            -22.748331
Log Pis Mean                 -0.12447047
Log Pis Std                  2.2142167
Log Pis Max                  10.982488
Log Pis Min                  -3.7226944
Policy mu Mean               0.058991324
Policy mu Std                0.89047605
Policy mu Max                2.7437801
Policy mu Min                -3.2125125
Policy log std Mean          -0.4845197
Policy log std Std           0.23294346
Policy log std Max           0.118828475
Policy log std Min           -1.3921282
Z mean eval                  0.008061169
Z variance eval              0.004962139
total_rewards                [1222.68431296 2971.92891349 3017.1004842  2994.4353217  3044.13485248
 1136.83206444 2955.83694959 1760.6555648   996.9036901  2943.29520963]
total_rewards_mean           2304.3807363401734
total_rewards_std            857.2035193076131
total_rewards_max            3044.134852481675
total_rewards_min            996.903690098098
Number of train steps total  178000
Number of env steps total    892000
Number of rollouts total     0
Train Time (s)               42.930238298140466
(Previous) Eval Time (s)     18.173276083078235
Sample Time (s)              21.944722237996757
Epoch Time (s)               83.04823661921546
Total Train Time (s)         13770.60696981661
Epoch                        177
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:37:50.368116 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #177 | Epoch Duration: 89.36081528663635
2020-01-11 04:37:50.368295 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #177 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008578257
Z variance train             0.004975738
KL Divergence                11.064215
KL Loss                      1.1064215
QF Loss                      146.25293
VF Loss                      200.29224
Policy Loss                  -1062.342
Q Predictions Mean           1064.7589
Q Predictions Std            519.4655
Q Predictions Max            1543.0243
Q Predictions Min            -18.403236
V Predictions Mean           1071.8573
V Predictions Std            519.17236
V Predictions Max            1543.7783
V Predictions Min            -2.5204515
Log Pis Mean                 -0.24810629
Log Pis Std                  2.213848
Log Pis Max                  10.103688
Log Pis Min                  -5.280247
Policy mu Mean               0.085883476
Policy mu Std                0.8883425
Policy mu Max                2.8922594
Policy mu Min                -3.2993615
Policy log std Mean          -0.47545943
Policy log std Std           0.23181254
Policy log std Max           0.16240802
Policy log std Min           -1.3227761
Z mean eval                  0.012163478
Z variance eval              0.004259481
total_rewards                [3130.07723091 3122.24027254 1067.84421348 1020.9239847  1025.37838272
 1391.56357795 3144.19846225 1658.61728522 2502.35888798 2506.8075543 ]
total_rewards_mean           2057.0009852058993
total_rewards_std            871.0076757991526
total_rewards_max            3144.1984622508207
total_rewards_min            1020.9239847032986
Number of train steps total  179000
Number of env steps total    897000
Number of rollouts total     0
Train Time (s)               43.487708563916385
(Previous) Eval Time (s)     24.4856426990591
Sample Time (s)              22.026134246960282
Epoch Time (s)               89.99948550993577
Total Train Time (s)         13856.164809009526
Epoch                        178
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:39:15.928850 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #178 | Epoch Duration: 85.5604145526886
2020-01-11 04:39:15.929020 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #178 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01284094
Z variance train             0.0042548673
KL Divergence                11.348459
KL Loss                      1.134846
QF Loss                      380.40094
VF Loss                      301.6054
Policy Loss                  -1099.4648
Q Predictions Mean           1096.0176
Q Predictions Std            489.17828
Q Predictions Max            1520.08
Q Predictions Min            -27.285255
V Predictions Mean           1105.7095
V Predictions Std            490.09476
V Predictions Max            1534.8398
V Predictions Min            -0.2583469
Log Pis Mean                 -0.49332714
Log Pis Std                  1.9054433
Log Pis Max                  6.5354166
Log Pis Min                  -4.848339
Policy mu Mean               0.09331287
Policy mu Std                0.82252616
Policy mu Max                2.6220076
Policy mu Min                -2.7139792
Policy log std Mean          -0.5206929
Policy log std Std           0.24127641
Policy log std Max           0.10641742
Policy log std Min           -1.4891624
Z mean eval                  0.01844802
Z variance eval              0.0038338914
total_rewards                [3282.10574655 1135.73111024 1955.08335952 1043.98679005 3214.07935795
  965.94372299  891.06236569 2385.84629845 1113.60857162 1092.9087823 ]
total_rewards_mean           1708.0356105378742
total_rewards_std            893.570810286251
total_rewards_max            3282.1057465524864
total_rewards_min            891.0623656884121
Number of train steps total  180000
Number of env steps total    902000
Number of rollouts total     0
Train Time (s)               43.7229773318395
(Previous) Eval Time (s)     20.046329407021403
Sample Time (s)              22.0456804134883
Epoch Time (s)               85.8149871523492
Total Train Time (s)         13938.645479021594
Epoch                        179
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:40:38.412320 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #179 | Epoch Duration: 82.4831805229187
2020-01-11 04:40:38.412446 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #179 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018081207
Z variance train             0.0038323023
KL Divergence                11.567029
KL Loss                      1.1567029
QF Loss                      287.73474
VF Loss                      377.75394
Policy Loss                  -1161.5773
Q Predictions Mean           1156.7075
Q Predictions Std            463.01758
Q Predictions Max            1564.6418
Q Predictions Min            -4.8180165
V Predictions Mean           1160.2646
V Predictions Std            462.8382
V Predictions Max            1553.8677
V Predictions Min            -5.5320635
Log Pis Mean                 -0.0892014
Log Pis Std                  2.5720031
Log Pis Max                  15.41733
Log Pis Min                  -6.3668528
Policy mu Mean               0.055445954
Policy mu Std                0.8990188
Policy mu Max                4.2386985
Policy mu Min                -3.4472651
Policy log std Mean          -0.48154044
Policy log std Std           0.23496893
Policy log std Max           0.11988944
Policy log std Min           -1.5242023
Z mean eval                  0.015217182
Z variance eval              0.0038263933
total_rewards                [1095.73706989 1675.73917354  993.01576864 2570.58996392 1193.66198768
 2218.50205921 1757.49694324 1771.17928942 2973.57139006 1322.01819275]
total_rewards_mean           1757.151183835663
total_rewards_std            623.6395254450773
total_rewards_max            2973.571390059141
total_rewards_min            993.0157686365063
Number of train steps total  181000
Number of env steps total    907000
Number of rollouts total     0
Train Time (s)               44.5986869209446
(Previous) Eval Time (s)     16.7142835278064
Sample Time (s)              21.85690538212657
Epoch Time (s)               83.16987583087757
Total Train Time (s)         14023.978694025893
Epoch                        180
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:42:03.747244 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #180 | Epoch Duration: 85.33470487594604
2020-01-11 04:42:03.747369 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #180 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013710159
Z variance train             0.0038258457
KL Divergence                11.584442
KL Loss                      1.1584443
QF Loss                      183.6096
VF Loss                      137.22066
Policy Loss                  -1121.3563
Q Predictions Mean           1120.07
Q Predictions Std            505.84454
Q Predictions Max            1545.6417
Q Predictions Min            -10.713402
V Predictions Mean           1115.0332
V Predictions Std            504.03598
V Predictions Max            1529.99
V Predictions Min            -20.189768
Log Pis Mean                 -0.2506926
Log Pis Std                  2.1635647
Log Pis Max                  7.6053705
Log Pis Min                  -7.5949736
Policy mu Mean               0.08864232
Policy mu Std                0.87353927
Policy mu Max                2.5727518
Policy mu Min                -2.8332033
Policy log std Mean          -0.4822086
Policy log std Std           0.22961049
Policy log std Max           0.11129475
Policy log std Min           -1.1586103
Z mean eval                  0.018315133
Z variance eval              0.003053553
total_rewards                [1058.16242881  910.2546114  2088.2718819  1085.07562321  935.94699334
 1734.77129715 2388.35205601 1597.07332087  969.81407618 1021.02269478]
total_rewards_mean           1378.8744983637946
total_rewards_std            509.59931031775795
total_rewards_max            2388.35205600637
total_rewards_min            910.2546113998287
Number of train steps total  182000
Number of env steps total    912000
Number of rollouts total     0
Train Time (s)               41.70687668211758
(Previous) Eval Time (s)     18.878882273100317
Sample Time (s)              21.9269639714621
Epoch Time (s)               82.51272292668
Total Train Time (s)         14100.69206480356
Epoch                        181
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:43:20.466648 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #181 | Epoch Duration: 76.71914005279541
2020-01-11 04:43:20.466934 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #181 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0179437
Z variance train             0.0030525927
KL Divergence                12.063272
KL Loss                      1.2063273
QF Loss                      204.14589
VF Loss                      178.51295
Policy Loss                  -1178.1229
Q Predictions Mean           1182.6672
Q Predictions Std            449.97635
Q Predictions Max            1565.0376
Q Predictions Min            3.5983942
V Predictions Mean           1174.6311
V Predictions Std            449.25137
V Predictions Max            1564.6451
V Predictions Min            -2.594541
Log Pis Mean                 -0.28508085
Log Pis Std                  1.9126573
Log Pis Max                  8.253434
Log Pis Min                  -5.194576
Policy mu Mean               -0.042875484
Policy mu Std                0.8750198
Policy mu Max                2.634834
Policy mu Min                -3.5194235
Policy log std Mean          -0.4791832
Policy log std Std           0.23538543
Policy log std Max           0.16652054
Policy log std Min           -1.2328839
Z mean eval                  0.021576975
Z variance eval              0.0026662447
total_rewards                [1164.05854673 1144.56135666 1074.39030983 1033.64155712 3234.54708097
 1036.03539615 1229.23570495 1023.88465469 1204.91526216 1066.65859187]
total_rewards_mean           1321.1928461109796
total_rewards_std            641.6293903613356
total_rewards_max            3234.5470809689455
total_rewards_min            1023.8846546858971
Number of train steps total  183000
Number of env steps total    917000
Number of rollouts total     0
Train Time (s)               44.60288444068283
(Previous) Eval Time (s)     13.085050599649549
Sample Time (s)              22.345412254333496
Epoch Time (s)               80.03334729466587
Total Train Time (s)         14180.685672479682
Epoch                        182
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:44:40.461924 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #182 | Epoch Duration: 79.99477648735046
2020-01-11 04:44:40.462099 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #182 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021763753
Z variance train             0.002666529
KL Divergence                12.354012
KL Loss                      1.2354012
QF Loss                      218.41199
VF Loss                      102.912186
Policy Loss                  -1082.4524
Q Predictions Mean           1080.0957
Q Predictions Std            511.06354
Q Predictions Max            1555.6293
Q Predictions Min            -9.754769
V Predictions Mean           1084.7258
V Predictions Std            509.3415
V Predictions Max            1554.2402
V Predictions Min            1.2363029
Log Pis Mean                 -0.38709256
Log Pis Std                  1.9988143
Log Pis Max                  7.817296
Log Pis Min                  -5.870285
Policy mu Mean               0.061376408
Policy mu Std                0.824286
Policy mu Max                2.0639904
Policy mu Min                -3.2623286
Policy log std Mean          -0.467122
Policy log std Std           0.2309971
Policy log std Max           0.09779668
Policy log std Min           -1.2350397
Z mean eval                  0.02388385
Z variance eval              0.0029803265
total_rewards                [2943.20639055 1033.25907688  983.3953163  1175.3838799   941.80150237
 2075.18330002  889.28503044 1465.53987913 3134.83446819 1008.151584  ]
total_rewards_mean           1565.0040427768665
total_rewards_std            810.0538754917463
total_rewards_max            3134.8344681931526
total_rewards_min            889.2850304380007
Number of train steps total  184000
Number of env steps total    922000
Number of rollouts total     0
Train Time (s)               44.16107143368572
(Previous) Eval Time (s)     13.046249131672084
Sample Time (s)              21.695287214126438
Epoch Time (s)               78.90260777948424
Total Train Time (s)         14261.876244002953
Epoch                        183
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:46:01.657510 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #183 | Epoch Duration: 81.19526219367981
2020-01-11 04:46:01.657714 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #183 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023284368
Z variance train             0.0029778106
KL Divergence                12.191868
KL Loss                      1.2191868
QF Loss                      209.82837
VF Loss                      251.14795
Policy Loss                  -1185.7664
Q Predictions Mean           1179.299
Q Predictions Std            416.56506
Q Predictions Max            1510.3729
Q Predictions Min            -1.5522921
V Predictions Mean           1177.7196
V Predictions Std            408.5584
V Predictions Max            1510.5948
V Predictions Min            0.57140833
Log Pis Mean                 -0.23376283
Log Pis Std                  2.1275492
Log Pis Max                  8.563822
Log Pis Min                  -6.036002
Policy mu Mean               0.014221775
Policy mu Std                0.93928665
Policy mu Max                2.3994505
Policy mu Min                -4.065844
Policy log std Mean          -0.49950647
Policy log std Std           0.23068333
Policy log std Max           0.1673387
Policy log std Min           -1.7543554
Z mean eval                  0.018822346
Z variance eval              0.0028909459
total_rewards                [3201.74093112 3164.78594765 3147.68710295 3204.79263515 3204.34204614
 3162.9614454  1193.33188367 3199.98101377 3199.33700149 3188.08187624]
total_rewards_mean           2986.704188357563
total_rewards_std            598.1054885890104
total_rewards_max            3204.792635145841
total_rewards_min            1193.331883674306
Number of train steps total  185000
Number of env steps total    927000
Number of rollouts total     0
Train Time (s)               44.22911007422954
(Previous) Eval Time (s)     15.338651848956943
Sample Time (s)              22.036988372448832
Epoch Time (s)               81.60475029563531
Total Train Time (s)         14360.080268810969
Epoch                        184
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:47:39.867264 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #184 | Epoch Duration: 98.20936417579651
2020-01-11 04:47:39.867547 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #184 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019824352
Z variance train             0.0028969024
KL Divergence                12.379459
KL Loss                      1.2379459
QF Loss                      1425.1226
VF Loss                      224.60078
Policy Loss                  -1174.5667
Q Predictions Mean           1172.304
Q Predictions Std            470.29803
Q Predictions Max            1544.208
Q Predictions Min            1.124646
V Predictions Mean           1169.3042
V Predictions Std            470.09576
V Predictions Max            1558.3655
V Predictions Min            -7.369547
Log Pis Mean                 -0.34580493
Log Pis Std                  2.154456
Log Pis Max                  7.454268
Log Pis Min                  -4.9795647
Policy mu Mean               -0.058515567
Policy mu Std                0.86249113
Policy mu Max                2.7206547
Policy mu Min                -3.2532654
Policy log std Mean          -0.49587512
Policy log std Std           0.23324896
Policy log std Max           0.14051604
Policy log std Min           -1.2554978
Z mean eval                  0.014856255
Z variance eval              0.0027972218
total_rewards                [1604.48102985 2078.04545566 1059.08276217 1102.20138769 1196.33668759
 1587.51036725 1009.85244863 1037.43899794 2758.96744963 1861.38226102]
total_rewards_mean           1529.5298847431561
total_rewards_std            543.9354182532
total_rewards_max            2758.967449633564
total_rewards_min            1009.8524486297723
Number of train steps total  186000
Number of env steps total    932000
Number of rollouts total     0
Train Time (s)               44.28684279229492
(Previous) Eval Time (s)     31.942998162005097
Sample Time (s)              22.27276735054329
Epoch Time (s)               98.5026083048433
Total Train Time (s)         14440.533394036349
Epoch                        185
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:49:00.321066 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #185 | Epoch Duration: 80.45331263542175
2020-01-11 04:49:00.321218 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #185 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014976008
Z variance train             0.0027954425
KL Divergence                12.482615
KL Loss                      1.2482616
QF Loss                      241.52145
VF Loss                      133.63995
Policy Loss                  -1119.1564
Q Predictions Mean           1117.6073
Q Predictions Std            489.3103
Q Predictions Max            1539.7072
Q Predictions Min            -23.991625
V Predictions Mean           1119.1819
V Predictions Std            486.5596
V Predictions Max            1537.9445
V Predictions Min            -24.175064
Log Pis Mean                 -0.05996167
Log Pis Std                  2.1691263
Log Pis Max                  9.936602
Log Pis Min                  -4.6767015
Policy mu Mean               0.12531225
Policy mu Std                0.90681964
Policy mu Max                4.153851
Policy mu Min                -3.1144218
Policy log std Mean          -0.47706082
Policy log std Std           0.24123324
Policy log std Max           0.1577161
Policy log std Min           -1.4028671
Z mean eval                  0.013264294
Z variance eval              0.003415869
total_rewards                [ 956.68938747 1075.88063671 3245.79065602 2895.00844096 1644.0900361
 1224.05250342 1517.52041554 1600.36030691 2954.57442537 2280.7471989 ]
total_rewards_mean           1939.471400739109
total_rewards_std            798.1345227072584
total_rewards_max            3245.7906560195943
total_rewards_min            956.6893874673672
Number of train steps total  187000
Number of env steps total    937000
Number of rollouts total     0
Train Time (s)               44.78130257735029
(Previous) Eval Time (s)     13.89348960109055
Sample Time (s)              21.777604229282588
Epoch Time (s)               80.45239640772343
Total Train Time (s)         14526.664993757382
Epoch                        186
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:50:26.454965 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #186 | Epoch Duration: 86.13361501693726
2020-01-11 04:50:26.455140 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #186 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01300182
Z variance train             0.0034137801
KL Divergence                12.095702
KL Loss                      1.2095703
QF Loss                      259.96173
VF Loss                      126.72494
Policy Loss                  -1089.4034
Q Predictions Mean           1089.995
Q Predictions Std            494.9882
Q Predictions Max            1544.1311
Q Predictions Min            -28.255194
V Predictions Mean           1088.8125
V Predictions Std            494.65598
V Predictions Max            1529.3588
V Predictions Min            -10.446766
Log Pis Mean                 -0.086189196
Log Pis Std                  2.4946735
Log Pis Max                  10.306862
Log Pis Min                  -6.4503655
Policy mu Mean               0.09457541
Policy mu Std                0.93092656
Policy mu Max                2.8907032
Policy mu Min                -2.8351297
Policy log std Mean          -0.4709599
Policy log std Std           0.22873373
Policy log std Max           0.12300217
Policy log std Min           -1.844729
Z mean eval                  0.018170072
Z variance eval              0.0034401126
total_rewards                [ 724.10221798 2053.90887828 2545.09004639 2317.75041409  892.14694226
 1051.35500813 1552.6351962   986.4829806  1212.17820422 1360.95662911]
total_rewards_mean           1469.6606517276575
total_rewards_std            599.9974087098893
total_rewards_max            2545.0900463875746
total_rewards_min            724.10221798427
Number of train steps total  188000
Number of env steps total    942000
Number of rollouts total     0
Train Time (s)               44.66001005098224
(Previous) Eval Time (s)     19.57447471981868
Sample Time (s)              21.76623470708728
Epoch Time (s)               86.0007194778882
Total Train Time (s)         14608.446604315192
Epoch                        187
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:51:48.238213 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #187 | Epoch Duration: 81.78294801712036
2020-01-11 04:51:48.238344 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #187 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01794054
Z variance train             0.0034479103
KL Divergence                12.116485
KL Loss                      1.2116485
QF Loss                      503.6012
VF Loss                      331.7635
Policy Loss                  -1140.3617
Q Predictions Mean           1141.526
Q Predictions Std            493.33124
Q Predictions Max            1561.189
Q Predictions Min            -2.9676867
V Predictions Mean           1143.7874
V Predictions Std            494.14148
V Predictions Max            1564.3298
V Predictions Min            4.8664274
Log Pis Mean                 -0.3192205
Log Pis Std                  1.7811723
Log Pis Max                  5.535537
Log Pis Min                  -4.951517
Policy mu Mean               0.106736906
Policy mu Std                0.82758784
Policy mu Max                2.4357798
Policy mu Min                -2.9895103
Policy log std Mean          -0.4749298
Policy log std Std           0.23320298
Policy log std Max           0.10712379
Policy log std Min           -1.38518
Z mean eval                  0.0123237055
Z variance eval              0.0035206913
total_rewards                [1014.52222151 1599.85720263 1157.02144662 1612.75713093 2151.02873441
 3180.27966498 1580.99243157 1052.77144908 1053.38205866 1704.06399539]
total_rewards_mean           1610.6676335784512
total_rewards_std            628.3626626250451
total_rewards_max            3180.279664981538
total_rewards_min            1014.5222215136326
Number of train steps total  189000
Number of env steps total    947000
Number of rollouts total     0
Train Time (s)               43.34727043332532
(Previous) Eval Time (s)     15.356479268986732
Sample Time (s)              21.975702182389796
Epoch Time (s)               80.67945188470185
Total Train Time (s)         14690.017347175162
Epoch                        188
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:53:09.811957 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #188 | Epoch Duration: 81.57350659370422
2020-01-11 04:53:09.812126 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #188 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012244986
Z variance train             0.0035206291
KL Divergence                11.947423
KL Loss                      1.1947423
QF Loss                      846.3314
VF Loss                      113.198616
Policy Loss                  -1138.8221
Q Predictions Mean           1135.5826
Q Predictions Std            498.95584
Q Predictions Max            1572.6163
Q Predictions Min            -7.687351
V Predictions Mean           1142.5176
V Predictions Std            498.74225
V Predictions Max            1578.9606
V Predictions Min            -5.8928385
Log Pis Mean                 -0.036196634
Log Pis Std                  2.303803
Log Pis Max                  9.02129
Log Pis Min                  -5.090041
Policy mu Mean               0.068963915
Policy mu Std                0.9510611
Policy mu Max                3.7669408
Policy mu Min                -3.1495874
Policy log std Mean          -0.50202256
Policy log std Std           0.23017001
Policy log std Max           0.15092197
Policy log std Min           -1.2717228
Z mean eval                  0.014792332
Z variance eval              0.0039329873
total_rewards                [3131.53053346  952.07569272 1061.90974798 2806.39508822  993.59807331
 1235.92562042 1498.22218677 1093.96262348 1002.2871679  2006.56965309]
total_rewards_mean           1578.2476387341617
total_rewards_std            761.2395005262347
total_rewards_max            3131.5305334611294
total_rewards_min            952.0756927163127
Number of train steps total  190000
Number of env steps total    952000
Number of rollouts total     0
Train Time (s)               44.75147570669651
(Previous) Eval Time (s)     16.250286477152258
Sample Time (s)              22.09293058188632
Epoch Time (s)               83.09469276573509
Total Train Time (s)         14773.16927336296
Epoch                        189
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:54:32.965500 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #189 | Epoch Duration: 83.15325975418091
2020-01-11 04:54:32.965626 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #189 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0145598175
Z variance train             0.0039320285
KL Divergence                11.863512
KL Loss                      1.1863512
QF Loss                      406.28186
VF Loss                      153.41101
Policy Loss                  -1120.3728
Q Predictions Mean           1115.8406
Q Predictions Std            508.53967
Q Predictions Max            1538.678
Q Predictions Min            -8.319982
V Predictions Mean           1113.6245
V Predictions Std            506.01938
V Predictions Max            1522.3909
V Predictions Min            -3.2242422
Log Pis Mean                 -0.2777219
Log Pis Std                  1.9796468
Log Pis Max                  8.295145
Log Pis Min                  -4.1157637
Policy mu Mean               0.1428327
Policy mu Std                0.8699403
Policy mu Max                3.2704368
Policy mu Min                -2.864975
Policy log std Mean          -0.4834118
Policy log std Std           0.23122028
Policy log std Max           -0.02258405
Policy log std Min           -1.3316936
Z mean eval                  0.01945493
Z variance eval              0.004057315
total_rewards                [1523.8649238  1510.94419471 1590.70699056 1579.45115157 1719.53800325
 1292.36500475 1502.67053544 2467.0889286   996.71462547 1194.28358864]
total_rewards_mean           1537.7627946806115
total_rewards_std            370.71624095654437
total_rewards_max            2467.088928604978
total_rewards_min            996.7146254729024
Number of train steps total  191000
Number of env steps total    957000
Number of rollouts total     0
Train Time (s)               43.21584547823295
(Previous) Eval Time (s)     16.308607785962522
Sample Time (s)              21.795715249609202
Epoch Time (s)               81.32016851380467
Total Train Time (s)         14855.072379310615
Epoch                        190
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:55:54.869619 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #190 | Epoch Duration: 81.90389895439148
2020-01-11 04:55:54.869736 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #190 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019652748
Z variance train             0.0040552355
KL Divergence                11.559088
KL Loss                      1.1559088
QF Loss                      183.75993
VF Loss                      88.105415
Policy Loss                  -1150.985
Q Predictions Mean           1150.1697
Q Predictions Std            481.97183
Q Predictions Max            1543.3997
Q Predictions Min            -0.66412634
V Predictions Mean           1153.8438
V Predictions Std            481.58493
V Predictions Max            1546.1389
V Predictions Min            -2.9243274
Log Pis Mean                 -0.332484
Log Pis Std                  2.0494928
Log Pis Max                  9.960827
Log Pis Min                  -3.9416966
Policy mu Mean               0.03881358
Policy mu Std                0.84852135
Policy mu Max                2.6081614
Policy mu Min                -3.488217
Policy log std Mean          -0.4872789
Policy log std Std           0.21771762
Policy log std Max           0.048890233
Policy log std Min           -1.3443143
Z mean eval                  0.023752669
Z variance eval              0.0042185234
total_rewards                [1150.277622   2560.82616395 1003.36341348 1711.25317017 1028.87855448
 2687.56959166 1303.40102624 1043.63233258 1841.88115111 3285.61661355]
total_rewards_mean           1761.6699639239243
total_rewards_std            777.0927203657716
total_rewards_max            3285.6166135543594
total_rewards_min            1003.3634134838072
Number of train steps total  192000
Number of env steps total    962000
Number of rollouts total     0
Train Time (s)               42.8692779308185
(Previous) Eval Time (s)     16.892097516916692
Sample Time (s)              21.755071406252682
Epoch Time (s)               81.51644685398787
Total Train Time (s)         14937.674719954375
Epoch                        191
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:57:17.473990 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #191 | Epoch Duration: 82.6041648387909
2020-01-11 04:57:17.474112 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #191 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024168978
Z variance train             0.004213297
KL Divergence                11.451375
KL Loss                      1.1451375
QF Loss                      174.57013
VF Loss                      111.90666
Policy Loss                  -1180.775
Q Predictions Mean           1178.435
Q Predictions Std            469.0828
Q Predictions Max            1572.9298
Q Predictions Min            -2.801859
V Predictions Mean           1188.6722
V Predictions Std            471.5542
V Predictions Max            1584.8398
V Predictions Min            4.2536607
Log Pis Mean                 -0.41272938
Log Pis Std                  1.9040238
Log Pis Max                  7.0212135
Log Pis Min                  -4.7679358
Policy mu Mean               0.036122803
Policy mu Std                0.81874794
Policy mu Max                2.739126
Policy mu Min                -2.9731245
Policy log std Mean          -0.5242738
Policy log std Std           0.21842456
Policy log std Max           -0.023830295
Policy log std Min           -1.399243
Z mean eval                  0.017603707
Z variance eval              0.004857211
total_rewards                [3070.48950085 2437.95397953 2244.42935821  996.50781406 3085.0317298
 1636.49957542 3044.0421019  3103.27150161 1555.32250674 3113.82582125]
total_rewards_mean           2428.737388935024
total_rewards_std            749.7560012781107
total_rewards_max            3113.8258212489104
total_rewards_min            996.5078140591431
Number of train steps total  193000
Number of env steps total    967000
Number of rollouts total     0
Train Time (s)               43.68292181007564
(Previous) Eval Time (s)     17.979583289008588
Sample Time (s)              21.750415809452534
Epoch Time (s)               83.41292090853676
Total Train Time (s)         15026.840525049716
Epoch                        192
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:58:46.643999 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #192 | Epoch Duration: 89.1697449684143
2020-01-11 04:58:46.644217 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #192 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017088164
Z variance train             0.0048592766
KL Divergence                11.020395
KL Loss                      1.1020396
QF Loss                      339.77258
VF Loss                      102.657104
Policy Loss                  -1127.846
Q Predictions Mean           1126.2327
Q Predictions Std            489.11993
Q Predictions Max            1544.7977
Q Predictions Min            0.007358074
V Predictions Mean           1130.7838
V Predictions Std            491.4053
V Predictions Max            1554.1394
V Predictions Min            3.5224512
Log Pis Mean                 -0.4935164
Log Pis Std                  1.8496336
Log Pis Max                  6.388857
Log Pis Min                  -5.263729
Policy mu Mean               -0.048658594
Policy mu Std                0.82730305
Policy mu Max                2.3163548
Policy mu Min                -2.9031472
Policy log std Mean          -0.48999175
Policy log std Std           0.21342637
Policy log std Max           0.042591333
Policy log std Min           -1.2588029
Z mean eval                  0.030934233
Z variance eval              0.004388688
total_rewards                [1014.51416566 3132.98684585 1024.51743421 3194.53754548 1013.77843607
 1802.71949666 1620.66555353 3237.81168252 1007.94320149  681.05820312]
total_rewards_mean           1773.0532564595499
total_rewards_std            976.2012380188479
total_rewards_max            3237.811682517938
total_rewards_min            681.0582031182636
Number of train steps total  194000
Number of env steps total    972000
Number of rollouts total     0
Train Time (s)               43.72480677906424
(Previous) Eval Time (s)     23.736151784658432
Sample Time (s)              19.89468353614211
Epoch Time (s)               87.35564209986478
Total Train Time (s)         15106.811188797466
Epoch                        193
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:00:06.617536 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #193 | Epoch Duration: 79.9731605052948
2020-01-11 05:00:06.617738 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #193 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03077724
Z variance train             0.004388277
KL Divergence                11.21661
KL Loss                      1.1216611
QF Loss                      226.13716
VF Loss                      147.39603
Policy Loss                  -1164.9373
Q Predictions Mean           1159.2208
Q Predictions Std            449.64404
Q Predictions Max            1528.6093
Q Predictions Min            -30.08054
V Predictions Mean           1158.9036
V Predictions Std            447.59277
V Predictions Max            1529.1702
V Predictions Min            -5.73038
Log Pis Mean                 -0.19999383
Log Pis Std                  2.38144
Log Pis Max                  10.279375
Log Pis Min                  -4.5973263
Policy mu Mean               -0.059345108
Policy mu Std                0.9100361
Policy mu Max                2.2799993
Policy mu Min                -3.6335988
Policy log std Mean          -0.51016915
Policy log std Std           0.21693766
Policy log std Max           0.046572387
Policy log std Min           -1.2088747
Z mean eval                  0.030039797
Z variance eval              0.0043648616
total_rewards                [1028.80651856 2622.65025197 1009.16834978 1110.29494826 1020.86381438
 1271.50474484 2602.3145714  1033.55037403 2909.04823849 1027.00384053]
total_rewards_mean           1563.5205652228838
total_rewards_std            758.8412573461159
total_rewards_max            2909.0482384901493
total_rewards_min            1009.1683497816089
Number of train steps total  195000
Number of env steps total    977000
Number of rollouts total     0
Train Time (s)               43.22048602858558
(Previous) Eval Time (s)     16.35344455484301
Sample Time (s)              21.466133874375373
Epoch Time (s)               81.04006445780396
Total Train Time (s)         15186.128562559374
Epoch                        194
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:01:25.938113 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #194 | Epoch Duration: 79.32021880149841
2020-01-11 05:01:25.938277 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #194 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030827206
Z variance train             0.0043564783
KL Divergence                11.19804
KL Loss                      1.119804
QF Loss                      511.02786
VF Loss                      257.58478
Policy Loss                  -1207.7919
Q Predictions Mean           1209.2124
Q Predictions Std            409.76434
Q Predictions Max            1548.1124
Q Predictions Min            -2.2403982
V Predictions Mean           1214.606
V Predictions Std            408.86664
V Predictions Max            1545.1633
V Predictions Min            -0.5067636
Log Pis Mean                 -0.24150309
Log Pis Std                  2.005313
Log Pis Max                  7.4469476
Log Pis Min                  -5.3604274
Policy mu Mean               0.03634503
Policy mu Std                0.8529565
Policy mu Max                3.0121446
Policy mu Min                -3.2231958
Policy log std Mean          -0.52735674
Policy log std Std           0.21264991
Policy log std Max           0.13919857
Policy log std Min           -1.333417
Z mean eval                  0.018892512
Z variance eval              0.003317495
total_rewards                [1892.03346179 3162.40296962 1153.58484302 1998.70266326 3187.4329717
 1858.53337584 3045.28065079 3201.22467779 3150.19941314 3179.76369744]
total_rewards_mean           2582.915872437862
total_rewards_std            732.2371132401922
total_rewards_max            3201.2246777873584
total_rewards_min            1153.5848430174544
Number of train steps total  196000
Number of env steps total    982000
Number of rollouts total     0
Train Time (s)               44.47256170492619
(Previous) Eval Time (s)     14.633364179171622
Sample Time (s)              19.91438814206049
Epoch Time (s)               79.0203140261583
Total Train Time (s)         15277.606904549524
Epoch                        195
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:02:57.419083 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #195 | Epoch Duration: 91.48067927360535
2020-01-11 05:02:57.419215 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #195 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01880539
Z variance train             0.0033175282
KL Divergence                11.841234
KL Loss                      1.1841234
QF Loss                      116.21336
VF Loss                      64.979546
Policy Loss                  -1207.2327
Q Predictions Mean           1206.9762
Q Predictions Std            433.21234
Q Predictions Max            1546.6102
Q Predictions Min            -2.9335935
V Predictions Mean           1208.364
V Predictions Std            431.42078
V Predictions Max            1544.0197
V Predictions Min            2.4136372
Log Pis Mean                 -0.32060227
Log Pis Std                  2.0599244
Log Pis Max                  10.917427
Log Pis Min                  -5.373156
Policy mu Mean               0.063571684
Policy mu Std                0.8373196
Policy mu Max                2.3331144
Policy mu Min                -2.9403534
Policy log std Mean          -0.4769946
Policy log std Std           0.20384109
Policy log std Max           0.097341925
Policy log std Min           -1.1007557
Z mean eval                  0.015268816
Z variance eval              0.0031830494
total_rewards                [3158.99907803 3086.83205382 3095.01165532 3106.08400032 1947.91448727
 3090.88116541 3123.81228007 2256.52091427 3187.03714257 2709.03506764]
total_rewards_mean           2876.212784472092
total_rewards_std            412.64345667578385
total_rewards_max            3187.037142570857
total_rewards_min            1947.9144872712134
Number of train steps total  197000
Number of env steps total    987000
Number of rollouts total     0
Train Time (s)               44.32374408701435
(Previous) Eval Time (s)     27.093496945220977
Sample Time (s)              22.318190350197256
Epoch Time (s)               93.73543138243258
Total Train Time (s)         15373.713131201454
Epoch                        196
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:04:33.526247 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #196 | Epoch Duration: 96.10693073272705
2020-01-11 05:04:33.526366 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #196 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015274443
Z variance train             0.0031846142
KL Divergence                11.987745
KL Loss                      1.1987746
QF Loss                      160.3
VF Loss                      105.534195
Policy Loss                  -1177.3151
Q Predictions Mean           1174.1355
Q Predictions Std            479.29935
Q Predictions Max            1547.5903
Q Predictions Min            -5.524525
V Predictions Mean           1180.5984
V Predictions Std            479.18362
V Predictions Max            1553.1918
V Predictions Min            4.304989
Log Pis Mean                 -0.31184652
Log Pis Std                  2.1220825
Log Pis Max                  8.662821
Log Pis Min                  -5.078973
Policy mu Mean               -0.0021701083
Policy mu Std                0.89131415
Policy mu Max                2.6295798
Policy mu Min                -2.9684515
Policy log std Mean          -0.4804374
Policy log std Std           0.21590127
Policy log std Max           0.090103924
Policy log std Min           -1.3737757
Z mean eval                  0.037805535
Z variance eval              0.0032305538
total_rewards                [3153.93733319 3130.94917666 3122.27412745 1621.19204782 2406.06881729
 1170.65600769 3151.1349692  2905.27414081 3083.98610243 2435.74231434]
total_rewards_mean           2618.121503687874
total_rewards_std            674.9150851571559
total_rewards_max            3153.9373331861457
total_rewards_min            1170.6560076899111
Number of train steps total  198000
Number of env steps total    992000
Number of rollouts total     0
Train Time (s)               43.67423610622063
(Previous) Eval Time (s)     29.464749246370047
Sample Time (s)              22.036765900906175
Epoch Time (s)               95.17575125349686
Total Train Time (s)         15467.20967237465
Epoch                        197
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:06:07.028895 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #197 | Epoch Duration: 93.50243830680847
2020-01-11 05:06:07.029020 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #197 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03691311
Z variance train             0.0032326956
KL Divergence                11.966248
KL Loss                      1.1966248
QF Loss                      159.69989
VF Loss                      150.87875
Policy Loss                  -1142.667
Q Predictions Mean           1145.2605
Q Predictions Std            468.63693
Q Predictions Max            1552.6437
Q Predictions Min            -7.055111
V Predictions Mean           1145.8833
V Predictions Std            468.238
V Predictions Max            1546.6464
V Predictions Min            -12.393055
Log Pis Mean                 -0.07745637
Log Pis Std                  2.2151976
Log Pis Max                  7.110168
Log Pis Min                  -5.2693157
Policy mu Mean               -0.048183363
Policy mu Std                0.92293465
Policy mu Max                2.4614213
Policy mu Min                -3.009604
Policy log std Mean          -0.5061874
Policy log std Std           0.21675076
Policy log std Max           0.043223143
Policy log std Min           -1.4402633
Z mean eval                  0.018889781
Z variance eval              0.0035749222
total_rewards                [1288.09600515 1035.07673633 1608.02440838 1063.70006217 1034.40986044
 1016.71821803 1040.87560634 3270.79320895 2400.98456704 3322.61017616]
total_rewards_mean           1708.1288848997458
total_rewards_std            892.2122968368233
total_rewards_max            3322.610176163913
total_rewards_min            1016.7182180271977
Number of train steps total  199000
Number of env steps total    997000
Number of rollouts total     0
Train Time (s)               44.275767508894205
(Previous) Eval Time (s)     27.79119976889342
Sample Time (s)              22.41465205932036
Epoch Time (s)               94.48161933710799
Total Train Time (s)         15551.385866529308
Epoch                        198
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:07:31.204484 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #198 | Epoch Duration: 84.17535471916199
2020-01-11 05:07:31.204658 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #198 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01858059
Z variance train             0.0035775006
KL Divergence                11.776364
KL Loss                      1.1776365
QF Loss                      4715.275
VF Loss                      104.21139
Policy Loss                  -1178.1321
Q Predictions Mean           1181.7913
Q Predictions Std            458.94037
Q Predictions Max            1553.0901
Q Predictions Min            3.2410142
V Predictions Mean           1173.3811
V Predictions Std            457.5343
V Predictions Max            1554.1816
V Predictions Min            -3.0221329
Log Pis Mean                 -0.3109426
Log Pis Std                  2.0714126
Log Pis Max                  9.377509
Log Pis Min                  -5.6987057
Policy mu Mean               0.05807909
Policy mu Std                0.8693893
Policy mu Max                3.4828112
Policy mu Min                -3.3001754
Policy log std Mean          -0.46214628
Policy log std Std           0.21543227
Policy log std Max           0.1103428
Policy log std Min           -1.6595414
Z mean eval                  0.031943996
Z variance eval              0.003342526
total_rewards                [1744.03436812 1541.42969003 3214.88497051 3187.93937359 2418.45656737
 3230.50923855 2557.80332709 1876.46789893 1999.75523599 1314.001163  ]
total_rewards_mean           2308.5281833177123
total_rewards_std            685.3694086177038
total_rewards_max            3230.509238549829
total_rewards_min            1314.0011630008569
Number of train steps total  200000
Number of env steps total    1002000
Number of rollouts total     0
Train Time (s)               43.026417300105095
(Previous) Eval Time (s)     17.484661316964775
Sample Time (s)              20.92107463441789
Epoch Time (s)               81.43215325148776
Total Train Time (s)         15639.192854267545
Epoch                        199
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:08:59.013032 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #199 | Epoch Duration: 87.80824160575867
2020-01-11 05:08:59.013172 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #199 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031612895
Z variance train             0.0033456583
KL Divergence                11.985376
KL Loss                      1.1985377
QF Loss                      490.61633
VF Loss                      609.83075
Policy Loss                  -1176.8396
Q Predictions Mean           1168.1704
Q Predictions Std            469.75723
Q Predictions Max            1565.7117
Q Predictions Min            4.5447016
V Predictions Mean           1163.5347
V Predictions Std            470.28757
V Predictions Max            1558.0125
V Predictions Min            -8.2154875
Log Pis Mean                 0.07433174
Log Pis Std                  2.4951713
Log Pis Max                  15.345135
Log Pis Min                  -5.0008087
Policy mu Mean               0.15613176
Policy mu Std                0.94914556
Policy mu Max                3.125331
Policy mu Min                -4.7276073
Policy log std Mean          -0.48707262
Policy log std Std           0.22827569
Policy log std Max           0.03204027
Policy log std Min           -1.5318503
Z mean eval                  0.028957814
Z variance eval              0.0045722546
total_rewards                [2289.58442023 1219.97060041 1051.47645927 1966.58057771 1037.80620792
 3223.94429554 1857.04351884 1572.71389711 1548.43042244 1343.7006299 ]
total_rewards_mean           1711.1251029360071
total_rewards_std            634.0459093895104
total_rewards_max            3223.9442955371524
total_rewards_min            1037.806207919064
Number of train steps total  201000
Number of env steps total    1007000
Number of rollouts total     0
Train Time (s)               43.72235556598753
(Previous) Eval Time (s)     23.860535346902907
Sample Time (s)              22.1971800676547
Epoch Time (s)               89.78007098054513
Total Train Time (s)         15721.378439617809
Epoch                        200
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:10:21.200883 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #200 | Epoch Duration: 82.18759822845459
2020-01-11 05:10:21.201056 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #200 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026658272
Z variance train             0.0045854645
KL Divergence                11.132504
KL Loss                      1.1132505
QF Loss                      287.7243
VF Loss                      128.31944
Policy Loss                  -1203.6218
Q Predictions Mean           1208.1453
Q Predictions Std            443.2779
Q Predictions Max            1578.1218
Q Predictions Min            1.1391437
V Predictions Mean           1207.7312
V Predictions Std            441.79202
V Predictions Max            1577.5599
V Predictions Min            2.2531903
Log Pis Mean                 -0.23777655
Log Pis Std                  1.9852902
Log Pis Max                  9.9319935
Log Pis Min                  -6.2281713
Policy mu Mean               0.048800796
Policy mu Std                0.903878
Policy mu Max                3.0797632
Policy mu Min                -3.1373215
Policy log std Mean          -0.50063664
Policy log std Std           0.20643412
Policy log std Max           0.04947847
Policy log std Min           -1.3090392
Z mean eval                  0.04147912
Z variance eval              0.0046531567
total_rewards                [1352.32083118 1031.56260369 1532.59103164 1459.67675692 1064.23624715
 1026.08609416 1027.36086223 1163.8106993  1669.90072765  885.10797441]
total_rewards_mean           1221.265382832643
total_rewards_std            249.97097864937447
total_rewards_max            1669.9007276545228
total_rewards_min            885.1079744067829
Number of train steps total  202000
Number of env steps total    1012000
Number of rollouts total     0
Train Time (s)               43.841583122033626
(Previous) Eval Time (s)     16.267810771241784
Sample Time (s)              22.15436092764139
Epoch Time (s)               82.2637548209168
Total Train Time (s)         15799.451940609142
Epoch                        201
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:11:39.276907 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #201 | Epoch Duration: 78.0757200717926
2020-01-11 05:11:39.277039 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #201 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04057731
Z variance train             0.0046540075
KL Divergence                10.980609
KL Loss                      1.098061
QF Loss                      209.03696
VF Loss                      181.91298
Policy Loss                  -1195.9683
Q Predictions Mean           1194.5522
Q Predictions Std            469.5361
Q Predictions Max            1566.3656
Q Predictions Min            -0.68142396
V Predictions Mean           1196.106
V Predictions Std            466.6617
V Predictions Max            1568.0188
V Predictions Min            -10.39262
Log Pis Mean                 -0.16485138
Log Pis Std                  1.8498018
Log Pis Max                  9.082382
Log Pis Min                  -5.5508556
Policy mu Mean               0.055429116
Policy mu Std                0.8909905
Policy mu Max                2.9042976
Policy mu Min                -2.8309193
Policy log std Mean          -0.47978488
Policy log std Std           0.21849164
Policy log std Max           0.07043147
Policy log std Min           -1.2991652
Z mean eval                  0.02347915
Z variance eval              0.0042143213
total_rewards                [1557.76022788 1535.33485655 1854.54415476 2149.93634257 1100.72245691
 1002.10837706  970.35135917 1077.44370503 1019.30968683 1028.68416453]
total_rewards_mean           1329.6195331267513
total_rewards_std            397.7449549470346
total_rewards_max            2149.936342565506
total_rewards_min            970.3513591664812
Number of train steps total  203000
Number of env steps total    1017000
Number of rollouts total     0
Train Time (s)               44.00782562699169
(Previous) Eval Time (s)     12.07953845988959
Sample Time (s)              21.512146807275712
Epoch Time (s)               77.59951089415699
Total Train Time (s)         15878.441208427772
Epoch                        202
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:12:58.267742 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #202 | Epoch Duration: 78.99047827720642
2020-01-11 05:12:58.267863 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #202 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024330173
Z variance train             0.004209565
KL Divergence                11.339241
KL Loss                      1.1339241
QF Loss                      207.93909
VF Loss                      581.8319
Policy Loss                  -1226.3855
Q Predictions Mean           1226.4498
Q Predictions Std            436.96265
Q Predictions Max            1581.9491
Q Predictions Min            -3.8557236
V Predictions Mean           1232.8586
V Predictions Std            433.1854
V Predictions Max            1590.5388
V Predictions Min            -9.252555
Log Pis Mean                 -0.12906411
Log Pis Std                  2.2935445
Log Pis Max                  11.519691
Log Pis Min                  -5.325606
Policy mu Mean               0.119625725
Policy mu Std                0.923766
Policy mu Max                3.6026149
Policy mu Min                -3.1539154
Policy log std Mean          -0.4796261
Policy log std Std           0.21721484
Policy log std Max           0.0047985315
Policy log std Min           -1.3977109
Z mean eval                  0.018380482
Z variance eval              0.0046613924
total_rewards                [1070.92148438 1278.40172444 1247.29806059 1129.63072684 1048.65206807
 1061.27523186 1051.38510228 1068.13453857 2880.37213288 1004.12054449]
total_rewards_mean           1284.019161438895
total_rewards_std            538.7995686163625
total_rewards_max            2880.37213287502
total_rewards_min            1004.120544494251
Number of train steps total  204000
Number of env steps total    1022000
Number of rollouts total     0
Train Time (s)               43.21215734817088
(Previous) Eval Time (s)     13.470395782031119
Sample Time (s)              21.61673050466925
Epoch Time (s)               78.29928363487124
Total Train Time (s)         15956.051635635551
Epoch                        203
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:14:15.880861 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #203 | Epoch Duration: 77.61288714408875
2020-01-11 05:14:15.881038 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #203 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018458635
Z variance train             0.0046680197
KL Divergence                11.013174
KL Loss                      1.1013174
QF Loss                      181.38187
VF Loss                      129.94176
Policy Loss                  -1212.4121
Q Predictions Mean           1207.332
Q Predictions Std            418.16565
Q Predictions Max            1559.5063
Q Predictions Min            -9.338366
V Predictions Mean           1205.0774
V Predictions Std            416.774
V Predictions Max            1555.1323
V Predictions Min            -4.7526636
Log Pis Mean                 -0.17436723
Log Pis Std                  2.0257962
Log Pis Max                  9.416391
Log Pis Min                  -4.5181484
Policy mu Mean               0.031987626
Policy mu Std                0.8959437
Policy mu Max                3.5785985
Policy mu Min                -2.9355702
Policy log std Mean          -0.5045988
Policy log std Std           0.20060357
Policy log std Max           0.0615353
Policy log std Min           -1.2974241
Z mean eval                  0.020120282
Z variance eval              0.0039657764
total_rewards                [1038.96917979 3138.71521092 3178.33774375 1393.88278181 3140.92589808
 3184.6649236  3205.42825093 1449.77644309 1062.15029838 1374.89040856]
total_rewards_mean           2216.7741138893066
total_rewards_std            961.1176049749415
total_rewards_max            3205.428250925404
total_rewards_min            1038.9691797862265
Number of train steps total  205000
Number of env steps total    1027000
Number of rollouts total     0
Train Time (s)               44.123685251921415
(Previous) Eval Time (s)     12.783756975084543
Sample Time (s)              21.571922816336155
Epoch Time (s)               78.47936504334211
Total Train Time (s)         16043.893831887748
Epoch                        204
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:15:43.726833 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #204 | Epoch Duration: 87.84564423561096
2020-01-11 05:15:43.727044 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #204 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019332632
Z variance train             0.0039645163
KL Divergence                11.424913
KL Loss                      1.1424913
QF Loss                      595.2398
VF Loss                      77.12708
Policy Loss                  -1242.2723
Q Predictions Mean           1238.7748
Q Predictions Std            400.23523
Q Predictions Max            1570.4504
Q Predictions Min            0.04084149
V Predictions Mean           1239.0015
V Predictions Std            392.9341
V Predictions Max            1565.1633
V Predictions Min            -0.18332112
Log Pis Mean                 -0.32106483
Log Pis Std                  1.932136
Log Pis Max                  7.9944525
Log Pis Min                  -5.671812
Policy mu Mean               0.11506987
Policy mu Std                0.89588195
Policy mu Max                3.3580978
Policy mu Min                -2.9386742
Policy log std Mean          -0.51568574
Policy log std Std           0.21202154
Policy log std Max           0.020687878
Policy log std Min           -1.933675
Z mean eval                  0.013162589
Z variance eval              0.0042747473
total_rewards                [1305.69244421 3220.71990675 1656.04425051 1060.73335263 1691.80423769
 1035.97937891  994.02238654 1203.45673089 1752.60085389  987.87059829]
total_rewards_mean           1490.8924140324227
total_rewards_std            643.214343106019
total_rewards_max            3220.719906752568
total_rewards_min            987.8705982883532
Number of train steps total  206000
Number of env steps total    1032000
Number of rollouts total     0
Train Time (s)               43.91707030730322
(Previous) Eval Time (s)     22.149782299995422
Sample Time (s)              21.65162673732266
Epoch Time (s)               87.7184793446213
Total Train Time (s)         16123.45713596791
Epoch                        205
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:17:03.292066 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #205 | Epoch Duration: 79.56486392021179
2020-01-11 05:17:03.292231 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #205 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013437783
Z variance train             0.0042627365
KL Divergence                11.244234
KL Loss                      1.1244234
QF Loss                      4597.5576
VF Loss                      554.21967
Policy Loss                  -1232.3114
Q Predictions Mean           1224.6781
Q Predictions Std            448.26996
Q Predictions Max            1609.0258
Q Predictions Min            -21.094643
V Predictions Mean           1223.3618
V Predictions Std            440.68237
V Predictions Max            1597.477
V Predictions Min            4.035065
Log Pis Mean                 -0.065366894
Log Pis Std                  2.096345
Log Pis Max                  9.062389
Log Pis Min                  -3.8664384
Policy mu Mean               0.047420915
Policy mu Std                0.91932386
Policy mu Max                3.4951289
Policy mu Min                -3.0914586
Policy log std Mean          -0.47667602
Policy log std Std           0.22031602
Policy log std Max           0.1358741
Policy log std Min           -1.7201365
Z mean eval                  0.011017143
Z variance eval              0.0046155276
total_rewards                [3225.3089987  3207.85139927 3173.40198225 1200.31449353 1328.70510471
 3278.4084962  3262.32099137 3242.73653698 1005.86434189 3201.39717375]
total_rewards_mean           2612.630951866441
total_rewards_std            942.2294739299584
total_rewards_max            3278.408496202156
total_rewards_min            1005.8643418900135
Number of train steps total  207000
Number of env steps total    1037000
Number of rollouts total     0
Train Time (s)               43.29207930481061
(Previous) Eval Time (s)     13.995899065863341
Sample Time (s)              22.055954307783395
Epoch Time (s)               79.34393267845735
Total Train Time (s)         16214.05802274542
Epoch                        206
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:18:33.895858 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #206 | Epoch Duration: 90.60349225997925
2020-01-11 05:18:33.896047 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #206 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010653345
Z variance train             0.0046108374
KL Divergence                10.994381
KL Loss                      1.0994381
QF Loss                      613.5414
VF Loss                      523.9135
Policy Loss                  -1183.0046
Q Predictions Mean           1180.727
Q Predictions Std            437.3267
Q Predictions Max            1566.9421
Q Predictions Min            -4.4582777
V Predictions Mean           1199.456
V Predictions Std            440.20377
V Predictions Max            1588.6908
V Predictions Min            -9.802548
Log Pis Mean                 -0.32740325
Log Pis Std                  2.2523813
Log Pis Max                  10.259196
Log Pis Min                  -5.814165
Policy mu Mean               -0.034147188
Policy mu Std                0.86815596
Policy mu Max                3.265385
Policy mu Min                -3.1049173
Policy log std Mean          -0.49357215
Policy log std Std           0.2172976
Policy log std Max           0.00394392
Policy log std Min           -1.3151133
Z mean eval                  0.0207407
Z variance eval              0.0045259795
total_rewards                [2992.24768926 1519.71466903 1622.69119858 1445.8255648  3214.39721682
  993.78856174 3200.90046974 1157.46316111 3205.37137139 3224.90955793]
total_rewards_mean           2257.730946039794
total_rewards_std            926.9856631384127
total_rewards_max            3224.9095579347468
total_rewards_min            993.7885617426978
Number of train steps total  208000
Number of env steps total    1042000
Number of rollouts total     0
Train Time (s)               43.476711708121
(Previous) Eval Time (s)     25.25520218303427
Sample Time (s)              22.419580991845578
Epoch Time (s)               91.15149488300085
Total Train Time (s)         16302.588849086314
Epoch                        207
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:20:02.430848 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #207 | Epoch Duration: 88.5346040725708
2020-01-11 05:20:02.431102 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #207 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021272648
Z variance train             0.0045259055
KL Divergence                11.054062
KL Loss                      1.1054062
QF Loss                      252.14691
VF Loss                      119.7411
Policy Loss                  -1244.3379
Q Predictions Mean           1242.429
Q Predictions Std            427.32126
Q Predictions Max            1585.5199
Q Predictions Min            -13.043429
V Predictions Mean           1245.302
V Predictions Std            427.34567
V Predictions Max            1591.8114
V Predictions Min            -1.3537312
Log Pis Mean                 0.0013493933
Log Pis Std                  2.203819
Log Pis Max                  8.874849
Log Pis Min                  -3.9881532
Policy mu Mean               0.14359191
Policy mu Std                0.9057685
Policy mu Max                2.793816
Policy mu Min                -2.8370028
Policy log std Mean          -0.5127837
Policy log std Std           0.21746047
Policy log std Max           0.01102373
Policy log std Min           -1.8552974
Z mean eval                  0.026287239
Z variance eval              0.004796763
total_rewards                [2230.49108912  933.96854301 1130.9277201  2452.94459343 1607.77094727
 3267.97407808 1060.05128407  900.00774175 1252.61010463 3248.65299282]
total_rewards_mean           1808.5399094286197
total_rewards_std            880.6951447857138
total_rewards_max            3267.974078082491
total_rewards_min            900.007741750749
Number of train steps total  209000
Number of env steps total    1047000
Number of rollouts total     0
Train Time (s)               43.95492256293073
(Previous) Eval Time (s)     22.63806111505255
Sample Time (s)              21.97846307279542
Epoch Time (s)               88.5714467507787
Total Train Time (s)         16387.231902874075
Epoch                        208
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:21:27.073909 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #208 | Epoch Duration: 84.64265298843384
2020-01-11 05:21:27.074042 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #208 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026514659
Z variance train             0.004787128
KL Divergence                10.9328165
KL Loss                      1.0932816
QF Loss                      143.832
VF Loss                      125.515076
Policy Loss                  -1222.9792
Q Predictions Mean           1221.0631
Q Predictions Std            450.54102
Q Predictions Max            1582.0052
Q Predictions Min            -3.6244812
V Predictions Mean           1215.3768
V Predictions Std            447.15533
V Predictions Max            1573.4495
V Predictions Min            2.9636307
Log Pis Mean                 -0.3984178
Log Pis Std                  1.6746689
Log Pis Max                  6.940127
Log Pis Min                  -6.2209096
Policy mu Mean               0.065750234
Policy mu Std                0.81234974
Policy mu Max                2.7850757
Policy mu Min                -2.8216305
Policy log std Mean          -0.48334607
Policy log std Std           0.21591058
Policy log std Max           0.15468282
Policy log std Min           -1.223254
Z mean eval                  0.013780375
Z variance eval              0.0047280197
total_rewards                [1112.09778916 1898.23535011 3234.42325147 3164.23687377 3231.95087868
 1030.07750331 3155.83927662 2930.21678352 2496.55448909 3181.63946525]
total_rewards_mean           2543.5271660983653
total_rewards_std            838.2311936673422
total_rewards_max            3234.423251465355
total_rewards_min            1030.0775033127752
Number of train steps total  210000
Number of env steps total    1052000
Number of rollouts total     0
Train Time (s)               44.199336491990834
(Previous) Eval Time (s)     18.709034299943596
Sample Time (s)              22.219856807030737
Epoch Time (s)               85.12822759896517
Total Train Time (s)         16478.53773483541
Epoch                        209
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:22:58.383373 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #209 | Epoch Duration: 91.30921387672424
2020-01-11 05:22:58.383552 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #209 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014496347
Z variance train             0.0047162306
KL Divergence                10.987686
KL Loss                      1.0987686
QF Loss                      197.58606
VF Loss                      259.37756
Policy Loss                  -1227.335
Q Predictions Mean           1226.1031
Q Predictions Std            447.35062
Q Predictions Max            1608.8416
Q Predictions Min            0.81295633
V Predictions Mean           1215.0481
V Predictions Std            443.20193
V Predictions Max            1595.7218
V Predictions Min            0.6433186
Log Pis Mean                 -0.3986276
Log Pis Std                  1.7736162
Log Pis Max                  6.683016
Log Pis Min                  -3.2863667
Policy mu Mean               0.06543896
Policy mu Std                0.83387196
Policy mu Max                2.5711076
Policy mu Min                -2.9776824
Policy log std Mean          -0.46502078
Policy log std Std           0.22470072
Policy log std Max           0.094572246
Policy log std Min           -1.3438892
Z mean eval                  0.01862069
Z variance eval              0.005458097
total_rewards                [2139.31067028 1025.54276584 3203.5286814  1382.18169851 1224.3408481
 1265.62643594 3118.60806031 1724.42342043 1553.72836446 1514.74436254]
total_rewards_mean           1815.2035307799656
total_rewards_std            732.1521191675139
total_rewards_max            3203.528681402849
total_rewards_min            1025.5427658367332
Number of train steps total  211000
Number of env steps total    1057000
Number of rollouts total     0
Train Time (s)               42.88761508092284
(Previous) Eval Time (s)     24.889772252179682
Sample Time (s)              20.891570174135268
Epoch Time (s)               88.66895750723779
Total Train Time (s)         16559.709030996542
Epoch                        210
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:24:19.557904 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #210 | Epoch Duration: 81.17419743537903
2020-01-11 05:24:19.558125 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #210 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020090763
Z variance train             0.005459784
KL Divergence                10.582567
KL Loss                      1.0582567
QF Loss                      278.22974
VF Loss                      92.76041
Policy Loss                  -1255.0143
Q Predictions Mean           1256.0471
Q Predictions Std            394.86432
Q Predictions Max            1579.2244
Q Predictions Min            -0.7591829
V Predictions Mean           1250.4343
V Predictions Std            393.4803
V Predictions Max            1574.848
V Predictions Min            2.1999784
Log Pis Mean                 -0.15971972
Log Pis Std                  2.1295793
Log Pis Max                  9.816036
Log Pis Min                  -10.242204
Policy mu Mean               0.0055589504
Policy mu Std                0.91996163
Policy mu Max                2.6990588
Policy mu Min                -3.0017998
Policy log std Mean          -0.48929417
Policy log std Std           0.21571329
Policy log std Max           0.079152584
Policy log std Min           -1.6536367
Z mean eval                  0.013240695
Z variance eval              0.0059935763
total_rewards                [2681.16094501 1051.47184651 2340.23787531 1040.26959016 1025.6108358
  900.36544118 1053.8853053  1245.38488488 2745.3629493  1212.21960727]
total_rewards_mean           1529.5969280727227
total_rewards_std            706.1947981023212
total_rewards_max            2745.362949302705
total_rewards_min            900.365441180988
Number of train steps total  212000
Number of env steps total    1062000
Number of rollouts total     0
Train Time (s)               44.074296122882515
(Previous) Eval Time (s)     17.394773373845965
Sample Time (s)              21.625037863384932
Epoch Time (s)               83.09410736011341
Total Train Time (s)         16641.004640232306
Epoch                        211
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:25:40.854926 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #211 | Epoch Duration: 81.2965841293335
2020-01-11 05:25:40.855110 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #211 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013394972
Z variance train             0.0059928414
KL Divergence                10.408925
KL Loss                      1.0408925
QF Loss                      307.7921
VF Loss                      129.95319
Policy Loss                  -1242.0403
Q Predictions Mean           1244.1262
Q Predictions Std            460.59988
Q Predictions Max            1589.2463
Q Predictions Min            -11.859721
V Predictions Mean           1246.4268
V Predictions Std            457.38644
V Predictions Max            1586.4567
V Predictions Min            3.8095038
Log Pis Mean                 -0.2789173
Log Pis Std                  2.2655787
Log Pis Max                  9.382054
Log Pis Min                  -5.0268903
Policy mu Mean               0.000526129
Policy mu Std                0.89063704
Policy mu Max                3.1980343
Policy mu Min                -3.6932864
Policy log std Mean          -0.49529552
Policy log std Std           0.23672125
Policy log std Max           0.15016925
Policy log std Min           -1.8460829
Z mean eval                  0.009532723
Z variance eval              0.006816038
total_rewards                [ 997.56875451  976.62037589 2500.36482693  962.41302953 1036.79442691
 1051.47682878 1957.87876941 1054.12279361 1038.36959098 1603.58239867]
total_rewards_mean           1317.919179522099
total_rewards_std            503.2477034088993
total_rewards_max            2500.364826930595
total_rewards_min            962.4130295321983
Number of train steps total  213000
Number of env steps total    1067000
Number of rollouts total     0
Train Time (s)               44.528609931934625
(Previous) Eval Time (s)     15.597021826077253
Sample Time (s)              21.929850053973496
Epoch Time (s)               82.05548181198537
Total Train Time (s)         16720.034200145397
Epoch                        212
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:26:59.890998 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #212 | Epoch Duration: 79.03571915626526
2020-01-11 05:26:59.891304 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #212 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.00977906
Z variance train             0.0068232557
KL Divergence                10.046473
KL Loss                      1.0046473
QF Loss                      102.34595
VF Loss                      131.47852
Policy Loss                  -1242.3745
Q Predictions Mean           1240.0375
Q Predictions Std            450.95114
Q Predictions Max            1613.1658
Q Predictions Min            -2.1711
V Predictions Mean           1235.2251
V Predictions Std            447.76926
V Predictions Max            1605.9148
V Predictions Min            -3.5055964
Log Pis Mean                 -0.45618686
Log Pis Std                  1.7575493
Log Pis Max                  4.7952633
Log Pis Min                  -5.2717032
Policy mu Mean               0.11332355
Policy mu Std                0.8090279
Policy mu Max                2.3190985
Policy mu Min                -3.1718838
Policy log std Mean          -0.4667257
Policy log std Std           0.19556215
Policy log std Max           0.059729576
Policy log std Min           -1.2480444
Z mean eval                  0.021234611
Z variance eval              0.007109215
total_rewards                [2093.97767411 2189.86885962 2039.95028569 1027.32618932 2139.83866335
 1272.21102261  997.5217878  1880.56657215 1776.85622534 1777.0502365 ]
total_rewards_mean           1719.5167516477504
total_rewards_std            432.8766714150192
total_rewards_max            2189.8688596179445
total_rewards_min            997.521787796541
Number of train steps total  214000
Number of env steps total    1072000
Number of rollouts total     0
Train Time (s)               43.889228329993784
(Previous) Eval Time (s)     12.577024376951158
Sample Time (s)              22.038533338345587
Epoch Time (s)               78.50478604529053
Total Train Time (s)         16801.723585878965
Epoch                        213
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:28:21.582525 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #213 | Epoch Duration: 81.690993309021
2020-01-11 05:28:21.582705 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #213 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021415848
Z variance train             0.007114268
KL Divergence                10.00509
KL Loss                      1.000509
QF Loss                      146.65913
VF Loss                      110.557076
Policy Loss                  -1274.8776
Q Predictions Mean           1273.7551
Q Predictions Std            389.20612
Q Predictions Max            1593.735
Q Predictions Min            -3.2181568
V Predictions Mean           1275.7594
V Predictions Std            390.9784
V Predictions Max            1595.9935
V Predictions Min            -9.558791
Log Pis Mean                 -0.25808248
Log Pis Std                  2.1057534
Log Pis Max                  11.298462
Log Pis Min                  -4.1839585
Policy mu Mean               0.1178919
Policy mu Std                0.88083225
Policy mu Max                2.8796358
Policy mu Min                -3.561486
Policy log std Mean          -0.47139478
Policy log std Std           0.20807
Policy log std Max           0.17634511
Policy log std Min           -1.2019062
Z mean eval                  0.022089245
Z variance eval              0.007369312
total_rewards                [2811.0518717  1860.0943774  3220.71826699 1553.57708568 2417.99268752
 3231.51026881 3208.91565354 2623.30857386 3184.97022854 1856.24317847]
total_rewards_mean           2596.838219251855
total_rewards_std            614.0694715524661
total_rewards_max            3231.51026881158
total_rewards_min            1553.5770856789197
Number of train steps total  215000
Number of env steps total    1077000
Number of rollouts total     0
Train Time (s)               44.38263331307098
(Previous) Eval Time (s)     15.762999833095819
Sample Time (s)              21.76617023907602
Epoch Time (s)               81.91180338524282
Total Train Time (s)         16894.635582163
Epoch                        214
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:29:54.495319 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #214 | Epoch Duration: 92.91248393058777
2020-01-11 05:29:54.495449 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #214 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021877665
Z variance train             0.007367936
KL Divergence                9.859629
KL Loss                      0.98596287
QF Loss                      649.3598
VF Loss                      671.5485
Policy Loss                  -1272.5056
Q Predictions Mean           1268.0837
Q Predictions Std            396.77267
Q Predictions Max            1551.9386
Q Predictions Min            -1.250475
V Predictions Mean           1268.7539
V Predictions Std            398.6426
V Predictions Max            1568.2245
V Predictions Min            3.6617079
Log Pis Mean                 -0.15051998
Log Pis Std                  2.164268
Log Pis Max                  9.589341
Log Pis Min                  -5.8871756
Policy mu Mean               0.13474463
Policy mu Std                0.877167
Policy mu Max                3.214901
Policy mu Min                -3.0451007
Policy log std Mean          -0.48103747
Policy log std Std           0.19829123
Policy log std Max           0.054726005
Policy log std Min           -1.2211442
Z mean eval                  0.012163282
Z variance eval              0.006206167
total_rewards                [3087.81054776 1300.54854994 1969.13474875 3054.8874828  3020.17592283
 3086.09763867 3105.11270662 3117.68035677 3094.5038722  3090.90667855]
total_rewards_mean           2792.6858504892316
total_rewards_std            598.4699143915855
total_rewards_max            3117.6803567715037
total_rewards_min            1300.548549940386
Number of train steps total  216000
Number of env steps total    1082000
Number of rollouts total     0
Train Time (s)               43.90410126093775
(Previous) Eval Time (s)     26.763447171077132
Sample Time (s)              22.317826095037162
Epoch Time (s)               92.98537452705204
Total Train Time (s)         16987.043764387257
Epoch                        215
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:31:26.907529 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #215 | Epoch Duration: 92.41194987297058
2020-01-11 05:31:26.907705 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #215 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011526787
Z variance train             0.006204327
KL Divergence                10.349722
KL Loss                      1.0349722
QF Loss                      348.2234
VF Loss                      180.51717
Policy Loss                  -1271.8884
Q Predictions Mean           1268.344
Q Predictions Std            399.00085
Q Predictions Max            1586.0773
Q Predictions Min            -15.037806
V Predictions Mean           1276.7634
V Predictions Std            398.83582
V Predictions Max            1591.7239
V Predictions Min            -2.7601924
Log Pis Mean                 -0.19655557
Log Pis Std                  1.9178457
Log Pis Max                  6.4735804
Log Pis Min                  -4.853282
Policy mu Mean               0.0038265258
Policy mu Std                0.8571221
Policy mu Max                2.508391
Policy mu Min                -3.0154803
Policy log std Mean          -0.4896985
Policy log std Std           0.2209061
Policy log std Max           0.056477666
Policy log std Min           -1.5648224
Z mean eval                  0.019531284
Z variance eval              0.005296621
total_rewards                [2900.72608427 1356.7323478  2520.62244362 3303.44949707 1607.92833424
  921.95337246 1084.11337688 3160.00767939 3255.24278978 3189.53767672]
total_rewards_mean           2330.031360224663
total_rewards_std            927.1961645017947
total_rewards_max            3303.449497071412
total_rewards_min            921.9533724636034
Number of train steps total  217000
Number of env steps total    1087000
Number of rollouts total     0
Train Time (s)               43.437553501687944
(Previous) Eval Time (s)     26.18978854222223
Sample Time (s)              21.55063707381487
Epoch Time (s)               91.17797911772504
Total Train Time (s)         17073.471140217967
Epoch                        216
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:32:53.337173 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #216 | Epoch Duration: 86.42927241325378
2020-01-11 05:32:53.337420 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #216 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019656561
Z variance train             0.00529845
KL Divergence                10.789646
KL Loss                      1.0789646
QF Loss                      162.23123
VF Loss                      58.88941
Policy Loss                  -1312.6558
Q Predictions Mean           1312.6068
Q Predictions Std            349.39572
Q Predictions Max            1578.2332
Q Predictions Min            6.6205363
V Predictions Mean           1310.5684
V Predictions Std            349.37408
V Predictions Max            1573.903
V Predictions Min            6.127217
Log Pis Mean                 -0.54294235
Log Pis Std                  1.8348954
Log Pis Max                  4.407429
Log Pis Min                  -5.5893126
Policy mu Mean               0.13410878
Policy mu Std                0.82072955
Policy mu Max                2.6527953
Policy mu Min                -2.6350222
Policy log std Mean          -0.48259804
Policy log std Std           0.207613
Policy log std Max           0.12539768
Policy log std Min           -1.2889435
Z mean eval                  0.021110287
Z variance eval              0.00554707
total_rewards                [1848.81128246  896.37410459  943.93138559 3234.81342049  955.29772329
 2137.46898223 2130.53540984 3235.39246664 2096.96911986 1264.78986051]
total_rewards_mean           1874.4383755496413
total_rewards_std            832.2684422126342
total_rewards_max            3235.392466641639
total_rewards_min            896.3741045936428
Number of train steps total  218000
Number of env steps total    1092000
Number of rollouts total     0
Train Time (s)               44.49467439297587
(Previous) Eval Time (s)     21.440832985565066
Sample Time (s)              20.144771555438638
Epoch Time (s)               86.08027893397957
Total Train Time (s)         17157.26748526795
Epoch                        217
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:34:17.134552 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #217 | Epoch Duration: 83.79697895050049
2020-01-11 05:34:17.134686 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #217 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021384563
Z variance train             0.0055433987
KL Divergence                10.656534
KL Loss                      1.0656534
QF Loss                      147.17596
VF Loss                      111.38238
Policy Loss                  -1320.4849
Q Predictions Mean           1318.3086
Q Predictions Std            341.24112
Q Predictions Max            1569.1436
Q Predictions Min            -6.9300523
V Predictions Mean           1327.3794
V Predictions Std            339.90543
V Predictions Max            1577.0063
V Predictions Min            0.12262231
Log Pis Mean                 -0.36932266
Log Pis Std                  2.0145352
Log Pis Max                  7.5948057
Log Pis Min                  -5.5426
Policy mu Mean               0.09763884
Policy mu Std                0.84844923
Policy mu Max                2.3906438
Policy mu Min                -2.9909008
Policy log std Mean          -0.48067427
Policy log std Std           0.21858975
Policy log std Max           0.024614483
Policy log std Min           -2.1868753
Z mean eval                  0.03242325
Z variance eval              0.0056788283
total_rewards                [3127.81422618  906.38101051 3151.2974069  3071.33462494 3065.07904463
 3106.0432817  3112.55783573 3130.10040409  868.28218274 1785.32401731]
total_rewards_mean           2532.421403474207
total_rewards_std            911.3722335507974
total_rewards_max            3151.2974069028214
total_rewards_min            868.2821827373454
Number of train steps total  219000
Number of env steps total    1097000
Number of rollouts total     0
Train Time (s)               44.31358917383477
(Previous) Eval Time (s)     19.157306300010532
Sample Time (s)              22.145087636075914
Epoch Time (s)               85.61598310992122
Total Train Time (s)         17250.623378630262
Epoch                        218
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:35:50.492935 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #218 | Epoch Duration: 93.35807251930237
2020-01-11 05:35:50.493175 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #218 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033062432
Z variance train             0.0056865504
KL Divergence                10.586223
KL Loss                      1.0586222
QF Loss                      331.98755
VF Loss                      85.63021
Policy Loss                  -1299.6832
Q Predictions Mean           1299.767
Q Predictions Std            358.4575
Q Predictions Max            1583.7002
Q Predictions Min            -15.277287
V Predictions Mean           1303.907
V Predictions Std            359.087
V Predictions Max            1588.9722
V Predictions Min            -11.130858
Log Pis Mean                 -0.3756051
Log Pis Std                  2.0412054
Log Pis Max                  8.069503
Log Pis Min                  -4.560147
Policy mu Mean               -0.026119733
Policy mu Std                0.8439781
Policy mu Max                3.0035605
Policy mu Min                -2.9688582
Policy log std Mean          -0.47739553
Policy log std Std           0.198025
Policy log std Max           -0.00730294
Policy log std Min           -1.2485476
Z mean eval                  0.03374462
Z variance eval              0.0053601987
total_rewards                [1007.93927583 3126.6355886   937.6422129  1035.59868544 1067.61477777
 3179.21142612 1621.71625276 1661.40916043 1882.94215312 3084.96160329]
total_rewards_mean           1860.56711362518
total_rewards_std            884.6592143629556
total_rewards_max            3179.2114261215943
total_rewards_min            937.6422128989199
Number of train steps total  220000
Number of env steps total    1102000
Number of rollouts total     0
Train Time (s)               44.797453481238335
(Previous) Eval Time (s)     26.899146114941686
Sample Time (s)              21.928814097307622
Epoch Time (s)               93.62541369348764
Total Train Time (s)         17336.49580253288
Epoch                        219
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:37:16.369318 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #219 | Epoch Duration: 85.8759982585907
2020-01-11 05:37:16.369441 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #219 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033503436
Z variance train             0.0053621265
KL Divergence                10.715426
KL Loss                      1.0715426
QF Loss                      376.8714
VF Loss                      104.94538
Policy Loss                  -1282.542
Q Predictions Mean           1278.3269
Q Predictions Std            405.37912
Q Predictions Max            1581.8856
Q Predictions Min            -0.16908139
V Predictions Mean           1278.0515
V Predictions Std            402.96402
V Predictions Max            1580.1212
V Predictions Min            6.5685725
Log Pis Mean                 -0.21364087
Log Pis Std                  2.101252
Log Pis Max                  12.682167
Log Pis Min                  -4.70086
Policy mu Mean               0.17181014
Policy mu Std                0.85781527
Policy mu Max                2.6841824
Policy mu Min                -3.264059
Policy log std Mean          -0.4770135
Policy log std Std           0.19630562
Policy log std Max           -0.04151553
Policy log std Min           -1.2974396
Z mean eval                  0.016264081
Z variance eval              0.0054261177
total_rewards                [1032.54906171  963.60658177 2105.63248551 2015.32425455 1034.72418979
 1033.83947666  986.45390096 2088.68957071 2154.15734546 1894.22219258]
total_rewards_mean           1530.9199059702707
total_rewards_std            525.0164623287361
total_rewards_max            2154.1573454648665
total_rewards_min            963.6065817667128
Number of train steps total  221000
Number of env steps total    1107000
Number of rollouts total     0
Train Time (s)               44.260840891394764
(Previous) Eval Time (s)     19.149510221090168
Sample Time (s)              21.847940299194306
Epoch Time (s)               85.25829141167924
Total Train Time (s)         17418.23941496713
Epoch                        220
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:38:38.115763 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #220 | Epoch Duration: 81.74622535705566
2020-01-11 05:38:38.115883 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #220 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017554734
Z variance train             0.0054284795
KL Divergence                10.754981
KL Loss                      1.0754981
QF Loss                      231.58537
VF Loss                      198.71014
Policy Loss                  -1332.0243
Q Predictions Mean           1327.3811
Q Predictions Std            336.90286
Q Predictions Max            1579.7212
Q Predictions Min            3.1465182
V Predictions Mean           1342.6304
V Predictions Std            335.55954
V Predictions Max            1598.3019
V Predictions Min            5.730605
Log Pis Mean                 -0.2361369
Log Pis Std                  1.9864123
Log Pis Max                  6.2224655
Log Pis Min                  -6.4766407
Policy mu Mean               0.17904909
Policy mu Std                0.8667477
Policy mu Max                2.7214582
Policy mu Min                -2.675555
Policy log std Mean          -0.5044622
Policy log std Std           0.20942964
Policy log std Max           0.117144644
Policy log std Min           -1.2117001
Z mean eval                  0.009163752
Z variance eval              0.0058133537
total_rewards                [2426.10401287 3282.89922881 2379.8770811  1537.96840843 1313.27077083
 1071.91696985 1040.09120229 1598.86347306 1858.76476258 3219.57643793]
total_rewards_mean           1972.933234774875
total_rewards_std            781.052712053619
total_rewards_max            3282.8992288098957
total_rewards_min            1040.091202294143
Number of train steps total  222000
Number of env steps total    1112000
Number of rollouts total     0
Train Time (s)               43.15941597195342
(Previous) Eval Time (s)     15.63720607291907
Sample Time (s)              21.45681931404397
Epoch Time (s)               80.25344135891646
Total Train Time (s)         17502.23029192537
Epoch                        221
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:40:02.108480 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #221 | Epoch Duration: 83.99250364303589
2020-01-11 05:40:02.108605 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #221 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.007580866
Z variance train             0.00580474
KL Divergence                10.60421
KL Loss                      1.060421
QF Loss                      491.4135
VF Loss                      269.30093
Policy Loss                  -1271.4113
Q Predictions Mean           1271.6936
Q Predictions Std            434.54477
Q Predictions Max            1587.6145
Q Predictions Min            -9.916288
V Predictions Mean           1274.9596
V Predictions Std            433.86502
V Predictions Max            1607.1786
V Predictions Min            -14.317717
Log Pis Mean                 -0.35215032
Log Pis Std                  1.9547782
Log Pis Max                  6.725547
Log Pis Min                  -4.7877
Policy mu Mean               0.11131436
Policy mu Std                0.8430646
Policy mu Max                2.3308353
Policy mu Min                -2.7631803
Policy log std Mean          -0.4704536
Policy log std Std           0.18942626
Policy log std Max           0.028735042
Policy log std Min           -1.0305068
Z mean eval                  0.03203143
Z variance eval              0.00799522
total_rewards                [1861.65976108  442.82767643 3162.40205247 2202.87323597 1516.35741343
 1033.23167228 3158.08383883 1875.2494862  1585.17644581 1957.95913518]
total_rewards_mean           1879.5820717677393
total_rewards_std            799.3980866208475
total_rewards_max            3162.40205246603
total_rewards_min            442.82767643115585
Number of train steps total  223000
Number of env steps total    1117000
Number of rollouts total     0
Train Time (s)               43.33873885311186
(Previous) Eval Time (s)     19.37601903406903
Sample Time (s)              22.053814372979105
Epoch Time (s)               84.76857226016
Total Train Time (s)         17585.573939690832
Epoch                        222
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:41:25.457422 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #222 | Epoch Duration: 83.34869313240051
2020-01-11 05:41:25.457653 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #222 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031906597
Z variance train             0.007992068
KL Divergence                10.023497
KL Loss                      1.0023497
QF Loss                      170.75124
VF Loss                      50.118073
Policy Loss                  -1320.3433
Q Predictions Mean           1320.4957
Q Predictions Std            379.8078
Q Predictions Max            1600.0336
Q Predictions Min            5.3548203
V Predictions Mean           1322.8379
V Predictions Std            381.90714
V Predictions Max            1597.1735
V Predictions Min            -5.190363
Log Pis Mean                 -0.20807925
Log Pis Std                  2.097477
Log Pis Max                  8.590152
Log Pis Min                  -4.883217
Policy mu Mean               0.058364242
Policy mu Std                0.9095357
Policy mu Max                2.4664552
Policy mu Min                -3.0873094
Policy log std Mean          -0.48820236
Policy log std Std           0.20431592
Policy log std Max           0.08133209
Policy log std Min           -1.3755097
Z mean eval                  0.016666386
Z variance eval              0.007376791
total_rewards                [1260.43224639 1011.87400442 1570.35145479 3177.95044934 3192.69459718
 1680.91551425 3112.23095664 1847.48447207 1842.20457176 1804.28506808]
total_rewards_mean           2050.0423334913094
total_rewards_std            769.3070880686225
total_rewards_max            3192.694597182326
total_rewards_min            1011.8740044177392
Number of train steps total  224000
Number of env steps total    1122000
Number of rollouts total     0
Train Time (s)               43.66156023973599
(Previous) Eval Time (s)     17.955870111938566
Sample Time (s)              19.96632000338286
Epoch Time (s)               81.58375035505742
Total Train Time (s)         17669.881965569686
Epoch                        223
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:42:49.766608 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #223 | Epoch Duration: 84.30879235267639
2020-01-11 05:42:49.766729 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #223 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0162565
Z variance train             0.007375314
KL Divergence                10.012645
KL Loss                      1.0012645
QF Loss                      141.08585
VF Loss                      123.330444
Policy Loss                  -1318.6193
Q Predictions Mean           1317.69
Q Predictions Std            404.1924
Q Predictions Max            1620.9846
Q Predictions Min            0.5234432
V Predictions Mean           1324.6678
V Predictions Std            404.39938
V Predictions Max            1629.7426
V Predictions Min            1.2206069
Log Pis Mean                 -0.3457514
Log Pis Std                  1.9833307
Log Pis Max                  7.391488
Log Pis Min                  -5.8721685
Policy mu Mean               0.14513485
Policy mu Std                0.8378807
Policy mu Max                2.1714046
Policy mu Min                -3.1852875
Policy log std Mean          -0.46045157
Policy log std Std           0.2102986
Policy log std Max           0.017139494
Policy log std Min           -1.1327369
Z mean eval                  0.016301583
Z variance eval              0.0066624694
total_rewards                [2175.84847235 3095.48769065 1507.06977164 1432.89422396 2783.2371294
 1405.49855243 1055.03952648 3317.23751319 1272.97811733 1037.8992578 ]
total_rewards_mean           1908.3190255228315
total_rewards_std            822.2351924320238
total_rewards_max            3317.2375131877525
total_rewards_min            1037.8992578034035
Number of train steps total  225000
Number of env steps total    1127000
Number of rollouts total     0
Train Time (s)               44.935841239988804
(Previous) Eval Time (s)     20.680706535931677
Sample Time (s)              21.638016413897276
Epoch Time (s)               87.25456418981776
Total Train Time (s)         17754.902485202067
Epoch                        224
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:44:14.788918 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #224 | Epoch Duration: 85.02209734916687
2020-01-11 05:44:14.789043 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #224 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016295187
Z variance train             0.00666136
KL Divergence                10.287653
KL Loss                      1.0287653
QF Loss                      311.24115
VF Loss                      120.06815
Policy Loss                  -1323.0463
Q Predictions Mean           1318.7894
Q Predictions Std            342.36563
Q Predictions Max            1629.8014
Q Predictions Min            11.460426
V Predictions Mean           1321.5095
V Predictions Std            343.06342
V Predictions Max            1643.3003
V Predictions Min            12.143109
Log Pis Mean                 -0.121838294
Log Pis Std                  2.0670884
Log Pis Max                  8.062561
Log Pis Min                  -4.578662
Policy mu Mean               0.11806498
Policy mu Std                0.8989129
Policy mu Max                2.6779191
Policy mu Min                -3.2109401
Policy log std Mean          -0.44735262
Policy log std Std           0.20560299
Policy log std Max           0.07714543
Policy log std Min           -1.20797
Z mean eval                  0.01123448
Z variance eval              0.0067920485
total_rewards                [3279.30828244  715.09932816 1300.27636671 3144.32727819  993.23216301
 3202.56817465 3188.76435005 3192.49350071 3238.92406869 2445.00681329]
total_rewards_mean           2470.0000325898573
total_rewards_std            995.2695226708951
total_rewards_max            3279.30828243953
total_rewards_min            715.0993281594217
Number of train steps total  226000
Number of env steps total    1132000
Number of rollouts total     0
Train Time (s)               44.22435575257987
(Previous) Eval Time (s)     18.447972868103534
Sample Time (s)              21.761760266963392
Epoch Time (s)               84.4340888876468
Total Train Time (s)         17844.561439279
Epoch                        225
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:45:44.451174 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #225 | Epoch Duration: 89.66202712059021
2020-01-11 05:45:44.451335 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #225 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010971708
Z variance train             0.0068011633
KL Divergence                10.289612
KL Loss                      1.0289612
QF Loss                      177.7467
VF Loss                      111.449715
Policy Loss                  -1302.82
Q Predictions Mean           1302.0531
Q Predictions Std            369.4671
Q Predictions Max            1599.9446
Q Predictions Min            3.9714959
V Predictions Mean           1296.3276
V Predictions Std            369.31458
V Predictions Max            1597.3827
V Predictions Min            -7.670264
Log Pis Mean                 -0.35943422
Log Pis Std                  2.1666276
Log Pis Max                  9.666627
Log Pis Min                  -6.6771374
Policy mu Mean               -0.045454383
Policy mu Std                0.8772899
Policy mu Max                2.4331627
Policy mu Min                -2.966364
Policy log std Mean          -0.4685278
Policy log std Std           0.21294583
Policy log std Max           0.08728081
Policy log std Min           -1.3575699
Z mean eval                  0.026983932
Z variance eval              0.0066373
total_rewards                [3234.1553045  2326.20950477 2932.2003322  1526.5207745  3155.65752698
 2894.29892364 3187.88200617 1334.73455405 3216.52391105 3286.95208938]
total_rewards_mean           2709.513492723102
total_rewards_std            693.813432743041
total_rewards_max            3286.952089376604
total_rewards_min            1334.7345540508782
Number of train steps total  227000
Number of env steps total    1137000
Number of rollouts total     0
Train Time (s)               43.36422969494015
(Previous) Eval Time (s)     23.675666354130954
Sample Time (s)              22.272337272763252
Epoch Time (s)               89.31223332183436
Total Train Time (s)         17937.628533023875
Epoch                        226
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:47:17.521125 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #226 | Epoch Duration: 93.0696542263031
2020-01-11 05:47:17.521331 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #226 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02695559
Z variance train             0.0066357134
KL Divergence                10.442001
KL Loss                      1.0442002
QF Loss                      175.6376
VF Loss                      60.11779
Policy Loss                  -1357.6149
Q Predictions Mean           1357.7988
Q Predictions Std            312.06284
Q Predictions Max            1610.9224
Q Predictions Min            10.516497
V Predictions Mean           1357.1323
V Predictions Std            312.94357
V Predictions Max            1609.0034
V Predictions Min            -30.562943
Log Pis Mean                 -0.48202202
Log Pis Std                  1.7737726
Log Pis Max                  9.54785
Log Pis Min                  -5.6487594
Policy mu Mean               0.13863538
Policy mu Std                0.79159945
Policy mu Max                2.0181837
Policy mu Min                -2.7713313
Policy log std Mean          -0.42904234
Policy log std Std           0.19517937
Policy log std Max           0.1887826
Policy log std Min           -1.3364106
Z mean eval                  0.011716746
Z variance eval              0.005187169
total_rewards                [ 252.50148969 1361.78823069 1810.74662691 1724.55349486 3305.65646937
 3262.41857386 1857.08381336 3083.30421633 2449.93986354 1624.06902557]
total_rewards_mean           2073.206180418373
total_rewards_std            914.0757072265657
total_rewards_max            3305.6564693740734
total_rewards_min            252.50148969335243
Number of train steps total  228000
Number of env steps total    1142000
Number of rollouts total     0
Train Time (s)               44.030011664144695
(Previous) Eval Time (s)     27.43284429470077
Sample Time (s)              19.799244246445596
Epoch Time (s)               91.26210020529106
Total Train Time (s)         18021.996566372924
Epoch                        227
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:48:41.892015 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #227 | Epoch Duration: 84.37045693397522
2020-01-11 05:48:41.892260 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #227 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0116091
Z variance train             0.005190021
KL Divergence                10.966108
KL Loss                      1.0966109
QF Loss                      771.2014
VF Loss                      472.77432
Policy Loss                  -1352.4418
Q Predictions Mean           1349.6603
Q Predictions Std            333.65125
Q Predictions Max            1618.3392
Q Predictions Min            -27.170555
V Predictions Mean           1356.2349
V Predictions Std            326.47385
V Predictions Max            1624.5281
V Predictions Min            -1.4941283
Log Pis Mean                 -0.04398138
Log Pis Std                  2.3533678
Log Pis Max                  14.334594
Log Pis Min                  -6.323253
Policy mu Mean               0.16961153
Policy mu Std                0.9283791
Policy mu Max                3.3322637
Policy mu Min                -4.4944644
Policy log std Mean          -0.4667835
Policy log std Std           0.21391219
Policy log std Max           0.030741602
Policy log std Min           -1.185555
Z mean eval                  0.027825797
Z variance eval              0.0057492163
total_rewards                [1015.70659033 1535.85546679 1407.64872039 1272.50285777 1824.96191547
 1569.13762878 1029.71332469  946.67216108 1625.65621807 1878.72944957]
total_rewards_mean           1410.6584332934794
total_rewards_std            318.31388093060195
total_rewards_max            1878.7294495675312
total_rewards_min            946.6721610761713
Number of train steps total  229000
Number of env steps total    1147000
Number of rollouts total     0
Train Time (s)               44.436056251171976
(Previous) Eval Time (s)     20.540953459218144
Sample Time (s)              21.777282861061394
Epoch Time (s)               86.75429257145151
Total Train Time (s)         18102.556990400422
Epoch                        228
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:50:02.456856 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #228 | Epoch Duration: 80.5644052028656
2020-01-11 05:50:02.457133 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #228 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028112924
Z variance train             0.0057528876
KL Divergence                10.601818
KL Loss                      1.0601819
QF Loss                      145.0816
VF Loss                      227.8258
Policy Loss                  -1355.1394
Q Predictions Mean           1355.787
Q Predictions Std            332.20312
Q Predictions Max            1610.9237
Q Predictions Min            4.492912
V Predictions Mean           1349.0242
V Predictions Std            330.25348
V Predictions Max            1602.9155
V Predictions Min            0.8934058
Log Pis Mean                 -0.24501061
Log Pis Std                  1.9285992
Log Pis Max                  8.359289
Log Pis Min                  -7.715605
Policy mu Mean               0.1374891
Policy mu Std                0.8582982
Policy mu Max                3.0549388
Policy mu Min                -2.4317515
Policy log std Mean          -0.474131
Policy log std Std           0.2000527
Policy log std Max           0.0024485588
Policy log std Min           -1.4279988
Z mean eval                  0.024107685
Z variance eval              0.0062800073
total_rewards                [1047.80787837 1848.15725995 1284.02703705 1589.6427644  1598.05792135
 1059.75717437 1206.25106418 1312.25567204 1030.52678371  983.15477737]
total_rewards_mean           1295.9638332790144
total_rewards_std            278.66885752785794
total_rewards_max            1848.1572599509004
total_rewards_min            983.1547773746229
Number of train steps total  230000
Number of env steps total    1152000
Number of rollouts total     0
Train Time (s)               43.52779212221503
(Previous) Eval Time (s)     14.350826160982251
Sample Time (s)              22.378673794213682
Epoch Time (s)               80.25729207741097
Total Train Time (s)         18179.823753353674
Epoch                        229
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:51:19.725170 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #229 | Epoch Duration: 77.26783013343811
2020-01-11 05:51:19.725355 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #229 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02407613
Z variance train             0.006282223
KL Divergence                10.539684
KL Loss                      1.0539684
QF Loss                      195.9566
VF Loss                      94.94075
Policy Loss                  -1381.3176
Q Predictions Mean           1385.2528
Q Predictions Std            251.3897
Q Predictions Max            1603.5878
Q Predictions Min            -11.867028
V Predictions Mean           1382.5537
V Predictions Std            249.33057
V Predictions Max            1594.9633
V Predictions Min            -7.976519
Log Pis Mean                 -0.36864668
Log Pis Std                  1.927021
Log Pis Max                  6.570953
Log Pis Min                  -6.5630627
Policy mu Mean               -0.032020435
Policy mu Std                0.8474609
Policy mu Max                2.420866
Policy mu Min                -2.6083887
Policy log std Mean          -0.45662966
Policy log std Std           0.19895667
Policy log std Max           0.060131043
Policy log std Min           -1.5446198
Z mean eval                  0.007216929
Z variance eval              0.0068115457
total_rewards                [1328.24029889 1518.45508847 1350.30294724 1544.71009994 1795.25295263
 1342.07565308 2665.04622345 1587.57480155 1352.94079589 1411.39857789]
total_rewards_mean           1589.599743902982
total_rewards_std            384.78073240901495
total_rewards_max            2665.0462234541887
total_rewards_min            1328.2402988912713
Number of train steps total  231000
Number of env steps total    1157000
Number of rollouts total     0
Train Time (s)               43.90234341612086
(Previous) Eval Time (s)     11.361135391984135
Sample Time (s)              21.754192379303277
Epoch Time (s)               77.01767118740827
Total Train Time (s)         18261.21231607767
Epoch                        230
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:52:41.122927 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #230 | Epoch Duration: 81.39740800857544
2020-01-11 05:52:41.123187 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #230 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.00747423
Z variance train             0.0068225833
KL Divergence                10.346174
KL Loss                      1.0346174
QF Loss                      211.78944
VF Loss                      147.91083
Policy Loss                  -1298.2479
Q Predictions Mean           1299.2803
Q Predictions Std            414.1425
Q Predictions Max            1613.6448
Q Predictions Min            -20.867493
V Predictions Mean           1295.8171
V Predictions Std            411.89005
V Predictions Max            1606.5718
V Predictions Min            3.6656663
Log Pis Mean                 -0.4268025
Log Pis Std                  1.9253876
Log Pis Max                  9.412919
Log Pis Min                  -4.191404
Policy mu Mean               0.06641238
Policy mu Std                0.8232723
Policy mu Max                2.6313384
Policy mu Min                -2.958893
Policy log std Mean          -0.4550782
Policy log std Std           0.19861622
Policy log std Max           0.046834826
Policy log std Min           -1.2736193
Z mean eval                  0.027549526
Z variance eval              0.006816688
total_rewards                [2498.72576267 1109.04326432 3369.61396968 1096.76420836 2374.3995511
 1096.05102963 1093.9007533  1087.83618166 1353.19982785 1081.62343047]
total_rewards_mean           1616.1157979041225
total_rewards_std            783.1130974306243
total_rewards_max            3369.613969679735
total_rewards_min            1081.6234304718464
Number of train steps total  232000
Number of env steps total    1162000
Number of rollouts total     0
Train Time (s)               43.99621141701937
(Previous) Eval Time (s)     15.740616519935429
Sample Time (s)              21.71601053373888
Epoch Time (s)               81.45283847069368
Total Train Time (s)         18342.37540854374
Epoch                        231
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:54:02.287867 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #231 | Epoch Duration: 81.16448211669922
2020-01-11 05:54:02.288070 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #231 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027061924
Z variance train             0.006812462
KL Divergence                10.215618
KL Loss                      1.0215619
QF Loss                      286.59998
VF Loss                      329.4139
Policy Loss                  -1383.2838
Q Predictions Mean           1381.8894
Q Predictions Std            300.49844
Q Predictions Max            1620.8019
Q Predictions Min            6.016404
V Predictions Mean           1373.6091
V Predictions Std            297.1222
V Predictions Max            1608.8881
V Predictions Min            -3.7428422
Log Pis Mean                 -0.13067903
Log Pis Std                  2.202669
Log Pis Max                  11.377605
Log Pis Min                  -5.5241976
Policy mu Mean               0.006116897
Policy mu Std                0.89433104
Policy mu Max                3.8030229
Policy mu Min                -3.1825945
Policy log std Mean          -0.49556658
Policy log std Std           0.22099711
Policy log std Max           0.0695191
Policy log std Min           -1.7584419
Z mean eval                  0.014684985
Z variance eval              0.008152269
total_rewards                [3112.4785202  1431.66366041 3089.3028941  1445.99435286 3141.68335973
 3180.04946505 1323.08279494 3136.33495597 1813.10860943 3164.21392182]
total_rewards_mean           2483.7912534505685
total_rewards_std            809.2794357901219
total_rewards_max            3180.049465052206
total_rewards_min            1323.0827949411314
Number of train steps total  233000
Number of env steps total    1167000
Number of rollouts total     0
Train Time (s)               43.87529403110966
(Previous) Eval Time (s)     15.45201878901571
Sample Time (s)              22.5628606043756
Epoch Time (s)               81.89017342450097
Total Train Time (s)         18431.855599387083
Epoch                        232
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:55:31.775463 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #232 | Epoch Duration: 89.48721051216125
2020-01-11 05:55:31.775776 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #232 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014813189
Z variance train             0.008135723
KL Divergence                9.693249
KL Loss                      0.9693249
QF Loss                      821.5596
VF Loss                      199.88571
Policy Loss                  -1417.875
Q Predictions Mean           1417.957
Q Predictions Std            285.68515
Q Predictions Max            1637.5593
Q Predictions Min            -4.397466
V Predictions Mean           1424.3474
V Predictions Std            282.1096
V Predictions Max            1646.3275
V Predictions Min            3.2435193
Log Pis Mean                 -0.13426782
Log Pis Std                  2.1780858
Log Pis Max                  9.963949
Log Pis Min                  -4.628115
Policy mu Mean               -0.06604715
Policy mu Std                0.91724753
Policy mu Max                3.7964401
Policy mu Min                -3.6828442
Policy log std Mean          -0.50492084
Policy log std Std           0.2043273
Policy log std Max           -0.019584954
Policy log std Min           -1.3020599
Z mean eval                  0.027392173
Z variance eval              0.007370589
total_rewards                [3228.54612521 3201.67654995 3171.48172266 1436.49104384 1387.82957923
 3135.14761249 1902.15352324 1282.47018584 3144.14973062 3266.17736685]
total_rewards_mean           2515.6123439941894
total_rewards_std            841.7079311570236
total_rewards_max            3266.1773668525043
total_rewards_min            1282.4701858429505
Number of train steps total  234000
Number of env steps total    1172000
Number of rollouts total     0
Train Time (s)               43.64209198998287
(Previous) Eval Time (s)     23.048779748845845
Sample Time (s)              21.938946842681617
Epoch Time (s)               88.62981858151034
Total Train Time (s)         18521.25472639315
Epoch                        233
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:57:01.178558 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #233 | Epoch Duration: 89.40255117416382
2020-01-11 05:57:01.178739 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #233 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02788423
Z variance train             0.007368467
KL Divergence                9.880417
KL Loss                      0.9880417
QF Loss                      136.26009
VF Loss                      216.95169
Policy Loss                  -1368.8832
Q Predictions Mean           1368.8073
Q Predictions Std            362.84708
Q Predictions Max            1639.3154
Q Predictions Min            -6.2625537
V Predictions Mean           1366.2571
V Predictions Std            358.9115
V Predictions Max            1638.7407
V Predictions Min            -10.379871
Log Pis Mean                 -0.3968569
Log Pis Std                  2.1510694
Log Pis Max                  10.770519
Log Pis Min                  -5.6792774
Policy mu Mean               0.13396658
Policy mu Std                0.81832415
Policy mu Max                3.7229087
Policy mu Min                -2.978798
Policy log std Mean          -0.46304655
Policy log std Std           0.20923188
Policy log std Max           -0.035154015
Policy log std Min           -1.3126141
Z mean eval                  0.03617896
Z variance eval              0.008532478
total_rewards                [1299.10451875  408.87349037 2010.31828944 2533.42638767 1778.84388083
 3097.68457424 1249.81767391 1799.11310825 1062.84554693 3139.12724217]
total_rewards_mean           1837.9154712554744
total_rewards_std            841.2903268720601
total_rewards_max            3139.127242172594
total_rewards_min            408.87349036654876
Number of train steps total  235000
Number of env steps total    1177000
Number of rollouts total     0
Train Time (s)               43.83190498594195
(Previous) Eval Time (s)     23.821283959783614
Sample Time (s)              22.010942861437798
Epoch Time (s)               89.66413180716336
Total Train Time (s)         18606.454042406753
Epoch                        234
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:58:26.380885 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #234 | Epoch Duration: 85.20200037956238
2020-01-11 05:58:26.381061 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #234 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03622899
Z variance train             0.008520247
KL Divergence                9.566642
KL Loss                      0.9566642
QF Loss                      481.3001
VF Loss                      104.585236
Policy Loss                  -1325.6287
Q Predictions Mean           1320.2216
Q Predictions Std            317.41602
Q Predictions Max            1575.4922
Q Predictions Min            -6.290701
V Predictions Mean           1326.5364
V Predictions Std            314.8556
V Predictions Max            1583.594
V Predictions Min            3.9584796
Log Pis Mean                 -0.3572631
Log Pis Std                  1.8994131
Log Pis Max                  6.579069
Log Pis Min                  -7.276464
Policy mu Mean               0.08524958
Policy mu Std                0.8659252
Policy mu Max                3.2136073
Policy mu Min                -2.3521647
Policy log std Mean          -0.45503426
Policy log std Std           0.1972053
Policy log std Max           -0.015454888
Policy log std Min           -1.2288777
Z mean eval                  0.041691102
Z variance eval              0.008036009
total_rewards                [3147.16363513 3220.43319361 1067.88456215 1747.21503177 1884.42971177
  993.4331827  1111.19240046  884.69150396 1026.71785216 2652.04623173]
total_rewards_mean           1773.5207305436786
total_rewards_std            875.1068556306494
total_rewards_max            3220.4331936088793
total_rewards_min            884.6915039590241
Number of train steps total  236000
Number of env steps total    1182000
Number of rollouts total     0
Train Time (s)               43.92063638428226
(Previous) Eval Time (s)     19.358894270844758
Sample Time (s)              20.814542965963483
Epoch Time (s)               84.0940736210905
Total Train Time (s)         18689.146401884966
Epoch                        235
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:59:49.074841 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #235 | Epoch Duration: 82.69364166259766
2020-01-11 05:59:49.074997 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #235 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.041721307
Z variance train             0.008028227
KL Divergence                9.686316
KL Loss                      0.96863157
QF Loss                      86.8884
VF Loss                      48.266247
Policy Loss                  -1400.5669
Q Predictions Mean           1398.9359
Q Predictions Std            274.45834
Q Predictions Max            1622.9259
Q Predictions Min            5.968979
V Predictions Mean           1401.6908
V Predictions Std            273.16925
V Predictions Max            1627.0979
V Predictions Min            4.9494357
Log Pis Mean                 -0.31150216
Log Pis Std                  2.0468788
Log Pis Max                  12.773743
Log Pis Min                  -6.348598
Policy mu Mean               0.11486837
Policy mu Std                0.8490734
Policy mu Max                3.3294709
Policy mu Min                -2.9574428
Policy log std Mean          -0.4573253
Policy log std Std           0.19669966
Policy log std Max           0.03166169
Policy log std Min           -1.2209218
Z mean eval                  0.01598142
Z variance eval              0.008076924
total_rewards                [ 962.58782031 1098.76462376 1085.99674686 1108.08576866 1037.04643015
 1370.07484892 1199.57036632  866.85479648 1321.9672058  1042.88920081]
total_rewards_mean           1109.383780806943
total_rewards_std            145.59194833316292
total_rewards_max            1370.0748489204257
total_rewards_min            866.8547964824955
Number of train steps total  237000
Number of env steps total    1187000
Number of rollouts total     0
Train Time (s)               44.21673125727102
(Previous) Eval Time (s)     17.95823817094788
Sample Time (s)              21.666268040891737
Epoch Time (s)               83.84123746911064
Total Train Time (s)         18765.737606312614
Epoch                        236
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:01:05.670309 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #236 | Epoch Duration: 76.59519076347351
2020-01-11 06:01:05.670490 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #236 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015952649
Z variance train             0.008068962
KL Divergence                9.614618
KL Loss                      0.96146184
QF Loss                      150.31284
VF Loss                      107.33585
Policy Loss                  -1388.4652
Q Predictions Mean           1386.1998
Q Predictions Std            280.8314
Q Predictions Max            1609.2604
Q Predictions Min            -1.1287608
V Predictions Mean           1394.17
V Predictions Std            280.94333
V Predictions Max            1621.0736
V Predictions Min            -0.24119395
Log Pis Mean                 -0.3595003
Log Pis Std                  1.8405579
Log Pis Max                  7.001207
Log Pis Min                  -5.6051736
Policy mu Mean               0.06386198
Policy mu Std                0.8334579
Policy mu Max                2.5108316
Policy mu Min                -2.6760104
Policy log std Mean          -0.46861544
Policy log std Std           0.19144757
Policy log std Max           0.016606927
Policy log std Min           -1.1416944
Z mean eval                  0.01735891
Z variance eval              0.008330317
total_rewards                [1731.37100274 1071.46402924 2764.60838927  958.64000982 1056.79730707
 1048.91268397 2143.47800137 1073.20572536 1029.58752489  951.88625476]
total_rewards_mean           1382.9950928484982
total_rewards_std            592.488093772817
total_rewards_max            2764.6083892674283
total_rewards_min            951.8862547589878
Number of train steps total  238000
Number of env steps total    1192000
Number of rollouts total     0
Train Time (s)               43.78344645584002
(Previous) Eval Time (s)     10.711980062071234
Sample Time (s)              21.427954643033445
Epoch Time (s)               75.9233811609447
Total Train Time (s)         18843.37494851835
Epoch                        237
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:02:23.311792 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #237 | Epoch Duration: 77.6411612033844
2020-01-11 06:02:23.311976 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #237 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017204124
Z variance train             0.008331707
KL Divergence                9.604055
KL Loss                      0.9604055
QF Loss                      204.77725
VF Loss                      175.20859
Policy Loss                  -1386.626
Q Predictions Mean           1384.3328
Q Predictions Std            282.44006
Q Predictions Max            1621.6254
Q Predictions Min            15.273836
V Predictions Mean           1388.5159
V Predictions Std            284.34824
V Predictions Max            1636.9291
V Predictions Min            18.008352
Log Pis Mean                 -0.4498618
Log Pis Std                  1.8841313
Log Pis Max                  9.727645
Log Pis Min                  -5.1635876
Policy mu Mean               0.10099721
Policy mu Std                0.8159041
Policy mu Max                3.4957469
Policy mu Min                -2.8158553
Policy log std Mean          -0.46521345
Policy log std Std           0.19183555
Policy log std Max           0.0075232685
Policy log std Min           -1.26916
Z mean eval                  0.017650202
Z variance eval              0.007820833
total_rewards                [3148.80139277 3315.61995155 3324.49860192 2263.13275313 3265.47642686
 2667.76666196 3296.54195684 1052.12106104 3285.95588413 1089.28316248]
total_rewards_mean           2670.919785267947
total_rewards_std            865.0276545405775
total_rewards_max            3324.498601918904
total_rewards_min            1052.1210610389737
Number of train steps total  239000
Number of env steps total    1197000
Number of rollouts total     0
Train Time (s)               42.78369616298005
(Previous) Eval Time (s)     12.429539756849408
Sample Time (s)              21.109603447839618
Epoch Time (s)               76.32283936766908
Total Train Time (s)         18933.41173529299
Epoch                        238
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:03:53.350796 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #238 | Epoch Duration: 90.03864574432373
2020-01-11 06:03:53.350990 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #238 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017502958
Z variance train             0.007828267
KL Divergence                9.801652
KL Loss                      0.9801652
QF Loss                      162.0404
VF Loss                      119.134125
Policy Loss                  -1367.2665
Q Predictions Mean           1368.4039
Q Predictions Std            296.20096
Q Predictions Max            1614.8
Q Predictions Min            2.0253959
V Predictions Mean           1370.9253
V Predictions Std            295.22342
V Predictions Max            1613.7211
V Predictions Min            3.8429985
Log Pis Mean                 -0.36311713
Log Pis Std                  2.0454218
Log Pis Max                  6.1624393
Log Pis Min                  -5.7212086
Policy mu Mean               0.10707519
Policy mu Std                0.8700043
Policy mu Max                2.9762864
Policy mu Min                -3.104498
Policy log std Mean          -0.47483373
Policy log std Std           0.21119136
Policy log std Max           0.10524005
Policy log std Min           -1.7640578
Z mean eval                  0.011832556
Z variance eval              0.0070038587
total_rewards                [1364.22908619 1941.41958855 3306.50923976  992.27322442  955.60610873
 3405.92634504 1073.60210851 2021.75591682 2753.87647519 2562.68497459]
total_rewards_mean           2037.788306781206
total_rewards_std            890.3288374245113
total_rewards_max            3405.9263450393264
total_rewards_min            955.6061087325512
Number of train steps total  240000
Number of env steps total    1202000
Number of rollouts total     0
Train Time (s)               43.76148539688438
(Previous) Eval Time (s)     26.14509457582608
Sample Time (s)              21.992311965674162
Epoch Time (s)               91.89889193838462
Total Train Time (s)         19019.179226906504
Epoch                        239
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:05:19.125351 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #239 | Epoch Duration: 85.77419781684875
2020-01-11 06:05:19.125634 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #239 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011586318
Z variance train             0.0070056096
KL Divergence                10.084494
KL Loss                      1.0084494
QF Loss                      165.65604
VF Loss                      71.61701
Policy Loss                  -1360.901
Q Predictions Mean           1358.2129
Q Predictions Std            309.30453
Q Predictions Max            1591.9908
Q Predictions Min            -13.106884
V Predictions Mean           1363.0032
V Predictions Std            302.9772
V Predictions Max            1595.5049
V Predictions Min            -0.6242293
Log Pis Mean                 -0.3144812
Log Pis Std                  1.9900836
Log Pis Max                  12.910147
Log Pis Min                  -5.5138087
Policy mu Mean               0.13174267
Policy mu Std                0.8353753
Policy mu Max                4.464844
Policy mu Min                -3.9441082
Policy log std Mean          -0.47724247
Policy log std Std           0.20290828
Policy log std Max           -0.030458927
Policy log std Min           -2.3799806
Z mean eval                  0.011321381
Z variance eval              0.0062913597
total_rewards                [1124.22801613  880.95839438 2237.09995441 2677.98060438 1139.10146426
 1171.31939073 1297.32173167  875.98305716 1770.14599946 1795.53201976]
total_rewards_mean           1496.967063232752
total_rewards_std            573.092672307887
total_rewards_max            2677.980604375668
total_rewards_min            875.9830571594418
Number of train steps total  241000
Number of env steps total    1207000
Number of rollouts total     0
Train Time (s)               44.08847771771252
(Previous) Eval Time (s)     20.020134875085205
Sample Time (s)              22.175148140639067
Epoch Time (s)               86.2837607334368
Total Train Time (s)         19101.101321168244
Epoch                        240
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:06:41.047676 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #240 | Epoch Duration: 81.92183661460876
2020-01-11 06:06:41.047799 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #240 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01164008
Z variance train             0.0062793186
KL Divergence                10.379103
KL Loss                      1.0379103
QF Loss                      459.6925
VF Loss                      269.9345
Policy Loss                  -1402.2992
Q Predictions Mean           1405.2229
Q Predictions Std            277.67337
Q Predictions Max            1637.8068
Q Predictions Min            -13.336756
V Predictions Mean           1400.388
V Predictions Std            276.31735
V Predictions Max            1613.7102
V Predictions Min            2.20267
Log Pis Mean                 0.3033645
Log Pis Std                  2.0806837
Log Pis Max                  10.916868
Log Pis Min                  -4.194953
Policy mu Mean               0.49234962
Policy mu Std                0.8947656
Policy mu Max                3.6774197
Policy mu Min                -3.13118
Policy log std Mean          -0.5103445
Policy log std Std           0.19189139
Policy log std Max           0.0027281344
Policy log std Min           -1.2276442
Z mean eval                  0.015316868
Z variance eval              0.005616518
total_rewards                [1066.41087795 1078.94995495 1256.15193403 1051.68344193 1077.77416635
 1085.62987411 1674.43869547 1034.23951969 1577.1332418  1032.44957775]
total_rewards_mean           1193.4861284022547
total_rewards_std            225.41442313292958
total_rewards_max            1674.438695467168
total_rewards_min            1032.449577751035
Number of train steps total  242000
Number of env steps total    1212000
Number of rollouts total     0
Train Time (s)               44.00463167903945
(Previous) Eval Time (s)     15.657989230938256
Sample Time (s)              21.517394182737917
Epoch Time (s)               81.18001509271562
Total Train Time (s)         19178.358314523473
Epoch                        241
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:07:58.306536 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #241 | Epoch Duration: 77.25864624977112
2020-01-11 06:07:58.306655 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #241 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015085973
Z variance train             0.0056175455
KL Divergence                10.626184
KL Loss                      1.0626185
QF Loss                      182.01155
VF Loss                      147.44275
Policy Loss                  -1406.3046
Q Predictions Mean           1404.6222
Q Predictions Std            263.14685
Q Predictions Max            1636.0258
Q Predictions Min            -2.639472
V Predictions Mean           1411.072
V Predictions Std            257.53073
V Predictions Max            1640.0608
V Predictions Min            13.048878
Log Pis Mean                 -0.26419702
Log Pis Std                  2.0140097
Log Pis Max                  11.117907
Log Pis Min                  -5.179428
Policy mu Mean               0.14811923
Policy mu Std                0.85314155
Policy mu Max                4.1075315
Policy mu Min                -2.9504895
Policy log std Mean          -0.46621045
Policy log std Std           0.19667827
Policy log std Max           0.08411974
Policy log std Min           -1.432195
Z mean eval                  0.012337999
Z variance eval              0.0052126357
total_rewards                [1264.2129105  2800.33900748 2709.35685919 1119.63466514 3241.06751723
 1337.04028621 1060.91700205 3036.74536593 1941.29520084 2318.72738916]
total_rewards_mean           2082.9336203722182
total_rewards_std            802.0530523545249
total_rewards_max            3241.0675172341644
total_rewards_min            1060.9170020522902
Number of train steps total  243000
Number of env steps total    1217000
Number of rollouts total     0
Train Time (s)               43.59529865020886
(Previous) Eval Time (s)     11.736374730244279
Sample Time (s)              22.37194906314835
Epoch Time (s)               77.70362244360149
Total Train Time (s)         19263.59582045907
Epoch                        242
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:09:23.547177 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #242 | Epoch Duration: 85.24041366577148
2020-01-11 06:09:23.547360 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #242 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012111683
Z variance train             0.0052143065
KL Divergence                10.773299
KL Loss                      1.07733
QF Loss                      2176.2605
VF Loss                      222.75069
Policy Loss                  -1405.5657
Q Predictions Mean           1403.3599
Q Predictions Std            251.25447
Q Predictions Max            1630.222
Q Predictions Min            7.8156977
V Predictions Mean           1403.564
V Predictions Std            247.09947
V Predictions Max            1640.2137
V Predictions Min            3.8329763
Log Pis Mean                 -0.45469153
Log Pis Std                  2.0185366
Log Pis Max                  12.951206
Log Pis Min                  -4.555563
Policy mu Mean               0.018026557
Policy mu Std                0.8382526
Policy mu Max                2.6783044
Policy mu Min                -4.0824895
Policy log std Mean          -0.45792982
Policy log std Std           0.20303416
Policy log std Max           0.014925957
Policy log std Min           -1.6532519
Z mean eval                  0.033665027
Z variance eval              0.0051673325
total_rewards                [1601.42477627 1094.85910434 1023.78322691 2767.24317772 1064.05758148
 1165.4437566  1681.77926418 1171.74857076 2826.67436288 1107.94331042]
total_rewards_mean           1550.495713155377
total_rewards_std            658.646743975388
total_rewards_max            2826.6743628838567
total_rewards_min            1023.7832269093949
Number of train steps total  244000
Number of env steps total    1222000
Number of rollouts total     0
Train Time (s)               44.48531526559964
(Previous) Eval Time (s)     19.27288953680545
Sample Time (s)              22.47244831826538
Epoch Time (s)               86.23065312067047
Total Train Time (s)         19345.532002367545
Epoch                        243
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:10:45.485007 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #243 | Epoch Duration: 81.9375147819519
2020-01-11 06:10:45.485144 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #243 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033997692
Z variance train             0.0051710596
KL Divergence                10.748179
KL Loss                      1.074818
QF Loss                      117.909966
VF Loss                      166.68864
Policy Loss                  -1411.3143
Q Predictions Mean           1414.2358
Q Predictions Std            260.22894
Q Predictions Max            1642.2766
Q Predictions Min            7.5943875
V Predictions Mean           1418.2761
V Predictions Std            259.87192
V Predictions Max            1638.8958
V Predictions Min            18.58233
Log Pis Mean                 -0.16418824
Log Pis Std                  2.6719267
Log Pis Max                  25.898558
Log Pis Min                  -8.755741
Policy mu Mean               0.074399546
Policy mu Std                0.92699146
Policy mu Max                5.234191
Policy mu Min                -6.922205
Policy log std Mean          -0.47270557
Policy log std Std           0.20473714
Policy log std Max           0.097857654
Policy log std Min           -1.2830653
Z mean eval                  0.020558504
Z variance eval              0.005669407
total_rewards                [1617.70977461 1218.4722699  3355.07771102 1128.43854575  949.63744559
 3358.48674939 1989.98142174 1106.1761519  1075.1522165  1180.30599342]
total_rewards_mean           1697.9438279805624
total_rewards_std            878.3745183348877
total_rewards_max            3358.4867493867205
total_rewards_min            949.6374455865495
Number of train steps total  245000
Number of env steps total    1227000
Number of rollouts total     0
Train Time (s)               44.320155404973775
(Previous) Eval Time (s)     14.979508527554572
Sample Time (s)              21.960259318817407
Epoch Time (s)               81.25992325134575
Total Train Time (s)         19428.54820589302
Epoch                        244
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:12:08.508080 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #244 | Epoch Duration: 83.02281403541565
2020-01-11 06:12:08.508206 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #244 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021391405
Z variance train             0.0056754653
KL Divergence                10.502852
KL Loss                      1.0502852
QF Loss                      114.30642
VF Loss                      57.127327
Policy Loss                  -1400.8243
Q Predictions Mean           1401.5405
Q Predictions Std            265.035
Q Predictions Max            1628.5776
Q Predictions Min            -12.047842
V Predictions Mean           1399.7203
V Predictions Std            264.8007
V Predictions Max            1615.2656
V Predictions Min            -5.6295958
Log Pis Mean                 -0.33271435
Log Pis Std                  1.8384812
Log Pis Max                  5.700668
Log Pis Min                  -5.6673536
Policy mu Mean               0.05413817
Policy mu Std                0.8574657
Policy mu Max                2.23934
Policy mu Min                -3.525137
Policy log std Mean          -0.47614
Policy log std Std           0.18592858
Policy log std Max           0.0068015456
Policy log std Min           -1.3310509
Z mean eval                  0.04779982
Z variance eval              0.005799531
total_rewards                [1058.88969811 3398.58546949 1088.6318617  1034.19928647 1048.72184119
 1602.38145977  973.31352597 3372.60087602 2757.90412338 3303.20761035]
total_rewards_mean           1963.8435752452388
total_rewards_std            1042.3980814791496
total_rewards_max            3398.585469493072
total_rewards_min            973.3135259735691
Number of train steps total  246000
Number of env steps total    1232000
Number of rollouts total     0
Train Time (s)               44.1132493969053
(Previous) Eval Time (s)     16.742116386070848
Sample Time (s)              22.394707740750164
Epoch Time (s)               83.25007352372631
Total Train Time (s)         19514.48256113194
Epoch                        245
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:13:34.446598 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #245 | Epoch Duration: 85.93827557563782
2020-01-11 06:13:34.446807 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #245 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.047576778
Z variance train             0.005799199
KL Divergence                10.431485
KL Loss                      1.0431485
QF Loss                      222.42029
VF Loss                      138.44357
Policy Loss                  -1396.1804
Q Predictions Mean           1396.3623
Q Predictions Std            349.5818
Q Predictions Max            1662.753
Q Predictions Min            -7.6186457
V Predictions Mean           1399.78
V Predictions Std            350.06155
V Predictions Max            1660.9725
V Predictions Min            -14.443803
Log Pis Mean                 -0.46639374
Log Pis Std                  1.9852093
Log Pis Max                  7.595132
Log Pis Min                  -5.9682093
Policy mu Mean               0.066350944
Policy mu Std                0.81052166
Policy mu Max                2.448742
Policy mu Min                -2.7688255
Policy log std Mean          -0.46851906
Policy log std Std           0.18774389
Policy log std Max           0.10258144
Policy log std Min           -1.2659717
Z mean eval                  0.012673994
Z variance eval              0.0065410347
total_rewards                [ 996.80490387 1076.53485864 1103.25715872  755.13280197 1691.57483473
 1000.68599784 1197.5407006  1041.06652515 1029.22682852 3443.20029943]
total_rewards_mean           1333.5024909485924
total_rewards_std            738.465814049693
total_rewards_max            3443.200299433523
total_rewards_min            755.1328019738286
Number of train steps total  247000
Number of env steps total    1237000
Number of rollouts total     0
Train Time (s)               44.61469912528992
(Previous) Eval Time (s)     19.430047732312232
Sample Time (s)              23.048122942913324
Epoch Time (s)               87.09286980051547
Total Train Time (s)         19595.120175004005
Epoch                        246
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:14:55.086417 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #246 | Epoch Duration: 80.63944149017334
2020-01-11 06:14:55.086593 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #246 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012623343
Z variance train             0.0065415404
KL Divergence                10.203417
KL Loss                      1.0203418
QF Loss                      140.3569
VF Loss                      115.43907
Policy Loss                  -1404.5471
Q Predictions Mean           1403.7144
Q Predictions Std            219.24483
Q Predictions Max            1612.0574
Q Predictions Min            5.812165
V Predictions Mean           1402.2517
V Predictions Std            218.70021
V Predictions Max            1607.9197
V Predictions Min            5.2635117
Log Pis Mean                 -0.28822377
Log Pis Std                  1.8871441
Log Pis Max                  9.291773
Log Pis Min                  -5.3429594
Policy mu Mean               0.22237028
Policy mu Std                0.85270476
Policy mu Max                2.968185
Policy mu Min                -2.7136507
Policy log std Mean          -0.47649312
Policy log std Std           0.18576382
Policy log std Max           0.02565229
Policy log std Min           -1.2010255
Z mean eval                  0.03620463
Z variance eval              0.006281513
total_rewards                [ 942.82570616  943.85933759 1650.97126495 1071.41518658 2201.58798266
 1043.52904523 1096.07848115  983.75957493 1646.17700068 1028.8840607 ]
total_rewards_mean           1260.9087640627645
total_rewards_std            403.50128225655436
total_rewards_max            2201.587982656383
total_rewards_min            942.8257061613241
Number of train steps total  248000
Number of env steps total    1242000
Number of rollouts total     0
Train Time (s)               44.898712780792266
(Previous) Eval Time (s)     12.976375581230968
Sample Time (s)              22.24879550607875
Epoch Time (s)               80.12388386810198
Total Train Time (s)         19674.75672171358
Epoch                        247
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:16:14.724752 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #247 | Epoch Duration: 79.63803100585938
2020-01-11 06:16:14.724888 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #247 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0371337
Z variance train             0.00628827
KL Divergence                10.30182
KL Loss                      1.030182
QF Loss                      217.7851
VF Loss                      69.10232
Policy Loss                  -1394.4407
Q Predictions Mean           1390.0044
Q Predictions Std            301.2303
Q Predictions Max            1615.0603
Q Predictions Min            4.712081
V Predictions Mean           1391.4152
V Predictions Std            298.72427
V Predictions Max            1617.6274
V Predictions Min            7.755002
Log Pis Mean                 -0.42915037
Log Pis Std                  2.2879515
Log Pis Max                  16.724323
Log Pis Min                  -5.6963506
Policy mu Mean               0.07240395
Policy mu Std                0.88672775
Policy mu Max                3.9681087
Policy mu Min                -5.121408
Policy log std Mean          -0.470232
Policy log std Std           0.19525608
Policy log std Max           0.0070111156
Policy log std Min           -1.3499329
Z mean eval                  0.014550736
Z variance eval              0.0054671294
total_rewards                [1060.2466586  2129.46651562 2778.13320968 3295.90490926 3372.45093474
 2820.30877468 3309.38068991 3343.23461338 1289.28549005 1296.94549798]
total_rewards_mean           2469.535729389364
total_rewards_std            897.4857410952378
total_rewards_max            3372.450934739943
total_rewards_min            1060.2466585964864
Number of train steps total  249000
Number of env steps total    1247000
Number of rollouts total     0
Train Time (s)               44.52698839874938
(Previous) Eval Time (s)     12.490264493972063
Sample Time (s)              22.058240048587322
Epoch Time (s)               79.07549294130877
Total Train Time (s)         19765.843822806142
Epoch                        248
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:17:45.815260 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #248 | Epoch Duration: 91.09027338027954
2020-01-11 06:17:45.815382 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #248 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014440109
Z variance train             0.0054673054
KL Divergence                10.637676
KL Loss                      1.0637677
QF Loss                      474.16943
VF Loss                      1650.5969
Policy Loss                  -1396.283
Q Predictions Mean           1397.1816
Q Predictions Std            281.5792
Q Predictions Max            1617.5715
Q Predictions Min            10.658552
V Predictions Mean           1394.0637
V Predictions Std            284.2121
V Predictions Max            1621.5663
V Predictions Min            8.840793
Log Pis Mean                 -0.40941083
Log Pis Std                  2.1679673
Log Pis Max                  16.568499
Log Pis Min                  -7.059907
Policy mu Mean               0.057038117
Policy mu Std                0.85304916
Policy mu Max                4.3014884
Policy mu Min                -5.162709
Policy log std Mean          -0.4549698
Policy log std Std           0.19762023
Policy log std Max           0.15529609
Policy log std Min           -1.552906
Z mean eval                  0.03165405
Z variance eval              0.0054059564
total_rewards                [2350.83734743 1931.16401833 3323.54217615 3356.45421076 3108.28307643
 3368.73678303 1588.59709794 3432.00270472 3356.97591762 3011.39239611]
total_rewards_mean           2882.7985728521967
total_rewards_std            641.2595438002085
total_rewards_max            3432.002704718272
total_rewards_min            1588.5970979385145
Number of train steps total  250000
Number of env steps total    1252000
Number of rollouts total     0
Train Time (s)               43.230359143577516
(Previous) Eval Time (s)     24.504811499733478
Sample Time (s)              22.376473469194025
Epoch Time (s)               90.11164411250502
Total Train Time (s)         19859.41178077925
Epoch                        249
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:19:19.384648 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #249 | Epoch Duration: 93.5691728591919
2020-01-11 06:19:19.384773 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #249 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03231845
Z variance train             0.005403714
KL Divergence                10.684814
KL Loss                      1.0684814
QF Loss                      157.28519
VF Loss                      117.61796
Policy Loss                  -1463.6626
Q Predictions Mean           1464.1865
Q Predictions Std            198.41544
Q Predictions Max            1657.4388
Q Predictions Min            101.11472
V Predictions Mean           1464.7783
V Predictions Std            194.98645
V Predictions Max            1648.1106
V Predictions Min            111.19637
Log Pis Mean                 -0.4032808
Log Pis Std                  1.987895
Log Pis Max                  10.687009
Log Pis Min                  -5.9517517
Policy mu Mean               0.26133826
Policy mu Std                0.8071741
Policy mu Max                3.06934
Policy mu Min                -2.8819804
Policy log std Mean          -0.45794833
Policy log std Std           0.18324022
Policy log std Max           0.14317513
Policy log std Min           -1.1842716
Z mean eval                  0.025130656
Z variance eval              0.0050231568
total_rewards                [1547.68129818 3177.8460714  1288.83123561 3140.47152508 1009.84655688
 3086.57176331 1190.09929125 1486.6621301  2603.16935404 2575.51490927]
total_rewards_mean           2110.6694135120792
total_rewards_std            839.726166133604
total_rewards_max            3177.8460714012426
total_rewards_min            1009.8465568839363
Number of train steps total  251000
Number of env steps total    1257000
Number of rollouts total     0
Train Time (s)               42.943413723260164
(Previous) Eval Time (s)     27.962087999563664
Sample Time (s)              22.092584413010627
Epoch Time (s)               92.99808613583446
Total Train Time (s)         19946.156150917523
Epoch                        250
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:20:46.132977 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #250 | Epoch Duration: 86.74809908866882
2020-01-11 06:20:46.133139 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #250 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025904547
Z variance train             0.005016298
KL Divergence                10.881938
KL Loss                      1.0881938
QF Loss                      252.95926
VF Loss                      132.44623
Policy Loss                  -1386.7241
Q Predictions Mean           1391.3218
Q Predictions Std            312.99893
Q Predictions Max            1642.3077
Q Predictions Min            -11.853959
V Predictions Mean           1389.6274
V Predictions Std            307.97217
V Predictions Max            1640.6489
V Predictions Min            3.9329934
Log Pis Mean                 -0.34363472
Log Pis Std                  2.190363
Log Pis Max                  13.0853615
Log Pis Min                  -5.617117
Policy mu Mean               0.09086689
Policy mu Std                0.8608685
Policy mu Max                3.6781461
Policy mu Min                -4.122481
Policy log std Mean          -0.4672235
Policy log std Std           0.21134396
Policy log std Max           0.03207922
Policy log std Min           -1.557446
Z mean eval                  0.023363914
Z variance eval              0.004975006
total_rewards                [3246.48019949 1154.22421761 1143.39529147 3019.7710259  2394.47267496
 1383.32153802 3194.08994464 1709.15953057 1880.28905949 3251.99382609]
total_rewards_mean           2237.7197308251043
total_rewards_std            842.9594694083222
total_rewards_max            3251.9938260937365
total_rewards_min            1143.3952914707913
Number of train steps total  252000
Number of env steps total    1262000
Number of rollouts total     0
Train Time (s)               44.19451269507408
(Previous) Eval Time (s)     21.711840831674635
Sample Time (s)              21.97817477909848
Epoch Time (s)               87.8845283058472
Total Train Time (s)         20032.908672864083
Epoch                        251
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:22:12.889816 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #251 | Epoch Duration: 86.75655150413513
2020-01-11 06:22:12.889970 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #251 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024185743
Z variance train             0.004971801
KL Divergence                10.928394
KL Loss                      1.0928395
QF Loss                      525.58026
VF Loss                      84.78343
Policy Loss                  -1381.6733
Q Predictions Mean           1381.2094
Q Predictions Std            292.21954
Q Predictions Max            1611.7156
Q Predictions Min            5.099703
V Predictions Mean           1380.5046
V Predictions Std            293.9663
V Predictions Max            1618.2913
V Predictions Min            -1.7242563
Log Pis Mean                 -0.12678568
Log Pis Std                  2.0510511
Log Pis Max                  9.491777
Log Pis Min                  -4.3861876
Policy mu Mean               0.14474727
Policy mu Std                0.8735942
Policy mu Max                3.172075
Policy mu Min                -3.5017114
Policy log std Mean          -0.47699475
Policy log std Std           0.20196466
Policy log std Max           -0.0023228526
Policy log std Min           -1.4548955
Z mean eval                  0.025535535
Z variance eval              0.005130503
total_rewards                [ 973.73470485 1046.37094933 2020.91804512 1095.18308825 1343.14585924
  230.37234025 1656.25897929 1032.28468294 1083.72897738 2189.58784935]
total_rewards_mean           1267.158547601939
total_rewards_std            538.921187861452
total_rewards_max            2189.5878493536793
total_rewards_min            230.37234025000532
Number of train steps total  253000
Number of env steps total    1267000
Number of rollouts total     0
Train Time (s)               43.5093941683881
(Previous) Eval Time (s)     20.583632573019713
Sample Time (s)              21.58637573523447
Epoch Time (s)               85.67940247664228
Total Train Time (s)         20109.685059281066
Epoch                        252
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:23:29.669809 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #252 | Epoch Duration: 76.77971458435059
2020-01-11 06:23:29.669965 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #252 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024925137
Z variance train             0.0051322496
KL Divergence                10.8295
KL Loss                      1.08295
QF Loss                      113.63004
VF Loss                      113.35526
Policy Loss                  -1432.5093
Q Predictions Mean           1430.9104
Q Predictions Std            163.44434
Q Predictions Max            1615.5023
Q Predictions Min            140.92972
V Predictions Mean           1434.5054
V Predictions Std            163.07233
V Predictions Max            1617.072
V Predictions Min            111.93179
Log Pis Mean                 -0.1345298
Log Pis Std                  1.8032064
Log Pis Max                  6.526406
Log Pis Min                  -5.410279
Policy mu Mean               0.15462743
Policy mu Std                0.85552686
Policy mu Max                3.0355606
Policy mu Min                -2.9303572
Policy log std Mean          -0.4772694
Policy log std Std           0.18299945
Policy log std Max           0.040554494
Policy log std Min           -1.2006605
Z mean eval                  0.023085585
Z variance eval              0.004301842
total_rewards                [1750.03320656 1124.90781031 1074.65504505 2427.02372207 3372.41007544
 3382.11656067 1016.99306174 1868.02178752  860.66627829 3400.46393928]
total_rewards_mean           2027.7291486925108
total_rewards_std            994.7889370410509
total_rewards_max            3400.463939276868
total_rewards_min            860.6662782915499
Number of train steps total  254000
Number of env steps total    1272000
Number of rollouts total     0
Train Time (s)               43.93464117962867
(Previous) Eval Time (s)     11.68369119707495
Sample Time (s)              22.10912109259516
Epoch Time (s)               77.72745346929878
Total Train Time (s)         20195.702575333882
Epoch                        253
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:24:55.689200 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #253 | Epoch Duration: 86.01911926269531
2020-01-11 06:24:55.689321 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #253 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022307556
Z variance train             0.0042987457
KL Divergence                11.245939
KL Loss                      1.124594
QF Loss                      281.05344
VF Loss                      270.42218
Policy Loss                  -1409.5173
Q Predictions Mean           1411.0925
Q Predictions Std            288.92828
Q Predictions Max            1635.0988
Q Predictions Min            -7.247744
V Predictions Mean           1418.3638
V Predictions Std            288.98642
V Predictions Max            1643.7158
V Predictions Min            -18.797821
Log Pis Mean                 -0.29775235
Log Pis Std                  2.0318625
Log Pis Max                  11.573058
Log Pis Min                  -6.234092
Policy mu Mean               0.15921684
Policy mu Std                0.8337675
Policy mu Max                2.6307273
Policy mu Min                -3.0423121
Policy log std Mean          -0.43944272
Policy log std Std           0.19538794
Policy log std Max           0.06903499
Policy log std Min           -1.4643621
Z mean eval                  0.010893904
Z variance eval              0.0038914655
total_rewards                [1255.98395624 2179.32247488 1239.01129409 2100.54794053 2593.88235936
 1174.87561463 3313.50685735 3264.88326578 3274.50734308 3184.16545144]
total_rewards_mean           2358.0686557379804
total_rewards_std            853.1220154478103
total_rewards_max            3313.5068573476055
total_rewards_min            1174.8756146279777
Number of train steps total  255000
Number of env steps total    1277000
Number of rollouts total     0
Train Time (s)               43.722310966812074
(Previous) Eval Time (s)     19.975110473111272
Sample Time (s)              22.145249709952623
Epoch Time (s)               85.84267114987597
Total Train Time (s)         20284.205796604976
Epoch                        254
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:26:24.195293 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #254 | Epoch Duration: 88.5058662891388
2020-01-11 06:26:24.195467 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #254 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011086327
Z variance train             0.0038898985
KL Divergence                11.467127
KL Loss                      1.1467127
QF Loss                      141.67197
VF Loss                      77.81264
Policy Loss                  -1462.2693
Q Predictions Mean           1462.3876
Q Predictions Std            202.78339
Q Predictions Max            1643.7837
Q Predictions Min            8.522137
V Predictions Mean           1459.7966
V Predictions Std            200.37692
V Predictions Max            1637.0743
V Predictions Min            13.59242
Log Pis Mean                 -0.26111907
Log Pis Std                  2.1423135
Log Pis Max                  15.558127
Log Pis Min                  -6.426102
Policy mu Mean               0.16627975
Policy mu Std                0.87130576
Policy mu Max                4.2888393
Policy mu Min                -3.048169
Policy log std Mean          -0.4754763
Policy log std Std           0.17757545
Policy log std Max           -0.03349501
Policy log std Min           -1.1669589
Z mean eval                  0.03251163
Z variance eval              0.0039229905
total_rewards                [1100.27764951 3448.17470322 1088.41251273 1031.41380558 1318.70632376
 1440.36471697 1137.69535757 2407.4556313  1770.16101311 1377.25450871]
total_rewards_mean           1611.991622244867
total_rewards_std            727.8692360477866
total_rewards_max            3448.1747032151625
total_rewards_min            1031.4138055790559
Number of train steps total  256000
Number of env steps total    1282000
Number of rollouts total     0
Train Time (s)               43.590130783151835
(Previous) Eval Time (s)     22.63805220508948
Sample Time (s)              21.015120401978493
Epoch Time (s)               87.24330339021981
Total Train Time (s)         20362.926839875057
Epoch                        255
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:27:42.917721 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #255 | Epoch Duration: 78.72212982177734
2020-01-11 06:27:42.917849 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #255 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03298801
Z variance train             0.0039224005
KL Divergence                11.447966
KL Loss                      1.1447966
QF Loss                      232.47324
VF Loss                      98.26904
Policy Loss                  -1443.523
Q Predictions Mean           1441.7583
Q Predictions Std            252.58174
Q Predictions Max            1648.0475
Q Predictions Min            6.921396
V Predictions Mean           1442.9595
V Predictions Std            250.31409
V Predictions Max            1655.7095
V Predictions Min            17.257753
Log Pis Mean                 -0.32996994
Log Pis Std                  1.8668325
Log Pis Max                  8.569384
Log Pis Min                  -5.130183
Policy mu Mean               0.013552114
Policy mu Std                0.8224526
Policy mu Max                3.2069426
Policy mu Min                -3.1441426
Policy log std Mean          -0.47648898
Policy log std Std           0.19043864
Policy log std Max           0.031688333
Policy log std Min           -1.2357253
Z mean eval                  0.01655155
Z variance eval              0.0035317824
total_rewards                [2589.88157401 1089.06397786 1069.04225733 1670.46081176 1370.62815784
 3331.88380555 3363.08792614 1888.27057779 3408.72171444 1242.62497552]
total_rewards_mean           2102.366577823752
total_rewards_std            929.8861910078656
total_rewards_max            3408.721714443412
total_rewards_min            1069.0422573347719
Number of train steps total  257000
Number of env steps total    1287000
Number of rollouts total     0
Train Time (s)               43.37632720824331
(Previous) Eval Time (s)     14.116653360892087
Sample Time (s)              20.061700381804258
Epoch Time (s)               77.55468095093966
Total Train Time (s)         20447.09754140675
Epoch                        256
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:29:07.090539 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #256 | Epoch Duration: 84.17259049415588
2020-01-11 06:29:07.090663 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #256 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015874885
Z variance train             0.0035308704
KL Divergence                11.735113
KL Loss                      1.1735114
QF Loss                      195.66481
VF Loss                      607.22797
Policy Loss                  -1444.2668
Q Predictions Mean           1449.7605
Q Predictions Std            215.85875
Q Predictions Max            1638.158
Q Predictions Min            -1.756247
V Predictions Mean           1463.7081
V Predictions Std            216.48633
V Predictions Max            1645.2733
V Predictions Min            5.3919873
Log Pis Mean                 -0.23203364
Log Pis Std                  1.951224
Log Pis Max                  6.673464
Log Pis Min                  -5.1604924
Policy mu Mean               0.071561925
Policy mu Std                0.85207206
Policy mu Max                2.5765946
Policy mu Min                -2.9976642
Policy log std Mean          -0.4922459
Policy log std Std           0.18829755
Policy log std Max           -0.03985268
Policy log std Min           -1.2345972
Z mean eval                  0.0205531
Z variance eval              0.0035629538
total_rewards                [3335.7541387   811.53535963 1428.24374247 1056.1452314  3359.83318511
 3361.6606513  2533.91977868 1177.50998847  877.19082388 1079.94840959]
total_rewards_mean           1902.1741309241163
total_rewards_std            1053.1275754083374
total_rewards_max            3361.660651297444
total_rewards_min            811.5353596303272
Number of train steps total  258000
Number of env steps total    1292000
Number of rollouts total     0
Train Time (s)               43.53271908080205
(Previous) Eval Time (s)     20.73436272703111
Sample Time (s)              22.154805037193
Epoch Time (s)               86.42188684502617
Total Train Time (s)         20530.674839081243
Epoch                        257
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:30:30.669505 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #257 | Epoch Duration: 83.57875061035156
2020-01-11 06:30:30.669627 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #257 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02130974
Z variance train             0.0035581538
KL Divergence                11.826263
KL Loss                      1.1826264
QF Loss                      85.467316
VF Loss                      72.0246
Policy Loss                  -1468.8783
Q Predictions Mean           1467.4069
Q Predictions Std            181.45882
Q Predictions Max            1650.2837
Q Predictions Min            357.2202
V Predictions Mean           1464.751
V Predictions Std            181.157
V Predictions Max            1650.8081
V Predictions Min            354.45
Log Pis Mean                 -0.37521523
Log Pis Std                  1.6650189
Log Pis Max                  7.286339
Log Pis Min                  -3.9859135
Policy mu Mean               0.12897776
Policy mu Std                0.7700954
Policy mu Max                2.534926
Policy mu Min                -2.9161153
Policy log std Mean          -0.48075986
Policy log std Std           0.18527922
Policy log std Max           -0.03557864
Policy log std Min           -1.2789394
Z mean eval                  0.017470915
Z variance eval              0.0038304955
total_rewards                [1415.16132019 1076.12798298  766.66999566  606.71721341  891.93906203
 1105.03052611 1068.02883269 3479.51299199  949.51982231 1092.01704027]
total_rewards_mean           1245.0724787645709
total_rewards_std            772.8518613259879
total_rewards_max            3479.5129919915853
total_rewards_min            606.7172134094952
Number of train steps total  259000
Number of env steps total    1297000
Number of rollouts total     0
Train Time (s)               43.651024849154055
(Previous) Eval Time (s)     17.89101221319288
Sample Time (s)              21.067363837733865
Epoch Time (s)               82.6094009000808
Total Train Time (s)         20606.351758045144
Epoch                        258
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:31:46.352291 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #258 | Epoch Duration: 75.68255305290222
2020-01-11 06:31:46.352474 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #258 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017776797
Z variance train             0.0038256433
KL Divergence                11.438848
KL Loss                      1.1438848
QF Loss                      100.66781
VF Loss                      71.15535
Policy Loss                  -1451.978
Q Predictions Mean           1451.8826
Q Predictions Std            224.27914
Q Predictions Max            1632.8043
Q Predictions Min            5.0590863
V Predictions Mean           1453.8899
V Predictions Std            222.65256
V Predictions Max            1635.9513
V Predictions Min            5.7912
Log Pis Mean                 -0.3238157
Log Pis Std                  1.8784436
Log Pis Max                  7.9315586
Log Pis Min                  -4.421927
Policy mu Mean               0.12141801
Policy mu Std                0.807409
Policy mu Max                3.4556584
Policy mu Min                -2.5766292
Policy log std Mean          -0.47496402
Policy log std Std           0.19051772
Policy log std Max           -0.0722128
Policy log std Min           -1.5107865
Z mean eval                  0.019126944
Z variance eval              0.004014209
total_rewards                [2893.60883703 1082.0428259  2549.28383825 1937.21596105 3342.65929869
 3301.21136715 3328.95783416 1118.49509834 3288.42873911 1914.10759474]
total_rewards_mean           2475.6011394403063
total_rewards_std            859.7303769935272
total_rewards_max            3342.659298691417
total_rewards_min            1082.042825895193
Number of train steps total  260000
Number of env steps total    1302000
Number of rollouts total     0
Train Time (s)               44.37857221392915
(Previous) Eval Time (s)     10.963938034139574
Sample Time (s)              22.002288688439876
Epoch Time (s)               77.3447989365086
Total Train Time (s)         20695.103849689942
Epoch                        259
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:33:15.107264 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #259 | Epoch Duration: 88.75464081764221
2020-01-11 06:33:15.107451 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #259 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017966747
Z variance train             0.0040094764
KL Divergence                11.341615
KL Loss                      1.1341615
QF Loss                      205.14017
VF Loss                      135.68788
Policy Loss                  -1456.3263
Q Predictions Mean           1458.3123
Q Predictions Std            235.53558
Q Predictions Max            1652.7233
Q Predictions Min            -0.79195863
V Predictions Mean           1448.262
V Predictions Std            233.78896
V Predictions Max            1642.0922
V Predictions Min            5.24648
Log Pis Mean                 -0.20100744
Log Pis Std                  1.8710853
Log Pis Max                  6.4750977
Log Pis Min                  -3.895576
Policy mu Mean               0.05393244
Policy mu Std                0.88961667
Policy mu Max                2.6357574
Policy mu Min                -3.1240985
Policy log std Mean          -0.45896998
Policy log std Std           0.19126798
Policy log std Max           -0.012785822
Policy log std Min           -1.4416186
Z mean eval                  0.021218488
Z variance eval              0.005753708
total_rewards                [1293.80367238 3358.68769843 1866.07665577 3321.09159937 2544.68519999
 2901.29418259 2862.86101545 3404.83360517 1076.88865119 1074.04521762]
total_rewards_mean           2370.426749796312
total_rewards_std            909.5290431632205
total_rewards_max            3404.8336051653996
total_rewards_min            1074.0452176217054
Number of train steps total  261000
Number of env steps total    1307000
Number of rollouts total     0
Train Time (s)               43.72826918680221
(Previous) Eval Time (s)     22.37353354599327
Sample Time (s)              22.237746360246092
Epoch Time (s)               88.33954909304157
Total Train Time (s)         20782.72408761736
Epoch                        260
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:34:42.729033 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #260 | Epoch Duration: 87.62145042419434
2020-01-11 06:34:42.729167 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #260 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020944247
Z variance train             0.005758908
KL Divergence                10.556215
KL Loss                      1.0556215
QF Loss                      151.55183
VF Loss                      83.40996
Policy Loss                  -1440.5652
Q Predictions Mean           1443.7256
Q Predictions Std            278.59097
Q Predictions Max            1663.0756
Q Predictions Min            -27.565582
V Predictions Mean           1439.7336
V Predictions Std            277.34534
V Predictions Max            1660.5327
V Predictions Min            0.34406203
Log Pis Mean                 -0.32310575
Log Pis Std                  1.7077228
Log Pis Max                  5.7418284
Log Pis Min                  -4.6660576
Policy mu Mean               0.039013434
Policy mu Std                0.8413438
Policy mu Max                2.5127273
Policy mu Min                -2.9765234
Policy log std Mean          -0.4570601
Policy log std Std           0.18484719
Policy log std Max           0.0050070286
Policy log std Min           -1.299943
Z mean eval                  0.024695037
Z variance eval              0.0057523535
total_rewards                [1896.53540491 3437.82194043 3436.23176011 3446.76629694 1237.72979573
 1353.06866989 1151.69433006 3485.2839942  1415.6605505  3444.26664381]
total_rewards_mean           2430.505938658783
total_rewards_std            1036.011747193837
total_rewards_max            3485.283994199954
total_rewards_min            1151.6943300625433
Number of train steps total  262000
Number of env steps total    1312000
Number of rollouts total     0
Train Time (s)               45.72675150912255
(Previous) Eval Time (s)     21.655193304177374
Sample Time (s)              21.513746175915003
Epoch Time (s)               88.89569098921493
Total Train Time (s)         20870.688145176973
Epoch                        261
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:36:10.695706 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #261 | Epoch Duration: 87.96642422676086
2020-01-11 06:36:10.695883 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #261 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025013294
Z variance train             0.005763191
KL Divergence                10.55451
KL Loss                      1.055451
QF Loss                      205.53732
VF Loss                      227.98393
Policy Loss                  -1447.2052
Q Predictions Mean           1444.5079
Q Predictions Std            256.6109
Q Predictions Max            1638.3824
Q Predictions Min            4.833823
V Predictions Mean           1437.5951
V Predictions Std            253.1159
V Predictions Max            1622.4266
V Predictions Min            10.533958
Log Pis Mean                 -0.38766482
Log Pis Std                  1.9487439
Log Pis Max                  14.484834
Log Pis Min                  -3.8413587
Policy mu Mean               0.097807944
Policy mu Std                0.83395964
Policy mu Max                4.3040266
Policy mu Min                -2.669325
Policy log std Mean          -0.45393026
Policy log std Std           0.18512964
Policy log std Max           -0.016544282
Policy log std Min           -1.1889353
Z mean eval                  0.029358868
Z variance eval              0.006209881
total_rewards                [3210.51430698 2909.38614378  754.14246641 1387.02219612 3252.39283802
 1744.52376686 2736.22981119 3205.51300074 3215.05071777  920.63490023]
total_rewards_mean           2333.541014809078
total_rewards_std            968.409204000416
total_rewards_max            3252.392838017637
total_rewards_min            754.1424664083316
Number of train steps total  263000
Number of env steps total    1317000
Number of rollouts total     0
Train Time (s)               43.15805828664452
(Previous) Eval Time (s)     20.72567647602409
Sample Time (s)              22.129681002814323
Epoch Time (s)               86.01341576548293
Total Train Time (s)         20958.697907883674
Epoch                        262
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:37:38.711388 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #262 | Epoch Duration: 88.01534724235535
2020-01-11 06:37:38.711597 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #262 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029596727
Z variance train             0.0062122024
KL Divergence                10.366664
KL Loss                      1.0366664
QF Loss                      164.7161
VF Loss                      75.28882
Policy Loss                  -1450.592
Q Predictions Mean           1449.4016
Q Predictions Std            174.62439
Q Predictions Max            1632.7565
Q Predictions Min            -0.75923914
V Predictions Mean           1453.014
V Predictions Std            174.59784
V Predictions Max            1634.8156
V Predictions Min            6.1412296
Log Pis Mean                 -0.45581424
Log Pis Std                  1.9357637
Log Pis Max                  9.755848
Log Pis Min                  -5.2247705
Policy mu Mean               0.14360799
Policy mu Std                0.8215278
Policy mu Max                2.8464408
Policy mu Min                -2.8126273
Policy log std Mean          -0.4609274
Policy log std Std           0.19233488
Policy log std Max           -0.055244178
Policy log std Min           -1.2969428
Z mean eval                  0.01418817
Z variance eval              0.00583703
total_rewards                [3368.29493602 3388.20966379 3338.26861053 3330.88698896 2493.27521142
 3267.91072629 3327.98657816 3347.90746217 3349.40379499 3413.28384358]
total_rewards_mean           3262.5427815924722
total_rewards_std            259.04056579263715
total_rewards_max            3413.2838435827357
total_rewards_min            2493.2752114212417
Number of train steps total  264000
Number of env steps total    1322000
Number of rollouts total     0
Train Time (s)               44.14159739809111
(Previous) Eval Time (s)     22.727364440914243
Sample Time (s)              22.78396760718897
Epoch Time (s)               89.65292944619432
Total Train Time (s)         21057.092456365004
Epoch                        263
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:39:17.108117 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #263 | Epoch Duration: 98.39637207984924
2020-01-11 06:39:17.108245 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #263 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015255625
Z variance train             0.005835143
KL Divergence                10.481537
KL Loss                      1.0481538
QF Loss                      70.284515
VF Loss                      53.058483
Policy Loss                  -1480.136
Q Predictions Mean           1475.7983
Q Predictions Std            236.09311
Q Predictions Max            1681.5001
Q Predictions Min            -4.526352
V Predictions Mean           1476.1378
V Predictions Std            235.60829
V Predictions Max            1679.5918
V Predictions Min            -7.279192
Log Pis Mean                 -0.38581836
Log Pis Std                  1.82171
Log Pis Max                  8.012297
Log Pis Min                  -5.1904507
Policy mu Mean               0.058863994
Policy mu Std                0.82358795
Policy mu Max                2.4007373
Policy mu Min                -3.0934756
Policy log std Mean          -0.46177277
Policy log std Std           0.20415989
Policy log std Max           0.027164549
Policy log std Min           -1.3668463
Z mean eval                  0.020401355
Z variance eval              0.0055464925
total_rewards                [3298.0982412  3287.9766118  1354.27771166 1132.14422318 2891.33669098
 3314.96801485 2891.88844231 3300.28759042 3320.07667609 1313.19527901]
total_rewards_mean           2610.4249481501947
total_rewards_std            895.0991838755563
total_rewards_max            3320.076676089565
total_rewards_min            1132.1442231764472
Number of train steps total  265000
Number of env steps total    1327000
Number of rollouts total     0
Train Time (s)               44.24115084996447
(Previous) Eval Time (s)     31.470560322981328
Sample Time (s)              22.005892228335142
Epoch Time (s)               97.71760340128094
Total Train Time (s)         21149.094549906906
Epoch                        264
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:40:49.112492 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #264 | Epoch Duration: 92.00413990020752
2020-01-11 06:40:49.112616 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #264 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020550456
Z variance train             0.0055449
KL Divergence                10.633336
KL Loss                      1.0633336
QF Loss                      256.38593
VF Loss                      89.32283
Policy Loss                  -1444.4257
Q Predictions Mean           1445.9849
Q Predictions Std            212.43906
Q Predictions Max            1641.9303
Q Predictions Min            43.813683
V Predictions Mean           1441.5267
V Predictions Std            210.3517
V Predictions Max            1634.28
V Predictions Min            52.080845
Log Pis Mean                 -0.23410615
Log Pis Std                  2.1208975
Log Pis Max                  10.453083
Log Pis Min                  -6.260852
Policy mu Mean               0.043500632
Policy mu Std                0.8925924
Policy mu Max                2.9798281
Policy mu Min                -2.877736
Policy log std Mean          -0.47048974
Policy log std Std           0.19453503
Policy log std Max           0.043433666
Policy log std Min           -1.1452465
Z mean eval                  0.0150171695
Z variance eval              0.0049866736
total_rewards                [1551.35966217 3401.27898116 2522.57942751 3368.8747002  3383.28459585
 3383.13715095 3362.37554678 3399.46258107 3388.11760009 3333.63899688]
total_rewards_mean           3109.410924266567
total_rewards_std            578.827512587934
total_rewards_max            3401.278981158167
total_rewards_min            1551.3596621700963
Number of train steps total  266000
Number of env steps total    1332000
Number of rollouts total     0
Train Time (s)               44.295836413279176
(Previous) Eval Time (s)     25.756845994386822
Sample Time (s)              21.909223731141537
Epoch Time (s)               91.96190613880754
Total Train Time (s)         21245.08977845963
Epoch                        265
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:42:25.109243 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #265 | Epoch Duration: 95.9965226650238
2020-01-11 06:42:25.109366 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #265 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014498599
Z variance train             0.0049831923
KL Divergence                10.846208
KL Loss                      1.0846208
QF Loss                      110.79349
VF Loss                      120.875305
Policy Loss                  -1464.4244
Q Predictions Mean           1464.23
Q Predictions Std            227.26572
Q Predictions Max            1647.0242
Q Predictions Min            -14.580218
V Predictions Mean           1465.4443
V Predictions Std            225.27855
V Predictions Max            1645.1089
V Predictions Min            6.934598
Log Pis Mean                 -0.19280034
Log Pis Std                  1.9837445
Log Pis Max                  7.6163616
Log Pis Min                  -5.299683
Policy mu Mean               0.09789323
Policy mu Std                0.86878496
Policy mu Max                2.4327397
Policy mu Min                -2.8235915
Policy log std Mean          -0.47310624
Policy log std Std           0.2111338
Policy log std Max           0.0037270784
Policy log std Min           -1.401054
Z mean eval                  0.013765177
Z variance eval              0.0047387728
total_rewards                [1115.41861732  854.94372949 1371.58328728 1852.62583268 1255.32233825
 1307.02893857 1079.24329673 3455.59008026 3494.82917247 1096.94720136]
total_rewards_mean           1688.3532494421556
total_rewards_std            926.8406301045768
total_rewards_max            3494.829172465591
total_rewards_min            854.9437294929869
Number of train steps total  267000
Number of env steps total    1337000
Number of rollouts total     0
Train Time (s)               43.25578205380589
(Previous) Eval Time (s)     29.791221170686185
Sample Time (s)              21.631549919955432
Epoch Time (s)               94.6785531444475
Total Train Time (s)         21325.432890919503
Epoch                        266
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:43:45.454678 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #266 | Epoch Duration: 80.345219373703
2020-01-11 06:43:45.454803 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #266 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013646148
Z variance train             0.0047320584
KL Divergence                11.042247
KL Loss                      1.1042247
QF Loss                      1135.7949
VF Loss                      187.76682
Policy Loss                  -1478.4465
Q Predictions Mean           1478.9232
Q Predictions Std            208.46977
Q Predictions Max            1663.4869
Q Predictions Min            8.337075
V Predictions Mean           1471.5701
V Predictions Std            204.01195
V Predictions Max            1650.6034
V Predictions Min            7.670309
Log Pis Mean                 -0.3566317
Log Pis Std                  1.9524366
Log Pis Max                  9.744076
Log Pis Min                  -4.8984547
Policy mu Mean               0.058179587
Policy mu Std                0.875758
Policy mu Max                4.1361885
Policy mu Min                -3.1966875
Policy log std Mean          -0.4554815
Policy log std Std           0.20616563
Policy log std Max           0.0016308427
Policy log std Min           -1.2578733
Z mean eval                  0.0075819604
Z variance eval              0.005767267
total_rewards                [3302.76643585 2396.25481963 3359.64810433 3347.41139712 3328.35931732
 3378.08768195 2965.5798393  3304.60232541 3338.40283401 3372.18599074]
total_rewards_mean           3209.329874565851
total_rewards_std            294.24540469157483
total_rewards_max            3378.0876819452046
total_rewards_min            2396.2548196327966
Number of train steps total  268000
Number of env steps total    1342000
Number of rollouts total     0
Train Time (s)               44.59943336574361
(Previous) Eval Time (s)     15.457648276817054
Sample Time (s)              21.83186190435663
Epoch Time (s)               81.88894354691729
Total Train Time (s)         21423.217028927524
Epoch                        267
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:45:23.245166 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #267 | Epoch Duration: 97.7902524471283
2020-01-11 06:45:23.245345 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #267 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.009533784
Z variance train             0.0057798023
KL Divergence                10.545311
KL Loss                      1.0545311
QF Loss                      5491.5347
VF Loss                      325.2544
Policy Loss                  -1469.0265
Q Predictions Mean           1471.8081
Q Predictions Std            220.79767
Q Predictions Max            1645.088
Q Predictions Min            18.076183
V Predictions Mean           1473.9489
V Predictions Std            217.3902
V Predictions Max            1637.1226
V Predictions Min            12.612349
Log Pis Mean                 -0.5263599
Log Pis Std                  1.7691903
Log Pis Max                  7.9775414
Log Pis Min                  -5.820357
Policy mu Mean               -0.06092726
Policy mu Std                0.8085733
Policy mu Max                3.40812
Policy mu Min                -2.6486466
Policy log std Mean          -0.42232838
Policy log std Std           0.20404471
Policy log std Max           0.12680432
Policy log std Min           -1.3652942
Z mean eval                  0.016826782
Z variance eval              0.0052619926
total_rewards                [1362.80622581 3311.45895055 1362.47559117  957.3817083   990.18038657
 3365.04931718 3424.3396708  1047.88059943 1085.61185849 3427.97266588]
total_rewards_mean           2033.5156974187207
total_rewards_std            1109.1338732418747
total_rewards_max            3427.972665878029
total_rewards_min            957.3817083026677
Number of train steps total  269000
Number of env steps total    1347000
Number of rollouts total     0
Train Time (s)               44.183652066625655
(Previous) Eval Time (s)     31.3587094983086
Sample Time (s)              22.039780049119145
Epoch Time (s)               97.5821416140534
Total Train Time (s)         21509.137973512523
Epoch                        268
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:46:49.167853 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #268 | Epoch Duration: 85.92237949371338
2020-01-11 06:46:49.167987 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #268 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017023476
Z variance train             0.005262524
KL Divergence                10.789046
KL Loss                      1.0789046
QF Loss                      97.167175
VF Loss                      84.06088
Policy Loss                  -1472.1896
Q Predictions Mean           1473.0629
Q Predictions Std            200.35518
Q Predictions Max            1637.2904
Q Predictions Min            2.3054092
V Predictions Mean           1479.2195
V Predictions Std            202.13666
V Predictions Max            1643.8143
V Predictions Min            0.5444301
Log Pis Mean                 -0.728395
Log Pis Std                  1.662596
Log Pis Max                  6.3108563
Log Pis Min                  -5.4439383
Policy mu Mean               0.09694034
Policy mu Std                0.7855488
Policy mu Max                1.6245056
Policy mu Min                -2.655982
Policy log std Mean          -0.41968477
Policy log std Std           0.18784916
Policy log std Max           0.035334706
Policy log std Min           -1.4489859
Z mean eval                  0.012929318
Z variance eval              0.0047602104
total_rewards                [3337.06934571 1151.69548439  987.1576736  3382.59015184 1086.74586229
 3444.58539722 3367.36912233 3416.81309773 3365.40160386 3391.6328748 ]
total_rewards_mean           2693.106061376374
total_rewards_std            1060.174576565406
total_rewards_max            3444.5853972231525
total_rewards_min            987.1576735960609
Number of train steps total  270000
Number of env steps total    1352000
Number of rollouts total     0
Train Time (s)               43.51119574997574
(Previous) Eval Time (s)     19.698722107801586
Sample Time (s)              21.440875311847776
Epoch Time (s)               84.6507931696251
Total Train Time (s)         21599.699998619035
Epoch                        269
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:48:19.731993 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #269 | Epoch Duration: 90.56390285491943
2020-01-11 06:48:19.732119 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #269 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012937373
Z variance train             0.0047616013
KL Divergence                10.995122
KL Loss                      1.0995122
QF Loss                      73.48664
VF Loss                      39.27158
Policy Loss                  -1456.9725
Q Predictions Mean           1456.2517
Q Predictions Std            237.32379
Q Predictions Max            1658.7488
Q Predictions Min            18.555433
V Predictions Mean           1454.0591
V Predictions Std            238.00772
V Predictions Max            1655.9427
V Predictions Min            3.6765707
Log Pis Mean                 -0.62011576
Log Pis Std                  1.7796404
Log Pis Max                  5.133111
Log Pis Min                  -5.815795
Policy mu Mean               0.15040495
Policy mu Std                0.7758908
Policy mu Max                2.1067092
Policy mu Min                -2.9490764
Policy log std Mean          -0.44177127
Policy log std Std           0.19858535
Policy log std Max           0.014966726
Policy log std Min           -1.2624927
Z mean eval                  0.013202605
Z variance eval              0.0047769914
total_rewards                [3261.77655883 2714.06257633 3262.47858638 1585.52681007 1511.13674053
 3250.22407777 3298.27302028 3255.59120996 3233.52839642 3247.70195939]
total_rewards_mean           2862.029993596247
total_rewards_std            676.6883102311872
total_rewards_max            3298.2730202774183
total_rewards_min            1511.1367405310177
Number of train steps total  271000
Number of env steps total    1357000
Number of rollouts total     0
Train Time (s)               43.94731139112264
(Previous) Eval Time (s)     25.61158533813432
Sample Time (s)              21.52877441002056
Epoch Time (s)               91.08767113927752
Total Train Time (s)         21694.335006531794
Epoch                        270
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:49:54.368836 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #270 | Epoch Duration: 94.63662195205688
2020-01-11 06:49:54.368957 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #270 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013207285
Z variance train             0.0047771065
KL Divergence                10.98196
KL Loss                      1.098196
QF Loss                      45.836845
VF Loss                      25.47816
Policy Loss                  -1486.4738
Q Predictions Mean           1485.1953
Q Predictions Std            164.89333
Q Predictions Max            1650.0881
Q Predictions Min            8.177234
V Predictions Mean           1485.1898
V Predictions Std            163.71469
V Predictions Max            1651.9303
V Predictions Min            6.2203097
Log Pis Mean                 -0.5438533
Log Pis Std                  1.6791495
Log Pis Max                  5.012432
Log Pis Min                  -4.558217
Policy mu Mean               0.07216095
Policy mu Std                0.8116269
Policy mu Max                1.9282811
Policy mu Min                -3.2014108
Policy log std Mean          -0.44280818
Policy log std Std           0.1921539
Policy log std Max           0.018708944
Policy log std Min           -1.3209087
Z mean eval                  0.03416139
Z variance eval              0.0051768287
total_rewards                [1303.72473609 3463.75599612 3426.95646512 1339.36177264 3374.7790661
 2719.59195764 3348.33022072 1819.13278869 3362.50237469 3401.46292516]
total_rewards_mean           2755.959830298621
total_rewards_std            863.9632098555235
total_rewards_max            3463.7559961226443
total_rewards_min            1303.7247360936315
Number of train steps total  272000
Number of env steps total    1362000
Number of rollouts total     0
Train Time (s)               43.41793708782643
(Previous) Eval Time (s)     29.160305257886648
Sample Time (s)              22.689532468561083
Epoch Time (s)               95.26777481427416
Total Train Time (s)         21786.530710527673
Epoch                        271
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:51:26.566737 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #271 | Epoch Duration: 92.1976866722107
2020-01-11 06:51:26.566863 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #271 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032638945
Z variance train             0.00517345
KL Divergence                10.796337
KL Loss                      1.0796337
QF Loss                      240.5978
VF Loss                      97.20588
Policy Loss                  -1456.6483
Q Predictions Mean           1454.8159
Q Predictions Std            257.81866
Q Predictions Max            1668.6678
Q Predictions Min            -3.2106051
V Predictions Mean           1462.7578
V Predictions Std            256.8732
V Predictions Max            1679.9702
V Predictions Min            3.9423223
Log Pis Mean                 -0.4554103
Log Pis Std                  1.8814453
Log Pis Max                  6.3049946
Log Pis Min                  -4.120413
Policy mu Mean               0.05989404
Policy mu Std                0.82299554
Policy mu Max                2.3878117
Policy mu Min                -2.8004568
Policy log std Mean          -0.4254149
Policy log std Std           0.19635835
Policy log std Max           0.11341819
Policy log std Min           -1.2454611
Z mean eval                  0.021477278
Z variance eval              0.004452334
total_rewards                [3306.49766396 3297.04713257 3293.61400521 3311.05599319 3263.10000012
 1914.44927012 3345.56210446 1000.15719925 3269.3130141  1257.19076699]
total_rewards_mean           2725.798714995712
total_rewards_std            899.4231095634442
total_rewards_max            3345.5621044606337
total_rewards_min            1000.1571992457625
Number of train steps total  273000
Number of env steps total    1367000
Number of rollouts total     0
Train Time (s)               43.835896912030876
(Previous) Eval Time (s)     26.089960461948067
Sample Time (s)              21.742079886607826
Epoch Time (s)               91.66793726058677
Total Train Time (s)         21879.42868444929
Epoch                        272
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:52:59.467343 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #272 | Epoch Duration: 92.900386095047
2020-01-11 06:52:59.467467 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #272 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021744521
Z variance train             0.004444836
KL Divergence                11.111997
KL Loss                      1.1111997
QF Loss                      480.70053
VF Loss                      279.95813
Policy Loss                  -1511.2736
Q Predictions Mean           1511.0051
Q Predictions Std            147.58992
Q Predictions Max            1678.6521
Q Predictions Min            94.9588
V Predictions Mean           1514.958
V Predictions Std            146.76006
V Predictions Max            1675.2958
V Predictions Min            93.13618
Log Pis Mean                 -0.494682
Log Pis Std                  1.5854523
Log Pis Max                  4.67634
Log Pis Min                  -4.649681
Policy mu Mean               0.088216834
Policy mu Std                0.77203953
Policy mu Max                2.0527198
Policy mu Min                -2.5070183
Policy log std Mean          -0.4430212
Policy log std Std           0.19552775
Policy log std Max           0.0074127913
Policy log std Min           -1.2535753
Z mean eval                  0.026267001
Z variance eval              0.004203904
total_rewards                [3191.09151382 3273.74815763 3209.18545769 3222.03674433 3183.25610206
 3191.57836355 3185.12852123 3248.85578763 3303.31864616 3228.10852205]
total_rewards_mean           3223.6307816154685
total_rewards_std            38.636985929035006
total_rewards_max            3303.3186461574646
total_rewards_min            3183.256102058096
Number of train steps total  274000
Number of env steps total    1372000
Number of rollouts total     0
Train Time (s)               44.71226417878643
(Previous) Eval Time (s)     27.32217744877562
Sample Time (s)              21.86613728106022
Epoch Time (s)               93.90057890862226
Total Train Time (s)         21979.020857186057
Epoch                        273
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:54:39.062108 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #273 | Epoch Duration: 99.5945303440094
2020-01-11 06:54:39.062289 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #273 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026425999
Z variance train             0.0042034667
KL Divergence                11.344856
KL Loss                      1.1344856
QF Loss                      151.41504
VF Loss                      44.824837
Policy Loss                  -1509.6857
Q Predictions Mean           1513.4583
Q Predictions Std            137.68369
Q Predictions Max            1665.392
Q Predictions Min            380.4723
V Predictions Mean           1508.7537
V Predictions Std            137.10678
V Predictions Max            1662.5072
V Predictions Min            362.12805
Log Pis Mean                 -0.5151319
Log Pis Std                  1.7754018
Log Pis Max                  5.138869
Log Pis Min                  -5.067999
Policy mu Mean               -0.0021039844
Policy mu Std                0.80799294
Policy mu Max                1.9625465
Policy mu Min                -2.9279282
Policy log std Mean          -0.44860697
Policy log std Std           0.19242766
Policy log std Max           0.004390478
Policy log std Min           -1.1943555
Z mean eval                  0.050694477
Z variance eval              0.0048032342
total_rewards                [3064.22698961 3123.64474089 3109.00834116 3132.8542753  3155.57629174
 3144.44484815 1334.77437329 3178.0421974  3155.66467156 1042.32891433]
total_rewards_mean           2744.0565643428254
total_rewards_std            781.0459052281973
total_rewards_max            3178.042197399904
total_rewards_min            1042.3289143307202
Number of train steps total  275000
Number of env steps total    1377000
Number of rollouts total     0
Train Time (s)               44.7989703589119
(Previous) Eval Time (s)     33.015879821032286
Sample Time (s)              21.618271828163415
Epoch Time (s)               99.4331220081076
Total Train Time (s)         22074.527585833333
Epoch                        274
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:56:14.570612 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #274 | Epoch Duration: 95.50819301605225
2020-01-11 06:56:14.570746 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #274 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.050330974
Z variance train             0.0048119887
KL Divergence                10.982243
KL Loss                      1.0982243
QF Loss                      137.00308
VF Loss                      128.02788
Policy Loss                  -1498.5743
Q Predictions Mean           1496.1902
Q Predictions Std            144.87459
Q Predictions Max            1659.728
Q Predictions Min            517.47314
V Predictions Mean           1495.6667
V Predictions Std            143.88466
V Predictions Max            1668.1658
V Predictions Min            553.1673
Log Pis Mean                 -0.78444123
Log Pis Std                  1.5985321
Log Pis Max                  4.944596
Log Pis Min                  -4.7099953
Policy mu Mean               0.068770505
Policy mu Std                0.7279713
Policy mu Max                1.8974974
Policy mu Min                -2.6252015
Policy log std Mean          -0.42741546
Policy log std Std           0.1975298
Policy log std Max           0.06066844
Policy log std Min           -1.1476007
Z mean eval                  0.021641113
Z variance eval              0.004869555
total_rewards                [3138.15995662 3174.9700754  3082.76553577 3093.33058638 3041.13922284
 3201.0750591  3204.33582666 1690.13190266 3109.5824969  3037.26335892]
total_rewards_mean           2977.275402125535
total_rewards_std            432.7964208229372
total_rewards_max            3204.3358266649716
total_rewards_min            1690.1319026558344
Number of train steps total  276000
Number of env steps total    1382000
Number of rollouts total     0
Train Time (s)               44.27378379786387
(Previous) Eval Time (s)     29.090723481960595
Sample Time (s)              21.92662231437862
Epoch Time (s)               95.29112959420308
Total Train Time (s)         22172.73103248235
Epoch                        275
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:57:52.779560 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #275 | Epoch Duration: 98.20870018005371
2020-01-11 06:57:52.779739 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #275 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021751642
Z variance train             0.0048675705
KL Divergence                11.02273
KL Loss                      1.102273
QF Loss                      46.266304
VF Loss                      34.58193
Policy Loss                  -1511.4856
Q Predictions Mean           1513.1755
Q Predictions Std            126.86537
Q Predictions Max            1681.4523
Q Predictions Min            757.12274
V Predictions Mean           1510.9833
V Predictions Std            124.971115
V Predictions Max            1677.0437
V Predictions Min            769.77374
Log Pis Mean                 -0.60784554
Log Pis Std                  1.771025
Log Pis Max                  7.3548436
Log Pis Min                  -5.655115
Policy mu Mean               0.102875106
Policy mu Std                0.7651342
Policy mu Max                2.226178
Policy mu Min                -2.5981467
Policy log std Mean          -0.43560386
Policy log std Std           0.19429748
Policy log std Max           0.038250685
Policy log std Min           -1.2444232
Z mean eval                  0.027347663
Z variance eval              0.004354815
total_rewards                [3197.27432081 3229.14368743 3144.21120012 2364.37464817 3273.88577115
 3208.99609981 3251.00707334 3273.45427296 3265.00871605 2147.00027969]
total_rewards_mean           3035.435606953106
total_rewards_std            394.71462361351905
total_rewards_max            3273.8857711511787
total_rewards_min            2147.000279692314
Number of train steps total  277000
Number of env steps total    1387000
Number of rollouts total     0
Train Time (s)               43.233756312169135
(Previous) Eval Time (s)     32.008037510793656
Sample Time (s)              21.824417354073375
Epoch Time (s)               97.06621117703617
Total Train Time (s)         22268.71806315705
Epoch                        276
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:59:28.769561 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #276 | Epoch Duration: 95.98969316482544
2020-01-11 06:59:28.769695 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #276 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028227663
Z variance train             0.0043624016
KL Divergence                11.303044
KL Loss                      1.1303045
QF Loss                      182.1453
VF Loss                      304.72586
Policy Loss                  -1507.4941
Q Predictions Mean           1511.9272
Q Predictions Std            161.71373
Q Predictions Max            1685.17
Q Predictions Min            105.26023
V Predictions Mean           1508.1807
V Predictions Std            161.05403
V Predictions Max            1671.3588
V Predictions Min            116.011894
Log Pis Mean                 -0.54206276
Log Pis Std                  1.765371
Log Pis Max                  7.0109143
Log Pis Min                  -4.920697
Policy mu Mean               0.108538866
Policy mu Std                0.77917176
Policy mu Max                2.1533244
Policy mu Min                -2.8777306
Policy log std Mean          -0.43045983
Policy log std Std           0.18985294
Policy log std Max           0.0010730624
Policy log std Min           -1.1494892
Z mean eval                  0.029621596
Z variance eval              0.004591116
total_rewards                [3313.4685075  3303.4044466  1912.69435453 3317.18115772 3339.06455034
 3328.37523327 3316.90019811 3307.70364625 1333.72288568 3318.42129424]
total_rewards_mean           2979.093627425817
total_rewards_std            690.2577292362494
total_rewards_max            3339.064550342891
total_rewards_min            1333.722885679505
Number of train steps total  278000
Number of env steps total    1392000
Number of rollouts total     0
Train Time (s)               43.98422539187595
(Previous) Eval Time (s)     30.931284696795046
Sample Time (s)              21.849338602740318
Epoch Time (s)               96.76484869141132
Total Train Time (s)         22362.614640902728
Epoch                        277
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:01:02.673793 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #277 | Epoch Duration: 93.90394997596741
2020-01-11 07:01:02.674097 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #277 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031533815
Z variance train             0.0045954175
KL Divergence                11.157186
KL Loss                      1.1157186
QF Loss                      344.8002
VF Loss                      352.31348
Policy Loss                  -1523.9907
Q Predictions Mean           1528.273
Q Predictions Std            124.605125
Q Predictions Max            1684.0117
Q Predictions Min            708.3514
V Predictions Mean           1514.4569
V Predictions Std            130.74684
V Predictions Max            1678.9779
V Predictions Min            621.08813
Log Pis Mean                 -0.46756572
Log Pis Std                  1.8391149
Log Pis Max                  8.811759
Log Pis Min                  -5.36807
Policy mu Mean               0.13297747
Policy mu Std                0.8003665
Policy mu Max                3.5524206
Policy mu Min                -2.9202876
Policy log std Mean          -0.44344175
Policy log std Std           0.19297901
Policy log std Max           0.017428845
Policy log std Min           -1.3958501
Z mean eval                  0.029218873
Z variance eval              0.0044524632
total_rewards                [3211.86828344 1835.25471397 2883.36139044 3168.25132929 3138.33412513
 3208.77022281 3279.77508118 3233.73190748 3118.59615274 3192.52001466]
total_rewards_mean           3027.0463221147484
total_rewards_std            410.2283304113844
total_rewards_max            3279.7750811812257
total_rewards_min            1835.254713972931
Number of train steps total  279000
Number of env steps total    1397000
Number of rollouts total     0
Train Time (s)               44.41893255384639
(Previous) Eval Time (s)     28.070121795870364
Sample Time (s)              22.008371042087674
Epoch Time (s)               94.49742539180443
Total Train Time (s)         22459.027226075996
Epoch                        278
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:02:39.087177 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #278 | Epoch Duration: 96.41285586357117
2020-01-11 07:02:39.087320 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #278 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028714776
Z variance train             0.004460813
KL Divergence                11.168061
KL Loss                      1.1168061
QF Loss                      54.19204
VF Loss                      75.4727
Policy Loss                  -1521.4575
Q Predictions Mean           1521.903
Q Predictions Std            168.02924
Q Predictions Max            1676.8583
Q Predictions Min            -6.87757
V Predictions Mean           1524.8951
V Predictions Std            167.1202
V Predictions Max            1686.6627
V Predictions Min            -1.7407877
Log Pis Mean                 -0.6247946
Log Pis Std                  1.6198714
Log Pis Max                  5.271737
Log Pis Min                  -7.1238165
Policy mu Mean               0.043267775
Policy mu Std                0.755138
Policy mu Max                1.8695371
Policy mu Min                -2.9661791
Policy log std Mean          -0.41593918
Policy log std Std           0.18130393
Policy log std Max           0.044557363
Policy log std Min           -1.2032146
Z mean eval                  0.038847614
Z variance eval              0.0046434244
total_rewards                [3184.43704616 3151.9523966  3232.13343079 3151.28997129 3203.74498333
 3229.99810288 3173.06628218 3101.34915813 3172.93428446 3228.40645206]
total_rewards_mean           3182.9312107879514
total_rewards_std            39.94167078972027
total_rewards_max            3232.1334307945262
total_rewards_min            3101.349158128717
Number of train steps total  280000
Number of env steps total    1402000
Number of rollouts total     0
Train Time (s)               43.59146991511807
(Previous) Eval Time (s)     29.985338758677244
Sample Time (s)              21.830810349434614
Epoch Time (s)               95.40761902322993
Total Train Time (s)         22558.125967681408
Epoch                        279
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:04:18.192786 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #279 | Epoch Duration: 99.10531234741211
2020-01-11 07:04:18.193082 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #279 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039326932
Z variance train             0.0046445513
KL Divergence                11.105675
KL Loss                      1.1105675
QF Loss                      78.7981
VF Loss                      59.222145
Policy Loss                  -1518.5375
Q Predictions Mean           1517.3025
Q Predictions Std            130.46388
Q Predictions Max            1675.8357
Q Predictions Min            706.5446
V Predictions Mean           1521.4586
V Predictions Std            129.6013
V Predictions Max            1684.5258
V Predictions Min            722.1835
Log Pis Mean                 -0.62839377
Log Pis Std                  1.6320002
Log Pis Max                  6.053006
Log Pis Min                  -4.454299
Policy mu Mean               0.02758503
Policy mu Std                0.7599392
Policy mu Max                2.3146372
Policy mu Min                -3.1311193
Policy log std Mean          -0.4239039
Policy log std Std           0.19780163
Policy log std Max           0.00042364
Policy log std Min           -1.5002031
Z mean eval                  0.019772414
Z variance eval              0.004570001
total_rewards                [1726.37191204 1560.10136623  744.14832246 2300.9215041  1239.52015833
 1854.08340301 2767.5244265  1022.0813136  2624.71215111  440.24009054]
total_rewards_mean           1627.9704647920405
total_rewards_std            742.9802667451501
total_rewards_max            2767.5244264983166
total_rewards_min            440.24009053794583
Number of train steps total  281000
Number of env steps total    1407000
Number of rollouts total     0
Train Time (s)               43.97527243522927
(Previous) Eval Time (s)     33.682775063905865
Sample Time (s)              22.41758856596425
Epoch Time (s)               100.07563606509939
Total Train Time (s)         22639.980876394548
Epoch                        280
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:05:40.049574 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #280 | Epoch Duration: 81.856276512146
2020-01-11 07:05:40.049744 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #280 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018816432
Z variance train             0.004570866
KL Divergence                11.182676
KL Loss                      1.1182677
QF Loss                      1050.4155
VF Loss                      1395.7574
Policy Loss                  -1516.7438
Q Predictions Mean           1523.1466
Q Predictions Std            122.167046
Q Predictions Max            1664.8344
Q Predictions Min            718.8879
V Predictions Mean           1526.5864
V Predictions Std            118.66605
V Predictions Max            1703.5149
V Predictions Min            1017.4172
Log Pis Mean                 -0.4670911
Log Pis Std                  1.7678791
Log Pis Max                  6.285914
Log Pis Min                  -4.4392595
Policy mu Mean               0.14327587
Policy mu Std                0.8038487
Policy mu Max                2.4732437
Policy mu Min                -2.8762717
Policy log std Mean          -0.42008552
Policy log std Std           0.18106319
Policy log std Max           -0.0068576634
Policy log std Min           -1.0562071
Z mean eval                  0.028027494
Z variance eval              0.0043388
total_rewards                [1123.31059148 3093.29888327 1130.5980779   865.61592193 3041.34729072
  635.3771598  2176.94175607  365.01689485 3050.83203838 2354.72838063]
total_rewards_mean           1783.7066995023445
total_rewards_std            1020.7793003133918
total_rewards_max            3093.2988832735423
total_rewards_min            365.0168948494455
Number of train steps total  282000
Number of env steps total    1412000
Number of rollouts total     0
Train Time (s)               42.9883788228035
(Previous) Eval Time (s)     15.463199658319354
Sample Time (s)              21.04810159187764
Epoch Time (s)               79.49968007300049
Total Train Time (s)         22721.85600776039
Epoch                        281
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:07:01.930213 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #281 | Epoch Duration: 81.88029670715332
2020-01-11 07:07:01.930478 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #281 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027472382
Z variance train             0.004336315
KL Divergence                11.352103
KL Loss                      1.1352104
QF Loss                      184.0552
VF Loss                      103.373856
Policy Loss                  -1517.321
Q Predictions Mean           1516.1873
Q Predictions Std            132.45117
Q Predictions Max            1700.9286
Q Predictions Min            670.37103
V Predictions Mean           1519.9194
V Predictions Std            129.95659
V Predictions Max            1703.1166
V Predictions Min            715.3126
Log Pis Mean                 -0.30339712
Log Pis Std                  1.9864633
Log Pis Max                  7.973607
Log Pis Min                  -4.932067
Policy mu Mean               -0.27100924
Policy mu Std                0.82200986
Policy mu Max                2.6120992
Policy mu Min                -3.2307127
Policy log std Mean          -0.40238142
Policy log std Std           0.18299106
Policy log std Max           0.034197003
Policy log std Min           -0.9424566
Z mean eval                  0.039914913
Z variance eval              0.0045172954
total_rewards                [3119.22817312 3278.85632434 3311.41341755 3266.78768426 3140.54618226
 3256.75350532 3221.67762888 3244.83852684 2320.8687049  3203.27605405]
total_rewards_mean           3136.4246201522374
total_rewards_std            277.7258287431182
total_rewards_max            3311.4134175509407
total_rewards_min            2320.8687048963725
Number of train steps total  283000
Number of env steps total    1417000
Number of rollouts total     0
Train Time (s)               44.37683756602928
(Previous) Eval Time (s)     17.84357769601047
Sample Time (s)              22.006537460256368
Epoch Time (s)               84.22695272229612
Total Train Time (s)         22821.06245818548
Epoch                        282
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:08:41.143768 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #282 | Epoch Duration: 99.21307849884033
2020-01-11 07:08:41.144075 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #282 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039793458
Z variance train             0.0045153685
KL Divergence                11.24029
KL Loss                      1.124029
QF Loss                      36.364273
VF Loss                      17.363567
Policy Loss                  -1517.1879
Q Predictions Mean           1516.72
Q Predictions Std            122.778366
Q Predictions Max            1670.9468
Q Predictions Min            833.73676
V Predictions Mean           1517.0088
V Predictions Std            120.42352
V Predictions Max            1669.2009
V Predictions Min            850.7101
Log Pis Mean                 -0.71015054
Log Pis Std                  1.7161623
Log Pis Max                  7.1147547
Log Pis Min                  -6.589006
Policy mu Mean               -0.014751767
Policy mu Std                0.76747495
Policy mu Max                2.2392852
Policy mu Min                -3.0063663
Policy log std Mean          -0.4240799
Policy log std Std           0.1866967
Policy log std Max           0.08638227
Policy log std Min           -1.2684443
Z mean eval                  0.022773407
Z variance eval              0.004306172
total_rewards                [3232.14228451 3257.29073888 2206.38779713 3304.37629996 3238.27981053
 3255.1626356  3243.41290234 3225.4044236  3248.2826205  1336.59641376]
total_rewards_mean           2954.7335926811206
total_rewards_std            623.1020247977691
total_rewards_max            3304.376299961246
total_rewards_min            1336.596413756825
Number of train steps total  284000
Number of env steps total    1422000
Number of rollouts total     0
Train Time (s)               43.86513606226072
(Previous) Eval Time (s)     32.829406627919525
Sample Time (s)              22.415879981126636
Epoch Time (s)               99.11042267130688
Total Train Time (s)         22914.14950486552
Epoch                        283
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:10:14.233035 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #283 | Epoch Duration: 93.08874583244324
2020-01-11 07:10:14.233216 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #283 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022820324
Z variance train             0.0043008747
KL Divergence                11.329166
KL Loss                      1.1329167
QF Loss                      40.881397
VF Loss                      18.653194
Policy Loss                  -1521.8419
Q Predictions Mean           1521.0212
Q Predictions Std            114.50331
Q Predictions Max            1685.0576
Q Predictions Min            1045.7838
V Predictions Mean           1523.8127
V Predictions Std            115.134315
V Predictions Max            1688.079
V Predictions Min            1007.4201
Log Pis Mean                 -0.84952664
Log Pis Std                  1.4550484
Log Pis Max                  5.089741
Log Pis Min                  -4.536531
Policy mu Mean               0.11344079
Policy mu Std                0.6753585
Policy mu Max                1.6971319
Policy mu Min                -2.3827848
Policy log std Mean          -0.4178647
Policy log std Std           0.17182213
Policy log std Max           0.059737384
Policy log std Min           -1.3025763
Z mean eval                  0.046170443
Z variance eval              0.0041458732
total_rewards                [3244.84011414 3249.13203941 3183.63018247 3216.00439614 3044.33800724
 3136.84250118 3244.39938301 3177.77122465 3157.01856714 3231.20756701]
total_rewards_mean           3188.5183982391263
total_rewards_std            60.939886844493316
total_rewards_max            3249.1320394130216
total_rewards_min            3044.3380072406967
Number of train steps total  285000
Number of env steps total    1427000
Number of rollouts total     0
Train Time (s)               43.96281835483387
(Previous) Eval Time (s)     26.807513593230397
Sample Time (s)              21.464998981449753
Epoch Time (s)               92.23533092951402
Total Train Time (s)         23013.21830403665
Epoch                        284
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:11:53.309344 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #284 | Epoch Duration: 99.07593703269958
2020-01-11 07:11:53.309592 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #284 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045634452
Z variance train             0.004148136
KL Divergence                11.315095
KL Loss                      1.1315095
QF Loss                      84.37909
VF Loss                      64.63895
Policy Loss                  -1522.068
Q Predictions Mean           1525.2958
Q Predictions Std            162.97493
Q Predictions Max            1684.8925
Q Predictions Min            18.101473
V Predictions Mean           1527.1902
V Predictions Std            163.91505
V Predictions Max            1689.6874
V Predictions Min            9.9526825
Log Pis Mean                 -0.6564212
Log Pis Std                  1.8468214
Log Pis Max                  10.166983
Log Pis Min                  -5.111636
Policy mu Mean               0.06322018
Policy mu Std                0.7824611
Policy mu Max                2.4912446
Policy mu Min                -3.0700796
Policy log std Mean          -0.43550792
Policy log std Std           0.18525787
Policy log std Max           0.07113862
Policy log std Min           -1.0545325
Z mean eval                  0.05014505
Z variance eval              0.004858154
total_rewards                [3294.91683051 3223.86284045 1802.14716525 1825.50671993 3392.65547276
 3384.00560741 3352.69135894 3349.34193277 3396.69791663 1059.32386975]
total_rewards_mean           2808.1149714379094
total_rewards_std            839.9309752641107
total_rewards_max            3396.6979166288847
total_rewards_min            1059.3238697516863
Number of train steps total  286000
Number of env steps total    1432000
Number of rollouts total     0
Train Time (s)               44.04431908484548
(Previous) Eval Time (s)     33.6478740372695
Sample Time (s)              21.92311033140868
Epoch Time (s)               99.61530345352367
Total Train Time (s)         23105.627093941905
Epoch                        285
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:13:25.720620 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #285 | Epoch Duration: 92.41087317466736
2020-01-11 07:13:25.720793 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #285 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05009327
Z variance train             0.004858623
KL Divergence                10.959498
KL Loss                      1.0959499
QF Loss                      44.416435
VF Loss                      19.506975
Policy Loss                  -1532.2448
Q Predictions Mean           1529.8651
Q Predictions Std            122.93678
Q Predictions Max            1688.6173
Q Predictions Min            1014.6432
V Predictions Mean           1530.8982
V Predictions Std            121.15685
V Predictions Max            1688.554
V Predictions Min            1072.5219
Log Pis Mean                 -0.41300464
Log Pis Std                  1.8470259
Log Pis Max                  8.089981
Log Pis Min                  -3.673275
Policy mu Mean               0.019406395
Policy mu Std                0.8096004
Policy mu Max                1.817296
Policy mu Min                -3.1457267
Policy log std Mean          -0.42803457
Policy log std Std           0.18461074
Policy log std Max           0.010297209
Policy log std Min           -1.1812949
Z mean eval                  0.026731033
Z variance eval              0.004567216
total_rewards                [3303.30077954 3274.09121428 3205.14587551 3265.56674512 3278.525786
 3245.91881748 3254.15191085 3334.61793637 3310.70434235 3268.32618634]
total_rewards_mean           3274.0349593851556
total_rewards_std            34.53615401206838
total_rewards_max            3334.6179363692167
total_rewards_min            3205.145875506987
Number of train steps total  287000
Number of env steps total    1437000
Number of rollouts total     0
Train Time (s)               43.04860408697277
(Previous) Eval Time (s)     26.4431718387641
Sample Time (s)              23.77471812721342
Epoch Time (s)               93.26649405295029
Total Train Time (s)         23204.96417229157
Epoch                        286
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:15:05.060664 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #286 | Epoch Duration: 99.33969306945801
2020-01-11 07:15:05.060854 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #286 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026268655
Z variance train             0.0045681745
KL Divergence                11.033847
KL Loss                      1.1033847
QF Loss                      379.03082
VF Loss                      232.14679
Policy Loss                  -1532.9431
Q Predictions Mean           1529.8821
Q Predictions Std            118.513374
Q Predictions Max            1673.6847
Q Predictions Min            845.8714
V Predictions Mean           1535.584
V Predictions Std            118.88492
V Predictions Max            1679.893
V Predictions Min            836.56067
Log Pis Mean                 -0.33824998
Log Pis Std                  1.9726996
Log Pis Max                  8.192004
Log Pis Min                  -4.7654843
Policy mu Mean               -0.09451731
Policy mu Std                0.8461531
Policy mu Max                1.9401077
Policy mu Min                -3.0810409
Policy log std Mean          -0.44823197
Policy log std Std           0.18966085
Policy log std Max           0.05593553
Policy log std Min           -1.1229949
Z mean eval                  0.023316294
Z variance eval              0.004808181
total_rewards                [3200.70966783 3132.50900119 3128.62509449 3208.31104517 1254.53224296
 3270.61422281 3188.9786871  3258.2685241  1073.94341084  978.15151795]
total_rewards_mean           2569.464341444295
total_rewards_std            963.5373356504015
total_rewards_max            3270.614222809354
total_rewards_min            978.1515179547406
Number of train steps total  288000
Number of env steps total    1442000
Number of rollouts total     0
Train Time (s)               43.924869515933096
(Previous) Eval Time (s)     32.51612358028069
Sample Time (s)              21.936639957595617
Epoch Time (s)               98.3776330538094
Total Train Time (s)         23297.83800709108
Epoch                        287
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:16:37.938726 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #287 | Epoch Duration: 92.87772393226624
2020-01-11 07:16:37.938970 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #287 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023172002
Z variance train             0.004810477
KL Divergence                10.953286
KL Loss                      1.0953287
QF Loss                      36.947548
VF Loss                      25.666645
Policy Loss                  -1524.6367
Q Predictions Mean           1523.5925
Q Predictions Std            117.12126
Q Predictions Max            1702.9447
Q Predictions Min            1131.7701
V Predictions Mean           1522.6885
V Predictions Std            116.5302
V Predictions Max            1699.5431
V Predictions Min            1217.3951
Log Pis Mean                 -0.76452166
Log Pis Std                  1.7893819
Log Pis Max                  8.893698
Log Pis Min                  -4.160428
Policy mu Mean               0.014274771
Policy mu Std                0.7471501
Policy mu Max                2.6304076
Policy mu Min                -2.7548134
Policy log std Mean          -0.411661
Policy log std Std           0.17744808
Policy log std Max           0.056948364
Policy log std Min           -1.1676023
Z mean eval                  0.036087237
Z variance eval              0.0058313166
total_rewards                [3288.69827262 1242.81907719 3254.94951035 3350.8388364  3255.73805627
 3266.82421254 1112.6866096  3334.92589629 3263.58775173 3372.1999402 ]
total_rewards_mean           2874.3268163188436
total_rewards_std            849.7009321435629
total_rewards_max            3372.199940198853
total_rewards_min            1112.6866096023732
Number of train steps total  289000
Number of env steps total    1447000
Number of rollouts total     0
Train Time (s)               45.80986724188551
(Previous) Eval Time (s)     27.015941545832902
Sample Time (s)              19.9100030567497
Epoch Time (s)               92.73581184446812
Total Train Time (s)         23393.92447556043
Epoch                        288
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:18:14.026684 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #288 | Epoch Duration: 96.08754825592041
2020-01-11 07:18:14.026816 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #288 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035465974
Z variance train             0.00582352
KL Divergence                10.556123
KL Loss                      1.0556123
QF Loss                      23.499794
VF Loss                      12.21387
Policy Loss                  -1545.2545
Q Predictions Mean           1545.5728
Q Predictions Std            99.51869
Q Predictions Max            1694.1029
Q Predictions Min            1245.9946
V Predictions Mean           1547.3596
V Predictions Std            99.24941
V Predictions Max            1692.9868
V Predictions Min            1247.407
Log Pis Mean                 -0.73926777
Log Pis Std                  1.8172351
Log Pis Max                  4.8493853
Log Pis Min                  -6.671455
Policy mu Mean               0.05069208
Policy mu Std                0.7834593
Policy mu Max                1.6636577
Policy mu Min                -2.723181
Policy log std Mean          -0.41787055
Policy log std Std           0.16638052
Policy log std Max           -0.008393824
Policy log std Min           -1.1550366
Z mean eval                  0.017478412
Z variance eval              0.006187247
total_rewards                [3223.97150846 3313.60284803 1132.77605294  920.42311822  818.24699526
 1236.29587832  818.91842862  896.89918813 1018.22933475  881.84171845]
total_rewards_mean           1426.1205071180957
total_rewards_std            930.2454730452604
total_rewards_max            3313.6028480255623
total_rewards_min            818.2469952556714
Number of train steps total  290000
Number of env steps total    1452000
Number of rollouts total     0
Train Time (s)               44.22686819918454
(Previous) Eval Time (s)     30.36746515473351
Sample Time (s)              21.662118405103683
Epoch Time (s)               96.25645175902173
Total Train Time (s)         23473.545514662284
Epoch                        289
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:19:33.650265 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #289 | Epoch Duration: 79.62335658073425
2020-01-11 07:19:33.650385 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #289 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01805344
Z variance train             0.006187835
KL Divergence                10.417551
KL Loss                      1.0417551
QF Loss                      36.82899
VF Loss                      22.511496
Policy Loss                  -1546.3381
Q Predictions Mean           1548.2035
Q Predictions Std            114.98848
Q Predictions Max            1692.8232
Q Predictions Min            788.75275
V Predictions Mean           1544.1637
V Predictions Std            114.91525
V Predictions Max            1691.9935
V Predictions Min            770.26855
Log Pis Mean                 -0.80296475
Log Pis Std                  1.7173759
Log Pis Max                  5.922335
Log Pis Min                  -4.7471743
Policy mu Mean               0.009102295
Policy mu Std                0.76892537
Policy mu Max                1.7872101
Policy mu Min                -2.3357732
Policy log std Mean          -0.38756868
Policy log std Std           0.16448505
Policy log std Max           0.019429356
Policy log std Min           -1.1453272
Z mean eval                  0.02405211
Z variance eval              0.0065417513
total_rewards                [ 973.3777656   690.40625352 3176.97486574 1466.30712094 2055.67569881
 2573.23179781 3168.28030797 1595.40230699 3123.81370678  911.38069269]
total_rewards_mean           1973.4850516858883
total_rewards_std            934.8999082416393
total_rewards_max            3176.9748657411933
total_rewards_min            690.4062535243645
Number of train steps total  291000
Number of env steps total    1457000
Number of rollouts total     0
Train Time (s)               43.84922704799101
(Previous) Eval Time (s)     13.73413924407214
Sample Time (s)              21.569792446680367
Epoch Time (s)               79.15315873874351
Total Train Time (s)         23559.714456947986
Epoch                        290
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:20:59.822901 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #290 | Epoch Duration: 86.17241024971008
2020-01-11 07:20:59.823078 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #290 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024204463
Z variance train             0.0065389336
KL Divergence                10.260991
KL Loss                      1.0260991
QF Loss                      59.1594
VF Loss                      89.82514
Policy Loss                  -1541.3102
Q Predictions Mean           1543.8677
Q Predictions Std            118.66726
Q Predictions Max            1718.5309
Q Predictions Min            993.9649
V Predictions Mean           1548.9417
V Predictions Std            118.52272
V Predictions Max            1728.1089
V Predictions Min            999.79254
Log Pis Mean                 -0.57868385
Log Pis Std                  1.9122604
Log Pis Max                  6.074005
Log Pis Min                  -5.1733913
Policy mu Mean               0.0050852727
Policy mu Std                0.8356753
Policy mu Max                2.0162163
Policy mu Min                -3.0475273
Policy log std Mean          -0.4103181
Policy log std Std           0.18207572
Policy log std Max           -0.011924863
Policy log std Min           -1.2525059
Z mean eval                  0.02311647
Z variance eval              0.006376679
total_rewards                [3203.69922669 3267.98867567 1233.86321492 3232.09054161 3049.50261131
 3284.97115357 3285.84702905 1769.45768368 1007.32686676 1041.80008842]
total_rewards_mean           2437.654709167959
total_rewards_std            980.254523067213
total_rewards_max            3285.8470290491746
total_rewards_min            1007.3268667635042
Number of train steps total  292000
Number of env steps total    1462000
Number of rollouts total     0
Train Time (s)               43.02243333496153
(Previous) Eval Time (s)     20.75314630800858
Sample Time (s)              21.82651406340301
Epoch Time (s)               85.60209370637313
Total Train Time (s)         23648.519383948762
Epoch                        291
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:22:28.629959 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #291 | Epoch Duration: 88.80675053596497
2020-01-11 07:22:28.630091 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #291 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022903357
Z variance train             0.0063771144
KL Divergence                10.374627
KL Loss                      1.0374627
QF Loss                      73.23422
VF Loss                      82.834946
Policy Loss                  -1531.8359
Q Predictions Mean           1530.076
Q Predictions Std            122.358475
Q Predictions Max            1676.963
Q Predictions Min            848.2191
V Predictions Mean           1539.6671
V Predictions Std            120.682884
V Predictions Max            1687.306
V Predictions Min            863.5173
Log Pis Mean                 -0.73269004
Log Pis Std                  1.6980205
Log Pis Max                  6.457573
Log Pis Min                  -4.0107346
Policy mu Mean               0.0025295664
Policy mu Std                0.74675894
Policy mu Max                1.892344
Policy mu Min                -2.7388306
Policy log std Mean          -0.39680266
Policy log std Std           0.171835
Policy log std Max           -0.022314072
Policy log std Min           -1.0241936
Z mean eval                  0.01204622
Z variance eval              0.0058208564
total_rewards                [3237.1468537  2600.87025561 1037.7743417  2632.6791531  2054.22839124
 3327.99984437 1151.88329927  792.6849037   945.03937718 2078.30283075]
total_rewards_mean           1985.8609250613008
total_rewards_std            909.8488132348169
total_rewards_max            3327.9998443714603
total_rewards_min            792.6849036950623
Number of train steps total  293000
Number of env steps total    1467000
Number of rollouts total     0
Train Time (s)               44.44435120001435
(Previous) Eval Time (s)     23.9575587650761
Sample Time (s)              21.84194660000503
Epoch Time (s)               90.24385656509548
Total Train Time (s)         23735.146352713928
Epoch                        292
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:23:55.258414 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #292 | Epoch Duration: 86.62822842597961
2020-01-11 07:23:55.258534 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #292 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012318188
Z variance train             0.005820183
KL Divergence                10.514395
KL Loss                      1.0514395
QF Loss                      157.8072
VF Loss                      118.98584
Policy Loss                  -1537.806
Q Predictions Mean           1537.3452
Q Predictions Std            128.06454
Q Predictions Max            1685.1567
Q Predictions Min            758.87714
V Predictions Mean           1537.6672
V Predictions Std            123.979385
V Predictions Max            1686.2188
V Predictions Min            773.05566
Log Pis Mean                 -0.56728846
Log Pis Std                  1.730212
Log Pis Max                  4.4876065
Log Pis Min                  -4.2621307
Policy mu Mean               -0.019481141
Policy mu Std                0.79035056
Policy mu Max                1.798464
Policy mu Min                -2.7653587
Policy log std Mean          -0.4016261
Policy log std Std           0.16603214
Policy log std Max           -0.02565609
Policy log std Min           -1.085077
Z mean eval                  0.040942423
Z variance eval              0.006093584
total_rewards                [ 846.94779462 1782.57378859  682.64820177 1363.77631201  720.45840665
  696.50193424  624.02709891 1007.06066492  641.10747139 1610.81427801]
total_rewards_mean           997.5915951108138
total_rewards_std            410.16972828655025
total_rewards_max            1782.5737885902904
total_rewards_min            624.027098914726
Number of train steps total  294000
Number of env steps total    1472000
Number of rollouts total     0
Train Time (s)               45.03676827484742
(Previous) Eval Time (s)     20.341685181949288
Sample Time (s)              22.150808694772422
Epoch Time (s)               87.52926215156913
Total Train Time (s)         23812.59217205504
Epoch                        293
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:25:12.706252 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #293 | Epoch Duration: 77.44762969017029
2020-01-11 07:25:12.706369 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #293 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.041598305
Z variance train             0.0060897493
KL Divergence                10.49053
KL Loss                      1.0490531
QF Loss                      73.87686
VF Loss                      83.86083
Policy Loss                  -1548.5515
Q Predictions Mean           1548.8846
Q Predictions Std            124.98568
Q Predictions Max            1701.9313
Q Predictions Min            789.2655
V Predictions Mean           1547.4811
V Predictions Std            122.87155
V Predictions Max            1711.7582
V Predictions Min            781.1787
Log Pis Mean                 -0.7177332
Log Pis Std                  1.8881764
Log Pis Max                  5.773047
Log Pis Min                  -5.4603777
Policy mu Mean               0.22139484
Policy mu Std                0.7738821
Policy mu Max                2.047459
Policy mu Min                -3.0059953
Policy log std Mean          -0.41270685
Policy log std Std           0.164828
Policy log std Max           0.11971688
Policy log std Min           -1.0560999
Z mean eval                  0.040184982
Z variance eval              0.005993829
total_rewards                [3316.12223143  461.67420952  729.9563326  3267.50613789 3387.79365053
 3317.12013342 3358.00509578 3322.63358544 3325.94829525 1312.48391091]
total_rewards_mean           2579.924358277628
total_rewards_std            1159.319431278269
total_rewards_max            3387.793650534006
total_rewards_min            461.67420952399186
Number of train steps total  295000
Number of env steps total    1477000
Number of rollouts total     0
Train Time (s)               43.46970587223768
(Previous) Eval Time (s)     10.259815887082368
Sample Time (s)              22.101524721365422
Epoch Time (s)               75.83104648068547
Total Train Time (s)         23903.780172855128
Epoch                        294
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:26:43.900471 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #294 | Epoch Duration: 91.19399213790894
2020-01-11 07:26:43.900663 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #294 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039715335
Z variance train             0.0059901765
KL Divergence                10.717698
KL Loss                      1.0717698
QF Loss                      303.91507
VF Loss                      267.82373
Policy Loss                  -1544.1919
Q Predictions Mean           1549.1068
Q Predictions Std            119.41295
Q Predictions Max            1715.8972
Q Predictions Min            1175.0581
V Predictions Mean           1547.6077
V Predictions Std            117.72145
V Predictions Max            1693.1829
V Predictions Min            1147.5942
Log Pis Mean                 -0.79851794
Log Pis Std                  1.7628379
Log Pis Max                  6.1692324
Log Pis Min                  -5.420769
Policy mu Mean               0.05628584
Policy mu Std                0.76577896
Policy mu Max                2.2958705
Policy mu Min                -2.4558456
Policy log std Mean          -0.3913809
Policy log std Std           0.16559133
Policy log std Max           0.097485006
Policy log std Min           -0.98645085
Z mean eval                  0.03850142
Z variance eval              0.0060333675
total_rewards                [ 903.23882662 3358.32991915 1547.56439029 3358.65324541 3379.0652872
 3362.637279   3422.50250538  790.99879749  655.77093673 3383.55875316]
total_rewards_mean           2416.2319940424504
total_rewards_std            1197.1247402929666
total_rewards_max            3422.5025053796558
total_rewards_min            655.7709367259056
Number of train steps total  296000
Number of env steps total    1482000
Number of rollouts total     0
Train Time (s)               44.13829726027325
(Previous) Eval Time (s)     25.622532341163605
Sample Time (s)              22.072213164065033
Epoch Time (s)               91.83304276550189
Total Train Time (s)         23992.61141707655
Epoch                        295
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:28:12.736902 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #295 | Epoch Duration: 88.83609318733215
2020-01-11 07:28:12.737072 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #295 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036130127
Z variance train             0.0060348464
KL Divergence                10.593413
KL Loss                      1.0593413
QF Loss                      131.05492
VF Loss                      359.5479
Policy Loss                  -1556.6317
Q Predictions Mean           1559.5781
Q Predictions Std            116.57127
Q Predictions Max            1695.4941
Q Predictions Min            1038.4824
V Predictions Mean           1567.721
V Predictions Std            118.01111
V Predictions Max            1718.7279
V Predictions Min            1013.7829
Log Pis Mean                 -0.6846751
Log Pis Std                  1.795592
Log Pis Max                  8.325117
Log Pis Min                  -3.9478722
Policy mu Mean               -0.05958395
Policy mu Std                0.758005
Policy mu Max                1.7504185
Policy mu Min                -3.2262735
Policy log std Mean          -0.40259477
Policy log std Std           0.15634641
Policy log std Max           0.08113438
Policy log std Min           -1.0997285
Z mean eval                  0.030911064
Z variance eval              0.0062564746
total_rewards                [3224.52577906  795.11704569 3249.76958244  995.65869448 3205.02873011
  793.02086803 2912.92879336 2988.87536076 3274.1994273  3337.49223284]
total_rewards_mean           2477.6616514073776
total_rewards_std            1066.4380540748343
total_rewards_max            3337.492232840513
total_rewards_min            793.0208680327314
Number of train steps total  297000
Number of env steps total    1487000
Number of rollouts total     0
Train Time (s)               44.42758700391278
(Previous) Eval Time (s)     22.62534489808604
Sample Time (s)              21.877392067108303
Epoch Time (s)               88.93032396910712
Total Train Time (s)         24083.384016295895
Epoch                        296
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:29:43.512542 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #296 | Epoch Duration: 90.77532362937927
2020-01-11 07:29:43.512758 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #296 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030865857
Z variance train             0.006252583
KL Divergence                10.477173
KL Loss                      1.0477173
QF Loss                      47.309853
VF Loss                      24.568499
Policy Loss                  -1548.9152
Q Predictions Mean           1548.5566
Q Predictions Std            104.051125
Q Predictions Max            1672.483
Q Predictions Min            1248.3186
V Predictions Mean           1547.4745
V Predictions Std            103.92573
V Predictions Max            1677.439
V Predictions Min            1242.9225
Log Pis Mean                 -0.5666536
Log Pis Std                  1.8718437
Log Pis Max                  6.0033894
Log Pis Min                  -6.849199
Policy mu Mean               -0.13274415
Policy mu Std                0.7764153
Policy mu Max                1.6150889
Policy mu Min                -2.7186172
Policy log std Mean          -0.38819584
Policy log std Std           0.15502892
Policy log std Max           0.037130684
Policy log std Min           -1.0992823
Z mean eval                  0.018364666
Z variance eval              0.0065234536
total_rewards                [1208.79270171 3327.16973976 1619.66867419  761.25489139  969.81863171
 1755.39249337 3430.14549748 1774.23945796 1075.08080738 1328.60389494]
total_rewards_mean           1725.0166789891603
total_rewards_std            885.0994459997163
total_rewards_max            3430.145497481613
total_rewards_min            761.2548913871022
Number of train steps total  298000
Number of env steps total    1492000
Number of rollouts total     0
Train Time (s)               44.020033415872604
(Previous) Eval Time (s)     24.47010381007567
Sample Time (s)              21.39981493074447
Epoch Time (s)               89.88995215669274
Total Train Time (s)         24165.718071575742
Epoch                        297
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:31:05.853036 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #297 | Epoch Duration: 82.34008383750916
2020-01-11 07:31:05.853313 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #297 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018274507
Z variance train             0.0065211453
KL Divergence                10.426962
KL Loss                      1.0426962
QF Loss                      11349.09
VF Loss                      241.47664
Policy Loss                  -1555.9921
Q Predictions Mean           1562.4192
Q Predictions Std            111.17554
Q Predictions Max            1705.0525
Q Predictions Min            949.1948
V Predictions Mean           1558.5239
V Predictions Std            109.92905
V Predictions Max            1696.6377
V Predictions Min            897.1887
Log Pis Mean                 -0.79296845
Log Pis Std                  1.6453621
Log Pis Max                  6.212986
Log Pis Min                  -5.0863976
Policy mu Mean               -0.005906219
Policy mu Std                0.7273131
Policy mu Max                1.7683465
Policy mu Min                -2.7125661
Policy log std Mean          -0.415378
Policy log std Std           0.15301824
Policy log std Max           0.016662538
Policy log std Min           -1.0561749
Z mean eval                  0.03993323
Z variance eval              0.0057715713
total_rewards                [ 754.9077074  1020.64342633 1064.88762492 1681.46340691 1757.73395117
 1184.78368012 1208.0915758  2943.71498446 2923.96374131 1438.9878611 ]
total_rewards_mean           1597.9177959515425
total_rewards_std            726.5001630146774
total_rewards_max            2943.714984460461
total_rewards_min            754.9077073962555
Number of train steps total  299000
Number of env steps total    1497000
Number of rollouts total     0
Train Time (s)               43.89086322998628
(Previous) Eval Time (s)     16.919984650798142
Sample Time (s)              22.10019518667832
Epoch Time (s)               82.91104306746274
Total Train Time (s)         24247.047502167523
Epoch                        298
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:32:27.183640 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #298 | Epoch Duration: 81.33013486862183
2020-01-11 07:32:27.183771 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #298 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040057126
Z variance train             0.005774919
KL Divergence                10.772654
KL Loss                      1.0772654
QF Loss                      45.83883
VF Loss                      18.325546
Policy Loss                  -1586.4672
Q Predictions Mean           1586.1609
Q Predictions Std            105.8034
Q Predictions Max            1718.2731
Q Predictions Min            1280.1299
V Predictions Mean           1585.2543
V Predictions Std            104.87654
V Predictions Max            1709.6547
V Predictions Min            1281.4456
Log Pis Mean                 -0.99770695
Log Pis Std                  1.6106539
Log Pis Max                  8.818715
Log Pis Min                  -4.6163583
Policy mu Mean               -0.07657858
Policy mu Std                0.68225867
Policy mu Max                1.5236979
Policy mu Min                -2.6489432
Policy log std Mean          -0.38571405
Policy log std Std           0.1433622
Policy log std Max           0.0015033185
Policy log std Min           -0.99870557
Z mean eval                  0.016148208
Z variance eval              0.0057254224
total_rewards                [ 483.516982    482.16506049 1069.03900735  463.90595299  705.1953369
  483.21104601 1307.86979807  726.94116481 3422.68558605 1293.67188609]
total_rewards_mean           1043.8201820740337
total_rewards_std            853.6300743658771
total_rewards_max            3422.685586052966
total_rewards_min            463.9059529851414
Number of train steps total  300000
Number of env steps total    1502000
Number of rollouts total     0
Train Time (s)               43.69529428705573
(Previous) Eval Time (s)     15.338853489141911
Sample Time (s)              21.9742146381177
Epoch Time (s)               81.00836241431534
Total Train Time (s)         24322.17454737425
Epoch                        299
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:33:42.316265 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #299 | Epoch Duration: 75.13237738609314
2020-01-11 07:33:42.316445 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #299 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015861355
Z variance train             0.005726319
KL Divergence                10.68182
KL Loss                      1.068182
QF Loss                      81.396736
VF Loss                      53.835213
Policy Loss                  -1563.0854
Q Predictions Mean           1563.8489
Q Predictions Std            108.12694
Q Predictions Max            1722.4493
Q Predictions Min            1143.1195
V Predictions Mean           1566.1973
V Predictions Std            108.41874
V Predictions Max            1724.7007
V Predictions Min            1126.4303
Log Pis Mean                 -0.67314315
Log Pis Std                  1.6759827
Log Pis Max                  6.895857
Log Pis Min                  -5.1186466
Policy mu Mean               -0.06845356
Policy mu Std                0.7550637
Policy mu Max                1.8236111
Policy mu Min                -2.5139549
Policy log std Mean          -0.41191325
Policy log std Std           0.14649872
Policy log std Max           -0.02710788
Policy log std Min           -1.2156563
Z mean eval                  0.022497078
Z variance eval              0.005790173
total_rewards                [1028.46887613  449.62472593  552.40426706  701.79930657 1057.45557747
  607.7882795   440.66624572  798.17734256  431.73363426  969.74798131]
total_rewards_mean           703.7866236511193
total_rewards_std            234.54744243558758
total_rewards_max            1057.4555774733258
total_rewards_min            431.7336342584669
Number of train steps total  301000
Number of env steps total    1507000
Number of rollouts total     0
Train Time (s)               43.50166854029521
(Previous) Eval Time (s)     9.462620404083282
Sample Time (s)              20.853709026239812
Epoch Time (s)               73.81799797061831
Total Train Time (s)         24393.0776854367
Epoch                        300
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:34:53.223818 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #300 | Epoch Duration: 70.90716290473938
2020-01-11 07:34:53.224066 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #300 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022320006
Z variance train             0.0057902387
KL Divergence                10.659512
KL Loss                      1.0659512
QF Loss                      299.5269
VF Loss                      193.27747
Policy Loss                  -1546.0905
Q Predictions Mean           1545.7501
Q Predictions Std            131.07413
Q Predictions Max            1716.4292
Q Predictions Min            605.61646
V Predictions Mean           1545.4421
V Predictions Std            131.0059
V Predictions Max            1714.3481
V Predictions Min            607.0689
Log Pis Mean                 -0.843099
Log Pis Std                  1.4854218
Log Pis Max                  5.007551
Log Pis Min                  -3.567421
Policy mu Mean               0.044838797
Policy mu Std                0.6993204
Policy mu Max                1.7566817
Policy mu Min                -2.4870462
Policy log std Mean          -0.38906154
Policy log std Std           0.13246976
Policy log std Max           0.018934727
Policy log std Min           -0.8550496
Z mean eval                  0.04264861
Z variance eval              0.005447953
total_rewards                [ 937.22569893 1005.45473703  922.95797441 1114.64833553  894.60483315
  901.48173197 1026.33344667 1263.4332689  2108.37461522 1284.97720712]
total_rewards_mean           1145.9491848926034
total_rewards_std            347.9438546699163
total_rewards_max            2108.374615221859
total_rewards_min            894.6048331540972
Number of train steps total  302000
Number of env steps total    1512000
Number of rollouts total     0
Train Time (s)               44.11867632297799
(Previous) Eval Time (s)     6.551524518057704
Sample Time (s)              18.648703860118985
Epoch Time (s)               69.31890470115468
Total Train Time (s)         24465.80612002965
Epoch                        301
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:36:05.954770 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #301 | Epoch Duration: 72.73054361343384
2020-01-11 07:36:05.954935 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #301 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.042944096
Z variance train             0.0054507083
KL Divergence                10.85503
KL Loss                      1.085503
QF Loss                      114.01956
VF Loss                      95.413284
Policy Loss                  -1577.1752
Q Predictions Mean           1573.9838
Q Predictions Std            135.75026
Q Predictions Max            1728.3204
Q Predictions Min            179.80896
V Predictions Mean           1573.7952
V Predictions Std            136.29889
V Predictions Max            1721.9995
V Predictions Min            139.44098
Log Pis Mean                 -0.61653805
Log Pis Std                  1.6397842
Log Pis Max                  6.003288
Log Pis Min                  -4.3283
Policy mu Mean               -0.042714417
Policy mu Std                0.787634
Policy mu Max                2.2284017
Policy mu Min                -2.4297838
Policy log std Mean          -0.39617407
Policy log std Std           0.14370278
Policy log std Max           -0.04679969
Policy log std Min           -1.0650394
Z mean eval                  0.04464964
Z variance eval              0.005735737
total_rewards                [661.85080111 657.34671067 909.10131198 661.90568559 677.66538089
 655.5012187  664.98251018 658.81788211 671.56446964 644.91784967]
total_rewards_mean           686.3653820523027
total_rewards_std            74.7221270505913
total_rewards_max            909.1013119768309
total_rewards_min            644.917849667243
Number of train steps total  303000
Number of env steps total    1517000
Number of rollouts total     0
Train Time (s)               43.68811382167041
(Previous) Eval Time (s)     9.96293494105339
Sample Time (s)              21.88589208899066
Epoch Time (s)               75.53694085171446
Total Train Time (s)         24538.588441842236
Epoch                        302
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:37:18.739185 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #302 | Epoch Duration: 72.78411865234375
2020-01-11 07:37:18.739321 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #302 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.044828914
Z variance train             0.0057315985
KL Divergence                10.784995
KL Loss                      1.0784996
QF Loss                      54.01645
VF Loss                      18.943228
Policy Loss                  -1576.8108
Q Predictions Mean           1575.7644
Q Predictions Std            109.50638
Q Predictions Max            1701.514
Q Predictions Min            1261.106
V Predictions Mean           1573.8693
V Predictions Std            108.317345
V Predictions Max            1699.8925
V Predictions Min            1260.8085
Log Pis Mean                 -0.78293043
Log Pis Std                  1.6787906
Log Pis Max                  4.183743
Log Pis Min                  -9.194816
Policy mu Mean               -0.07786687
Policy mu Std                0.7411436
Policy mu Max                1.4438964
Policy mu Min                -2.5038595
Policy log std Mean          -0.40815
Policy log std Std           0.14978075
Policy log std Max           0.02300325
Policy log std Min           -1.1698582
Z mean eval                  0.032996632
Z variance eval              0.0056920685
total_rewards                [1523.20106524  687.18072168 1524.31155601  961.85027089  667.67896751
  677.58852111 1246.05452402  678.70453307  665.58047922  677.34652615]
total_rewards_mean           930.9497164898685
total_rewards_std            345.59739074533866
total_rewards_max            1524.311556011533
total_rewards_min            665.5804792225233
Number of train steps total  304000
Number of env steps total    1522000
Number of rollouts total     0
Train Time (s)               43.57157294405624
(Previous) Eval Time (s)     7.209875799249858
Sample Time (s)              21.533976946026087
Epoch Time (s)               72.31542568933219
Total Train Time (s)         24612.99553020764
Epoch                        303
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:38:33.149112 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #303 | Epoch Duration: 74.40962624549866
2020-01-11 07:38:33.149295 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #303 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03311576
Z variance train             0.005684052
KL Divergence                10.948637
KL Loss                      1.0948638
QF Loss                      63.014748
VF Loss                      34.877453
Policy Loss                  -1574.0276
Q Predictions Mean           1575.1089
Q Predictions Std            108.79437
Q Predictions Max            1715.6932
Q Predictions Min            1279.1663
V Predictions Mean           1573.2104
V Predictions Std            108.808365
V Predictions Max            1710.5089
V Predictions Min            1272.3059
Log Pis Mean                 -0.6366846
Log Pis Std                  1.5661882
Log Pis Max                  4.6704063
Log Pis Min                  -5.4610853
Policy mu Mean               0.04652549
Policy mu Std                0.76942766
Policy mu Max                1.8188392
Policy mu Min                -2.3235762
Policy log std Mean          -0.41367948
Policy log std Std           0.14842898
Policy log std Max           -0.046515435
Policy log std Min           -0.9538859
Z mean eval                  0.023544708
Z variance eval              0.0053404937
total_rewards                [1217.60767222  922.47921608  686.73247675 1104.68012619 2051.1178641
  664.46278173 1746.84827111 1502.71751611  687.71857609  964.81687468]
total_rewards_mean           1154.91813750607
total_rewards_std            452.6764316544608
total_rewards_max            2051.117864097118
total_rewards_min            664.4627817332724
Number of train steps total  305000
Number of env steps total    1527000
Number of rollouts total     0
Train Time (s)               43.752070205286145
(Previous) Eval Time (s)     9.303830736782402
Sample Time (s)              21.43821882456541
Epoch Time (s)               74.49411976663396
Total Train Time (s)         24688.6613054974
Epoch                        304
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:39:48.819844 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #304 | Epoch Duration: 75.67041778564453
2020-01-11 07:39:48.820041 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #304 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023721768
Z variance train             0.00534606
KL Divergence                11.09484
KL Loss                      1.1094841
QF Loss                      109.1359
VF Loss                      51.771564
Policy Loss                  -1561.5413
Q Predictions Mean           1562.0151
Q Predictions Std            110.38781
Q Predictions Max            1700.2954
Q Predictions Min            1257.5831
V Predictions Mean           1559.2036
V Predictions Std            111.88798
V Predictions Max            1697.0466
V Predictions Min            1255.68
Log Pis Mean                 -0.67762774
Log Pis Std                  1.6947261
Log Pis Max                  4.780022
Log Pis Min                  -5.922353
Policy mu Mean               0.044492956
Policy mu Std                0.7681694
Policy mu Max                3.0445874
Policy mu Min                -2.2778213
Policy log std Mean          -0.3981779
Policy log std Std           0.14672685
Policy log std Max           -0.047412813
Policy log std Min           -1.1241518
Z mean eval                  0.01758303
Z variance eval              0.0056151813
total_rewards                [ 927.71011147  666.44910413  902.1243457   683.71160565  942.06225354
  971.1778049  1429.07957126  906.01628204  905.6914794   932.45312909]
total_rewards_mean           926.6475687175437
total_rewards_std            195.67335649300227
total_rewards_max            1429.0795712601314
total_rewards_min            666.4491041324267
Number of train steps total  306000
Number of env steps total    1532000
Number of rollouts total     0
Train Time (s)               44.30069108912721
(Previous) Eval Time (s)     10.479897025972605
Sample Time (s)              22.12555873207748
Epoch Time (s)               76.9061468471773
Total Train Time (s)         24764.218695231248
Epoch                        305
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:41:04.381435 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #305 | Epoch Duration: 75.56124567985535
2020-01-11 07:41:04.381606 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #305 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017499566
Z variance train             0.0056183683
KL Divergence                10.928062
KL Loss                      1.0928062
QF Loss                      360.56067
VF Loss                      64.57749
Policy Loss                  -1544.4006
Q Predictions Mean           1543.5084
Q Predictions Std            148.20888
Q Predictions Max            1702.898
Q Predictions Min            181.94878
V Predictions Mean           1540.7549
V Predictions Std            147.33228
V Predictions Max            1696.4569
V Predictions Min            168.21672
Log Pis Mean                 -0.770729
Log Pis Std                  1.669648
Log Pis Max                  3.9371865
Log Pis Min                  -5.565453
Policy mu Mean               0.214625
Policy mu Std                0.7466558
Policy mu Max                1.9041324
Policy mu Min                -2.2979276
Policy log std Mean          -0.41250268
Policy log std Std           0.13963346
Policy log std Max           0.087703735
Policy log std Min           -1.047816
Z mean eval                  0.01946177
Z variance eval              0.0052672997
total_rewards                [ 940.21041411 2040.04633457  641.83200509  660.98349601  670.50164961
  663.63720252  829.14183379  935.84380519  678.55163639  659.20168504]
total_rewards_mean           871.9950062325879
total_rewards_std            404.8610943971384
total_rewards_max            2040.046334567353
total_rewards_min            641.8320050947281
Number of train steps total  307000
Number of env steps total    1537000
Number of rollouts total     0
Train Time (s)               43.52748491289094
(Previous) Eval Time (s)     9.134741642978042
Sample Time (s)              22.398944261483848
Epoch Time (s)               75.06117081735283
Total Train Time (s)         24838.620691689663
Epoch                        306
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:42:18.785199 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #306 | Epoch Duration: 74.40347456932068
2020-01-11 07:42:18.785321 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #306 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019331899
Z variance train             0.0052659707
KL Divergence                11.118235
KL Loss                      1.1118234
QF Loss                      68.20291
VF Loss                      40.37908
Policy Loss                  -1594.9419
Q Predictions Mean           1595.1313
Q Predictions Std            122.0576
Q Predictions Max            1739.3394
Q Predictions Min            852.7819
V Predictions Mean           1597.1892
V Predictions Std            122.91231
V Predictions Max            1742.5264
V Predictions Min            833.17834
Log Pis Mean                 -0.636546
Log Pis Std                  1.6764902
Log Pis Max                  4.42223
Log Pis Min                  -5.324046
Policy mu Mean               0.14230533
Policy mu Std                0.74576926
Policy mu Max                1.9656533
Policy mu Min                -2.650637
Policy log std Mean          -0.40157926
Policy log std Std           0.15236391
Policy log std Max           -0.006198257
Policy log std Min           -1.1297224
Z mean eval                  0.025569955
Z variance eval              0.005944919
total_rewards                [ 933.10006144  706.08392176  705.64396861  911.74631034  693.55552003
 1021.20766059 1236.4754879   696.54777056  999.0566447   938.44984569]
total_rewards_mean           884.1867191612312
total_rewards_std            172.4298399678868
total_rewards_max            1236.475487900548
total_rewards_min            693.5555200262183
Number of train steps total  308000
Number of env steps total    1542000
Number of rollouts total     0
Train Time (s)               43.4625813937746
(Previous) Eval Time (s)     8.476812905166298
Sample Time (s)              21.589231914374977
Epoch Time (s)               73.52862621331587
Total Train Time (s)         24911.4869130305
Epoch                        307
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:43:31.655134 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #307 | Epoch Duration: 72.86970281600952
2020-01-11 07:43:31.655295 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #307 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025523484
Z variance train             0.005946162
KL Divergence                10.709993
KL Loss                      1.0709994
QF Loss                      49.881496
VF Loss                      38.369423
Policy Loss                  -1583.2947
Q Predictions Mean           1585.5369
Q Predictions Std            145.52473
Q Predictions Max            1746.6099
Q Predictions Min            159.59727
V Predictions Mean           1586.6436
V Predictions Std            145.47101
V Predictions Max            1749.2502
V Predictions Min            176.87387
Log Pis Mean                 -0.731531
Log Pis Std                  1.7277
Log Pis Max                  4.201536
Log Pis Min                  -5.9453125
Policy mu Mean               0.084681414
Policy mu Std                0.7584547
Policy mu Max                1.9998726
Policy mu Min                -2.2411556
Policy log std Mean          -0.39748183
Policy log std Std           0.16092819
Policy log std Max           -0.005213648
Policy log std Min           -1.3182544
Z mean eval                  0.018298175
Z variance eval              0.007070626
total_rewards                [ 682.26065469 1167.10986396 1007.47805771 1225.35761947 2075.84513913
 1008.63963664  977.23923265  991.51837737  985.03791625  930.9799345 ]
total_rewards_mean           1105.1466432376005
total_rewards_std            351.0360153764841
total_rewards_max            2075.8451391335816
total_rewards_min            682.2606546870323
Number of train steps total  309000
Number of env steps total    1547000
Number of rollouts total     0
Train Time (s)               43.211109892930835
(Previous) Eval Time (s)     7.817656164988875
Sample Time (s)              19.7558690845035
Epoch Time (s)               70.78463514242321
Total Train Time (s)         24985.296397794504
Epoch                        308
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:44:45.469085 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #308 | Epoch Duration: 73.81364679336548
2020-01-11 07:44:45.469261 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #308 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018326107
Z variance train             0.007045319
KL Divergence                10.162836
KL Loss                      1.0162836
QF Loss                      206.05643
VF Loss                      101.94348
Policy Loss                  -1563.1815
Q Predictions Mean           1568.1599
Q Predictions Std            124.25857
Q Predictions Max            1731.8159
Q Predictions Min            1163.7904
V Predictions Mean           1560.9082
V Predictions Std            123.50123
V Predictions Max            1721.1509
V Predictions Min            1251.2692
Log Pis Mean                 -0.56113374
Log Pis Std                  1.9276264
Log Pis Max                  9.281296
Log Pis Min                  -4.7727327
Policy mu Mean               0.06250777
Policy mu Std                0.79752284
Policy mu Max                1.9439701
Policy mu Min                -2.740313
Policy log std Mean          -0.41375664
Policy log std Std           0.18372795
Policy log std Max           0.04887572
Policy log std Min           -1.2744313
Z mean eval                  0.018095724
Z variance eval              0.0075516934
total_rewards                [658.65028528 999.08651237 933.74993998 650.51267998 656.1288773
 661.54031608 940.17417995 938.95196085 673.51420128 941.08096324]
total_rewards_mean           805.3389916315589
total_rewards_std            146.38803430299112
total_rewards_max            999.0865123699622
total_rewards_min            650.5126799816403
Number of train steps total  310000
Number of env steps total    1552000
Number of rollouts total     0
Train Time (s)               44.06038928683847
(Previous) Eval Time (s)     10.846431476995349
Sample Time (s)              22.91354905627668
Epoch Time (s)               77.8203698201105
Total Train Time (s)         25059.50395769812
Epoch                        309
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:45:59.683138 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #309 | Epoch Duration: 74.21371030807495
2020-01-11 07:45:59.683401 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #309 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018544914
Z variance train             0.0075529604
KL Divergence                10.167841
KL Loss                      1.0167841
QF Loss                      57.13797
VF Loss                      71.37454
Policy Loss                  -1583.605
Q Predictions Mean           1583.0857
Q Predictions Std            166.65425
Q Predictions Max            1737.3525
Q Predictions Min            158.0454
V Predictions Mean           1580.188
V Predictions Std            168.32939
V Predictions Max            1734.5824
V Predictions Min            160.10414
Log Pis Mean                 -0.75372493
Log Pis Std                  1.6339861
Log Pis Max                  3.453133
Log Pis Min                  -5.8345137
Policy mu Mean               0.11532703
Policy mu Std                0.7389652
Policy mu Max                1.8620465
Policy mu Min                -2.310659
Policy log std Mean          -0.4033723
Policy log std Std           0.15523286
Policy log std Max           -0.03720033
Policy log std Min           -1.1895897
Z mean eval                  0.020526718
Z variance eval              0.007013702
total_rewards                [ 793.62288332  990.29945882  739.13912689 1028.52663035  807.1364025
  998.71356757  948.31150504  886.60883953 2051.53225068  942.87100203]
total_rewards_mean           1018.6761666728532
total_rewards_std            356.3384432100317
total_rewards_max            2051.532250679598
total_rewards_min            739.1391268912878
Number of train steps total  311000
Number of env steps total    1557000
Number of rollouts total     0
Train Time (s)               44.49184877006337
(Previous) Eval Time (s)     7.2395106120966375
Sample Time (s)              21.657291805837303
Epoch Time (s)               73.38865118799731
Total Train Time (s)         25135.17485576868
Epoch                        310
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:47:15.355489 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #310 | Epoch Duration: 75.67186975479126
2020-01-11 07:47:15.355613 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #310 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020457037
Z variance train             0.00701216
KL Divergence                10.516094
KL Loss                      1.0516094
QF Loss                      39.810646
VF Loss                      34.2018
Policy Loss                  -1583.2036
Q Predictions Mean           1582.844
Q Predictions Std            121.03185
Q Predictions Max            1754.1564
Q Predictions Min            1259.9381
V Predictions Mean           1582.0286
V Predictions Std            121.47234
V Predictions Max            1752.1786
V Predictions Min            1258.5142
Log Pis Mean                 -0.7715813
Log Pis Std                  1.6960912
Log Pis Max                  5.909898
Log Pis Min                  -5.62728
Policy mu Mean               0.13292016
Policy mu Std                0.7551717
Policy mu Max                1.9423974
Policy mu Min                -2.561604
Policy log std Mean          -0.42125598
Policy log std Std           0.14950472
Policy log std Max           0.09231186
Policy log std Min           -0.98029566
Z mean eval                  0.049547315
Z variance eval              0.006511529
total_rewards                [ 801.38017456  886.07826378  952.91346264  820.88811626  833.53495406
  795.13007497 1019.85336641  826.21305889  782.39423003  957.37223764]
total_rewards_mean           867.5757939248575
total_rewards_std            77.98221232949706
total_rewards_max            1019.8533664134777
total_rewards_min            782.3942300314427
Number of train steps total  312000
Number of env steps total    1562000
Number of rollouts total     0
Train Time (s)               44.2501554870978
(Previous) Eval Time (s)     9.5225272863172
Sample Time (s)              21.799235832411796
Epoch Time (s)               75.5719186058268
Total Train Time (s)         25209.166262989864
Epoch                        311
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:48:29.349280 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #311 | Epoch Duration: 73.99357271194458
2020-01-11 07:48:29.349406 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #311 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05272895
Z variance train             0.006489233
KL Divergence                10.771063
KL Loss                      1.0771064
QF Loss                      85.67027
VF Loss                      62.469692
Policy Loss                  -1608.0116
Q Predictions Mean           1607.2375
Q Predictions Std            117.48548
Q Predictions Max            1770.555
Q Predictions Min            1284.412
V Predictions Mean           1604.459
V Predictions Std            118.3157
V Predictions Max            1766.0496
V Predictions Min            1277.7504
Log Pis Mean                 -0.90004516
Log Pis Std                  1.6395224
Log Pis Max                  4.592739
Log Pis Min                  -7.124709
Policy mu Mean               0.03795031
Policy mu Std                0.73936474
Policy mu Max                1.8070592
Policy mu Min                -2.8313003
Policy log std Mean          -0.42719653
Policy log std Std           0.14100984
Policy log std Max           -0.057346642
Policy log std Min           -1.4108491
Z mean eval                  0.031695865
Z variance eval              0.0058772946
total_rewards                [ 799.34572562  865.7199558   877.11952483  840.84690118  847.27123175
  915.17372978  772.18436433 1055.0756935   881.29980612 1020.64613016]
total_rewards_mean           887.468306305341
total_rewards_std            84.8879465193568
total_rewards_max            1055.075693496177
total_rewards_min            772.1843643311884
Number of train steps total  313000
Number of env steps total    1567000
Number of rollouts total     0
Train Time (s)               43.844319318886846
(Previous) Eval Time (s)     7.943938240874559
Sample Time (s)              21.810737289022654
Epoch Time (s)               73.59899484878406
Total Train Time (s)         25282.273555345833
Epoch                        312
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:49:42.460917 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #312 | Epoch Duration: 73.11140656471252
2020-01-11 07:49:42.461065 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #312 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031198552
Z variance train             0.0058818134
KL Divergence                10.921141
KL Loss                      1.0921141
QF Loss                      66.84595
VF Loss                      72.45666
Policy Loss                  -1588.9454
Q Predictions Mean           1587.6404
Q Predictions Std            146.21269
Q Predictions Max            1760.3389
Q Predictions Min            594.5371
V Predictions Mean           1583.0325
V Predictions Std            146.56784
V Predictions Max            1758.7089
V Predictions Min            561.11926
Log Pis Mean                 -0.61463714
Log Pis Std                  1.7805392
Log Pis Max                  8.172039
Log Pis Min                  -3.897586
Policy mu Mean               0.0783088
Policy mu Std                0.7698254
Policy mu Max                2.2067456
Policy mu Min                -3.302696
Policy log std Mean          -0.42502776
Policy log std Std           0.16595684
Policy log std Max           -0.0005221665
Policy log std Min           -1.4975607
Z mean eval                  0.028946644
Z variance eval              0.005575747
total_rewards                [ 837.59948109  908.31436078 1840.57462962  835.86240272  900.14314889
 1032.82007163 1487.75700592  795.42223594  786.80633779  822.07098895]
total_rewards_mean           1024.7370663353547
total_rewards_std            336.1674576815333
total_rewards_max            1840.5746296226685
total_rewards_min            786.8063377948681
Number of train steps total  314000
Number of env steps total    1572000
Number of rollouts total     0
Train Time (s)               43.81738266395405
(Previous) Eval Time (s)     7.456094016321003
Sample Time (s)              21.551520962268114
Epoch Time (s)               72.82499764254317
Total Train Time (s)         25357.498048777226
Epoch                        313
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:50:57.687198 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #313 | Epoch Duration: 75.22601675987244
2020-01-11 07:50:57.687318 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #313 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029261187
Z variance train             0.005579276
KL Divergence                11.09017
KL Loss                      1.109017
QF Loss                      58.723583
VF Loss                      57.722073
Policy Loss                  -1566.1938
Q Predictions Mean           1564.6113
Q Predictions Std            182.22513
Q Predictions Max            1746.2649
Q Predictions Min            203.20723
V Predictions Mean           1563.7411
V Predictions Std            180.76329
V Predictions Max            1739.8265
V Predictions Min            194.74399
Log Pis Mean                 -0.6450721
Log Pis Std                  1.5600191
Log Pis Max                  3.9761264
Log Pis Min                  -5.3677516
Policy mu Mean               0.030248975
Policy mu Std                0.76594514
Policy mu Max                2.5713873
Policy mu Min                -1.984333
Policy log std Mean          -0.40613517
Policy log std Std           0.15773304
Policy log std Max           0.07574484
Policy log std Min           -1.2473772
Z mean eval                  0.011793645
Z variance eval              0.0069126626
total_rewards                [877.110503   999.26044952 974.86772402 800.39090371 879.52239258
 823.92336743 900.99266489 749.04381889 717.40147286 840.64037721]
total_rewards_mean           856.3153674107514
total_rewards_std            85.25360414152382
total_rewards_max            999.2604495196645
total_rewards_min            717.4014728641733
Number of train steps total  315000
Number of env steps total    1577000
Number of rollouts total     0
Train Time (s)               43.798387050163
(Previous) Eval Time (s)     9.85687794117257
Sample Time (s)              21.804841002449393
Epoch Time (s)               75.46010599378496
Total Train Time (s)         25431.4231235818
Epoch                        314
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:52:11.614560 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #314 | Epoch Duration: 73.92714142799377
2020-01-11 07:52:11.614684 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #314 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011365612
Z variance train             0.0069214515
KL Divergence                10.719057
KL Loss                      1.0719057
QF Loss                      55.471325
VF Loss                      31.778687
Policy Loss                  -1591.7369
Q Predictions Mean           1589.7872
Q Predictions Std            141.22542
Q Predictions Max            1760.0074
Q Predictions Min            524.5599
V Predictions Mean           1590.1152
V Predictions Std            140.7838
V Predictions Max            1761.9517
V Predictions Min            486.0982
Log Pis Mean                 -0.6290919
Log Pis Std                  1.7426682
Log Pis Max                  6.795663
Log Pis Min                  -5.3987126
Policy mu Mean               0.02533712
Policy mu Std                0.76828694
Policy mu Max                1.805138
Policy mu Min                -2.7161577
Policy log std Mean          -0.41432557
Policy log std Std           0.14098425
Policy log std Max           0.011154592
Policy log std Min           -0.94381905
Z mean eval                  0.019201528
Z variance eval              0.0059985695
total_rewards                [1038.60492068  767.18559827  710.56350812  900.29578212  928.19511327
  920.97414999  761.02134964 1081.27093517  789.61820661 1035.41907601]
total_rewards_mean           893.314863988047
total_rewards_std            124.9887650498189
total_rewards_max            1081.2709351707756
total_rewards_min            710.5635081175852
Number of train steps total  316000
Number of env steps total    1582000
Number of rollouts total     0
Train Time (s)               43.52071629976854
(Previous) Eval Time (s)     8.323658614885062
Sample Time (s)              21.607981910463423
Epoch Time (s)               73.45235682511702
Total Train Time (s)         25504.927920886315
Epoch                        315
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:53:25.127359 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #315 | Epoch Duration: 73.51252841949463
2020-01-11 07:53:25.127661 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #315 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01917739
Z variance train             0.0060010264
KL Divergence                10.792269
KL Loss                      1.0792269
QF Loss                      97.235176
VF Loss                      51.51295
Policy Loss                  -1584.6093
Q Predictions Mean           1585.9177
Q Predictions Std            144.54655
Q Predictions Max            1757.3474
Q Predictions Min            851.6149
V Predictions Mean           1585.863
V Predictions Std            141.53964
V Predictions Max            1753.893
V Predictions Min            826.39575
Log Pis Mean                 -0.4581018
Log Pis Std                  1.8617
Log Pis Max                  10.246071
Log Pis Min                  -5.1630745
Policy mu Mean               0.15575463
Policy mu Std                0.8183094
Policy mu Max                3.4421778
Policy mu Min                -2.9931486
Policy log std Mean          -0.43703735
Policy log std Std           0.15733507
Policy log std Max           0.007882804
Policy log std Min           -1.2485859
Z mean eval                  0.028385645
Z variance eval              0.006272608
total_rewards                [ 898.98897448 1048.99991025 1895.54465774 1001.70943676 1015.26163861
 1004.16033099 1027.22095991 1891.3152241   908.6696611   903.60322806]
total_rewards_mean           1159.547402199229
total_rewards_std            370.5565062114333
total_rewards_max            1895.5446577386617
total_rewards_min            898.9889744810911
Number of train steps total  317000
Number of env steps total    1587000
Number of rollouts total     0
Train Time (s)               44.63431650400162
(Previous) Eval Time (s)     8.383576071821153
Sample Time (s)              21.28289634268731
Epoch Time (s)               74.30078891851008
Total Train Time (s)         25582.2989564999
Epoch                        316
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:54:42.499501 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #316 | Epoch Duration: 77.3716287612915
2020-01-11 07:54:42.499620 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #316 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02911746
Z variance train             0.0063015064
KL Divergence                10.897984
KL Loss                      1.0897983
QF Loss                      196.30862
VF Loss                      270.2513
Policy Loss                  -1588.9398
Q Predictions Mean           1594.957
Q Predictions Std            158.67401
Q Predictions Max            1778.5199
Q Predictions Min            160.54355
V Predictions Mean           1596.6824
V Predictions Std            159.27527
V Predictions Max            1795.115
V Predictions Min            158.39398
Log Pis Mean                 -0.5788642
Log Pis Std                  1.7474046
Log Pis Max                  7.293186
Log Pis Min                  -5.1400614
Policy mu Mean               0.012535562
Policy mu Std                0.7988544
Policy mu Max                1.7877607
Policy mu Min                -3.1730366
Policy log std Mean          -0.41365167
Policy log std Std           0.15356019
Policy log std Max           -0.0006393492
Policy log std Min           -1.5859387
Z mean eval                  0.039470747
Z variance eval              0.0062099057
total_rewards                [ 925.13686064 1011.63300663 1732.43690088  741.27763243 3265.84296213
  924.10581991  715.01065505  888.52977391 1260.71320536  899.8935966 ]
total_rewards_mean           1236.458041352831
total_rewards_std            732.2197963459531
total_rewards_max            3265.842962126712
total_rewards_min            715.0106550459643
Number of train steps total  318000
Number of env steps total    1592000
Number of rollouts total     0
Train Time (s)               43.826358647085726
(Previous) Eval Time (s)     11.454204814974219
Sample Time (s)              21.74682102492079
Epoch Time (s)               77.02738448698074
Total Train Time (s)         25660.535860163625
Epoch                        317
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:56:00.744691 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #317 | Epoch Duration: 78.24495768547058
2020-01-11 07:56:00.744875 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #317 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035602685
Z variance train             0.0062168133
KL Divergence                10.722432
KL Loss                      1.0722432
QF Loss                      178.53577
VF Loss                      162.4192
Policy Loss                  -1578.2164
Q Predictions Mean           1580.1709
Q Predictions Std            169.51228
Q Predictions Max            1749.2705
Q Predictions Min            501.7759
V Predictions Mean           1587.6909
V Predictions Std            169.07133
V Predictions Max            1754.4033
V Predictions Min            481.42
Log Pis Mean                 -0.74901557
Log Pis Std                  1.7503573
Log Pis Max                  9.499966
Log Pis Min                  -5.03995
Policy mu Mean               -0.011087908
Policy mu Std                0.7873071
Policy mu Max                1.7290282
Policy mu Min                -3.8169618
Policy log std Mean          -0.42254546
Policy log std Std           0.1810847
Policy log std Max           0.04102233
Policy log std Min           -1.4159881
Z mean eval                  0.020217488
Z variance eval              0.0064376285
total_rewards                [1312.86287614 2865.65477964 1420.36014764 2608.44993545 2105.95970446
 3152.32802049  866.72186336  838.76806562 3166.02681647 2694.89221208]
total_rewards_mean           2103.2024421357573
total_rewards_std            873.8170206407938
total_rewards_max            3166.0268164736262
total_rewards_min            838.7680656183535
Number of train steps total  319000
Number of env steps total    1597000
Number of rollouts total     0
Train Time (s)               44.41506898403168
(Previous) Eval Time (s)     12.671517636161298
Sample Time (s)              21.676887661684304
Epoch Time (s)               78.76347428187728
Total Train Time (s)         25747.436628390104
Epoch                        318
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:57:27.646997 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #318 | Epoch Duration: 86.9019923210144
2020-01-11 07:57:27.647130 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #318 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020777661
Z variance train             0.0064405976
KL Divergence                10.5047
KL Loss                      1.05047
QF Loss                      107.54952
VF Loss                      122.585014
Policy Loss                  -1577.8179
Q Predictions Mean           1579.907
Q Predictions Std            182.71275
Q Predictions Max            1768.8394
Q Predictions Min            520.4053
V Predictions Mean           1586.0802
V Predictions Std            182.3507
V Predictions Max            1784.2445
V Predictions Min            525.968
Log Pis Mean                 -0.5030364
Log Pis Std                  1.7978052
Log Pis Max                  12.29676
Log Pis Min                  -5.896312
Policy mu Mean               -0.011347513
Policy mu Std                0.78740674
Policy mu Max                2.6065402
Policy mu Min                -3.6261425
Policy log std Mean          -0.4328173
Policy log std Std           0.16128984
Policy log std Max           0.020773053
Policy log std Min           -1.2768158
Z mean eval                  0.021537198
Z variance eval              0.0060772365
total_rewards                [2255.36568801 3240.06922743 3232.93099004 3157.83983386 1078.87785568
 3230.18622783 2394.63991665 3224.62228884 1179.78893085 3148.32295328]
total_rewards_mean           2614.264391248575
total_rewards_std            818.4829982342874
total_rewards_max            3240.0692274336407
total_rewards_min            1078.8778556796474
Number of train steps total  320000
Number of env steps total    1602000
Number of rollouts total     0
Train Time (s)               44.04644576180726
(Previous) Eval Time (s)     20.809801507741213
Sample Time (s)              21.579447130672634
Epoch Time (s)               86.43569440022111
Total Train Time (s)         25839.901475212537
Epoch                        319
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:59:00.114040 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #319 | Epoch Duration: 92.46681094169617
2020-01-11 07:59:00.114164 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #319 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021672685
Z variance train             0.0060777087
KL Divergence                10.509211
KL Loss                      1.0509211
QF Loss                      52.654465
VF Loss                      17.401268
Policy Loss                  -1599.0238
Q Predictions Mean           1599.2871
Q Predictions Std            126.1851
Q Predictions Max            1772.7433
Q Predictions Min            1080.0691
V Predictions Mean           1599.4719
V Predictions Std            124.168526
V Predictions Max            1768.4897
V Predictions Min            1138.2672
Log Pis Mean                 -0.5371586
Log Pis Std                  1.7361168
Log Pis Max                  5.1400023
Log Pis Min                  -5.7621975
Policy mu Mean               0.12050583
Policy mu Std                0.7958763
Policy mu Max                1.966441
Policy mu Min                -2.596932
Policy log std Mean          -0.40709546
Policy log std Std           0.15278797
Policy log std Max           0.10564694
Policy log std Min           -1.1765176
Z mean eval                  0.016439762
Z variance eval              0.0052978247
total_rewards                [3200.6656114  1153.90337762 2810.36960757 3234.85204839 3186.85811622
 1935.57242345 3245.94789176  967.22044988 1188.39522545  724.67961212]
total_rewards_mean           2164.8464363858766
total_rewards_std            1019.0308955955255
total_rewards_max            3245.9478917551546
total_rewards_min            724.6796121178429
Number of train steps total  321000
Number of env steps total    1607000
Number of rollouts total     0
Train Time (s)               45.012574716005474
(Previous) Eval Time (s)     26.840676533058286
Sample Time (s)              21.723888197913766
Epoch Time (s)               93.57713944697753
Total Train Time (s)         25928.607481598854
Epoch                        320
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:00:28.822080 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #320 | Epoch Duration: 88.70782208442688
2020-01-11 08:00:28.822203 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #320 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016358163
Z variance train             0.0052896524
KL Divergence                10.903791
KL Loss                      1.0903791
QF Loss                      223.36652
VF Loss                      73.15917
Policy Loss                  -1600.1826
Q Predictions Mean           1597.5764
Q Predictions Std            146.4906
Q Predictions Max            1759.1925
Q Predictions Min            333.85684
V Predictions Mean           1602.4456
V Predictions Std            147.60172
V Predictions Max            1767.9719
V Predictions Min            300.42175
Log Pis Mean                 -0.64080167
Log Pis Std                  1.6446128
Log Pis Max                  4.5088973
Log Pis Min                  -4.2070985
Policy mu Mean               0.067366764
Policy mu Std                0.7684579
Policy mu Max                2.095186
Policy mu Min                -2.4656994
Policy log std Mean          -0.42167583
Policy log std Std           0.17017499
Policy log std Max           0.12238696
Policy log std Min           -1.3736085
Z mean eval                  0.021297824
Z variance eval              0.0044701486
total_rewards                [1549.57067746 1973.6930712  1755.60239868 2209.74347946 2301.6323085
 1139.87153565 3211.18069727 1847.7400207   664.88860124 1798.00774111]
total_rewards_mean           1845.1930531256044
total_rewards_std            648.9928630596943
total_rewards_max            3211.1806972684044
total_rewards_min            664.8886012375676
Number of train steps total  322000
Number of env steps total    1612000
Number of rollouts total     0
Train Time (s)               44.28610119828954
(Previous) Eval Time (s)     21.97111358633265
Sample Time (s)              22.374645525123924
Epoch Time (s)               88.63186030974612
Total Train Time (s)         26014.258660362568
Epoch                        321
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:01:54.475298 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #321 | Epoch Duration: 85.65300250053406
2020-01-11 08:01:54.475422 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #321 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020256285
Z variance train             0.004469757
KL Divergence                11.331961
KL Loss                      1.1331961
QF Loss                      125.28469
VF Loss                      65.57204
Policy Loss                  -1589.0814
Q Predictions Mean           1589.7415
Q Predictions Std            176.21918
Q Predictions Max            1763.1135
Q Predictions Min            319.2912
V Predictions Mean           1590.775
V Predictions Std            177.55074
V Predictions Max            1763.2277
V Predictions Min            289.3324
Log Pis Mean                 -0.5851505
Log Pis Std                  1.7613602
Log Pis Max                  6.750832
Log Pis Min                  -4.704011
Policy mu Mean               0.07421831
Policy mu Std                0.8289577
Policy mu Max                2.0421727
Policy mu Min                -3.1128204
Policy log std Mean          -0.41215885
Policy log std Std           0.15478523
Policy log std Max           0.06090334
Policy log std Min           -1.2083068
Z mean eval                  0.014184949
Z variance eval              0.0043439474
total_rewards                [ 976.50742807 3090.47581007 1159.24736388 1377.19144999 1140.84819158
  660.8986527  3156.81019955 2175.24952608  845.50596336  839.30709418]
total_rewards_mean           1542.2041679461051
total_rewards_std            884.0803565568157
total_rewards_max            3156.810199553944
total_rewards_min            660.8986526972903
Number of train steps total  323000
Number of env steps total    1617000
Number of rollouts total     0
Train Time (s)               43.76145833497867
(Previous) Eval Time (s)     18.99200346088037
Sample Time (s)              21.838416762650013
Epoch Time (s)               84.59187855850905
Total Train Time (s)         26094.268236011732
Epoch                        322
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:03:14.488415 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #322 | Epoch Duration: 80.01288437843323
2020-01-11 08:03:14.488582 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #322 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014545386
Z variance train             0.004347601
KL Divergence                11.393499
KL Loss                      1.1393499
QF Loss                      144.37277
VF Loss                      84.53502
Policy Loss                  -1606.28
Q Predictions Mean           1604.2991
Q Predictions Std            151.31244
Q Predictions Max            1781.5052
Q Predictions Min            560.40436
V Predictions Mean           1604.0359
V Predictions Std            151.57864
V Predictions Max            1786.4326
V Predictions Min            549.86523
Log Pis Mean                 -0.3888887
Log Pis Std                  1.9785043
Log Pis Max                  9.138994
Log Pis Min                  -5.9158573
Policy mu Mean               -0.011463758
Policy mu Std                0.8465474
Policy mu Max                2.095378
Policy mu Min                -3.977599
Policy log std Mean          -0.4384451
Policy log std Std           0.16910759
Policy log std Max           0.08063999
Policy log std Min           -1.3542173
Z mean eval                  0.013714209
Z variance eval              0.004566461
total_rewards                [1648.61935333 1610.03027573 2571.1429852  1075.12321735 3246.74714615
 2612.31799324 3137.52403588 3133.60741626 3155.81458972 3171.48304639]
total_rewards_mean           2536.2410059243157
total_rewards_std            761.4604601977808
total_rewards_max            3246.7471461469977
total_rewards_min            1075.1232173483147
Number of train steps total  324000
Number of env steps total    1622000
Number of rollouts total     0
Train Time (s)               44.62422355217859
(Previous) Eval Time (s)     14.412773524876684
Sample Time (s)              21.8647135309875
Epoch Time (s)               80.90171060804278
Total Train Time (s)         26186.89562969841
Epoch                        323
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:04:47.121449 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #323 | Epoch Duration: 92.63273620605469
2020-01-11 08:04:47.121583 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #323 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01421026
Z variance train             0.0045645256
KL Divergence                11.171366
KL Loss                      1.1171366
QF Loss                      428.9978
VF Loss                      119.88649
Policy Loss                  -1589.5177
Q Predictions Mean           1590.6415
Q Predictions Std            167.91449
Q Predictions Max            1763.9785
Q Predictions Min            56.097755
V Predictions Mean           1595.7511
V Predictions Std            167.55287
V Predictions Max            1771.4352
V Predictions Min            122.32607
Log Pis Mean                 -0.12518182
Log Pis Std                  2.1753345
Log Pis Max                  10.800411
Log Pis Min                  -4.6349926
Policy mu Mean               0.018370053
Policy mu Std                0.93536747
Policy mu Max                2.1948044
Policy mu Min                -3.926015
Policy log std Mean          -0.43440032
Policy log std Std           0.16081344
Policy log std Max           0.109568626
Policy log std Min           -1.290178
Z mean eval                  0.024430973
Z variance eval              0.0042838333
total_rewards                [3148.65692093 1206.83240068 2828.11483083  736.19395161 1793.5661692
 1920.49483912 3144.12890011 3129.24399385 2791.96039072 1597.07335945]
total_rewards_mean           2229.62657564871
total_rewards_std            844.2116970340994
total_rewards_max            3148.6569209309396
total_rewards_min            736.1939516081055
Number of train steps total  325000
Number of env steps total    1627000
Number of rollouts total     0
Train Time (s)               45.28055504988879
(Previous) Eval Time (s)     26.14354086201638
Sample Time (s)              21.27308055665344
Epoch Time (s)               92.69717646855861
Total Train Time (s)         26276.622056102846
Epoch                        324
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:06:16.850654 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #324 | Epoch Duration: 89.72895812988281
2020-01-11 08:06:16.850835 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #324 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024586875
Z variance train             0.004286547
KL Divergence                11.361498
KL Loss                      1.1361498
QF Loss                      202.81221
VF Loss                      168.70111
Policy Loss                  -1561.8666
Q Predictions Mean           1561.9692
Q Predictions Std            223.10387
Q Predictions Max            1761.7839
Q Predictions Min            92.251884
V Predictions Mean           1565.9651
V Predictions Std            220.37956
V Predictions Max            1758.0363
V Predictions Min            108.47826
Log Pis Mean                 -0.4548148
Log Pis Std                  1.8727231
Log Pis Max                  8.389824
Log Pis Min                  -4.6204915
Policy mu Mean               0.0423945
Policy mu Std                0.8382478
Policy mu Max                2.1185448
Policy mu Min                -3.841287
Policy log std Mean          -0.39366236
Policy log std Std           0.14935789
Policy log std Max           0.18274724
Policy log std Min           -1.2284615
Z mean eval                  0.033136744
Z variance eval              0.0048553487
total_rewards                [2505.93360259 3109.86144562 3112.78980455 2725.04010444 3117.21234601
 3084.75419081 3078.88324236 3078.22926113 3075.42550989 3189.22825649]
total_rewards_mean           3007.7357763897803
total_rewards_std            204.61132295867097
total_rewards_max            3189.2282564857423
total_rewards_min            2505.933602593562
Number of train steps total  326000
Number of env steps total    1632000
Number of rollouts total     0
Train Time (s)               44.25271269818768
(Previous) Eval Time (s)     23.175047306809574
Sample Time (s)              20.117600886151195
Epoch Time (s)               87.54536089114845
Total Train Time (s)         26371.7576639303
Epoch                        325
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:07:51.995331 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #325 | Epoch Duration: 95.14431858062744
2020-01-11 08:07:51.995645 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #325 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033422165
Z variance train             0.0048518055
KL Divergence                10.9813385
KL Loss                      1.0981339
QF Loss                      275.52753
VF Loss                      183.12025
Policy Loss                  -1592.5396
Q Predictions Mean           1592.2347
Q Predictions Std            161.87993
Q Predictions Max            1786.5835
Q Predictions Min            684.3089
V Predictions Mean           1583.8916
V Predictions Std            163.64278
V Predictions Max            1769.5029
V Predictions Min            674.0138
Log Pis Mean                 -0.44084132
Log Pis Std                  1.754055
Log Pis Max                  5.046939
Log Pis Min                  -3.951457
Policy mu Mean               0.05972572
Policy mu Std                0.8614762
Policy mu Max                2.0300193
Policy mu Min                -3.241343
Policy log std Mean          -0.41896844
Policy log std Std           0.17286432
Policy log std Max           -0.049818516
Policy log std Min           -1.3823814
Z mean eval                  0.012575368
Z variance eval              0.0045647137
total_rewards                [3169.06250889  993.921469   1254.39549307   23.32433956 2030.51348239
 3209.05278791  716.91629147  984.00604723 3213.25018605 2914.96931859]
total_rewards_mean           1850.9411924165966
total_rewards_std            1143.2550339270388
total_rewards_max            3213.250186049407
total_rewards_min            23.324339559331104
Number of train steps total  327000
Number of env steps total    1637000
Number of rollouts total     0
Train Time (s)               43.756329610943794
(Previous) Eval Time (s)     30.77373472834006
Sample Time (s)              21.71735625527799
Epoch Time (s)               96.24742059456185
Total Train Time (s)         26453.992702031508
Epoch                        326
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:09:14.233312 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #326 | Epoch Duration: 82.23743009567261
2020-01-11 08:09:14.233488 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #326 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012588156
Z variance train             0.0045630718
KL Divergence                11.066974
KL Loss                      1.1066974
QF Loss                      127.80555
VF Loss                      80.51075
Policy Loss                  -1594.1525
Q Predictions Mean           1594.5852
Q Predictions Std            165.11766
Q Predictions Max            1775.8655
Q Predictions Min            469.6199
V Predictions Mean           1594.7026
V Predictions Std            162.37573
V Predictions Max            1773.651
V Predictions Min            486.94305
Log Pis Mean                 -0.45476812
Log Pis Std                  1.7947009
Log Pis Max                  10.626499
Log Pis Min                  -3.8283136
Policy mu Mean               0.087430775
Policy mu Std                0.8350529
Policy mu Max                2.5749183
Policy mu Min                -3.0843606
Policy log std Mean          -0.42250016
Policy log std Std           0.16181971
Policy log std Max           0.03153348
Policy log std Min           -1.1702523
Z mean eval                  0.014634356
Z variance eval              0.0044669234
total_rewards                [1733.91495569 1781.78286004  777.63836669 1115.9003072  2578.10796473
 1631.09224566 1052.73129329 1210.25342017 3287.49447911 2885.40238235]
total_rewards_mean           1805.431827493137
total_rewards_std            803.0287223039987
total_rewards_max            3287.494479112631
total_rewards_min            777.6383666862567
Number of train steps total  328000
Number of env steps total    1642000
Number of rollouts total     0
Train Time (s)               43.70379091706127
(Previous) Eval Time (s)     16.763499225024134
Sample Time (s)              21.683094382286072
Epoch Time (s)               82.15038452437147
Total Train Time (s)         26537.692538451403
Epoch                        327
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:10:37.937743 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #327 | Epoch Duration: 83.70411014556885
2020-01-11 08:10:37.937933 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #327 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01439731
Z variance train             0.0044714874
KL Divergence                11.065623
KL Loss                      1.1065624
QF Loss                      370.19876
VF Loss                      234.54785
Policy Loss                  -1606.4202
Q Predictions Mean           1604.7528
Q Predictions Std            131.84521
Q Predictions Max            1775.8882
Q Predictions Min            590.65204
V Predictions Mean           1600.9681
V Predictions Std            132.77994
V Predictions Max            1765.479
V Predictions Min            573.71704
Log Pis Mean                 -0.43165886
Log Pis Std                  2.0580583
Log Pis Max                  9.9997225
Log Pis Min                  -5.570334
Policy mu Mean               0.043258633
Policy mu Std                0.90673006
Policy mu Max                2.6365178
Policy mu Min                -3.3256395
Policy log std Mean          -0.40167055
Policy log std Std           0.16972707
Policy log std Max           0.198769
Policy log std Min           -1.4122872
Z mean eval                  0.03132275
Z variance eval              0.0053633116
total_rewards                [1851.77829733 3212.89512723  456.47295055  462.12769979 1575.88270012
 3264.60388153 1588.69063801  461.51501773 2727.83051418 1569.29228123]
total_rewards_mean           1717.1089107683033
total_rewards_std            1023.2689691777231
total_rewards_max            3264.603881528969
total_rewards_min            456.4729505480006
Number of train steps total  329000
Number of env steps total    1647000
Number of rollouts total     0
Train Time (s)               44.52558602206409
(Previous) Eval Time (s)     18.316982559859753
Sample Time (s)              22.139857369475067
Epoch Time (s)               84.98242595139891
Total Train Time (s)         26622.263045823667
Epoch                        328
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:12:02.514526 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #328 | Epoch Duration: 84.57643508911133
2020-01-11 08:12:02.514746 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #328 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031881567
Z variance train             0.00535968
KL Divergence                10.595966
KL Loss                      1.0595967
QF Loss                      72.76416
VF Loss                      140.97133
Policy Loss                  -1590.7874
Q Predictions Mean           1591.9937
Q Predictions Std            163.72598
Q Predictions Max            1780.7751
Q Predictions Min            634.4382
V Predictions Mean           1595.3469
V Predictions Std            165.02849
V Predictions Max            1780.923
V Predictions Min            610.9909
Log Pis Mean                 -0.15195596
Log Pis Std                  1.9223503
Log Pis Max                  8.400595
Log Pis Min                  -4.6056166
Policy mu Mean               0.07009832
Policy mu Std                0.88433504
Policy mu Max                2.086606
Policy mu Min                -3.9366555
Policy log std Mean          -0.41836587
Policy log std Std           0.16025811
Policy log std Max           0.007945359
Policy log std Min           -1.22406
Z mean eval                  0.015176279
Z variance eval              0.0050917426
total_rewards                [1080.839369   1018.99250506 1149.81996981  967.82771514  467.75280557
 3255.93074067 1390.6913524  1066.09391768  722.51641853  740.73643418]
total_rewards_mean           1186.120122802959
total_rewards_std            731.9633360352168
total_rewards_max            3255.9307406710154
total_rewards_min            467.7528055672306
Number of train steps total  330000
Number of env steps total    1652000
Number of rollouts total     0
Train Time (s)               43.6446664868854
(Previous) Eval Time (s)     17.910721326246858
Sample Time (s)              22.228083512280136
Epoch Time (s)               83.78347132541239
Total Train Time (s)         26700.25857352931
Epoch                        329
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:13:20.513650 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #329 | Epoch Duration: 77.99872875213623
2020-01-11 08:13:20.513830 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #329 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015058669
Z variance train             0.005093497
KL Divergence                10.754173
KL Loss                      1.0754174
QF Loss                      154.88943
VF Loss                      123.37998
Policy Loss                  -1583.3693
Q Predictions Mean           1580.3281
Q Predictions Std            141.24593
Q Predictions Max            1741.5704
Q Predictions Min            845.03546
V Predictions Mean           1583.6956
V Predictions Std            145.63193
V Predictions Max            1749.4946
V Predictions Min            850.34686
Log Pis Mean                 -0.5402349
Log Pis Std                  1.9946342
Log Pis Max                  11.006716
Log Pis Min                  -7.789568
Policy mu Mean               0.026856108
Policy mu Std                0.8281027
Policy mu Max                2.7114692
Policy mu Min                -2.998542
Policy log std Mean          -0.39563814
Policy log std Std           0.15215611
Policy log std Max           0.13566568
Policy log std Min           -1.0758739
Z mean eval                  0.018552154
Z variance eval              0.004931882
total_rewards                [2685.22003051  857.51678735 2871.78561568  855.20534687 2609.10721727
 1919.14430791 1487.64430215 2090.06835847 1255.78468307 1146.89947272]
total_rewards_mean           1777.8376122019931
total_rewards_std            726.746512644001
total_rewards_max            2871.7856156841226
total_rewards_min            855.2053468710034
Number of train steps total  331000
Number of env steps total    1657000
Number of rollouts total     0
Train Time (s)               44.08069920679554
(Previous) Eval Time (s)     12.125725517049432
Sample Time (s)              21.50679672975093
Epoch Time (s)               77.7132214535959
Total Train Time (s)         26783.56822864944
Epoch                        330
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:14:43.830174 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #330 | Epoch Duration: 83.3161473274231
2020-01-11 08:14:43.830413 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #330 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019806188
Z variance train             0.004927748
KL Divergence                11.028384
KL Loss                      1.1028384
QF Loss                      236.69046
VF Loss                      202.9501
Policy Loss                  -1574.4995
Q Predictions Mean           1573.2361
Q Predictions Std            212.93993
Q Predictions Max            1760.3478
Q Predictions Min            246.22676
V Predictions Mean           1578.5125
V Predictions Std            208.78627
V Predictions Max            1773.3541
V Predictions Min            241.10854
Log Pis Mean                 -0.69058555
Log Pis Std                  1.7827868
Log Pis Max                  5.4528074
Log Pis Min                  -6.645152
Policy mu Mean               -0.04658988
Policy mu Std                0.79471517
Policy mu Max                1.8956343
Policy mu Min                -2.9401395
Policy log std Mean          -0.3901794
Policy log std Std           0.17056037
Policy log std Max           -0.004907608
Policy log std Min           -1.3048357
Z mean eval                  0.051410817
Z variance eval              0.004416505
total_rewards                [ 822.35904242 1175.17440097 1153.11051988 1175.63736511  674.41284661
  999.741026   2396.66778238  970.78367146 1158.94593536  667.61791245]
total_rewards_mean           1119.4450502635964
total_rewards_std            465.5261225509768
total_rewards_max            2396.6677823847
total_rewards_min            667.6179124499729
Number of train steps total  332000
Number of env steps total    1662000
Number of rollouts total     0
Train Time (s)               44.43434979300946
(Previous) Eval Time (s)     17.728387143928558
Sample Time (s)              19.645544851198792
Epoch Time (s)               81.80828178813681
Total Train Time (s)         26859.305551290978
Epoch                        331
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:15:59.570003 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #331 | Epoch Duration: 75.73943519592285
2020-01-11 08:15:59.570144 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #331 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.051622085
Z variance train             0.0044199396
KL Divergence                11.285092
KL Loss                      1.1285093
QF Loss                      90.55813
VF Loss                      62.762188
Policy Loss                  -1608.2975
Q Predictions Mean           1609.9481
Q Predictions Std            129.8586
Q Predictions Max            1768.4868
Q Predictions Min            733.20496
V Predictions Mean           1613.2395
V Predictions Std            129.46771
V Predictions Max            1769.6519
V Predictions Min            691.91345
Log Pis Mean                 -0.63791656
Log Pis Std                  1.7252047
Log Pis Max                  6.4486074
Log Pis Min                  -5.181603
Policy mu Mean               0.086588286
Policy mu Std                0.8097483
Policy mu Max                1.730436
Policy mu Min                -3.0193248
Policy log std Mean          -0.4171219
Policy log std Std           0.16407295
Policy log std Max           0.074038
Policy log std Min           -1.1575558
Z mean eval                  0.019300858
Z variance eval              0.004251418
total_rewards                [2662.93143003  995.47886126 2516.33691854 3165.57001169  896.453486
 1519.56313624 1536.06210062 1301.5869383  2004.6689888  1437.7856537 ]
total_rewards_mean           1803.6437525182253
total_rewards_std            718.0460113351136
total_rewards_max            3165.570011691921
total_rewards_min            896.4534859982169
Number of train steps total  333000
Number of env steps total    1667000
Number of rollouts total     0
Train Time (s)               43.519993271678686
(Previous) Eval Time (s)     11.659314261283726
Sample Time (s)              21.746665767394006
Epoch Time (s)               76.92597330035642
Total Train Time (s)         26940.81375456415
Epoch                        332
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:17:21.084888 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #332 | Epoch Duration: 81.51456022262573
2020-01-11 08:17:21.085124 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #332 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019133558
Z variance train             0.0042510764
KL Divergence                11.322966
KL Loss                      1.1322966
QF Loss                      93.17981
VF Loss                      247.99335
Policy Loss                  -1591.6161
Q Predictions Mean           1594.1105
Q Predictions Std            189.42323
Q Predictions Max            1786.3477
Q Predictions Min            282.13852
V Predictions Mean           1598.9525
V Predictions Std            192.1947
V Predictions Max            1808.4489
V Predictions Min            239.15216
Log Pis Mean                 -0.5786614
Log Pis Std                  1.6097333
Log Pis Max                  4.7855797
Log Pis Min                  -4.154455
Policy mu Mean               0.03525013
Policy mu Std                0.81994885
Policy mu Max                1.8901659
Policy mu Min                -3.266861
Policy log std Mean          -0.40471527
Policy log std Std           0.14772336
Policy log std Max           -0.007389039
Policy log std Min           -1.0415586
Z mean eval                  0.035123035
Z variance eval              0.005449222
total_rewards                [2376.95925875 1727.92656485 1381.89751511 1708.28232099 1110.67509813
 1742.71119996 3285.69449531 3079.01156616 1311.29533821  815.86015665]
total_rewards_mean           1854.031351412625
total_rewards_std            775.9560259390321
total_rewards_max            3285.6944953075113
total_rewards_min            815.860156647854
Number of train steps total  334000
Number of env steps total    1672000
Number of rollouts total     0
Train Time (s)               44.30104281893
(Previous) Eval Time (s)     16.247630076948553
Sample Time (s)              19.70622243359685
Epoch Time (s)               80.2548953294754
Total Train Time (s)         27023.80020328192
Epoch                        333
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:18:44.071073 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #333 | Epoch Duration: 82.9858021736145
2020-01-11 08:18:44.071200 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #333 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035016615
Z variance train             0.0054317787
KL Divergence                10.939215
KL Loss                      1.0939215
QF Loss                      123.84578
VF Loss                      126.34335
Policy Loss                  -1608.3978
Q Predictions Mean           1611.4829
Q Predictions Std            197.26456
Q Predictions Max            1790.915
Q Predictions Min            81.60528
V Predictions Mean           1615.0769
V Predictions Std            195.11288
V Predictions Max            1795.2749
V Predictions Min            155.31116
Log Pis Mean                 -0.42319593
Log Pis Std                  1.8539758
Log Pis Max                  6.038534
Log Pis Min                  -4.4164743
Policy mu Mean               0.008930002
Policy mu Std                0.8324524
Policy mu Max                2.4645295
Policy mu Min                -2.7712169
Policy log std Mean          -0.4105072
Policy log std Std           0.16605146
Policy log std Max           -0.061569378
Policy log std Min           -1.2516102
Z mean eval                  0.034831923
Z variance eval              0.0051335837
total_rewards                [ 943.23792395 1942.33073344  952.88650541 1010.58381569  820.97464591
  448.51634894 1007.63579127 1394.01425416 1710.69334429 1524.18651444]
total_rewards_mean           1175.5059877503459
total_rewards_std            430.9134123882593
total_rewards_max            1942.3307334440403
total_rewards_min            448.51634893900086
Number of train steps total  335000
Number of env steps total    1677000
Number of rollouts total     0
Train Time (s)               43.43440444115549
(Previous) Eval Time (s)     18.978283593896776
Sample Time (s)              19.882171478588134
Epoch Time (s)               82.2948595136404
Total Train Time (s)         27098.777397201397
Epoch                        334
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:19:59.050678 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #334 | Epoch Duration: 74.97938394546509
2020-01-11 08:19:59.050815 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #334 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03699854
Z variance train             0.0051426324
KL Divergence                11.028818
KL Loss                      1.1028818
QF Loss                      517.60144
VF Loss                      676.1959
Policy Loss                  -1614.8867
Q Predictions Mean           1621.9362
Q Predictions Std            163.49792
Q Predictions Max            1794.4316
Q Predictions Min            506.9538
V Predictions Mean           1598.7686
V Predictions Std            161.94786
V Predictions Max            1770.6869
V Predictions Min            507.07803
Log Pis Mean                 -0.5083604
Log Pis Std                  1.8826902
Log Pis Max                  6.87489
Log Pis Min                  -5.1070127
Policy mu Mean               0.05867836
Policy mu Std                0.8031593
Policy mu Max                2.0456777
Policy mu Min                -3.2384732
Policy log std Mean          -0.40559247
Policy log std Std           0.16191547
Policy log std Max           0.13876835
Policy log std Min           -1.4462572
Z mean eval                  0.014994006
Z variance eval              0.0057617845
total_rewards                [ 915.39527295 1082.42355672  870.71022253  949.61812627  776.06004613
  716.37733177 1224.13404445  948.20371712  925.59397956  927.39801005]
total_rewards_mean           933.5914307551014
total_rewards_std            135.4333607749352
total_rewards_max            1224.1340444511184
total_rewards_min            716.3773317670763
Number of train steps total  336000
Number of env steps total    1682000
Number of rollouts total     0
Train Time (s)               43.11377377901226
(Previous) Eval Time (s)     11.662600342184305
Sample Time (s)              21.745233917143196
Epoch Time (s)               76.52160803833976
Total Train Time (s)         27172.627932025585
Epoch                        335
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:21:12.905966 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #335 | Epoch Duration: 73.85504961013794
2020-01-11 08:21:12.906125 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #335 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014837032
Z variance train             0.0057516578
KL Divergence                10.663889
KL Loss                      1.066389
QF Loss                      330.52795
VF Loss                      134.37772
Policy Loss                  -1592.3864
Q Predictions Mean           1596.0164
Q Predictions Std            150.17372
Q Predictions Max            1792.9287
Q Predictions Min            531.13727
V Predictions Mean           1583.8398
V Predictions Std            148.11362
V Predictions Max            1784.8782
V Predictions Min            525.46246
Log Pis Mean                 -0.42256552
Log Pis Std                  1.5831581
Log Pis Max                  4.7776613
Log Pis Min                  -4.1446905
Policy mu Mean               -0.06392711
Policy mu Std                0.80811507
Policy mu Max                1.7265952
Policy mu Min                -2.951859
Policy log std Mean          -0.39565387
Policy log std Std           0.1606846
Policy log std Max           0.02311334
Policy log std Min           -1.2720339
Z mean eval                  0.034915935
Z variance eval              0.00509807
total_rewards                [1257.14844488  970.80494251 1064.18780746  775.00129315 1017.03838963
 1210.41768139 1626.00966138 3113.75955233  981.08353112 1006.42650921]
total_rewards_mean           1302.1877813073604
total_rewards_std            641.3563905093943
total_rewards_max            3113.7595523298664
total_rewards_min            775.0012931548617
Number of train steps total  337000
Number of env steps total    1687000
Number of rollouts total     0
Train Time (s)               43.91962854517624
(Previous) Eval Time (s)     8.995783212594688
Sample Time (s)              21.524741175118834
Epoch Time (s)               74.44015293288976
Total Train Time (s)         27251.693459875416
Epoch                        336
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:22:31.979171 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #336 | Epoch Duration: 79.07290863990784
2020-01-11 08:22:31.979362 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #336 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03487339
Z variance train             0.0051056272
KL Divergence                10.842577
KL Loss                      1.0842577
QF Loss                      769.6667
VF Loss                      97.27713
Policy Loss                  -1605.2633
Q Predictions Mean           1603.1724
Q Predictions Std            175.75754
Q Predictions Max            1789.1163
Q Predictions Min            41.536243
V Predictions Mean           1599.1262
V Predictions Std            176.12592
V Predictions Max            1788.601
V Predictions Min            -5.337884
Log Pis Mean                 -0.51305306
Log Pis Std                  1.7591677
Log Pis Max                  9.668308
Log Pis Min                  -4.8479643
Policy mu Mean               -0.0381669
Policy mu Std                0.8039585
Policy mu Max                1.7683108
Policy mu Min                -3.3680665
Policy log std Mean          -0.41152754
Policy log std Std           0.1673325
Policy log std Max           0.029325724
Policy log std Min           -1.7012882
Z mean eval                  0.024404129
Z variance eval              0.0055455063
total_rewards                [ 917.74992807  986.51007878 1080.73061938 2074.16446056  896.51830848
 1869.63004585  997.01776265 1406.29229018 1011.05292942  967.6282483 ]
total_rewards_mean           1220.72946716717
total_rewards_std            401.65857270468416
total_rewards_max            2074.1644605640413
total_rewards_min            896.518308481492
Number of train steps total  338000
Number of env steps total    1692000
Number of rollouts total     0
Train Time (s)               44.857825436163694
(Previous) Eval Time (s)     13.628277905285358
Sample Time (s)              21.841606095898896
Epoch Time (s)               80.32770943734795
Total Train Time (s)         27330.83136665076
Epoch                        337
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:23:51.119894 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #337 | Epoch Duration: 79.14038634300232
2020-01-11 08:23:51.120034 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #337 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024241263
Z variance train             0.005548147
KL Divergence                10.605716
KL Loss                      1.0605716
QF Loss                      98.773445
VF Loss                      110.49419
Policy Loss                  -1583.8966
Q Predictions Mean           1590.0161
Q Predictions Std            137.50146
Q Predictions Max            1779.9271
Q Predictions Min            660.0428
V Predictions Mean           1592.5577
V Predictions Std            138.66263
V Predictions Max            1783.5194
V Predictions Min            631.2348
Log Pis Mean                 -0.5394889
Log Pis Std                  1.633646
Log Pis Max                  5.5056825
Log Pis Min                  -4.354549
Policy mu Mean               -0.08165062
Policy mu Std                0.7941732
Policy mu Max                1.8152573
Policy mu Min                -3.3267996
Policy log std Mean          -0.4001753
Policy log std Std           0.16820814
Policy log std Max           0.019361585
Policy log std Min           -1.1431444
Z mean eval                  0.031405635
Z variance eval              0.005427887
total_rewards                [1194.66262961 1130.34946261 1650.13914083  917.63889337 1243.5072312
  819.09221943 1104.31694539  970.48717302 1034.47109053 1098.08102141]
total_rewards_mean           1116.2745807399529
total_rewards_std            215.34520343993154
total_rewards_max            1650.1391408309971
total_rewards_min            819.0922194303787
Number of train steps total  339000
Number of env steps total    1697000
Number of rollouts total     0
Train Time (s)               43.417569464072585
(Previous) Eval Time (s)     12.44071755791083
Sample Time (s)              22.827867821790278
Epoch Time (s)               78.68615484377369
Total Train Time (s)         27407.935516647063
Epoch                        338
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:25:08.232351 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #338 | Epoch Duration: 77.11222076416016
2020-01-11 08:25:08.232483 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #338 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031178284
Z variance train             0.005425027
KL Divergence                10.713856
KL Loss                      1.0713856
QF Loss                      446.79977
VF Loss                      424.51706
Policy Loss                  -1597.7517
Q Predictions Mean           1596.261
Q Predictions Std            162.92038
Q Predictions Max            1783.6855
Q Predictions Min            531.98865
V Predictions Mean           1591.622
V Predictions Std            167.1432
V Predictions Max            1794.3945
V Predictions Min            525.7832
Log Pis Mean                 -0.69855607
Log Pis Std                  1.9547533
Log Pis Max                  12.439182
Log Pis Min                  -4.9718394
Policy mu Mean               0.02571403
Policy mu Std                0.81130713
Policy mu Max                2.7160184
Policy mu Min                -3.4907193
Policy log std Mean          -0.38138768
Policy log std Std           0.17439073
Policy log std Max           0.08469483
Policy log std Min           -1.4843841
Z mean eval                  0.041306816
Z variance eval              0.0063190074
total_rewards                [2375.93258552  933.56581059  786.55314478 2004.20326746 1712.33582174
 1214.76729617 1056.82348972 1943.04077834 1207.21975585  797.77988684]
total_rewards_mean           1403.222183702624
total_rewards_std            534.3820341233657
total_rewards_max            2375.932585521153
total_rewards_min            786.5531447779603
Number of train steps total  340000
Number of env steps total    1702000
Number of rollouts total     0
Train Time (s)               44.19133966229856
(Previous) Eval Time (s)     10.866542446892709
Sample Time (s)              21.669571340084076
Epoch Time (s)               76.72745344927534
Total Train Time (s)         27487.91418771539
Epoch                        339
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:26:28.212034 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #339 | Epoch Duration: 79.97945618629456
2020-01-11 08:26:28.212155 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #339 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.041179504
Z variance train             0.0063129314
KL Divergence                10.476453
KL Loss                      1.0476453
QF Loss                      146.35614
VF Loss                      84.9545
Policy Loss                  -1601.4167
Q Predictions Mean           1603.0251
Q Predictions Std            137.28925
Q Predictions Max            1773.3228
Q Predictions Min            487.239
V Predictions Mean           1601.5908
V Predictions Std            136.21518
V Predictions Max            1767.0872
V Predictions Min            483.81534
Log Pis Mean                 -0.76502657
Log Pis Std                  1.5485584
Log Pis Max                  4.2740474
Log Pis Min                  -5.329573
Policy mu Mean               0.010869001
Policy mu Std                0.7745526
Policy mu Max                1.6379046
Policy mu Min                -2.290373
Policy log std Mean          -0.36612344
Policy log std Std           0.1602865
Policy log std Max           0.064453274
Policy log std Min           -1.3303021
Z mean eval                  0.021173839
Z variance eval              0.0060393754
total_rewards                [1480.07040757  906.09447297 1131.58674815 1505.28762619 1112.0339265
 1746.06864973 1230.92578505  959.77966234 1314.29325226 1431.21232406]
total_rewards_mean           1281.7352854828196
total_rewards_std            250.40118455064717
total_rewards_max            1746.0686497318734
total_rewards_min            906.0944729698882
Number of train steps total  341000
Number of env steps total    1707000
Number of rollouts total     0
Train Time (s)               43.445199297741055
(Previous) Eval Time (s)     14.118310886900872
Sample Time (s)              21.63758152909577
Epoch Time (s)               79.2010917137377
Total Train Time (s)         27565.7686310485
Epoch                        340
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:27:46.070149 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #340 | Epoch Duration: 77.85789155960083
2020-01-11 08:27:46.070311 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #340 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021744091
Z variance train             0.00603799
KL Divergence                10.458967
KL Loss                      1.0458968
QF Loss                      104.660645
VF Loss                      112.485
Policy Loss                  -1587.8466
Q Predictions Mean           1587.7596
Q Predictions Std            183.90051
Q Predictions Max            1791.5219
Q Predictions Min            39.807438
V Predictions Mean           1585.7831
V Predictions Std            183.65622
V Predictions Max            1787.3457
V Predictions Min            12.375993
Log Pis Mean                 -0.6906029
Log Pis Std                  1.7183712
Log Pis Max                  5.04734
Log Pis Min                  -4.059283
Policy mu Mean               -0.00073620304
Policy mu Std                0.79430073
Policy mu Max                2.4388828
Policy mu Min                -3.410467
Policy log std Mean          -0.41099653
Policy log std Std           0.18163012
Policy log std Max           0.04012531
Policy log std Min           -1.1709862
Z mean eval                  0.0150053445
Z variance eval              0.0071214996
total_rewards                [1020.98699732 3359.22098215 2429.29165837 1274.1085958  1000.9477961
 1211.94453911 1576.90625711 1800.24279467 1801.63413634 1011.21664973]
total_rewards_mean           1648.6500406695056
total_rewards_std            716.7830465836158
total_rewards_max            3359.2209821474553
total_rewards_min            1000.9477960967886
Number of train steps total  342000
Number of env steps total    1712000
Number of rollouts total     0
Train Time (s)               43.51511581707746
(Previous) Eval Time (s)     12.774838216137141
Sample Time (s)              22.294963569846004
Epoch Time (s)               78.5849176030606
Total Train Time (s)         27646.951120391954
Epoch                        341
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:29:07.254816 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #341 | Epoch Duration: 81.18438529968262
2020-01-11 08:29:07.254937 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #341 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0154912155
Z variance train             0.00710711
KL Divergence                10.233053
KL Loss                      1.0233053
QF Loss                      114.946754
VF Loss                      86.841354
Policy Loss                  -1612.1711
Q Predictions Mean           1614.8743
Q Predictions Std            164.36017
Q Predictions Max            1788.4463
Q Predictions Min            386.5205
V Predictions Mean           1618.1792
V Predictions Std            163.93875
V Predictions Max            1789.8406
V Predictions Min            386.8262
Log Pis Mean                 -0.64663
Log Pis Std                  1.7995462
Log Pis Max                  10.458513
Log Pis Min                  -4.415206
Policy mu Mean               0.047106136
Policy mu Std                0.77694446
Policy mu Max                2.3979356
Policy mu Min                -3.0403378
Policy log std Mean          -0.37965754
Policy log std Std           0.15221278
Policy log std Max           0.014823079
Policy log std Min           -1.1644688
Z mean eval                  0.024828658
Z variance eval              0.007428441
total_rewards                [1044.05790675 3276.27307898 1687.65829174 1123.0070522  2449.94275909
  962.63932256 2242.19995999 1924.15176715 1114.78734434 1402.40907857]
total_rewards_mean           1722.7126561365847
total_rewards_std            715.8341506277267
total_rewards_max            3276.2730789785096
total_rewards_min            962.6393225584937
Number of train steps total  343000
Number of env steps total    1717000
Number of rollouts total     0
Train Time (s)               44.463441140949726
(Previous) Eval Time (s)     15.374061487615108
Sample Time (s)              21.39814644586295
Epoch Time (s)               81.23564907442778
Total Train Time (s)         27730.348225569818
Epoch                        342
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:30:30.653997 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #342 | Epoch Duration: 83.39896845817566
2020-01-11 08:30:30.654121 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #342 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02444512
Z variance train             0.007431204
KL Divergence                10.243774
KL Loss                      1.0243775
QF Loss                      224.87471
VF Loss                      221.97581
Policy Loss                  -1580.0383
Q Predictions Mean           1581.6226
Q Predictions Std            182.18886
Q Predictions Max            1771.6907
Q Predictions Min            35.646313
V Predictions Mean           1581.4277
V Predictions Std            185.50201
V Predictions Max            1770.7695
V Predictions Min            58.87959
Log Pis Mean                 -0.5431438
Log Pis Std                  2.0243533
Log Pis Max                  10.182942
Log Pis Min                  -6.2565174
Policy mu Mean               -0.1407253
Policy mu Std                0.7836602
Policy mu Max                2.0109603
Policy mu Min                -3.2290077
Policy log std Mean          -0.37159717
Policy log std Std           0.16669385
Policy log std Max           0.3466752
Policy log std Min           -1.1585351
Z mean eval                  0.019699028
Z variance eval              0.0078628715
total_rewards                [1847.32394625  933.11261858 1529.59386444 1848.30491166 1615.09621201
  838.77993866 1234.51119477 1243.54532585  753.42917219  963.55717602]
total_rewards_mean           1280.7254360438208
total_rewards_std            389.25895090856073
total_rewards_max            1848.3049116577147
total_rewards_min            753.429172193992
Number of train steps total  344000
Number of env steps total    1722000
Number of rollouts total     0
Train Time (s)               43.74641282716766
(Previous) Eval Time (s)     17.537122837733477
Sample Time (s)              22.030811372678727
Epoch Time (s)               83.31434703757986
Total Train Time (s)         27808.461326497607
Epoch                        343
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:31:48.770761 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #343 | Epoch Duration: 78.11654877662659
2020-01-11 08:31:48.770882 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #343 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019882578
Z variance train             0.007858537
KL Divergence                10.07112
KL Loss                      1.007112
QF Loss                      174.23111
VF Loss                      98.96109
Policy Loss                  -1589.1398
Q Predictions Mean           1589.2378
Q Predictions Std            148.97635
Q Predictions Max            1770.6781
Q Predictions Min            501.95447
V Predictions Mean           1587.5707
V Predictions Std            146.60562
V Predictions Max            1772.8624
V Predictions Min            519.41364
Log Pis Mean                 -0.46038952
Log Pis Std                  1.6133666
Log Pis Max                  4.8936896
Log Pis Min                  -3.3402863
Policy mu Mean               -0.092432715
Policy mu Std                0.808015
Policy mu Max                2.6536894
Policy mu Min                -3.2707055
Policy log std Mean          -0.44272664
Policy log std Std           0.18584602
Policy log std Max           -0.028314114
Policy log std Min           -1.5843875
Z mean eval                  0.021334548
Z variance eval              0.0071939984
total_rewards                [1528.29994399 1326.00371899 1786.24243263 1877.70921925 1458.01435488
 1475.05359651 1055.47592827 1036.42521679 1295.24690609  951.66566643]
total_rewards_mean           1379.013698383144
total_rewards_std            294.4113523011848
total_rewards_max            1877.709219245492
total_rewards_min            951.6656664340555
Number of train steps total  345000
Number of env steps total    1727000
Number of rollouts total     0
Train Time (s)               43.97850830713287
(Previous) Eval Time (s)     12.339085289742798
Sample Time (s)              21.98027894180268
Epoch Time (s)               78.29787253867835
Total Train Time (s)         27887.595183409285
Epoch                        344
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:33:07.911184 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #344 | Epoch Duration: 79.14020943641663
2020-01-11 08:33:07.911311 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #344 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021220425
Z variance train             0.0072005554
KL Divergence                10.191629
KL Loss                      1.019163
QF Loss                      85.16434
VF Loss                      30.909552
Policy Loss                  -1594.9094
Q Predictions Mean           1595.0956
Q Predictions Std            132.57875
Q Predictions Max            1776.6771
Q Predictions Min            690.12573
V Predictions Mean           1595.6458
V Predictions Std            131.93654
V Predictions Max            1781.0067
V Predictions Min            699.2912
Log Pis Mean                 -0.49883506
Log Pis Std                  1.8267933
Log Pis Max                  9.493164
Log Pis Min                  -5.2845016
Policy mu Mean               0.038452085
Policy mu Std                0.80742365
Policy mu Max                1.9577341
Policy mu Min                -3.6971316
Policy log std Mean          -0.4301634
Policy log std Std           0.156026
Policy log std Max           -0.060588807
Policy log std Min           -1.1696011
Z mean eval                  0.02739026
Z variance eval              0.0076830303
total_rewards                [1273.72368743 1006.69757587 1374.05245688  999.46278238 1197.91052168
  973.2554149  1140.36668752  937.9984909  1152.77460481 1195.71927446]
total_rewards_mean           1125.1961496821907
total_rewards_std            135.359240732664
total_rewards_max            1374.0524568763333
total_rewards_min            937.998490898677
Number of train steps total  346000
Number of env steps total    1732000
Number of rollouts total     0
Train Time (s)               44.0599802271463
(Previous) Eval Time (s)     13.181172438897192
Sample Time (s)              21.661219909321517
Epoch Time (s)               78.902372575365
Total Train Time (s)         27964.65313700633
Epoch                        345
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:34:24.970947 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #345 | Epoch Duration: 77.05954194068909
2020-01-11 08:34:24.971072 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #345 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027502334
Z variance train             0.00768092
KL Divergence                10.066092
KL Loss                      1.0066092
QF Loss                      101.00949
VF Loss                      132.71631
Policy Loss                  -1589.8357
Q Predictions Mean           1587.61
Q Predictions Std            205.3102
Q Predictions Max            1771.6892
Q Predictions Min            6.2859073
V Predictions Mean           1585.2499
V Predictions Std            204.58905
V Predictions Max            1773.2428
V Predictions Min            5.8638206
Log Pis Mean                 -0.37496653
Log Pis Std                  1.7517602
Log Pis Max                  5.7854934
Log Pis Min                  -4.7977786
Policy mu Mean               0.24616288
Policy mu Std                0.80156285
Policy mu Max                2.0081763
Policy mu Min                -3.212401
Policy log std Mean          -0.4507699
Policy log std Std           0.15874392
Policy log std Max           0.0524078
Policy log std Min           -1.2119491
Z mean eval                  0.014397221
Z variance eval              0.006737438
total_rewards                [1029.75285437 1180.17984423 1290.57672944 1170.61606414  949.6064626
  646.78809533 1574.00712291 1788.63892336 1715.11225979  928.35688732]
total_rewards_mean           1227.3635243489525
total_rewards_std            350.0292745057058
total_rewards_max            1788.6389233602551
total_rewards_min            646.7880953258061
Number of train steps total  347000
Number of env steps total    1737000
Number of rollouts total     0
Train Time (s)               44.45746978092939
(Previous) Eval Time (s)     11.338087378069758
Sample Time (s)              22.069446576293558
Epoch Time (s)               77.8650037352927
Total Train Time (s)         28043.34297024645
Epoch                        346
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:35:43.663466 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #346 | Epoch Duration: 78.6922972202301
2020-01-11 08:35:43.663592 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #346 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014604432
Z variance train             0.0067257173
KL Divergence                10.376923
KL Loss                      1.0376923
QF Loss                      73.51094
VF Loss                      20.216423
Policy Loss                  -1613.4481
Q Predictions Mean           1611.4307
Q Predictions Std            166.27791
Q Predictions Max            1775.8662
Q Predictions Min            8.582314
V Predictions Mean           1611.477
V Predictions Std            165.97757
V Predictions Max            1777.7196
V Predictions Min            4.7851596
Log Pis Mean                 -0.47924447
Log Pis Std                  1.7264307
Log Pis Max                  5.1463747
Log Pis Min                  -5.9402533
Policy mu Mean               0.10737754
Policy mu Std                0.77891725
Policy mu Max                1.7867548
Policy mu Min                -2.8700786
Policy log std Mean          -0.4238793
Policy log std Std           0.15658718
Policy log std Max           0.02021426
Policy log std Min           -1.3762774
Z mean eval                  0.017376183
Z variance eval              0.0069610826
total_rewards                [1228.57691677  984.69125795 2212.66103919 1818.85227957  966.65353112
 1022.09554824 1196.73264262 1485.00956355 1254.87489687 2968.18017008]
total_rewards_mean           1513.8327845969377
total_rewards_std            613.8028116203667
total_rewards_max            2968.1801700822343
total_rewards_min            966.6535311231592
Number of train steps total  348000
Number of env steps total    1742000
Number of rollouts total     0
Train Time (s)               43.92891082307324
(Previous) Eval Time (s)     12.16512429015711
Sample Time (s)              21.132530007511377
Epoch Time (s)               77.22656512074172
Total Train Time (s)         28123.17720273882
Epoch                        347
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:37:03.500229 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #347 | Epoch Duration: 79.83654403686523
2020-01-11 08:37:03.500356 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #347 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018789278
Z variance train             0.0069615035
KL Divergence                10.139203
KL Loss                      1.0139203
QF Loss                      93.52893
VF Loss                      130.09785
Policy Loss                  -1592.5536
Q Predictions Mean           1588.874
Q Predictions Std            169.5438
Q Predictions Max            1782.6272
Q Predictions Min            567.03973
V Predictions Mean           1585.5956
V Predictions Std            170.45163
V Predictions Max            1774.7753
V Predictions Min            536.3977
Log Pis Mean                 -0.45776048
Log Pis Std                  1.7161089
Log Pis Max                  8.61013
Log Pis Min                  -4.4697776
Policy mu Mean               0.15444066
Policy mu Std                0.81001836
Policy mu Max                2.702063
Policy mu Min                -3.474629
Policy log std Mean          -0.41526365
Policy log std Std           0.14999254
Policy log std Max           -0.009844005
Policy log std Min           -1.2070589
Z mean eval                  0.042315852
Z variance eval              0.0062444275
total_rewards                [ 653.57558619 1324.30275393  636.53689688 3336.09447539 1283.19893173
  992.93611702  763.26077194 1221.24020705 1763.64860849  904.20341097]
total_rewards_mean           1287.8997759588774
total_rewards_std            759.1668179276083
total_rewards_max            3336.0944753922076
total_rewards_min            636.5368968783102
Number of train steps total  349000
Number of env steps total    1747000
Number of rollouts total     0
Train Time (s)               43.41631590202451
(Previous) Eval Time (s)     14.77483515162021
Sample Time (s)              21.844357011374086
Epoch Time (s)               80.0355080650188
Total Train Time (s)         28200.64631734509
Epoch                        348
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:38:20.973230 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #348 | Epoch Duration: 77.4727714061737
2020-01-11 08:38:20.973389 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #348 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.042428236
Z variance train             0.006243805
KL Divergence                10.355272
KL Loss                      1.0355272
QF Loss                      54.75563
VF Loss                      59.537918
Policy Loss                  -1628.1172
Q Predictions Mean           1627.5743
Q Predictions Std            140.33163
Q Predictions Max            1813.6313
Q Predictions Min            467.72824
V Predictions Mean           1627.3604
V Predictions Std            138.93208
V Predictions Max            1813.4497
V Predictions Min            473.07086
Log Pis Mean                 -0.5300249
Log Pis Std                  1.676555
Log Pis Max                  9.069103
Log Pis Min                  -4.6234617
Policy mu Mean               0.06861036
Policy mu Std                0.81874937
Policy mu Max                2.6372194
Policy mu Min                -4.189261
Policy log std Mean          -0.4195534
Policy log std Std           0.18051879
Policy log std Max           0.052947313
Policy log std Min           -1.6066146
Z mean eval                  0.018298116
Z variance eval              0.0065164575
total_rewards                [1127.99436839  856.17905462 1924.25687832 1231.32859065  859.61691715
 1203.56183486 1577.19250113  958.98819014 1692.58421942  858.77550175]
total_rewards_mean           1229.0478056425934
total_rewards_std            362.7391605976414
total_rewards_max            1924.256878319735
total_rewards_min            856.1790546225931
Number of train steps total  350000
Number of env steps total    1752000
Number of rollouts total     0
Train Time (s)               44.686848788987845
(Previous) Eval Time (s)     12.211845832876861
Sample Time (s)              21.82902750186622
Epoch Time (s)               78.72772212373093
Total Train Time (s)         28278.531265412457
Epoch                        349
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:39:38.861634 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #349 | Epoch Duration: 77.88811826705933
2020-01-11 08:39:38.861791 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #349 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018191224
Z variance train             0.006509534
KL Divergence                10.4904585
KL Loss                      1.0490459
QF Loss                      275.0641
VF Loss                      89.58978
Policy Loss                  -1600.0582
Q Predictions Mean           1603.8887
Q Predictions Std            154.42426
Q Predictions Max            1780.7684
Q Predictions Min            609.1187
V Predictions Mean           1593.3394
V Predictions Std            152.57953
V Predictions Max            1762.645
V Predictions Min            600.74304
Log Pis Mean                 -0.5721728
Log Pis Std                  1.79665
Log Pis Max                  8.020449
Log Pis Min                  -4.659837
Policy mu Mean               0.054226458
Policy mu Std                0.81052035
Policy mu Max                2.9194357
Policy mu Min                -3.2261894
Policy log std Mean          -0.40195206
Policy log std Std           0.15950727
Policy log std Max           0.015394688
Policy log std Min           -1.1706173
Z mean eval                  0.04193222
Z variance eval              0.0063886433
total_rewards                [2535.61084968 1233.2080621   824.30685947  889.9116637  2998.46562534
 1572.37665106 1305.19263831 1227.32638323  843.06267535 1338.24958988]
total_rewards_mean           1476.7710998134366
total_rewards_std            691.9327433640453
total_rewards_max            2998.465625344248
total_rewards_min            824.3068594691922
Number of train steps total  351000
Number of env steps total    1757000
Number of rollouts total     0
Train Time (s)               44.725860820151865
(Previous) Eval Time (s)     11.371986582875252
Sample Time (s)              22.648360586259514
Epoch Time (s)               78.74620798928663
Total Train Time (s)         28360.596563053317
Epoch                        350
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:41:00.931919 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #350 | Epoch Duration: 82.07001113891602
2020-01-11 08:41:00.932050 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #350 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043152004
Z variance train             0.0063698897
KL Divergence                10.322041
KL Loss                      1.032204
QF Loss                      186.89767
VF Loss                      181.0143
Policy Loss                  -1602.4081
Q Predictions Mean           1603.8108
Q Predictions Std            135.55106
Q Predictions Max            1768.8566
Q Predictions Min            794.874
V Predictions Mean           1591.1843
V Predictions Std            135.11026
V Predictions Max            1762.875
V Predictions Min            788.0754
Log Pis Mean                 -0.6601909
Log Pis Std                  1.6651907
Log Pis Max                  4.093054
Log Pis Min                  -4.6721296
Policy mu Mean               0.057092626
Policy mu Std                0.79546577
Policy mu Max                1.9747661
Policy mu Min                -2.3495634
Policy log std Mean          -0.38996148
Policy log std Std           0.16740867
Policy log std Max           0.36742878
Policy log std Min           -1.1390752
Z mean eval                  0.039121285
Z variance eval              0.0069284057
total_rewards                [1162.79204579 3047.1768473  1336.20502835 1343.01037129 3433.18802065
 1659.2797737  1198.59948893 3419.23976521 1559.14376489 1831.21445478]
total_rewards_mean           1998.9849560890289
total_rewards_std            878.5892434655137
total_rewards_max            3433.188020649782
total_rewards_min            1162.7920457927296
Number of train steps total  352000
Number of env steps total    1762000
Number of rollouts total     0
Train Time (s)               44.23676648689434
(Previous) Eval Time (s)     14.695552721619606
Sample Time (s)              21.591566252987832
Epoch Time (s)               80.52388546150178
Total Train Time (s)         28445.410461383406
Epoch                        351
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:42:25.751566 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #351 | Epoch Duration: 84.81936836242676
2020-01-11 08:42:25.751872 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #351 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03923536
Z variance train             0.0069308034
KL Divergence                10.273788
KL Loss                      1.0273789
QF Loss                      95.75261
VF Loss                      55.642345
Policy Loss                  -1614.8427
Q Predictions Mean           1616.2163
Q Predictions Std            136.03519
Q Predictions Max            1804.5637
Q Predictions Min            840.33563
V Predictions Mean           1615.7014
V Predictions Std            133.23334
V Predictions Max            1798.3062
V Predictions Min            821.5848
Log Pis Mean                 -0.56479037
Log Pis Std                  1.7136415
Log Pis Max                  5.728731
Log Pis Min                  -7.4427676
Policy mu Mean               -0.012170848
Policy mu Std                0.8045047
Policy mu Max                2.0235767
Policy mu Min                -2.5758862
Policy log std Mean          -0.40706
Policy log std Std           0.16817878
Policy log std Max           -0.03177166
Policy log std Min           -1.3173261
Z mean eval                  0.00875388
Z variance eval              0.0067572743
total_rewards                [2453.81249131 2147.55683321 1550.17891261 1882.83117145  958.69274475
 1058.1776683  1890.19773052 1277.40485397 1314.8316787  1906.80265278]
total_rewards_mean           1644.0486737618044
total_rewards_std            464.8079858031517
total_rewards_max            2453.8124913149454
total_rewards_min            958.6927447461505
Number of train steps total  353000
Number of env steps total    1767000
Number of rollouts total     0
Train Time (s)               44.613380334340036
(Previous) Eval Time (s)     18.990759515203536
Sample Time (s)              22.356466566678137
Epoch Time (s)               85.96060641622171
Total Train Time (s)         28527.893898531795
Epoch                        352
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:43:48.242851 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #352 | Epoch Duration: 82.49067997932434
2020-01-11 08:43:48.243161 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #352 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.00892235
Z variance train             0.006759754
KL Divergence                10.541372
KL Loss                      1.0541372
QF Loss                      123.72356
VF Loss                      24.135435
Policy Loss                  -1585.1403
Q Predictions Mean           1583.0706
Q Predictions Std            154.56432
Q Predictions Max            1769.4108
Q Predictions Min            457.50253
V Predictions Mean           1584.9236
V Predictions Std            154.1775
V Predictions Max            1780.2499
V Predictions Min            467.67862
Log Pis Mean                 -0.6262531
Log Pis Std                  1.7743201
Log Pis Max                  5.246772
Log Pis Min                  -7.5511317
Policy mu Mean               0.084856786
Policy mu Std                0.77382594
Policy mu Max                1.7648224
Policy mu Min                -3.1739118
Policy log std Mean          -0.4039204
Policy log std Std           0.16620316
Policy log std Max           -0.0752964
Policy log std Min           -1.1626266
Z mean eval                  0.042515486
Z variance eval              0.0084383255
total_rewards                [2010.40526378 3266.89867921 3237.28159067 3251.66029163 2264.32013473
 1175.98845202 3250.27753121 1032.1567303   960.40273655 2404.16365714]
total_rewards_mean           2285.3555067228363
total_rewards_std            915.4926268124321
total_rewards_max            3266.898679207382
total_rewards_min            960.4027365484687
Number of train steps total  354000
Number of env steps total    1772000
Number of rollouts total     0
Train Time (s)               43.185190978925675
(Previous) Eval Time (s)     15.520585247781128
Sample Time (s)              22.796069382689893
Epoch Time (s)               81.5018456093967
Total Train Time (s)         28614.93135658838
Epoch                        353
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:45:15.285829 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #353 | Epoch Duration: 87.04242181777954
2020-01-11 08:45:15.286079 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #353 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04312618
Z variance train             0.008436238
KL Divergence                10.138221
KL Loss                      1.0138221
QF Loss                      130.6193
VF Loss                      134.9566
Policy Loss                  -1577.4794
Q Predictions Mean           1578.8933
Q Predictions Std            184.33914
Q Predictions Max            1753.3523
Q Predictions Min            270.03333
V Predictions Mean           1580.6188
V Predictions Std            180.51712
V Predictions Max            1758.05
V Predictions Min            281.93787
Log Pis Mean                 -0.50246894
Log Pis Std                  1.876864
Log Pis Max                  9.367413
Log Pis Min                  -5.0078125
Policy mu Mean               0.056813765
Policy mu Std                0.84102845
Policy mu Max                2.6188653
Policy mu Min                -2.9974275
Policy log std Mean          -0.41180328
Policy log std Std           0.17283793
Policy log std Max           -0.04889451
Policy log std Min           -1.394753
Z mean eval                  0.02035668
Z variance eval              0.0077701346
total_rewards                [1121.72703891 1886.18612286 3330.16366889 3323.57435994 3290.22900737
 3397.5993262  2382.38018825 1653.15262866 2755.17754442 1541.21368594]
total_rewards_mean           2468.1403571429464
total_rewards_std            823.3600674244904
total_rewards_max            3397.5993262011675
total_rewards_min            1121.727038906157
Number of train steps total  355000
Number of env steps total    1777000
Number of rollouts total     0
Train Time (s)               44.193287276197225
(Previous) Eval Time (s)     21.06090047582984
Sample Time (s)              22.13536772504449
Epoch Time (s)               87.38955547707155
Total Train Time (s)         28705.685515010264
Epoch                        354
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:46:46.043629 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #354 | Epoch Duration: 90.75737833976746
2020-01-11 08:46:46.043754 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #354 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0197987
Z variance train             0.007765443
KL Divergence                10.295045
KL Loss                      1.0295045
QF Loss                      234.80728
VF Loss                      164.6467
Policy Loss                  -1591.7133
Q Predictions Mean           1591.3135
Q Predictions Std            163.07292
Q Predictions Max            1766.3218
Q Predictions Min            400.31693
V Predictions Mean           1597.1533
V Predictions Std            165.66182
V Predictions Max            1776.8312
V Predictions Min            350.45346
Log Pis Mean                 -0.7465694
Log Pis Std                  1.5974731
Log Pis Max                  7.1958156
Log Pis Min                  -4.524844
Policy mu Mean               -0.003580169
Policy mu Std                0.76287955
Policy mu Max                1.8131979
Policy mu Min                -3.2414033
Policy log std Mean          -0.37099528
Policy log std Std           0.15726008
Policy log std Max           -0.03167036
Policy log std Min           -1.1858999
Z mean eval                  0.028544087
Z variance eval              0.007873349
total_rewards                [1277.98894449 2438.76923343  940.83655549 3354.79536053 1626.35615938
 1516.2362539  2519.28751033 3311.17591225 1854.98465787 2058.65555642]
total_rewards_mean           2089.9086144090134
total_rewards_std            773.1254285580987
total_rewards_max            3354.7953605304883
total_rewards_min            940.8365554854214
Number of train steps total  356000
Number of env steps total    1782000
Number of rollouts total     0
Train Time (s)               44.31179168401286
(Previous) Eval Time (s)     24.428494095802307
Sample Time (s)              20.26468313066289
Epoch Time (s)               89.00496891047806
Total Train Time (s)         28791.28622760577
Epoch                        355
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:48:11.647751 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #355 | Epoch Duration: 85.60388398170471
2020-01-11 08:48:11.647934 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #355 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028395634
Z variance train             0.007870117
KL Divergence                10.458557
KL Loss                      1.0458558
QF Loss                      47.880234
VF Loss                      29.496447
Policy Loss                  -1573.3702
Q Predictions Mean           1571.6842
Q Predictions Std            158.07666
Q Predictions Max            1746.9814
Q Predictions Min            600.25116
V Predictions Mean           1572.0981
V Predictions Std            159.00812
V Predictions Max            1742.3313
V Predictions Min            587.5658
Log Pis Mean                 -0.5416445
Log Pis Std                  1.6105772
Log Pis Max                  5.4338007
Log Pis Min                  -4.836663
Policy mu Mean               -0.004462477
Policy mu Std                0.8194249
Policy mu Max                1.827117
Policy mu Min                -3.0893278
Policy log std Mean          -0.39591646
Policy log std Std           0.15241535
Policy log std Max           -0.051104397
Policy log std Min           -1.1531699
Z mean eval                  0.04007045
Z variance eval              0.0073118866
total_rewards                [1268.14346231  942.94183094  764.06704775 1018.10601898  786.49321435
 1357.83612949  937.15049971  885.14438102  752.14226379  993.15992631]
total_rewards_mean           970.5184774661602
total_rewards_std            193.57455803934192
total_rewards_max            1357.8361294939605
total_rewards_min            752.1422637941097
Number of train steps total  357000
Number of env steps total    1787000
Number of rollouts total     0
Train Time (s)               44.58253805199638
(Previous) Eval Time (s)     21.027162682730705
Sample Time (s)              21.523280145134777
Epoch Time (s)               87.13298087986186
Total Train Time (s)         28867.178739712108
Epoch                        356
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:49:27.545069 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #356 | Epoch Duration: 75.89698457717896
2020-01-11 08:49:27.545227 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #356 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03986578
Z variance train             0.0073238597
KL Divergence                10.575025
KL Loss                      1.0575025
QF Loss                      152.98413
VF Loss                      134.01915
Policy Loss                  -1606.8485
Q Predictions Mean           1608.2212
Q Predictions Std            194.5713
Q Predictions Max            1799.8644
Q Predictions Min            9.719782
V Predictions Mean           1611.2916
V Predictions Std            193.23132
V Predictions Max            1803.0863
V Predictions Min            -13.606516
Log Pis Mean                 -0.3796136
Log Pis Std                  1.738003
Log Pis Max                  5.440524
Log Pis Min                  -5.3419447
Policy mu Mean               0.19842303
Policy mu Std                0.8431867
Policy mu Max                3.5111136
Policy mu Min                -2.988626
Policy log std Mean          -0.42456007
Policy log std Std           0.14578283
Policy log std Max           -0.088208675
Policy log std Min           -1.078156
Z mean eval                  0.037643023
Z variance eval              0.007304775
total_rewards                [1177.77869226 1026.94143552 1136.50389924 1013.57018021 2695.23848957
 1919.76452368 1108.36222264 1293.06802904 1288.18774711 1023.78968724]
total_rewards_mean           1368.3204906513793
total_rewards_std            509.47015747965014
total_rewards_max            2695.2384895707596
total_rewards_min            1013.5701802146309
Number of train steps total  358000
Number of env steps total    1792000
Number of rollouts total     0
Train Time (s)               44.24296108307317
(Previous) Eval Time (s)     9.790921948850155
Sample Time (s)              22.398806403391063
Epoch Time (s)               76.43268943531439
Total Train Time (s)         28946.6980020809
Epoch                        357
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:50:47.069012 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #357 | Epoch Duration: 79.52364993095398
2020-01-11 08:50:47.069205 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #357 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037584506
Z variance train             0.007308217
KL Divergence                10.549411
KL Loss                      1.054941
QF Loss                      105.3882
VF Loss                      45.000153
Policy Loss                  -1583.5032
Q Predictions Mean           1584.2803
Q Predictions Std            145.68044
Q Predictions Max            1758.134
Q Predictions Min            615.6424
V Predictions Mean           1580.0524
V Predictions Std            143.49965
V Predictions Max            1749.0297
V Predictions Min            652.4477
Log Pis Mean                 -0.3494424
Log Pis Std                  1.8303982
Log Pis Max                  8.52174
Log Pis Min                  -5.7148075
Policy mu Mean               0.118113905
Policy mu Std                0.8443442
Policy mu Max                2.9367845
Policy mu Min                -3.5164096
Policy log std Mean          -0.43202114
Policy log std Std           0.16096775
Policy log std Max           -0.06239444
Policy log std Min           -1.667022
Z mean eval                  0.06033958
Z variance eval              0.007021744
total_rewards                [1226.31954072 1251.23855602 1038.29173785 1063.68629577 2088.73648847
 1695.01856479 1616.51925372 1073.06340871 1068.26688041 1650.0147204 ]
total_rewards_mean           1377.115544685636
total_rewards_std            343.3240320593048
total_rewards_max            2088.736488471719
total_rewards_min            1038.291737850377
Number of train steps total  359000
Number of env steps total    1797000
Number of rollouts total     0
Train Time (s)               44.4883395251818
(Previous) Eval Time (s)     12.881631926167756
Sample Time (s)              22.33604956138879
Epoch Time (s)               79.70602101273835
Total Train Time (s)         29026.80068911938
Epoch                        358
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:52:07.173265 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #358 | Epoch Duration: 80.10392117500305
2020-01-11 08:52:07.173388 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #358 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06032131
Z variance train             0.0070244437
KL Divergence                10.6537695
KL Loss                      1.065377
QF Loss                      723.7007
VF Loss                      157.01848
Policy Loss                  -1561.3312
Q Predictions Mean           1565.813
Q Predictions Std            210.82368
Q Predictions Max            1776.4031
Q Predictions Min            32.89304
V Predictions Mean           1563.5713
V Predictions Std            218.44023
V Predictions Max            1765.0751
V Predictions Min            20.84277
Log Pis Mean                 -0.76426244
Log Pis Std                  1.7073606
Log Pis Max                  11.548962
Log Pis Min                  -4.8861566
Policy mu Mean               0.016624926
Policy mu Std                0.7785999
Policy mu Max                3.5071523
Policy mu Min                -3.3537486
Policy log std Mean          -0.4320736
Policy log std Std           0.15766408
Policy log std Max           -0.01808849
Policy log std Min           -1.2878377
Z mean eval                  0.019901745
Z variance eval              0.006597714
total_rewards                [1129.74554137 1011.79622427  967.20117807 1409.10475472 1001.67796014
 1281.45180111 1745.42678482 1169.70153107 1318.05234053  980.72543486]
total_rewards_mean           1201.4883550975292
total_rewards_std            233.37660129559092
total_rewards_max            1745.4267848222953
total_rewards_min            967.2011780703546
Number of train steps total  360000
Number of env steps total    1802000
Number of rollouts total     0
Train Time (s)               44.42237682035193
(Previous) Eval Time (s)     13.279280080925673
Sample Time (s)              21.566851863171905
Epoch Time (s)               79.2685087644495
Total Train Time (s)         29103.897287300322
Epoch                        359
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:53:24.273611 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #359 | Epoch Duration: 77.1001193523407
2020-01-11 08:53:24.273770 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #359 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0194584
Z variance train             0.0065987534
KL Divergence                10.488529
KL Loss                      1.0488529
QF Loss                      109.97894
VF Loss                      78.32607
Policy Loss                  -1582.493
Q Predictions Mean           1587.473
Q Predictions Std            155.61566
Q Predictions Max            1784.1975
Q Predictions Min            575.29755
V Predictions Mean           1586.5093
V Predictions Std            152.33313
V Predictions Max            1791.0458
V Predictions Min            576.9746
Log Pis Mean                 -0.56037545
Log Pis Std                  1.5043279
Log Pis Max                  6.2584553
Log Pis Min                  -4.7847414
Policy mu Mean               0.20139527
Policy mu Std                0.7632909
Policy mu Max                2.0425768
Policy mu Min                -2.648889
Policy log std Mean          -0.4281714
Policy log std Std           0.16016513
Policy log std Max           0.10940924
Policy log std Min           -1.6352326
Z mean eval                  0.020793596
Z variance eval              0.0063254638
total_rewards                [1206.27442372 2135.73577083 2068.51992544 3297.21072692 3235.69452837
 2129.8297896  1182.92610086 3295.08769408 3314.65604805 1787.10077229]
total_rewards_mean           2365.3035780174932
total_rewards_std            816.3157072240983
total_rewards_max            3314.656048052293
total_rewards_min            1182.926100860375
Number of train steps total  361000
Number of env steps total    1807000
Number of rollouts total     0
Train Time (s)               43.46888437168673
(Previous) Eval Time (s)     11.110640234779567
Sample Time (s)              21.982343829702586
Epoch Time (s)               76.56186843616888
Total Train Time (s)         29193.217639951967
Epoch                        360
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:54:53.596788 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #360 | Epoch Duration: 89.32290172576904
2020-01-11 08:54:53.596916 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #360 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02023709
Z variance train             0.0063280733
KL Divergence                10.642711
KL Loss                      1.0642711
QF Loss                      63.962517
VF Loss                      62.09579
Policy Loss                  -1578.8245
Q Predictions Mean           1579.0787
Q Predictions Std            160.01624
Q Predictions Max            1776.6614
Q Predictions Min            403.3308
V Predictions Mean           1581.8867
V Predictions Std            158.73352
V Predictions Max            1774.8129
V Predictions Min            454.7756
Log Pis Mean                 -0.49820742
Log Pis Std                  2.1153047
Log Pis Max                  9.348211
Log Pis Min                  -6.6905456
Policy mu Mean               -0.011110611
Policy mu Std                0.87972635
Policy mu Max                2.8092744
Policy mu Min                -3.1766133
Policy log std Mean          -0.45653808
Policy log std Std           0.15520556
Policy log std Max           -0.037112653
Policy log std Min           -1.0621632
Z mean eval                  0.017410174
Z variance eval              0.0056271716
total_rewards                [2326.60777023 1633.90705534 1795.00374907 1009.75279436 2994.06561354
  931.22025009 1829.69288661 1519.98695065 1109.41803456 1623.68967881]
total_rewards_mean           1677.3344783280231
total_rewards_std            595.5500495640341
total_rewards_max            2994.065613541986
total_rewards_min            931.220250094663
Number of train steps total  362000
Number of env steps total    1812000
Number of rollouts total     0
Train Time (s)               43.770733542740345
(Previous) Eval Time (s)     23.871424017008394
Sample Time (s)              21.937244853470474
Epoch Time (s)               89.57940241321921
Total Train Time (s)         29273.793080274016
Epoch                        361
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:56:14.178723 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #361 | Epoch Duration: 80.58165502548218
2020-01-11 08:56:14.179031 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #361 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018065587
Z variance train             0.005612917
KL Divergence                10.908308
KL Loss                      1.0908308
QF Loss                      173.47806
VF Loss                      155.20255
Policy Loss                  -1578.1633
Q Predictions Mean           1581.691
Q Predictions Std            191.14073
Q Predictions Max            1748.483
Q Predictions Min            -74.25055
V Predictions Mean           1585.752
V Predictions Std            183.33513
V Predictions Max            1754.0742
V Predictions Min            149.61859
Log Pis Mean                 -0.51907146
Log Pis Std                  2.03842
Log Pis Max                  12.50744
Log Pis Min                  -6.917639
Policy mu Mean               0.02095441
Policy mu Std                0.8456099
Policy mu Max                2.5251503
Policy mu Min                -4.888721
Policy log std Mean          -0.43575755
Policy log std Std           0.15523526
Policy log std Max           -0.053106546
Policy log std Min           -1.1307911
Z mean eval                  0.021877166
Z variance eval              0.00581782
total_rewards                [3313.09231541 2478.62889903 3253.8845731  3220.13221811 2052.48989678
 1103.86201949 2604.69283807 2084.60501576 3263.5077848  1765.93003269]
total_rewards_mean           2514.0825593238555
total_rewards_std            721.2009431786446
total_rewards_max            3313.092315414649
total_rewards_min            1103.862019490594
Number of train steps total  363000
Number of env steps total    1817000
Number of rollouts total     0
Train Time (s)               43.79615624016151
(Previous) Eval Time (s)     14.873384980950505
Sample Time (s)              19.868582343216985
Epoch Time (s)               78.538123564329
Total Train Time (s)         29362.682586877607
Epoch                        362
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:57:43.069950 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #362 | Epoch Duration: 88.8907036781311
2020-01-11 08:57:43.070070 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #362 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021482792
Z variance train             0.005822067
KL Divergence                10.74568
KL Loss                      1.074568
QF Loss                      92.61853
VF Loss                      116.45922
Policy Loss                  -1613.5043
Q Predictions Mean           1615.1294
Q Predictions Std            159.0768
Q Predictions Max            1785.9772
Q Predictions Min            67.9002
V Predictions Mean           1606.727
V Predictions Std            157.57361
V Predictions Max            1770.5841
V Predictions Min            47.33178
Log Pis Mean                 -0.6550981
Log Pis Std                  1.8581347
Log Pis Max                  8.259348
Log Pis Min                  -8.282949
Policy mu Mean               -0.07007191
Policy mu Std                0.78307414
Policy mu Max                2.3917062
Policy mu Min                -2.9829628
Policy log std Mean          -0.4227519
Policy log std Std           0.145492
Policy log std Max           -0.094533384
Policy log std Min           -1.0625552
Z mean eval                  0.03256905
Z variance eval              0.0065496005
total_rewards                [1525.95737571 1046.90275768 2644.52233488 1342.23668451 1058.01196672
 3300.31362496 2777.54805403 1841.11865669 1596.49976128 2427.62068183]
total_rewards_mean           1956.073189828837
total_rewards_std            742.6661337129317
total_rewards_max            3300.313624956846
total_rewards_min            1046.9027576806973
Number of train steps total  364000
Number of env steps total    1822000
Number of rollouts total     0
Train Time (s)               43.93427317170426
(Previous) Eval Time (s)     25.225754915270954
Sample Time (s)              21.705902906134725
Epoch Time (s)               90.86593099310994
Total Train Time (s)         29447.82639144035
Epoch                        363
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:59:08.216803 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #363 | Epoch Duration: 85.14663982391357
2020-01-11 08:59:08.216942 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #363 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033298254
Z variance train             0.0065448536
KL Divergence                10.462652
KL Loss                      1.0462652
QF Loss                      90.42299
VF Loss                      46.034004
Policy Loss                  -1613.157
Q Predictions Mean           1612.2793
Q Predictions Std            162.80928
Q Predictions Max            1786.3793
Q Predictions Min            451.55426
V Predictions Mean           1610.6536
V Predictions Std            160.3162
V Predictions Max            1791.4492
V Predictions Min            460.81943
Log Pis Mean                 -0.5179421
Log Pis Std                  2.0359492
Log Pis Max                  7.3094425
Log Pis Min                  -7.1214113
Policy mu Mean               -0.03329616
Policy mu Std                0.8452966
Policy mu Max                1.8295625
Policy mu Min                -3.078993
Policy log std Mean          -0.42223772
Policy log std Std           0.16614553
Policy log std Max           -0.04890853
Policy log std Min           -1.9062796
Z mean eval                  0.023007322
Z variance eval              0.0063352897
total_rewards                [1004.05439978 2606.74080876 1255.57317138 1597.41978725 1333.32645619
 1363.48097511 1264.5122618   916.15411535 1550.89350919 2996.54149145]
total_rewards_mean           1588.869697626596
total_rewards_std            643.8997363908526
total_rewards_max            2996.541491452906
total_rewards_min            916.1541153517205
Number of train steps total  365000
Number of env steps total    1827000
Number of rollouts total     0
Train Time (s)               44.28938355483115
(Previous) Eval Time (s)     19.506219437811524
Sample Time (s)              22.244354818947613
Epoch Time (s)               86.03995781159028
Total Train Time (s)         29528.485680039972
Epoch                        364
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:00:28.879783 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #364 | Epoch Duration: 80.66273164749146
2020-01-11 09:00:28.879960 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #364 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022920968
Z variance train             0.0063345814
KL Divergence                10.55207
KL Loss                      1.055207
QF Loss                      531.5933
VF Loss                      41.559246
Policy Loss                  -1566.1764
Q Predictions Mean           1565.3134
Q Predictions Std            153.44945
Q Predictions Max            1757.0521
Q Predictions Min            804.49915
V Predictions Mean           1562.2958
V Predictions Std            152.35095
V Predictions Max            1753.6787
V Predictions Min            798.4401
Log Pis Mean                 -0.7942945
Log Pis Std                  1.7241231
Log Pis Max                  7.559999
Log Pis Min                  -4.4304633
Policy mu Mean               0.05550593
Policy mu Std                0.75893325
Policy mu Max                1.9504902
Policy mu Min                -3.8220153
Policy log std Mean          -0.4288632
Policy log std Std           0.16216516
Policy log std Max           -0.12094964
Policy log std Min           -1.1566843
Z mean eval                  0.030071061
Z variance eval              0.0061508697
total_rewards                [1201.4210802   994.82317697  951.11602396 3291.68421913 1525.10731395
 1022.26470298 1035.4138859  1410.4831924   954.07463889 3326.73241291]
total_rewards_mean           1571.3120647301848
total_rewards_std            888.4033748315208
total_rewards_max            3326.732412908577
total_rewards_min            951.116023961083
Number of train steps total  366000
Number of env steps total    1832000
Number of rollouts total     0
Train Time (s)               44.1781565239653
(Previous) Eval Time (s)     14.12872127816081
Sample Time (s)              22.042681188788265
Epoch Time (s)               80.34955899091437
Total Train Time (s)         29610.372451466043
Epoch                        365
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:01:50.768855 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #365 | Epoch Duration: 81.88875579833984
2020-01-11 09:01:50.768987 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #365 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029880702
Z variance train             0.0061562173
KL Divergence                10.746494
KL Loss                      1.0746495
QF Loss                      87.812515
VF Loss                      54.729485
Policy Loss                  -1588.7637
Q Predictions Mean           1588.2266
Q Predictions Std            129.20651
Q Predictions Max            1744.9199
Q Predictions Min            1067.1826
V Predictions Mean           1588.7241
V Predictions Std            129.16946
V Predictions Max            1748.5308
V Predictions Min            1078.4025
Log Pis Mean                 -0.47968182
Log Pis Std                  2.0042055
Log Pis Max                  8.031124
Log Pis Min                  -4.1425066
Policy mu Mean               -0.019663924
Policy mu Std                0.8395766
Policy mu Max                2.4528794
Policy mu Min                -4.003307
Policy log std Mean          -0.42696646
Policy log std Std           0.1690768
Policy log std Max           -0.060465485
Policy log std Min           -1.6077231
Z mean eval                  0.05540328
Z variance eval              0.007245449
total_rewards                [2106.69287377 1661.66746018 1012.30935643  959.24813994 1416.65595602
 2120.77917824  976.48119404 2091.44547001 1845.24702975 1684.59932821]
total_rewards_mean           1587.5125986596697
total_rewards_std            449.1489647126284
total_rewards_max            2120.779178239879
total_rewards_min            959.248139944389
Number of train steps total  367000
Number of env steps total    1837000
Number of rollouts total     0
Train Time (s)               44.544120602775365
(Previous) Eval Time (s)     15.667669487185776
Sample Time (s)              22.082416114397347
Epoch Time (s)               82.29420620435849
Total Train Time (s)         29693.265106536914
Epoch                        366
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:03:13.669402 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #366 | Epoch Duration: 82.90026879310608
2020-01-11 09:03:13.669703 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #366 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.055538673
Z variance train             0.0072424123
KL Divergence                10.535621
KL Loss                      1.053562
QF Loss                      153.95674
VF Loss                      43.51954
Policy Loss                  -1607.9291
Q Predictions Mean           1607.5752
Q Predictions Std            144.18616
Q Predictions Max            1767.5974
Q Predictions Min            529.55347
V Predictions Mean           1609.1006
V Predictions Std            144.97467
V Predictions Max            1772.7744
V Predictions Min            522.1287
Log Pis Mean                 -0.7159653
Log Pis Std                  1.7835023
Log Pis Max                  8.398695
Log Pis Min                  -6.4850755
Policy mu Mean               0.059407726
Policy mu Std                0.7869805
Policy mu Max                1.9960221
Policy mu Min                -3.2854078
Policy log std Mean          -0.4247302
Policy log std Std           0.16119337
Policy log std Max           0.06423628
Policy log std Min           -1.3437254
Z mean eval                  0.049411807
Z variance eval              0.0068442672
total_rewards                [2458.02407308 3330.90641234 1300.65120451 1276.85018994 2469.22686416
 1713.31970288 3289.61393758 3174.53612514 1763.15644884 1170.35233398]
total_rewards_mean           2194.66372924501
total_rewards_std            818.7552392612885
total_rewards_max            3330.906412341267
total_rewards_min            1170.3523339832095
Number of train steps total  368000
Number of env steps total    1842000
Number of rollouts total     0
Train Time (s)               44.03500987030566
(Previous) Eval Time (s)     16.273460939060897
Sample Time (s)              21.493056918028742
Epoch Time (s)               81.8015277273953
Total Train Time (s)         29778.634455102496
Epoch                        367
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:04:39.040823 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #367 | Epoch Duration: 85.37089037895203
2020-01-11 09:04:39.041003 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #367 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.049109846
Z variance train             0.006847205
KL Divergence                10.733709
KL Loss                      1.0733709
QF Loss                      242.17712
VF Loss                      28.481216
Policy Loss                  -1613.0234
Q Predictions Mean           1613.542
Q Predictions Std            131.56932
Q Predictions Max            1792.9214
Q Predictions Min            542.3563
V Predictions Mean           1615.9993
V Predictions Std            132.29689
V Predictions Max            1798.5748
V Predictions Min            502.5311
Log Pis Mean                 -0.44871536
Log Pis Std                  1.8450598
Log Pis Max                  8.945951
Log Pis Min                  -4.327595
Policy mu Mean               -0.013863944
Policy mu Std                0.84604007
Policy mu Max                2.1329684
Policy mu Min                -3.5199292
Policy log std Mean          -0.4382101
Policy log std Std           0.1635252
Policy log std Max           0.008228213
Policy log std Min           -1.3579632
Z mean eval                  0.017358351
Z variance eval              0.0058527915
total_rewards                [1750.91464019 2192.51031959 1073.78645723 1056.08091245 3328.05457002
 3358.74213244 3358.48740682 1058.45903762 3347.14310612 2516.94346174]
total_rewards_mean           2304.112204422726
total_rewards_std            966.8007971776494
total_rewards_max            3358.742132444995
total_rewards_min            1056.0809124508444
Number of train steps total  369000
Number of env steps total    1847000
Number of rollouts total     0
Train Time (s)               44.09264005254954
(Previous) Eval Time (s)     19.84259732766077
Sample Time (s)              21.88117990968749
Epoch Time (s)               85.8164172898978
Total Train Time (s)         29867.168603728525
Epoch                        368
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:06:07.579660 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #368 | Epoch Duration: 88.53845310211182
2020-01-11 09:06:07.579904 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #368 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01756373
Z variance train             0.0058537805
KL Divergence                10.910417
KL Loss                      1.0910417
QF Loss                      35.230457
VF Loss                      40.080914
Policy Loss                  -1603.5132
Q Predictions Mean           1601.9382
Q Predictions Std            141.12488
Q Predictions Max            1759.8547
Q Predictions Min            705.7271
V Predictions Mean           1604.5239
V Predictions Std            141.36191
V Predictions Max            1764.6765
V Predictions Min            708.27405
Log Pis Mean                 -0.59212947
Log Pis Std                  1.9344808
Log Pis Max                  9.063433
Log Pis Min                  -4.407107
Policy mu Mean               0.04710779
Policy mu Std                0.8034465
Policy mu Max                2.1973395
Policy mu Min                -3.3394282
Policy log std Mean          -0.438495
Policy log std Std           0.15945612
Policy log std Max           0.026569188
Policy log std Min           -1.0968995
Z mean eval                  0.029029336
Z variance eval              0.005762805
total_rewards                [1523.78133977 3348.06552817 2999.28479213  905.40128358 2093.04373349
 3260.52685548 1522.03753607 1592.71124634 2530.20725745 1639.34836357]
total_rewards_mean           2141.4407936043567
total_rewards_std            802.7348889650295
total_rewards_max            3348.06552816555
total_rewards_min            905.4012835766162
Number of train steps total  370000
Number of env steps total    1852000
Number of rollouts total     0
Train Time (s)               44.70516276592389
(Previous) Eval Time (s)     22.56438369816169
Sample Time (s)              21.924450215883553
Epoch Time (s)               89.19399667996913
Total Train Time (s)         29953.000179021154
Epoch                        369
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:07:33.417294 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #369 | Epoch Duration: 85.8370418548584
2020-01-11 09:07:33.417539 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #369 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029380944
Z variance train             0.005763788
KL Divergence                10.721092
KL Loss                      1.0721092
QF Loss                      138.22789
VF Loss                      98.76664
Policy Loss                  -1600.6473
Q Predictions Mean           1600.2969
Q Predictions Std            148.90347
Q Predictions Max            1778.8525
Q Predictions Min            739.1036
V Predictions Mean           1594.3582
V Predictions Std            148.45769
V Predictions Max            1770.8016
V Predictions Min            756.3707
Log Pis Mean                 -0.6103569
Log Pis Std                  1.9242069
Log Pis Max                  8.849497
Log Pis Min                  -5.009255
Policy mu Mean               0.014498414
Policy mu Std                0.8310057
Policy mu Max                2.514448
Policy mu Min                -3.1032293
Policy log std Mean          -0.4353839
Policy log std Std           0.16780014
Policy log std Max           -0.043234438
Policy log std Min           -1.2684808
Z mean eval                  0.012191942
Z variance eval              0.0051916745
total_rewards                [1259.1122483  1758.33011407 1154.83145008 1833.8351748  3340.30563637
 3354.49180047 1638.94276825 1674.0256632  1121.78805705 1286.40653499]
total_rewards_mean           1842.2069447575482
total_rewards_std            790.469089704272
total_rewards_max            3354.4918004651577
total_rewards_min            1121.7880570475254
Number of train steps total  371000
Number of env steps total    1857000
Number of rollouts total     0
Train Time (s)               44.54192630993202
(Previous) Eval Time (s)     19.20732482802123
Sample Time (s)              21.42465651873499
Epoch Time (s)               85.17390765668824
Total Train Time (s)         30036.998336640652
Epoch                        370
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:08:57.417884 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #370 | Epoch Duration: 84.00011706352234
2020-01-11 09:08:57.418076 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #370 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011817065
Z variance train             0.00518661
KL Divergence                10.851876
KL Loss                      1.0851877
QF Loss                      114.11685
VF Loss                      91.20301
Policy Loss                  -1589.9615
Q Predictions Mean           1586.4213
Q Predictions Std            162.36884
Q Predictions Max            1764.1123
Q Predictions Min            375.31656
V Predictions Mean           1591.7539
V Predictions Std            162.10303
V Predictions Max            1770.7057
V Predictions Min            401.54004
Log Pis Mean                 -0.54605794
Log Pis Std                  1.7381188
Log Pis Max                  8.863119
Log Pis Min                  -5.0264077
Policy mu Mean               0.0068770205
Policy mu Std                0.82103866
Policy mu Max                1.9273913
Policy mu Min                -3.1959522
Policy log std Mean          -0.42774186
Policy log std Std           0.15954864
Policy log std Max           -0.00502643
Policy log std Min           -1.4854015
Z mean eval                  0.035162568
Z variance eval              0.0047867163
total_rewards                [2747.84335814 2630.3823663   979.7088005  1247.8425782  1296.85927976
  941.54435009 1753.42783991 1800.59241256 1280.60863527  938.7805149 ]
total_rewards_mean           1561.7590135627038
total_rewards_std            632.6011457161575
total_rewards_max            2747.84335814003
total_rewards_min            938.7805148996301
Number of train steps total  372000
Number of env steps total    1862000
Number of rollouts total     0
Train Time (s)               44.801213891245425
(Previous) Eval Time (s)     18.033316106069833
Sample Time (s)              21.862218076363206
Epoch Time (s)               84.69674807367846
Total Train Time (s)         30117.886175457388
Epoch                        371
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:10:18.309592 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #371 | Epoch Duration: 80.89138650894165
2020-01-11 09:10:18.309772 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #371 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03531011
Z variance train             0.004787643
KL Divergence                11.121107
KL Loss                      1.1121107
QF Loss                      65.048416
VF Loss                      67.25836
Policy Loss                  -1591.0624
Q Predictions Mean           1589.9751
Q Predictions Std            165.697
Q Predictions Max            1764.6127
Q Predictions Min            641.29974
V Predictions Mean           1591.2668
V Predictions Std            162.61848
V Predictions Max            1767.3483
V Predictions Min            651.42224
Log Pis Mean                 -0.6502075
Log Pis Std                  1.712208
Log Pis Max                  5.861554
Log Pis Min                  -5.382333
Policy mu Mean               0.004419157
Policy mu Std                0.76601666
Policy mu Max                1.6869414
Policy mu Min                -3.2149265
Policy log std Mean          -0.4264233
Policy log std Std           0.17152658
Policy log std Max           -0.026454926
Policy log std Min           -1.2423632
Z mean eval                  0.0833737
Z variance eval              0.0052017285
total_rewards                [1596.91483303 3358.87687368 1428.96979755 2714.6904851  1154.19917859
 3037.74328988 1024.63083965 3336.74017211 1567.50170105 2472.42197317]
total_rewards_mean           2169.268914379606
total_rewards_std            866.0317020005202
total_rewards_max            3358.8768736771053
total_rewards_min            1024.63083964894
Number of train steps total  373000
Number of env steps total    1867000
Number of rollouts total     0
Train Time (s)               44.808717992156744
(Previous) Eval Time (s)     14.227712060790509
Sample Time (s)              22.17492312565446
Epoch Time (s)               81.21135317860171
Total Train Time (s)         30203.841584998183
Epoch                        372
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:11:44.272112 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #372 | Epoch Duration: 85.96219253540039
2020-01-11 09:11:44.272307 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #372 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0865839
Z variance train             0.0052209357
KL Divergence                10.9923725
KL Loss                      1.0992373
QF Loss                      137.25421
VF Loss                      272.98
Policy Loss                  -1565.6735
Q Predictions Mean           1571.4594
Q Predictions Std            163.30266
Q Predictions Max            1764.4655
Q Predictions Min            570.5967
V Predictions Mean           1574.2188
V Predictions Std            163.03937
V Predictions Max            1777.8983
V Predictions Min            552.4089
Log Pis Mean                 -0.40776348
Log Pis Std                  1.8323733
Log Pis Max                  11.163192
Log Pis Min                  -4.5574465
Policy mu Mean               0.03509532
Policy mu Std                0.81953704
Policy mu Max                2.4419258
Policy mu Min                -2.9729013
Policy log std Mean          -0.45129418
Policy log std Std           0.15460026
Policy log std Max           -0.03443089
Policy log std Min           -1.1724085
Z mean eval                  0.020032877
Z variance eval              0.004371083
total_rewards                [3433.43866184 3415.18933806 2027.37054117 1441.95175251 2496.96074981
 1910.96699745 1025.39176676 1325.66924327 1273.67741445 1287.3443928 ]
total_rewards_mean           1963.7960858131435
total_rewards_std            839.7302883507175
total_rewards_max            3433.4386618378444
total_rewards_min            1025.391766762436
Number of train steps total  374000
Number of env steps total    1872000
Number of rollouts total     0
Train Time (s)               43.83992154011503
(Previous) Eval Time (s)     18.97828818531707
Sample Time (s)              21.744686746038496
Epoch Time (s)               84.5628964714706
Total Train Time (s)         30286.746833753306
Epoch                        373
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:13:07.186176 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #373 | Epoch Duration: 82.9136860370636
2020-01-11 09:13:07.186455 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #373 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02018581
Z variance train             0.004374239
KL Divergence                11.304903
KL Loss                      1.1304903
QF Loss                      57.841377
VF Loss                      33.11249
Policy Loss                  -1591.1129
Q Predictions Mean           1590.2561
Q Predictions Std            148.98062
Q Predictions Max            1760.252
Q Predictions Min            508.835
V Predictions Mean           1587.9487
V Predictions Std            149.37988
V Predictions Max            1756.8567
V Predictions Min            486.8504
Log Pis Mean                 -0.6104243
Log Pis Std                  1.7825649
Log Pis Max                  4.5030975
Log Pis Min                  -6.2993865
Policy mu Mean               -0.024394505
Policy mu Std                0.80093515
Policy mu Max                1.7520926
Policy mu Min                -2.7129183
Policy log std Mean          -0.44955635
Policy log std Std           0.16638312
Policy log std Max           -0.048143268
Policy log std Min           -1.1113353
Z mean eval                  0.023864137
Z variance eval              0.004711358
total_rewards                [1895.64494987 2449.66946583 3005.62107078 2433.22072045  919.40253977
 2754.38454043  379.6955034  1126.59369323  997.99370887 1330.87846308]
total_rewards_mean           1729.3104655722764
total_rewards_std            851.8257261938786
total_rewards_max            3005.6210707830405
total_rewards_min            379.6955034006129
Number of train steps total  375000
Number of env steps total    1877000
Number of rollouts total     0
Train Time (s)               43.94729198468849
(Previous) Eval Time (s)     17.328822585288435
Sample Time (s)              21.859599237330258
Epoch Time (s)               83.13571380730718
Total Train Time (s)         30369.587151289452
Epoch                        374
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:14:30.028059 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #374 | Epoch Duration: 82.84140729904175
2020-01-11 09:14:30.028191 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #374 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023998078
Z variance train             0.0047129826
KL Divergence                11.20516
KL Loss                      1.1205161
QF Loss                      94.80691
VF Loss                      91.93688
Policy Loss                  -1581.7117
Q Predictions Mean           1583.0938
Q Predictions Std            185.8163
Q Predictions Max            1768.5851
Q Predictions Min            28.28528
V Predictions Mean           1583.6925
V Predictions Std            183.77002
V Predictions Max            1763.9204
V Predictions Min            101.841354
Log Pis Mean                 -0.27314466
Log Pis Std                  2.0163252
Log Pis Max                  10.244379
Log Pis Min                  -6.0270853
Policy mu Mean               -0.039832845
Policy mu Std                0.882825
Policy mu Max                4.752212
Policy mu Min                -3.537464
Policy log std Mean          -0.4548141
Policy log std Std           0.18027134
Policy log std Max           0.35365033
Policy log std Min           -1.4027538
Z mean eval                  0.035158183
Z variance eval              0.0040123686
total_rewards                [2551.65918898 1039.98905927 2069.04226601 3085.25195239 3371.69739821
 2773.3678163  1159.12204779 3325.17719476 1073.97561598 1075.939514  ]
total_rewards_mean           2152.522205368622
total_rewards_std            939.6854831075234
total_rewards_max            3371.697398213535
total_rewards_min            1039.9890592679333
Number of train steps total  376000
Number of env steps total    1882000
Number of rollouts total     0
Train Time (s)               44.06935302820057
(Previous) Eval Time (s)     17.034283032175153
Sample Time (s)              22.527968580834568
Epoch Time (s)               83.63160464121029
Total Train Time (s)         30456.768402692862
Epoch                        375
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:15:57.213542 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #375 | Epoch Duration: 87.18524670600891
2020-01-11 09:15:57.213702 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #375 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035332225
Z variance train             0.0040121293
KL Divergence                11.640718
KL Loss                      1.1640719
QF Loss                      95.844185
VF Loss                      17.29914
Policy Loss                  -1592.3113
Q Predictions Mean           1590.0032
Q Predictions Std            164.42143
Q Predictions Max            1761.8774
Q Predictions Min            534.62695
V Predictions Mean           1591.4526
V Predictions Std            164.77882
V Predictions Max            1763.0542
V Predictions Min            527.69116
Log Pis Mean                 -0.33493653
Log Pis Std                  1.9418341
Log Pis Max                  6.3821497
Log Pis Min                  -4.078553
Policy mu Mean               -0.0016354447
Policy mu Std                0.84172815
Policy mu Max                2.1687117
Policy mu Min                -3.2170534
Policy log std Mean          -0.44590345
Policy log std Std           0.17245246
Policy log std Max           -0.056915373
Policy log std Min           -1.2155539
Z mean eval                  0.030171206
Z variance eval              0.0039273696
total_rewards                [1049.65166849 2479.66127781 1263.17437989 1882.00785904 1025.73380611
 1933.43588275 1082.52264686 1136.66204768 2757.42706732 2766.7968593 ]
total_rewards_mean           1737.707349523842
total_rewards_std            685.8944805814577
total_rewards_max            2766.796859297223
total_rewards_min            1025.733806106935
Number of train steps total  377000
Number of env steps total    1887000
Number of rollouts total     0
Train Time (s)               44.334608355071396
(Previous) Eval Time (s)     20.58766701677814
Sample Time (s)              21.40770101454109
Epoch Time (s)               86.32997638639063
Total Train Time (s)         30539.570628764573
Epoch                        376
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:17:20.020273 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #376 | Epoch Duration: 82.80643606185913
2020-01-11 09:17:20.020458 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #376 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030100593
Z variance train             0.003928072
KL Divergence                11.6947365
KL Loss                      1.1694736
QF Loss                      80.91618
VF Loss                      47.505596
Policy Loss                  -1596.449
Q Predictions Mean           1594.6697
Q Predictions Std            163.0805
Q Predictions Max            1760.2966
Q Predictions Min            394.62006
V Predictions Mean           1595.898
V Predictions Std            162.17194
V Predictions Max            1756.9231
V Predictions Min            408.06677
Log Pis Mean                 -0.40513474
Log Pis Std                  2.050919
Log Pis Max                  9.119312
Log Pis Min                  -5.5293927
Policy mu Mean               -0.019330347
Policy mu Std                0.8459839
Policy mu Max                2.1427076
Policy mu Min                -3.4681976
Policy log std Mean          -0.44694868
Policy log std Std           0.15561825
Policy log std Max           -0.113211334
Policy log std Min           -1.1501802
Z mean eval                  0.03705223
Z variance eval              0.004069281
total_rewards                [1718.601252   1019.78806433 2361.08394118 2696.88033803 1608.07331519
 1540.13001197  788.09141342 1152.97102327 1654.18588528 1577.93183256]
total_rewards_mean           1611.7737077222057
total_rewards_std            547.5239130724883
total_rewards_max            2696.880338025724
total_rewards_min            788.0914134159273
Number of train steps total  378000
Number of env steps total    1892000
Number of rollouts total     0
Train Time (s)               44.27053480502218
(Previous) Eval Time (s)     17.06386477779597
Sample Time (s)              22.013196270912886
Epoch Time (s)               83.34759585373104
Total Train Time (s)         30620.731353993993
Epoch                        377
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:18:41.184587 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #377 | Epoch Duration: 81.16398668289185
2020-01-11 09:18:41.184748 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #377 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035679836
Z variance train             0.004057874
KL Divergence                11.66156
KL Loss                      1.166156
QF Loss                      143.74973
VF Loss                      101.11779
Policy Loss                  -1574.2853
Q Predictions Mean           1580.2532
Q Predictions Std            146.78502
Q Predictions Max            1761.3417
Q Predictions Min            861.68066
V Predictions Mean           1578.585
V Predictions Std            148.3414
V Predictions Max            1749.0555
V Predictions Min            847.54645
Log Pis Mean                 -0.6117564
Log Pis Std                  1.9554999
Log Pis Max                  9.017606
Log Pis Min                  -5.973505
Policy mu Mean               0.0017880189
Policy mu Std                0.7687398
Policy mu Max                2.5807517
Policy mu Min                -3.0188897
Policy log std Mean          -0.45732865
Policy log std Std           0.17161769
Policy log std Max           -0.069542766
Policy log std Min           -1.2737775
Z mean eval                  0.026615392
Z variance eval              0.0039227623
total_rewards                [ 991.80468001 1328.01273771 1544.51122081 2140.83760244 1642.48389054
 2002.93948503 2072.1820287  1290.29138672 1616.85328094 1561.14559473]
total_rewards_mean           1619.1061907644241
total_rewards_std            349.377527966852
total_rewards_max            2140.8376024432737
total_rewards_min            991.804680012093
Number of train steps total  379000
Number of env steps total    1897000
Number of rollouts total     0
Train Time (s)               43.70665404293686
(Previous) Eval Time (s)     14.880003672093153
Sample Time (s)              22.569869220722467
Epoch Time (s)               81.15652693575248
Total Train Time (s)         30702.675599162932
Epoch                        378
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:20:03.137338 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #378 | Epoch Duration: 81.95245623588562
2020-01-11 09:20:03.137521 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #378 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026588518
Z variance train             0.003923542
KL Divergence                11.648031
KL Loss                      1.1648031
QF Loss                      79.54381
VF Loss                      53.35173
Policy Loss                  -1581.8833
Q Predictions Mean           1582.8049
Q Predictions Std            169.10014
Q Predictions Max            1735.3948
Q Predictions Min            567.6263
V Predictions Mean           1585.1826
V Predictions Std            169.12871
V Predictions Max            1746.3984
V Predictions Min            578.39905
Log Pis Mean                 -0.29712436
Log Pis Std                  2.0730364
Log Pis Max                  10.786016
Log Pis Min                  -5.086143
Policy mu Mean               0.011493613
Policy mu Std                0.85540175
Policy mu Max                2.583342
Policy mu Min                -2.9966483
Policy log std Mean          -0.45194808
Policy log std Std           0.17138568
Policy log std Max           -0.012025446
Policy log std Min           -1.2420077
Z mean eval                  0.03512335
Z variance eval              0.0045207716
total_rewards                [2179.46406893 1104.04474614 2795.05700597 3410.76382474 1012.37308825
 1850.09820275 1660.33041457 1689.29393002 3326.01020393 2084.01067463]
total_rewards_mean           2111.144615992106
total_rewards_std            794.2879914408334
total_rewards_max            3410.7638247395503
total_rewards_min            1012.373088248161
Number of train steps total  380000
Number of env steps total    1902000
Number of rollouts total     0
Train Time (s)               44.954034503083676
(Previous) Eval Time (s)     15.675676940008998
Sample Time (s)              21.544733237475157
Epoch Time (s)               82.17444468056783
Total Train Time (s)         30789.904683255125
Epoch                        379
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:21:30.367963 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #379 | Epoch Duration: 87.23031210899353
2020-01-11 09:21:30.368101 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #379 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034649946
Z variance train             0.0045240195
KL Divergence                11.406532
KL Loss                      1.1406533
QF Loss                      374.41437
VF Loss                      209.36333
Policy Loss                  -1570.6674
Q Predictions Mean           1572.0468
Q Predictions Std            146.18349
Q Predictions Max            1768.4739
Q Predictions Min            729.13635
V Predictions Mean           1573.4492
V Predictions Std            142.84438
V Predictions Max            1767.6458
V Predictions Min            715.81116
Log Pis Mean                 -0.63729537
Log Pis Std                  1.7825913
Log Pis Max                  8.331643
Log Pis Min                  -4.9692297
Policy mu Mean               0.021859469
Policy mu Std                0.7391765
Policy mu Max                2.3107874
Policy mu Min                -3.0193672
Policy log std Mean          -0.4331406
Policy log std Std           0.1728687
Policy log std Max           0.005158752
Policy log std Min           -1.5714147
Z mean eval                  0.017013956
Z variance eval              0.005888532
total_rewards                [2624.58076225 1935.86674235  876.45868985  649.7132877   658.03329401
 3296.05145412 2171.60197898  375.57219571 2702.56548232 2988.99652877]
total_rewards_mean           1827.9440416052844
total_rewards_std            1039.4397668573395
total_rewards_max            3296.0514541184266
total_rewards_min            375.57219571207185
Number of train steps total  381000
Number of env steps total    1907000
Number of rollouts total     0
Train Time (s)               44.075378451962024
(Previous) Eval Time (s)     20.731317806057632
Sample Time (s)              21.769374831113964
Epoch Time (s)               86.57607108913362
Total Train Time (s)         30876.024597799405
Epoch                        380
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:22:56.493005 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #380 | Epoch Duration: 86.12480425834656
2020-01-11 09:22:56.493131 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #380 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016060593
Z variance train             0.0058770366
KL Divergence                10.96324
KL Loss                      1.096324
QF Loss                      258.45752
VF Loss                      221.25656
Policy Loss                  -1598.1653
Q Predictions Mean           1598.976
Q Predictions Std            149.90541
Q Predictions Max            1752.864
Q Predictions Min            417.2194
V Predictions Mean           1594.1912
V Predictions Std            147.70702
V Predictions Max            1741.8325
V Predictions Min            452.46027
Log Pis Mean                 -0.056133933
Log Pis Std                  2.1676164
Log Pis Max                  12.360083
Log Pis Min                  -5.13876
Policy mu Mean               -0.21658604
Policy mu Std                0.94267845
Policy mu Max                2.1151729
Policy mu Min                -4.7517066
Policy log std Mean          -0.45729694
Policy log std Std           0.18017605
Policy log std Max           -0.036390394
Policy log std Min           -1.3021544
Z mean eval                  0.091763295
Z variance eval              0.00539909
total_rewards                [2062.06766251 3438.73703513 3493.61998458 3426.26769069 1728.46317253
 1487.44275685 3409.64815427 1294.38053601 2955.49416293 2059.15301176]
total_rewards_mean           2535.5274167268635
total_rewards_std            849.0572884867654
total_rewards_max            3493.619984577968
total_rewards_min            1294.38053601463
Number of train steps total  382000
Number of env steps total    1912000
Number of rollouts total     0
Train Time (s)               43.520297795999795
(Previous) Eval Time (s)     20.279807440936565
Sample Time (s)              21.894813927356154
Epoch Time (s)               85.69491916429251
Total Train Time (s)         30963.446879660245
Epoch                        381
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:24:23.916390 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #381 | Epoch Duration: 87.4231481552124
2020-01-11 09:24:23.916566 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #381 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.093595535
Z variance train             0.00540196
KL Divergence                11.138187
KL Loss                      1.1138188
QF Loss                      67.89351
VF Loss                      43.075146
Policy Loss                  -1595.8247
Q Predictions Mean           1594.638
Q Predictions Std            149.45294
Q Predictions Max            1737.0594
Q Predictions Min            17.67638
V Predictions Mean           1599.6833
V Predictions Std            147.8489
V Predictions Max            1744.7761
V Predictions Min            55.342037
Log Pis Mean                 -0.75366104
Log Pis Std                  1.8718992
Log Pis Max                  7.484896
Log Pis Min                  -5.9506316
Policy mu Mean               0.028306998
Policy mu Std                0.7675873
Policy mu Max                2.494018
Policy mu Min                -3.0935645
Policy log std Mean          -0.4293008
Policy log std Std           0.16977714
Policy log std Max           -0.012977868
Policy log std Min           -1.2389119
Z mean eval                  0.0503698
Z variance eval              0.0055506905
total_rewards                [3409.59249362 3338.52041973 1931.00461446 1531.91967783 3388.59714394
 3377.51365899 1590.45843852 1184.17428149 3371.77335389 1048.56834232]
total_rewards_mean           2417.2122424806503
total_rewards_std            985.2823476903743
total_rewards_max            3409.5924936242063
total_rewards_min            1048.568342323555
Number of train steps total  383000
Number of env steps total    1917000
Number of rollouts total     0
Train Time (s)               43.5425562011078
(Previous) Eval Time (s)     22.00774807156995
Sample Time (s)              20.1775856888853
Epoch Time (s)               85.72788996156305
Total Train Time (s)         31050.502389057074
Epoch                        382
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:25:50.976092 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #382 | Epoch Duration: 87.05939769744873
2020-01-11 09:25:50.976230 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #382 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.047523372
Z variance train             0.005564657
KL Divergence                11.0273485
KL Loss                      1.1027349
QF Loss                      83.86392
VF Loss                      279.11002
Policy Loss                  -1604.2815
Q Predictions Mean           1606.7725
Q Predictions Std            123.649956
Q Predictions Max            1783.6215
Q Predictions Min            1122.6904
V Predictions Mean           1608.0479
V Predictions Std            127.09778
V Predictions Max            1795.1527
V Predictions Min            1112.8364
Log Pis Mean                 -0.50287765
Log Pis Std                  1.9181663
Log Pis Max                  6.3966904
Log Pis Min                  -4.4134293
Policy mu Mean               -0.08868454
Policy mu Std                0.8320582
Policy mu Max                1.7653911
Policy mu Min                -3.531901
Policy log std Mean          -0.41376093
Policy log std Std           0.17165926
Policy log std Max           -0.010903001
Policy log std Min           -1.1994724
Z mean eval                  0.03733926
Z variance eval              0.0058961296
total_rewards                [2901.88864892 3280.5063044  3340.82522264 3073.75954518 3314.91028705
 3415.90839247 2198.03977222 3339.3106038  2546.96613144  624.36874459]
total_rewards_mean           2803.6483652710845
total_rewards_std            818.7585726356358
total_rewards_max            3415.908392474452
total_rewards_min            624.3687445909243
Number of train steps total  384000
Number of env steps total    1922000
Number of rollouts total     0
Train Time (s)               45.04267161525786
(Previous) Eval Time (s)     23.339014149736613
Sample Time (s)              21.713080117013305
Epoch Time (s)               90.09476588200778
Total Train Time (s)         31144.054819612764
Epoch                        383
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:27:24.530950 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #383 | Epoch Duration: 93.55462694168091
2020-01-11 09:27:24.531089 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #383 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03645215
Z variance train             0.0059059267
KL Divergence                10.962561
KL Loss                      1.0962561
QF Loss                      77.76238
VF Loss                      56.375885
Policy Loss                  -1582.3948
Q Predictions Mean           1578.958
Q Predictions Std            175.8628
Q Predictions Max            1769.6327
Q Predictions Min            636.02
V Predictions Mean           1578.0963
V Predictions Std            175.42047
V Predictions Max            1768.9425
V Predictions Min            630.72327
Log Pis Mean                 -0.53396416
Log Pis Std                  1.8721591
Log Pis Max                  8.173789
Log Pis Min                  -5.5821753
Policy mu Mean               -0.07236507
Policy mu Std                0.79603446
Policy mu Max                1.7367907
Policy mu Min                -3.1707993
Policy log std Mean          -0.4067966
Policy log std Std           0.15892029
Policy log std Max           -0.06191951
Policy log std Min           -1.0266603
Z mean eval                  0.03324442
Z variance eval              0.0073736184
total_rewards                [1364.70758133 1191.79394151 1559.67908049 3392.29540816 2494.86175627
 1064.03211039 3350.46454644 3368.14673784 3356.87765196 3342.50618204]
total_rewards_mean           2448.536499641866
total_rewards_std            981.6952906932875
total_rewards_max            3392.2954081561224
total_rewards_min            1064.0321103902052
Number of train steps total  385000
Number of env steps total    1927000
Number of rollouts total     0
Train Time (s)               43.89446491608396
(Previous) Eval Time (s)     26.798635552171618
Sample Time (s)              21.656194041483104
Epoch Time (s)               92.34929450973868
Total Train Time (s)         31233.53478709841
Epoch                        384
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:28:54.014065 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #384 | Epoch Duration: 89.48288297653198
2020-01-11 09:28:54.014186 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #384 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03335324
Z variance train             0.0073956596
KL Divergence                9.979719
KL Loss                      0.99797195
QF Loss                      170.77203
VF Loss                      140.91893
Policy Loss                  -1598.3776
Q Predictions Mean           1592.6178
Q Predictions Std            122.749855
Q Predictions Max            1745.4446
Q Predictions Min            1028.2332
V Predictions Mean           1601.2323
V Predictions Std            124.6419
V Predictions Max            1773.2084
V Predictions Min            1023.35376
Log Pis Mean                 -0.66395485
Log Pis Std                  1.949215
Log Pis Max                  7.7266083
Log Pis Min                  -4.505163
Policy mu Mean               -0.111886345
Policy mu Std                0.8204569
Policy mu Max                1.6826273
Policy mu Min                -3.175541
Policy log std Mean          -0.4011198
Policy log std Std           0.15889497
Policy log std Max           0.008446157
Policy log std Min           -1.1599854
Z mean eval                  0.037707455
Z variance eval              0.008600192
total_rewards                [2489.65040994 2455.64960366 1544.26850444 2176.27069993 1884.06236406
 1485.76840401 3013.81067467 1034.67694066 1808.80901253 1419.66493265]
total_rewards_mean           1931.2631546538923
total_rewards_std            570.0673862525899
total_rewards_max            3013.810674667122
total_rewards_min            1034.6769406588958
Number of train steps total  386000
Number of env steps total    1932000
Number of rollouts total     0
Train Time (s)               43.76964649185538
(Previous) Eval Time (s)     23.931960746645927
Sample Time (s)              22.10584252467379
Epoch Time (s)               89.8074497631751
Total Train Time (s)         31318.12425248325
Epoch                        385
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:30:18.611120 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #385 | Epoch Duration: 84.59677338600159
2020-01-11 09:30:18.611391 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #385 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036391605
Z variance train             0.00859228
KL Divergence                9.522913
KL Loss                      0.9522913
QF Loss                      106.12506
VF Loss                      73.042114
Policy Loss                  -1586.3019
Q Predictions Mean           1582.5752
Q Predictions Std            128.5637
Q Predictions Max            1741.2083
Q Predictions Min            821.3038
V Predictions Mean           1586.9785
V Predictions Std            126.70195
V Predictions Max            1743.8408
V Predictions Min            856.6993
Log Pis Mean                 -0.34265453
Log Pis Std                  2.1269128
Log Pis Max                  7.442872
Log Pis Min                  -4.6362963
Policy mu Mean               -0.05674391
Policy mu Std                0.8827351
Policy mu Max                2.0677712
Policy mu Min                -3.0682516
Policy log std Mean          -0.43698668
Policy log std Std           0.1628649
Policy log std Max           -0.009572804
Policy log std Min           -0.99013597
Z mean eval                  0.02877644
Z variance eval              0.006990602
total_rewards                [ 998.17562585 3432.99924182 1008.50380925 1419.75014509 1002.48562478
 3099.60606947 1220.17036839 1017.32866501 1887.6281943  2542.36976586]
total_rewards_mean           1762.9017509824585
total_rewards_std            888.7899485571863
total_rewards_max            3432.999241815643
total_rewards_min            998.1756258518438
Number of train steps total  387000
Number of env steps total    1937000
Number of rollouts total     0
Train Time (s)               43.908888164907694
(Previous) Eval Time (s)     18.720981194172055
Sample Time (s)              22.460656724404544
Epoch Time (s)               85.09052608348429
Total Train Time (s)         31401.042607719544
Epoch                        386
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:31:41.534369 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #386 | Epoch Duration: 82.92276668548584
2020-01-11 09:31:41.534548 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #386 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030678025
Z variance train             0.006994559
KL Divergence                10.028563
KL Loss                      1.0028563
QF Loss                      823.54285
VF Loss                      307.167
Policy Loss                  -1602.5596
Q Predictions Mean           1604.0881
Q Predictions Std            188.13644
Q Predictions Max            1787.0626
Q Predictions Min            108.731766
V Predictions Mean           1592.9323
V Predictions Std            184.5828
V Predictions Max            1771.6188
V Predictions Min            244.40959
Log Pis Mean                 -0.39520884
Log Pis Std                  2.0379417
Log Pis Max                  11.394801
Log Pis Min                  -4.465742
Policy mu Mean               -0.044848766
Policy mu Std                0.85433555
Policy mu Max                2.1754732
Policy mu Min                -3.0234604
Policy log std Mean          -0.4256867
Policy log std Std           0.16348045
Policy log std Max           -0.027377754
Policy log std Min           -1.2019194
Z mean eval                  0.024393592
Z variance eval              0.008503623
total_rewards                [3351.35493216 2842.07693406 3345.05830437 3281.90805626 3124.05359639
 3397.70582925 2838.30026942 1959.413718   1120.01152117 3313.77387838]
total_rewards_mean           2857.3657039464524
total_rewards_std            711.2537174911819
total_rewards_max            3397.7058292497186
total_rewards_min            1120.0115211669186
Number of train steps total  388000
Number of env steps total    1942000
Number of rollouts total     0
Train Time (s)               44.277994784060866
(Previous) Eval Time (s)     16.552979791071266
Sample Time (s)              19.72032984206453
Epoch Time (s)               80.55130441719666
Total Train Time (s)         31492.981296275742
Epoch                        387
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:33:13.480162 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #387 | Epoch Duration: 91.94542074203491
2020-01-11 09:33:13.480419 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #387 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024709936
Z variance train             0.008500455
KL Divergence                9.684944
KL Loss                      0.9684944
QF Loss                      204.78503
VF Loss                      87.63285
Policy Loss                  -1588.3702
Q Predictions Mean           1588.9805
Q Predictions Std            172.15773
Q Predictions Max            1775.314
Q Predictions Min            553.63824
V Predictions Mean           1581.3248
V Predictions Std            172.26251
V Predictions Max            1768.6816
V Predictions Min            535.17725
Log Pis Mean                 -0.6010854
Log Pis Std                  2.0768526
Log Pis Max                  10.348816
Log Pis Min                  -5.759371
Policy mu Mean               -0.06471622
Policy mu Std                0.8746298
Policy mu Max                2.261077
Policy mu Min                -3.2145119
Policy log std Mean          -0.42013493
Policy log std Std           0.16178107
Policy log std Max           -0.053400382
Policy log std Min           -1.123861
Z mean eval                  0.034934916
Z variance eval              0.0073450385
total_rewards                [3327.2592247  1685.76634883  932.4505561  3296.50319845 3404.88215514
 3373.30538262 2749.60320825 3317.03975837 3420.85314878 1021.23718576]
total_rewards_mean           2652.8900166991552
total_rewards_std            977.3049172314858
total_rewards_max            3420.8531487813325
total_rewards_min            932.4505560980953
Number of train steps total  389000
Number of env steps total    1947000
Number of rollouts total     0
Train Time (s)               43.643697826657444
(Previous) Eval Time (s)     27.946836553979665
Sample Time (s)              21.861449704505503
Epoch Time (s)               93.45198408514261
Total Train Time (s)         31586.04797716206
Epoch                        388
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:34:46.551508 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #388 | Epoch Duration: 93.07091999053955
2020-01-11 09:34:46.551683 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #388 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033855956
Z variance train             0.007358926
KL Divergence                9.870373
KL Loss                      0.9870373
QF Loss                      171.50276
VF Loss                      67.07585
Policy Loss                  -1604.5283
Q Predictions Mean           1610.3463
Q Predictions Std            146.92508
Q Predictions Max            1779.8142
Q Predictions Min            506.3907
V Predictions Mean           1607.3975
V Predictions Std            148.72656
V Predictions Max            1776.9602
V Predictions Min            467.11078
Log Pis Mean                 -0.29313585
Log Pis Std                  2.0866807
Log Pis Max                  7.357292
Log Pis Min                  -4.6614013
Policy mu Mean               -0.066526614
Policy mu Std                0.88160694
Policy mu Max                2.3722994
Policy mu Min                -3.2766576
Policy log std Mean          -0.42021474
Policy log std Std           0.16322435
Policy log std Max           -0.03193623
Policy log std Min           -1.5618092
Z mean eval                  0.023906633
Z variance eval              0.0066853673
total_rewards                [1640.50479542 1030.22330213 1095.26042908  808.47534951 2996.86430875
 2446.25310687 1103.45075507  996.06260027 2992.60432194 2281.12342536]
total_rewards_mean           1739.0822394409242
total_rewards_std            818.2953262014748
total_rewards_max            2996.8643087470505
total_rewards_min            808.4753495095295
Number of train steps total  390000
Number of env steps total    1952000
Number of rollouts total     0
Train Time (s)               44.0970305823721
(Previous) Eval Time (s)     27.56551990332082
Sample Time (s)              21.37083867425099
Epoch Time (s)               93.03338915994391
Total Train Time (s)         31668.258181950077
Epoch                        389
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:36:08.764954 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #389 | Epoch Duration: 82.2130835056305
2020-01-11 09:36:08.765150 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #389 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0237369
Z variance train             0.0066868686
KL Divergence                10.160548
KL Loss                      1.0160549
QF Loss                      57.720665
VF Loss                      83.721176
Policy Loss                  -1605.4167
Q Predictions Mean           1605.3909
Q Predictions Std            130.57982
Q Predictions Max            1783.9889
Q Predictions Min            715.3685
V Predictions Mean           1602.9761
V Predictions Std            126.1645
V Predictions Max            1778.3744
V Predictions Min            834.2384
Log Pis Mean                 -0.44669306
Log Pis Std                  1.8370103
Log Pis Max                  9.348786
Log Pis Min                  -3.921846
Policy mu Mean               0.04034691
Policy mu Std                0.83290154
Policy mu Max                2.242352
Policy mu Min                -3.3142653
Policy log std Mean          -0.44682196
Policy log std Std           0.16759714
Policy log std Max           -0.07104643
Policy log std Min           -1.2903318
Z mean eval                  0.021307275
Z variance eval              0.0055681756
total_rewards                [2271.9528957  1386.1512479  1408.00886608 1616.43224013 1166.54433316
 3383.49652347 3385.4089655  3404.86869277 1864.2595982  2031.09298702]
total_rewards_mean           2191.8216349926934
total_rewards_std            842.704471071621
total_rewards_max            3404.8686927721383
total_rewards_min            1166.5443331592
Number of train steps total  391000
Number of env steps total    1957000
Number of rollouts total     0
Train Time (s)               44.144872524775565
(Previous) Eval Time (s)     16.74497465370223
Sample Time (s)              21.68204898200929
Epoch Time (s)               82.57189616048709
Total Train Time (s)         31755.24295039056
Epoch                        390
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:37:35.752544 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #390 | Epoch Duration: 86.98727369308472
2020-01-11 09:37:35.752667 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #390 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02117848
Z variance train             0.0055705914
KL Divergence                10.550653
KL Loss                      1.0550654
QF Loss                      80.7935
VF Loss                      29.469433
Policy Loss                  -1591.7391
Q Predictions Mean           1594.8643
Q Predictions Std            142.20142
Q Predictions Max            1789.3528
Q Predictions Min            825.7018
V Predictions Mean           1591.1355
V Predictions Std            140.79608
V Predictions Max            1784.1212
V Predictions Min            826.1939
Log Pis Mean                 -0.67299163
Log Pis Std                  1.9180058
Log Pis Max                  8.248602
Log Pis Min                  -4.6847568
Policy mu Mean               -0.005249822
Policy mu Std                0.827003
Policy mu Max                1.8284051
Policy mu Min                -3.2907238
Policy log std Mean          -0.44269216
Policy log std Std           0.15951933
Policy log std Max           0.005228281
Policy log std Min           -1.4675286
Z mean eval                  0.057103496
Z variance eval              0.004785658
total_rewards                [2378.89623555 1067.54950697 3470.56799438 3411.57135359 1363.46698028
 2161.69460301 1030.26103689 2903.16018815 1489.16459512 2155.18179946]
total_rewards_mean           2143.151429340452
total_rewards_std            862.3022954878915
total_rewards_max            3470.567994384894
total_rewards_min            1030.2610368890516
Number of train steps total  392000
Number of env steps total    1962000
Number of rollouts total     0
Train Time (s)               44.87745970534161
(Previous) Eval Time (s)     21.160103262402117
Sample Time (s)              21.906436883844435
Epoch Time (s)               87.94399985158816
Total Train Time (s)         31841.356293457095
Epoch                        391
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:39:01.867758 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #391 | Epoch Duration: 86.1149971485138
2020-01-11 09:39:01.867884 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #391 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.058273263
Z variance train             0.0047807163
KL Divergence                10.992271
KL Loss                      1.0992272
QF Loss                      68.95523
VF Loss                      74.64601
Policy Loss                  -1570.051
Q Predictions Mean           1570.2666
Q Predictions Std            192.71512
Q Predictions Max            1761.9259
Q Predictions Min            526.98865
V Predictions Mean           1571.1328
V Predictions Std            189.70609
V Predictions Max            1758.2312
V Predictions Min            549.7333
Log Pis Mean                 -0.54933757
Log Pis Std                  1.7981894
Log Pis Max                  6.8148785
Log Pis Min                  -4.5967755
Policy mu Mean               0.094988704
Policy mu Std                0.84039086
Policy mu Max                3.251623
Policy mu Min                -2.8956108
Policy log std Mean          -0.43545905
Policy log std Std           0.15662035
Policy log std Max           -0.05897543
Policy log std Min           -1.3961664
Z mean eval                  0.029187758
Z variance eval              0.004792294
total_rewards                [3273.87152515 1539.0361257  1017.21958622 1880.75411899 1026.80035975
 2004.06125363 1032.20377344 1610.39643493 2115.91200938 2771.11803232]
total_rewards_mean           1827.1373219516815
total_rewards_std            718.3391500202376
total_rewards_max            3273.871525145466
total_rewards_min            1017.2195862218151
Number of train steps total  393000
Number of env steps total    1967000
Number of rollouts total     0
Train Time (s)               44.03453034441918
(Previous) Eval Time (s)     19.3308427920565
Sample Time (s)              21.547540419735014
Epoch Time (s)               84.9129135562107
Total Train Time (s)         31922.923273317516
Epoch                        392
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:40:23.439068 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #392 | Epoch Duration: 81.57107329368591
2020-01-11 09:40:23.439262 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #392 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029225081
Z variance train             0.004792987
KL Divergence                10.933201
KL Loss                      1.0933201
QF Loss                      374.86182
VF Loss                      53.875805
Policy Loss                  -1593.9564
Q Predictions Mean           1594.5668
Q Predictions Std            162.74586
Q Predictions Max            1755.1039
Q Predictions Min            219.67859
V Predictions Mean           1592.7766
V Predictions Std            162.53145
V Predictions Max            1754.0642
V Predictions Min            228.96918
Log Pis Mean                 -0.39648804
Log Pis Std                  1.9513263
Log Pis Max                  7.6973753
Log Pis Min                  -6.546302
Policy mu Mean               -0.031116536
Policy mu Std                0.8528036
Policy mu Max                2.9274259
Policy mu Min                -3.2831361
Policy log std Mean          -0.43901417
Policy log std Std           0.17676339
Policy log std Max           -0.006457597
Policy log std Min           -1.370884
Z mean eval                  0.04815344
Z variance eval              0.004920203
total_rewards                [2544.85772904 2880.11078474 1044.62270672 2740.33795221 1652.29776402
 3319.91001874 3348.22199961 3344.84199917 1840.31898267 2738.57182138]
total_rewards_mean           2545.4091758293052
total_rewards_std            749.5296879771262
total_rewards_max            3348.2219996051235
total_rewards_min            1044.6227067204713
Number of train steps total  394000
Number of env steps total    1972000
Number of rollouts total     0
Train Time (s)               43.79629038227722
(Previous) Eval Time (s)     15.98873781785369
Sample Time (s)              21.874442882835865
Epoch Time (s)               81.65947108296677
Total Train Time (s)         32011.12169243116
Epoch                        393
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:41:51.642114 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #393 | Epoch Duration: 88.2027018070221
2020-01-11 09:41:51.642278 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #393 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.048187878
Z variance train             0.004921936
KL Divergence                10.945257
KL Loss                      1.0945257
QF Loss                      35.285072
VF Loss                      23.938076
Policy Loss                  -1613.364
Q Predictions Mean           1612.7834
Q Predictions Std            126.70307
Q Predictions Max            1772.7787
Q Predictions Min            607.4654
V Predictions Mean           1610.2361
V Predictions Std            126.83849
V Predictions Max            1770.3904
V Predictions Min            605.3572
Log Pis Mean                 -0.7284294
Log Pis Std                  1.607147
Log Pis Max                  4.483685
Log Pis Min                  -7.172286
Policy mu Mean               -0.019182207
Policy mu Std                0.7622031
Policy mu Max                1.6711817
Policy mu Min                -3.0333223
Policy log std Mean          -0.40763187
Policy log std Std           0.14633591
Policy log std Max           0.024621576
Policy log std Min           -0.9931139
Z mean eval                  0.031060273
Z variance eval              0.004566136
total_rewards                [2970.54971436  836.61998824 1035.41918563 1511.2866029  2037.18085502
  991.02618159 1596.67219719 2380.19743813  947.81404332 1016.39347695]
total_rewards_mean           1532.3159683327785
total_rewards_std            684.0032359073153
total_rewards_max            2970.549714355563
total_rewards_min            836.6199882401763
Number of train steps total  395000
Number of env steps total    1977000
Number of rollouts total     0
Train Time (s)               44.39575390703976
(Previous) Eval Time (s)     22.531718033831567
Sample Time (s)              21.479280422907323
Epoch Time (s)               88.40675236377865
Total Train Time (s)         32091.358766228426
Epoch                        394
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:43:11.881431 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #394 | Epoch Duration: 80.2390341758728
2020-01-11 09:43:11.881558 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #394 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0306077
Z variance train             0.0045676017
KL Divergence                11.079067
KL Loss                      1.1079067
QF Loss                      337.52332
VF Loss                      362.61435
Policy Loss                  -1572.3138
Q Predictions Mean           1571.3835
Q Predictions Std            206.81618
Q Predictions Max            1751.2831
Q Predictions Min            188.65186
V Predictions Mean           1578.5164
V Predictions Std            195.7652
V Predictions Max            1754.7283
V Predictions Min            561.98505
Log Pis Mean                 -0.48692572
Log Pis Std                  2.0576947
Log Pis Max                  10.162743
Log Pis Min                  -5.865412
Policy mu Mean               -0.011750032
Policy mu Std                0.8370112
Policy mu Max                3.2309222
Policy mu Min                -3.6329703
Policy log std Mean          -0.42629734
Policy log std Std           0.1597263
Policy log std Max           -0.024498284
Policy log std Min           -1.0882196
Z mean eval                  0.047807448
Z variance eval              0.0047131954
total_rewards                [2403.99902133 1224.94602298 1968.17343641 3382.01633086 3437.93486514
 1600.09948582 2250.55900313 2904.25016894 3402.95215378  968.73161174]
total_rewards_mean           2354.36621001338
total_rewards_std            869.4231623088847
total_rewards_max            3437.93486514254
total_rewards_min            968.7316117369226
Number of train steps total  396000
Number of env steps total    1982000
Number of rollouts total     0
Train Time (s)               44.60602247295901
(Previous) Eval Time (s)     14.363750775810331
Sample Time (s)              21.587981456890702
Epoch Time (s)               80.55775470566005
Total Train Time (s)         32180.062831178308
Epoch                        395
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:44:40.592499 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #395 | Epoch Duration: 88.71081256866455
2020-01-11 09:44:40.592687 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #395 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04776016
Z variance train             0.0047126953
KL Divergence                11.12265
KL Loss                      1.112265
QF Loss                      198.00055
VF Loss                      207.88138
Policy Loss                  -1587.9014
Q Predictions Mean           1585.9425
Q Predictions Std            156.14613
Q Predictions Max            1757.2118
Q Predictions Min            676.82605
V Predictions Mean           1594.7585
V Predictions Std            154.03561
V Predictions Max            1759.5052
V Predictions Min            671.9615
Log Pis Mean                 -0.4433126
Log Pis Std                  2.010884
Log Pis Max                  9.385865
Log Pis Min                  -4.731546
Policy mu Mean               -0.07563191
Policy mu Std                0.82802755
Policy mu Max                2.1560593
Policy mu Min                -3.1863742
Policy log std Mean          -0.4311382
Policy log std Std           0.17833544
Policy log std Max           -0.03675732
Policy log std Min           -1.1785791
Z mean eval                  0.024972491
Z variance eval              0.0044233534
total_rewards                [3311.80239827 1553.45664467 2979.62021541 1039.09191402 2624.95027823
  231.59495364 1192.63720197 3362.83684051 1056.19669812  758.28527838]
total_rewards_mean           1811.0472423211577
total_rewards_std            1091.136723438302
total_rewards_max            3362.836840509087
total_rewards_min            231.5949536429165
Number of train steps total  397000
Number of env steps total    1987000
Number of rollouts total     0
Train Time (s)               44.69372630910948
(Previous) Eval Time (s)     22.516565705183893
Sample Time (s)              19.84792149439454
Epoch Time (s)               87.05821350868791
Total Train Time (s)         32261.26465618657
Epoch                        396
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:46:01.798881 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #396 | Epoch Duration: 81.2060399055481
2020-01-11 09:46:01.799074 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #396 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02552099
Z variance train             0.004418764
KL Divergence                11.333353
KL Loss                      1.1333354
QF Loss                      152.7461
VF Loss                      83.80544
Policy Loss                  -1601.8339
Q Predictions Mean           1600.4824
Q Predictions Std            162.62871
Q Predictions Max            1768.6855
Q Predictions Min            342.83627
V Predictions Mean           1603.0198
V Predictions Std            162.42628
V Predictions Max            1779.9176
V Predictions Min            336.5894
Log Pis Mean                 -0.65603304
Log Pis Std                  1.9619265
Log Pis Max                  9.745523
Log Pis Min                  -5.829157
Policy mu Mean               0.060999334
Policy mu Std                0.80961
Policy mu Max                1.8175116
Policy mu Min                -3.4628253
Policy log std Mean          -0.41467515
Policy log std Std           0.16640146
Policy log std Max           -0.06346026
Policy log std Min           -1.109416
Z mean eval                  0.025401682
Z variance eval              0.0036299217
total_rewards                [3380.60701933 3365.09343108 2717.98023306 3408.70287799 1332.88335429
 1920.11203628 1970.33363528 1178.78380447 1366.21636803 1866.50840809]
total_rewards_mean           2250.722116790489
total_rewards_std            847.7667113333929
total_rewards_max            3408.7028779906414
total_rewards_min            1178.7838044659852
Number of train steps total  398000
Number of env steps total    1992000
Number of rollouts total     0
Train Time (s)               43.93366579292342
(Previous) Eval Time (s)     16.6641682269983
Sample Time (s)              22.259055827278644
Epoch Time (s)               82.85688984720036
Total Train Time (s)         32346.974836374167
Epoch                        397
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:47:27.513082 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #397 | Epoch Duration: 85.71385383605957
2020-01-11 09:47:27.513260 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #397 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025480459
Z variance train             0.0036304544
KL Divergence                11.840689
KL Loss                      1.1840689
QF Loss                      45.788902
VF Loss                      32.84723
Policy Loss                  -1592.7548
Q Predictions Mean           1591.8027
Q Predictions Std            139.39502
Q Predictions Max            1747.229
Q Predictions Min            580.4843
V Predictions Mean           1592.4929
V Predictions Std            138.76962
V Predictions Max            1746.9084
V Predictions Min            595.09094
Log Pis Mean                 -0.54927576
Log Pis Std                  1.8392469
Log Pis Max                  9.802824
Log Pis Min                  -5.9674206
Policy mu Mean               -0.01778
Policy mu Std                0.7827325
Policy mu Max                2.0666158
Policy mu Min                -3.2301936
Policy log std Mean          -0.42616403
Policy log std Std           0.16370526
Policy log std Max           -0.020790458
Policy log std Min           -1.1838785
Z mean eval                  0.06848463
Z variance eval              0.0042392705
total_rewards                [1063.77053164 1921.49621065  966.18896298 1022.01939774 1045.80103168
 1363.04279711 1333.32335523 1017.15999134 1154.43962344 1308.17707418]
total_rewards_mean           1219.5418975997234
total_rewards_std            271.4746722734392
total_rewards_max            1921.4962106532996
total_rewards_min            966.1889629782444
Number of train steps total  399000
Number of env steps total    1997000
Number of rollouts total     0
Train Time (s)               44.16065013688058
(Previous) Eval Time (s)     19.520886411890388
Sample Time (s)              21.768831009045243
Epoch Time (s)               85.45036755781621
Total Train Time (s)         32425.1187781943
Epoch                        398
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:48:45.658943 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #398 | Epoch Duration: 78.14555525779724
2020-01-11 09:48:45.659072 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #398 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.068414606
Z variance train             0.004238569
KL Divergence                11.452742
KL Loss                      1.1452742
QF Loss                      459.0232
VF Loss                      89.63302
Policy Loss                  -1590.9093
Q Predictions Mean           1589.7504
Q Predictions Std            177.49937
Q Predictions Max            1768.3262
Q Predictions Min            39.129475
V Predictions Mean           1591.0917
V Predictions Std            177.23991
V Predictions Max            1769.3619
V Predictions Min            16.589556
Log Pis Mean                 -0.29107535
Log Pis Std                  2.0704439
Log Pis Max                  13.288227
Log Pis Min                  -5.4315677
Policy mu Mean               0.0003029344
Policy mu Std                0.86562353
Policy mu Max                3.7133646
Policy mu Min                -3.5163507
Policy log std Mean          -0.43944037
Policy log std Std           0.16015802
Policy log std Max           -0.039675474
Policy log std Min           -1.2621952
Z mean eval                  0.028690476
Z variance eval              0.0041880147
total_rewards                [2195.55127241 1447.14389532 1752.45655425 3345.27799805 1642.62036536
  967.50086499 1287.79245739 1561.27692533 2694.3099691  2493.0998365 ]
total_rewards_mean           1938.7030138693008
total_rewards_std            692.5369005411654
total_rewards_max            3345.277998054349
total_rewards_min            967.5008649933291
Number of train steps total  400000
Number of env steps total    2002000
Number of rollouts total     0
Train Time (s)               44.104760359972715
(Previous) Eval Time (s)     12.215835974086076
Sample Time (s)              21.956174852792174
Epoch Time (s)               78.27677118685097
Total Train Time (s)         32509.232140354812
Epoch                        399
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:50:09.775487 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #399 | Epoch Duration: 84.11630272865295
2020-01-11 09:50:09.775610 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #399 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02873512
Z variance train             0.004188933
KL Divergence                11.458357
KL Loss                      1.1458358
QF Loss                      495.8388
VF Loss                      69.230606
Policy Loss                  -1606.2483
Q Predictions Mean           1605.739
Q Predictions Std            157.88875
Q Predictions Max            1797.7977
Q Predictions Min            563.5737
V Predictions Mean           1604.6841
V Predictions Std            151.1835
V Predictions Max            1787.7338
V Predictions Min            553.32855
Log Pis Mean                 -0.62669086
Log Pis Std                  1.8867359
Log Pis Max                  10.180595
Log Pis Min                  -5.1777625
Policy mu Mean               0.0025412415
Policy mu Std                0.7645875
Policy mu Max                2.2605612
Policy mu Min                -3.4298737
Policy log std Mean          -0.42254272
Policy log std Std           0.16649707
Policy log std Max           0.07949382
Policy log std Min           -1.8576792
Z mean eval                  0.01992378
Z variance eval              0.0040773842
total_rewards                [2405.28326533 1092.47792998 2624.34471387 3294.91125313 2355.65337843
  942.9728172  1247.47211088 1976.84194247 3353.04763753 1858.91006814]
total_rewards_mean           2115.1915116955233
total_rewards_std            811.3591099424316
total_rewards_max            3353.047637528799
total_rewards_min            942.9728172020039
Number of train steps total  401000
Number of env steps total    2007000
Number of rollouts total     0
Train Time (s)               43.753201817162335
(Previous) Eval Time (s)     18.055111817084253
Sample Time (s)              21.792721931356937
Epoch Time (s)               83.60103556560352
Total Train Time (s)         32594.603281114716
Epoch                        400
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:51:35.149904 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #400 | Epoch Duration: 85.37418055534363
2020-01-11 09:51:35.150025 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #400 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019555544
Z variance train             0.0040806746
KL Divergence                11.503165
KL Loss                      1.1503166
QF Loss                      91.43132
VF Loss                      82.494255
Policy Loss                  -1596.8832
Q Predictions Mean           1594.3378
Q Predictions Std            137.64142
Q Predictions Max            1726.8728
Q Predictions Min            503.93164
V Predictions Mean           1600.7451
V Predictions Std            136.65097
V Predictions Max            1730.1764
V Predictions Min            502.01895
Log Pis Mean                 -0.5797672
Log Pis Std                  1.8614651
Log Pis Max                  8.731564
Log Pis Min                  -5.295706
Policy mu Mean               -0.04670352
Policy mu Std                0.82338816
Policy mu Max                1.9700998
Policy mu Min                -3.1362293
Policy log std Mean          -0.41933092
Policy log std Std           0.14794248
Policy log std Max           -0.082303226
Policy log std Min           -0.9620409
Z mean eval                  0.036667813
Z variance eval              0.004473659
total_rewards                [3306.11722012 2615.18152668 2774.87043447 3289.79391824 1825.50126829
 1108.60251225 3327.64351269 3243.32735101  690.59696926 2447.34742097]
total_rewards_mean           2462.8982133979785
total_rewards_std            908.5059705138043
total_rewards_max            3327.643512691818
total_rewards_min            690.5969692622226
Number of train steps total  402000
Number of env steps total    2012000
Number of rollouts total     0
Train Time (s)               44.42399117490277
(Previous) Eval Time (s)     19.828015092760324
Sample Time (s)              21.849277175497264
Epoch Time (s)               86.10128344316036
Total Train Time (s)         32683.86976518482
Epoch                        401
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:53:04.420271 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #401 | Epoch Duration: 89.27013731002808
2020-01-11 09:53:04.420452 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #401 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036778543
Z variance train             0.004471118
KL Divergence                11.220928
KL Loss                      1.1220928
QF Loss                      56.099693
VF Loss                      35.07785
Policy Loss                  -1595.767
Q Predictions Mean           1594.4912
Q Predictions Std            150.68236
Q Predictions Max            1764.4332
Q Predictions Min            334.2847
V Predictions Mean           1595.8585
V Predictions Std            151.65633
V Predictions Max            1766.7838
V Predictions Min            311.25632
Log Pis Mean                 -0.60848844
Log Pis Std                  1.9531544
Log Pis Max                  9.369238
Log Pis Min                  -6.2616553
Policy mu Mean               -0.005264183
Policy mu Std                0.8345723
Policy mu Max                1.8127494
Policy mu Min                -3.278984
Policy log std Mean          -0.42473063
Policy log std Std           0.16296995
Policy log std Max           -0.06620884
Policy log std Min           -1.2119961
Z mean eval                  0.027873537
Z variance eval              0.004623713
total_rewards                [1214.30489611 1270.3790273  1607.50290539  922.68678051 2158.88227989
 1321.28693202 1321.97432565  878.31769016 1560.91562664 1837.8931397 ]
total_rewards_mean           1409.4143603367222
total_rewards_std            374.06765061408447
total_rewards_max            2158.8822798900137
total_rewards_min            878.3176901648312
Number of train steps total  403000
Number of env steps total    2017000
Number of rollouts total     0
Train Time (s)               44.44942449871451
(Previous) Eval Time (s)     22.996610771864653
Sample Time (s)              22.268480900209397
Epoch Time (s)               89.71451617078856
Total Train Time (s)         32764.232915828936
Epoch                        402
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:54:24.786164 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #402 | Epoch Duration: 80.36558365821838
2020-01-11 09:54:24.786296 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #402 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028510774
Z variance train             0.0046254224
KL Divergence                11.007957
KL Loss                      1.1007957
QF Loss                      57.28871
VF Loss                      62.372128
Policy Loss                  -1582.3027
Q Predictions Mean           1581.0822
Q Predictions Std            183.41765
Q Predictions Max            1739.6937
Q Predictions Min            491.95514
V Predictions Mean           1579.3469
V Predictions Std            181.39944
V Predictions Max            1741.9078
V Predictions Min            505.82977
Log Pis Mean                 -0.45537788
Log Pis Std                  1.9446499
Log Pis Max                  7.238984
Log Pis Min                  -4.383488
Policy mu Mean               -0.012465748
Policy mu Std                0.8365931
Policy mu Max                2.1574872
Policy mu Min                -3.3943353
Policy log std Mean          -0.41444626
Policy log std Std           0.14754072
Policy log std Max           -0.05098912
Policy log std Min           -1.0516797
Z mean eval                  0.059936155
Z variance eval              0.0042701485
total_rewards                [1236.85012093 1567.0921174   822.62932232 3248.81704364 1554.64283144
  787.12906834 3186.21096372 2039.38359743 1234.0411331  1006.99508624]
total_rewards_mean           1668.3791284562842
total_rewards_std            852.445120618131
total_rewards_max            3248.8170436412847
total_rewards_min            787.1290683358266
Number of train steps total  404000
Number of env steps total    2022000
Number of rollouts total     0
Train Time (s)               43.70406606188044
(Previous) Eval Time (s)     13.647428926080465
Sample Time (s)              21.33023300766945
Epoch Time (s)               78.68172799563035
Total Train Time (s)         32844.2049535336
Epoch                        403
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:55:44.762053 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #403 | Epoch Duration: 79.97564363479614
2020-01-11 09:55:44.762230 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #403 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0596968
Z variance train             0.0042693526
KL Divergence                11.21712
KL Loss                      1.1217121
QF Loss                      68.90484
VF Loss                      19.75755
Policy Loss                  -1591.351
Q Predictions Mean           1589.2977
Q Predictions Std            150.05334
Q Predictions Max            1746.6686
Q Predictions Min            667.2879
V Predictions Mean           1592.0625
V Predictions Std            149.27634
V Predictions Max            1750.6586
V Predictions Min            687.72205
Log Pis Mean                 -0.6952343
Log Pis Std                  1.8116138
Log Pis Max                  6.3281183
Log Pis Min                  -5.0010834
Policy mu Mean               -0.03089193
Policy mu Std                0.8221202
Policy mu Max                1.8848207
Policy mu Min                -3.191041
Policy log std Mean          -0.41099486
Policy log std Std           0.1789388
Policy log std Max           0.18447697
Policy log std Min           -1.7070208
Z mean eval                  0.045780353
Z variance eval              0.004648667
total_rewards                [ 882.08823908 1616.5413738  1202.03705881 1010.55452245 3368.27568107
  971.2659616  1154.88939924 3344.96515975 1325.30535479 1062.8410165 ]
total_rewards_mean           1593.8763767107691
total_rewards_std            902.787104033141
total_rewards_max            3368.2756810736287
total_rewards_min            882.0882390752264
Number of train steps total  405000
Number of env steps total    2027000
Number of rollouts total     0
Train Time (s)               43.85655133193359
(Previous) Eval Time (s)     14.941091482993215
Sample Time (s)              21.493842666503042
Epoch Time (s)               80.29148548142985
Total Train Time (s)         32923.996626323555
Epoch                        404
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:57:04.558365 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #404 | Epoch Duration: 79.79592657089233
2020-01-11 09:57:04.558635 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #404 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046174645
Z variance train             0.0046465555
KL Divergence                11.08263
KL Loss                      1.108263
QF Loss                      80.80413
VF Loss                      85.64337
Policy Loss                  -1596.8245
Q Predictions Mean           1595.973
Q Predictions Std            151.52708
Q Predictions Max            1770.5875
Q Predictions Min            615.5908
V Predictions Mean           1597.186
V Predictions Std            149.0489
V Predictions Max            1762.4048
V Predictions Min            602.2928
Log Pis Mean                 -0.6490203
Log Pis Std                  1.7368915
Log Pis Max                  7.7811184
Log Pis Min                  -4.838678
Policy mu Mean               -0.024588572
Policy mu Std                0.7701395
Policy mu Max                2.0680416
Policy mu Min                -3.2753584
Policy log std Mean          -0.38430008
Policy log std Std           0.18485703
Policy log std Max           0.013963014
Policy log std Min           -1.327599
Z mean eval                  0.0491075
Z variance eval              0.004963823
total_rewards                [1402.08757287 1087.49747936 1013.67551548  982.94261994 1040.76470179
 2337.85862523 1306.10745238 2751.09916012 1341.44824302 3322.20487791]
total_rewards_mean           1658.5686248113466
total_rewards_std            793.3146767766219
total_rewards_max            3322.204877909343
total_rewards_min            982.942619942608
Number of train steps total  406000
Number of env steps total    2032000
Number of rollouts total     0
Train Time (s)               44.82578624319285
(Previous) Eval Time (s)     14.445264023728669
Sample Time (s)              19.95860836096108
Epoch Time (s)               79.2296586278826
Total Train Time (s)         33006.11909423722
Epoch                        405
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:58:26.684229 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #405 | Epoch Duration: 82.12542986869812
2020-01-11 09:58:26.684408 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #405 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.048721053
Z variance train             0.0049568666
KL Divergence                10.878016
KL Loss                      1.0878017
QF Loss                      103.08352
VF Loss                      74.43802
Policy Loss                  -1591.7771
Q Predictions Mean           1591.9305
Q Predictions Std            115.769516
Q Predictions Max            1759.6969
Q Predictions Min            1271.8839
V Predictions Mean           1591.573
V Predictions Std            117.4644
V Predictions Max            1752.0065
V Predictions Min            1290.5702
Log Pis Mean                 -0.5745977
Log Pis Std                  1.7171882
Log Pis Max                  6.346272
Log Pis Min                  -4.5699944
Policy mu Mean               -0.012905885
Policy mu Std                0.76807135
Policy mu Max                1.6077695
Policy mu Min                -2.7443612
Policy log std Mean          -0.40550938
Policy log std Std           0.16745785
Policy log std Max           0.19012693
Policy log std Min           -1.2913088
Z mean eval                  0.025263513
Z variance eval              0.004585
total_rewards                [1038.02804411 1250.83131065 1322.61162652 1042.31379805 1332.52164229
 1032.35030792  827.47235404 1657.7279465  2794.82540258  813.54109329]
total_rewards_mean           1311.222352594596
total_rewards_std            550.6170942628942
total_rewards_max            2794.825402581638
total_rewards_min            813.541093293217
Number of train steps total  407000
Number of env steps total    2037000
Number of rollouts total     0
Train Time (s)               43.70531533891335
(Previous) Eval Time (s)     17.340778197161853
Sample Time (s)              20.819760993588716
Epoch Time (s)               81.86585452966392
Total Train Time (s)         33083.72113795485
Epoch                        406
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:59:44.289045 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #406 | Epoch Duration: 77.60441422462463
2020-01-11 09:59:44.289196 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #406 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025014248
Z variance train             0.0045805024
KL Divergence                11.098764
KL Loss                      1.1098765
QF Loss                      58.272633
VF Loss                      53.68545
Policy Loss                  -1581.7523
Q Predictions Mean           1582.6345
Q Predictions Std            184.0123
Q Predictions Max            1752.3634
Q Predictions Min            -18.65623
V Predictions Mean           1583.5459
V Predictions Std            183.45135
V Predictions Max            1749.9181
V Predictions Min            -37.924927
Log Pis Mean                 -0.8044244
Log Pis Std                  1.6054268
Log Pis Max                  6.611467
Log Pis Min                  -5.3727217
Policy mu Mean               0.05774051
Policy mu Std                0.71430016
Policy mu Max                2.0268798
Policy mu Min                -3.0357165
Policy log std Mean          -0.38128805
Policy log std Std           0.15238386
Policy log std Max           0.0851737
Policy log std Min           -1.1513546
Z mean eval                  0.020404741
Z variance eval              0.0039542047
total_rewards                [3339.85075021 3410.10904746 3445.51663985 1571.40853452 1027.93517304
 2032.7789219  1059.61456553 2491.26037776 3429.02698131 1856.96348961]
total_rewards_mean           2366.446448118172
total_rewards_std            940.6492508783352
total_rewards_max            3445.5166398452943
total_rewards_min            1027.9351730376554
Number of train steps total  408000
Number of env steps total    2042000
Number of rollouts total     0
Train Time (s)               44.216263202019036
(Previous) Eval Time (s)     13.079178046900779
Sample Time (s)              21.871654911432415
Epoch Time (s)               79.16709616035223
Total Train Time (s)         33172.88454333646
Epoch                        407
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:01:13.456006 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #407 | Epoch Duration: 89.16664242744446
2020-01-11 10:01:13.456193 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #407 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020373438
Z variance train             0.003953137
KL Divergence                11.437708
KL Loss                      1.1437708
QF Loss                      41.483543
VF Loss                      22.385668
Policy Loss                  -1597.6859
Q Predictions Mean           1596.6597
Q Predictions Std            144.91743
Q Predictions Max            1766.6725
Q Predictions Min            451.84985
V Predictions Mean           1594.8708
V Predictions Std            145.03032
V Predictions Max            1760.9363
V Predictions Min            447.8497
Log Pis Mean                 -0.6031505
Log Pis Std                  1.8660742
Log Pis Max                  10.7844095
Log Pis Min                  -4.8971896
Policy mu Mean               0.061777726
Policy mu Std                0.7765889
Policy mu Max                1.9528108
Policy mu Min                -3.1295543
Policy log std Mean          -0.40822005
Policy log std Std           0.16424647
Policy log std Max           0.00569582
Policy log std Min           -1.1840518
Z mean eval                  0.016694665
Z variance eval              0.004488242
total_rewards                [3300.25609916 2134.74946231 2631.62482141 1899.616996   2521.03483891
 2506.77389338 2187.35876355  987.91191084 1882.54761203 2244.97672725]
total_rewards_mean           2229.6851124846567
total_rewards_std            570.2480901990435
total_rewards_max            3300.2560991601877
total_rewards_min            987.9119108365325
Number of train steps total  409000
Number of env steps total    2047000
Number of rollouts total     0
Train Time (s)               44.52024574205279
(Previous) Eval Time (s)     23.078484694007784
Sample Time (s)              22.135430924594402
Epoch Time (s)               89.73416136065498
Total Train Time (s)         33260.895247299224
Epoch                        408
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:02:41.469276 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #408 | Epoch Duration: 88.01296401023865
2020-01-11 10:02:41.469400 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #408 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017403819
Z variance train             0.0044914745
KL Divergence                11.226816
KL Loss                      1.1226816
QF Loss                      96.31591
VF Loss                      96.18205
Policy Loss                  -1591.6344
Q Predictions Mean           1589.2524
Q Predictions Std            138.13144
Q Predictions Max            1772.221
Q Predictions Min            843.672
V Predictions Mean           1586.8599
V Predictions Std            135.02504
V Predictions Max            1771.8573
V Predictions Min            915.27985
Log Pis Mean                 -0.60152805
Log Pis Std                  2.051593
Log Pis Max                  17.470154
Log Pis Min                  -4.254171
Policy mu Mean               -0.0312527
Policy mu Std                0.7946091
Policy mu Max                6.0916715
Policy mu Min                -2.9380434
Policy log std Mean          -0.43034586
Policy log std Std           0.18469715
Policy log std Max           -0.019308507
Policy log std Min           -1.3159962
Z mean eval                  0.03654516
Z variance eval              0.004289997
total_rewards                [1317.63826447 2034.2688422  2518.48319073 3449.96418764 1053.68463478
 2302.98219622 1278.74211494 3431.75130106 1318.77701107 3423.31048289]
total_rewards_mean           2212.9602225979615
total_rewards_std            918.248631360824
total_rewards_max            3449.9641876444925
total_rewards_min            1053.6846347768699
Number of train steps total  410000
Number of env steps total    2052000
Number of rollouts total     0
Train Time (s)               43.66368260234594
(Previous) Eval Time (s)     21.357044871896505
Sample Time (s)              21.309025610797107
Epoch Time (s)               86.32975308503956
Total Train Time (s)         33345.237115043215
Epoch                        409
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:04:05.817054 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #409 | Epoch Duration: 84.34754180908203
2020-01-11 10:04:05.817231 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #409 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03726532
Z variance train             0.004289718
KL Divergence                11.252178
KL Loss                      1.1252178
QF Loss                      162.92867
VF Loss                      30.84566
Policy Loss                  -1613.7416
Q Predictions Mean           1615.1934
Q Predictions Std            130.13083
Q Predictions Max            1770.2314
Q Predictions Min            887.03455
V Predictions Mean           1617.3477
V Predictions Std            130.62064
V Predictions Max            1770.431
V Predictions Min            888.3679
Log Pis Mean                 -0.45927292
Log Pis Std                  1.7436233
Log Pis Max                  9.574704
Log Pis Min                  -4.076935
Policy mu Mean               -0.067217
Policy mu Std                0.80935884
Policy mu Max                2.0646832
Policy mu Min                -3.4432418
Policy log std Mean          -0.43365756
Policy log std Std           0.17261325
Policy log std Max           0.05938244
Policy log std Min           -1.8894175
Z mean eval                  0.028117204
Z variance eval              0.004556128
total_rewards                [3397.59302364 1437.25444354 2304.57086361 1700.00409187 3437.77037862
 1452.52470692 1698.19757919 2111.79841981 3440.07311379 1364.64177525]
total_rewards_mean           2234.442839623827
total_rewards_std            827.7114484681912
total_rewards_max            3440.073113785742
total_rewards_min            1364.6417752480038
Number of train steps total  411000
Number of env steps total    2057000
Number of rollouts total     0
Train Time (s)               44.514041516929865
(Previous) Eval Time (s)     19.37452652398497
Sample Time (s)              22.049870115239173
Epoch Time (s)               85.938438156154
Total Train Time (s)         33431.19002089882
Epoch                        410
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:05:31.774149 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #410 | Epoch Duration: 85.9567723274231
2020-01-11 10:05:31.774326 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #410 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028168729
Z variance train             0.004557061
KL Divergence                11.106297
KL Loss                      1.1106297
QF Loss                      54.90493
VF Loss                      37.814205
Policy Loss                  -1585.3577
Q Predictions Mean           1582.6884
Q Predictions Std            167.30971
Q Predictions Max            1741.3688
Q Predictions Min            457.27072
V Predictions Mean           1580.8564
V Predictions Std            164.6593
V Predictions Max            1741.4966
V Predictions Min            473.20566
Log Pis Mean                 -0.51236266
Log Pis Std                  1.9570614
Log Pis Max                  9.62731
Log Pis Min                  -6.262004
Policy mu Mean               0.0013535988
Policy mu Std                0.81030935
Policy mu Max                2.3442142
Policy mu Min                -3.407337
Policy log std Mean          -0.4316326
Policy log std Std           0.15703546
Policy log std Max           -0.005167693
Policy log std Min           -1.1865871
Z mean eval                  0.030692587
Z variance eval              0.0047499896
total_rewards                [3337.85661705 2794.16242234 1259.49950227 3364.41767331 3333.73360284
  162.38428625 3378.98123457 2941.11402481 2252.70213038  257.50283749]
total_rewards_mean           2308.235433130485
total_rewards_std            1221.6200902346213
total_rewards_max            3378.9812345716687
total_rewards_min            162.38428624563247
Number of train steps total  412000
Number of env steps total    2062000
Number of rollouts total     0
Train Time (s)               44.394464975222945
(Previous) Eval Time (s)     19.392593116965145
Sample Time (s)              19.922708219382912
Epoch Time (s)               83.709766311571
Total Train Time (s)         33517.998010479845
Epoch                        411
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:06:58.590420 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #411 | Epoch Duration: 86.81593346595764
2020-01-11 10:06:58.590670 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #411 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030715942
Z variance train             0.0047515086
KL Divergence                11.039928
KL Loss                      1.1039928
QF Loss                      92.04673
VF Loss                      134.64557
Policy Loss                  -1598.9081
Q Predictions Mean           1598.8472
Q Predictions Std            143.25525
Q Predictions Max            1779.789
Q Predictions Min            887.9675
V Predictions Mean           1596.6798
V Predictions Std            144.3177
V Predictions Max            1775.2887
V Predictions Min            826.7734
Log Pis Mean                 -0.46164948
Log Pis Std                  1.7603521
Log Pis Max                  8.032549
Log Pis Min                  -4.5693254
Policy mu Mean               0.09387618
Policy mu Std                0.81727314
Policy mu Max                2.2706065
Policy mu Min                -3.2034235
Policy log std Mean          -0.43801665
Policy log std Std           0.17464265
Policy log std Max           -0.047109693
Policy log std Min           -1.1750313
Z mean eval                  0.040632047
Z variance eval              0.00457923
total_rewards                [1325.62287061 3002.42695453 3414.45125048 2904.74020252 3230.16186108
 1413.91028592 1345.71973448 1075.97401539 1041.7861485  3414.2711387 ]
total_rewards_mean           2216.906446221545
total_rewards_std            993.2487152878663
total_rewards_max            3414.4512504848544
total_rewards_min            1041.7861485014575
Number of train steps total  413000
Number of env steps total    2067000
Number of rollouts total     0
Train Time (s)               44.09549510432407
(Previous) Eval Time (s)     22.498523585963994
Sample Time (s)              21.94700916018337
Epoch Time (s)               88.54102785047144
Total Train Time (s)         33605.01668032771
Epoch                        412
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:08:25.612249 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #412 | Epoch Duration: 87.02141094207764
2020-01-11 10:08:25.612372 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #412 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04170108
Z variance train             0.0045724222
KL Divergence                11.01188
KL Loss                      1.1011881
QF Loss                      339.13422
VF Loss                      343.0679
Policy Loss                  -1605.9452
Q Predictions Mean           1606.3369
Q Predictions Std            159.82904
Q Predictions Max            1776.457
Q Predictions Min            177.9054
V Predictions Mean           1595.3252
V Predictions Std            162.14554
V Predictions Max            1775.2816
V Predictions Min            140.46284
Log Pis Mean                 -0.619273
Log Pis Std                  1.8414258
Log Pis Max                  6.5182176
Log Pis Min                  -4.175502
Policy mu Mean               -0.011328106
Policy mu Std                0.78494865
Policy mu Max                2.229261
Policy mu Min                -3.1564486
Policy log std Mean          -0.42283726
Policy log std Std           0.17168625
Policy log std Max           -0.034901828
Policy log std Min           -1.1264278
Z mean eval                  0.025383497
Z variance eval              0.0049944995
total_rewards                [3416.28306919 3427.65190276 3398.35313834 1026.50058477 3410.84610384
 2771.61122093 1006.3649221  3450.18510507 1876.72049846 3372.40702325]
total_rewards_mean           2715.6923568699194
total_rewards_std            969.5309064994068
total_rewards_max            3450.1851050657287
total_rewards_min            1006.3649221028347
Number of train steps total  414000
Number of env steps total    2072000
Number of rollouts total     0
Train Time (s)               43.707261573988944
(Previous) Eval Time (s)     20.97865751804784
Sample Time (s)              22.049426056910306
Epoch Time (s)               86.73534514894709
Total Train Time (s)         33697.30685824016
Epoch                        413
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:09:57.905325 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #413 | Epoch Duration: 92.29283094406128
2020-01-11 10:09:57.905452 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #413 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025285404
Z variance train             0.004993367
KL Divergence                10.772072
KL Loss                      1.0772072
QF Loss                      57.866295
VF Loss                      56.159363
Policy Loss                  -1602.0059
Q Predictions Mean           1602.729
Q Predictions Std            140.36406
Q Predictions Max            1770.2067
Q Predictions Min            730.8027
V Predictions Mean           1601.0046
V Predictions Std            140.73152
V Predictions Max            1774.5011
V Predictions Min            732.6645
Log Pis Mean                 -0.7255064
Log Pis Std                  1.6403565
Log Pis Max                  5.302866
Log Pis Min                  -4.745646
Policy mu Mean               0.007553021
Policy mu Std                0.734692
Policy mu Max                1.8768035
Policy mu Min                -2.8947158
Policy log std Mean          -0.41241574
Policy log std Std           0.16164042
Policy log std Max           -0.0063180327
Policy log std Min           -1.0568717
Z mean eval                  0.02089102
Z variance eval              0.005191033
total_rewards                [1863.38794665 1488.6374344  3429.79079048  214.09493762 2111.95728961
  968.06409938 3174.74579645 1249.70673239 2130.65565961  992.06968681]
total_rewards_mean           1762.3110373405755
total_rewards_std            948.806667466418
total_rewards_max            3429.790790477138
total_rewards_min            214.09493762178533
Number of train steps total  415000
Number of env steps total    2077000
Number of rollouts total     0
Train Time (s)               43.820963468868285
(Previous) Eval Time (s)     26.535887914709747
Sample Time (s)              21.335630847141147
Epoch Time (s)               91.69248223071918
Total Train Time (s)         33779.21077685477
Epoch                        414
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:11:19.815027 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #414 | Epoch Duration: 81.90948104858398
2020-01-11 10:11:19.815163 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #414 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020821359
Z variance train             0.0051883557
KL Divergence                10.691193
KL Loss                      1.0691193
QF Loss                      106.786316
VF Loss                      25.456488
Policy Loss                  -1585.4181
Q Predictions Mean           1586.7615
Q Predictions Std            138.03758
Q Predictions Max            1755.9775
Q Predictions Min            921.45166
V Predictions Mean           1584.8492
V Predictions Std            136.9133
V Predictions Max            1757.0474
V Predictions Min            930.1926
Log Pis Mean                 -0.56413877
Log Pis Std                  1.7798759
Log Pis Max                  7.4764886
Log Pis Min                  -3.9663205
Policy mu Mean               -0.042111054
Policy mu Std                0.778972
Policy mu Max                2.1743755
Policy mu Min                -3.1807425
Policy log std Mean          -0.42987022
Policy log std Std           0.18034427
Policy log std Max           0.0082782805
Policy log std Min           -1.2505882
Z mean eval                  0.010901123
Z variance eval              0.005262171
total_rewards                [1148.62816435 1022.7584073  2862.29981065 3393.7628378  1085.56077603
 2305.60768246 1968.35850542  984.03202389 3324.48947522 2050.0642471 ]
total_rewards_mean           2014.556193021718
total_rewards_std            899.0783157400377
total_rewards_max            3393.762837797845
total_rewards_min            984.0320238884048
Number of train steps total  416000
Number of env steps total    2082000
Number of rollouts total     0
Train Time (s)               44.00342003023252
(Previous) Eval Time (s)     16.75262748496607
Sample Time (s)              22.059208745136857
Epoch Time (s)               82.81525626033545
Total Train Time (s)         33864.99655889394
Epoch                        415
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:12:45.603745 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #415 | Epoch Duration: 85.7884750366211
2020-01-11 10:12:45.603868 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #415 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010834925
Z variance train             0.00526198
KL Divergence                10.642378
KL Loss                      1.0642378
QF Loss                      69.78224
VF Loss                      30.273838
Policy Loss                  -1601.0483
Q Predictions Mean           1602.6421
Q Predictions Std            163.99011
Q Predictions Max            1777.9135
Q Predictions Min            328.34488
V Predictions Mean           1598.0406
V Predictions Std            164.21
V Predictions Max            1770.6221
V Predictions Min            325.31204
Log Pis Mean                 -0.7104558
Log Pis Std                  1.7519795
Log Pis Max                  5.7689853
Log Pis Min                  -6.619829
Policy mu Mean               -0.0038391042
Policy mu Std                0.757129
Policy mu Max                2.1362824
Policy mu Min                -3.2266772
Policy log std Mean          -0.4057369
Policy log std Std           0.15614094
Policy log std Max           -0.072677895
Policy log std Min           -1.0822009
Z mean eval                  0.032213707
Z variance eval              0.006158604
total_rewards                [1859.33040394 1930.55503238 1898.70275525 2939.37975304 2928.58802763
 2120.02964376 3417.23208488 3393.82425008 3414.83521303 2940.20766956]
total_rewards_mean           2684.2684833557805
total_rewards_std            628.3945593941586
total_rewards_max            3417.2320848791205
total_rewards_min            1859.3304039447812
Number of train steps total  417000
Number of env steps total    2087000
Number of rollouts total     0
Train Time (s)               44.92625656770542
(Previous) Eval Time (s)     19.72558824205771
Sample Time (s)              21.99207156850025
Epoch Time (s)               86.64391637826338
Total Train Time (s)         33954.296445443295
Epoch                        416
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:14:14.908330 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #416 | Epoch Duration: 89.30435419082642
2020-01-11 10:14:14.908510 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #416 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032392897
Z variance train             0.006157639
KL Divergence                10.285584
KL Loss                      1.0285585
QF Loss                      83.00711
VF Loss                      31.044632
Policy Loss                  -1561.7244
Q Predictions Mean           1562.5422
Q Predictions Std            190.50854
Q Predictions Max            1753.7457
Q Predictions Min            113.82708
V Predictions Mean           1558.9032
V Predictions Std            193.2283
V Predictions Max            1749.7565
V Predictions Min            -8.229139
Log Pis Mean                 -0.82201517
Log Pis Std                  1.6782593
Log Pis Max                  7.3866315
Log Pis Min                  -6.118288
Policy mu Mean               0.0020271812
Policy mu Std                0.72997534
Policy mu Max                2.3185546
Policy mu Min                -3.0228617
Policy log std Mean          -0.3991692
Policy log std Std           0.15885164
Policy log std Max           0.06456584
Policy log std Min           -1.2272319
Z mean eval                  0.048802875
Z variance eval              0.005862237
total_rewards                [3410.95350885 1779.41781386 3370.98923794  993.9799548  1466.41072537
  975.04196932 1519.50172197 1739.81092041 3180.79456945 3424.38558187]
total_rewards_mean           2186.128600384088
total_rewards_std            981.9205212309656
total_rewards_max            3424.3855818682937
total_rewards_min            975.0419693178862
Number of train steps total  418000
Number of env steps total    2092000
Number of rollouts total     0
Train Time (s)               44.652648696210235
(Previous) Eval Time (s)     22.38578214403242
Sample Time (s)              21.7036827839911
Epoch Time (s)               88.74211362423375
Total Train Time (s)         34042.24182308279
Epoch                        417
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:15:42.857801 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #417 | Epoch Duration: 87.9491560459137
2020-01-11 10:15:42.857972 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #417 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.048504267
Z variance train             0.0058672205
KL Divergence                10.384885
KL Loss                      1.0384885
QF Loss                      44.35047
VF Loss                      20.977325
Policy Loss                  -1592.7501
Q Predictions Mean           1591.4253
Q Predictions Std            163.71191
Q Predictions Max            1743.146
Q Predictions Min            435.46912
V Predictions Mean           1592.2838
V Predictions Std            165.06071
V Predictions Max            1750.3251
V Predictions Min            427.48013
Log Pis Mean                 -0.63800037
Log Pis Std                  1.7849765
Log Pis Max                  4.9391303
Log Pis Min                  -4.8314533
Policy mu Mean               0.027184011
Policy mu Std                0.75329983
Policy mu Max                2.2092245
Policy mu Min                -2.1485975
Policy log std Mean          -0.42819557
Policy log std Std           0.17483515
Policy log std Max           -0.07482353
Policy log std Min           -1.8971288
Z mean eval                  0.018744558
Z variance eval              0.0059148306
total_rewards                [3392.72473347 3380.47531105 1529.36674009 1142.01795096  976.45208126
 3291.11537685 1623.30740217 1304.00441878 1478.37668016 2722.7119095 ]
total_rewards_mean           2084.055260428666
total_rewards_std            941.6851954863286
total_rewards_max            3392.7247334722347
total_rewards_min            976.4520812621316
Number of train steps total  419000
Number of env steps total    2097000
Number of rollouts total     0
Train Time (s)               44.43624848732725
(Previous) Eval Time (s)     21.59257356170565
Sample Time (s)              21.940329589881003
Epoch Time (s)               87.9691516389139
Total Train Time (s)         34129.3310555974
Epoch                        418
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:17:09.949033 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #418 | Epoch Duration: 87.09094047546387
2020-01-11 10:17:09.949157 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #418 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018991493
Z variance train             0.005925267
KL Divergence                10.358462
KL Loss                      1.0358462
QF Loss                      57.551476
VF Loss                      92.26728
Policy Loss                  -1624.6987
Q Predictions Mean           1624.1703
Q Predictions Std            124.62468
Q Predictions Max            1764.3796
Q Predictions Min            934.8316
V Predictions Mean           1619.7096
V Predictions Std            123.0347
V Predictions Max            1761.009
V Predictions Min            921.4779
Log Pis Mean                 -0.6422279
Log Pis Std                  1.6841868
Log Pis Max                  6.8869934
Log Pis Min                  -5.4149933
Policy mu Mean               0.019720403
Policy mu Std                0.7569996
Policy mu Max                1.7172209
Policy mu Min                -3.0191615
Policy log std Mean          -0.40653896
Policy log std Std           0.16392137
Policy log std Max           0.0053376257
Policy log std Min           -1.3676419
Z mean eval                  0.03719402
Z variance eval              0.0057175467
total_rewards                [1540.53272546 3430.63840917 1059.45771482 1004.67280145 3103.69224463
  999.20147105 1583.3616653  3334.23102492 1495.3575507  1023.64427216]
total_rewards_mean           1857.4789879671068
total_rewards_std            964.9579665963802
total_rewards_max            3430.638409173693
total_rewards_min            999.2014710497049
Number of train steps total  420000
Number of env steps total    2102000
Number of rollouts total     0
Train Time (s)               43.65261345356703
(Previous) Eval Time (s)     20.714115587063134
Sample Time (s)              23.0869585480541
Epoch Time (s)               87.45368758868426
Total Train Time (s)         34214.09800397279
Epoch                        419
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:18:34.718685 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #419 | Epoch Duration: 84.76943254470825
2020-01-11 10:18:34.718817 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #419 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037079204
Z variance train             0.0057207732
KL Divergence                10.4868555
KL Loss                      1.0486856
QF Loss                      107.98298
VF Loss                      153.58162
Policy Loss                  -1595.3497
Q Predictions Mean           1593.6018
Q Predictions Std            162.32579
Q Predictions Max            1763.1135
Q Predictions Min            340.8334
V Predictions Mean           1590.522
V Predictions Std            161.88603
V Predictions Max            1752.4001
V Predictions Min            370.89273
Log Pis Mean                 -0.5629088
Log Pis Std                  1.7569321
Log Pis Max                  9.484291
Log Pis Min                  -4.681893
Policy mu Mean               -0.05406201
Policy mu Std                0.8051263
Policy mu Max                2.1718402
Policy mu Min                -3.2243247
Policy log std Mean          -0.42981967
Policy log std Std           0.16625118
Policy log std Max           0.014373779
Policy log std Min           -1.1692228
Z mean eval                  0.045706023
Z variance eval              0.0049371766
total_rewards                [3323.06500417 3382.87374747 3372.30251062 3334.209628    195.26967512
 3383.11693235 3301.2718218  3373.08760688 3300.35572104 3292.42813441]
total_rewards_mean           3025.7980781861115
total_rewards_std            944.1181470044937
total_rewards_max            3383.1169323496456
total_rewards_min            195.2696751198628
Number of train steps total  421000
Number of env steps total    2107000
Number of rollouts total     0
Train Time (s)               45.27690525026992
(Previous) Eval Time (s)     18.029610578902066
Sample Time (s)              21.930998436175287
Epoch Time (s)               85.23751426534727
Total Train Time (s)         34311.53843258694
Epoch                        420
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:20:12.162127 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #420 | Epoch Duration: 97.44321537017822
2020-01-11 10:20:12.162249 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #420 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046046287
Z variance train             0.0049349144
KL Divergence                10.876612
KL Loss                      1.0876611
QF Loss                      413.22632
VF Loss                      388.5256
Policy Loss                  -1622.8385
Q Predictions Mean           1623.5269
Q Predictions Std            108.48547
Q Predictions Max            1764.0597
Q Predictions Min            1185.1873
V Predictions Mean           1621.3525
V Predictions Std            102.727745
V Predictions Max            1760.4323
V Predictions Min            1234.2627
Log Pis Mean                 -0.6166121
Log Pis Std                  2.3589394
Log Pis Max                  10.310904
Log Pis Min                  -6.5778866
Policy mu Mean               -0.02889107
Policy mu Std                0.83827156
Policy mu Max                2.187685
Policy mu Min                -3.460463
Policy log std Mean          -0.39613524
Policy log std Std           0.15938178
Policy log std Max           -0.044918478
Policy log std Min           -1.0425658
Z mean eval                  0.064903036
Z variance eval              0.005142391
total_rewards                [1532.8432983  1070.87412016 1763.22046384 1070.74711373 1184.78510246
  984.85462565  864.42895184 3420.4542509  2739.1261582  1012.29393457]
total_rewards_mean           1564.36280196596
total_rewards_std            814.0925113761175
total_rewards_max            3420.4542509035778
total_rewards_min            864.4289518445262
Number of train steps total  422000
Number of env steps total    2112000
Number of rollouts total     0
Train Time (s)               44.25772107997909
(Previous) Eval Time (s)     30.235086511820555
Sample Time (s)              21.81770514138043
Epoch Time (s)               96.31051273318008
Total Train Time (s)         34392.92920529237
Epoch                        421
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:21:33.555435 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #421 | Epoch Duration: 81.39309549331665
2020-01-11 10:21:33.555554 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #421 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06271132
Z variance train             0.005129234
KL Divergence                10.739638
KL Loss                      1.0739639
QF Loss                      209.40823
VF Loss                      111.48163
Policy Loss                  -1598.8533
Q Predictions Mean           1605.8944
Q Predictions Std            150.76033
Q Predictions Max            1750.8589
Q Predictions Min            706.3663
V Predictions Mean           1598.1436
V Predictions Std            149.66055
V Predictions Max            1744.068
V Predictions Min            684.7065
Log Pis Mean                 -0.36794126
Log Pis Std                  1.9499289
Log Pis Max                  9.829863
Log Pis Min                  -4.977973
Policy mu Mean               0.024303058
Policy mu Std                0.84369206
Policy mu Max                2.7546904
Policy mu Min                -3.2508779
Policy log std Mean          -0.45625305
Policy log std Std           0.20130521
Policy log std Max           0.024656862
Policy log std Min           -1.6531074
Z mean eval                  0.039798718
Z variance eval              0.0054273154
total_rewards                [2586.0569912  2603.21876941  851.43266762 1242.4792175  3330.90836086
  966.81583426 3159.20367141 1721.11835965  986.17493111 3327.15154641]
total_rewards_mean           2077.456034944934
total_rewards_std            979.2789778237062
total_rewards_max            3330.9083608631972
total_rewards_min            851.4326676199286
Number of train steps total  423000
Number of env steps total    2117000
Number of rollouts total     0
Train Time (s)               44.103894896805286
(Previous) Eval Time (s)     15.317425206303596
Sample Time (s)              21.721309169195592
Epoch Time (s)               81.14262927230448
Total Train Time (s)         34479.609833678696
Epoch                        422
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:23:00.241750 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #422 | Epoch Duration: 86.68610405921936
2020-01-11 10:23:00.241874 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #422 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039777223
Z variance train             0.0054323096
KL Divergence                10.588204
KL Loss                      1.0588205
QF Loss                      47.982944
VF Loss                      55.71228
Policy Loss                  -1610.8401
Q Predictions Mean           1609.9966
Q Predictions Std            137.24483
Q Predictions Max            1765.2556
Q Predictions Min            876.4627
V Predictions Mean           1607.8137
V Predictions Std            138.31104
V Predictions Max            1758.9109
V Predictions Min            856.1678
Log Pis Mean                 -0.6534684
Log Pis Std                  1.7476176
Log Pis Max                  5.8929257
Log Pis Min                  -4.5433674
Policy mu Mean               -0.075230084
Policy mu Std                0.76970404
Policy mu Max                1.7870693
Policy mu Min                -3.2223153
Policy log std Mean          -0.3933958
Policy log std Std           0.1675179
Policy log std Max           0.03903839
Policy log std Min           -1.2199308
Z mean eval                  0.020855092
Z variance eval              0.0064779907
total_rewards                [2705.9284131  2518.6893324  3422.01107431 2955.82809504  963.11972439
 3204.81330834 3373.77423827 3351.16448359  926.92945197  940.18761474]
total_rewards_mean           2436.2445736149557
total_rewards_std            1015.5925726862155
total_rewards_max            3422.011074309905
total_rewards_min            926.9294519727679
Number of train steps total  424000
Number of env steps total    2122000
Number of rollouts total     0
Train Time (s)               44.75283586094156
(Previous) Eval Time (s)     20.860650508198887
Sample Time (s)              22.1466554091312
Epoch Time (s)               87.76014177827165
Total Train Time (s)         34570.47340590088
Epoch                        423
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:24:31.111846 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #423 | Epoch Duration: 90.86988162994385
2020-01-11 10:24:31.111975 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #423 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021538332
Z variance train             0.006479801
KL Divergence                10.138121
KL Loss                      1.0138121
QF Loss                      159.17307
VF Loss                      67.47805
Policy Loss                  -1599.8583
Q Predictions Mean           1601.2655
Q Predictions Std            138.53351
Q Predictions Max            1785.1565
Q Predictions Min            708.0457
V Predictions Mean           1593.7184
V Predictions Std            138.2164
V Predictions Max            1774.7555
V Predictions Min            707.87134
Log Pis Mean                 -0.76276565
Log Pis Std                  1.678355
Log Pis Max                  10.121363
Log Pis Min                  -4.615576
Policy mu Mean               -0.06854699
Policy mu Std                0.7834798
Policy mu Max                1.9511886
Policy mu Min                -3.5373213
Policy log std Mean          -0.42415467
Policy log std Std           0.18639688
Policy log std Max           -0.00910458
Policy log std Min           -1.4267193
Z mean eval                  0.05299849
Z variance eval              0.005476638
total_rewards                [3402.59933854 2058.23475053 1014.78393915 3421.09793592 1002.65755276
 3408.40653709 1040.2701065  3373.96611121 1317.86497945 3391.19472224]
total_rewards_mean           2343.107597338735
total_rewards_std            1094.1441496722
total_rewards_max            3421.0979359183666
total_rewards_min            1002.657552763286
Number of train steps total  425000
Number of env steps total    2127000
Number of rollouts total     0
Train Time (s)               44.128924182616174
(Previous) Eval Time (s)     23.970138983801007
Sample Time (s)              21.789212381932884
Epoch Time (s)               89.88827554835007
Total Train Time (s)         34656.55666887853
Epoch                        424
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:25:57.204723 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #424 | Epoch Duration: 86.09259963035583
2020-01-11 10:25:57.205029 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #424 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.052982964
Z variance train             0.005468615
KL Divergence                10.598629
KL Loss                      1.059863
QF Loss                      315.86044
VF Loss                      139.0233
Policy Loss                  -1585.5432
Q Predictions Mean           1593.8064
Q Predictions Std            185.6676
Q Predictions Max            1785.0992
Q Predictions Min            0.95872295
V Predictions Mean           1582.0728
V Predictions Std            185.1784
V Predictions Max            1787.264
V Predictions Min            -0.7358458
Log Pis Mean                 -0.74169767
Log Pis Std                  1.7649686
Log Pis Max                  8.531136
Log Pis Min                  -4.8237543
Policy mu Mean               -0.055435125
Policy mu Std                0.71690124
Policy mu Max                2.411398
Policy mu Min                -3.1958675
Policy log std Mean          -0.40491545
Policy log std Std           0.16393173
Policy log std Max           -0.08412215
Policy log std Min           -1.1099111
Z mean eval                  0.0179339
Z variance eval              0.0053111985
total_rewards                [1240.40745998 3376.96258524 1018.1583209  3339.9019119  3340.53330176
 3414.95628687  981.6091961  3342.66029537 3363.90683782 3352.48877054]
total_rewards_mean           2677.1584966489436
total_rewards_std            1047.6342763720538
total_rewards_max            3414.956286872557
total_rewards_min            981.6091961037203
Number of train steps total  426000
Number of env steps total    2132000
Number of rollouts total     0
Train Time (s)               43.93067805003375
(Previous) Eval Time (s)     20.174190239049494
Sample Time (s)              21.70748033327982
Epoch Time (s)               85.81234862236306
Total Train Time (s)         34748.51248085592
Epoch                        425
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:27:29.164137 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #425 | Epoch Duration: 91.95889735221863
2020-01-11 10:27:29.164261 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #425 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01795488
Z variance train             0.0053164633
KL Divergence                10.645961
KL Loss                      1.064596
QF Loss                      68.26048
VF Loss                      57.821747
Policy Loss                  -1600.9614
Q Predictions Mean           1601.9453
Q Predictions Std            161.34557
Q Predictions Max            1758.4786
Q Predictions Min            493.3699
V Predictions Mean           1598.6865
V Predictions Std            161.05583
V Predictions Max            1753.7886
V Predictions Min            497.9421
Log Pis Mean                 -0.3411343
Log Pis Std                  2.0087042
Log Pis Max                  9.1412325
Log Pis Min                  -6.7617617
Policy mu Mean               -0.084391735
Policy mu Std                0.8812782
Policy mu Max                1.9804287
Policy mu Min                -3.3145347
Policy log std Mean          -0.45986763
Policy log std Std           0.19205222
Policy log std Max           -0.0841465
Policy log std Min           -1.3650331
Z mean eval                  0.041395936
Z variance eval              0.006292251
total_rewards                [ 820.61287704 1592.36824396 3070.56763944 3352.51466765 1440.6802247
 2266.01149326 1254.24821251  991.89402954 3338.47727875 1239.84767452]
total_rewards_mean           1936.7222341367328
total_rewards_std            939.0348747570995
total_rewards_max            3352.514667646256
total_rewards_min            820.6128770392561
Number of train steps total  427000
Number of env steps total    2137000
Number of rollouts total     0
Train Time (s)               44.70247075892985
(Previous) Eval Time (s)     26.32050161017105
Sample Time (s)              21.845119996462017
Epoch Time (s)               92.86809236556292
Total Train Time (s)         34834.07763751736
Epoch                        426
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:28:54.731461 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #426 | Epoch Duration: 85.56710481643677
2020-01-11 10:28:54.731579 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #426 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04149147
Z variance train             0.006286992
KL Divergence                10.276199
KL Loss                      1.02762
QF Loss                      113.105316
VF Loss                      60.534683
Policy Loss                  -1617.3156
Q Predictions Mean           1616.7434
Q Predictions Std            121.4078
Q Predictions Max            1764.5582
Q Predictions Min            1053.3938
V Predictions Mean           1618.4924
V Predictions Std            122.46463
V Predictions Max            1764.1505
V Predictions Min            1053.8705
Log Pis Mean                 -0.44005996
Log Pis Std                  1.9978248
Log Pis Max                  6.931865
Log Pis Min                  -5.912814
Policy mu Mean               -0.057485502
Policy mu Std                0.8378346
Policy mu Max                3.014869
Policy mu Min                -3.2992754
Policy log std Mean          -0.43498197
Policy log std Std           0.19213448
Policy log std Max           -0.031466335
Policy log std Min           -1.7977107
Z mean eval                  0.026760021
Z variance eval              0.005169266
total_rewards                [1264.24408751 2203.80052435 3386.35023366 1040.37637225 1946.62517151
 1017.05092993 3446.95879198 3350.56143507 3386.70295412 1024.71757265]
total_rewards_mean           2206.7388073016723
total_rewards_std            1037.2642444258897
total_rewards_max            3446.958791975509
total_rewards_min            1017.0509299330979
Number of train steps total  428000
Number of env steps total    2142000
Number of rollouts total     0
Train Time (s)               44.12428648909554
(Previous) Eval Time (s)     19.019253837876022
Sample Time (s)              22.17116096895188
Epoch Time (s)               85.31470129592344
Total Train Time (s)         34920.55805512797
Epoch                        427
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:30:21.217048 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #427 | Epoch Duration: 86.4853572845459
2020-01-11 10:30:21.217242 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #427 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02646998
Z variance train             0.005167483
KL Divergence                10.7358055
KL Loss                      1.0735806
QF Loss                      158.53326
VF Loss                      162.77887
Policy Loss                  -1591.8593
Q Predictions Mean           1594.7175
Q Predictions Std            129.30318
Q Predictions Max            1755.5442
Q Predictions Min            918.7906
V Predictions Mean           1582.7314
V Predictions Std            126.76602
V Predictions Max            1729.7234
V Predictions Min            926.8848
Log Pis Mean                 -0.5517511
Log Pis Std                  1.9886631
Log Pis Max                  7.9767003
Log Pis Min                  -4.612892
Policy mu Mean               -0.037086632
Policy mu Std                0.82305855
Policy mu Max                1.8772979
Policy mu Min                -3.3157556
Policy log std Mean          -0.40194497
Policy log std Std           0.16843387
Policy log std Max           -0.004427433
Policy log std Min           -1.016227
Z mean eval                  0.022647059
Z variance eval              0.004890357
total_rewards                [1865.53461815 3364.34876415 3118.22555863 3032.61558821 1888.9347878
 2350.50023659 3415.52867876 3029.08528865 1569.29303437 2008.48647167]
total_rewards_mean           2564.2553026983614
total_rewards_std            663.0170250660227
total_rewards_max            3415.5286787606647
total_rewards_min            1569.2930343701537
Number of train steps total  429000
Number of env steps total    2147000
Number of rollouts total     0
Train Time (s)               45.37784397462383
(Previous) Eval Time (s)     20.18963426211849
Sample Time (s)              22.065056156367064
Epoch Time (s)               87.63253439310938
Total Train Time (s)         35013.01158173755
Epoch                        428
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:31:53.674992 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #428 | Epoch Duration: 92.45759892463684
2020-01-11 10:31:53.675165 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #428 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02908602
Z variance train             0.0048726466
KL Divergence                11.012226
KL Loss                      1.1012226
QF Loss                      152.63423
VF Loss                      481.61853
Policy Loss                  -1585.1462
Q Predictions Mean           1584.1077
Q Predictions Std            145.85112
Q Predictions Max            1731.294
Q Predictions Min            783.71136
V Predictions Mean           1567.1375
V Predictions Std            144.83684
V Predictions Max            1720.9036
V Predictions Min            757.71655
Log Pis Mean                 -0.7919892
Log Pis Std                  1.6988844
Log Pis Max                  8.438897
Log Pis Min                  -4.0351906
Policy mu Mean               -0.05741197
Policy mu Std                0.7597566
Policy mu Max                1.8336898
Policy mu Min                -3.1565127
Policy log std Mean          -0.40681842
Policy log std Std           0.18902709
Policy log std Max           0.07659924
Policy log std Min           -1.1898354
Z mean eval                  0.028030839
Z variance eval              0.0042320197
total_rewards                [1588.56667865 3322.67672823 3350.69834103 2979.05336369 3378.62797876
 3314.54257202 1882.09583319 1748.8583918  3393.7288979  3373.43689224]
total_rewards_mean           2833.228567750698
total_rewards_std            727.5578366552892
total_rewards_max            3393.7288979035243
total_rewards_min            1588.566678649517
Number of train steps total  430000
Number of env steps total    2152000
Number of rollouts total     0
Train Time (s)               43.397168445866555
(Previous) Eval Time (s)     25.01445165090263
Sample Time (s)              21.70131302252412
Epoch Time (s)               90.1129331192933
Total Train Time (s)         35105.501206020825
Epoch                        429
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:33:26.170321 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #429 | Epoch Duration: 92.49501609802246
2020-01-11 10:33:26.170491 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #429 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027812203
Z variance train             0.004231902
KL Divergence                11.311183
KL Loss                      1.1311183
QF Loss                      478.3916
VF Loss                      45.529232
Policy Loss                  -1585.9713
Q Predictions Mean           1589.8278
Q Predictions Std            164.6814
Q Predictions Max            1763.3317
Q Predictions Min            440.77316
V Predictions Mean           1584.8518
V Predictions Std            164.35405
V Predictions Max            1758.5859
V Predictions Min            432.4623
Log Pis Mean                 -0.61042774
Log Pis Std                  1.9151314
Log Pis Max                  6.6569815
Log Pis Min                  -5.6042323
Policy mu Mean               -0.0030623376
Policy mu Std                0.8004616
Policy mu Max                2.3506043
Policy mu Min                -3.495625
Policy log std Mean          -0.4211681
Policy log std Std           0.19663131
Policy log std Max           -0.064290196
Policy log std Min           -1.8074926
Z mean eval                  0.07292004
Z variance eval              0.0044191494
total_rewards                [1120.68090462 1240.16603331 1428.53177771 1374.59955193  993.74649413
 1134.7497225   963.05989803  313.27388935  273.60615585 1859.53900303]
total_rewards_mean           1070.195343046774
total_rewards_std            458.75301438099586
total_rewards_max            1859.5390030321425
total_rewards_min            273.606155850245
Number of train steps total  431000
Number of env steps total    2157000
Number of rollouts total     0
Train Time (s)               44.34756094403565
(Previous) Eval Time (s)     27.39627779275179
Sample Time (s)              22.001143116969615
Epoch Time (s)               93.74498185375705
Total Train Time (s)         35183.129645798355
Epoch                        430
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:34:43.799552 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #430 | Epoch Duration: 77.62893295288086
2020-01-11 10:34:43.799685 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #430 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07340163
Z variance train             0.0044134567
KL Divergence                11.349701
KL Loss                      1.1349701
QF Loss                      78.908554
VF Loss                      160.0292
Policy Loss                  -1602.7756
Q Predictions Mean           1599.6997
Q Predictions Std            168.43398
Q Predictions Max            1755.72
Q Predictions Min            -6.046746
V Predictions Mean           1592.7473
V Predictions Std            167.02849
V Predictions Max            1742.1038
V Predictions Min            7.175918
Log Pis Mean                 -0.49267036
Log Pis Std                  1.7879122
Log Pis Max                  6.438826
Log Pis Min                  -4.241744
Policy mu Mean               0.063560896
Policy mu Std                0.8400167
Policy mu Max                2.4049182
Policy mu Min                -3.2083526
Policy log std Mean          -0.4283689
Policy log std Std           0.17764989
Policy log std Max           -0.057553828
Policy log std Min           -1.2040215
Z mean eval                  0.034679122
Z variance eval              0.0040349015
total_rewards                [2000.59707287 1238.48418496 1556.67627607 3399.72093423 2594.51532084
 3375.68716677 2125.08839163 2489.01118077  873.49852709 2384.73383186]
total_rewards_mean           2203.8012887098894
total_rewards_std            789.8151705410232
total_rewards_max            3399.7209342261626
total_rewards_min            873.4985270946007
Number of train steps total  432000
Number of env steps total    2162000
Number of rollouts total     0
Train Time (s)               44.585199526976794
(Previous) Eval Time (s)     11.279985398985445
Sample Time (s)              21.802556219510734
Epoch Time (s)               77.66774114547297
Total Train Time (s)         35270.477105199825
Epoch                        431
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:36:11.150597 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #431 | Epoch Duration: 87.35081958770752
2020-01-11 10:36:11.150721 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #431 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035246886
Z variance train             0.00403869
KL Divergence                11.489667
KL Loss                      1.1489667
QF Loss                      98.39465
VF Loss                      31.850533
Policy Loss                  -1594.9419
Q Predictions Mean           1592.4453
Q Predictions Std            144.00429
Q Predictions Max            1756.0703
Q Predictions Min            509.86783
V Predictions Mean           1593.6135
V Predictions Std            143.26927
V Predictions Max            1764.428
V Predictions Min            529.5368
Log Pis Mean                 -0.86287314
Log Pis Std                  1.8306942
Log Pis Max                  7.2389283
Log Pis Min                  -4.2238774
Policy mu Mean               -0.015616392
Policy mu Std                0.74549663
Policy mu Max                2.296814
Policy mu Min                -3.2834272
Policy log std Mean          -0.42759213
Policy log std Std           0.19460128
Policy log std Max           -0.04695201
Policy log std Min           -1.3367208
Z mean eval                  0.0301067
Z variance eval              0.004188868
total_rewards                [ 958.74214801 2684.22974419  946.83242775  938.98858035  920.20008942
 3382.77395936 1217.81209759 2614.89386948 1134.46437965 2910.04151338]
total_rewards_mean           1770.8978809186563
total_rewards_std            943.8055486427497
total_rewards_max            3382.773959363513
total_rewards_min            920.2000894215172
Number of train steps total  433000
Number of env steps total    2167000
Number of rollouts total     0
Train Time (s)               44.11824107868597
(Previous) Eval Time (s)     20.962795304134488
Sample Time (s)              22.27293019928038
Epoch Time (s)               87.35396658210084
Total Train Time (s)         35354.55297765508
Epoch                        432
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:37:35.229741 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #432 | Epoch Duration: 84.07892799377441
2020-01-11 10:37:35.229869 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #432 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030456875
Z variance train             0.004200744
KL Divergence                11.527336
KL Loss                      1.1527337
QF Loss                      160.34027
VF Loss                      61.1077
Policy Loss                  -1616.1038
Q Predictions Mean           1618.8093
Q Predictions Std            141.64603
Q Predictions Max            1772.2987
Q Predictions Min            671.4707
V Predictions Mean           1616.792
V Predictions Std            141.89827
V Predictions Max            1772.7828
V Predictions Min            666.8741
Log Pis Mean                 -0.65349984
Log Pis Std                  1.8166771
Log Pis Max                  7.857119
Log Pis Min                  -4.223794
Policy mu Mean               -0.07229629
Policy mu Std                0.7565922
Policy mu Max                1.7659171
Policy mu Min                -3.2218444
Policy log std Mean          -0.4304436
Policy log std Std           0.16051707
Policy log std Max           -0.066343725
Policy log std Min           -1.2578695
Z mean eval                  0.028866103
Z variance eval              0.0057829646
total_rewards                [2854.70679826 1126.72792218  974.80964514 3444.0512371  3358.32257426
 3366.36138462 3396.22204269  957.99226157 3344.04998765 3357.68190144]
total_rewards_mean           2618.0925754915825
total_rewards_std            1058.5845755814232
total_rewards_max            3444.05123710182
total_rewards_min            957.992261570027
Number of train steps total  434000
Number of env steps total    2172000
Number of rollouts total     0
Train Time (s)               44.4672495117411
(Previous) Eval Time (s)     17.68750739796087
Sample Time (s)              21.902359307277948
Epoch Time (s)               84.05711621697992
Total Train Time (s)         35446.94788051024
Epoch                        433
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:39:07.629297 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #433 | Epoch Duration: 92.3993194103241
2020-01-11 10:39:07.629476 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #433 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028806046
Z variance train             0.0057719187
KL Divergence                10.938383
KL Loss                      1.0938383
QF Loss                      118.10965
VF Loss                      65.17627
Policy Loss                  -1580.1469
Q Predictions Mean           1579.4481
Q Predictions Std            172.86339
Q Predictions Max            1745.5673
Q Predictions Min            707.50256
V Predictions Mean           1580.5922
V Predictions Std            169.866
V Predictions Max            1739.6786
V Predictions Min            708.2436
Log Pis Mean                 -0.65882874
Log Pis Std                  1.908595
Log Pis Max                  8.15929
Log Pis Min                  -6.4155846
Policy mu Mean               -0.103749625
Policy mu Std                0.7823121
Policy mu Max                2.4791713
Policy mu Min                -3.0729501
Policy log std Mean          -0.43968132
Policy log std Std           0.1914089
Policy log std Max           0.035698563
Policy log std Min           -1.5135711
Z mean eval                  0.045296457
Z variance eval              0.0051886206
total_rewards                [3388.78797008 3120.77202362 3381.9119165  2685.04491389 1526.52982598
 1147.57064102 3338.49089463 3341.26444026 1108.99097365  985.6189364 ]
total_rewards_mean           2402.498253603503
total_rewards_std            1015.2834387954412
total_rewards_max            3388.787970082962
total_rewards_min            985.6189363997629
Number of train steps total  435000
Number of env steps total    2177000
Number of rollouts total     0
Train Time (s)               44.13703267881647
(Previous) Eval Time (s)     26.029467666056007
Sample Time (s)              21.8753508948721
Epoch Time (s)               92.04185123974457
Total Train Time (s)         35534.10752240522
Epoch                        434
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:40:34.795598 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #434 | Epoch Duration: 87.16590452194214
2020-01-11 10:40:34.795872 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #434 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045556813
Z variance train             0.0051903874
KL Divergence                10.974791
KL Loss                      1.0974791
QF Loss                      223.15178
VF Loss                      124.28986
Policy Loss                  -1601.2476
Q Predictions Mean           1604.8811
Q Predictions Std            126.399284
Q Predictions Max            1763.3307
Q Predictions Min            785.631
V Predictions Mean           1603.9758
V Predictions Std            127.7153
V Predictions Max            1764.4753
V Predictions Min            767.5661
Log Pis Mean                 -0.83741105
Log Pis Std                  1.6763242
Log Pis Max                  8.345573
Log Pis Min                  -4.7479277
Policy mu Mean               -0.047495198
Policy mu Std                0.70850307
Policy mu Max                2.1989772
Policy mu Min                -3.0294602
Policy log std Mean          -0.44152245
Policy log std Std           0.17083897
Policy log std Max           0.040799826
Policy log std Min           -1.2962646
Z mean eval                  0.02754276
Z variance eval              0.005251941
total_rewards                [1049.33055424 3425.16204721 1210.1146686  3400.76086059  960.28551807
 1927.09423973 3378.13403563 3405.87776927 3447.07082764 3365.87548677]
total_rewards_mean           2556.970600775895
total_rewards_std            1064.915188246552
total_rewards_max            3447.070827641458
total_rewards_min            960.2855180736648
Number of train steps total  436000
Number of env steps total    2182000
Number of rollouts total     0
Train Time (s)               43.87439854070544
(Previous) Eval Time (s)     21.153260773047805
Sample Time (s)              19.6073117996566
Epoch Time (s)               84.63497111340985
Total Train Time (s)         35622.565903522074
Epoch                        435
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:42:03.257692 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #435 | Epoch Duration: 88.46164464950562
2020-01-11 10:42:03.257830 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #435 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027203983
Z variance train             0.005246723
KL Divergence                10.755868
KL Loss                      1.0755868
QF Loss                      122.562065
VF Loss                      99.00402
Policy Loss                  -1589.2087
Q Predictions Mean           1590.0874
Q Predictions Std            159.54987
Q Predictions Max            1745.0353
Q Predictions Min            392.60788
V Predictions Mean           1591.692
V Predictions Std            157.85956
V Predictions Max            1742.5533
V Predictions Min            412.09406
Log Pis Mean                 -0.7465311
Log Pis Std                  1.7125965
Log Pis Max                  7.0907087
Log Pis Min                  -5.023163
Policy mu Mean               -0.055164695
Policy mu Std                0.7561592
Policy mu Max                2.079494
Policy mu Min                -3.3644593
Policy log std Mean          -0.40540138
Policy log std Std           0.1754967
Policy log std Max           0.11243048
Policy log std Min           -1.6316049
Z mean eval                  0.05563424
Z variance eval              0.006353197
total_rewards                [3378.48318513 3445.29332582 3363.26544072 3407.0722185  2677.21710431
 2749.37787326 3390.96680964 3393.06809917 1186.31284279 3383.08134038]
total_rewards_mean           3037.4138239715476
total_rewards_std            673.4818141039281
total_rewards_max            3445.293325820451
total_rewards_min            1186.3128427862773
Number of train steps total  437000
Number of env steps total    2187000
Number of rollouts total     0
Train Time (s)               43.74637300008908
(Previous) Eval Time (s)     24.97971588000655
Sample Time (s)              21.998125093989074
Epoch Time (s)               90.7242139740847
Total Train Time (s)         35717.64548318274
Epoch                        436
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:43:38.339935 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #436 | Epoch Duration: 95.08194851875305
2020-01-11 10:43:38.340138 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #436 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.055627503
Z variance train             0.0063485056
KL Divergence                10.3560295
KL Loss                      1.0356029
QF Loss                      348.22836
VF Loss                      51.700935
Policy Loss                  -1576.1437
Q Predictions Mean           1572.9622
Q Predictions Std            166.21178
Q Predictions Max            1733.3201
Q Predictions Min            655.5037
V Predictions Mean           1576.1621
V Predictions Std            164.70517
V Predictions Max            1737.3168
V Predictions Min            658.39465
Log Pis Mean                 -0.7906088
Log Pis Std                  1.8998154
Log Pis Max                  8.677748
Log Pis Min                  -4.454563
Policy mu Mean               -0.1606816
Policy mu Std                0.7445372
Policy mu Max                2.7298484
Policy mu Min                -3.5234733
Policy log std Mean          -0.4148747
Policy log std Std           0.16796163
Policy log std Max           0.006165445
Policy log std Min           -1.1937356
Z mean eval                  0.04486929
Z variance eval              0.007007065
total_rewards                [2971.12824166 3522.42397504 3059.91215663 3390.8145747  3426.67402013
  959.87590743 1613.06114461 3476.12544495 3455.18096514 3394.9434557 ]
total_rewards_mean           2927.013988600159
total_rewards_std            850.5550077762033
total_rewards_max            3522.4239750439297
total_rewards_min            959.8759074259159
Number of train steps total  438000
Number of env steps total    2192000
Number of rollouts total     0
Train Time (s)               43.129139319993556
(Previous) Eval Time (s)     29.337198494933546
Sample Time (s)              22.108080366626382
Epoch Time (s)               94.57441818155348
Total Train Time (s)         35808.50159617048
Epoch                        437
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:45:09.200501 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #437 | Epoch Duration: 90.86023378372192
2020-01-11 10:45:09.200677 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #437 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04549117
Z variance train             0.0070205256
KL Divergence                10.180519
KL Loss                      1.018052
QF Loss                      190.99113
VF Loss                      211.06882
Policy Loss                  -1567.1757
Q Predictions Mean           1568.1936
Q Predictions Std            173.54037
Q Predictions Max            1739.111
Q Predictions Min            -19.80521
V Predictions Mean           1574.8203
V Predictions Std            168.17352
V Predictions Max            1749.509
V Predictions Min            168.47635
Log Pis Mean                 -0.5072488
Log Pis Std                  2.0270443
Log Pis Max                  8.40369
Log Pis Min                  -4.9919515
Policy mu Mean               -0.13080545
Policy mu Std                0.8164789
Policy mu Max                3.012078
Policy mu Min                -3.0928812
Policy log std Mean          -0.42919254
Policy log std Std           0.1913178
Policy log std Max           -0.010944009
Policy log std Min           -1.4859262
Z mean eval                  0.0333787
Z variance eval              0.006917719
total_rewards                [1181.07265773 3322.63435444 1321.71317984 1218.39958179 1305.9459099
 2153.28449676 1277.91622012 2675.30928502 1245.73950263  987.74497016]
total_rewards_mean           1668.97601583949
total_rewards_std            739.691222509332
total_rewards_max            3322.6343544383794
total_rewards_min            987.7449701649729
Number of train steps total  439000
Number of env steps total    2197000
Number of rollouts total     0
Train Time (s)               43.8600476142019
(Previous) Eval Time (s)     25.62275251187384
Sample Time (s)              21.928432940971106
Epoch Time (s)               91.41123306704685
Total Train Time (s)         35890.23677552771
Epoch                        438
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:46:30.938420 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #438 | Epoch Duration: 81.73761415481567
2020-01-11 10:46:30.938550 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #438 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03311942
Z variance train             0.006917756
KL Divergence                10.243927
KL Loss                      1.0243927
QF Loss                      287.24023
VF Loss                      89.81706
Policy Loss                  -1594.858
Q Predictions Mean           1595.0007
Q Predictions Std            134.3115
Q Predictions Max            1748.2089
Q Predictions Min            847.1162
V Predictions Mean           1597.942
V Predictions Std            134.10619
V Predictions Max            1748.7666
V Predictions Min            847.5306
Log Pis Mean                 -0.5899761
Log Pis Std                  1.7287846
Log Pis Max                  6.282351
Log Pis Min                  -4.1873364
Policy mu Mean               -0.115102656
Policy mu Std                0.777398
Policy mu Max                1.4196924
Policy mu Min                -2.8376687
Policy log std Mean          -0.4339246
Policy log std Std           0.19276568
Policy log std Max           0.04046002
Policy log std Min           -1.2855947
Z mean eval                  0.037672844
Z variance eval              0.005769494
total_rewards                [1003.92412498 3295.86534676 3334.39072222 1256.12229361 3314.86792222
 3307.04589714 2760.84774733 1813.19721603  872.61547631 3363.0459737 ]
total_rewards_mean           2432.1922720284388
total_rewards_std            1015.7463552906469
total_rewards_max            3363.045973698346
total_rewards_min            872.6154763050699
Number of train steps total  440000
Number of env steps total    2202000
Number of rollouts total     0
Train Time (s)               44.46432670112699
(Previous) Eval Time (s)     15.948871950153261
Sample Time (s)              21.886097877286375
Epoch Time (s)               82.29929652856663
Total Train Time (s)         35979.95494984556
Epoch                        439
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:48:00.662568 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #439 | Epoch Duration: 89.72390723228455
2020-01-11 10:48:00.662691 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #439 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03815579
Z variance train             0.0057310583
KL Divergence                10.554247
KL Loss                      1.0554247
QF Loss                      204.9299
VF Loss                      451.54742
Policy Loss                  -1611.6095
Q Predictions Mean           1605.8699
Q Predictions Std            116.97851
Q Predictions Max            1771.7684
Q Predictions Min            889.5424
V Predictions Mean           1600.0095
V Predictions Std            118.07458
V Predictions Max            1767.9131
V Predictions Min            854.89136
Log Pis Mean                 -0.76731205
Log Pis Std                  1.6595504
Log Pis Max                  6.8187203
Log Pis Min                  -7.093354
Policy mu Mean               -0.07944814
Policy mu Std                0.76358056
Policy mu Max                1.8191252
Policy mu Min                -3.3067844
Policy log std Mean          -0.409294
Policy log std Std           0.15135291
Policy log std Max           -0.00246346
Policy log std Min           -1.1130188
Z mean eval                  0.042291965
Z variance eval              0.005197646
total_rewards                [1790.04596818 2316.67063751 2708.17903116 1426.31320118 1691.39350198
 2082.59664198 1524.28314467 2647.91916699 1515.613909   2197.97060439]
total_rewards_mean           1990.0985807047298
total_rewards_std            446.76648095572966
total_rewards_max            2708.179031159288
total_rewards_min            1426.3132011829257
Number of train steps total  441000
Number of env steps total    2207000
Number of rollouts total     0
Train Time (s)               44.60781469615176
(Previous) Eval Time (s)     23.373236063867807
Sample Time (s)              21.65349749615416
Epoch Time (s)               89.63454825617373
Total Train Time (s)         36064.47977210535
Epoch                        440
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:49:25.197127 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #440 | Epoch Duration: 84.53430819511414
2020-01-11 10:49:25.197373 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #440 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04201417
Z variance train             0.0051915394
KL Divergence                10.823021
KL Loss                      1.0823021
QF Loss                      164.5767
VF Loss                      119.54262
Policy Loss                  -1594.1793
Q Predictions Mean           1596.0292
Q Predictions Std            160.32153
Q Predictions Max            1747.7056
Q Predictions Min            167.45166
V Predictions Mean           1601.2032
V Predictions Std            158.53807
V Predictions Max            1752.526
V Predictions Min            159.97884
Log Pis Mean                 -0.84536505
Log Pis Std                  1.628603
Log Pis Max                  6.102312
Log Pis Min                  -6.149683
Policy mu Mean               -0.018308962
Policy mu Std                0.77438694
Policy mu Max                3.8478897
Policy mu Min                -3.1230109
Policy log std Mean          -0.44195488
Policy log std Std           0.18534096
Policy log std Max           0.0057160556
Policy log std Min           -1.6134028
Z mean eval                  0.04986633
Z variance eval              0.0046862336
total_rewards                [1042.85098291 3281.09549536 3325.40025434 1238.32168645  983.84169585
 2272.56537283 1482.58725527 3342.94936726 3292.95790592 1214.36908946]
total_rewards_mean           2147.6939105631086
total_rewards_std            1007.1295493417147
total_rewards_max            3342.9493672598182
total_rewards_min            983.841695845547
Number of train steps total  442000
Number of env steps total    2212000
Number of rollouts total     0
Train Time (s)               44.81727113109082
(Previous) Eval Time (s)     18.2727120090276
Sample Time (s)              21.927315916866064
Epoch Time (s)               85.01729905698448
Total Train Time (s)         36152.0814912864
Epoch                        441
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:50:52.801887 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #441 | Epoch Duration: 87.60433793067932
2020-01-11 10:50:52.802017 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #441 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04835587
Z variance train             0.004682877
KL Divergence                11.085741
KL Loss                      1.1085742
QF Loss                      274.94275
VF Loss                      136.23616
Policy Loss                  -1595.584
Q Predictions Mean           1595.6716
Q Predictions Std            139.0555
Q Predictions Max            1740.0708
Q Predictions Min            770.21985
V Predictions Mean           1596.4177
V Predictions Std            139.50137
V Predictions Max            1740.8489
V Predictions Min            787.95544
Log Pis Mean                 -0.6666499
Log Pis Std                  1.7528532
Log Pis Max                  6.596644
Log Pis Min                  -4.365125
Policy mu Mean               -0.06930624
Policy mu Std                0.76183826
Policy mu Max                1.8787419
Policy mu Min                -3.1199048
Policy log std Mean          -0.43796405
Policy log std Std           0.17103033
Policy log std Max           -0.0018621385
Policy log std Min           -1.7061121
Z mean eval                  0.022086985
Z variance eval              0.0048543205
total_rewards                [3363.6974325  1819.3820919  2904.03267286 1901.3877625  1509.53166788
 1520.97732544 2713.08988352  882.74882493 3350.97764553 1029.99941919]
total_rewards_mean           2099.5824726243545
total_rewards_std            872.521476973332
total_rewards_max            3363.697432495318
total_rewards_min            882.7488249276554
Number of train steps total  443000
Number of env steps total    2217000
Number of rollouts total     0
Train Time (s)               44.47541615087539
(Previous) Eval Time (s)     20.859542040154338
Sample Time (s)              22.48085530148819
Epoch Time (s)               87.81581349251792
Total Train Time (s)         36239.38627897436
Epoch                        442
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:52:20.114648 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #442 | Epoch Duration: 87.31253719329834
2020-01-11 10:52:20.114773 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #442 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02227671
Z variance train             0.0048478246
KL Divergence                11.174303
KL Loss                      1.1174303
QF Loss                      69.88832
VF Loss                      48.767384
Policy Loss                  -1564.4854
Q Predictions Mean           1562.99
Q Predictions Std            152.3062
Q Predictions Max            1733.5823
Q Predictions Min            714.6149
V Predictions Mean           1565.2712
V Predictions Std            152.67787
V Predictions Max            1735.7462
V Predictions Min            725.77155
Log Pis Mean                 -0.65090173
Log Pis Std                  1.6301646
Log Pis Max                  3.9907265
Log Pis Min                  -6.7689314
Policy mu Mean               0.025866942
Policy mu Std                0.7615523
Policy mu Max                1.8864186
Policy mu Min                -3.2535117
Policy log std Mean          -0.43747878
Policy log std Std           0.16872987
Policy log std Max           -0.0394938
Policy log std Min           -1.3090761
Z mean eval                  0.0467276
Z variance eval              0.0049676113
total_rewards                [3321.89678953  968.22240172 3328.25451701 1203.35504635 2492.42046061
  976.64154139 3321.77695304 2684.68959724 3334.99100048 1972.78975321]
total_rewards_mean           2360.5038060582324
total_rewards_std            959.157203417872
total_rewards_max            3334.9910004781923
total_rewards_min            968.2224017226374
Number of train steps total  444000
Number of env steps total    2222000
Number of rollouts total     0
Train Time (s)               44.20695641078055
(Previous) Eval Time (s)     20.356010620947927
Sample Time (s)              21.82711312128231
Epoch Time (s)               86.39008015301079
Total Train Time (s)         36327.087933089584
Epoch                        443
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:53:47.824440 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #443 | Epoch Duration: 87.70956206321716
2020-01-11 10:53:47.824599 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #443 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0465127
Z variance train             0.0049682693
KL Divergence                11.1543045
KL Loss                      1.1154305
QF Loss                      69.7117
VF Loss                      50.423706
Policy Loss                  -1591.597
Q Predictions Mean           1590.8195
Q Predictions Std            154.9394
Q Predictions Max            1764.7968
Q Predictions Min            725.49554
V Predictions Mean           1590.105
V Predictions Std            156.12868
V Predictions Max            1767.2368
V Predictions Min            682.72925
Log Pis Mean                 -0.45714694
Log Pis Std                  1.7667719
Log Pis Max                  7.966549
Log Pis Min                  -4.947542
Policy mu Mean               -0.052321553
Policy mu Std                0.81722903
Policy mu Max                1.8123362
Policy mu Min                -3.3438232
Policy log std Mean          -0.42298985
Policy log std Std           0.1747642
Policy log std Max           0.0492374
Policy log std Min           -1.4026638
Z mean eval                  0.038570732
Z variance eval              0.0050668935
total_rewards                [3299.12567801 3364.6439476  1380.2427908  1622.37147666 3086.33927206
 3318.39610059  929.26344565 1685.40266507 1240.7276006  3381.19539881]
total_rewards_mean           2330.7708375862953
total_rewards_std            981.352857602277
total_rewards_max            3381.1953988134546
total_rewards_min            929.2634456529432
Number of train steps total  445000
Number of env steps total    2227000
Number of rollouts total     0
Train Time (s)               45.024957643356174
(Previous) Eval Time (s)     21.675249645020813
Sample Time (s)              21.635212580207735
Epoch Time (s)               88.33541986858472
Total Train Time (s)         36418.61959547596
Epoch                        444
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:55:19.359484 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #444 | Epoch Duration: 91.53476977348328
2020-01-11 10:55:19.359606 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #444 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03709659
Z variance train             0.0050602434
KL Divergence                11.024193
KL Loss                      1.1024193
QF Loss                      250.23026
VF Loss                      83.69302
Policy Loss                  -1573.4039
Q Predictions Mean           1580.9434
Q Predictions Std            155.90677
Q Predictions Max            1760.5435
Q Predictions Min            631.66254
V Predictions Mean           1573.1068
V Predictions Std            159.50508
V Predictions Max            1751.048
V Predictions Min            595.2537
Log Pis Mean                 -0.5616677
Log Pis Std                  2.0859382
Log Pis Max                  8.43943
Log Pis Min                  -3.9807305
Policy mu Mean               -0.07489232
Policy mu Std                0.8077283
Policy mu Max                2.1405172
Policy mu Min                -3.0951266
Policy log std Mean          -0.42478275
Policy log std Std           0.16874412
Policy log std Max           0.0586994
Policy log std Min           -1.2519616
Z mean eval                  0.05153997
Z variance eval              0.005256702
total_rewards                [ 963.78568255 2586.53706483 1581.03179281 3262.79710012 1969.45481769
  807.45643576  108.52845771 3348.0952868  3290.31426627 3355.50206776]
total_rewards_mean           2127.350297230174
total_rewards_std            1155.2571641214322
total_rewards_max            3355.5020677576495
total_rewards_min            108.52845771189732
Number of train steps total  446000
Number of env steps total    2232000
Number of rollouts total     0
Train Time (s)               44.27392094396055
(Previous) Eval Time (s)     24.874362755566835
Sample Time (s)              21.206887021660805
Epoch Time (s)               90.35517072118819
Total Train Time (s)         36504.92656473396
Epoch                        445
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:56:45.669685 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #445 | Epoch Duration: 86.30998539924622
2020-01-11 10:56:45.669807 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #445 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.051444292
Z variance train             0.005257389
KL Divergence                10.790631
KL Loss                      1.0790632
QF Loss                      113.16531
VF Loss                      103.61795
Policy Loss                  -1585.1432
Q Predictions Mean           1587.6157
Q Predictions Std            139.6028
Q Predictions Max            1734.0007
Q Predictions Min            736.2187
V Predictions Mean           1587.4386
V Predictions Std            138.71497
V Predictions Max            1731.32
V Predictions Min            728.2645
Log Pis Mean                 -0.6703626
Log Pis Std                  1.7428954
Log Pis Max                  7.2229185
Log Pis Min                  -5.6833935
Policy mu Mean               -0.074165046
Policy mu Std                0.79423356
Policy mu Max                1.8709042
Policy mu Min                -3.2083936
Policy log std Mean          -0.42599258
Policy log std Std           0.16571534
Policy log std Max           -0.003800422
Policy log std Min           -1.2353401
Z mean eval                  0.028337335
Z variance eval              0.0061446284
total_rewards                [1214.34718232 1153.59816311 1238.82340207 3364.09064165 1906.60831153
 3268.84346236 2391.91452419  954.00191745  975.49777437 1473.04328572]
total_rewards_mean           1794.076866477709
total_rewards_std            868.528586377763
total_rewards_max            3364.0906416471466
total_rewards_min            954.0019174487086
Number of train steps total  447000
Number of env steps total    2237000
Number of rollouts total     0
Train Time (s)               44.16440379060805
(Previous) Eval Time (s)     20.82894552592188
Sample Time (s)              22.01428517512977
Epoch Time (s)               87.0076344916597
Total Train Time (s)         36589.02786963293
Epoch                        446
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:58:09.773657 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #446 | Epoch Duration: 84.10376048088074
2020-01-11 10:58:09.773779 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #446 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028161183
Z variance train             0.0061399965
KL Divergence                10.339512
KL Loss                      1.0339512
QF Loss                      118.854095
VF Loss                      49.85461
Policy Loss                  -1587.5938
Q Predictions Mean           1589.0562
Q Predictions Std            171.64449
Q Predictions Max            1748.1576
Q Predictions Min            472.6646
V Predictions Mean           1591.1198
V Predictions Std            171.17398
V Predictions Max            1751.0287
V Predictions Min            487.87155
Log Pis Mean                 -0.7170336
Log Pis Std                  1.8371453
Log Pis Max                  8.841251
Log Pis Min                  -6.3727183
Policy mu Mean               -0.098466754
Policy mu Std                0.76334107
Policy mu Max                2.6569378
Policy mu Min                -3.0673208
Policy log std Mean          -0.44383764
Policy log std Std           0.17217809
Policy log std Max           -0.008027285
Policy log std Min           -1.2084897
Z mean eval                  0.022035003
Z variance eval              0.0055007995
total_rewards                [3277.56736745 1530.65883936 2534.8666659  1001.89053208 2950.0694773
 1738.39997253 1728.13656225 1722.0808425  3196.99693866 3326.06705041]
total_rewards_mean           2300.6734248441467
total_rewards_std            808.9616891991919
total_rewards_max            3326.0670504082227
total_rewards_min            1001.8905320791907
Number of train steps total  448000
Number of env steps total    2242000
Number of rollouts total     0
Train Time (s)               44.29875557171181
(Previous) Eval Time (s)     17.924817939754575
Sample Time (s)              21.92328712902963
Epoch Time (s)               84.14686064049602
Total Train Time (s)         36676.94350693794
Epoch                        447
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:59:37.697920 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #447 | Epoch Duration: 87.92404627799988
2020-01-11 10:59:37.698046 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #447 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023126584
Z variance train             0.005512815
KL Divergence                10.585405
KL Loss                      1.0585406
QF Loss                      255.97336
VF Loss                      149.55614
Policy Loss                  -1597.9336
Q Predictions Mean           1602.224
Q Predictions Std            143.1459
Q Predictions Max            1758.8832
Q Predictions Min            285.64908
V Predictions Mean           1604.4827
V Predictions Std            145.61531
V Predictions Max            1759.1919
V Predictions Min            265.3242
Log Pis Mean                 -0.51741666
Log Pis Std                  1.7486199
Log Pis Max                  5.956944
Log Pis Min                  -5.53126
Policy mu Mean               -0.013318104
Policy mu Std                0.8340724
Policy mu Max                2.3845942
Policy mu Min                -3.2079465
Policy log std Mean          -0.44045964
Policy log std Std           0.18136656
Policy log std Max           0.09043792
Policy log std Min           -1.4178876
Z mean eval                  0.030765047
Z variance eval              0.005662992
total_rewards                [2096.51321566  913.82990632 1197.2470236  2674.05287266 1155.01236825
 3350.36534427 2977.18371655 1659.66894706 3169.68545819  948.28115124]
total_rewards_mean           2014.1840003799784
total_rewards_std            914.7845943728495
total_rewards_max            3350.365344269065
total_rewards_min            913.8299063210271
Number of train steps total  449000
Number of env steps total    2247000
Number of rollouts total     0
Train Time (s)               44.66559220897034
(Previous) Eval Time (s)     21.701777204871178
Sample Time (s)              21.7752432259731
Epoch Time (s)               88.14261263981462
Total Train Time (s)         36763.867857369594
Epoch                        448
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:01:04.625028 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #448 | Epoch Duration: 86.92688083648682
2020-01-11 11:01:04.625163 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #448 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031010967
Z variance train             0.005668751
KL Divergence                10.50128
KL Loss                      1.050128
QF Loss                      68.60212
VF Loss                      54.350655
Policy Loss                  -1603.5912
Q Predictions Mean           1604.3553
Q Predictions Std            161.6107
Q Predictions Max            1776.0576
Q Predictions Min            393.22263
V Predictions Mean           1597.7195
V Predictions Std            160.62628
V Predictions Max            1767.5403
V Predictions Min            398.3017
Log Pis Mean                 -0.57442975
Log Pis Std                  1.8497596
Log Pis Max                  5.7086315
Log Pis Min                  -5.2819567
Policy mu Mean               -0.030251661
Policy mu Std                0.802793
Policy mu Max                1.8763468
Policy mu Min                -3.1943874
Policy log std Mean          -0.4165683
Policy log std Std           0.1461985
Policy log std Max           0.04269892
Policy log std Min           -1.0431098
Z mean eval                  0.014049791
Z variance eval              0.006497448
total_rewards                [ 991.58026011 3378.45841513 1211.07791251 3320.91019508  985.76015084
 2330.59713779 1230.44741312 3263.22398423 2066.7812201  3255.69632219]
total_rewards_mean           2203.4533011104522
total_rewards_std            988.8115726807778
total_rewards_max            3378.4584151315394
total_rewards_min            985.760150842151
Number of train steps total  450000
Number of env steps total    2252000
Number of rollouts total     0
Train Time (s)               44.21162130404264
(Previous) Eval Time (s)     20.48580706305802
Sample Time (s)              22.54131638025865
Epoch Time (s)               87.2387447473593
Total Train Time (s)         36853.47060219897
Epoch                        449
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:02:34.232969 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #449 | Epoch Duration: 89.6076979637146
2020-01-11 11:02:34.233091 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #449 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013973111
Z variance train             0.006498164
KL Divergence                10.161388
KL Loss                      1.0161389
QF Loss                      63.20387
VF Loss                      52.393402
Policy Loss                  -1595.2445
Q Predictions Mean           1595.9669
Q Predictions Std            173.58908
Q Predictions Max            1741.4563
Q Predictions Min            409.67505
V Predictions Mean           1596.082
V Predictions Std            172.65942
V Predictions Max            1739.9575
V Predictions Min            427.8466
Log Pis Mean                 -0.6194021
Log Pis Std                  1.8932283
Log Pis Max                  9.966106
Log Pis Min                  -4.3127356
Policy mu Mean               -0.002772182
Policy mu Std                0.77114356
Policy mu Max                1.9666437
Policy mu Min                -3.5471053
Policy log std Mean          -0.413162
Policy log std Std           0.18248291
Policy log std Max           0.07124394
Policy log std Min           -1.2430952
Z mean eval                  0.04053046
Z variance eval              0.0063159177
total_rewards                [2869.25008468 2584.40462194 2604.67866865 2403.91213836 1193.86544135
 3400.25587943 3370.64173115 1178.83152391 3401.24574976 3388.60987949]
total_rewards_mean           2639.569571871384
total_rewards_std            811.830421425142
total_rewards_max            3401.245749759712
total_rewards_min            1178.8315239056278
Number of train steps total  451000
Number of env steps total    2257000
Number of rollouts total     0
Train Time (s)               44.468699829652905
(Previous) Eval Time (s)     22.85449790302664
Sample Time (s)              23.685917552094907
Epoch Time (s)               91.00911528477445
Total Train Time (s)         36945.7869872516
Epoch                        450
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:04:06.555230 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #450 | Epoch Duration: 92.32203722000122
2020-01-11 11:04:06.555387 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #450 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040337853
Z variance train             0.0063165515
KL Divergence                10.19615
KL Loss                      1.019615
QF Loss                      40.800713
VF Loss                      16.874876
Policy Loss                  -1607.6436
Q Predictions Mean           1607.9778
Q Predictions Std            171.1768
Q Predictions Max            1816.2936
Q Predictions Min            163.09575
V Predictions Mean           1608.9725
V Predictions Std            170.87105
V Predictions Max            1815.5083
V Predictions Min            147.50917
Log Pis Mean                 -0.5656693
Log Pis Std                  1.6764107
Log Pis Max                  5.021531
Log Pis Min                  -3.5501056
Policy mu Mean               -0.009597505
Policy mu Std                0.76016486
Policy mu Max                1.8039443
Policy mu Min                -3.1274114
Policy log std Mean          -0.39636227
Policy log std Std           0.16216832
Policy log std Max           0.0222103
Policy log std Min           -1.2542138
Z mean eval                  0.018709652
Z variance eval              0.005393756
total_rewards                [1239.47543638 1830.64894121 3341.24887353 1284.78319657 1435.24116701
 1601.75120306 1468.72675153 1165.17024479 1395.43679139 1139.40881828]
total_rewards_mean           1590.1891423745333
total_rewards_std            616.5202432223866
total_rewards_max            3341.2488735256798
total_rewards_min            1139.4088182830737
Number of train steps total  452000
Number of env steps total    2262000
Number of rollouts total     0
Train Time (s)               43.86359504982829
(Previous) Eval Time (s)     24.167137467768043
Sample Time (s)              21.618810595478863
Epoch Time (s)               89.6495431130752
Total Train Time (s)         37025.84895034507
Epoch                        451
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:05:26.621313 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #451 | Epoch Duration: 80.06579446792603
2020-01-11 11:05:26.621433 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #451 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017995255
Z variance train             0.005410691
KL Divergence                10.58631
KL Loss                      1.0586311
QF Loss                      216.63846
VF Loss                      160.35892
Policy Loss                  -1582.5505
Q Predictions Mean           1583.2065
Q Predictions Std            169.5052
Q Predictions Max            1759.5217
Q Predictions Min            376.61224
V Predictions Mean           1580.5981
V Predictions Std            168.30327
V Predictions Max            1750.1462
V Predictions Min            360.40128
Log Pis Mean                 -0.4150297
Log Pis Std                  1.789046
Log Pis Max                  7.6619296
Log Pis Min                  -5.2567506
Policy mu Mean               0.17808537
Policy mu Std                0.81224954
Policy mu Max                2.2061963
Policy mu Min                -2.7258728
Policy log std Mean          -0.40817937
Policy log std Std           0.17640182
Policy log std Max           0.13170257
Policy log std Min           -1.2030888
Z mean eval                  0.03318385
Z variance eval              0.0054369923
total_rewards                [2276.2476559  2239.05403042  943.94407945 2634.13130956 1533.97741062
 3354.95706099  993.0530775   995.89450313 1770.17690714 2629.50094935]
total_rewards_mean           1937.093698406717
total_rewards_std            783.3013428994118
total_rewards_max            3354.957060986116
total_rewards_min            943.9440794495044
Number of train steps total  453000
Number of env steps total    2267000
Number of rollouts total     0
Train Time (s)               45.2436537030153
(Previous) Eval Time (s)     14.583135391119868
Sample Time (s)              20.52275795582682
Epoch Time (s)               80.34954704996198
Total Train Time (s)         37108.27202345757
Epoch                        452
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:06:49.048893 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #452 | Epoch Duration: 82.42735290527344
2020-01-11 11:06:49.049062 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #452 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03340658
Z variance train             0.005436032
KL Divergence                10.596015
KL Loss                      1.0596015
QF Loss                      95.44167
VF Loss                      38.020042
Policy Loss                  -1599.542
Q Predictions Mean           1598.4619
Q Predictions Std            139.89146
Q Predictions Max            1752.3815
Q Predictions Min            818.0171
V Predictions Mean           1601.0923
V Predictions Std            140.13925
V Predictions Max            1756.8246
V Predictions Min            803.9853
Log Pis Mean                 -0.59018713
Log Pis Std                  2.029521
Log Pis Max                  9.09878
Log Pis Min                  -3.9364989
Policy mu Mean               0.0012106622
Policy mu Std                0.7877012
Policy mu Max                2.2112908
Policy mu Min                -3.3973475
Policy log std Mean          -0.4185187
Policy log std Std           0.16712572
Policy log std Max           0.12547156
Policy log std Min           -1.6094923
Z mean eval                  0.045613058
Z variance eval              0.005963371
total_rewards                [1816.11559256 2430.54336492 2723.49853655 3304.70330984 2347.77857907
 2439.41121297 3273.05743056 2146.75126365 2118.60600054 3368.91402687]
total_rewards_mean           2596.9379317542453
total_rewards_std            522.0890044015476
total_rewards_max            3368.914026872733
total_rewards_min            1816.115592562954
Number of train steps total  454000
Number of env steps total    2272000
Number of rollouts total     0
Train Time (s)               44.965308255981654
(Previous) Eval Time (s)     16.660678781569004
Sample Time (s)              21.60605057887733
Epoch Time (s)               83.23203761642799
Total Train Time (s)         37200.55702860048
Epoch                        453
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:08:21.342374 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #453 | Epoch Duration: 92.29309630393982
2020-01-11 11:08:21.342636 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #453 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045712717
Z variance train             0.0059638717
KL Divergence                10.392592
KL Loss                      1.0392593
QF Loss                      63.13999
VF Loss                      28.676483
Policy Loss                  -1603.0192
Q Predictions Mean           1602.8441
Q Predictions Std            124.37979
Q Predictions Max            1761.8816
Q Predictions Min            695.7199
V Predictions Mean           1600.3374
V Predictions Std            123.28578
V Predictions Max            1758.6292
V Predictions Min            710.27924
Log Pis Mean                 -0.5642482
Log Pis Std                  1.8295683
Log Pis Max                  5.0245733
Log Pis Min                  -5.048773
Policy mu Mean               0.035023276
Policy mu Std                0.82555234
Policy mu Max                2.1801622
Policy mu Min                -2.9721532
Policy log std Mean          -0.41155282
Policy log std Std           0.17252009
Policy log std Max           -0.013633847
Policy log std Min           -1.2052715
Z mean eval                  0.06879847
Z variance eval              0.0047939876
total_rewards                [ 999.05729134 3326.44877161 1525.80865787 1147.03834051 3328.24050647
 1116.46550421  105.76261696 1871.81632788 2848.25028784 1437.17091164]
total_rewards_mean           1770.6059216329934
total_rewards_std            1018.4922551628592
total_rewards_max            3328.240506470991
total_rewards_min            105.76261695838834
Number of train steps total  455000
Number of env steps total    2277000
Number of rollouts total     0
Train Time (s)               44.593603231944144
(Previous) Eval Time (s)     25.72148409532383
Sample Time (s)              22.174474884290248
Epoch Time (s)               92.48956221155822
Total Train Time (s)         37284.352319032885
Epoch                        454
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:09:45.139571 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #454 | Epoch Duration: 83.79677557945251
2020-01-11 11:09:45.139706 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #454 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06908182
Z variance train             0.0047968975
KL Divergence                10.983572
KL Loss                      1.0983572
QF Loss                      74.521324
VF Loss                      34.855476
Policy Loss                  -1584.369
Q Predictions Mean           1586.149
Q Predictions Std            188.25488
Q Predictions Max            1764.7157
Q Predictions Min            429.01636
V Predictions Mean           1586.6804
V Predictions Std            187.23837
V Predictions Max            1769.1494
V Predictions Min            444.09656
Log Pis Mean                 -0.49693036
Log Pis Std                  1.940385
Log Pis Max                  6.945325
Log Pis Min                  -5.587004
Policy mu Mean               0.032243963
Policy mu Std                0.8358864
Policy mu Max                2.4765334
Policy mu Min                -3.1711779
Policy log std Mean          -0.4153223
Policy log std Std           0.18744142
Policy log std Max           0.03675562
Policy log std Min           -1.5307148
Z mean eval                  0.017431369
Z variance eval              0.0049882447
total_rewards                [1259.69026563 1240.95866994 3351.50497021 3353.40638472 3286.31511855
 3328.20495417 1067.15461766 3352.92101641 1073.90237123 3307.57659269]
total_rewards_mean           2462.1634961215304
total_rewards_std            1064.578317036753
total_rewards_max            3353.406384723588
total_rewards_min            1067.1546176576585
Number of train steps total  456000
Number of env steps total    2282000
Number of rollouts total     0
Train Time (s)               44.2453753198497
(Previous) Eval Time (s)     17.028463087044656
Sample Time (s)              22.28878639731556
Epoch Time (s)               83.56262480420992
Total Train Time (s)         37375.214381751604
Epoch                        455
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:11:16.005284 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #455 | Epoch Duration: 90.86541628837585
2020-01-11 11:11:16.005485 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #455 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017542398
Z variance train             0.0049841353
KL Divergence                10.89875
KL Loss                      1.0898751
QF Loss                      48.65888
VF Loss                      38.43663
Policy Loss                  -1577.8074
Q Predictions Mean           1578.4551
Q Predictions Std            150.82286
Q Predictions Max            1748.4009
Q Predictions Min            656.8232
V Predictions Mean           1578.1758
V Predictions Std            150.8893
V Predictions Max            1743.853
V Predictions Min            647.1338
Log Pis Mean                 -0.8827914
Log Pis Std                  1.6834908
Log Pis Max                  6.114741
Log Pis Min                  -5.4400673
Policy mu Mean               0.023935571
Policy mu Std                0.7260227
Policy mu Max                3.0049868
Policy mu Min                -2.4806151
Policy log std Mean          -0.41804934
Policy log std Std           0.14938483
Policy log std Max           -0.0036364198
Policy log std Min           -0.970549
Z mean eval                  0.049556132
Z variance eval              0.0042136684
total_rewards                [1017.91323952  805.45737508 2608.40650772  918.86765802 1172.70563662
 1158.77579475 1235.36059597 1138.12695691  785.68859807  908.03408158]
total_rewards_mean           1174.9336444239793
total_rewards_std            500.9592430509555
total_rewards_max            2608.4065077244027
total_rewards_min            785.6885980689308
Number of train steps total  457000
Number of env steps total    2287000
Number of rollouts total     0
Train Time (s)               44.32005964498967
(Previous) Eval Time (s)     24.331003583967686
Sample Time (s)              21.960206603631377
Epoch Time (s)               90.61126983258873
Total Train Time (s)         37452.67600824544
Epoch                        456
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:12:33.470409 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #456 | Epoch Duration: 77.46479916572571
2020-01-11 11:12:33.470570 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #456 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04924965
Z variance train             0.004215479
KL Divergence                11.296188
KL Loss                      1.1296189
QF Loss                      102.46518
VF Loss                      118.08189
Policy Loss                  -1602.2148
Q Predictions Mean           1604.4679
Q Predictions Std            132.5773
Q Predictions Max            1745.0769
Q Predictions Min            754.43353
V Predictions Mean           1607.1492
V Predictions Std            133.88069
V Predictions Max            1755.9556
V Predictions Min            743.76306
Log Pis Mean                 -0.84502333
Log Pis Std                  1.7162641
Log Pis Max                  6.929064
Log Pis Min                  -4.7320523
Policy mu Mean               -0.051911075
Policy mu Std                0.7440415
Policy mu Max                1.4228688
Policy mu Min                -2.6124456
Policy log std Mean          -0.39664355
Policy log std Std           0.15039152
Policy log std Max           -0.004167199
Policy log std Min           -0.9955353
Z mean eval                  0.088755295
Z variance eval              0.0050175637
total_rewards                [2059.37334029 1519.84170667 1177.76044969 1145.9124817   721.01004385
  974.69364121  980.13929111  222.10126271 2558.38185592  961.94295357]
total_rewards_mean           1232.115702670329
total_rewards_std            634.0834769924626
total_rewards_max            2558.381855922178
total_rewards_min            222.10126270606887
Number of train steps total  458000
Number of env steps total    2292000
Number of rollouts total     0
Train Time (s)               44.08297983324155
(Previous) Eval Time (s)     11.184287080075592
Sample Time (s)              21.880861286073923
Epoch Time (s)               77.14812819939107
Total Train Time (s)         37531.641377166845
Epoch                        457
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:13:52.442091 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #457 | Epoch Duration: 78.97140264511108
2020-01-11 11:13:52.442217 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #457 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09054723
Z variance train             0.005023646
KL Divergence                10.852275
KL Loss                      1.0852275
QF Loss                      129.66946
VF Loss                      49.54545
Policy Loss                  -1586.029
Q Predictions Mean           1588.7299
Q Predictions Std            126.69573
Q Predictions Max            1735.8612
Q Predictions Min            835.1408
V Predictions Mean           1583.1405
V Predictions Std            125.67759
V Predictions Max            1731.3826
V Predictions Min            844.4795
Log Pis Mean                 -0.7148007
Log Pis Std                  1.6510977
Log Pis Max                  6.7458296
Log Pis Min                  -4.2544246
Policy mu Mean               0.13947208
Policy mu Std                0.7609652
Policy mu Max                3.303967
Policy mu Min                -2.415792
Policy log std Mean          -0.39242253
Policy log std Std           0.14987533
Policy log std Max           0.0739502
Policy log std Min           -1.1401159
Z mean eval                  0.05598563
Z variance eval              0.0051139244
total_rewards                [3369.74656895  984.99705503 1157.17402076 3295.74515277 1540.88313012
  960.35178766 1739.71439854 1215.91796055 3395.4591303  3338.24133633]
total_rewards_mean           2099.823054100339
total_rewards_std            1044.4370424050387
total_rewards_max            3395.459130301854
total_rewards_min            960.3517876597679
Number of train steps total  459000
Number of env steps total    2297000
Number of rollouts total     0
Train Time (s)               44.3805262488313
(Previous) Eval Time (s)     13.007311180699617
Sample Time (s)              21.23146680602804
Epoch Time (s)               78.61930423555896
Total Train Time (s)         37618.32757093897
Epoch                        458
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:15:19.132906 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #458 | Epoch Duration: 86.69059658050537
2020-01-11 11:15:19.133028 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #458 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.055923294
Z variance train             0.0051046954
KL Divergence                10.754393
KL Loss                      1.0754393
QF Loss                      284.93744
VF Loss                      540.0359
Policy Loss                  -1603.0453
Q Predictions Mean           1605.7424
Q Predictions Std            123.735374
Q Predictions Max            1746.3125
Q Predictions Min            952.3333
V Predictions Mean           1590.0846
V Predictions Std            119.81118
V Predictions Max            1730.8782
V Predictions Min            994.2405
Log Pis Mean                 -0.53575003
Log Pis Std                  1.7480915
Log Pis Max                  7.1494355
Log Pis Min                  -5.5261536
Policy mu Mean               0.04099105
Policy mu Std                0.8075019
Policy mu Max                2.192454
Policy mu Min                -2.8807836
Policy log std Mean          -0.43500352
Policy log std Std           0.15629777
Policy log std Max           0.0017513037
Policy log std Min           -1.2198186
Z mean eval                  0.02548359
Z variance eval              0.005558394
total_rewards                [ 921.78376538 3347.89525615  951.27361838 3364.66964222 3375.37646379
 1787.65019335  955.64370774 3302.68972861 1913.05398897 1128.43635932]
total_rewards_mean           2104.847272391181
total_rewards_std            1064.1056743152085
total_rewards_max            3375.3764637909476
total_rewards_min            921.7837653783421
Number of train steps total  460000
Number of env steps total    2302000
Number of rollouts total     0
Train Time (s)               44.799364460166544
(Previous) Eval Time (s)     21.07834458211437
Sample Time (s)              22.27562635578215
Epoch Time (s)               88.15333539806306
Total Train Time (s)         37706.70416087797
Epoch                        459
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:16:47.512281 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #459 | Epoch Duration: 88.37915921211243
2020-01-11 11:16:47.512405 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #459 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025470015
Z variance train             0.005550533
KL Divergence                10.518337
KL Loss                      1.0518337
QF Loss                      3300.2664
VF Loss                      1218.1993
Policy Loss                  -1593.0892
Q Predictions Mean           1592.0078
Q Predictions Std            151.44083
Q Predictions Max            1730.4955
Q Predictions Min            754.0712
V Predictions Mean           1592.5635
V Predictions Std            151.1838
V Predictions Max            1737.5966
V Predictions Min            731.8814
Log Pis Mean                 -0.4676373
Log Pis Std                  1.8548887
Log Pis Max                  7.6901526
Log Pis Min                  -6.3366265
Policy mu Mean               -0.02468768
Policy mu Std                0.8203435
Policy mu Max                2.0042036
Policy mu Min                -3.346057
Policy log std Mean          -0.44159234
Policy log std Std           0.18027394
Policy log std Max           -0.035621077
Policy log std Min           -1.5523472
Z mean eval                  0.024390915
Z variance eval              0.0054761395
total_rewards                [ 989.3819035  3126.72412238 1012.27887775  942.67820195 3347.68946602
  952.43384672 2330.1431839  1495.16637949 3342.80750042 1787.88076093]
total_rewards_mean           1932.7184243078123
total_rewards_std            972.869481686191
total_rewards_max            3347.689466016886
total_rewards_min            942.6782019529022
Number of train steps total  461000
Number of env steps total    2307000
Number of rollouts total     0
Train Time (s)               44.76723102061078
(Previous) Eval Time (s)     21.303909044712782
Sample Time (s)              22.048775016330183
Epoch Time (s)               88.11991508165374
Total Train Time (s)         37792.43093128316
Epoch                        460
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:18:13.243950 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #460 | Epoch Duration: 85.7314522266388
2020-01-11 11:18:13.244086 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #460 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024238296
Z variance train             0.0054846015
KL Divergence                10.573185
KL Loss                      1.0573186
QF Loss                      119.94528
VF Loss                      67.81767
Policy Loss                  -1602.7626
Q Predictions Mean           1604.9675
Q Predictions Std            169.53134
Q Predictions Max            1738.6871
Q Predictions Min            208.55902
V Predictions Mean           1603.3848
V Predictions Std            168.57277
V Predictions Max            1737.1096
V Predictions Min            218.95102
Log Pis Mean                 -0.52114147
Log Pis Std                  1.7231407
Log Pis Max                  5.732762
Log Pis Min                  -4.1017733
Policy mu Mean               -0.06932036
Policy mu Std                0.81186795
Policy mu Max                2.1338766
Policy mu Min                -3.6109438
Policy log std Mean          -0.40293446
Policy log std Std           0.17032799
Policy log std Max           0.1359567
Policy log std Min           -1.0866234
Z mean eval                  0.0495966
Z variance eval              0.0046555125
total_rewards                [1494.08292378 3321.88793144 2317.49158931 1731.06842715 1794.79163739
  878.88206358  192.46149818 1722.56610448 1002.09797836 2900.1224678 ]
total_rewards_mean           1735.5452621482175
total_rewards_std            890.2983551013908
total_rewards_max            3321.887931444808
total_rewards_min            192.46149818245084
Number of train steps total  462000
Number of env steps total    2312000
Number of rollouts total     0
Train Time (s)               44.36724050203338
(Previous) Eval Time (s)     18.915190214291215
Sample Time (s)              21.830081139691174
Epoch Time (s)               85.11251185601577
Total Train Time (s)         37874.980482907034
Epoch                        461
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:19:35.798792 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #461 | Epoch Duration: 82.55460023880005
2020-01-11 11:19:35.798946 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #461 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04997396
Z variance train             0.0046493816
KL Divergence                11.033581
KL Loss                      1.1033581
QF Loss                      351.71762
VF Loss                      197.41481
Policy Loss                  -1596.149
Q Predictions Mean           1596.4329
Q Predictions Std            132.42935
Q Predictions Max            1738.3009
Q Predictions Min            780.8357
V Predictions Mean           1603.7661
V Predictions Std            133.02454
V Predictions Max            1744.5409
V Predictions Min            772.6459
Log Pis Mean                 -0.5617671
Log Pis Std                  1.9177816
Log Pis Max                  7.7606907
Log Pis Min                  -5.0833035
Policy mu Mean               -0.042645086
Policy mu Std                0.79992974
Policy mu Max                2.0602455
Policy mu Min                -3.0607076
Policy log std Mean          -0.44527662
Policy log std Std           0.16823126
Policy log std Max           0.01582846
Policy log std Min           -1.121843
Z mean eval                  0.030038211
Z variance eval              0.0052049174
total_rewards                [3409.03227218  899.22144918 3323.97389266  923.00376086  965.40598609
 3411.25738224 3342.2814631  2307.87921324 3323.67740469 3433.4325136 ]
total_rewards_mean           2533.9165337827917
total_rewards_std            1096.569032503733
total_rewards_max            3433.432513595645
total_rewards_min            899.2214491788757
Number of train steps total  463000
Number of env steps total    2317000
Number of rollouts total     0
Train Time (s)               43.92808769410476
(Previous) Eval Time (s)     16.357009805738926
Sample Time (s)              21.470477659720927
Epoch Time (s)               81.75557515956461
Total Train Time (s)         37965.76514291903
Epoch                        462
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:21:06.587060 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #462 | Epoch Duration: 90.78797483444214
2020-01-11 11:21:06.587182 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #462 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030378286
Z variance train             0.005207335
KL Divergence                10.703825
KL Loss                      1.0703825
QF Loss                      103.30211
VF Loss                      55.390003
Policy Loss                  -1593.9105
Q Predictions Mean           1591.7612
Q Predictions Std            159.37517
Q Predictions Max            1784.264
Q Predictions Min            814.98395
V Predictions Mean           1591.2452
V Predictions Std            156.75624
V Predictions Max            1781.3293
V Predictions Min            831.42474
Log Pis Mean                 -0.46798414
Log Pis Std                  1.8304487
Log Pis Max                  8.859575
Log Pis Min                  -5.3961196
Policy mu Mean               0.11238059
Policy mu Std                0.8057376
Policy mu Max                2.3205724
Policy mu Min                -3.2610805
Policy log std Mean          -0.43915215
Policy log std Std           0.17804234
Policy log std Max           0.009803981
Policy log std Min           -1.5347577
Z mean eval                  0.014506231
Z variance eval              0.0060693393
total_rewards                [3292.22778156 3311.57044924  952.23262674 3315.56895461  978.12007824
 3331.18242772 3320.710268   3299.02110305 3326.99473962 3278.35676428]
total_rewards_mean           2840.5985193062857
total_rewards_std            937.8526986286691
total_rewards_max            3331.1824277238657
total_rewards_min            952.2326267414194
Number of train steps total  464000
Number of env steps total    2322000
Number of rollouts total     0
Train Time (s)               44.17435749201104
(Previous) Eval Time (s)     25.38916263729334
Sample Time (s)              21.510744851082563
Epoch Time (s)               91.07426498038694
Total Train Time (s)         38059.73161241645
Epoch                        463
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:22:40.559885 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #463 | Epoch Duration: 93.97260093688965
2020-01-11 11:22:40.560061 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #463 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0111277485
Z variance train             0.0060693547
KL Divergence                10.359755
KL Loss                      1.0359755
QF Loss                      212.69885
VF Loss                      65.70147
Policy Loss                  -1626.1395
Q Predictions Mean           1626.2126
Q Predictions Std            130.57492
Q Predictions Max            1813.5153
Q Predictions Min            849.68036
V Predictions Mean           1620.7363
V Predictions Std            131.16464
V Predictions Max            1810.8524
V Predictions Min            840.39624
Log Pis Mean                 -0.56396544
Log Pis Std                  1.6902027
Log Pis Max                  6.1790175
Log Pis Min                  -4.6059785
Policy mu Mean               0.013854131
Policy mu Std                0.7558309
Policy mu Max                1.6892306
Policy mu Min                -3.233366
Policy log std Mean          -0.45772484
Policy log std Std           0.18289648
Policy log std Max           -0.06508666
Policy log std Min           -1.5255711
Z mean eval                  0.040314708
Z variance eval              0.004957321
total_rewards                [2844.76497014 1182.74088709 1732.24091271  199.51160519 3309.91635419
 1214.49511732 2280.25106039 1501.8688444  3316.29569498 1469.98170569]
total_rewards_mean           1905.206715207388
total_rewards_std            963.2374505977274
total_rewards_max            3316.2956949783643
total_rewards_min            199.51160518561812
Number of train steps total  465000
Number of env steps total    2327000
Number of rollouts total     0
Train Time (s)               44.362497601192445
(Previous) Eval Time (s)     28.287242055870593
Sample Time (s)              22.130231382790953
Epoch Time (s)               94.77997103985399
Total Train Time (s)         38145.63868236542
Epoch                        464
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:24:06.467534 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #464 | Epoch Duration: 85.9073429107666
2020-01-11 11:24:06.467660 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #464 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039342593
Z variance train             0.0049520247
KL Divergence                10.895686
KL Loss                      1.0895686
QF Loss                      536.4615
VF Loss                      351.63687
Policy Loss                  -1594.4658
Q Predictions Mean           1600.0203
Q Predictions Std            137.56732
Q Predictions Max            1738.1768
Q Predictions Min            804.32
V Predictions Mean           1600.7834
V Predictions Std            139.35057
V Predictions Max            1739.483
V Predictions Min            770.75275
Log Pis Mean                 -0.36996022
Log Pis Std                  1.8760717
Log Pis Max                  9.530429
Log Pis Min                  -5.2696996
Policy mu Mean               0.08154326
Policy mu Std                0.8623873
Policy mu Max                3.1183608
Policy mu Min                -3.0015683
Policy log std Mean          -0.42727032
Policy log std Std           0.17324214
Policy log std Max           0.10265857
Policy log std Min           -1.1806719
Z mean eval                  0.039820056
Z variance eval              0.005202382
total_rewards                [1003.16517571 2279.89524416 1613.89593725  969.03107861 2255.79859602
 3298.81646986  945.36511323 1990.36391935  977.80299062 2503.92385872]
total_rewards_mean           1783.8058383525408
total_rewards_std            773.3127341112588
total_rewards_max            3298.8164698592705
total_rewards_min            945.3651132295304
Number of train steps total  466000
Number of env steps total    2332000
Number of rollouts total     0
Train Time (s)               43.37815560027957
(Previous) Eval Time (s)     19.41433356422931
Sample Time (s)              21.076353740878403
Epoch Time (s)               83.86884290538728
Total Train Time (s)         38227.371189386584
Epoch                        465
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:25:28.203406 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #465 | Epoch Duration: 81.7356538772583
2020-01-11 11:25:28.203527 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #465 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03933625
Z variance train             0.005190739
KL Divergence                10.735617
KL Loss                      1.0735617
QF Loss                      319.224
VF Loss                      861.66046
Policy Loss                  -1592.0017
Q Predictions Mean           1590.6447
Q Predictions Std            156.64388
Q Predictions Max            1745.4637
Q Predictions Min            544.37537
V Predictions Mean           1607.3507
V Predictions Std            162.96262
V Predictions Max            1757.834
V Predictions Min            434.78094
Log Pis Mean                 -0.5884214
Log Pis Std                  1.9079884
Log Pis Max                  9.945863
Log Pis Min                  -8.165806
Policy mu Mean               -0.0064296997
Policy mu Std                0.7749443
Policy mu Max                2.3998077
Policy mu Min                -3.0875049
Policy log std Mean          -0.43151355
Policy log std Std           0.16267677
Policy log std Max           -0.042580485
Policy log std Min           -1.1590601
Z mean eval                  0.024553308
Z variance eval              0.0053873835
total_rewards                [1233.75416822 3306.06847588  940.81314434 1985.76950126  859.84588738
 1786.69781707  918.25571264 3115.93097711 1002.18467968 3345.49334883]
total_rewards_mean           1849.4813712408063
total_rewards_std            987.6931659456761
total_rewards_max            3345.4933488322135
total_rewards_min            859.8458873844653
Number of train steps total  467000
Number of env steps total    2337000
Number of rollouts total     0
Train Time (s)               44.348359948024154
(Previous) Eval Time (s)     17.280888291075826
Sample Time (s)              21.592600067146122
Epoch Time (s)               83.2218483062461
Total Train Time (s)         38311.62386131752
Epoch                        466
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:26:52.464939 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #466 | Epoch Duration: 84.26131844520569
2020-01-11 11:26:52.465064 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #466 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024963934
Z variance train             0.005382416
KL Divergence                10.689629
KL Loss                      1.0689629
QF Loss                      256.30618
VF Loss                      90.26051
Policy Loss                  -1591.0985
Q Predictions Mean           1594.8816
Q Predictions Std            166.77031
Q Predictions Max            1762.7941
Q Predictions Min            691.22754
V Predictions Mean           1588.9972
V Predictions Std            165.37477
V Predictions Max            1766.2523
V Predictions Min            682.97034
Log Pis Mean                 -0.49828643
Log Pis Std                  1.9870515
Log Pis Max                  9.428129
Log Pis Min                  -4.3298545
Policy mu Mean               4.8739216e-06
Policy mu Std                0.8198267
Policy mu Max                2.2885106
Policy mu Min                -3.49101
Policy log std Mean          -0.44938278
Policy log std Std           0.18902887
Policy log std Max           0.03125617
Policy log std Min           -1.336013
Z mean eval                  0.028305799
Z variance eval              0.006048495
total_rewards                [ 971.53392516 3385.46874761 3354.87496031 1012.11254941 3346.16057105
 1566.01315005 3359.97779349 1259.57070198  929.58541991 2747.62161219]
total_rewards_mean           2193.2919431167566
total_rewards_std            1073.2310841321769
total_rewards_max            3385.4687476103904
total_rewards_min            929.5854199105897
Number of train steps total  468000
Number of env steps total    2342000
Number of rollouts total     0
Train Time (s)               43.948375263717026
(Previous) Eval Time (s)     18.32009903760627
Sample Time (s)              21.966536218766123
Epoch Time (s)               84.23501052008942
Total Train Time (s)         38397.001580820885
Epoch                        467
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:28:17.849634 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #467 | Epoch Duration: 85.38445019721985
2020-01-11 11:28:17.849830 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #467 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027747337
Z variance train             0.006055789
KL Divergence                10.453645
KL Loss                      1.0453645
QF Loss                      62.617622
VF Loss                      99.959724
Policy Loss                  -1596.1155
Q Predictions Mean           1597.6685
Q Predictions Std            144.62512
Q Predictions Max            1750.4442
Q Predictions Min            705.0338
V Predictions Mean           1602.3253
V Predictions Std            143.8595
V Predictions Max            1762.5309
V Predictions Min            723.5567
Log Pis Mean                 -0.77600706
Log Pis Std                  1.6277945
Log Pis Max                  6.770405
Log Pis Min                  -4.7188244
Policy mu Mean               -0.10925663
Policy mu Std                0.751388
Policy mu Max                2.4090922
Policy mu Min                -3.1858153
Policy log std Mean          -0.4313991
Policy log std Std           0.16053855
Policy log std Max           -0.046330005
Policy log std Min           -1.3925223
Z mean eval                  0.06467513
Z variance eval              0.00581799
total_rewards                [3320.10881529 1795.40254463 3325.43884664 3398.44617805 3215.1387248
 1043.31414276 1285.05571735 3090.95361805 1402.3374599  1045.16478293]
total_rewards_mean           2292.136083039481
total_rewards_std            1000.2798718092117
total_rewards_max            3398.446178051683
total_rewards_min            1043.3141427636813
Number of train steps total  469000
Number of env steps total    2347000
Number of rollouts total     0
Train Time (s)               44.132700093090534
(Previous) Eval Time (s)     19.469287319108844
Sample Time (s)              20.47040459467098
Epoch Time (s)               84.07239200687036
Total Train Time (s)         38481.9486889136
Epoch                        468
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:29:42.805497 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #468 | Epoch Duration: 84.95551776885986
2020-01-11 11:29:42.805667 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #468 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06482526
Z variance train             0.0058150594
KL Divergence                10.678534
KL Loss                      1.0678533
QF Loss                      103.70029
VF Loss                      49.026894
Policy Loss                  -1601.1481
Q Predictions Mean           1602.8179
Q Predictions Std            160.14366
Q Predictions Max            1766.0002
Q Predictions Min            91.37987
V Predictions Mean           1597.967
V Predictions Std            158.05122
V Predictions Max            1758.0232
V Predictions Min            130.1712
Log Pis Mean                 -0.66402304
Log Pis Std                  1.7009732
Log Pis Max                  7.3076334
Log Pis Min                  -4.379617
Policy mu Mean               0.037500326
Policy mu Std                0.7483803
Policy mu Max                1.5923396
Policy mu Min                -3.085201
Policy log std Mean          -0.4310182
Policy log std Std           0.17029312
Policy log std Max           -0.06891939
Policy log std Min           -1.2223043
Z mean eval                  0.031845987
Z variance eval              0.005472172
total_rewards                [ 954.94915804 3231.95917533 2395.83724626 2698.19927421 1825.8678584
 1231.73188976 2132.73835883 1215.60393896 3342.94144594 2035.28086952]
total_rewards_mean           2106.51092152522
total_rewards_std            787.322632174323
total_rewards_max            3342.9414459380014
total_rewards_min            954.9491580403426
Number of train steps total  470000
Number of env steps total    2352000
Number of rollouts total     0
Train Time (s)               44.28959732502699
(Previous) Eval Time (s)     20.35218335269019
Sample Time (s)              21.801901194266975
Epoch Time (s)               86.44368187198415
Total Train Time (s)         38568.54349822644
Epoch                        469
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:31:09.403488 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #469 | Epoch Duration: 86.59770250320435
2020-01-11 11:31:09.403614 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #469 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03167949
Z variance train             0.0054753534
KL Divergence                10.698907
KL Loss                      1.0698907
QF Loss                      124.32557
VF Loss                      48.12812
Policy Loss                  -1592.0292
Q Predictions Mean           1588.5667
Q Predictions Std            150.37076
Q Predictions Max            1743.7773
Q Predictions Min            661.83685
V Predictions Mean           1596.3942
V Predictions Std            148.77242
V Predictions Max            1752.6744
V Predictions Min            693.03046
Log Pis Mean                 -0.7816746
Log Pis Std                  1.9277943
Log Pis Max                  8.178732
Log Pis Min                  -7.343575
Policy mu Mean               0.028466647
Policy mu Std                0.8002901
Policy mu Max                2.385359
Policy mu Min                -3.0852067
Policy log std Mean          -0.4287126
Policy log std Std           0.1768053
Policy log std Max           -0.03589821
Policy log std Min           -1.5566704
Z mean eval                  0.018882608
Z variance eval              0.0059959595
total_rewards                [1701.08043058 1792.17888016 1227.48019342 1287.911154   2319.28510355
 3390.16259969 1187.90132965 1013.20863416 2315.18353604 2068.9640879 ]
total_rewards_mean           1830.3355949142274
total_rewards_std            687.0511616517194
total_rewards_max            3390.1625996854236
total_rewards_min            1013.2086341592961
Number of train steps total  471000
Number of env steps total    2357000
Number of rollouts total     0
Train Time (s)               44.48940603993833
(Previous) Eval Time (s)     20.505970834288746
Sample Time (s)              21.453124444000423
Epoch Time (s)               86.4485013182275
Total Train Time (s)         38651.4974139519
Epoch                        470
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:32:32.360618 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #470 | Epoch Duration: 82.95690941810608
2020-01-11 11:32:32.360754 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #470 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018919151
Z variance train             0.005994773
KL Divergence                10.451551
KL Loss                      1.0451552
QF Loss                      96.15448
VF Loss                      24.680943
Policy Loss                  -1589.6853
Q Predictions Mean           1590.0524
Q Predictions Std            203.6397
Q Predictions Max            1755.4979
Q Predictions Min            24.358486
V Predictions Mean           1588.7328
V Predictions Std            203.48982
V Predictions Max            1751.0688
V Predictions Min            20.747555
Log Pis Mean                 -0.3930388
Log Pis Std                  1.805016
Log Pis Max                  9.21253
Log Pis Min                  -4.30842
Policy mu Mean               -0.04487959
Policy mu Std                0.8194103
Policy mu Max                2.8172019
Policy mu Min                -3.2728698
Policy log std Mean          -0.43681684
Policy log std Std           0.18512456
Policy log std Max           0.022544324
Policy log std Min           -1.9457989
Z mean eval                  0.026705822
Z variance eval              0.006165122
total_rewards                [1741.30959584 2871.08600612 1536.49296921 1196.0648581   958.62780787
  978.91690843 2374.61867569 3383.12744492 1089.3243087  1254.47457853]
total_rewards_mean           1738.4043153413247
total_rewards_std            810.4396822200367
total_rewards_max            3383.127444915809
total_rewards_min            958.6278078722667
Number of train steps total  472000
Number of env steps total    2362000
Number of rollouts total     0
Train Time (s)               44.67121214000508
(Previous) Eval Time (s)     17.014131798874587
Sample Time (s)              21.251761380117387
Epoch Time (s)               82.93710531899706
Total Train Time (s)         38733.399993834086
Epoch                        471
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:33:54.268932 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #471 | Epoch Duration: 81.90806245803833
2020-01-11 11:33:54.269112 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #471 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026546266
Z variance train             0.0061690905
KL Divergence                10.405967
KL Loss                      1.0405967
QF Loss                      4061.1643
VF Loss                      860.13403
Policy Loss                  -1585.2949
Q Predictions Mean           1586.759
Q Predictions Std            204.91354
Q Predictions Max            1737.6976
Q Predictions Min            41.683388
V Predictions Mean           1592.6675
V Predictions Std            195.08788
V Predictions Max            1740.7072
V Predictions Min            6.9389963
Log Pis Mean                 -0.4065365
Log Pis Std                  2.4420578
Log Pis Max                  20.261787
Log Pis Min                  -4.649601
Policy mu Mean               -0.08466598
Policy mu Std                0.8809186
Policy mu Max                3.1116574
Policy mu Min                -4.9315805
Policy log std Mean          -0.39988807
Policy log std Std           0.1931594
Policy log std Max           -0.020143539
Policy log std Min           -1.7809504
Z mean eval                  0.032431263
Z variance eval              0.006120314
total_rewards                [2095.14604481 1282.23111378 3199.41655817 1175.19645064 3355.49500327
 3316.29959473 1829.56185219 1876.03138038 1240.83137072 1250.28574058]
total_rewards_mean           2062.049510927606
total_rewards_std            857.7576398479134
total_rewards_max            3355.495003269556
total_rewards_min            1175.196450644907
Number of train steps total  473000
Number of env steps total    2367000
Number of rollouts total     0
Train Time (s)               44.901605260092765
(Previous) Eval Time (s)     15.984805227722973
Sample Time (s)              21.560896852985024
Epoch Time (s)               82.44730734080076
Total Train Time (s)         38820.76050587278
Epoch                        472
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:35:21.632824 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #472 | Epoch Duration: 87.36357522010803
2020-01-11 11:35:21.632958 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #472 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032447886
Z variance train             0.006120625
KL Divergence                10.456136
KL Loss                      1.0456136
QF Loss                      145.36403
VF Loss                      40.992294
Policy Loss                  -1587.3743
Q Predictions Mean           1588.0214
Q Predictions Std            153.31694
Q Predictions Max            1762.4056
Q Predictions Min            63.137634
V Predictions Mean           1588.9867
V Predictions Std            154.43196
V Predictions Max            1764.8325
V Predictions Min            37.57732
Log Pis Mean                 -0.3562401
Log Pis Std                  2.1924129
Log Pis Max                  10.78471
Log Pis Min                  -4.7652183
Policy mu Mean               -0.030261777
Policy mu Std                0.88540334
Policy mu Max                2.643137
Policy mu Min                -3.4813836
Policy log std Mean          -0.43726954
Policy log std Std           0.18028769
Policy log std Max           -0.032936484
Policy log std Min           -1.5968575
Z mean eval                  0.02131763
Z variance eval              0.0064923353
total_rewards                [1773.4683681  3378.69606924 3325.09657581 3374.04000429 3361.9258706
 1260.21750755 3376.39645488 3355.80851653 2455.19385849 3380.21310798]
total_rewards_mean           2904.1056333470588
total_rewards_std            752.9216531359522
total_rewards_max            3380.213107977814
total_rewards_min            1260.2175075488499
Number of train steps total  474000
Number of env steps total    2372000
Number of rollouts total     0
Train Time (s)               44.56628241110593
(Previous) Eval Time (s)     20.90081677818671
Sample Time (s)              22.098418114241213
Epoch Time (s)               87.56551730353385
Total Train Time (s)         38915.433859357145
Epoch                        473
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:36:56.309591 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #473 | Epoch Duration: 94.676522731781
2020-01-11 11:36:56.309759 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #473 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021402331
Z variance train             0.006491092
KL Divergence                10.234398
KL Loss                      1.0234398
QF Loss                      125.32503
VF Loss                      234.97726
Policy Loss                  -1580.2408
Q Predictions Mean           1580.2012
Q Predictions Std            173.28328
Q Predictions Max            1762.9427
Q Predictions Min            599.5532
V Predictions Mean           1572.6392
V Predictions Std            173.82147
V Predictions Max            1758.3281
V Predictions Min            591.2079
Log Pis Mean                 -0.62040704
Log Pis Std                  1.8596069
Log Pis Max                  8.09343
Log Pis Min                  -7.3644485
Policy mu Mean               0.011531522
Policy mu Std                0.8032857
Policy mu Max                2.6625125
Policy mu Min                -3.2200513
Policy log std Mean          -0.41465285
Policy log std Std           0.17046544
Policy log std Max           -0.056069165
Policy log std Min           -1.1029048
Z mean eval                  0.041731805
Z variance eval              0.007844637
total_rewards                [3304.45631575 3334.73363004 1579.5661924  3338.33138027 2330.18810539
 3345.47640217  991.3706393  2416.17000262 3281.38481254 3313.46726143]
total_rewards_mean           2723.514474191157
total_rewards_std            818.1252071611385
total_rewards_max            3345.4764021665483
total_rewards_min            991.3706393037467
Number of train steps total  475000
Number of env steps total    2377000
Number of rollouts total     0
Train Time (s)               43.924478555098176
(Previous) Eval Time (s)     28.011559715028852
Sample Time (s)              21.674996059853584
Epoch Time (s)               93.61103432998061
Total Train Time (s)         39006.09585759556
Epoch                        474
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:38:26.980796 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #474 | Epoch Duration: 90.67090582847595
2020-01-11 11:38:26.980956 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #474 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04091321
Z variance train             0.007853009
KL Divergence                9.693945
KL Loss                      0.9693945
QF Loss                      72.85878
VF Loss                      139.12723
Policy Loss                  -1599.2039
Q Predictions Mean           1597.8071
Q Predictions Std            140.54979
Q Predictions Max            1754.4834
Q Predictions Min            669.60565
V Predictions Mean           1601.8145
V Predictions Std            141.79701
V Predictions Max            1751.9419
V Predictions Min            673.1277
Log Pis Mean                 -0.56636214
Log Pis Std                  1.8763988
Log Pis Max                  9.576909
Log Pis Min                  -4.3395877
Policy mu Mean               -0.01786303
Policy mu Std                0.7833121
Policy mu Max                2.078257
Policy mu Min                -3.0811398
Policy log std Mean          -0.4352995
Policy log std Std           0.18076803
Policy log std Max           -0.03548315
Policy log std Min           -1.2853885
Z mean eval                  0.040193684
Z variance eval              0.00631067
total_rewards                [1784.41596646 1818.12308398 1064.52728244 1798.68057562  917.55996648
 3310.60260196 2865.73089248 1206.60666243 3310.65479222 3410.48036959]
total_rewards_mean           2148.738219366348
total_rewards_std            935.3904668696986
total_rewards_max            3410.4803695879345
total_rewards_min            917.5599664809102
Number of train steps total  476000
Number of env steps total    2382000
Number of rollouts total     0
Train Time (s)               44.14155068201944
(Previous) Eval Time (s)     25.071165257133543
Sample Time (s)              21.995008398313075
Epoch Time (s)               91.20772433746606
Total Train Time (s)         39094.384524723515
Epoch                        475
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:39:55.269261 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #475 | Epoch Duration: 88.28818988800049
2020-01-11 11:39:55.269383 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #475 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040007375
Z variance train             0.006324249
KL Divergence                10.27408
KL Loss                      1.027408
QF Loss                      119.90073
VF Loss                      224.17834
Policy Loss                  -1578.4968
Q Predictions Mean           1578.9353
Q Predictions Std            197.23781
Q Predictions Max            1783.6617
Q Predictions Min            -20.00339
V Predictions Mean           1566.3064
V Predictions Std            195.74911
V Predictions Max            1768.1166
V Predictions Min            -3.8722522
Log Pis Mean                 -0.5581944
Log Pis Std                  1.8132107
Log Pis Max                  7.9833345
Log Pis Min                  -4.797927
Policy mu Mean               -0.10398536
Policy mu Std                0.8271082
Policy mu Max                1.8834062
Policy mu Min                -3.0291836
Policy log std Mean          -0.42465243
Policy log std Std           0.18141492
Policy log std Max           -0.0061784387
Policy log std Min           -1.2299169
Z mean eval                  0.022703683
Z variance eval              0.0056710485
total_rewards                [3398.44424145 1832.12829523 2398.41425127  981.66993578 3345.05592303
 2116.19326134 1357.05322685 3293.71702688 1272.80323467  524.6618387 ]
total_rewards_mean           2052.0141235187853
total_rewards_std            988.3168006800832
total_rewards_max            3398.444241446876
total_rewards_min            524.6618386972833
Number of train steps total  477000
Number of env steps total    2387000
Number of rollouts total     0
Train Time (s)               44.77072752872482
(Previous) Eval Time (s)     22.151385870296508
Sample Time (s)              21.375520029105246
Epoch Time (s)               88.29763342812657
Total Train Time (s)         39179.49312423542
Epoch                        476
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:41:20.388762 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #476 | Epoch Duration: 85.11927103996277
2020-01-11 11:41:20.388936 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #476 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023458418
Z variance train             0.0056771925
KL Divergence                10.652408
KL Loss                      1.0652407
QF Loss                      146.84744
VF Loss                      116.69038
Policy Loss                  -1583.062
Q Predictions Mean           1580.0726
Q Predictions Std            199.81073
Q Predictions Max            1770.6288
Q Predictions Min            21.588293
V Predictions Mean           1580.7996
V Predictions Std            196.43393
V Predictions Max            1778.5564
V Predictions Min            11.089067
Log Pis Mean                 -0.45689505
Log Pis Std                  1.9917428
Log Pis Max                  9.0755
Log Pis Min                  -4.6752534
Policy mu Mean               -0.12509553
Policy mu Std                0.81281036
Policy mu Max                3.208358
Policy mu Min                -3.2564232
Policy log std Mean          -0.43560863
Policy log std Std           0.18266045
Policy log std Max           -0.077943996
Policy log std Min           -1.464717
Z mean eval                  0.03371198
Z variance eval              0.0068192966
total_rewards                [2047.14844024 3335.40720994 3332.73738459 3319.84615176 3330.12144991
 1036.39042607 3357.75485964 1326.94459226 3339.73510745 3334.38690506]
total_rewards_mean           2776.0472526914746
total_rewards_std            886.0570919576809
total_rewards_max            3357.754859642148
total_rewards_min            1036.390426065428
Number of train steps total  478000
Number of env steps total    2392000
Number of rollouts total     0
Train Time (s)               44.24505592789501
(Previous) Eval Time (s)     18.972797507885844
Sample Time (s)              21.946917563676834
Epoch Time (s)               85.16477099945769
Total Train Time (s)         39272.8736868687
Epoch                        477
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:42:53.771226 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #477 | Epoch Duration: 93.38216972351074
2020-01-11 11:42:53.771350 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #477 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03236216
Z variance train             0.0068176603
KL Divergence                10.22064
KL Loss                      1.0220641
QF Loss                      103.02768
VF Loss                      53.97545
Policy Loss                  -1596.0597
Q Predictions Mean           1596.8782
Q Predictions Std            150.53888
Q Predictions Max            1765.0653
Q Predictions Min            760.9348
V Predictions Mean           1598.2189
V Predictions Std            150.63806
V Predictions Max            1768.0198
V Predictions Min            749.23834
Log Pis Mean                 -0.6167864
Log Pis Std                  1.8151612
Log Pis Max                  7.437038
Log Pis Min                  -4.1947403
Policy mu Mean               -0.10388612
Policy mu Std                0.77746415
Policy mu Max                2.1198642
Policy mu Min                -3.2860367
Policy log std Mean          -0.4156271
Policy log std Std           0.20430636
Policy log std Max           0.012547195
Policy log std Min           -1.5053349
Z mean eval                  0.026246693
Z variance eval              0.006298966
total_rewards                [1268.25262576 1041.67914604 1247.72607092  990.62051064  978.62177769
 1072.16167163 1217.47690087 1215.65855379 3297.3686503  3394.04722994]
total_rewards_mean           1572.3613137583293
total_rewards_std            892.637220412207
total_rewards_max            3394.0472299437884
total_rewards_min            978.6217776920324
Number of train steps total  479000
Number of env steps total    2397000
Number of rollouts total     0
Train Time (s)               44.74728161515668
(Previous) Eval Time (s)     27.18994884006679
Sample Time (s)              22.338778597302735
Epoch Time (s)               94.2760090525262
Total Train Time (s)         39354.56474262383
Epoch                        478
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:44:15.464775 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #478 | Epoch Duration: 81.69333219528198
2020-01-11 11:44:15.464898 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #478 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026108354
Z variance train             0.006290353
KL Divergence                10.424361
KL Loss                      1.0424361
QF Loss                      293.9813
VF Loss                      110.70407
Policy Loss                  -1598.9785
Q Predictions Mean           1602.2197
Q Predictions Std            122.16969
Q Predictions Max            1748.826
Q Predictions Min            832.94183
V Predictions Mean           1598.46
V Predictions Std            123.04165
V Predictions Max            1748.8804
V Predictions Min            834.3662
Log Pis Mean                 -0.46031514
Log Pis Std                  1.7341832
Log Pis Max                  5.0097466
Log Pis Min                  -4.665149
Policy mu Mean               0.06213158
Policy mu Std                0.83636063
Policy mu Max                2.732247
Policy mu Min                -3.076935
Policy log std Mean          -0.43530068
Policy log std Std           0.1702686
Policy log std Max           -0.062075764
Policy log std Min           -1.643488
Z mean eval                  0.0500846
Z variance eval              0.0053098663
total_rewards                [1479.9153692  1034.38898958 1166.61604478 2110.0464695  1666.65091531
 1074.34017462 2819.99151786 1990.04772503 1016.93327811 3318.3497402 ]
total_rewards_mean           1767.7280224173949
total_rewards_std            755.9727542780776
total_rewards_max            3318.3497401955738
total_rewards_min            1016.933278108943
Number of train steps total  480000
Number of env steps total    2402000
Number of rollouts total     0
Train Time (s)               44.43149974476546
(Previous) Eval Time (s)     14.607020578812808
Sample Time (s)              21.752376671414822
Epoch Time (s)               80.79089699499309
Total Train Time (s)         39438.56049094023
Epoch                        479
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:45:39.463512 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #479 | Epoch Duration: 83.99852323532104
2020-01-11 11:45:39.463635 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #479 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0507492
Z variance train             0.005312594
KL Divergence                10.753181
KL Loss                      1.0753182
QF Loss                      513.10297
VF Loss                      116.67736
Policy Loss                  -1598.26
Q Predictions Mean           1602.2523
Q Predictions Std            154.19398
Q Predictions Max            1787.2701
Q Predictions Min            438.6907
V Predictions Mean           1597.8982
V Predictions Std            154.63094
V Predictions Max            1777.0217
V Predictions Min            444.77927
Log Pis Mean                 -0.5687648
Log Pis Std                  1.8951789
Log Pis Max                  9.162108
Log Pis Min                  -5.3588085
Policy mu Mean               0.086352944
Policy mu Std                0.797586
Policy mu Max                2.42915
Policy mu Min                -4.250392
Policy log std Mean          -0.4336517
Policy log std Std           0.1837741
Policy log std Max           -0.079017505
Policy log std Min           -1.3105437
Z mean eval                  0.024545033
Z variance eval              0.0057456912
total_rewards                [3397.80715926 1350.37927791 2616.99009819 1229.86997246 3386.12959924
 3187.12504184  976.81955432 3372.42335388 1143.56210434 3429.73458255]
total_rewards_mean           2409.0840744005764
total_rewards_std            1035.1252697890886
total_rewards_max            3429.734582553617
total_rewards_min            976.8195543245971
Number of train steps total  481000
Number of env steps total    2407000
Number of rollouts total     0
Train Time (s)               44.55571030406281
(Previous) Eval Time (s)     17.814392295200378
Sample Time (s)              22.35312554007396
Epoch Time (s)               84.72322813933715
Total Train Time (s)         39527.93880770821
Epoch                        480
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:47:08.849639 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #480 | Epoch Duration: 89.38589096069336
2020-01-11 11:47:08.849832 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #480 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024932602
Z variance train             0.005741612
KL Divergence                10.504374
KL Loss                      1.0504373
QF Loss                      298.9395
VF Loss                      54.554176
Policy Loss                  -1582.1681
Q Predictions Mean           1582.3933
Q Predictions Std            153.13387
Q Predictions Max            1750.6616
Q Predictions Min            343.87076
V Predictions Mean           1585.6395
V Predictions Std            151.80635
V Predictions Max            1752.4197
V Predictions Min            382.95352
Log Pis Mean                 -0.5233352
Log Pis Std                  1.8700229
Log Pis Max                  10.009386
Log Pis Min                  -6.3067417
Policy mu Mean               -0.04284058
Policy mu Std                0.8038047
Policy mu Max                2.4437814
Policy mu Min                -2.9621263
Policy log std Mean          -0.4266542
Policy log std Std           0.18023618
Policy log std Max           0.044320792
Policy log std Min           -1.3863078
Z mean eval                  0.0345406
Z variance eval              0.005558816
total_rewards                [2485.99733104 3306.64440226 1133.21722019 3333.92683059 3330.55907436
 3301.16222675 3350.16015985 1089.73757486 3359.78667766 1013.76658266]
total_rewards_mean           2570.4958080208135
total_rewards_std            1007.776185446465
total_rewards_max            3359.7866776595683
total_rewards_min            1013.7665826597761
Number of train steps total  482000
Number of env steps total    2412000
Number of rollouts total     0
Train Time (s)               44.48274300713092
(Previous) Eval Time (s)     22.476806764956564
Sample Time (s)              23.283022926654667
Epoch Time (s)               90.24257269874215
Total Train Time (s)         39620.96431810036
Epoch                        481
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:48:41.877573 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #481 | Epoch Duration: 93.02760791778564
2020-01-11 11:48:41.877709 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #481 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035111103
Z variance train             0.0055551543
KL Divergence                10.662203
KL Loss                      1.0662203
QF Loss                      422.2978
VF Loss                      87.44145
Policy Loss                  -1573.8116
Q Predictions Mean           1576.6396
Q Predictions Std            143.95471
Q Predictions Max            1725.7427
Q Predictions Min            696.0955
V Predictions Mean           1573.9082
V Predictions Std            137.59834
V Predictions Max            1723.0846
V Predictions Min            725.6098
Log Pis Mean                 -0.49341196
Log Pis Std                  2.0483286
Log Pis Max                  7.4760203
Log Pis Min                  -5.4165354
Policy mu Mean               0.006893271
Policy mu Std                0.8411428
Policy mu Max                3.0857856
Policy mu Min                -3.122951
Policy log std Mean          -0.4237151
Policy log std Std           0.1837535
Policy log std Max           -0.00819245
Policy log std Min           -1.6893939
Z mean eval                  0.03539573
Z variance eval              0.0059864507
total_rewards                [3106.59961595 3331.27679943 3291.4361306  3332.0135283  1025.27222095
  956.5347288  3323.91525183 1173.26793194 3286.26028644 1440.65200252]
total_rewards_mean           2426.7228496761736
total_rewards_std            1051.6887025124024
total_rewards_max            3332.013528298851
total_rewards_min            956.5347288043041
Number of train steps total  483000
Number of env steps total    2417000
Number of rollouts total     0
Train Time (s)               43.872573339380324
(Previous) Eval Time (s)     25.261597925331444
Sample Time (s)              22.04772422509268
Epoch Time (s)               91.18189548980445
Total Train Time (s)         39710.02780556213
Epoch                        482
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:50:10.949998 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #482 | Epoch Duration: 89.07217764854431
2020-01-11 11:50:10.950177 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #482 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035526976
Z variance train             0.0059862644
KL Divergence                10.5114565
KL Loss                      1.0511457
QF Loss                      226.60504
VF Loss                      217.0901
Policy Loss                  -1594.9838
Q Predictions Mean           1592.7783
Q Predictions Std            155.48932
Q Predictions Max            1756.7552
Q Predictions Min            594.3246
V Predictions Mean           1589.0048
V Predictions Std            152.77646
V Predictions Max            1746.6289
V Predictions Min            619.2546
Log Pis Mean                 -0.8627136
Log Pis Std                  1.8501414
Log Pis Max                  5.870371
Log Pis Min                  -8.217597
Policy mu Mean               0.07422252
Policy mu Std                0.76739264
Policy mu Max                2.1770089
Policy mu Min                -3.223407
Policy log std Mean          -0.43655768
Policy log std Std           0.18193173
Policy log std Max           0.016509384
Policy log std Min           -1.3782719
Z mean eval                  0.032915678
Z variance eval              0.0056324657
total_rewards                [3247.25693568 2598.85940167 1299.99749857 2242.43268663 3317.0048685
 2687.37116682 1203.45753299 2713.31149027  971.40055991 1016.40897823]
total_rewards_mean           2129.750111927412
total_rewards_std            875.8111026616851
total_rewards_max            3317.0048684996427
total_rewards_min            971.4005599127989
Number of train steps total  484000
Number of env steps total    2422000
Number of rollouts total     0
Train Time (s)               45.00715429522097
(Previous) Eval Time (s)     23.151640705298632
Sample Time (s)              22.631556702312082
Epoch Time (s)               90.79035170283169
Total Train Time (s)         39798.669979656115
Epoch                        483
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:51:39.602168 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #483 | Epoch Duration: 88.65184569358826
2020-01-11 11:51:39.602346 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #483 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033706192
Z variance train             0.0056355484
KL Divergence                10.69441
KL Loss                      1.0694411
QF Loss                      68.71708
VF Loss                      70.1354
Policy Loss                  -1600.0375
Q Predictions Mean           1600.2661
Q Predictions Std            146.7854
Q Predictions Max            1764.9564
Q Predictions Min            795.1664
V Predictions Mean           1595.2725
V Predictions Std            145.8095
V Predictions Max            1756.9927
V Predictions Min            794.52484
Log Pis Mean                 -0.68630147
Log Pis Std                  1.7709581
Log Pis Max                  5.8269286
Log Pis Min                  -4.5639315
Policy mu Mean               -0.03761283
Policy mu Std                0.7851166
Policy mu Max                2.0229323
Policy mu Min                -2.9419122
Policy log std Mean          -0.43078384
Policy log std Std           0.1944679
Policy log std Max           -0.002020508
Policy log std Min           -1.2043407
Z mean eval                  0.015113154
Z variance eval              0.0062797293
total_rewards                [2215.75757171 3336.67285926 3367.43033883 2341.06189789 1197.70353106
 3179.38180858 3386.19412071 3325.59296954 1194.13069164 3363.84430003]
total_rewards_mean           2690.7770089247438
total_rewards_std            852.6754601913832
total_rewards_max            3386.194120709699
total_rewards_min            1194.1306916387803
Number of train steps total  485000
Number of env steps total    2427000
Number of rollouts total     0
Train Time (s)               44.05919709475711
(Previous) Eval Time (s)     21.012847993988544
Sample Time (s)              21.194192287512124
Epoch Time (s)               86.26623737625778
Total Train Time (s)         39890.815355093684
Epoch                        484
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:53:11.751531 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #484 | Epoch Duration: 92.1490592956543
2020-01-11 11:53:11.751664 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #484 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015203002
Z variance train             0.0062852753
KL Divergence                10.419625
KL Loss                      1.0419625
QF Loss                      80.630646
VF Loss                      42.573364
Policy Loss                  -1612.113
Q Predictions Mean           1611.0671
Q Predictions Std            117.346886
Q Predictions Max            1763.7722
Q Predictions Min            943.55035
V Predictions Mean           1613.7812
V Predictions Std            116.87262
V Predictions Max            1773.649
V Predictions Min            931.0562
Log Pis Mean                 -0.55776143
Log Pis Std                  2.0745194
Log Pis Max                  10.856245
Log Pis Min                  -5.1836243
Policy mu Mean               -0.010108501
Policy mu Std                0.809138
Policy mu Max                1.903446
Policy mu Min                -3.8528895
Policy log std Mean          -0.4089975
Policy log std Std           0.19628264
Policy log std Max           0.03218025
Policy log std Min           -1.2417431
Z mean eval                  0.025279706
Z variance eval              0.004969645
total_rewards                [3402.77678062 3359.60205575 3372.51432671 1472.4682435  1199.70706009
 3360.09052739  969.40295003 3362.40774793 1020.06165025 3400.01055224]
total_rewards_mean           2491.9041894508237
total_rewards_std            1090.3025892142066
total_rewards_max            3402.776780615525
total_rewards_min            969.4029500326803
Number of train steps total  486000
Number of env steps total    2432000
Number of rollouts total     0
Train Time (s)               44.603486771695316
(Previous) Eval Time (s)     26.895427256822586
Sample Time (s)              22.24713866505772
Epoch Time (s)               93.74605269357562
Total Train Time (s)         39982.551466355566
Epoch                        485
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:54:43.492165 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #485 | Epoch Duration: 91.74040532112122
2020-01-11 11:54:43.492337 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #485 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025207262
Z variance train             0.0049723256
KL Divergence                10.891911
KL Loss                      1.0891911
QF Loss                      77.08871
VF Loss                      52.682487
Policy Loss                  -1575.105
Q Predictions Mean           1574.067
Q Predictions Std            151.4004
Q Predictions Max            1743.9603
Q Predictions Min            685.9535
V Predictions Mean           1573.4463
V Predictions Std            152.47485
V Predictions Max            1738.5282
V Predictions Min            693.76324
Log Pis Mean                 -0.41078117
Log Pis Std                  2.0664155
Log Pis Max                  9.98921
Log Pis Min                  -4.5081844
Policy mu Mean               -0.038125027
Policy mu Std                0.819106
Policy mu Max                2.6459222
Policy mu Min                -3.3775818
Policy log std Mean          -0.40523902
Policy log std Std           0.18518862
Policy log std Max           0.03522247
Policy log std Min           -1.5414618
Z mean eval                  0.034820635
Z variance eval              0.005382019
total_rewards                [3339.32186095 3284.80194749 1049.93285497 3389.13383866 1228.00976244
 3361.27956787 1257.85763369 1248.11446733 3398.86289492 2342.99617476]
total_rewards_mean           2390.031100307341
total_rewards_std            1019.5684778759854
total_rewards_max            3398.862894918583
total_rewards_min            1049.9328549690888
Number of train steps total  487000
Number of env steps total    2437000
Number of rollouts total     0
Train Time (s)               44.03810505429283
(Previous) Eval Time (s)     24.88953877799213
Sample Time (s)              22.707901176065207
Epoch Time (s)               91.63554500835016
Total Train Time (s)         40072.24175354047
Epoch                        486
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:56:13.186797 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #486 | Epoch Duration: 89.69431805610657
2020-01-11 11:56:13.186984 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #486 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03483317
Z variance train             0.005385071
KL Divergence                10.6901
KL Loss                      1.06901
QF Loss                      133.60196
VF Loss                      57.174614
Policy Loss                  -1594.8385
Q Predictions Mean           1595.6067
Q Predictions Std            151.9369
Q Predictions Max            1753.4154
Q Predictions Min            569.8961
V Predictions Mean           1591.0829
V Predictions Std            151.99225
V Predictions Max            1752.6011
V Predictions Min            570.06683
Log Pis Mean                 -0.6122068
Log Pis Std                  1.7577363
Log Pis Max                  7.176218
Log Pis Min                  -4.7100043
Policy mu Mean               -0.056545544
Policy mu Std                0.7767074
Policy mu Max                2.3483806
Policy mu Min                -3.440632
Policy log std Mean          -0.4103438
Policy log std Std           0.17868015
Policy log std Max           0.037930995
Policy log std Min           -1.2538476
Z mean eval                  0.016160633
Z variance eval              0.0063018044
total_rewards                [3349.69528222 3323.23815275 3333.78966976 3425.74590418 3414.67737915
 1218.77670733 3389.80894947 3314.38843049 3358.28245495 3399.73996003]
total_rewards_mean           3152.814289034063
total_rewards_std            645.7233111518601
total_rewards_max            3425.745904182641
total_rewards_min            1218.7767073310465
Number of train steps total  488000
Number of env steps total    2442000
Number of rollouts total     0
Train Time (s)               44.19953224668279
(Previous) Eval Time (s)     22.948066086042672
Sample Time (s)              21.96653296938166
Epoch Time (s)               89.11413130210713
Total Train Time (s)         40167.30448262254
Epoch                        487
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:57:48.254500 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #487 | Epoch Duration: 95.06736612319946
2020-01-11 11:57:48.254683 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #487 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015499082
Z variance train             0.0063115517
KL Divergence                10.405137
KL Loss                      1.0405138
QF Loss                      143.55643
VF Loss                      90.95771
Policy Loss                  -1565.9283
Q Predictions Mean           1566.255
Q Predictions Std            168.847
Q Predictions Max            1758.2972
Q Predictions Min            535.28235
V Predictions Mean           1560.1853
V Predictions Std            167.90376
V Predictions Max            1743.8866
V Predictions Min            537.7574
Log Pis Mean                 -0.347448
Log Pis Std                  1.9738966
Log Pis Max                  8.101436
Log Pis Min                  -4.3538766
Policy mu Mean               -0.050385434
Policy mu Std                0.8549579
Policy mu Max                2.2057567
Policy mu Min                -3.2481709
Policy log std Mean          -0.44286215
Policy log std Std           0.20630768
Policy log std Max           0.037477612
Policy log std Min           -1.2355107
Z mean eval                  0.03178631
Z variance eval              0.005846373
total_rewards                [1775.22809906 1223.42250779 3352.19824311 3433.09900528  110.29641524
 3345.96455748 3345.19294478 3336.7224382  3303.33103449 1082.90244276]
total_rewards_mean           2430.8357688175715
total_rewards_std            1191.5672091074518
total_rewards_max            3433.0990052769757
total_rewards_min            110.29641524146088
Number of train steps total  489000
Number of env steps total    2447000
Number of rollouts total     0
Train Time (s)               44.743666369933635
(Previous) Eval Time (s)     28.901048209052533
Sample Time (s)              22.17640303168446
Epoch Time (s)               95.82111761067063
Total Train Time (s)         40258.19395518117
Epoch                        488
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:59:19.149211 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #488 | Epoch Duration: 90.89432144165039
2020-01-11 11:59:19.149463 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #488 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031422038
Z variance train             0.0058430876
KL Divergence                10.498688
KL Loss                      1.0498688
QF Loss                      125.316345
VF Loss                      118.7547
Policy Loss                  -1569.9464
Q Predictions Mean           1567.8877
Q Predictions Std            168.7709
Q Predictions Max            1790.3229
Q Predictions Min            219.3082
V Predictions Mean           1565.7244
V Predictions Std            170.7861
V Predictions Max            1785.324
V Predictions Min            193.04164
Log Pis Mean                 -0.48166895
Log Pis Std                  1.9282018
Log Pis Max                  8.515306
Log Pis Min                  -3.5483787
Policy mu Mean               0.10614216
Policy mu Std                0.80057293
Policy mu Max                2.502337
Policy mu Min                -3.171853
Policy log std Mean          -0.44373775
Policy log std Std           0.18742466
Policy log std Max           -0.06833136
Policy log std Min           -1.2214599
Z mean eval                  0.032098543
Z variance eval              0.0068218447
total_rewards                [3282.19411162 3272.02135312 3305.15127078 2891.12819025 3268.39789772
 3280.37457654 3327.32134811 3141.64061465 3340.62442839 3341.08693407]
total_rewards_mean           3244.9940725259485
total_rewards_std            129.8431775655827
total_rewards_max            3341.086934073185
total_rewards_min            2891.12819025464
Number of train steps total  490000
Number of env steps total    2452000
Number of rollouts total     0
Train Time (s)               44.43532662792131
(Previous) Eval Time (s)     23.973988614976406
Sample Time (s)              21.175531641580164
Epoch Time (s)               89.58484688447788
Total Train Time (s)         40356.13098983094
Epoch                        489
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:00:57.089117 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #489 | Epoch Duration: 97.93949913978577
2020-01-11 12:00:57.089265 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #489 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032099523
Z variance train             0.006827563
KL Divergence                10.184329
KL Loss                      1.018433
QF Loss                      43.253983
VF Loss                      22.804968
Policy Loss                  -1592.4012
Q Predictions Mean           1590.979
Q Predictions Std            135.63237
Q Predictions Max            1766.1378
Q Predictions Min            648.47
V Predictions Mean           1593.5853
V Predictions Std            136.30339
V Predictions Max            1768.7362
V Predictions Min            658.9903
Log Pis Mean                 -0.6624875
Log Pis Std                  1.8626785
Log Pis Max                  6.302866
Log Pis Min                  -5.8868093
Policy mu Mean               -0.0348597
Policy mu Std                0.7827309
Policy mu Max                1.9397523
Policy mu Min                -2.8630943
Policy log std Mean          -0.4087218
Policy log std Std           0.16881661
Policy log std Max           0.04025185
Policy log std Min           -1.1506994
Z mean eval                  0.032672547
Z variance eval              0.0067387857
total_rewards                [3390.86713105 3379.34976501 1086.75535269 3346.35645917 3397.6361058
 3412.57004972 3440.65625144 3355.81983501  960.9264702  1066.22473871]
total_rewards_mean           2683.7162158800356
total_rewards_std            1078.1103255803855
total_rewards_max            3440.6562514362145
total_rewards_min            960.9264701969818
Number of train steps total  491000
Number of env steps total    2457000
Number of rollouts total     0
Train Time (s)               44.71360935876146
(Previous) Eval Time (s)     32.32838522223756
Sample Time (s)              22.10190811380744
Epoch Time (s)               99.14390269480646
Total Train Time (s)         40446.88091314258
Epoch                        490
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:02:27.843564 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #490 | Epoch Duration: 90.75418257713318
2020-01-11 12:02:27.843742 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #490 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032618605
Z variance train             0.0067345435
KL Divergence                10.131844
KL Loss                      1.0131844
QF Loss                      150.26035
VF Loss                      122.37718
Policy Loss                  -1564.1271
Q Predictions Mean           1565.1023
Q Predictions Std            188.60126
Q Predictions Max            1735.3121
Q Predictions Min            75.87108
V Predictions Mean           1561.4781
V Predictions Std            187.35498
V Predictions Max            1731.2952
V Predictions Min            146.65392
Log Pis Mean                 -0.6440798
Log Pis Std                  1.9056644
Log Pis Max                  7.3944736
Log Pis Min                  -4.27065
Policy mu Mean               -0.03452511
Policy mu Std                0.79776746
Policy mu Max                3.311732
Policy mu Min                -3.6401327
Policy log std Mean          -0.42582187
Policy log std Std           0.18934259
Policy log std Max           -0.02027613
Policy log std Min           -1.1850876
Z mean eval                  0.03139729
Z variance eval              0.00591907
total_rewards                [2933.73191893 1245.34774548 3383.83962883 2990.15969835 3405.19247962
 3342.74649751 1019.69952876 1815.28235594 2542.48105878 2958.97613888]
total_rewards_mean           2563.74570510746
total_rewards_std            845.2961661650562
total_rewards_max            3405.1924796173466
total_rewards_min            1019.699528759244
Number of train steps total  492000
Number of env steps total    2462000
Number of rollouts total     0
Train Time (s)               45.10637855017558
(Previous) Eval Time (s)     23.938417402096093
Sample Time (s)              21.87305481825024
Epoch Time (s)               90.91785077052191
Total Train Time (s)         40537.118788309395
Epoch                        491
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:03:58.087567 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #491 | Epoch Duration: 90.24367618560791
2020-01-11 12:03:58.087774 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #491 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031102274
Z variance train             0.005911546
KL Divergence                10.616279
KL Loss                      1.0616279
QF Loss                      66.8978
VF Loss                      65.902596
Policy Loss                  -1599.025
Q Predictions Mean           1598.142
Q Predictions Std            145.75027
Q Predictions Max            1759.0308
Q Predictions Min            674.6327
V Predictions Mean           1594.2192
V Predictions Std            143.72562
V Predictions Max            1756.7521
V Predictions Min            676.9243
Log Pis Mean                 -0.5321752
Log Pis Std                  2.0057342
Log Pis Max                  10.182611
Log Pis Min                  -5.019034
Policy mu Mean               -0.037270073
Policy mu Std                0.80238676
Policy mu Max                2.5839038
Policy mu Min                -2.9707932
Policy log std Mean          -0.42095828
Policy log std Std           0.1825434
Policy log std Max           -0.03791192
Policy log std Min           -1.5064112
Z mean eval                  0.017194843
Z variance eval              0.006484691
total_rewards                [3129.38191089  873.36197254 2458.48058805 3284.20615138 3345.58711229
 3360.34667815 3395.52018294 3371.59547687 3343.38957373  896.56833648]
total_rewards_mean           2745.84379833368
total_rewards_std            967.1366189354569
total_rewards_max            3395.5201829428165
total_rewards_min            873.3619725400473
Number of train steps total  493000
Number of env steps total    2467000
Number of rollouts total     0
Train Time (s)               45.15211064508185
(Previous) Eval Time (s)     23.26398040028289
Sample Time (s)              21.95555431675166
Epoch Time (s)               90.3716453621164
Total Train Time (s)         40631.757693277206
Epoch                        492
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:05:32.729792 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #492 | Epoch Duration: 94.64186573028564
2020-01-11 12:05:32.729930 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #492 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017004108
Z variance train             0.0064743273
KL Divergence                10.227785
KL Loss                      1.0227785
QF Loss                      60.845886
VF Loss                      62.588768
Policy Loss                  -1582.8038
Q Predictions Mean           1582.5265
Q Predictions Std            134.45946
Q Predictions Max            1756.2324
Q Predictions Min            921.3672
V Predictions Mean           1584.2307
V Predictions Std            133.87088
V Predictions Max            1762.3289
V Predictions Min            943.76733
Log Pis Mean                 -0.6610282
Log Pis Std                  1.8467772
Log Pis Max                  9.981168
Log Pis Min                  -5.43676
Policy mu Mean               -0.1114602
Policy mu Std                0.7640335
Policy mu Max                2.6346219
Policy mu Min                -3.2998188
Policy log std Mean          -0.4107599
Policy log std Std           0.16801612
Policy log std Max           -0.011649311
Policy log std Min           -1.3506209
Z mean eval                  0.051700473
Z variance eval              0.008081324
total_rewards                [3357.61584376 3343.44380504 3384.22676919 3359.92943785 3370.2178375
 1341.45297531 3346.17651043 3400.46819877  957.13573436 2125.41137928]
total_rewards_mean           2798.6078491492635
total_rewards_std            906.8454258193495
total_rewards_max            3400.4681987688764
total_rewards_min            957.135734361029
Number of train steps total  494000
Number of env steps total    2472000
Number of rollouts total     0
Train Time (s)               44.6788081410341
(Previous) Eval Time (s)     27.533962205052376
Sample Time (s)              22.260589766316116
Epoch Time (s)               94.47336011240259
Total Train Time (s)         40724.77107152203
Epoch                        493
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:07:05.748025 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #493 | Epoch Duration: 93.01790022850037
2020-01-11 12:07:05.748260 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #493 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05173541
Z variance train             0.008090822
KL Divergence                9.688862
KL Loss                      0.9688862
QF Loss                      214.4623
VF Loss                      64.40693
Policy Loss                  -1585.1953
Q Predictions Mean           1584.1073
Q Predictions Std            150.16022
Q Predictions Max            1720.1089
Q Predictions Min            700.42487
V Predictions Mean           1583.3326
V Predictions Std            151.30615
V Predictions Max            1720.8903
V Predictions Min            676.3397
Log Pis Mean                 -0.42750186
Log Pis Std                  2.0976772
Log Pis Max                  10.238341
Log Pis Min                  -5.3465996
Policy mu Mean               -0.109654985
Policy mu Std                0.84156376
Policy mu Max                2.9551816
Policy mu Min                -3.252159
Policy log std Mean          -0.43955675
Policy log std Std           0.18963866
Policy log std Max           -0.009786606
Policy log std Min           -1.3697684
Z mean eval                  0.04072684
Z variance eval              0.007813832
total_rewards                [3412.80687605 3432.75925184 1683.34933693 3399.7466963  1260.23714537
 1051.71764426 3418.19141135 1234.51951898 1174.61257364 3417.72432738]
total_rewards_mean           2348.566478209239
total_rewards_std            1078.346759027092
total_rewards_max            3432.7592518395836
total_rewards_min            1051.7176442583275
Number of train steps total  495000
Number of env steps total    2477000
Number of rollouts total     0
Train Time (s)               44.027247064281255
(Previous) Eval Time (s)     26.078233415726572
Sample Time (s)              21.22911149682477
Epoch Time (s)               91.3345919768326
Total Train Time (s)         40812.558037677314
Epoch                        494
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:08:33.541121 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #494 | Epoch Duration: 87.79270148277283
2020-01-11 12:08:33.541299 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #494 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040821806
Z variance train             0.007806746
KL Divergence                9.822347
KL Loss                      0.98223466
QF Loss                      82.938705
VF Loss                      40.437164
Policy Loss                  -1588.0046
Q Predictions Mean           1589.385
Q Predictions Std            154.4753
Q Predictions Max            1754.9777
Q Predictions Min            492.40274
V Predictions Mean           1592.3416
V Predictions Std            154.00606
V Predictions Max            1763.1318
V Predictions Min            500.3038
Log Pis Mean                 -0.62857425
Log Pis Std                  1.8266008
Log Pis Max                  10.180255
Log Pis Min                  -4.4852257
Policy mu Mean               -0.07665717
Policy mu Std                0.7699134
Policy mu Max                2.0499637
Policy mu Min                -3.392565
Policy log std Mean          -0.40658164
Policy log std Std           0.16797154
Policy log std Max           0.09361875
Policy log std Min           -1.1203774
Z mean eval                  0.043753132
Z variance eval              0.007535752
total_rewards                [1378.91098403 1575.92096598 2446.80681343  910.59590899  753.29455614
 1031.36533565 1000.16543549 3206.56171763 3318.63031547 2909.82453168]
total_rewards_mean           1853.2076564485592
total_rewards_std            961.826739725879
total_rewards_max            3318.630315470916
total_rewards_min            753.2945561424276
Number of train steps total  496000
Number of env steps total    2482000
Number of rollouts total     0
Train Time (s)               44.545811555814
(Previous) Eval Time (s)     22.53609969187528
Sample Time (s)              22.03153358027339
Epoch Time (s)               89.11344482796267
Total Train Time (s)         40897.76185288699
Epoch                        495
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:09:58.744253 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #495 | Epoch Duration: 85.2028238773346
2020-01-11 12:09:58.744374 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #495 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043694895
Z variance train             0.007550816
KL Divergence                9.881319
KL Loss                      0.98813194
QF Loss                      140.64716
VF Loss                      64.54732
Policy Loss                  -1571.1382
Q Predictions Mean           1569.8506
Q Predictions Std            190.83939
Q Predictions Max            1735.924
Q Predictions Min            -14.330564
V Predictions Mean           1575.0858
V Predictions Std            192.39224
V Predictions Max            1748.2935
V Predictions Min            -29.539076
Log Pis Mean                 -0.45486602
Log Pis Std                  1.9786334
Log Pis Max                  7.752437
Log Pis Min                  -4.6637936
Policy mu Mean               -0.18098567
Policy mu Std                0.8014455
Policy mu Max                1.8705552
Policy mu Min                -3.1454291
Policy log std Mean          -0.41546044
Policy log std Std           0.17903371
Policy log std Max           0.013889611
Policy log std Min           -1.0948875
Z mean eval                  0.05107529
Z variance eval              0.007888548
total_rewards                [ 187.03435453 1228.14266508 3404.74389143 3348.48126547 3313.69034378
 3347.89268188 3358.75498698  194.38438365 3353.28672384 1485.15497261]
total_rewards_mean           2322.156626925513
total_rewards_std            1318.4072438831793
total_rewards_max            3404.743891431855
total_rewards_min            187.0343545296379
Number of train steps total  497000
Number of env steps total    2487000
Number of rollouts total     0
Train Time (s)               44.05850703874603
(Previous) Eval Time (s)     18.625220635905862
Sample Time (s)              21.94613646855578
Epoch Time (s)               84.62986414320767
Total Train Time (s)         40985.974445813335
Epoch                        496
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:11:26.961253 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #496 | Epoch Duration: 88.21675777435303
2020-01-11 12:11:26.961421 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #496 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05126732
Z variance train             0.007899689
KL Divergence                9.6847515
KL Loss                      0.96847516
QF Loss                      419.1424
VF Loss                      52.876667
Policy Loss                  -1592.3237
Q Predictions Mean           1593.2007
Q Predictions Std            131.82562
Q Predictions Max            1746.919
Q Predictions Min            869.3777
V Predictions Mean           1586.9597
V Predictions Std            130.78505
V Predictions Max            1740.6154
V Predictions Min            862.326
Log Pis Mean                 -0.7386975
Log Pis Std                  1.8158091
Log Pis Max                  9.557329
Log Pis Min                  -4.588715
Policy mu Mean               -0.011798084
Policy mu Std                0.7563419
Policy mu Max                3.5624292
Policy mu Min                -3.1876662
Policy log std Mean          -0.3967016
Policy log std Std           0.18814817
Policy log std Max           -0.026163995
Policy log std Min           -1.3037194
Z mean eval                  0.056580685
Z variance eval              0.009561444
total_rewards                [ 949.7737022   955.55425463 2357.002192   3389.07018637  680.66790195
 1014.1009047  3463.60163703  981.41022189 3468.45147991  953.99470083]
total_rewards_mean           1821.362718151077
total_rewards_std            1143.4361323872283
total_rewards_max            3468.451479908845
total_rewards_min            680.6679019477464
Number of train steps total  498000
Number of env steps total    2492000
Number of rollouts total     0
Train Time (s)               44.343569377902895
(Previous) Eval Time (s)     22.211867009289563
Sample Time (s)              21.708189125638455
Epoch Time (s)               88.26362551283091
Total Train Time (s)         41069.956090423744
Epoch                        497
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:12:50.945258 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #497 | Epoch Duration: 83.98371648788452
2020-01-11 12:12:50.945378 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #497 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.055217616
Z variance train             0.009565655
KL Divergence                9.256702
KL Loss                      0.92567027
QF Loss                      81.733376
VF Loss                      65.541275
Policy Loss                  -1575.0596
Q Predictions Mean           1576.9204
Q Predictions Std            168.79683
Q Predictions Max            1764.6014
Q Predictions Min            294.8545
V Predictions Mean           1577.2847
V Predictions Std            170.47647
V Predictions Max            1773.8588
V Predictions Min            260.28214
Log Pis Mean                 -0.51213515
Log Pis Std                  1.9779786
Log Pis Max                  8.399037
Log Pis Min                  -4.2907443
Policy mu Mean               0.003919056
Policy mu Std                0.81412935
Policy mu Max                3.0875676
Policy mu Min                -3.0722756
Policy log std Mean          -0.43664303
Policy log std Std           0.19763245
Policy log std Max           -0.047468007
Policy log std Min           -1.6052655
Z mean eval                  0.027103111
Z variance eval              0.008590585
total_rewards                [1675.98185109  718.923569    902.87672236 3405.69830141  847.45746108
 1210.34816835 3386.45335039 1810.71721217  294.68593016  910.65243417]
total_rewards_mean           1516.379500016802
total_rewards_std            1029.1590394865889
total_rewards_max            3405.698301405785
total_rewards_min            294.68593015867566
Number of train steps total  499000
Number of env steps total    2497000
Number of rollouts total     0
Train Time (s)               44.63232981506735
(Previous) Eval Time (s)     17.931716221850365
Sample Time (s)              22.187605537008494
Epoch Time (s)               84.75165157392621
Total Train Time (s)         41153.17374315858
Epoch                        498
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:14:14.165874 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #498 | Epoch Duration: 83.22040343284607
2020-01-11 12:14:14.165996 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #498 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02534615
Z variance train             0.008602631
KL Divergence                9.472161
KL Loss                      0.94721615
QF Loss                      234.95416
VF Loss                      189.11095
Policy Loss                  -1584.592
Q Predictions Mean           1588.7104
Q Predictions Std            140.14471
Q Predictions Max            1766.675
Q Predictions Min            894.84973
V Predictions Mean           1584.2214
V Predictions Std            139.68837
V Predictions Max            1761.2002
V Predictions Min            871.6483
Log Pis Mean                 -0.42137325
Log Pis Std                  2.0166008
Log Pis Max                  8.840765
Log Pis Min                  -4.835064
Policy mu Mean               0.040860277
Policy mu Std                0.8257437
Policy mu Max                2.2420514
Policy mu Min                -3.4046497
Policy log std Mean          -0.4266615
Policy log std Std           0.16430415
Policy log std Max           0.13109171
Policy log std Min           -1.3110391
Z mean eval                  0.03143128
Z variance eval              0.009184889
total_rewards                [3397.33494967 3339.67267551 1482.98345651 3007.28318548 1188.30329285
 3357.95283367 3391.36454993 3353.73815616 2677.99377559 3371.14324966]
total_rewards_mean           2856.77701250232
total_rewards_std            793.7017065304718
total_rewards_max            3397.33494967071
total_rewards_min            1188.303292850121
Number of train steps total  500000
Number of env steps total    2502000
Number of rollouts total     0
Train Time (s)               43.635860552079976
(Previous) Eval Time (s)     16.40022307401523
Sample Time (s)              22.04705395642668
Epoch Time (s)               82.08313758252189
Total Train Time (s)         41246.91253012279
Epoch                        499
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:15:47.912677 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #499 | Epoch Duration: 93.74658751487732
2020-01-11 12:15:47.912804 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #499 | Started Training: True
2020-01-11 12:15:48.245956 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Variant:
2020-01-11 12:15:48.246555 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] {
  "env_name": "HalfCheetah-v2",
  "n_train_tasks": 1,
  "n_eval_tasks": 1,
  "latent_size": 5,
  "net_size": 300,
  "path_to_weights": null,
  "env_params": {
    "n_tasks": 2,
    "randomize_tasks": true
  },
  "algo_params": {
    "meta_batch": 1,
    "num_iterations": 500,
    "num_initial_steps": 2000,
    "num_tasks_sample": 5,
    "num_steps_prior": 400,
    "num_steps_posterior": 0,
    "num_extra_rl_steps_posterior": 600,
    "num_train_steps_per_itr": 1000,
    "num_evals": 2,
    "num_steps_per_eval": 600,
    "batch_size": 256,
    "embedding_batch_size": 20,
    "embedding_mini_batch_size": 20,
    "max_path_length": 200,
    "discount": 0.99,
    "soft_target_tau": 0.005,
    "policy_lr": 0.0003,
    "qf_lr": 0.0003,
    "vf_lr": 0.0003,
    "context_lr": 0.0003,
    "reward_scale": 5.0,
    "sparse_rewards": false,
    "kl_lambda": 0.1,
    "use_information_bottleneck": true,
    "use_next_obs_in_context": false,
    "update_post_train": 1,
    "num_exp_traj_eval": 2,
    "recurrent": true,
    "dump_eval_paths": false
  },
  "util_params": {
    "base_log_dir": "./test/train1000/H-20_inverse-seed",
    "use_gpu": true,
    "gpu_id": 1,
    "debug": false,
    "docker": false,
    "num_iterations": 3000
  }
}
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0020600972
Z variance train             0.69202816
KL Divergence                0.15040708
KL Loss                      0.015040708
QF Loss                      28.183
VF Loss                      15.911762
Policy Loss                  -3.9524562
Q Predictions Mean           -0.00330954
Q Predictions Std            0.0025812825
Q Predictions Max            0.003119661
Q Predictions Min            -0.009606319
V Predictions Mean           5.9093145e-05
V Predictions Std            0.0024167623
V Predictions Max            0.0058722943
V Predictions Min            -0.0071488265
Log Pis Mean                 -3.9758787
Log Pis Std                  0.5386233
Log Pis Max                  -2.552077
Log Pis Min                  -5.277665
Policy mu Mean               -9.328403e-05
Policy mu Std                0.0020495066
Policy mu Max                0.007327754
Policy mu Min                -0.0048345733
Policy log std Mean          -0.00030216295
Policy log std Std           0.0015193376
Policy log std Max           0.0043097665
Policy log std Min           -0.003943738
Z mean eval                  0.18584004
Z variance eval              0.30799332
total_rewards                [-209.75237883 -200.52026262 -177.23130825 -167.54452311 -186.50713563
 -191.19055325 -167.23350191 -167.15963588 -182.70551887 -157.74649576]
total_rewards_mean           -180.75913141105792
total_rewards_std            15.688514848634444
total_rewards_max            -157.74649576028037
total_rewards_min            -209.7523788279863
Number of train steps total  1000
Number of env steps total    7000
Number of rollouts total     0
Train Time (s)               42.24196321005002
(Previous) Eval Time (s)     0
Sample Time (s)              30.262959756422788
Epoch Time (s)               72.5049229664728
Total Train Time (s)         105.48112335661426
Epoch                        0
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:17:33.823390 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #0 | Epoch Duration: 105.48710322380066
2020-01-11 12:17:33.823677 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #0 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.16559115
Z variance train             0.30562943
KL Divergence                1.3302995
KL Loss                      0.13302995
QF Loss                      12.327865
VF Loss                      3.5192213
Policy Loss                  -16.371422
Q Predictions Mean           12.9579735
Q Predictions Std            6.2498684
Q Predictions Max            29.620481
Q Predictions Min            -6.919672
V Predictions Mean           16.500942
V Predictions Std            5.595462
V Predictions Max            30.714216
V Predictions Min            -2.165135
Log Pis Mean                 -3.0824866
Log Pis Std                  1.3168906
Log Pis Max                  0.49670863
Log Pis Min                  -7.115242
Policy mu Mean               0.056227464
Policy mu Std                0.4509173
Policy mu Max                1.1253784
Policy mu Min                -1.2824268
Policy log std Mean          -0.2003717
Policy log std Std           0.08322352
Policy log std Max           -0.094599195
Policy log std Min           -0.4677144
Z mean eval                  0.30950513
Z variance eval              0.15528515
total_rewards                [-248.31617773 -251.37876513 -201.14882157 -212.3997642  -236.65337911
 -237.58134203 -224.93979461 -250.78461873 -248.1475152  -201.03185997]
total_rewards_mean           -231.23820382833233
total_rewards_std            19.097635912892873
total_rewards_max            -201.03185996873373
total_rewards_min            -251.3787651252597
Number of train steps total  2000
Number of env steps total    12000
Number of rollouts total     0
Train Time (s)               42.16188034089282
(Previous) Eval Time (s)     32.98200049530715
Sample Time (s)              20.7704764935188
Epoch Time (s)               95.91435732971877
Total Train Time (s)         200.70479990076274
Epoch                        1
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:19:09.044587 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #1 | Epoch Duration: 95.22071552276611
2020-01-11 12:19:09.044712 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #1 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.3095908
Z variance train             0.1552274
KL Divergence                2.8877683
KL Loss                      0.28877684
QF Loss                      28.534382
VF Loss                      4.261294
Policy Loss                  -29.617222
Q Predictions Mean           25.296654
Q Predictions Std            10.647309
Q Predictions Max            54.617996
Q Predictions Min            -14.917496
V Predictions Mean           28.97959
V Predictions Std            9.933784
V Predictions Max            57.860794
V Predictions Min            -5.908034
Log Pis Mean                 -3.3271968
Log Pis Std                  1.2098199
Log Pis Max                  1.4419845
Log Pis Min                  -7.258246
Policy mu Mean               0.1135541
Policy mu Std                0.38979638
Policy mu Max                1.3143734
Policy mu Min                -0.9772454
Policy log std Mean          -0.20843469
Policy log std Std           0.06674733
Policy log std Max           -0.063460186
Policy log std Min           -0.4690865
Z mean eval                  0.558038
Z variance eval              0.0816489
total_rewards                [-308.48214667 -236.20604511 -220.78454545 -285.96465983 -245.84911356
 -268.79605359 -245.72562265 -199.17705236 -250.92078715 -243.59187613]
total_rewards_mean           -250.549790250008
total_rewards_std            29.61095610771312
total_rewards_max            -199.17705236455774
total_rewards_min            -308.48214666784423
Number of train steps total  3000
Number of env steps total    17000
Number of rollouts total     0
Train Time (s)               43.24886351823807
(Previous) Eval Time (s)     32.28811395308003
Sample Time (s)              21.617964779026806
Epoch Time (s)               97.1549422503449
Total Train Time (s)         298.77745401859283
Epoch                        2
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:20:47.118075 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #2 | Epoch Duration: 98.07326865196228
2020-01-11 12:20:47.118200 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #2 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.54893386
Z variance train             0.08726196
KL Divergence                4.8524704
KL Loss                      0.48524705
QF Loss                      29.061104
VF Loss                      4.823239
Policy Loss                  -46.339714
Q Predictions Mean           42.183025
Q Predictions Std            13.1568365
Q Predictions Max            84.283646
Q Predictions Min            -0.1025891
V Predictions Mean           46.56375
V Predictions Std            12.467995
V Predictions Max            86.88575
V Predictions Min            6.473359
Log Pis Mean                 -3.2811937
Log Pis Std                  1.3717824
Log Pis Max                  1.0882809
Log Pis Min                  -7.5400743
Policy mu Mean               0.043214638
Policy mu Std                0.47027314
Policy mu Max                1.9189286
Policy mu Min                -1.5536793
Policy log std Mean          -0.20664339
Policy log std Std           0.076004475
Policy log std Max           -0.049106747
Policy log std Min           -0.6495507
Z mean eval                  0.753764
Z variance eval              0.06121973
total_rewards                [-143.78836915 -138.68591203 -112.81884455 -121.69072401 -127.97149908
 -209.06694622 -123.37751558 -156.05747855 -104.44968863 -119.70540432]
total_rewards_mean           -135.76123821072343
total_rewards_std            28.346472627427573
total_rewards_max            -104.44968862586441
total_rewards_min            -209.0669462172701
Number of train steps total  4000
Number of env steps total    22000
Number of rollouts total     0
Train Time (s)               42.96867426857352
(Previous) Eval Time (s)     33.20618709176779
Sample Time (s)              21.9429399385117
Epoch Time (s)               98.11780129885301
Total Train Time (s)         395.22616697242483
Epoch                        3
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:22:23.567994 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #3 | Epoch Duration: 96.44968152046204
2020-01-11 12:22:23.568123 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #3 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7764463
Z variance train             0.052531708
KL Divergence                7.237256
KL Loss                      0.7237256
QF Loss                      43.32676
VF Loss                      10.039244
Policy Loss                  -63.192448
Q Predictions Mean           58.852
Q Predictions Std            15.130372
Q Predictions Max            113.83617
Q Predictions Min            9.308786
V Predictions Mean           64.5431
V Predictions Std            14.823861
V Predictions Max            113.81343
V Predictions Min            20.945656
Log Pis Mean                 -3.104137
Log Pis Std                  1.6060246
Log Pis Max                  2.8944268
Log Pis Min                  -7.5435195
Policy mu Mean               0.06680863
Policy mu Std                0.49880254
Policy mu Max                1.9226758
Policy mu Min                -1.372908
Policy log std Mean          -0.21119244
Policy log std Std           0.091725096
Policy log std Max           0.0024010278
Policy log std Min           -0.64928174
Z mean eval                  0.92060405
Z variance eval              0.051371843
total_rewards                [-188.52086373 -160.05642317 -147.70690989 -208.72723178 -133.73984975
 -156.9290255  -164.89975776 -125.04828521 -168.04285173 -193.47276985]
total_rewards_mean           -164.71439683565586
total_rewards_std            24.99284059854631
total_rewards_max            -125.04828520742674
total_rewards_min            -208.72723178178572
Number of train steps total  5000
Number of env steps total    27000
Number of rollouts total     0
Train Time (s)               43.3089035442099
(Previous) Eval Time (s)     31.537812333088368
Sample Time (s)              21.530327634885907
Epoch Time (s)               96.37704351218417
Total Train Time (s)         490.5649649677798
Epoch                        4
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:23:58.909286 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #4 | Epoch Duration: 95.34105110168457
2020-01-11 12:23:58.909469 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #4 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92265236
Z variance train             0.051336445
KL Divergence                8.434088
KL Loss                      0.84340876
QF Loss                      35.216118
VF Loss                      8.430434
Policy Loss                  -74.90462
Q Predictions Mean           69.91186
Q Predictions Std            15.972688
Q Predictions Max            126.75994
Q Predictions Min            34.293987
V Predictions Mean           73.58263
V Predictions Std            15.714586
V Predictions Max            128.46939
V Predictions Min            36.665367
Log Pis Mean                 -2.8829134
Log Pis Std                  1.4986029
Log Pis Max                  3.7177806
Log Pis Min                  -6.833454
Policy mu Mean               0.06435246
Policy mu Std                0.51327604
Policy mu Max                1.9853638
Policy mu Min                -1.5592855
Policy log std Mean          -0.23384398
Policy log std Std           0.10498797
Policy log std Max           -0.0113859745
Policy log std Min           -0.7179337
Z mean eval                  1.0178843
Z variance eval              0.04250083
total_rewards                [-151.79513374 -162.93276438 -147.15128462 -145.74472617 -128.95805731
 -150.01460259 -192.21842933 -133.37765019 -128.87438563 -167.95424981]
total_rewards_mean           -150.90212837765387
total_rewards_std            18.59750413650274
total_rewards_max            -128.87438562965554
total_rewards_min            -192.21842933225838
Number of train steps total  6000
Number of env steps total    32000
Number of rollouts total     0
Train Time (s)               43.5812860801816
(Previous) Eval Time (s)     30.501552977599204
Sample Time (s)              20.07932383241132
Epoch Time (s)               94.16216289019212
Total Train Time (s)         587.2914257170632
Epoch                        5
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:25:35.635278 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #5 | Epoch Duration: 96.72567749023438
2020-01-11 12:25:35.635413 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #5 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0181682
Z variance train             0.042591345
KL Divergence                9.576448
KL Loss                      0.9576449
QF Loss                      39.25441
VF Loss                      8.310037
Policy Loss                  -86.86194
Q Predictions Mean           83.98616
Q Predictions Std            18.742405
Q Predictions Max            151.65579
Q Predictions Min            47.155373
V Predictions Mean           85.274796
V Predictions Std            18.601213
V Predictions Max            132.48674
V Predictions Min            46.928284
Log Pis Mean                 -3.1312184
Log Pis Std                  1.5873042
Log Pis Max                  2.9333131
Log Pis Min                  -6.9211426
Policy mu Mean               0.017812004
Policy mu Std                0.46540222
Policy mu Max                1.9541844
Policy mu Min                -1.9846884
Policy log std Mean          -0.21517003
Policy log std Std           0.101355664
Policy log std Max           -0.0061489344
Policy log std Min           -0.73644257
Z mean eval                  1.0568721
Z variance eval              0.04502411
total_rewards                [-107.83425917 -134.4388758  -117.44695325 -125.75032666  -73.35675248
  -84.37024071  -99.00594087  -53.99233715  -61.54109585 -126.99450769]
total_rewards_mean           -98.47312896343854
total_rewards_std            27.333514033836128
total_rewards_max            -53.99233714892616
total_rewards_min            -134.43887579708087
Number of train steps total  7000
Number of env steps total    37000
Number of rollouts total     0
Train Time (s)               44.387974727898836
(Previous) Eval Time (s)     33.06481331726536
Sample Time (s)              21.364508517086506
Epoch Time (s)               98.8172965622507
Total Train Time (s)         686.1522840294056
Epoch                        6
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:27:14.497373 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #6 | Epoch Duration: 98.86184525489807
2020-01-11 12:27:14.497553 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #6 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0613319
Z variance train             0.04488374
KL Divergence                10.342905
KL Loss                      1.0342906
QF Loss                      38.843193
VF Loss                      21.359701
Policy Loss                  -101.65652
Q Predictions Mean           97.68727
Q Predictions Std            23.980492
Q Predictions Max            163.92717
Q Predictions Min            57.86278
V Predictions Mean           98.7585
V Predictions Std            23.798973
V Predictions Max            166.61041
V Predictions Min            63.63736
Log Pis Mean                 -3.214964
Log Pis Std                  1.3896179
Log Pis Max                  1.9597057
Log Pis Min                  -6.3674264
Policy mu Mean               0.012315399
Policy mu Std                0.46292523
Policy mu Max                1.8960283
Policy mu Min                -1.7398049
Policy log std Mean          -0.23355329
Policy log std Std           0.10025261
Policy log std Max           0.090940714
Policy log std Min           -0.6785979
Z mean eval                  1.0979204
Z variance eval              0.04145319
total_rewards                [-45.95266423 -61.60290244 -71.36822087 -47.1051806  -13.1582554
 -50.81926584 -61.6739537  -82.97738117 -18.52707876 -43.53391899]
total_rewards_mean           -49.67188220003153
total_rewards_std            20.56463391918392
total_rewards_max            -13.158255402119606
total_rewards_min            -82.97738117328277
Number of train steps total  8000
Number of env steps total    42000
Number of rollouts total     0
Train Time (s)               43.162616645917296
(Previous) Eval Time (s)     33.10909095685929
Sample Time (s)              22.25908508663997
Epoch Time (s)               98.53079268941656
Total Train Time (s)         784.7431868975982
Epoch                        7
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:28:53.090500 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #7 | Epoch Duration: 98.59273481369019
2020-01-11 12:28:53.090759 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #7 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0979568
Z variance train             0.041657664
KL Divergence                11.14563
KL Loss                      1.114563
QF Loss                      28.661596
VF Loss                      10.421909
Policy Loss                  -113.773964
Q Predictions Mean           109.389755
Q Predictions Std            26.95564
Q Predictions Max            188.39154
Q Predictions Min            72.94373
V Predictions Mean           114.68779
V Predictions Std            27.058546
V Predictions Max            197.47667
V Predictions Min            79.670876
Log Pis Mean                 -3.1573057
Log Pis Std                  1.4279749
Log Pis Max                  2.6324375
Log Pis Min                  -6.765694
Policy mu Mean               -0.03201894
Policy mu Std                0.46627107
Policy mu Max                1.9313345
Policy mu Min                -1.9017223
Policy log std Mean          -0.23636396
Policy log std Std           0.101216555
Policy log std Max           0.10597792
Policy log std Min           -0.70060575
Z mean eval                  1.1419532
Z variance eval              0.03755837
total_rewards                [-59.87330452 -17.83489846 -71.8545005  -10.9047206  -71.58403273
  -9.13220641 -36.87867087 -35.96536922 -22.75054316  -4.44734399]
total_rewards_mean           -34.12255904742957
total_rewards_std            24.372051984117
total_rewards_max            -4.447343992945109
total_rewards_min            -71.85450050443185
Number of train steps total  9000
Number of env steps total    47000
Number of rollouts total     0
Train Time (s)               42.691810810007155
(Previous) Eval Time (s)     33.17076000524685
Sample Time (s)              22.516645714640617
Epoch Time (s)               98.37921652989462
Total Train Time (s)         881.7194856475107
Epoch                        8
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:30:30.069834 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #8 | Epoch Duration: 96.97886943817139
2020-01-11 12:30:30.070137 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #8 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1372417
Z variance train             0.03777818
KL Divergence                11.72912
KL Loss                      1.172912
QF Loss                      31.659367
VF Loss                      7.179397
Policy Loss                  -117.81958
Q Predictions Mean           114.34748
Q Predictions Std            27.767927
Q Predictions Max            197.00972
Q Predictions Min            75.42309
V Predictions Mean           118.76131
V Predictions Std            28.36486
V Predictions Max            204.55684
V Predictions Min            84.16558
Log Pis Mean                 -3.267201
Log Pis Std                  1.4309007
Log Pis Max                  2.0273662
Log Pis Min                  -6.361932
Policy mu Mean               0.03513206
Policy mu Std                0.45367497
Policy mu Max                1.7903631
Policy mu Min                -1.9631909
Policy log std Mean          -0.22874789
Policy log std Std           0.107567474
Policy log std Max           0.08112313
Policy log std Min           -0.7886902
Z mean eval                  1.1606027
Z variance eval              0.045483314
total_rewards                [-15.07297906  -7.33435856 -10.24317321   8.00023741 -58.45675469
 -15.77935169  -8.01537386 -14.0461922  -16.23445675   1.0362501 ]
total_rewards_mean           -13.614615251334635
total_rewards_std            16.699370250394903
total_rewards_max            8.000237406874145
total_rewards_min            -58.4567546940165
Number of train steps total  10000
Number of env steps total    52000
Number of rollouts total     0
Train Time (s)               42.66581978695467
(Previous) Eval Time (s)     31.77016917290166
Sample Time (s)              21.60548312496394
Epoch Time (s)               96.04147208482027
Total Train Time (s)         979.2595014832914
Epoch                        9
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:32:07.608243 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #9 | Epoch Duration: 97.5378828048706
2020-01-11 12:32:07.608422 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #9 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1607916
Z variance train             0.0455797
KL Divergence                11.662987
KL Loss                      1.1662987
QF Loss                      29.607681
VF Loss                      8.75674
Policy Loss                  -129.58498
Q Predictions Mean           127.31658
Q Predictions Std            32.415054
Q Predictions Max            236.31355
Q Predictions Min            89.65092
V Predictions Mean           130.50073
V Predictions Std            32.65002
V Predictions Max            241.80768
V Predictions Min            92.4087
Log Pis Mean                 -3.2984648
Log Pis Std                  1.4175286
Log Pis Max                  1.2915066
Log Pis Min                  -7.524759
Policy mu Mean               0.007542758
Policy mu Std                0.46677092
Policy mu Max                1.7791708
Policy mu Min                -1.7558572
Policy log std Mean          -0.23715217
Policy log std Std           0.11719772
Policy log std Max           0.26493296
Policy log std Min           -0.76352626
Z mean eval                  1.1816143
Z variance eval              0.04508263
total_rewards                [ 6.11185369 51.75237034  9.24413526 64.9956963  52.55719444 39.08494432
  7.46589628 34.04390559 31.1594491  17.39348515]
total_rewards_mean           31.380893047804165
total_rewards_std            19.889735920234337
total_rewards_max            64.99569629637664
total_rewards_min            6.111853694534236
Number of train steps total  11000
Number of env steps total    57000
Number of rollouts total     0
Train Time (s)               42.36824020976201
(Previous) Eval Time (s)     33.266366666182876
Sample Time (s)              22.16512540495023
Epoch Time (s)               97.79973228089511
Total Train Time (s)         1074.651222480461
Epoch                        10
---------------------------  --------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:33:43.000370 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #10 | Epoch Duration: 95.39181804656982
2020-01-11 12:33:43.000509 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #10 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1835927
Z variance train             0.045223754
KL Divergence                11.998756
KL Loss                      1.1998757
QF Loss                      32.248833
VF Loss                      7.871694
Policy Loss                  -142.76549
Q Predictions Mean           140.76733
Q Predictions Std            35.249115
Q Predictions Max            244.27731
Q Predictions Min            97.60948
V Predictions Mean           142.14252
V Predictions Std            35.167618
V Predictions Max            250.84715
V Predictions Min            100.46678
Log Pis Mean                 -3.1800642
Log Pis Std                  1.466007
Log Pis Max                  3.694059
Log Pis Min                  -6.7546625
Policy mu Mean               0.058144093
Policy mu Std                0.45798707
Policy mu Max                1.5080462
Policy mu Min                -1.9619982
Policy log std Mean          -0.22972734
Policy log std Std           0.114281006
Policy log std Max           0.27930713
Policy log std Min           -0.7352505
Z mean eval                  1.208993
Z variance eval              0.045823883
total_rewards                [272.9658942  181.14123446  79.07467    133.8316305  128.9309958
 167.64296372 168.42909512 177.0944402  187.36081143 113.57286621]
total_rewards_mean           161.00446016503946
total_rewards_std            49.72213636036173
total_rewards_max            272.965894198641
total_rewards_min            79.07467000315766
Number of train steps total  12000
Number of env steps total    62000
Number of rollouts total     0
Train Time (s)               42.3035854822956
(Previous) Eval Time (s)     30.85820125695318
Sample Time (s)              21.268086451105773
Epoch Time (s)               94.42987319035456
Total Train Time (s)         1167.793439622037
Epoch                        11
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:35:16.147177 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #11 | Epoch Duration: 93.14648270606995
2020-01-11 12:35:16.147434 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #11 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2079556
Z variance train             0.045861937
KL Divergence                12.235235
KL Loss                      1.2235235
QF Loss                      30.506771
VF Loss                      9.51557
Policy Loss                  -152.44145
Q Predictions Mean           148.17366
Q Predictions Std            38.71521
Q Predictions Max            262.89227
Q Predictions Min            102.13195
V Predictions Mean           153.01993
V Predictions Std            39.79134
V Predictions Max            270.85574
V Predictions Min            103.26917
Log Pis Mean                 -3.1609511
Log Pis Std                  1.4801074
Log Pis Max                  2.3881633
Log Pis Min                  -8.005582
Policy mu Mean               0.0426883
Policy mu Std                0.47691208
Policy mu Max                2.172201
Policy mu Min                -1.8370585
Policy log std Mean          -0.23474894
Policy log std Std           0.10717843
Policy log std Max           0.22917502
Policy log std Min           -0.8652712
Z mean eval                  1.2277794
Z variance eval              0.04472827
total_rewards                [249.54219435 241.99780266 193.58951365 233.54665129 123.40303788
 251.02130087 179.99137319 290.52194408 237.95189856 230.49714685]
total_rewards_mean           223.2062863376139
total_rewards_std            44.084756055709946
total_rewards_max            290.5219440765163
total_rewards_min            123.4030378834662
Number of train steps total  13000
Number of env steps total    67000
Number of rollouts total     0
Train Time (s)               42.30710013723001
(Previous) Eval Time (s)     29.574527690187097
Sample Time (s)              21.614177708048373
Epoch Time (s)               93.49580553546548
Total Train Time (s)         1264.6672550505027
Epoch                        12
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:36:53.024243 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #12 | Epoch Duration: 96.87660026550293
2020-01-11 12:36:53.024558 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #12 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2270677
Z variance train             0.04472376
KL Divergence                12.672585
KL Loss                      1.2672585
QF Loss                      27.576317
VF Loss                      9.040525
Policy Loss                  -156.08661
Q Predictions Mean           153.14452
Q Predictions Std            38.082855
Q Predictions Max            281.83264
Q Predictions Min            108.399055
V Predictions Mean           156.49568
V Predictions Std            37.921284
V Predictions Max            277.76697
V Predictions Min            117.20155
Log Pis Mean                 -3.1251464
Log Pis Std                  1.3510581
Log Pis Max                  1.15365
Log Pis Min                  -6.6285667
Policy mu Mean               0.0315288
Policy mu Std                0.46606022
Policy mu Max                1.5845894
Policy mu Min                -1.8225046
Policy log std Mean          -0.22964394
Policy log std Std           0.103285536
Policy log std Max           0.19793047
Policy log std Min           -0.7842805
Z mean eval                  1.2334087
Z variance eval              0.050741185
total_rewards                [283.16278203 199.25185456 309.33779705 284.60992609 156.38972552
 202.50260768 262.73954623 255.95735192 280.21910777 386.52401349]
total_rewards_mean           262.06947123351773
total_rewards_std            61.40514371125438
total_rewards_max            386.524013491249
total_rewards_min            156.38972551853075
Number of train steps total  14000
Number of env steps total    72000
Number of rollouts total     0
Train Time (s)               42.61099339509383
(Previous) Eval Time (s)     32.95507546002045
Sample Time (s)              21.01467065513134
Epoch Time (s)               96.58073951024562
Total Train Time (s)         1360.5995521345176
Epoch                        13
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:38:28.956632 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #13 | Epoch Duration: 95.93184661865234
2020-01-11 12:38:28.956792 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #13 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2320352
Z variance train             0.050591785
KL Divergence                12.208779
KL Loss                      1.220878
QF Loss                      36.76989
VF Loss                      10.960081
Policy Loss                  -175.248
Q Predictions Mean           170.6648
Q Predictions Std            46.07423
Q Predictions Max            313.8325
Q Predictions Min            122.313675
V Predictions Mean           174.81021
V Predictions Std            45.80331
V Predictions Max            320.71243
V Predictions Min            127.4466
Log Pis Mean                 -2.9783516
Log Pis Std                  1.5033078
Log Pis Max                  1.5007019
Log Pis Min                  -6.666532
Policy mu Mean               0.012805298
Policy mu Std                0.49441925
Policy mu Max                1.6241202
Policy mu Min                -2.1117616
Policy log std Mean          -0.24656254
Policy log std Std           0.1254228
Policy log std Max           0.31772053
Policy log std Min           -0.8626399
Z mean eval                  1.2546648
Z variance eval              0.046989657
total_rewards                [368.14599353 551.47460327 479.21103138 304.17266708 519.3472135
 334.6984743  296.02615315 566.3024509  778.29124031 402.65537882]
total_rewards_mean           460.03252062452464
total_rewards_std            142.64076879890865
total_rewards_max            778.2912403144154
total_rewards_min            296.0261531526455
Number of train steps total  15000
Number of env steps total    77000
Number of rollouts total     0
Train Time (s)               43.10120340809226
(Previous) Eval Time (s)     32.30595307610929
Sample Time (s)              19.919198364950716
Epoch Time (s)               95.32635484915227
Total Train Time (s)         1453.7026953506283
Epoch                        14
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:40:02.060016 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #14 | Epoch Duration: 93.10308194160461
2020-01-11 12:40:02.060203 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #14 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2574222
Z variance train             0.047022916
KL Divergence                12.526917
KL Loss                      1.2526917
QF Loss                      36.390167
VF Loss                      23.787
Policy Loss                  -187.41519
Q Predictions Mean           183.7345
Q Predictions Std            49.392025
Q Predictions Max            342.20676
Q Predictions Min            130.11653
V Predictions Mean           183.97731
V Predictions Std            49.881306
V Predictions Max            341.52216
V Predictions Min            129.51389
Log Pis Mean                 -2.9938405
Log Pis Std                  1.466527
Log Pis Max                  1.7879374
Log Pis Min                  -6.7233686
Policy mu Mean               0.018197922
Policy mu Std                0.52159256
Policy mu Max                1.7157183
Policy mu Min                -1.914024
Policy log std Mean          -0.26438263
Policy log std Std           0.1292547
Policy log std Max           0.19127452
Policy log std Min           -1.0364424
Z mean eval                  1.2737949
Z variance eval              0.048073187
total_rewards                [ 324.09429894  335.12848833  340.84343242  366.96223161  646.85367844
  835.09312417 1115.44310841  430.19168651  378.63944555  961.85738732]
total_rewards_mean           573.510688170678
total_rewards_std            281.54121093512686
total_rewards_max            1115.4431084063585
total_rewards_min            324.09429893924283
Number of train steps total  16000
Number of env steps total    82000
Number of rollouts total     0
Train Time (s)               42.072212557308376
(Previous) Eval Time (s)     30.082427410874516
Sample Time (s)              21.673911201301962
Epoch Time (s)               93.82855116948485
Total Train Time (s)         1549.1563392947428
Epoch                        15
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:41:37.515338 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #15 | Epoch Duration: 95.45493793487549
2020-01-11 12:41:37.515579 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #15 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2731892
Z variance train             0.048077628
KL Divergence                13.153128
KL Loss                      1.3153127
QF Loss                      35.558628
VF Loss                      10.831697
Policy Loss                  -201.45845
Q Predictions Mean           198.48401
Q Predictions Std            61.341423
Q Predictions Max            403.41638
Q Predictions Min            132.80156
V Predictions Mean           202.65594
V Predictions Std            60.660152
V Predictions Max            404.85812
V Predictions Min            139.3603
Log Pis Mean                 -2.6592836
Log Pis Std                  1.7516173
Log Pis Max                  3.6335368
Log Pis Min                  -7.4293675
Policy mu Mean               0.019532805
Policy mu Std                0.55550194
Policy mu Max                1.8551294
Policy mu Min                -1.9014325
Policy log std Mean          -0.27483907
Policy log std Std           0.13503657
Policy log std Max           0.25802267
Policy log std Min           -1.0399631
Z mean eval                  1.3069807
Z variance eval              0.046694607
total_rewards                [ 773.98590825 1468.11113766 1625.96768342 1026.68685291  599.08758512
 1206.14656651 1570.48278279 1720.23511779 1612.74556764 1674.72759047]
total_rewards_mean           1327.8176792552258
total_rewards_std            382.915745431692
total_rewards_max            1720.2351177919156
total_rewards_min            599.0875851234638
Number of train steps total  17000
Number of env steps total    87000
Number of rollouts total     0
Train Time (s)               42.10780535824597
(Previous) Eval Time (s)     31.708558866288513
Sample Time (s)              19.872026523109525
Epoch Time (s)               93.68839074764401
Total Train Time (s)         1643.8396025388502
Epoch                        16
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:43:12.199247 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #16 | Epoch Duration: 94.68350601196289
2020-01-11 12:43:12.199431 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #16 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3068507
Z variance train             0.046612017
KL Divergence                13.563445
KL Loss                      1.3563446
QF Loss                      40.374428
VF Loss                      14.575862
Policy Loss                  -226.86494
Q Predictions Mean           222.65259
Q Predictions Std            76.50847
Q Predictions Max            415.65952
Q Predictions Min            129.33469
V Predictions Mean           227.1358
V Predictions Std            76.51096
V Predictions Max            434.5397
V Predictions Min            140.02516
Log Pis Mean                 -2.6116195
Log Pis Std                  1.9291317
Log Pis Max                  3.6538892
Log Pis Min                  -12.030105
Policy mu Mean               0.036597036
Policy mu Std                0.5841259
Policy mu Max                1.8888711
Policy mu Min                -1.9460658
Policy log std Mean          -0.28591633
Policy log std Std           0.13215803
Policy log std Max           0.14121822
Policy log std Min           -0.98576915
Z mean eval                  1.3331821
Z variance eval              0.039041124
total_rewards                [1916.57753348  568.78764664 2153.62798758 2154.41305608 1324.13718089
 1864.40850363 1935.04910215 2015.87413857 1157.8693063  2188.10974475]
total_rewards_mean           1727.8854200073554
total_rewards_std            508.57892261105684
total_rewards_max            2188.1097447514467
total_rewards_min            568.7876466359617
Number of train steps total  18000
Number of env steps total    92000
Number of rollouts total     0
Train Time (s)               42.7711774520576
(Previous) Eval Time (s)     32.70342986704782
Sample Time (s)              20.144336157478392
Epoch Time (s)               95.61894347658381
Total Train Time (s)         1736.4320395989344
Epoch                        17
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:44:44.792866 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #17 | Epoch Duration: 92.59329605102539
2020-01-11 12:44:44.793045 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #17 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.332936
Z variance train             0.0389629
KL Divergence                13.933081
KL Loss                      1.393308
QF Loss                      43.115383
VF Loss                      16.060017
Policy Loss                  -235.54831
Q Predictions Mean           231.72572
Q Predictions Std            88.57946
Q Predictions Max            460.36053
Q Predictions Min            146.3666
V Predictions Mean           236.00883
V Predictions Std            88.03071
V Predictions Max            460.78793
V Predictions Min            151.30215
Log Pis Mean                 -2.2603025
Log Pis Std                  2.0039499
Log Pis Max                  4.8563023
Log Pis Min                  -7.2395973
Policy mu Mean               0.06626826
Policy mu Std                0.6166891
Policy mu Max                2.233716
Policy mu Min                -2.0703816
Policy log std Mean          -0.29066566
Policy log std Std           0.14860824
Policy log std Max           -0.0016314387
Policy log std Min           -1.0322715
Z mean eval                  1.3701439
Z variance eval              0.033238254
total_rewards                [2354.28111817 2418.19780421 2311.8338507  2306.85915677 2319.28661064
  464.01333167 1212.98903057 2338.30813367 1430.45423874 2453.95206225]
total_rewards_mean           1961.0175337389578
total_rewards_std            648.2363437245234
total_rewards_max            2453.952062252085
total_rewards_min            464.0133316651063
Number of train steps total  19000
Number of env steps total    97000
Number of rollouts total     0
Train Time (s)               42.39368833322078
(Previous) Eval Time (s)     29.677535419818014
Sample Time (s)              20.067608659621328
Epoch Time (s)               92.13883241266012
Total Train Time (s)         1831.766337290872
Epoch                        18
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:46:20.126970 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #18 | Epoch Duration: 95.3337950706482
2020-01-11 12:46:20.127106 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #18 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3713998
Z variance train             0.033314634
KL Divergence                14.355921
KL Loss                      1.435592
QF Loss                      55.852654
VF Loss                      17.857512
Policy Loss                  -270.89783
Q Predictions Mean           266.40155
Q Predictions Std            100.397446
Q Predictions Max            508.59058
Q Predictions Min            163.2699
V Predictions Mean           269.35526
V Predictions Std            98.74502
V Predictions Max            497.2213
V Predictions Min            168.31602
Log Pis Mean                 -2.082341
Log Pis Std                  2.2511666
Log Pis Max                  8.544183
Log Pis Min                  -10.9767475
Policy mu Mean               0.05093154
Policy mu Std                0.69079363
Policy mu Max                2.0510473
Policy mu Min                -2.2593732
Policy log std Mean          -0.3302134
Policy log std Std           0.16345575
Policy log std Max           -0.06507003
Policy log std Min           -1.0522617
Z mean eval                  1.3988658
Z variance eval              0.03226484
total_rewards                [2427.89417958 2679.52528575 2501.96232065 2585.09543706 2464.11082209
 2612.2745451  2584.22805677 2494.07545404 2605.67878791 2546.20251824]
total_rewards_mean           2550.104740719544
total_rewards_std            73.41291610919005
total_rewards_max            2679.525285753112
total_rewards_min            2427.89417957559
Number of train steps total  20000
Number of env steps total    102000
Number of rollouts total     0
Train Time (s)               42.947358006145805
(Previous) Eval Time (s)     32.87226929701865
Sample Time (s)              21.883602315559983
Epoch Time (s)               97.70322961872444
Total Train Time (s)         1929.3250639033504
Epoch                        19
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:47:57.688885 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #19 | Epoch Duration: 97.56160640716553
2020-01-11 12:47:57.689128 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #19 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3969795
Z variance train             0.032188494
KL Divergence                14.978494
KL Loss                      1.4978493
QF Loss                      44.22353
VF Loss                      19.815252
Policy Loss                  -280.6172
Q Predictions Mean           277.75757
Q Predictions Std            112.606766
Q Predictions Max            544.99835
Q Predictions Min            168.76175
V Predictions Mean           282.16754
V Predictions Std            113.47301
V Predictions Max            550.1002
V Predictions Min            174.89703
Log Pis Mean                 -1.9954413
Log Pis Std                  2.300026
Log Pis Max                  7.138862
Log Pis Min                  -7.584649
Policy mu Mean               0.066559315
Policy mu Std                0.6698342
Policy mu Max                2.2319143
Policy mu Min                -2.302606
Policy log std Mean          -0.330361
Policy log std Std           0.15515842
Policy log std Max           0.016320847
Policy log std Min           -1.0694513
Z mean eval                  1.4407095
Z variance eval              0.030914783
total_rewards                [2227.68912838 2090.81784224 2750.57789446 2764.41643719 2857.96789534
  981.01837828 2512.47921353 2889.58863    2922.95018308 2483.42228042]
total_rewards_mean           2448.0927882913397
total_rewards_std            558.022211652051
total_rewards_max            2922.950183076543
total_rewards_min            981.0183782805298
Number of train steps total  21000
Number of env steps total    107000
Number of rollouts total     0
Train Time (s)               42.49451812496409
(Previous) Eval Time (s)     32.73039839696139
Sample Time (s)              22.784715045709163
Epoch Time (s)               98.00963156763464
Total Train Time (s)         2027.3100720141083
Epoch                        20
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:49:35.673179 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #20 | Epoch Duration: 97.98391056060791
2020-01-11 12:49:35.673309 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #20 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4402459
Z variance train             0.030920345
KL Divergence                14.740303
KL Loss                      1.4740304
QF Loss                      77.01211
VF Loss                      20.950796
Policy Loss                  -322.4619
Q Predictions Mean           318.2886
Q Predictions Std            139.3641
Q Predictions Max            647.6665
Q Predictions Min            176.54297
V Predictions Mean           322.44772
V Predictions Std            139.29616
V Predictions Max            646.75684
V Predictions Min            181.09706
Log Pis Mean                 -1.5741367
Log Pis Std                  2.6301477
Log Pis Max                  8.580648
Log Pis Min                  -8.004488
Policy mu Mean               0.09951649
Policy mu Std                0.7310671
Policy mu Max                2.190695
Policy mu Min                -2.363791
Policy log std Mean          -0.35569277
Policy log std Std           0.16852129
Policy log std Max           -0.03988194
Policy log std Min           -1.3093686
Z mean eval                  1.4337538
Z variance eval              0.051154934
total_rewards                [2577.2221641  2597.38865375 2127.21964426 2553.29701086 2635.98652576
 1748.97087775 2660.2779425  2488.03899832 2649.54099843 2595.43411576]
total_rewards_mean           2463.337693146589
total_rewards_std            279.93779180341136
total_rewards_max            2660.27794249936
total_rewards_min            1748.9708777451065
Number of train steps total  22000
Number of env steps total    112000
Number of rollouts total     0
Train Time (s)               43.114227146841586
(Previous) Eval Time (s)     32.70444031525403
Sample Time (s)              22.011008651927114
Epoch Time (s)               97.82967611402273
Total Train Time (s)         2124.8140120147727
Epoch                        21
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:51:13.181889 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #21 | Epoch Duration: 97.5084342956543
2020-01-11 12:51:13.182177 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #21 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4348826
Z variance train             0.051005304
KL Divergence                13.688628
KL Loss                      1.3688629
QF Loss                      80.68423
VF Loss                      23.173033
Policy Loss                  -346.53867
Q Predictions Mean           343.6209
Q Predictions Std            150.69302
Q Predictions Max            640.82043
Q Predictions Min            177.68805
V Predictions Mean           346.72223
V Predictions Std            150.42761
V Predictions Max            636.2412
V Predictions Min            177.81708
Log Pis Mean                 -1.4201126
Log Pis Std                  2.5483716
Log Pis Max                  6.6180053
Log Pis Min                  -8.258106
Policy mu Mean               0.10870341
Policy mu Std                0.7253248
Policy mu Max                2.325253
Policy mu Min                -2.2543678
Policy log std Mean          -0.371331
Policy log std Std           0.17255661
Policy log std Max           -0.09147741
Policy log std Min           -1.2143077
Z mean eval                  1.4746153
Z variance eval              0.042634986
total_rewards                [2845.80362884 2893.33617203 2899.1189105  2895.43166859 2949.7832196
 2880.10551696 2951.32339746 2936.93438651 2865.95674059 2823.22069397]
total_rewards_mean           2894.10143350612
total_rewards_std            40.7207233987449
total_rewards_max            2951.3233974609852
total_rewards_min            2823.220693973689
Number of train steps total  23000
Number of env steps total    117000
Number of rollouts total     0
Train Time (s)               43.09139126073569
(Previous) Eval Time (s)     32.3829345991835
Sample Time (s)              21.354831613134593
Epoch Time (s)               96.82915747305378
Total Train Time (s)         2220.6476048659533
Epoch                        22
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:52:49.012852 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #22 | Epoch Duration: 95.83047795295715
2020-01-11 12:52:49.012991 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #22 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4750243
Z variance train             0.042638432
KL Divergence                14.42005
KL Loss                      1.442005
QF Loss                      65.07955
VF Loss                      16.579695
Policy Loss                  -370.32285
Q Predictions Mean           364.97375
Q Predictions Std            169.06178
Q Predictions Max            703.5051
Q Predictions Min            185.68782
V Predictions Mean           368.95444
V Predictions Std            168.06778
V Predictions Max            698.9242
V Predictions Min            190.25488
Log Pis Mean                 -1.2532831
Log Pis Std                  2.495862
Log Pis Max                  5.549727
Log Pis Min                  -7.4365654
Policy mu Mean               0.1073413
Policy mu Std                0.75832653
Policy mu Max                2.0711715
Policy mu Min                -2.3818464
Policy log std Mean          -0.3846419
Policy log std Std           0.18187062
Policy log std Max           -0.08167314
Policy log std Min           -1.2568288
Z mean eval                  1.5220845
Z variance eval              0.03439974
total_rewards                [3068.92902256 2874.85444534 1104.89537187 3213.44738972 2918.40894962
 3104.08341211 2908.92818147 2960.87581186 1787.12983927 2825.92342263]
total_rewards_mean           2676.747584645047
total_rewards_std            643.5172597062459
total_rewards_max            3213.4473897206167
total_rewards_min            1104.895371869934
Number of train steps total  24000
Number of env steps total    122000
Number of rollouts total     0
Train Time (s)               42.9812594843097
(Previous) Eval Time (s)     31.38402487291023
Sample Time (s)              21.683006569277495
Epoch Time (s)               96.04829092649743
Total Train Time (s)         2317.3493792139925
Epoch                        23
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:54:25.716570 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #23 | Epoch Duration: 96.70348477363586
2020-01-11 12:54:25.716695 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #23 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5214757
Z variance train             0.034399014
KL Divergence                15.356363
KL Loss                      1.5356363
QF Loss                      86.39348
VF Loss                      17.51632
Policy Loss                  -407.3951
Q Predictions Mean           402.9383
Q Predictions Std            187.25491
Q Predictions Max            744.6842
Q Predictions Min            195.15234
V Predictions Mean           407.96094
V Predictions Std            186.45229
V Predictions Max            746.0808
V Predictions Min            203.17554
Log Pis Mean                 -1.3011489
Log Pis Std                  2.6717217
Log Pis Max                  8.488476
Log Pis Min                  -6.4356136
Policy mu Mean               0.095635585
Policy mu Std                0.7832526
Policy mu Max                3.028858
Policy mu Min                -2.4715254
Policy log std Mean          -0.39920008
Policy log std Std           0.18112087
Policy log std Max           -0.1036234
Policy log std Min           -1.2012184
Z mean eval                  1.5422484
Z variance eval              0.036072426
total_rewards                [3102.68658939 3100.47625311 3219.32227599 3022.94718176  687.5122642
 3146.86598966 3191.29314703 3168.8034992  3241.44862427 3052.05708953]
total_rewards_mean           2893.341291412474
total_rewards_std            738.2934552829313
total_rewards_max            3241.448624271655
total_rewards_min            687.5122641955594
Number of train steps total  25000
Number of env steps total    127000
Number of rollouts total     0
Train Time (s)               43.293173434212804
(Previous) Eval Time (s)     32.03896441170946
Sample Time (s)              21.43511241907254
Epoch Time (s)               96.7672502649948
Total Train Time (s)         2414.1288167624734
Epoch                        24
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:56:02.500429 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #24 | Epoch Duration: 96.78362512588501
2020-01-11 12:56:02.500602 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #24 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5442002
Z variance train             0.03611075
KL Divergence                15.63897
KL Loss                      1.563897
QF Loss                      115.99391
VF Loss                      21.889174
Policy Loss                  -426.1147
Q Predictions Mean           424.17957
Q Predictions Std            201.89757
Q Predictions Max            814.08746
Q Predictions Min            210.66583
V Predictions Mean           426.34274
V Predictions Std            198.69307
V Predictions Max            815.8374
V Predictions Min            213.97511
Log Pis Mean                 -1.1354558
Log Pis Std                  2.8598182
Log Pis Max                  7.474073
Log Pis Min                  -6.1769667
Policy mu Mean               0.07859081
Policy mu Std                0.7893187
Policy mu Max                2.2749133
Policy mu Min                -2.2572641
Policy log std Mean          -0.39531025
Policy log std Std           0.19104998
Policy log std Max           -0.119996905
Policy log std Min           -1.4175198
Z mean eval                  1.5877932
Z variance eval              0.030448034
total_rewards                [3046.45643943 3145.29303524 3023.7012785  3112.28882408 3204.08908387
 3216.00807392 3012.61119801 3106.68700723 3030.18903549 3093.6330734 ]
total_rewards_mean           3099.095704915676
total_rewards_std            69.11638186440432
total_rewards_max            3216.0080739218242
total_rewards_min            3012.6111980063947
Number of train steps total  26000
Number of env steps total    132000
Number of rollouts total     0
Train Time (s)               42.20840078499168
(Previous) Eval Time (s)     32.05512595595792
Sample Time (s)              20.991761366836727
Epoch Time (s)               95.25528810778633
Total Train Time (s)         2505.9166415324435
Epoch                        25
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:57:34.287362 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #25 | Epoch Duration: 91.78662061691284
2020-01-11 12:57:34.287542 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #25 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5879084
Z variance train             0.030477792
KL Divergence                16.222404
KL Loss                      1.6222404
QF Loss                      102.902374
VF Loss                      29.149105
Policy Loss                  -462.8815
Q Predictions Mean           458.9621
Q Predictions Std            218.92155
Q Predictions Max            867.1898
Q Predictions Min            217.17345
V Predictions Mean           463.86685
V Predictions Std            219.13406
V Predictions Max            878.8083
V Predictions Min            220.54941
Log Pis Mean                 -1.122361
Log Pis Std                  2.573708
Log Pis Max                  7.2253137
Log Pis Min                  -6.745794
Policy mu Mean               -0.025069773
Policy mu Std                0.7971674
Policy mu Max                2.46408
Policy mu Min                -2.0529642
Policy log std Mean          -0.39240864
Policy log std Std           0.18601194
Policy log std Max           -0.070201725
Policy log std Min           -1.3447236
Z mean eval                  1.6264435
Z variance eval              0.023386572
total_rewards                [3423.94336701 3450.98343749 3398.96464205 3413.67293179 1679.80257134
 3390.73134695 3332.47804895 3420.84052158 3412.34547239 3244.35056325]
total_rewards_mean           3216.81129027973
total_rewards_std            515.3947403335997
total_rewards_max            3450.9834374937227
total_rewards_min            1679.802571336076
Number of train steps total  27000
Number of env steps total    137000
Number of rollouts total     0
Train Time (s)               42.16971834609285
(Previous) Eval Time (s)     28.586221844423562
Sample Time (s)              21.54930498590693
Epoch Time (s)               92.30524517642334
Total Train Time (s)         2601.143303928897
Epoch                        26
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:59:09.519063 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #26 | Epoch Duration: 95.23125004768372
2020-01-11 12:59:09.519492 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #26 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6261961
Z variance train             0.023336252
KL Divergence                17.209616
KL Loss                      1.7209616
QF Loss                      123.18682
VF Loss                      30.016088
Policy Loss                  -480.05936
Q Predictions Mean           472.97424
Q Predictions Std            237.87042
Q Predictions Max            882.9557
Q Predictions Min            223.6351
V Predictions Mean           481.00937
V Predictions Std            238.36607
V Predictions Max            880.4326
V Predictions Min            229.16469
Log Pis Mean                 -1.3092086
Log Pis Std                  2.5801399
Log Pis Max                  8.371778
Log Pis Min                  -6.103297
Policy mu Mean               0.052476365
Policy mu Std                0.7680616
Policy mu Max                2.415873
Policy mu Min                -2.2790542
Policy log std Mean          -0.38445655
Policy log std Std           0.18576057
Policy log std Max           -0.10632616
Policy log std Min           -1.3433657
Z mean eval                  1.6467371
Z variance eval              0.022244427
total_rewards                [3611.66325525 3539.06703021 3417.41692221 3474.74268673 3609.53298141
 3507.80599486 3754.72299195 3434.27222788 3566.29256822 3547.01023981]
total_rewards_mean           3546.2526898516817
total_rewards_std            93.76924673088803
total_rewards_max            3754.7229919526653
total_rewards_min            3417.416922206335
Number of train steps total  28000
Number of env steps total    142000
Number of rollouts total     0
Train Time (s)               42.527222691103816
(Previous) Eval Time (s)     31.511936719994992
Sample Time (s)              19.917980534490198
Epoch Time (s)               93.957139945589
Total Train Time (s)         2695.9869467737153
Epoch                        27
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:00:44.360772 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #27 | Epoch Duration: 94.84103059768677
2020-01-11 13:00:44.360918 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #27 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6473491
Z variance train             0.022244647
KL Divergence                17.757713
KL Loss                      1.7757714
QF Loss                      137.49762
VF Loss                      29.620857
Policy Loss                  -560.29047
Q Predictions Mean           554.1667
Q Predictions Std            245.90453
Q Predictions Max            955.2624
Q Predictions Min            224.00615
V Predictions Mean           561.72125
V Predictions Std            245.51239
V Predictions Max            960.3256
V Predictions Min            230.49055
Log Pis Mean                 -0.29365793
Log Pis Std                  3.167773
Log Pis Max                  9.017248
Log Pis Min                  -6.825396
Policy mu Mean               0.16897821
Policy mu Std                0.8810352
Policy mu Max                2.4743404
Policy mu Min                -2.6210074
Policy log std Mean          -0.46411452
Policy log std Std           0.22301826
Policy log std Max           -0.081804045
Policy log std Min           -1.4099196
Z mean eval                  1.6581113
Z variance eval              0.02714703
total_rewards                [3625.93309588 3449.09692828 3628.96990868 3674.94677924 3683.73298121
 3608.60484683 3508.48010231 3536.91431339 3546.88356542 3470.58652697]
total_rewards_mean           3573.4149048204176
total_rewards_std            78.640332317214
total_rewards_max            3683.7329812077005
total_rewards_min            3449.0969282761625
Number of train steps total  29000
Number of env steps total    147000
Number of rollouts total     0
Train Time (s)               42.31541578704491
(Previous) Eval Time (s)     32.3956492850557
Sample Time (s)              21.46703255129978
Epoch Time (s)               96.17809762340039
Total Train Time (s)         2791.8865153039806
Epoch                        28
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:02:20.261646 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #28 | Epoch Duration: 95.90057134628296
2020-01-11 13:02:20.261841 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #28 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6575752
Z variance train             0.027196934
KL Divergence                17.45718
KL Loss                      1.745718
QF Loss                      159.87155
VF Loss                      30.11134
Policy Loss                  -577.23224
Q Predictions Mean           572.5016
Q Predictions Std            262.8892
Q Predictions Max            986.64374
Q Predictions Min            228.02573
V Predictions Mean           575.4907
V Predictions Std            260.7483
V Predictions Max            989.2197
V Predictions Min            231.86612
Log Pis Mean                 -0.24156313
Log Pis Std                  3.3678453
Log Pis Max                  9.481196
Log Pis Min                  -6.5673943
Policy mu Mean               0.14427069
Policy mu Std                0.9240663
Policy mu Max                3.1558218
Policy mu Min                -2.400493
Policy log std Mean          -0.45407328
Policy log std Std           0.22298846
Policy log std Max           -0.06876079
Policy log std Min           -1.5007874
Z mean eval                  1.6772344
Z variance eval              0.030634668
total_rewards                [3946.92814518 3679.38992324 3952.80315624 3775.25970158 3713.42669026
 3832.92652702 3847.59403404 3679.94408416 3883.63085213 3806.02637528]
total_rewards_mean           3811.792948913736
total_rewards_std            95.39023362771717
total_rewards_max            3952.803156240816
total_rewards_min            3679.3899232424988
Number of train steps total  30000
Number of env steps total    152000
Number of rollouts total     0
Train Time (s)               42.44721477571875
(Previous) Eval Time (s)     32.117874330841005
Sample Time (s)              21.49486838746816
Epoch Time (s)               96.05995749402791
Total Train Time (s)         2886.4317364036106
Epoch                        29
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:03:54.806501 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #29 | Epoch Duration: 94.5445499420166
2020-01-11 13:03:54.806627 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #29 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6758677
Z variance train             0.030652165
KL Divergence                18.109795
KL Loss                      1.8109795
QF Loss                      122.54306
VF Loss                      57.039158
Policy Loss                  -589.9078
Q Predictions Mean           590.3627
Q Predictions Std            291.64346
Q Predictions Max            1052.1368
Q Predictions Min            237.9438
V Predictions Mean           594.5376
V Predictions Std            288.14334
V Predictions Max            1043.5312
V Predictions Min            242.38663
Log Pis Mean                 -0.18591428
Log Pis Std                  3.4023447
Log Pis Max                  11.095757
Log Pis Min                  -7.090241
Policy mu Mean               0.07597696
Policy mu Std                0.8923723
Policy mu Max                2.4517636
Policy mu Min                -2.8139453
Policy log std Mean          -0.42308435
Policy log std Std           0.21284893
Policy log std Max           -0.05305621
Policy log std Min           -1.4591577
Z mean eval                  1.70501
Z variance eval              0.030382406
total_rewards                [3710.31168588 3837.92783062 3794.31602835 3939.13380361 1264.83082036
 3972.41733441 3912.9336196  3829.75607714 3970.22500915 3687.36148661]
total_rewards_mean           3591.9213695720273
total_rewards_std            781.538213658533
total_rewards_max            3972.4173344120554
total_rewards_min            1264.8308203556874
Number of train steps total  31000
Number of env steps total    157000
Number of rollouts total     0
Train Time (s)               43.83397172112018
(Previous) Eval Time (s)     30.60223420104012
Sample Time (s)              21.506750700529665
Epoch Time (s)               95.94295662268996
Total Train Time (s)         2983.4585837787017
Epoch                        30
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:05:31.837710 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #30 | Epoch Duration: 97.03098630905151
2020-01-11 13:05:31.837838 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #30 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.70429
Z variance train             0.030391488
KL Divergence                18.316103
KL Loss                      1.8316103
QF Loss                      150.75728
VF Loss                      35.64144
Policy Loss                  -600.43634
Q Predictions Mean           596.3391
Q Predictions Std            303.25516
Q Predictions Max            1102.1014
Q Predictions Min            232.03543
V Predictions Mean           598.9276
V Predictions Std            299.45108
V Predictions Max            1086.6866
V Predictions Min            236.6767
Log Pis Mean                 -0.62261677
Log Pis Std                  3.2029912
Log Pis Max                  8.347695
Log Pis Min                  -8.025433
Policy mu Mean               0.056232136
Policy mu Std                0.86135644
Policy mu Max                2.320281
Policy mu Min                -2.3070376
Policy log std Mean          -0.43735743
Policy log std Std           0.22598304
Policy log std Max           -0.07654556
Policy log std Min           -1.642095
Z mean eval                  1.7227081
Z variance eval              0.02600883
total_rewards                [3911.60691777 3867.8612136  3896.18373867 3998.64414795 4028.08441913
 3885.98183657 3869.35713857 3974.07172404 4092.42388191 4035.68194874]
total_rewards_mean           3955.9896966940514
total_rewards_std            76.176549330897
total_rewards_max            4092.4238819134353
total_rewards_min            3867.8612135981034
Number of train steps total  32000
Number of env steps total    162000
Number of rollouts total     0
Train Time (s)               43.76305831409991
(Previous) Eval Time (s)     31.689995681867003
Sample Time (s)              21.660417574923486
Epoch Time (s)               97.1134715708904
Total Train Time (s)         3078.651874409057
Epoch                        31
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:07:07.031406 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #31 | Epoch Duration: 95.19345712661743
2020-01-11 13:07:07.031587 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #31 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7236696
Z variance train             0.025973987
KL Divergence                18.948772
KL Loss                      1.8948773
QF Loss                      138.42473
VF Loss                      50.495758
Policy Loss                  -705.56854
Q Predictions Mean           701.58203
Q Predictions Std            320.22345
Q Predictions Max            1192.1971
Q Predictions Min            245.64796
V Predictions Mean           703.2892
V Predictions Std            316.1158
V Predictions Max            1179.1351
V Predictions Min            254.56488
Log Pis Mean                 0.21200214
Log Pis Std                  3.2604585
Log Pis Max                  12.618551
Log Pis Min                  -6.9899282
Policy mu Mean               0.01760473
Policy mu Std                0.94023377
Policy mu Max                2.8478248
Policy mu Min                -2.370255
Policy log std Mean          -0.47180378
Policy log std Std           0.23501635
Policy log std Max           -0.045796543
Policy log std Min           -1.5181723
Z mean eval                  1.761437
Z variance eval              0.024826769
total_rewards                [3997.20837802 4058.01024451 3946.18910031 4033.75966836 4079.07090757
 4176.36620998 4013.27251139 4158.60600998 4083.89637642 3996.80479251]
total_rewards_mean           4054.318419905404
total_rewards_std            69.02281367730966
total_rewards_max            4176.366209982842
total_rewards_min            3946.1891003098517
Number of train steps total  33000
Number of env steps total    167000
Number of rollouts total     0
Train Time (s)               43.45320475520566
(Previous) Eval Time (s)     29.76971656223759
Sample Time (s)              21.108813083730638
Epoch Time (s)               94.33173440117389
Total Train Time (s)         3175.17664096551
Epoch                        32
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:08:43.557521 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #32 | Epoch Duration: 96.52573537826538
2020-01-11 13:08:43.557779 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #32 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7603706
Z variance train             0.024814371
KL Divergence                19.653616
KL Loss                      1.9653616
QF Loss                      152.53018
VF Loss                      39.55108
Policy Loss                  -710.3494
Q Predictions Mean           709.30383
Q Predictions Std            338.89688
Q Predictions Max            1215.605
Q Predictions Min            257.50848
V Predictions Mean           713.64136
V Predictions Std            335.77423
V Predictions Max            1212.1195
V Predictions Min            262.20078
Log Pis Mean                 0.078160554
Log Pis Std                  3.2945733
Log Pis Max                  10.038805
Log Pis Min                  -7.2271013
Policy mu Mean               0.054890815
Policy mu Std                0.9362431
Policy mu Max                2.5031528
Policy mu Min                -2.1412113
Policy log std Mean          -0.46457693
Policy log std Std           0.23096186
Policy log std Max           -0.060051404
Policy log std Min           -1.5508921
Z mean eval                  1.763665
Z variance eval              0.026596207
total_rewards                [4029.51356759 4111.12098674 4074.43708371 3956.59466184 3794.56929378
 3855.62681448 4270.30193264 4087.09765866 3885.90078721 4035.68243773]
total_rewards_mean           4010.0845224388904
total_rewards_std            133.27161988186495
total_rewards_max            4270.301932640566
total_rewards_min            3794.5692937794715
Number of train steps total  34000
Number of env steps total    172000
Number of rollouts total     0
Train Time (s)               43.260340380016714
(Previous) Eval Time (s)     31.963442329782993
Sample Time (s)              21.72004848672077
Epoch Time (s)               96.94383119652048
Total Train Time (s)         3272.5101396888494
Epoch                        33
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:10:20.892399 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #33 | Epoch Duration: 97.33446168899536
2020-01-11 13:10:20.892585 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #33 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7627236
Z variance train             0.026588555
KL Divergence                19.24765
KL Loss                      1.924765
QF Loss                      211.40443
VF Loss                      44.433987
Policy Loss                  -770.23566
Q Predictions Mean           768.1849
Q Predictions Std            339.6553
Q Predictions Max            1240.3774
Q Predictions Min            252.86581
V Predictions Mean           771.69226
V Predictions Std            337.0856
V Predictions Max            1218.7611
V Predictions Min            256.75513
Log Pis Mean                 0.5810482
Log Pis Std                  3.5844746
Log Pis Max                  10.855139
Log Pis Min                  -5.8510513
Policy mu Mean               0.015143187
Policy mu Std                0.98229116
Policy mu Max                2.6882925
Policy mu Min                -3.0781655
Policy log std Mean          -0.4938961
Policy log std Std           0.24346676
Policy log std Max           -0.10703277
Policy log std Min           -1.793875
Z mean eval                  1.7625809
Z variance eval              0.03201181
total_rewards                [4362.34411473 4091.48663088 4197.18655178 4226.57998139 4043.24074053
 4178.69396481 4064.21123995 4185.65013362 4208.43294407 4216.94757443]
total_rewards_mean           4177.477387617948
total_rewards_std            88.20586516367179
total_rewards_max            4362.344114727202
total_rewards_min            4043.240740528118
Number of train steps total  35000
Number of env steps total    177000
Number of rollouts total     0
Train Time (s)               41.82646150980145
(Previous) Eval Time (s)     32.353807064238936
Sample Time (s)              20.06849890667945
Epoch Time (s)               94.24876748071983
Total Train Time (s)         3366.258900405839
Epoch                        34
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:11:54.641617 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #34 | Epoch Duration: 93.74889802932739
2020-01-11 13:11:54.641760 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #34 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.76393
Z variance train             0.03211578
KL Divergence                18.732975
KL Loss                      1.8732976
QF Loss                      130.6392
VF Loss                      45.200127
Policy Loss                  -767.8724
Q Predictions Mean           758.98035
Q Predictions Std            356.0424
Q Predictions Max            1246.1046
Q Predictions Min            261.94604
V Predictions Mean           767.92694
V Predictions Std            355.11023
V Predictions Max            1246.8025
V Predictions Min            272.32123
Log Pis Mean                 0.0857845
Log Pis Std                  3.5025406
Log Pis Max                  12.109724
Log Pis Min                  -6.4053335
Policy mu Mean               0.072730206
Policy mu Std                0.9476609
Policy mu Max                2.3968682
Policy mu Min                -2.3062422
Policy log std Mean          -0.48189226
Policy log std Std           0.24552834
Policy log std Max           -0.02354765
Policy log std Min           -1.8787483
Z mean eval                  1.7914375
Z variance eval              0.027954247
total_rewards                [4264.11938824 4338.8948006  4267.35439648 4417.75297312 4406.73412138
 4289.02527991 4156.55457093 4334.02115857 4189.07231036 4317.41727431]
total_rewards_mean           4298.094627388478
total_rewards_std            79.71849142375869
total_rewards_max            4417.752973120028
total_rewards_min            4156.554570926937
Number of train steps total  36000
Number of env steps total    182000
Number of rollouts total     0
Train Time (s)               44.266317484900355
(Previous) Eval Time (s)     31.85366951394826
Sample Time (s)              21.329572279006243
Epoch Time (s)               97.44955927785486
Total Train Time (s)         3463.903490829747
Epoch                        35
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:13:32.286860 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #35 | Epoch Duration: 97.64494276046753
2020-01-11 13:13:32.287049 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #35 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.792774
Z variance train             0.027984345
KL Divergence                19.109781
KL Loss                      1.9109782
QF Loss                      186.15009
VF Loss                      68.417694
Policy Loss                  -782.692
Q Predictions Mean           778.2642
Q Predictions Std            373.88458
Q Predictions Max            1329.1456
Q Predictions Min            255.30331
V Predictions Mean           778.00085
V Predictions Std            372.1411
V Predictions Max            1317.0128
V Predictions Min            259.64163
Log Pis Mean                 0.8567048
Log Pis Std                  4.0499516
Log Pis Max                  11.966231
Log Pis Min                  -7.833919
Policy mu Mean               0.042244542
Policy mu Std                1.014811
Policy mu Max                2.5400286
Policy mu Min                -2.8833814
Policy log std Mean          -0.49927464
Policy log std Std           0.2561925
Policy log std Max           -0.0281557
Policy log std Min           -1.9259164
Z mean eval                  1.792972
Z variance eval              0.034658805
total_rewards                [4477.94622984 4341.04454965 4262.71482407 4438.40452072 4369.84114135
 4331.07488011 4407.51339641 4609.72283156 4410.52475098 4188.31188955]
total_rewards_mean           4383.709901424894
total_rewards_std            110.3824198405617
total_rewards_max            4609.722831560889
total_rewards_min            4188.311889547502
Number of train steps total  37000
Number of env steps total    187000
Number of rollouts total     0
Train Time (s)               43.325576439034194
(Previous) Eval Time (s)     32.04880224680528
Sample Time (s)              21.396969705820084
Epoch Time (s)               96.77134839165956
Total Train Time (s)         3559.584328929428
Epoch                        36
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:15:07.971503 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #36 | Epoch Duration: 95.6843113899231
2020-01-11 13:15:07.971708 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #36 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7909782
Z variance train             0.03459408
KL Divergence                19.044308
KL Loss                      1.9044307
QF Loss                      198.32599
VF Loss                      38.240124
Policy Loss                  -855.11005
Q Predictions Mean           849.8803
Q Predictions Std            379.2237
Q Predictions Max            1345.5767
Q Predictions Min            261.06635
V Predictions Mean           853.85425
V Predictions Std            378.29037
V Predictions Max            1347.5538
V Predictions Min            258.81378
Log Pis Mean                 0.52666783
Log Pis Std                  3.3548326
Log Pis Max                  11.139956
Log Pis Min                  -7.7290106
Policy mu Mean               0.025746236
Policy mu Std                0.96954167
Policy mu Max                2.3731723
Policy mu Min                -2.3516304
Policy log std Mean          -0.49954593
Policy log std Std           0.26622272
Policy log std Max           -0.054417476
Policy log std Min           -1.698126
Z mean eval                  1.8462458
Z variance eval              0.01787645
total_rewards                [4201.82680052 4400.68525456 4339.56710068 4188.13837346 4408.60400272
 4356.71408992 4240.52828534 4295.0123606  4194.71355891 4368.09894114]
total_rewards_mean           4299.388876784935
total_rewards_std            82.55066388061809
total_rewards_max            4408.604002720664
total_rewards_min            4188.138373462806
Number of train steps total  38000
Number of env steps total    192000
Number of rollouts total     0
Train Time (s)               43.50834957091138
(Previous) Eval Time (s)     30.96148019609973
Sample Time (s)              21.091371241025627
Epoch Time (s)               95.56120100803673
Total Train Time (s)         3656.5657838168554
Epoch                        37
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:16:44.954639 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #37 | Epoch Duration: 96.98271465301514
2020-01-11 13:16:44.954889 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #37 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8472153
Z variance train             0.01788735
KL Divergence                20.802034
KL Loss                      2.0802035
QF Loss                      322.19202
VF Loss                      85.758896
Policy Loss                  -881.6459
Q Predictions Mean           880.7978
Q Predictions Std            390.57278
Q Predictions Max            1446.9421
Q Predictions Min            270.96408
V Predictions Mean           880.2649
V Predictions Std            389.33936
V Predictions Max            1442.4596
V Predictions Min            261.87442
Log Pis Mean                 0.300747
Log Pis Std                  3.298462
Log Pis Max                  10.336834
Log Pis Min                  -6.6074185
Policy mu Mean               -0.030406967
Policy mu Std                0.97060084
Policy mu Max                2.5133967
Policy mu Min                -2.6227758
Policy log std Mean          -0.48952666
Policy log std Std           0.25298738
Policy log std Max           -0.010105312
Policy log std Min           -1.6307201
Z mean eval                  1.865009
Z variance eval              0.01560286
total_rewards                [4298.57000654 4417.6070239  4155.85532372 4489.00420186 4190.91247359
 4307.06918909 4312.59314719 4071.59734287 4271.48438605 4193.73028597]
total_rewards_mean           4270.842338077934
total_rewards_std            117.56481439648198
total_rewards_max            4489.004201861221
total_rewards_min            4071.5973428666694
Number of train steps total  39000
Number of env steps total    197000
Number of rollouts total     0
Train Time (s)               43.52528098132461
(Previous) Eval Time (s)     32.38273781212047
Sample Time (s)              21.407889638561755
Epoch Time (s)               97.31590843200684
Total Train Time (s)         3752.063366523944
Epoch                        38
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:18:20.452606 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #38 | Epoch Duration: 95.49755501747131
2020-01-11 13:18:20.452793 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #38 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8651285
Z variance train             0.01559487
KL Divergence                21.507
KL Loss                      2.1507
QF Loss                      137.6814
VF Loss                      92.44415
Policy Loss                  -905.0648
Q Predictions Mean           898.81836
Q Predictions Std            419.47894
Q Predictions Max            1464.7845
Q Predictions Min            269.07904
V Predictions Mean           902.75104
V Predictions Std            417.28006
V Predictions Max            1446.949
V Predictions Min            278.17352
Log Pis Mean                 0.55937356
Log Pis Std                  3.6366942
Log Pis Max                  12.339548
Log Pis Min                  -5.5139065
Policy mu Mean               -0.015056311
Policy mu Std                0.9651629
Policy mu Max                2.4770067
Policy mu Min                -2.8489897
Policy log std Mean          -0.48547044
Policy log std Std           0.25118575
Policy log std Max           -0.048802465
Policy log std Min           -1.7813113
Z mean eval                  1.8748318
Z variance eval              0.013171451
total_rewards                [4769.93290827 4580.65852388 4620.76419977 4734.0912128  4486.28702408
 4604.42958398 4633.26529122 4465.13661702 4594.80229352 4591.77123298]
total_rewards_mean           4608.113888751186
total_rewards_std            89.07538491754516
total_rewards_max            4769.932908273719
total_rewards_min            4465.136617023151
Number of train steps total  40000
Number of env steps total    202000
Number of rollouts total     0
Train Time (s)               43.22206576168537
(Previous) Eval Time (s)     30.56412765197456
Sample Time (s)              21.837384913116693
Epoch Time (s)               95.62357832677662
Total Train Time (s)         3847.6009027049877
Epoch                        39
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:19:55.992843 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #39 | Epoch Duration: 95.53987884521484
2020-01-11 13:19:55.993116 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #39 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8745253
Z variance train             0.013175577
KL Divergence                22.213459
KL Loss                      2.221346
QF Loss                      242.82385
VF Loss                      87.23586
Policy Loss                  -925.4173
Q Predictions Mean           916.97534
Q Predictions Std            431.6822
Q Predictions Max            1489.5942
Q Predictions Min            271.84863
V Predictions Mean           922.02734
V Predictions Std            426.43524
V Predictions Max            1471.8368
V Predictions Min            282.47174
Log Pis Mean                 0.659155
Log Pis Std                  3.4385557
Log Pis Max                  11.475911
Log Pis Min                  -6.44726
Policy mu Mean               -0.00047588968
Policy mu Std                1.0198287
Policy mu Max                2.886326
Policy mu Min                -2.631104
Policy log std Mean          -0.5099922
Policy log std Std           0.2723689
Policy log std Max           -0.0995183
Policy log std Min           -1.8496935
Z mean eval                  1.8704599
Z variance eval              0.020186761
total_rewards                [4567.02099442 4510.47073024 4401.00660371 4486.27139078 4544.53997381
 4537.89961207 4512.91248296 4440.4075391  4371.55224293 4534.03404316]
total_rewards_mean           4490.611561317698
total_rewards_std            62.05120076193455
total_rewards_max            4567.020994422799
total_rewards_min            4371.552242933667
Number of train steps total  41000
Number of env steps total    207000
Number of rollouts total     0
Train Time (s)               43.79435905907303
(Previous) Eval Time (s)     30.480160533916205
Sample Time (s)              22.022109216079116
Epoch Time (s)               96.29662880906835
Total Train Time (s)         3946.307220946066
Epoch                        40
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:21:34.698828 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #40 | Epoch Duration: 98.70552706718445
2020-01-11 13:21:34.698968 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #40 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8711998
Z variance train             0.020245332
KL Divergence                21.602934
KL Loss                      2.1602933
QF Loss                      211.41788
VF Loss                      76.311
Policy Loss                  -945.0127
Q Predictions Mean           946.83057
Q Predictions Std            444.9426
Q Predictions Max            1516.571
Q Predictions Min            271.4715
V Predictions Mean           941.0121
V Predictions Std            441.13876
V Predictions Max            1506.7993
V Predictions Min            272.3872
Log Pis Mean                 0.292354
Log Pis Std                  3.5337758
Log Pis Max                  10.584921
Log Pis Min                  -6.563359
Policy mu Mean               0.08018626
Policy mu Std                0.98344374
Policy mu Max                2.758355
Policy mu Min                -2.2926068
Policy log std Mean          -0.4838504
Policy log std Std           0.27592275
Policy log std Max           -0.08923848
Policy log std Min           -1.9567071
Z mean eval                  1.8853958
Z variance eval              0.015078606
total_rewards                [4479.84615043 4609.58956945 4535.77348273 4536.29752029 4508.50038365
 4794.93243288 4679.25697496 4536.24520018 4878.49137144 4697.63079134]
total_rewards_mean           4625.656387734913
total_rewards_std            126.46574543213134
total_rewards_max            4878.491371435974
total_rewards_min            4479.846150430956
Number of train steps total  42000
Number of env steps total    212000
Number of rollouts total     0
Train Time (s)               42.866991941817105
(Previous) Eval Time (s)     32.8888155198656
Sample Time (s)              21.875162133481354
Epoch Time (s)               97.63096959516406
Total Train Time (s)         4043.042207996361
Epoch                        41
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:23:11.435379 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #41 | Epoch Duration: 96.73625421524048
2020-01-11 13:23:11.435569 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #41 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8853323
Z variance train             0.015009066
KL Divergence                22.616392
KL Loss                      2.2616394
QF Loss                      181.07072
VF Loss                      84.155594
Policy Loss                  -956.0091
Q Predictions Mean           950.57465
Q Predictions Std            460.56714
Q Predictions Max            1543.5399
Q Predictions Min            196.46454
V Predictions Mean           953.58264
V Predictions Std            457.92645
V Predictions Max            1544.3177
V Predictions Min            221.9864
Log Pis Mean                 0.3543234
Log Pis Std                  3.6568136
Log Pis Max                  12.143593
Log Pis Min                  -6.925106
Policy mu Mean               0.026537674
Policy mu Std                0.96838295
Policy mu Max                2.7585096
Policy mu Min                -2.6952069
Policy log std Mean          -0.49374
Policy log std Std           0.27509674
Policy log std Max           -0.016464382
Policy log std Min           -1.6403594
Z mean eval                  1.9114069
Z variance eval              0.010052593
total_rewards                [4726.81116392 4788.24418733 4787.60331898 4763.67728311 4784.28641556
 4733.22048907 4848.35815074 4503.92492825 4773.88972308 4685.30300233]
total_rewards_mean           4739.531866238159
total_rewards_std            88.85178491113889
total_rewards_max            4848.358150744882
total_rewards_min            4503.924928253288
Number of train steps total  43000
Number of env steps total    217000
Number of rollouts total     0
Train Time (s)               42.34037375962362
(Previous) Eval Time (s)     31.993841150775552
Sample Time (s)              21.5357922767289
Epoch Time (s)               95.87000718712807
Total Train Time (s)         4139.921473968308
Epoch                        42
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:24:48.315351 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #42 | Epoch Duration: 96.87965893745422
2020-01-11 13:24:48.315532 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #42 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.912514
Z variance train             0.01004279
KL Divergence                23.79985
KL Loss                      2.379985
QF Loss                      274.67453
VF Loss                      116.109764
Policy Loss                  -1028.4525
Q Predictions Mean           1030.912
Q Predictions Std            453.84097
Q Predictions Max            1603.6067
Q Predictions Min            277.5246
V Predictions Mean           1032.0232
V Predictions Std            450.2161
V Predictions Max            1613.3221
V Predictions Min            286.79727
Log Pis Mean                 0.6879817
Log Pis Std                  3.6948128
Log Pis Max                  11.301444
Log Pis Min                  -7.237737
Policy mu Mean               0.025068423
Policy mu Std                1.0350338
Policy mu Max                3.0605705
Policy mu Min                -2.7941632
Policy log std Mean          -0.5078104
Policy log std Std           0.27949294
Policy log std Max           -0.03891574
Policy log std Min           -1.954822
Z mean eval                  1.8949807
Z variance eval              0.0133387325
total_rewards                [4778.17486993 4981.0149229  4927.6604487  4694.11266093 4963.21260248
 5093.6399771  4811.35074979 4882.76054644 5016.56796097 4883.7071148 ]
total_rewards_mean           4903.220185405264
total_rewards_std            113.11829680587303
total_rewards_max            5093.63997710216
total_rewards_min            4694.1126609255025
Number of train steps total  44000
Number of env steps total    222000
Number of rollouts total     0
Train Time (s)               42.64674807572737
(Previous) Eval Time (s)     33.00324227614328
Sample Time (s)              21.83800086705014
Epoch Time (s)               97.4879912189208
Total Train Time (s)         4238.371556752827
Epoch                        43
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:26:26.766025 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #43 | Epoch Duration: 98.45036292076111
2020-01-11 13:26:26.766160 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #43 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8948425
Z variance train             0.0133519
KL Divergence                23.205814
KL Loss                      2.3205814
QF Loss                      199.22879
VF Loss                      81.07489
Policy Loss                  -1090.3064
Q Predictions Mean           1088.9043
Q Predictions Std            460.66116
Q Predictions Max            1648.0137
Q Predictions Min            279.9093
V Predictions Mean           1091.4546
V Predictions Std            458.32193
V Predictions Max            1664.7235
V Predictions Min            283.26486
Log Pis Mean                 1.1016394
Log Pis Std                  3.794955
Log Pis Max                  10.671128
Log Pis Min                  -6.529024
Policy mu Mean               -0.03347673
Policy mu Std                1.0509853
Policy mu Max                2.9624019
Policy mu Min                -2.556752
Policy log std Mean          -0.53069896
Policy log std Std           0.29415345
Policy log std Max           -0.030977607
Policy log std Min           -2.0328226
Z mean eval                  1.8877357
Z variance eval              0.01387343
total_rewards                [4509.2360483  4708.1623878  4757.57789002 4538.02959373 4747.6359794
 4783.41534067 4768.04894099 4567.82348565 4570.37050892 4767.40539121]
total_rewards_mean           4671.770556668182
total_rewards_std            105.22072404782914
total_rewards_max            4783.4153406681735
total_rewards_min            4509.236048297228
Number of train steps total  45000
Number of env steps total    227000
Number of rollouts total     0
Train Time (s)               42.375199652742594
(Previous) Eval Time (s)     33.96535968314856
Sample Time (s)              21.132043573074043
Epoch Time (s)               97.4726029089652
Total Train Time (s)         4334.496799193323
Epoch                        44
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:28:02.896367 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #44 | Epoch Duration: 96.13004970550537
2020-01-11 13:28:02.896639 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #44 | Started Training: True
