---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0007111436
Z variance train             0.69280326
KL Divergence                0.1495356
KL Loss                      0.01495356
QF Loss                      69.50569
VF Loss                      29.639257
Policy Loss                  -5.4038105
Q Predictions Mean           0.0033121614
Q Predictions Std            0.0017587668
Q Predictions Max            0.008227947
Q Predictions Min            -0.0015977039
V Predictions Mean           -0.00029463152
V Predictions Std            0.0020243167
V Predictions Max            0.004122844
V Predictions Min            -0.006428632
Log Pis Mean                 -5.422134
Log Pis Std                  0.6595036
Log Pis Max                  -3.5287657
Log Pis Min                  -7.012924
Policy mu Mean               0.0015601738
Policy mu Std                0.001667595
Policy mu Max                0.0055234022
Policy mu Min                -0.0032934812
Policy log std Mean          0.00043443142
Policy log std Std           0.0017997469
Policy log std Max           0.005979537
Policy log std Min           -0.0037199063
Z mean eval                  0.18768252
Z variance eval              0.14730497
total_rewards                [  14.00028753  -31.55095684 -226.86372544   -3.98702791   53.89787073
  -74.96443857  -12.16322149  -30.99285471   12.30646493  -53.08923595]
total_rewards_mean           -35.34068377127018
total_rewards_std            72.65531124277545
total_rewards_max            53.897870730937704
total_rewards_min            -226.8637254375447
Number of train steps total  1000
Number of env steps total    7000
Number of rollouts total     0
Train Time (s)               30.07871193718165
(Previous) Eval Time (s)     0
Sample Time (s)              22.95115672517568
Epoch Time (s)               53.02986866235733
Total Train Time (s)         57.862271438818425
Epoch                        0
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:16:29.199706 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #0 | Epoch Duration: 57.8650336265564
2020-01-11 03:16:29.199895 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #0 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.18722084
Z variance train             0.14853871
KL Divergence                2.7861366
KL Loss                      0.27861366
QF Loss                      48.19011
VF Loss                      4.1835685
Policy Loss                  -9.512016
Q Predictions Mean           3.6318457
Q Predictions Std            8.760866
Q Predictions Max            29.975864
Q Predictions Min            -23.36469
V Predictions Mean           10.310211
V Predictions Std            8.521749
V Predictions Max            34.14213
V Predictions Min            -13.94922
Log Pis Mean                 -5.2847686
Log Pis Std                  0.5802789
Log Pis Max                  -3.918102
Log Pis Min                  -7.654071
Policy mu Mean               -0.0133898165
Policy mu Std                0.14630279
Policy mu Max                0.44273037
Policy mu Min                -0.55860287
Policy log std Mean          -0.2799964
Policy log std Std           0.029475626
Policy log std Max           -0.19588062
Policy log std Min           -0.41837108
Z mean eval                  0.14425269
Z variance eval              0.03420157
total_rewards                [ 47.96509837  14.07117867 173.66179988  16.13680027  52.80957115
  87.54043317 306.37415648 238.40122172 280.50058111 447.02988885]
total_rewards_mean           166.4490729658226
total_rewards_std            139.833210977617
total_rewards_max            447.0298888459089
total_rewards_min            14.07117867156966
Number of train steps total  2000
Number of env steps total    12000
Number of rollouts total     0
Train Time (s)               29.249305265024304
(Previous) Eval Time (s)     4.8348440788686275
Sample Time (s)              15.75704830000177
Epoch Time (s)               49.8411976438947
Total Train Time (s)         116.66827899916098
Epoch                        1
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:17:28.007307 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #1 | Epoch Duration: 58.80724906921387
2020-01-11 03:17:28.007495 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #1 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.13958915
Z variance train             0.034409728
KL Divergence                6.1003313
KL Loss                      0.61003315
QF Loss                      82.67131
VF Loss                      11.706245
Policy Loss                  -22.653818
Q Predictions Mean           17.357052
Q Predictions Std            15.013961
Q Predictions Max            57.756996
Q Predictions Min            -32.1553
V Predictions Mean           24.27089
V Predictions Std            14.021844
V Predictions Max            62.20539
V Predictions Min            -22.829952
Log Pis Mean                 -3.7396107
Log Pis Std                  1.285501
Log Pis Max                  -0.8504703
Log Pis Min                  -9.2934
Policy mu Mean               0.011537545
Policy mu Std                0.21715458
Policy mu Max                0.6880044
Policy mu Min                -0.74749595
Policy log std Mean          -0.6653442
Policy log std Std           0.106234394
Policy log std Max           -0.34577504
Policy log std Min           -1.0635878
Z mean eval                  0.20194706
Z variance eval              0.019815784
total_rewards                [298.66488095 377.97489911 188.71140318 377.27829558 287.60327572
 358.84028923   8.82174145   3.23773512 289.1894981  327.9222451 ]
total_rewards_mean           251.82442635314933
total_rewards_std            133.63947488151322
total_rewards_max            377.97489910669213
total_rewards_min            3.2377351183449252
Number of train steps total  3000
Number of env steps total    17000
Number of rollouts total     0
Train Time (s)               27.1356070949696
(Previous) Eval Time (s)     13.800593433901668
Sample Time (s)              18.643156186211854
Epoch Time (s)               59.57935671508312
Total Train Time (s)         185.00775074306875
Epoch                        2
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:18:36.347122 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #2 | Epoch Duration: 68.33947658538818
2020-01-11 03:18:36.347303 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #2 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.19896053
Z variance train             0.020200843
KL Divergence                7.5326552
KL Loss                      0.75326556
QF Loss                      112.58616
VF Loss                      12.693346
Policy Loss                  -43.681957
Q Predictions Mean           40.023003
Q Predictions Std            15.565252
Q Predictions Max            73.52837
Q Predictions Min            -27.113647
V Predictions Mean           42.693695
V Predictions Std            14.684568
V Predictions Max            75.33157
V Predictions Min            -23.203854
Log Pis Mean                 -3.0951161
Log Pis Std                  1.4846718
Log Pis Max                  -0.2341809
Log Pis Min                  -7.691781
Policy mu Mean               0.004568341
Policy mu Std                0.21790825
Policy mu Max                0.9716887
Policy mu Min                -0.69259274
Policy log std Mean          -0.7961521
Policy log std Std           0.11852843
Policy log std Max           -0.43446904
Policy log std Min           -1.1741184
Z mean eval                  0.21762693
Z variance eval              0.013804589
total_rewards                [214.6942854  210.90843858 276.89681978 236.76517041 179.246178
 204.07881529   7.22038409 235.86616231  58.24339253 200.87165342]
total_rewards_mean           182.4791299818242
total_rewards_std            79.70151890255684
total_rewards_max            276.8968197817103
total_rewards_min            7.220384091456773
Number of train steps total  4000
Number of env steps total    22000
Number of rollouts total     0
Train Time (s)               28.182227700948715
(Previous) Eval Time (s)     22.56042685592547
Sample Time (s)              18.19216518336907
Epoch Time (s)               68.93481974024326
Total Train Time (s)         251.7596828932874
Epoch                        3
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:19:43.099507 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #3 | Epoch Duration: 66.75206208229065
2020-01-11 03:19:43.099696 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #3 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.22463217
Z variance train             0.014188205
KL Divergence                8.463063
KL Loss                      0.8463063
QF Loss                      108.58185
VF Loss                      18.436272
Policy Loss                  -57.473396
Q Predictions Mean           52.912117
Q Predictions Std            20.455147
Q Predictions Max            103.359474
Q Predictions Min            -21.327036
V Predictions Mean           58.025932
V Predictions Std            19.029228
V Predictions Max            98.53959
V Predictions Min            -13.60782
Log Pis Mean                 -3.2443657
Log Pis Std                  1.5840989
Log Pis Max                  -0.16876617
Log Pis Min                  -9.885862
Policy mu Mean               0.022113647
Policy mu Std                0.2537919
Policy mu Max                0.8153246
Policy mu Min                -0.78958535
Policy log std Mean          -0.7594018
Policy log std Std           0.108144365
Policy log std Max           -0.4079075
Policy log std Min           -1.0856087
Z mean eval                  0.29892033
Z variance eval              0.013701287
total_rewards                [158.95969706 181.3274048  127.98129476  29.31454848 306.65043237
 158.20926517  67.59949787  41.93972695  75.63325891  53.91713384]
total_rewards_mean           120.15322602031384
total_rewards_std            80.64684097378489
total_rewards_max            306.6504323699024
total_rewards_min            29.314548476198578
Number of train steps total  5000
Number of env steps total    27000
Number of rollouts total     0
Train Time (s)               26.87611459195614
(Previous) Eval Time (s)     20.377358423080295
Sample Time (s)              17.928523713257164
Epoch Time (s)               65.1819967282936
Total Train Time (s)         310.9865999035537
Epoch                        4
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:20:42.330258 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #4 | Epoch Duration: 59.23035669326782
2020-01-11 03:20:42.330550 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #4 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.30578932
Z variance train             0.01215495
KL Divergence                9.109398
KL Loss                      0.9109398
QF Loss                      145.23572
VF Loss                      16.488611
Policy Loss                  -74.223434
Q Predictions Mean           70.19043
Q Predictions Std            20.767406
Q Predictions Max            113.55323
Q Predictions Min            -23.025692
V Predictions Mean           73.45296
V Predictions Std            19.39197
V Predictions Max            124.43048
V Predictions Min            -11.286664
Log Pis Mean                 -3.0350795
Log Pis Std                  1.5637962
Log Pis Max                  0.96182406
Log Pis Min                  -8.495542
Policy mu Mean               0.03747923
Policy mu Std                0.2613341
Policy mu Max                0.97027767
Policy mu Min                -0.8806474
Policy log std Mean          -0.77577466
Policy log std Std           0.10570175
Policy log std Max           -0.4187682
Policy log std Min           -1.0943424
Z mean eval                  0.32748044
Z variance eval              0.01574593
total_rewards                [ 94.05598754 113.63772341  70.84445821  34.73149022  93.14444108
  39.46521679  76.11159621 217.92909419  28.35957557  90.81832159]
total_rewards_mean           85.90979048123187
total_rewards_std            51.72237631353141
total_rewards_max            217.92909418665312
total_rewards_min            28.359575567968875
Number of train steps total  6000
Number of env steps total    32000
Number of rollouts total     0
Train Time (s)               28.468368031084538
(Previous) Eval Time (s)     14.425354977604002
Sample Time (s)              18.173614399507642
Epoch Time (s)               61.06733740819618
Total Train Time (s)         380.7155390540138
Epoch                        5
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:21:52.058852 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #5 | Epoch Duration: 69.72808051109314
2020-01-11 03:21:52.059046 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #5 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.32936147
Z variance train             0.015748452
KL Divergence                8.420627
KL Loss                      0.84206265
QF Loss                      154.15768
VF Loss                      27.507387
Policy Loss                  -94.3253
Q Predictions Mean           90.96997
Q Predictions Std            22.255493
Q Predictions Max            139.42342
Q Predictions Min            -30.076017
V Predictions Mean           93.16261
V Predictions Std            21.139242
V Predictions Max            146.12671
V Predictions Min            -24.818361
Log Pis Mean                 -3.6114368
Log Pis Std                  1.4335512
Log Pis Max                  -0.3939123
Log Pis Min                  -9.466815
Policy mu Mean               0.06584862
Policy mu Std                0.27868098
Policy mu Max                0.99131376
Policy mu Min                -0.95145416
Policy log std Mean          -0.6747285
Policy log std Std           0.11750259
Policy log std Max           -0.34635544
Policy log std Min           -1.0904018
Z mean eval                  0.26609927
Z variance eval              0.012010933
total_rewards                [ -4.80026783  15.38829441  89.6193241   -0.10354879 -28.39134502
 -20.50840603  96.33554517 -15.08998181  -1.31664611  45.35398492]
total_rewards_mean           17.64869530236571
total_rewards_std            42.39143451487798
total_rewards_max            96.33554517308197
total_rewards_min            -28.391345020852953
Number of train steps total  7000
Number of env steps total    37000
Number of rollouts total     0
Train Time (s)               24.82856333302334
(Previous) Eval Time (s)     23.0858018361032
Sample Time (s)              17.834485481493175
Epoch Time (s)               65.74885065061972
Total Train Time (s)         439.63256664481014
Epoch                        6
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:22:50.980352 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #6 | Epoch Duration: 58.921141386032104
2020-01-11 03:22:50.980633 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #6 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.35418946
Z variance train             0.01135229
KL Divergence                9.546211
KL Loss                      0.95462114
QF Loss                      227.18376
VF Loss                      40.33774
Policy Loss                  -97.3167
Q Predictions Mean           93.209366
Q Predictions Std            23.542912
Q Predictions Max            150.00052
Q Predictions Min            -8.637249
V Predictions Mean           95.42553
V Predictions Std            22.818138
V Predictions Max            159.47981
V Predictions Min            -2.2414496
Log Pis Mean                 -3.9486437
Log Pis Std                  1.4011819
Log Pis Max                  -1.178171
Log Pis Min                  -9.871375
Policy mu Mean               0.004853488
Policy mu Std                0.28635484
Policy mu Max                1.107944
Policy mu Min                -0.9432404
Policy log std Mean          -0.59874105
Policy log std Std           0.112378635
Policy log std Max           -0.29864386
Policy log std Min           -0.95232606
Z mean eval                  0.51611984
Z variance eval              0.017133329
total_rewards                [ 58.9230366   64.91746744 -90.18703978 -16.93030133 123.43967777
  11.64982738  83.68769434  -9.44510361 -13.04985555  76.53903657]
total_rewards_mean           28.954443983386994
total_rewards_std            60.18087432431614
total_rewards_max            123.43967777435226
total_rewards_min            -90.18703977741289
Number of train steps total  8000
Number of env steps total    42000
Number of rollouts total     0
Train Time (s)               28.159306711982936
(Previous) Eval Time (s)     16.257794691249728
Sample Time (s)              18.320272703655064
Epoch Time (s)               62.73737410688773
Total Train Time (s)         507.13103967299685
Epoch                        7
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:23:58.475731 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #7 | Epoch Duration: 67.49489831924438
2020-01-11 03:23:58.475889 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #7 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.5034417
Z variance train             0.01786727
KL Divergence                8.807041
KL Loss                      0.8807041
QF Loss                      188.02
VF Loss                      32.8407
Policy Loss                  -114.19888
Q Predictions Mean           110.690475
Q Predictions Std            27.263206
Q Predictions Max            155.89728
Q Predictions Min            -12.47857
V Predictions Mean           117.06068
V Predictions Std            25.54699
V Predictions Max            161.93475
V Predictions Min            -16.065434
Log Pis Mean                 -3.2456832
Log Pis Std                  1.631841
Log Pis Max                  3.5598595
Log Pis Min                  -7.593236
Policy mu Mean               0.009642176
Policy mu Std                0.32874343
Policy mu Max                1.0842344
Policy mu Min                -1.0483272
Policy log std Mean          -0.70162904
Policy log std Std           0.14981861
Policy log std Max           -0.34593722
Policy log std Min           -1.2650514
Z mean eval                  0.54885375
Z variance eval              0.0142388595
total_rewards                [  7.91550698  66.6498799  114.08832991 -40.2615703   27.21515304
 -68.30886235  -1.09655134  94.3517987   60.57018587  43.85456066]
total_rewards_mean           30.497843106939683
total_rewards_std            54.53715975819693
total_rewards_max            114.08832991479257
total_rewards_min            -68.30886234863344
Number of train steps total  9000
Number of env steps total    47000
Number of rollouts total     0
Train Time (s)               26.61880941130221
(Previous) Eval Time (s)     21.01503843208775
Sample Time (s)              18.567066584248096
Epoch Time (s)               66.20091442763805
Total Train Time (s)         569.4529223539867
Epoch                        8
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:25:00.801203 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #8 | Epoch Duration: 62.32512378692627
2020-01-11 03:25:00.801480 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #8 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.20044012
Z variance train             0.02119305
KL Divergence                7.3962517
KL Loss                      0.73962516
QF Loss                      244.30061
VF Loss                      20.876696
Policy Loss                  -115.610054
Q Predictions Mean           112.66367
Q Predictions Std            22.676142
Q Predictions Max            162.06639
Q Predictions Min            -36.56254
V Predictions Mean           117.426216
V Predictions Std            22.78295
V Predictions Max            165.24786
V Predictions Min            -20.412582
Log Pis Mean                 -3.3146615
Log Pis Std                  1.5929854
Log Pis Max                  1.8636954
Log Pis Min                  -8.249573
Policy mu Mean               0.027097441
Policy mu Std                0.3258119
Policy mu Max                1.1779407
Policy mu Min                -1.0195366
Policy log std Mean          -0.7119627
Policy log std Std           0.12863982
Policy log std Max           -0.36608803
Policy log std Min           -1.3362197
Z mean eval                  0.5433329
Z variance eval              0.016662344
total_rewards                [  1.36539742 -39.78129557 -15.20043885  21.16950838 122.70415198
 -12.7601363  105.49676608 103.44073389  77.14992112 146.28225743]
total_rewards_mean           50.98668655740536
total_rewards_std            63.77028100337434
total_rewards_max            146.28225742810832
total_rewards_min            -39.781295574254635
Number of train steps total  10000
Number of env steps total    52000
Number of rollouts total     0
Train Time (s)               29.525174090173095
(Previous) Eval Time (s)     17.13894143514335
Sample Time (s)              18.02102380571887
Epoch Time (s)               64.68513933103532
Total Train Time (s)         640.6399309765548
Epoch                        9
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:26:11.989899 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #9 | Epoch Duration: 71.1881856918335
2020-01-11 03:26:11.990209 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #9 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.54553485
Z variance train             0.015634373
KL Divergence                9.232988
KL Loss                      0.92329884
QF Loss                      214.75227
VF Loss                      21.24357
Policy Loss                  -143.40146
Q Predictions Mean           139.8292
Q Predictions Std            25.807838
Q Predictions Max            187.6023
Q Predictions Min            -26.11967
V Predictions Mean           143.36987
V Predictions Std            25.044538
V Predictions Max            192.82747
V Predictions Min            -53.040443
Log Pis Mean                 -3.2694788
Log Pis Std                  1.7068185
Log Pis Max                  4.738654
Log Pis Min                  -8.930595
Policy mu Mean               0.06982015
Policy mu Std                0.32872978
Policy mu Max                1.4110968
Policy mu Min                -1.2271042
Policy log std Mean          -0.70314467
Policy log std Std           0.1436817
Policy log std Max           -0.39803433
Policy log std Min           -1.5892609
Z mean eval                  0.57717735
Z variance eval              0.02215753
total_rewards                [ 70.66703855 113.96616177   5.55028387  49.15753449  76.52246067
  36.44158213  27.94920307  58.83616892  44.8505133   74.12351887]
total_rewards_mean           55.80644656555906
total_rewards_std            28.66737456889748
total_rewards_max            113.96616177424664
total_rewards_min            5.550283874486045
Number of train steps total  11000
Number of env steps total    57000
Number of rollouts total     0
Train Time (s)               26.18080514203757
(Previous) Eval Time (s)     23.641721657011658
Sample Time (s)              18.85543723590672
Epoch Time (s)               68.67796403495595
Total Train Time (s)         711.0938390330411
Epoch                        10
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:27:22.443437 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #10 | Epoch Duration: 70.45301127433777
2020-01-11 03:27:22.443648 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #10 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.5812179
Z variance train             0.023214545
KL Divergence                8.728807
KL Loss                      0.87288076
QF Loss                      201.6477
VF Loss                      44.7297
Policy Loss                  -153.33871
Q Predictions Mean           148.3994
Q Predictions Std            29.909353
Q Predictions Max            220.3124
Q Predictions Min            -5.4840345
V Predictions Mean           152.16708
V Predictions Std            23.96081
V Predictions Max            226.97108
V Predictions Min            12.218166
Log Pis Mean                 -3.235735
Log Pis Std                  1.7110013
Log Pis Max                  4.1791124
Log Pis Min                  -8.300232
Policy mu Mean               0.055269033
Policy mu Std                0.33789483
Policy mu Max                1.3588798
Policy mu Min                -1.2473369
Policy log std Mean          -0.7119409
Policy log std Std           0.14773114
Policy log std Max           -0.38511634
Policy log std Min           -1.3798723
Z mean eval                  0.60608304
Z variance eval              0.013422793
total_rewards                [143.68586168  58.03274245  60.87477969  33.3288478    4.77619137
  25.11201399  17.61253695 250.35080818   5.57475357 119.56483374]
total_rewards_mean           71.89133694159321
total_rewards_std            74.23766892714623
total_rewards_max            250.3508081787017
total_rewards_min            4.776191366281468
Number of train steps total  12000
Number of env steps total    62000
Number of rollouts total     0
Train Time (s)               26.675670464988798
(Previous) Eval Time (s)     25.416499115061015
Sample Time (s)              18.177351393271238
Epoch Time (s)               70.26952097332105
Total Train Time (s)         770.2186742620543
Epoch                        11
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:28:21.569574 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #11 | Epoch Duration: 59.125765800476074
2020-01-11 03:28:21.569783 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #11 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6069572
Z variance train             0.013817665
KL Divergence                10.12755
KL Loss                      1.012755
QF Loss                      237.9425
VF Loss                      32.709206
Policy Loss                  -167.34221
Q Predictions Mean           162.30997
Q Predictions Std            28.307238
Q Predictions Max            209.97751
Q Predictions Min            -18.696152
V Predictions Mean           166.75073
V Predictions Std            26.508955
V Predictions Max            211.31908
V Predictions Min            -54.912685
Log Pis Mean                 -3.3113174
Log Pis Std                  1.7729657
Log Pis Max                  3.2222211
Log Pis Min                  -8.4787445
Policy mu Mean               0.037758883
Policy mu Std                0.3474832
Policy mu Max                1.1453158
Policy mu Min                -1.4719917
Policy log std Mean          -0.6538307
Policy log std Std           0.14762701
Policy log std Max           -0.33877504
Policy log std Min           -1.4539844
Z mean eval                  0.654648
Z variance eval              0.0107842265
total_rewards                [ 130.99459617   37.07599952  -54.94227907   91.06887775 -187.55035145
   13.85582252    2.34506808  -49.56595881   43.00519135   29.83689445]
total_rewards_mean           5.612386050482222
total_rewards_std            83.72604626829403
total_rewards_max            130.99459616947462
total_rewards_min            -187.55035145496333
Number of train steps total  13000
Number of env steps total    67000
Number of rollouts total     0
Train Time (s)               29.566403006669134
(Previous) Eval Time (s)     14.272446635179222
Sample Time (s)              18.81917978776619
Epoch Time (s)               62.658029429614544
Total Train Time (s)         840.1090457998216
Epoch                        12
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:29:31.462241 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #12 | Epoch Duration: 69.89228010177612
2020-01-11 03:29:31.462493 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #12 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6484249
Z variance train             0.010893333
KL Divergence                11.196309
KL Loss                      1.1196309
QF Loss                      214.59839
VF Loss                      62.04062
Policy Loss                  -173.96155
Q Predictions Mean           171.7445
Q Predictions Std            28.09185
Q Predictions Max            223.21835
Q Predictions Min            11.70386
V Predictions Mean           179.85933
V Predictions Std            24.175901
V Predictions Max            229.71165
V Predictions Min            61.383648
Log Pis Mean                 -3.0406108
Log Pis Std                  1.6995105
Log Pis Max                  3.2174013
Log Pis Min                  -7.761197
Policy mu Mean               0.021149555
Policy mu Std                0.36804366
Policy mu Max                1.3824763
Policy mu Min                -1.5050123
Policy log std Mean          -0.67290133
Policy log std Std           0.14514771
Policy log std Max           -0.4122878
Policy log std Min           -1.5782896
Z mean eval                  0.6505477
Z variance eval              0.0089729
total_rewards                [-30.21452651 -41.69801503 118.36332107  39.95807862 229.84921408
 -46.67255674 197.73300803  -4.79803572  62.22236033 108.23096024]
total_rewards_mean           63.29738083760706
total_rewards_std            93.7595312164279
total_rewards_max            229.84921407889644
total_rewards_min            -46.67255674008302
Number of train steps total  14000
Number of env steps total    72000
Number of rollouts total     0
Train Time (s)               26.44997218903154
(Previous) Eval Time (s)     21.50635995203629
Sample Time (s)              18.171491474844515
Epoch Time (s)               66.12782361591235
Total Train Time (s)         909.4373334730044
Epoch                        13
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:30:40.792237 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #13 | Epoch Duration: 69.32953691482544
2020-01-11 03:30:40.792474 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #13 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.35296655
Z variance train             0.021226514
KL Divergence                7.8010893
KL Loss                      0.7801089
QF Loss                      265.97226
VF Loss                      37.18196
Policy Loss                  -164.77693
Q Predictions Mean           161.66232
Q Predictions Std            30.790628
Q Predictions Max            203.54988
Q Predictions Min            -3.23198
V Predictions Mean           165.60953
V Predictions Std            27.078503
V Predictions Max            208.47821
V Predictions Min            3.9660437
Log Pis Mean                 -3.1487572
Log Pis Std                  1.8365537
Log Pis Max                  3.7875195
Log Pis Min                  -9.948297
Policy mu Mean               0.050780382
Policy mu Std                0.34758723
Policy mu Max                1.1877016
Policy mu Min                -1.5764284
Policy log std Mean          -0.691293
Policy log std Std           0.14364557
Policy log std Max           -0.3624735
Policy log std Min           -1.5587778
Z mean eval                  0.67162335
Z variance eval              0.010211244
total_rewards                [ 46.43514769 184.18421549  13.28445187 125.7873351    2.04232179
 218.97361196 151.4899056  156.17309448 183.04691048   8.44064705]
total_rewards_mean           108.98576415127334
total_rewards_std            78.84812448153275
total_rewards_max            218.97361195664305
total_rewards_min            2.04232179123409
Number of train steps total  15000
Number of env steps total    77000
Number of rollouts total     0
Train Time (s)               29.366876787040383
(Previous) Eval Time (s)     24.707781281787902
Sample Time (s)              18.52231630962342
Epoch Time (s)               72.5969743784517
Total Train Time (s)         979.6874375357293
Epoch                        14
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:31:51.042574 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #14 | Epoch Duration: 70.24991536140442
2020-01-11 03:31:51.042787 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #14 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6690649
Z variance train             0.010235261
KL Divergence                11.790938
KL Loss                      1.1790938
QF Loss                      304.55713
VF Loss                      36.62172
Policy Loss                  -193.53809
Q Predictions Mean           191.94504
Q Predictions Std            25.46615
Q Predictions Max            255.48216
Q Predictions Min            13.120646
V Predictions Mean           192.58087
V Predictions Std            25.380335
V Predictions Max            270.90552
V Predictions Min            36.681244
Log Pis Mean                 -2.9276276
Log Pis Std                  1.7975532
Log Pis Max                  4.4996424
Log Pis Min                  -8.409382
Policy mu Mean               0.05749204
Policy mu Std                0.3699249
Policy mu Max                1.5180372
Policy mu Min                -1.5089194
Policy log std Mean          -0.71429354
Policy log std Std           0.13474534
Policy log std Max           -0.42689556
Policy log std Min           -1.6738021
Z mean eval                  0.6902353
Z variance eval              0.014196296
total_rewards                [-31.85465628 117.06543695 100.57184375 108.06075617 168.86524871
  49.06330367  97.62048149  88.91188785  39.59237926  23.25849689]
total_rewards_mean           76.11551784575391
total_rewards_std            53.8900865028662
total_rewards_max            168.86524871050403
total_rewards_min            -31.854656276321684
Number of train steps total  16000
Number of env steps total    82000
Number of rollouts total     0
Train Time (s)               27.95773120317608
(Previous) Eval Time (s)     22.360426841769367
Sample Time (s)              19.1163699189201
Epoch Time (s)               69.43452796386555
Total Train Time (s)         1048.5641627577133
Epoch                        15
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:32:59.922619 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #15 | Epoch Duration: 68.87966132164001
2020-01-11 03:32:59.922816 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #15 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6923238
Z variance train             0.014213341
KL Divergence                11.64362
KL Loss                      1.164362
QF Loss                      172.50627
VF Loss                      44.48893
Policy Loss                  -205.8193
Q Predictions Mean           200.77193
Q Predictions Std            23.84222
Q Predictions Max            282.10364
Q Predictions Min            29.684013
V Predictions Mean           203.37166
V Predictions Std            19.13233
V Predictions Max            272.70828
V Predictions Min            129.88678
Log Pis Mean                 -3.3298812
Log Pis Std                  1.7665997
Log Pis Max                  2.6907642
Log Pis Min                  -9.186504
Policy mu Mean               0.08369846
Policy mu Std                0.34483203
Policy mu Max                1.4590036
Policy mu Min                -1.2146711
Policy log std Mean          -0.7027419
Policy log std Std           0.12603186
Policy log std Max           -0.40591824
Policy log std Min           -1.5213488
Z mean eval                  0.6945084
Z variance eval              0.01150859
total_rewards                [182.3608812   94.46364337 143.47784022  19.90357579 177.09730596
 116.50978876 240.9201372   20.79882263 127.15831342 101.24064704]
total_rewards_mean           122.39309555864193
total_rewards_std            65.72078129545694
total_rewards_max            240.92013720077537
total_rewards_min            19.903575786521003
Number of train steps total  17000
Number of env steps total    87000
Number of rollouts total     0
Train Time (s)               24.828399889171124
(Previous) Eval Time (s)     21.805228765122592
Sample Time (s)              18.85377375688404
Epoch Time (s)               65.48740241117775
Total Train Time (s)         1113.607843842823
Epoch                        16
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:34:04.964926 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #16 | Epoch Duration: 65.04195523262024
2020-01-11 03:34:04.965119 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #16 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.69392526
Z variance train             0.01152909
KL Divergence                12.443283
KL Loss                      1.2443284
QF Loss                      233.98004
VF Loss                      35.488136
Policy Loss                  -208.77776
Q Predictions Mean           206.01566
Q Predictions Std            32.38121
Q Predictions Max            259.89194
Q Predictions Min            -30.990711
V Predictions Mean           208.38412
V Predictions Std            32.25189
V Predictions Max            265.0374
V Predictions Min            -110.498055
Log Pis Mean                 -3.2332573
Log Pis Std                  1.7271649
Log Pis Max                  3.2953906
Log Pis Min                  -8.970548
Policy mu Mean               0.053399127
Policy mu Std                0.33935666
Policy mu Max                1.4635673
Policy mu Min                -1.7957724
Policy log std Mean          -0.7222102
Policy log std Std           0.1412551
Policy log std Max           -0.26181477
Policy log std Min           -1.6006993
Z mean eval                  0.71026254
Z variance eval              0.009848932
total_rewards                [210.34923685  83.13503295  65.24515202 101.6459953  330.45727328
 322.16998538 277.20218544  32.565091   382.91847755 226.27780952]
total_rewards_mean           203.19662392951662
total_rewards_std            118.98892673180261
total_rewards_max            382.9184775499112
total_rewards_min            32.565090999306676
Number of train steps total  18000
Number of env steps total    92000
Number of rollouts total     0
Train Time (s)               28.449849078897387
(Previous) Eval Time (s)     21.359467243310064
Sample Time (s)              18.08360978960991
Epoch Time (s)               67.89292611181736
Total Train Time (s)         1180.1226809867658
Epoch                        17
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:35:11.481671 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #17 | Epoch Duration: 66.51638913154602
2020-01-11 03:35:11.481889 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #17 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7109053
Z variance train             0.009838758
KL Divergence                12.4456415
KL Loss                      1.2445642
QF Loss                      185.30629
VF Loss                      28.986546
Policy Loss                  -222.26201
Q Predictions Mean           219.27486
Q Predictions Std            27.078827
Q Predictions Max            273.61908
Q Predictions Min            -48.352512
V Predictions Mean           220.71852
V Predictions Std            26.383245
V Predictions Max            271.82047
V Predictions Min            -61.301167
Log Pis Mean                 -3.0656972
Log Pis Std                  2.0124834
Log Pis Max                  14.894779
Log Pis Min                  -10.005009
Policy mu Mean               0.03598152
Policy mu Std                0.33536142
Policy mu Max                2.2286584
Policy mu Min                -2.5230548
Policy log std Mean          -0.7267268
Policy log std Std           0.13806933
Policy log std Max           -0.39144304
Policy log std Min           -1.6582252
Z mean eval                  0.7193595
Z variance eval              0.010459467
total_rewards                [ 36.96947051  78.54057899  37.7533013    4.54891089  16.20566784
  24.83375482 143.87058763  79.88123891  56.15764637  34.87728003]
total_rewards_mean           51.36384372968655
total_rewards_std            38.6369350389794
total_rewards_max            143.87058762832316
total_rewards_min            4.548910894629974
Number of train steps total  19000
Number of env steps total    97000
Number of rollouts total     0
Train Time (s)               26.770887195132673
(Previous) Eval Time (s)     19.98260773019865
Sample Time (s)              19.801727114245296
Epoch Time (s)               66.55522203957662
Total Train Time (s)         1246.276926830411
Epoch                        18
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:36:17.637471 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #18 | Epoch Duration: 66.15541195869446
2020-01-11 03:36:17.637665 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #18 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.72472054
Z variance train             0.010450283
KL Divergence                12.833864
KL Loss                      1.2833865
QF Loss                      236.22527
VF Loss                      76.334435
Policy Loss                  -232.2547
Q Predictions Mean           225.35959
Q Predictions Std            25.552698
Q Predictions Max            288.91867
Q Predictions Min            1.5154634
V Predictions Mean           226.27019
V Predictions Std            23.444933
V Predictions Max            292.5475
V Predictions Min            61.232388
Log Pis Mean                 -3.01473
Log Pis Std                  1.8805358
Log Pis Max                  8.33905
Log Pis Min                  -8.687319
Policy mu Mean               0.014879188
Policy mu Std                0.36196807
Policy mu Max                2.1950548
Policy mu Min                -1.2122825
Policy log std Mean          -0.73605955
Policy log std Std           0.14597315
Policy log std Max           -0.3454131
Policy log std Min           -1.6585814
Z mean eval                  0.7293374
Z variance eval              0.012279026
total_rewards                [ 67.81308932 167.01725478  91.08097111 172.92004223 306.58120793
 301.67379042 237.41620852  74.06614161 331.83282391  63.52524691]
total_rewards_mean           181.39267767248933
total_rewards_std            101.31992397526702
total_rewards_max            331.8328239101088
total_rewards_min            63.52524691370002
Number of train steps total  20000
Number of env steps total    102000
Number of rollouts total     0
Train Time (s)               27.8594450391829
(Previous) Eval Time (s)     19.582483114674687
Sample Time (s)              17.964899419806898
Epoch Time (s)               65.40682757366449
Total Train Time (s)         1317.667057198938
Epoch                        19
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:37:29.028680 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #19 | Epoch Duration: 71.39084911346436
2020-01-11 03:37:29.028903 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #19 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.72803175
Z variance train             0.012268839
KL Divergence                12.727528
KL Loss                      1.2727528
QF Loss                      156.61862
VF Loss                      48.11882
Policy Loss                  -233.22481
Q Predictions Mean           230.65811
Q Predictions Std            30.903418
Q Predictions Max            297.40674
Q Predictions Min            -9.352205
V Predictions Mean           234.67012
V Predictions Std            27.117731
V Predictions Max            295.58344
V Predictions Min            19.175674
Log Pis Mean                 -2.9144242
Log Pis Std                  1.8515092
Log Pis Max                  3.3475566
Log Pis Min                  -9.624564
Policy mu Mean               0.034603864
Policy mu Std                0.33342487
Policy mu Max                1.5425142
Policy mu Min                -1.402113
Policy log std Mean          -0.768944
Policy log std Std           0.12126361
Policy log std Max           -0.39748865
Policy log std Min           -1.3821671
Z mean eval                  0.748752
Z variance eval              0.014075378
total_rewards                [285.8004526  105.27294428  55.68544619  11.9612765  141.99221693
 279.19107335 128.92930601 162.64663554 333.29914618 228.10933157]
total_rewards_mean           173.28878291584675
total_rewards_std            100.01326752960613
total_rewards_max            333.29914618485793
total_rewards_min            11.961276501660977
Number of train steps total  21000
Number of env steps total    107000
Number of rollouts total     0
Train Time (s)               28.32223001914099
(Previous) Eval Time (s)     25.566187248099595
Sample Time (s)              18.014545517973602
Epoch Time (s)               71.90296278521419
Total Train Time (s)         1387.1957493536174
Epoch                        20
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:38:38.558104 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #20 | Epoch Duration: 69.52903413772583
2020-01-11 03:38:38.558303 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #20 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7451602
Z variance train             0.014067242
KL Divergence                12.673101
KL Loss                      1.2673101
QF Loss                      197.9515
VF Loss                      79.746666
Policy Loss                  -234.4805
Q Predictions Mean           231.6966
Q Predictions Std            37.157845
Q Predictions Max            283.7031
Q Predictions Min            -17.691284
V Predictions Mean           237.48476
V Predictions Std            31.311888
V Predictions Max            285.87686
V Predictions Min            27.934252
Log Pis Mean                 -2.8665183
Log Pis Std                  1.8115149
Log Pis Max                  3.5061545
Log Pis Min                  -8.313202
Policy mu Mean               -0.0006065613
Policy mu Std                0.3210416
Policy mu Max                1.1892976
Policy mu Min                -1.2198368
Policy log std Mean          -0.7571856
Policy log std Std           0.15314043
Policy log std Max           -0.41159606
Policy log std Min           -1.6240695
Z mean eval                  0.7580375
Z variance eval              0.018518653
total_rewards                [162.82046148  16.65744174 116.85255595 374.35972847 305.90886798
  90.7011549   92.67959118  87.07266002 416.6362295   90.09157319]
total_rewards_mean           175.37802644076106
total_rewards_std            131.41290143529054
total_rewards_max            416.6362294975662
total_rewards_min            16.657441738619212
Number of train steps total  22000
Number of env steps total    112000
Number of rollouts total     0
Train Time (s)               28.588295630179346
(Previous) Eval Time (s)     23.19198343111202
Sample Time (s)              18.85999903595075
Epoch Time (s)               70.64027809724212
Total Train Time (s)         1460.0477204890922
Epoch                        21
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:39:51.412863 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #21 | Epoch Duration: 72.85439991950989
2020-01-11 03:39:51.413147 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #21 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7606193
Z variance train             0.018565113
KL Divergence                13.043941
KL Loss                      1.3043941
QF Loss                      165.19003
VF Loss                      52.61403
Policy Loss                  -249.91528
Q Predictions Mean           247.29309
Q Predictions Std            31.09944
Q Predictions Max            306.60385
Q Predictions Min            -12.391284
V Predictions Mean           248.25667
V Predictions Std            29.070091
V Predictions Max            305.3214
V Predictions Min            -3.0749936
Log Pis Mean                 -3.1697474
Log Pis Std                  1.5416833
Log Pis Max                  1.9370449
Log Pis Min                  -7.5658283
Policy mu Mean               0.045888465
Policy mu Std                0.32297447
Policy mu Max                1.0278764
Policy mu Min                -1.7198079
Policy log std Mean          -0.72098887
Policy log std Std           0.12221545
Policy log std Max           -0.35186893
Policy log std Min           -1.5748951
Z mean eval                  0.76344836
Z variance eval              0.015128831
total_rewards                [204.31602316 103.05691785 -30.92436493 131.02246692 123.66251747
 362.1187438   23.90046009  80.51399952  76.87177353 369.18851955]
total_rewards_mean           144.37270569574645
total_rewards_std            125.59448984770096
total_rewards_max            369.1885195498377
total_rewards_min            -30.924364930484234
Number of train steps total  23000
Number of env steps total    117000
Number of rollouts total     0
Train Time (s)               28.244730638805777
(Previous) Eval Time (s)     25.40576889924705
Sample Time (s)              18.55090286117047
Epoch Time (s)               72.2014023992233
Total Train Time (s)         1528.1538036484271
Epoch                        22
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:40:59.520135 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #22 | Epoch Duration: 68.10676980018616
2020-01-11 03:40:59.520353 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #22 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.75995666
Z variance train             0.015054673
KL Divergence                13.184206
KL Loss                      1.3184206
QF Loss                      405.34247
VF Loss                      61.547997
Policy Loss                  -249.15596
Q Predictions Mean           246.17238
Q Predictions Std            29.106161
Q Predictions Max            298.52466
Q Predictions Min            -20.918173
V Predictions Mean           252.4101
V Predictions Std            26.064615
V Predictions Max            298.70825
V Predictions Min            18.406628
Log Pis Mean                 -2.906857
Log Pis Std                  1.6232436
Log Pis Max                  1.7773979
Log Pis Min                  -7.7317166
Policy mu Mean               0.0069695185
Policy mu Std                0.32273653
Policy mu Max                1.0825757
Policy mu Min                -1.2719525
Policy log std Mean          -0.75098616
Policy log std Std           0.13049361
Policy log std Max           -0.4243511
Policy log std Min           -1.7053806
Z mean eval                  0.739631
Z variance eval              0.014698912
total_rewards                [355.36089997 116.94542552  55.27625328 188.52924141 158.3982388
 189.37969432  81.93391652  82.57953375  95.67789694 275.31604009]
total_rewards_mean           159.93971405959084
total_rewards_std            90.65849001968445
total_rewards_max            355.3608999741153
total_rewards_min            55.27625328107531
Number of train steps total  24000
Number of env steps total    122000
Number of rollouts total     0
Train Time (s)               27.786528019234538
(Previous) Eval Time (s)     21.310829661786556
Sample Time (s)              18.693867267575115
Epoch Time (s)               67.79122494859621
Total Train Time (s)         1599.1637954819016
Epoch                        23
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:42:10.531927 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #23 | Epoch Duration: 71.0114016532898
2020-01-11 03:42:10.532124 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #23 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.74161875
Z variance train             0.0146800475
KL Divergence                12.693905
KL Loss                      1.2693905
QF Loss                      174.94424
VF Loss                      58.60338
Policy Loss                  -256.6574
Q Predictions Mean           252.08908
Q Predictions Std            29.561289
Q Predictions Max            306.6537
Q Predictions Min            -9.410652
V Predictions Mean           258.20245
V Predictions Std            30.1722
V Predictions Max            316.4161
V Predictions Min            24.670963
Log Pis Mean                 -2.7622693
Log Pis Std                  1.520641
Log Pis Max                  3.8383126
Log Pis Min                  -8.559996
Policy mu Mean               0.011537492
Policy mu Std                0.3416359
Policy mu Max                2.1310303
Policy mu Min                -1.5964568
Policy log std Mean          -0.7411953
Policy log std Std           0.12994018
Policy log std Max           -0.39049596
Policy log std Min           -1.4497437
Z mean eval                  0.7485394
Z variance eval              0.015585186
total_rewards                [265.27969066 306.96841571 121.91733363  80.50578446  80.94463564
   9.01189208  23.67835925  29.26754493 334.01247403 151.65401159]
total_rewards_mean           140.32401419871317
total_rewards_std            114.74032623584272
total_rewards_max            334.0124740324415
total_rewards_min            9.011892082345208
Number of train steps total  25000
Number of env steps total    127000
Number of rollouts total     0
Train Time (s)               28.629480347968638
(Previous) Eval Time (s)     24.530726076103747
Sample Time (s)              17.757304337807
Epoch Time (s)               70.91751076187938
Total Train Time (s)         1664.2884180345573
Epoch                        24
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:43:15.656841 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #24 | Epoch Duration: 65.12452387809753
2020-01-11 03:43:15.657148 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #24 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.75126064
Z variance train             0.015575742
KL Divergence                13.6505575
KL Loss                      1.3650558
QF Loss                      352.50134
VF Loss                      47.772385
Policy Loss                  -253.19876
Q Predictions Mean           250.65405
Q Predictions Std            42.312073
Q Predictions Max            321.40988
Q Predictions Min            -29.354832
V Predictions Mean           249.70818
V Predictions Std            40.526394
V Predictions Max            315.51523
V Predictions Min            -30.268946
Log Pis Mean                 -2.5805027
Log Pis Std                  1.828088
Log Pis Max                  8.943451
Log Pis Min                  -7.941637
Policy mu Mean               0.025180906
Policy mu Std                0.33519953
Policy mu Max                2.126047
Policy mu Min                -1.7749556
Policy log std Mean          -0.779299
Policy log std Std           0.13995592
Policy log std Max           -0.4512185
Policy log std Min           -1.6189661
Z mean eval                  0.7652315
Z variance eval              0.013945426
total_rewards                [150.62512464 177.06131979 158.53774804 111.8102991  150.49759813
 269.53489721 212.73601121 461.0063713  116.69506522 203.72082234]
total_rewards_mean           201.22252569923592
total_rewards_std            97.45323781014369
total_rewards_max            461.0063712975957
total_rewards_min            111.81029910050478
Number of train steps total  26000
Number of env steps total    132000
Number of rollouts total     0
Train Time (s)               30.10825598007068
(Previous) Eval Time (s)     18.737423228099942
Sample Time (s)              18.657793413382024
Epoch Time (s)               67.50347262155265
Total Train Time (s)         1737.755612990819
Epoch                        25
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:44:29.126075 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #25 | Epoch Duration: 73.46868205070496
2020-01-11 03:44:29.126333 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #25 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7671998
Z variance train             0.013943056
KL Divergence                14.452051
KL Loss                      1.4452051
QF Loss                      125.30353
VF Loss                      57.41455
Policy Loss                  -268.5525
Q Predictions Mean           264.02426
Q Predictions Std            40.324284
Q Predictions Max            338.7571
Q Predictions Min            -6.264393
V Predictions Mean           265.84335
V Predictions Std            34.314533
V Predictions Max            328.62518
V Predictions Min            13.52258
Log Pis Mean                 -3.0505385
Log Pis Std                  2.0271177
Log Pis Max                  10.56304
Log Pis Min                  -10.020205
Policy mu Mean               0.034904655
Policy mu Std                0.34602568
Policy mu Max                1.8879055
Policy mu Min                -2.4926836
Policy log std Mean          -0.7365954
Policy log std Std           0.14738698
Policy log std Max           -0.41419873
Policy log std Min           -1.8539121
Z mean eval                  0.7759563
Z variance eval              0.01866042
total_rewards                [219.72985544 -71.74920805 213.28855865 181.63845249 189.12837537
 149.45783177 277.15021392 242.33216753 238.33432962 200.72515692]
total_rewards_mean           184.00357336583482
total_rewards_std            91.69443408659173
total_rewards_max            277.1502139195471
total_rewards_min            -71.74920804843367
Number of train steps total  27000
Number of env steps total    137000
Number of rollouts total     0
Train Time (s)               26.763115728273988
(Previous) Eval Time (s)     24.702343795914203
Sample Time (s)              18.184475107118487
Epoch Time (s)               69.64993463130668
Total Train Time (s)         1810.9634965872392
Epoch                        26
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:45:42.334294 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #26 | Epoch Duration: 73.20777440071106
2020-01-11 03:45:42.334494 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #26 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.77781254
Z variance train             0.018764269
KL Divergence                14.789951
KL Loss                      1.4789952
QF Loss                      154.86755
VF Loss                      44.472855
Policy Loss                  -277.54874
Q Predictions Mean           274.6021
Q Predictions Std            31.11767
Q Predictions Max            328.51895
Q Predictions Min            -5.77285
V Predictions Mean           274.04694
V Predictions Std            29.622057
V Predictions Max            333.7296
V Predictions Min            -3.580032
Log Pis Mean                 -2.8420212
Log Pis Std                  1.8740761
Log Pis Max                  5.676107
Log Pis Min                  -9.852439
Policy mu Mean               0.054800574
Policy mu Std                0.34094942
Policy mu Max                1.7994422
Policy mu Min                -1.8188704
Policy log std Mean          -0.754624
Policy log std Std           0.15707599
Policy log std Max           -0.42197204
Policy log std Min           -1.8445907
Z mean eval                  0.784774
Z variance eval              0.017804269
total_rewards                [228.70116868 274.25057621 246.35571382 158.96786416  65.51500837
  98.11993687 308.11686734 327.4726165  250.30073903  95.66983938]
total_rewards_mean           205.34703303638517
total_rewards_std            89.27637865956473
total_rewards_max            327.4726164986696
total_rewards_min            65.51500836871367
Number of train steps total  28000
Number of env steps total    142000
Number of rollouts total     0
Train Time (s)               27.873672848101705
(Previous) Eval Time (s)     28.259893426205963
Sample Time (s)              18.32898649573326
Epoch Time (s)               74.46255277004093
Total Train Time (s)         1882.463045461569
Epoch                        27
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:46:53.833984 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #27 | Epoch Duration: 71.49934959411621
2020-01-11 03:46:53.834137 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #27 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7850268
Z variance train             0.01778864
KL Divergence                15.229598
KL Loss                      1.5229598
QF Loss                      388.01218
VF Loss                      97.185844
Policy Loss                  -282.4482
Q Predictions Mean           278.28503
Q Predictions Std            32.75839
Q Predictions Max            330.7655
Q Predictions Min            8.865522
V Predictions Mean           280.69135
V Predictions Std            28.489902
V Predictions Max            334.3245
V Predictions Min            35.119953
Log Pis Mean                 -2.7555573
Log Pis Std                  1.7200489
Log Pis Max                  3.9272196
Log Pis Min                  -7.513995
Policy mu Mean               0.047942042
Policy mu Std                0.3584079
Policy mu Max                1.8640476
Policy mu Min                -1.2806234
Policy log std Mean          -0.7513478
Policy log std Std           0.1265368
Policy log std Max           -0.44503015
Policy log std Min           -1.3245828
Z mean eval                  0.7786517
Z variance eval              0.015273402
total_rewards                [322.65398276 162.57982948 256.54174474  19.74189226 185.41627771
 226.20205376  89.72408786 218.85954913 140.48663003 146.06524545]
total_rewards_mean           176.82712931699945
total_rewards_std            81.62774927495961
total_rewards_max            322.6539827591292
total_rewards_min            19.741892260041293
Number of train steps total  29000
Number of env steps total    147000
Number of rollouts total     0
Train Time (s)               26.68394313706085
(Previous) Eval Time (s)     25.296388660091907
Sample Time (s)              17.699599695857614
Epoch Time (s)               69.67993149301037
Total Train Time (s)         1952.1252978867851
Epoch                        28
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:48:03.498622 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #28 | Epoch Duration: 69.66435146331787
2020-01-11 03:48:03.498816 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #28 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7809794
Z variance train             0.015278704
KL Divergence                14.738406
KL Loss                      1.4738406
QF Loss                      136.45888
VF Loss                      47.273197
Policy Loss                  -288.73328
Q Predictions Mean           283.6267
Q Predictions Std            33.44206
Q Predictions Max            340.58917
Q Predictions Min            -38.949596
V Predictions Mean           285.34955
V Predictions Std            27.578405
V Predictions Max            350.3904
V Predictions Min            59.84125
Log Pis Mean                 -2.9582672
Log Pis Std                  1.5484574
Log Pis Max                  2.5507705
Log Pis Min                  -8.625285
Policy mu Mean               0.046379216
Policy mu Std                0.3209607
Policy mu Max                1.1426018
Policy mu Min                -1.4782823
Policy log std Mean          -0.7394495
Policy log std Std           0.13637923
Policy log std Max           -0.36781466
Policy log std Min           -1.6526048
Z mean eval                  0.7699901
Z variance eval              0.013746428
total_rewards                [246.66360295 198.01772681 188.41250238 451.02907144 426.07026893
 250.1201469  341.91748431 261.45930937 460.02969632 333.17969841]
total_rewards_mean           315.6899507821487
total_rewards_std            97.14912694136119
total_rewards_max            460.0296963193616
total_rewards_min            188.41250237533598
Number of train steps total  30000
Number of env steps total    152000
Number of rollouts total     0
Train Time (s)               25.926625015679747
(Previous) Eval Time (s)     25.28052101098001
Sample Time (s)              19.019168213009834
Epoch Time (s)               70.22631423966959
Total Train Time (s)         2021.0735512236133
Epoch                        29
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:49:12.448410 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #29 | Epoch Duration: 68.94942569732666
2020-01-11 03:49:12.448651 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #29 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7658783
Z variance train             0.0137972785
KL Divergence                14.860693
KL Loss                      1.4860693
QF Loss                      162.3968
VF Loss                      31.86914
Policy Loss                  -281.66705
Q Predictions Mean           279.57898
Q Predictions Std            33.1799
Q Predictions Max            343.11212
Q Predictions Min            -19.590673
V Predictions Mean           283.51834
V Predictions Std            32.1938
V Predictions Max            343.18594
V Predictions Min            -24.702333
Log Pis Mean                 -2.9646575
Log Pis Std                  1.7400949
Log Pis Max                  7.8213367
Log Pis Min                  -9.93593
Policy mu Mean               0.053396158
Policy mu Std                0.3204567
Policy mu Max                1.7102147
Policy mu Min                -1.6427199
Policy log std Mean          -0.7392926
Policy log std Std           0.13603288
Policy log std Max           -0.23520611
Policy log std Min           -1.6357927
Z mean eval                  0.7738697
Z variance eval              0.02026751
total_rewards                [ 54.55975132 433.86749084 535.2733309  184.46343164 213.97248889
 141.55532036 165.39954972 394.88310947 367.85811088 254.94852482]
total_rewards_mean           274.67811088467937
total_rewards_std            143.77467525012491
total_rewards_max            535.2733308981489
total_rewards_min            54.55975131777895
Number of train steps total  31000
Number of env steps total    157000
Number of rollouts total     0
Train Time (s)               24.487768333870918
(Previous) Eval Time (s)     24.003323103301227
Sample Time (s)              18.0525656118989
Epoch Time (s)               66.54365704907104
Total Train Time (s)         2084.4483446185477
Epoch                        30
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:50:15.823069 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #30 | Epoch Duration: 63.37422823905945
2020-01-11 03:50:15.823254 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #30 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.77263224
Z variance train             0.020372901
KL Divergence                14.40239
KL Loss                      1.440239
QF Loss                      117.51446
VF Loss                      68.321045
Policy Loss                  -293.63455
Q Predictions Mean           290.57843
Q Predictions Std            39.236668
Q Predictions Max            341.0071
Q Predictions Min            -13.509363
V Predictions Mean           291.88507
V Predictions Std            37.814137
V Predictions Max            343.72836
V Predictions Min            -41.970776
Log Pis Mean                 -2.8492913
Log Pis Std                  1.6587346
Log Pis Max                  4.0810885
Log Pis Min                  -7.394895
Policy mu Mean               0.094547614
Policy mu Std                0.34680784
Policy mu Max                2.4639869
Policy mu Min                -2.2069185
Policy log std Mean          -0.74679935
Policy log std Std           0.15543489
Policy log std Max           0.01631555
Policy log std Min           -1.7076864
Z mean eval                  0.7985636
Z variance eval              0.016128482
total_rewards                [239.64708349 226.44496784 334.24396764 516.68411483 320.11940186
 353.46401003 478.51475961 209.23942832 201.41039963 239.91803593]
total_rewards_mean           311.9686169178049
total_rewards_std            106.03911424414076
total_rewards_max            516.6841148295854
total_rewards_min            201.41039962678082
Number of train steps total  32000
Number of env steps total    162000
Number of rollouts total     0
Train Time (s)               26.230613856576383
(Previous) Eval Time (s)     20.83361671678722
Sample Time (s)              19.155642635654658
Epoch Time (s)               66.21987320901826
Total Train Time (s)         2156.641087961849
Epoch                        31
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:51:28.018149 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #31 | Epoch Duration: 72.19473576545715
2020-01-11 03:51:28.018358 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #31 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.796374
Z variance train             0.016122315
KL Divergence                15.027939
KL Loss                      1.5027939
QF Loss                      156.96738
VF Loss                      50.340324
Policy Loss                  -297.0927
Q Predictions Mean           295.10446
Q Predictions Std            21.458134
Q Predictions Max            363.33072
Q Predictions Min            226.10008
V Predictions Mean           302.11597
V Predictions Std            22.42754
V Predictions Max            367.20236
V Predictions Min            220.77332
Log Pis Mean                 -2.9117777
Log Pis Std                  1.6610363
Log Pis Max                  2.6073208
Log Pis Min                  -9.355399
Policy mu Mean               0.02291039
Policy mu Std                0.31791502
Policy mu Max                1.1057758
Policy mu Min                -1.0338318
Policy log std Mean          -0.77831364
Policy log std Std           0.1477217
Policy log std Max           -0.33850408
Policy log std Min           -1.5744648
Z mean eval                  0.81349814
Z variance eval              0.014644829
total_rewards                [256.97508517 231.03154218 180.60297095 186.67219733 372.56212197
 397.95959293 150.22484902 155.50275539 181.3563338   28.33417146]
total_rewards_mean           214.122162019577
total_rewards_std            102.96049590941092
total_rewards_max            397.9595929273419
total_rewards_min            28.334171461525862
Number of train steps total  33000
Number of env steps total    167000
Number of rollouts total     0
Train Time (s)               27.5904444437474
(Previous) Eval Time (s)     26.80814232910052
Sample Time (s)              19.245804839767516
Epoch Time (s)               73.64439161261544
Total Train Time (s)         2229.246109861415
Epoch                        32
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:52:40.626941 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #32 | Epoch Duration: 72.60826778411865
2020-01-11 03:52:40.627391 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #32 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.81126225
Z variance train             0.014692453
KL Divergence                14.8645
KL Loss                      1.4864501
QF Loss                      94.33034
VF Loss                      54.623405
Policy Loss                  -301.4431
Q Predictions Mean           300.48248
Q Predictions Std            33.928215
Q Predictions Max            358.8151
Q Predictions Min            -13.603962
V Predictions Mean           306.88742
V Predictions Std            29.111578
V Predictions Max            366.88916
V Predictions Min            56.27022
Log Pis Mean                 -3.159423
Log Pis Std                  1.6764936
Log Pis Max                  5.0393066
Log Pis Min                  -9.460457
Policy mu Mean               0.061121017
Policy mu Std                0.29598722
Policy mu Max                1.3468851
Policy mu Min                -1.4158834
Policy log std Mean          -0.75133514
Policy log std Std           0.12773114
Policy log std Max           -0.3566537
Policy log std Min           -1.4091214
Z mean eval                  0.79580534
Z variance eval              0.0118832365
total_rewards                [316.34061312  44.72056029 200.31792138  47.01018111 295.43119991
 539.78931339 536.00526097 177.71493012 231.0851563  413.63402648]
total_rewards_mean           280.20491630463926
total_rewards_std            167.7171362089707
total_rewards_max            539.7893133924937
total_rewards_min            44.720560286652955
Number of train steps total  34000
Number of env steps total    172000
Number of rollouts total     0
Train Time (s)               25.725533698685467
(Previous) Eval Time (s)     25.771705746185035
Sample Time (s)              18.984671857208014
Epoch Time (s)               70.48191130207852
Total Train Time (s)         2296.080437990371
Epoch                        33
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:53:47.461712 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #33 | Epoch Duration: 66.83406281471252
2020-01-11 03:53:47.461944 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #33 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.79991406
Z variance train             0.011840081
KL Divergence                15.390139
KL Loss                      1.5390139
QF Loss                      302.37915
VF Loss                      94.49457
Policy Loss                  -308.41412
Q Predictions Mean           303.8765
Q Predictions Std            34.93788
Q Predictions Max            391.10727
Q Predictions Min            -2.4655972
V Predictions Mean           301.9819
V Predictions Std            34.58567
V Predictions Max            394.09283
V Predictions Min            15.07126
Log Pis Mean                 -2.829511
Log Pis Std                  1.5562015
Log Pis Max                  6.277613
Log Pis Min                  -8.520113
Policy mu Mean               0.029291047
Policy mu Std                0.328224
Policy mu Max                1.155629
Policy mu Min                -3.037689
Policy log std Mean          -0.7708024
Policy log std Std           0.13806044
Policy log std Max           -0.3984789
Policy log std Min           -1.7296336
Z mean eval                  0.7997624
Z variance eval              0.011469017
total_rewards                [613.62049689 204.33169356 474.81927735 102.48343758 217.87224871
 273.01423844 322.80671268 285.76910522 284.26520713 276.52315761]
total_rewards_mean           305.55055751748057
total_rewards_std            136.29795868105407
total_rewards_max            613.6204968937537
total_rewards_min            102.48343758005977
Number of train steps total  35000
Number of env steps total    177000
Number of rollouts total     0
Train Time (s)               27.72141413995996
(Previous) Eval Time (s)     22.123562355991453
Sample Time (s)              18.45872044097632
Epoch Time (s)               68.30369693692774
Total Train Time (s)         2365.585138650611
Epoch                        34
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:54:56.969721 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #34 | Epoch Duration: 69.50745248794556
2020-01-11 03:54:56.970142 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #34 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7988483
Z variance train             0.01149949
KL Divergence                15.380762
KL Loss                      1.5380763
QF Loss                      162.1677
VF Loss                      38.29681
Policy Loss                  -308.3271
Q Predictions Mean           305.653
Q Predictions Std            38.80897
Q Predictions Max            373.50406
Q Predictions Min            0.24111721
V Predictions Mean           307.42456
V Predictions Std            35.298454
V Predictions Max            369.7358
V Predictions Min            -9.853882
Log Pis Mean                 -2.759622
Log Pis Std                  1.9448377
Log Pis Max                  8.825727
Log Pis Min                  -8.228796
Policy mu Mean               0.051096562
Policy mu Std                0.32848912
Policy mu Max                1.6467946
Policy mu Min                -1.8291388
Policy log std Mean          -0.7750391
Policy log std Std           0.142983
Policy log std Max           -0.37977204
Policy log std Min           -1.8589388
Z mean eval                  0.7863915
Z variance eval              0.014677035
total_rewards                [ 45.42789095  57.74303645 129.28560598 295.98736002 309.27049057
 133.33979033 294.45675153 347.4381112  188.12374443 222.39329683]
total_rewards_mean           202.34660782963434
total_rewards_std            102.94407078328433
total_rewards_max            347.4381112027812
total_rewards_min            45.42789094730747
Number of train steps total  36000
Number of env steps total    182000
Number of rollouts total     0
Train Time (s)               28.903704093769193
(Previous) Eval Time (s)     23.326994626782835
Sample Time (s)              18.512391277123243
Epoch Time (s)               70.74308999767527
Total Train Time (s)         2431.3872176506557
Epoch                        35
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:56:02.774772 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #35 | Epoch Duration: 65.8043463230133
2020-01-11 03:56:02.775109 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #35 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7817628
Z variance train             0.014581867
KL Divergence                15.103876
KL Loss                      1.5103877
QF Loss                      163.1334
VF Loss                      58.873985
Policy Loss                  -310.9073
Q Predictions Mean           307.81152
Q Predictions Std            34.372643
Q Predictions Max            394.34625
Q Predictions Min            -1.195832
V Predictions Mean           316.51532
V Predictions Std            31.102024
V Predictions Max            399.46677
V Predictions Min            28.62391
Log Pis Mean                 -3.081427
Log Pis Std                  1.8621163
Log Pis Max                  6.7654676
Log Pis Min                  -10.327641
Policy mu Mean               0.06354298
Policy mu Std                0.31919622
Policy mu Max                1.2899609
Policy mu Min                -1.4253762
Policy log std Mean          -0.7758134
Policy log std Std           0.13305938
Policy log std Max           -0.4254352
Policy log std Min           -1.9822227
Z mean eval                  0.8120845
Z variance eval              0.01190261
total_rewards                [562.957137   574.08100413 228.13345458 232.80350897 242.24291575
 256.71578652   7.82587268  95.4400667  178.3115125  229.17575981]
total_rewards_mean           260.7687018640612
total_rewards_std            170.52862687615837
total_rewards_max            574.0810041313963
total_rewards_min            7.825872676862154
Number of train steps total  37000
Number of env steps total    187000
Number of rollouts total     0
Train Time (s)               30.29506926704198
(Previous) Eval Time (s)     18.387960937805474
Sample Time (s)              19.088959247339517
Epoch Time (s)               67.77198945218697
Total Train Time (s)         2501.7840570546687
Epoch                        36
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:57:13.171645 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #36 | Epoch Duration: 70.39615535736084
2020-01-11 03:57:13.172011 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #36 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.81133974
Z variance train             0.011868821
KL Divergence                15.486149
KL Loss                      1.5486149
QF Loss                      130.61353
VF Loss                      41.77863
Policy Loss                  -316.76913
Q Predictions Mean           311.59702
Q Predictions Std            44.480675
Q Predictions Max            369.1749
Q Predictions Min            -24.94041
V Predictions Mean           317.10315
V Predictions Std            34.655445
V Predictions Max            377.9884
V Predictions Min            22.854246
Log Pis Mean                 -2.9062238
Log Pis Std                  1.7159638
Log Pis Max                  6.569688
Log Pis Min                  -7.122958
Policy mu Mean               0.044092387
Policy mu Std                0.31266814
Policy mu Max                1.1552476
Policy mu Min                -1.6050397
Policy log std Mean          -0.76144445
Policy log std Std           0.15449
Policy log std Max           -0.3784804
Policy log std Min           -1.9403936
Z mean eval                  0.7899966
Z variance eval              0.015322109
total_rewards                [ 71.78107232  52.17822558 259.90110502 195.36848702 260.41572054
 248.18817227 537.55232662 126.55112909 344.49930133 425.06950693]
total_rewards_mean           252.15050467329792
total_rewards_std            145.4472455712616
total_rewards_max            537.5523266249579
total_rewards_min            52.17822558209087
Number of train steps total  38000
Number of env steps total    192000
Number of rollouts total     0
Train Time (s)               26.654523170087487
(Previous) Eval Time (s)     21.01183094503358
Sample Time (s)              18.40460590366274
Epoch Time (s)               66.07096001878381
Total Train Time (s)         2568.8169862418436
Epoch                        37
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:58:20.205346 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #37 | Epoch Duration: 67.033123254776
2020-01-11 03:58:20.205581 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #37 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7898148
Z variance train             0.015410727
KL Divergence                15.478196
KL Loss                      1.5478196
QF Loss                      109.59188
VF Loss                      82.6082
Policy Loss                  -319.04422
Q Predictions Mean           316.33594
Q Predictions Std            34.28622
Q Predictions Max            396.79272
Q Predictions Min            31.516495
V Predictions Mean           324.83624
V Predictions Std            29.43903
V Predictions Max            402.11508
V Predictions Min            112.826454
Log Pis Mean                 -2.7948074
Log Pis Std                  1.7569478
Log Pis Max                  4.8748126
Log Pis Min                  -7.731574
Policy mu Mean               0.05564673
Policy mu Std                0.32502094
Policy mu Max                2.196056
Policy mu Min                -1.7143375
Policy log std Mean          -0.7788903
Policy log std Std           0.14874274
Policy log std Max           -0.37732953
Policy log std Min           -1.9650885
Z mean eval                  0.7974572
Z variance eval              0.016433844
total_rewards                [536.71314164 373.74217949 197.56421407 628.89521622 279.18873869
 455.13693211 192.76406104 315.65564778 375.76890744 216.61326418]
total_rewards_mean           357.20423026537543
total_rewards_std            140.12581190152017
total_rewards_max            628.8952162185373
total_rewards_min            192.76406104015865
Number of train steps total  39000
Number of env steps total    197000
Number of rollouts total     0
Train Time (s)               25.172023478895426
(Previous) Eval Time (s)     21.97370264073834
Sample Time (s)              17.87066791485995
Epoch Time (s)               65.01639403449371
Total Train Time (s)         2637.585715209134
Epoch                        38
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:59:28.975094 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #38 | Epoch Duration: 68.76926612854004
2020-01-11 03:59:28.975346 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #38 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7983228
Z variance train             0.016434748
KL Divergence                15.439045
KL Loss                      1.5439045
QF Loss                      166.85406
VF Loss                      35.512405
Policy Loss                  -322.5543
Q Predictions Mean           317.89627
Q Predictions Std            37.074757
Q Predictions Max            396.14148
Q Predictions Min            -5.249235
V Predictions Mean           319.91785
V Predictions Std            33.430374
V Predictions Max            393.24738
V Predictions Min            0.78805536
Log Pis Mean                 -2.8286085
Log Pis Std                  1.6550952
Log Pis Max                  1.6653223
Log Pis Min                  -9.006538
Policy mu Mean               0.044833552
Policy mu Std                0.3074588
Policy mu Max                1.9553895
Policy mu Min                -1.6371406
Policy log std Mean          -0.8154963
Policy log std Std           0.14278194
Policy log std Max           -0.48251134
Policy log std Min           -1.5990126
Z mean eval                  0.8081606
Z variance eval              0.014622383
total_rewards                [345.06697124  47.19311089 174.00043865 483.69279695 633.43899052
 166.92123444 500.33033638 171.31981944  64.10140449 241.50263285]
total_rewards_mean           282.7567735846487
total_rewards_std            189.0080526671105
total_rewards_max            633.4389905222487
total_rewards_min            47.1931108947941
Number of train steps total  40000
Number of env steps total    202000
Number of rollouts total     0
Train Time (s)               28.036943424958736
(Previous) Eval Time (s)     25.726241477765143
Sample Time (s)              19.01010990748182
Epoch Time (s)               72.7732948102057
Total Train Time (s)         2700.247945719864
Epoch                        39
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:00:31.637588 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #39 | Epoch Duration: 62.66209578514099
2020-01-11 04:00:31.637748 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #39 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8079885
Z variance train             0.014617458
KL Divergence                16.042326
KL Loss                      1.6042327
QF Loss                      167.35788
VF Loss                      57.86468
Policy Loss                  -326.64975
Q Predictions Mean           325.07526
Q Predictions Std            29.81944
Q Predictions Max            398.6382
Q Predictions Min            8.82721
V Predictions Mean           328.19287
V Predictions Std            29.824434
V Predictions Max            396.4111
V Predictions Min            14.335817
Log Pis Mean                 -2.7607412
Log Pis Std                  1.6911871
Log Pis Max                  7.8218927
Log Pis Min                  -9.400939
Policy mu Mean               0.021489475
Policy mu Std                0.30881
Policy mu Max                1.4851677
Policy mu Min                -1.5512114
Policy log std Mean          -0.8194401
Policy log std Std           0.15004666
Policy log std Max           -0.3715225
Policy log std Min           -1.8778483
Z mean eval                  0.8223106
Z variance eval              0.018016908
total_rewards                [540.41390684 431.21243277 348.37967472 293.56634132 249.90750478
 175.3651696  482.62280222 451.98019292 114.454731   140.48736145]
total_rewards_mean           322.8390117627205
total_rewards_std            143.7166740810801
total_rewards_max            540.4139068448112
total_rewards_min            114.45473099683792
Number of train steps total  41000
Number of env steps total    207000
Number of rollouts total     0
Train Time (s)               29.03519000299275
(Previous) Eval Time (s)     15.614734085276723
Sample Time (s)              19.301058046519756
Epoch Time (s)               63.95098213478923
Total Train Time (s)         2773.10077460343
Epoch                        40
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:01:44.491513 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #40 | Epoch Duration: 72.85361576080322
2020-01-11 04:01:44.491708 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #40 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8193482
Z variance train             0.017992038
KL Divergence                16.006649
KL Loss                      1.600665
QF Loss                      161.56693
VF Loss                      24.728008
Policy Loss                  -336.85867
Q Predictions Mean           334.33038
Q Predictions Std            43.966064
Q Predictions Max            403.11295
Q Predictions Min            -8.226973
V Predictions Mean           335.48346
V Predictions Std            42.162888
V Predictions Max            405.11862
V Predictions Min            10.233463
Log Pis Mean                 -2.8226914
Log Pis Std                  1.8026079
Log Pis Max                  6.9778595
Log Pis Min                  -7.835019
Policy mu Mean               -0.0381509
Policy mu Std                0.3290929
Policy mu Max                1.9216088
Policy mu Min                -2.406027
Policy log std Mean          -0.7865526
Policy log std Std           0.14197198
Policy log std Max           -0.40670907
Policy log std Min           -1.8371272
Z mean eval                  0.80505645
Z variance eval              0.019476179
total_rewards                [283.9381733  373.83402489 310.91622822 296.18495913   6.59562442
 249.87479839 272.39814875 273.40140045 187.59148502 161.18304408]
total_rewards_mean           241.5917886645015
total_rewards_std            96.79969276625931
total_rewards_max            373.83402488904153
total_rewards_min            6.595624421566688
Number of train steps total  42000
Number of env steps total    212000
Number of rollouts total     0
Train Time (s)               28.013907020911574
(Previous) Eval Time (s)     24.51706035900861
Sample Time (s)              18.56665640231222
Epoch Time (s)               71.0976237822324
Total Train Time (s)         2843.3488158369437
Epoch                        41
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:02:54.741840 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #41 | Epoch Duration: 70.2499487400055
2020-01-11 04:02:54.742063 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #41 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.80466795
Z variance train             0.01948788
KL Divergence                15.912004
KL Loss                      1.5912005
QF Loss                      144.39706
VF Loss                      42.652977
Policy Loss                  -333.73587
Q Predictions Mean           330.41544
Q Predictions Std            40.99793
Q Predictions Max            417.51883
Q Predictions Min            -29.792728
V Predictions Mean           333.12418
V Predictions Std            35.858604
V Predictions Max            412.97647
V Predictions Min            11.747393
Log Pis Mean                 -2.883854
Log Pis Std                  1.4496377
Log Pis Max                  0.33044976
Log Pis Min                  -8.31875
Policy mu Mean               0.0137185
Policy mu Std                0.30322617
Policy mu Max                1.9117794
Policy mu Min                -1.1377403
Policy log std Mean          -0.77417314
Policy log std Std           0.13503987
Policy log std Max           -0.43046707
Policy log std Min           -1.5060688
Z mean eval                  0.80447114
Z variance eval              0.014865798
total_rewards                [408.62420141 368.68903947 264.63955903 511.62359111 365.47792879
 313.99455755  58.54559514 563.18343605 440.2217012  320.11120427]
total_rewards_mean           361.51108140318837
total_rewards_std            132.97808785098442
total_rewards_max            563.1834360542979
total_rewards_min            58.54559514307448
Number of train steps total  43000
Number of env steps total    217000
Number of rollouts total     0
Train Time (s)               28.422670356929302
(Previous) Eval Time (s)     23.66909060627222
Sample Time (s)              18.180722386110574
Epoch Time (s)               70.2724833493121
Total Train Time (s)         2914.514129581861
Epoch                        42
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:04:05.910801 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #42 | Epoch Duration: 71.16855001449585
2020-01-11 04:04:05.911068 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #42 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8047541
Z variance train             0.014865035
KL Divergence                16.736244
KL Loss                      1.6736244
QF Loss                      127.78496
VF Loss                      40.17981
Policy Loss                  -326.85928
Q Predictions Mean           323.7555
Q Predictions Std            56.507496
Q Predictions Max            413.1879
Q Predictions Min            -17.320232
V Predictions Mean           325.77597
V Predictions Std            55.91823
V Predictions Max            410.69055
V Predictions Min            -15.517127
Log Pis Mean                 -2.7433496
Log Pis Std                  1.90336
Log Pis Max                  7.45051
Log Pis Min                  -9.23304
Policy mu Mean               0.03163413
Policy mu Std                0.33421305
Policy mu Max                1.7226882
Policy mu Min                -1.506763
Policy log std Mean          -0.7825661
Policy log std Std           0.15049206
Policy log std Max           -0.280898
Policy log std Min           -1.477716
Z mean eval                  0.81466657
Z variance eval              0.013608192
total_rewards                [ 49.79803576 209.27814045 218.2297276  153.68945515 166.1919987
  88.33252521 381.57950853 417.77242348 180.57350969 253.06679913]
total_rewards_mean           211.85121236984727
total_rewards_std            109.96418374024914
total_rewards_max            417.77242348311506
total_rewards_min            49.798035762160204
Number of train steps total  44000
Number of env steps total    222000
Number of rollouts total     0
Train Time (s)               29.331219749059528
(Previous) Eval Time (s)     24.564867781940848
Sample Time (s)              18.967769879847765
Epoch Time (s)               72.86385741084814
Total Train Time (s)         2984.001841260586
Epoch                        43
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:05:15.397010 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #43 | Epoch Duration: 69.48574686050415
2020-01-11 04:05:15.397159 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #43 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8160682
Z variance train             0.013625774
KL Divergence                16.32885
KL Loss                      1.632885
QF Loss                      255.94595
VF Loss                      44.688625
Policy Loss                  -342.26056
Q Predictions Mean           337.87164
Q Predictions Std            41.254486
Q Predictions Max            411.46725
Q Predictions Min            -0.6582997
V Predictions Mean           338.075
V Predictions Std            39.200317
V Predictions Max            405.34903
V Predictions Min            28.975967
Log Pis Mean                 -2.9625201
Log Pis Std                  1.7323954
Log Pis Max                  6.698341
Log Pis Min                  -7.926832
Policy mu Mean               0.017039597
Policy mu Std                0.3164579
Policy mu Max                1.5591819
Policy mu Min                -1.4768586
Policy log std Mean          -0.7645022
Policy log std Std           0.15865351
Policy log std Max           -0.43566164
Policy log std Min           -1.8523582
Z mean eval                  0.80745
Z variance eval              0.0133001935
total_rewards                [354.11550925 228.64433135 538.22651482 277.80450944 189.3347526
 353.43339702 258.86359118 237.88790688 217.86319425 306.07016222]
total_rewards_mean           296.2243869019182
total_rewards_std            96.20676809973236
total_rewards_max            538.2265148209417
total_rewards_min            189.33475259994094
Number of train steps total  45000
Number of env steps total    227000
Number of rollouts total     0
Train Time (s)               27.89505500625819
(Previous) Eval Time (s)     21.186477091163397
Sample Time (s)              17.728863310534507
Epoch Time (s)               66.8103954079561
Total Train Time (s)         3054.738431226928
Epoch                        44
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:06:26.136825 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #44 | Epoch Duration: 70.73952651023865
2020-01-11 04:06:26.137029 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #44 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.80768555
Z variance train             0.013281028
KL Divergence                15.95775
KL Loss                      1.595775
QF Loss                      149.64413
VF Loss                      26.272923
Policy Loss                  -344.98923
Q Predictions Mean           342.93982
Q Predictions Std            25.082594
Q Predictions Max            409.33603
Q Predictions Min            258.07874
V Predictions Mean           346.7558
V Predictions Std            25.051443
V Predictions Max            403.9058
V Predictions Min            278.45062
Log Pis Mean                 -2.9411578
Log Pis Std                  1.6731529
Log Pis Max                  3.4907334
Log Pis Min                  -9.002154
Policy mu Mean               0.028811894
Policy mu Std                0.31374604
Policy mu Max                1.1324953
Policy mu Min                -1.0065082
Policy log std Mean          -0.7649702
Policy log std Std           0.13746597
Policy log std Max           -0.3206239
Policy log std Min           -1.6561513
Z mean eval                  0.8091407
Z variance eval              0.012542789
total_rewards                [241.74422359 550.88150603 339.62393306 359.95970935 367.1793015
 414.01205891 330.05686164 595.56996895 487.79204563 197.60972812]
total_rewards_mean           388.4429336768436
total_rewards_std            120.33512079738715
total_rewards_max            595.5699689460167
total_rewards_min            197.60972811652198
Number of train steps total  46000
Number of env steps total    232000
Number of rollouts total     0
Train Time (s)               26.81837469385937
(Previous) Eval Time (s)     25.115316424984485
Sample Time (s)              18.93168356223032
Epoch Time (s)               70.86537468107417
Total Train Time (s)         3127.171344930306
Epoch                        45
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:07:38.569058 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #45 | Epoch Duration: 72.43187808990479
2020-01-11 04:07:38.569259 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #45 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.80856675
Z variance train             0.0125403255
KL Divergence                16.21865
KL Loss                      1.6218652
QF Loss                      139.58688
VF Loss                      28.012146
Policy Loss                  -350.12186
Q Predictions Mean           348.65607
Q Predictions Std            26.126358
Q Predictions Max            416.1751
Q Predictions Min            244.68503
V Predictions Mean           352.50037
V Predictions Std            26.278131
V Predictions Max            417.64362
V Predictions Min            222.86711
Log Pis Mean                 -2.8541505
Log Pis Std                  1.716267
Log Pis Max                  1.8113286
Log Pis Min                  -8.604999
Policy mu Mean               0.023205679
Policy mu Std                0.31586716
Policy mu Max                1.2589817
Policy mu Min                -1.6372228
Policy log std Mean          -0.7945501
Policy log std Std           0.15248863
Policy log std Max           -0.37793043
Policy log std Min           -1.863426
Z mean eval                  0.8111132
Z variance eval              0.010555501
total_rewards                [249.56712657 152.07501166 194.50436514 228.89942055 291.49648855
 573.4394406  309.79550791 660.84034873 744.46120664  97.68934437]
total_rewards_mean           350.2768260728431
total_rewards_std            214.23137447338863
total_rewards_max            744.4612066404208
total_rewards_min            97.68934437385919
Number of train steps total  47000
Number of env steps total    237000
Number of rollouts total     0
Train Time (s)               28.66368319839239
(Previous) Eval Time (s)     26.681495619937778
Sample Time (s)              18.397144082468003
Epoch Time (s)               73.74232290079817
Total Train Time (s)         3196.7352440180257
Epoch                        46
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:08:48.136468 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #46 | Epoch Duration: 69.5670690536499
2020-01-11 04:08:48.136682 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #46 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8118909
Z variance train             0.010583001
KL Divergence                15.769209
KL Loss                      1.5769209
QF Loss                      117.72101
VF Loss                      78.06004
Policy Loss                  -342.88007
Q Predictions Mean           339.09918
Q Predictions Std            46.152805
Q Predictions Max            404.5696
Q Predictions Min            -15.46731
V Predictions Mean           340.13678
V Predictions Std            43.8095
V Predictions Max            400.7169
V Predictions Min            11.976256
Log Pis Mean                 -2.7085493
Log Pis Std                  1.9521893
Log Pis Max                  8.936626
Log Pis Min                  -10.183688
Policy mu Mean               0.020117454
Policy mu Std                0.33511204
Policy mu Max                1.3021035
Policy mu Min                -1.915746
Policy log std Mean          -0.8023311
Policy log std Std           0.16438335
Policy log std Max           -0.39728487
Policy log std Min           -1.9137367
Z mean eval                  0.82143945
Z variance eval              0.01807115
total_rewards                [615.19150152 135.12793738 633.09307315 159.1462093  119.19813569
 276.27779596 303.39894628 499.77617544 246.71191014 657.1564983 ]
total_rewards_mean           364.5078183158213
total_rewards_std            204.76356955480554
total_rewards_max            657.15649830361
total_rewards_min            119.19813568984974
Number of train steps total  48000
Number of env steps total    242000
Number of rollouts total     0
Train Time (s)               25.682717863004655
(Previous) Eval Time (s)     22.50592914223671
Sample Time (s)              17.555466641671956
Epoch Time (s)               65.74411364691332
Total Train Time (s)         3265.559481624514
Epoch                        47
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:09:56.960741 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #47 | Epoch Duration: 68.82388639450073
2020-01-11 04:09:56.960947 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #47 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8214429
Z variance train             0.018125918
KL Divergence                15.560294
KL Loss                      1.5560294
QF Loss                      179.20407
VF Loss                      63.21602
Policy Loss                  -351.1158
Q Predictions Mean           348.93915
Q Predictions Std            48.579987
Q Predictions Max            417.58456
Q Predictions Min            -30.448668
V Predictions Mean           349.12338
V Predictions Std            44.253365
V Predictions Max            418.45035
V Predictions Min            18.444342
Log Pis Mean                 -2.6299314
Log Pis Std                  2.077522
Log Pis Max                  7.7849517
Log Pis Min                  -8.790115
Policy mu Mean               0.053459365
Policy mu Std                0.35244325
Policy mu Max                1.4417102
Policy mu Min                -1.3777083
Policy log std Mean          -0.80529803
Policy log std Std           0.17368759
Policy log std Max           -0.3838036
Policy log std Min           -2.0088515
Z mean eval                  0.81672823
Z variance eval              0.017194733
total_rewards                [727.83264865 258.0930308  304.6647673  339.52254177 236.49704929
 199.44752781 662.90212461 265.94563619 302.68272629 317.99428068]
total_rewards_mean           361.55823333928436
total_rewards_std            171.99379845557598
total_rewards_max            727.8326486489648
total_rewards_min            199.44752780897386
Number of train steps total  49000
Number of env steps total    247000
Number of rollouts total     0
Train Time (s)               26.925372815225273
(Previous) Eval Time (s)     25.58542653499171
Sample Time (s)              18.476802026387304
Epoch Time (s)               70.98760137660429
Total Train Time (s)         3338.6976445335895
Epoch                        48
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:11:10.101632 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #48 | Epoch Duration: 73.14047741889954
2020-01-11 04:11:10.101902 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #48 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8158151
Z variance train             0.017109035
KL Divergence                15.817215
KL Loss                      1.5817215
QF Loss                      110.25838
VF Loss                      20.09011
Policy Loss                  -355.70767
Q Predictions Mean           352.1467
Q Predictions Std            33.769714
Q Predictions Max            432.2449
Q Predictions Min            37.913918
V Predictions Mean           357.67252
V Predictions Std            31.377342
V Predictions Max            435.64667
V Predictions Min            102.11248
Log Pis Mean                 -2.9049096
Log Pis Std                  1.5759073
Log Pis Max                  1.6533121
Log Pis Min                  -7.8071785
Policy mu Mean               0.029004619
Policy mu Std                0.32637748
Policy mu Max                1.058201
Policy mu Min                -1.1328586
Policy log std Mean          -0.79439384
Policy log std Std           0.14301819
Policy log std Max           -0.4222151
Policy log std Min           -1.5190759
Z mean eval                  0.81187755
Z variance eval              0.012928223
total_rewards                [210.47871588 396.48877058 597.46306046 430.42108332 512.4578254
 530.48121644 458.78676676 391.11437051 417.79445135 691.92866502]
total_rewards_mean           463.74149257157006
total_rewards_std            124.08219305123683
total_rewards_max            691.9286650189233
total_rewards_min            210.47871587896597
Number of train steps total  50000
Number of env steps total    252000
Number of rollouts total     0
Train Time (s)               30.39946267893538
(Previous) Eval Time (s)     27.738010487053543
Sample Time (s)              19.733163479249924
Epoch Time (s)               77.87063664523885
Total Train Time (s)         3415.9294491847977
Epoch                        49
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:12:27.334150 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #49 | Epoch Duration: 77.2320442199707
2020-01-11 04:12:27.334364 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #49 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8113245
Z variance train             0.012908128
KL Divergence                15.4984045
KL Loss                      1.5498405
QF Loss                      194.04723
VF Loss                      31.30147
Policy Loss                  -360.51608
Q Predictions Mean           357.312
Q Predictions Std            40.16957
Q Predictions Max            431.6584
Q Predictions Min            13.899
V Predictions Mean           357.53558
V Predictions Std            38.863045
V Predictions Max            428.07556
V Predictions Min            23.052252
Log Pis Mean                 -2.7640061
Log Pis Std                  1.8062696
Log Pis Max                  4.8727636
Log Pis Min                  -8.365217
Policy mu Mean               0.08199888
Policy mu Std                0.3201614
Policy mu Max                1.2813345
Policy mu Min                -1.3649118
Policy log std Mean          -0.81012154
Policy log std Std           0.16022435
Policy log std Max           -0.42266536
Policy log std Min           -1.7561952
Z mean eval                  0.8316635
Z variance eval              0.012104737
total_rewards                [ 54.0296543  491.79148091 708.82644542 289.20677933 664.72353513
 811.45767175 258.83968129 550.36202224 107.6636794  450.38516043]
total_rewards_mean           438.7286110190477
total_rewards_std            243.0393264122654
total_rewards_max            811.4576717460009
total_rewards_min            54.029654295447585
Number of train steps total  51000
Number of env steps total    257000
Number of rollouts total     0
Train Time (s)               28.772571854293346
(Previous) Eval Time (s)     27.09911274118349
Sample Time (s)              18.30313781509176
Epoch Time (s)               74.1748224105686
Total Train Time (s)         3485.8598514515907
Epoch                        50
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:13:37.266541 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #50 | Epoch Duration: 69.93200588226318
2020-01-11 04:13:37.266770 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #50 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8266894
Z variance train             0.012080883
KL Divergence                15.675956
KL Loss                      1.5675956
QF Loss                      188.996
VF Loss                      31.42228
Policy Loss                  -360.41672
Q Predictions Mean           357.58374
Q Predictions Std            32.11384
Q Predictions Max            426.88705
Q Predictions Min            200.05238
V Predictions Mean           363.2622
V Predictions Std            30.579529
V Predictions Max            434.6431
V Predictions Min            271.17343
Log Pis Mean                 -2.8963144
Log Pis Std                  1.7817934
Log Pis Max                  5.642202
Log Pis Min                  -9.486546
Policy mu Mean               0.057754714
Policy mu Std                0.33287537
Policy mu Max                1.3287252
Policy mu Min                -1.0251387
Policy log std Mean          -0.78318745
Policy log std Std           0.17157407
Policy log std Max           -0.36391857
Policy log std Min           -1.9735897
Z mean eval                  0.81960773
Z variance eval              0.014349001
total_rewards                [178.29719185 140.63071294   8.16026862 129.70734493 264.18297455
 630.19615637 352.05349031 234.65925999 530.82445788 441.35391988]
total_rewards_mean           291.00657773188294
total_rewards_std            185.50567217332545
total_rewards_max            630.1961563668647
total_rewards_min            8.160268622085578
Number of train steps total  52000
Number of env steps total    262000
Number of rollouts total     0
Train Time (s)               27.097180482931435
(Previous) Eval Time (s)     22.8559861429967
Sample Time (s)              18.228359398897737
Epoch Time (s)               68.18152602482587
Total Train Time (s)         3551.5646804757416
Epoch                        51
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:14:42.975483 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #51 | Epoch Duration: 65.70852708816528
2020-01-11 04:14:42.975715 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #51 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.81719697
Z variance train             0.014450093
KL Divergence                15.140713
KL Loss                      1.5140713
QF Loss                      279.7078
VF Loss                      54.09053
Policy Loss                  -364.2611
Q Predictions Mean           362.17166
Q Predictions Std            45.573833
Q Predictions Max            476.99286
Q Predictions Min            -20.259342
V Predictions Mean           370.0345
V Predictions Std            38.979935
V Predictions Max            485.88107
V Predictions Min            21.019634
Log Pis Mean                 -2.679289
Log Pis Std                  1.8405964
Log Pis Max                  5.0956354
Log Pis Min                  -8.898292
Policy mu Mean               0.06348329
Policy mu Std                0.33507285
Policy mu Max                1.2487913
Policy mu Min                -2.2944024
Policy log std Mean          -0.7961225
Policy log std Std           0.14486061
Policy log std Max           -0.392954
Policy log std Min           -1.5724276
Z mean eval                  0.8213089
Z variance eval              0.011591291
total_rewards                [610.01486088 176.98900544 625.56804753 396.62098791  54.49295519
 321.32888739 384.81939572 374.14092264 283.07823274  89.70129437]
total_rewards_mean           331.6754589805428
total_rewards_std            182.8850647793886
total_rewards_max            625.5680475260699
total_rewards_min            54.492955187967546
Number of train steps total  53000
Number of env steps total    267000
Number of rollouts total     0
Train Time (s)               26.443884385749698
(Previous) Eval Time (s)     20.38270544121042
Sample Time (s)              18.224346722941846
Epoch Time (s)               65.05093654990196
Total Train Time (s)         3616.714787494391
Epoch                        52
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:15:48.122921 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #52 | Epoch Duration: 65.14703702926636
2020-01-11 04:15:48.123073 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #52 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.82217824
Z variance train             0.011541474
KL Divergence                15.766862
KL Loss                      1.5766863
QF Loss                      384.86478
VF Loss                      89.37344
Policy Loss                  -368.6933
Q Predictions Mean           362.84222
Q Predictions Std            45.695724
Q Predictions Max            455.681
Q Predictions Min            -56.865784
V Predictions Mean           369.2723
V Predictions Std            30.01864
V Predictions Max            460.087
V Predictions Min            262.13165
Log Pis Mean                 -2.636076
Log Pis Std                  1.8560567
Log Pis Max                  8.459513
Log Pis Min                  -10.605503
Policy mu Mean               0.077479325
Policy mu Std                0.34189698
Policy mu Max                1.4084789
Policy mu Min                -1.0579523
Policy log std Mean          -0.7975232
Policy log std Std           0.16050014
Policy log std Max           -0.40379748
Policy log std Min           -2.2999294
Z mean eval                  0.8234863
Z variance eval              0.010827424
total_rewards                [362.69668146 791.50071402 108.53654518 355.3558383  270.0546105
 280.56813654 537.0329339  244.24199729 638.06402947 527.73382066]
total_rewards_mean           411.5785307318205
total_rewards_std            196.83661633210136
total_rewards_max            791.500714018416
total_rewards_min            108.53654517903833
Number of train steps total  54000
Number of env steps total    272000
Number of rollouts total     0
Train Time (s)               29.874001041986048
(Previous) Eval Time (s)     20.478517852257937
Sample Time (s)              19.172903404105455
Epoch Time (s)               69.52542229834944
Total Train Time (s)         3687.3005087384954
Epoch                        53
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:16:58.709989 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #53 | Epoch Duration: 70.58679699897766
2020-01-11 04:16:58.710180 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #53 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8229575
Z variance train             0.010826922
KL Divergence                15.964656
KL Loss                      1.5964656
QF Loss                      171.93033
VF Loss                      94.37228
Policy Loss                  -372.12515
Q Predictions Mean           369.00922
Q Predictions Std            42.976505
Q Predictions Max            445.91312
Q Predictions Min            -4.534584
V Predictions Mean           380.12738
V Predictions Std            39.41678
V Predictions Max            459.49484
V Predictions Min            -7.5415864
Log Pis Mean                 -2.6565177
Log Pis Std                  1.7526478
Log Pis Max                  5.7456512
Log Pis Min                  -7.8003125
Policy mu Mean               0.020326216
Policy mu Std                0.32380596
Policy mu Max                1.4918844
Policy mu Min                -1.3271695
Policy log std Mean          -0.8066346
Policy log std Std           0.14453734
Policy log std Max           -0.3550755
Policy log std Min           -2.0086493
Z mean eval                  0.8141901
Z variance eval              0.010475473
total_rewards                [318.99647745 374.33723022 322.41768702 793.45745503 411.06814331
 674.67842136 331.97921791 783.06794305 333.26549971 335.11271918]
total_rewards_mean           467.8380794240367
total_rewards_std            189.11117098407422
total_rewards_max            793.4574550261502
total_rewards_min            318.9964774529009
Number of train steps total  55000
Number of env steps total    277000
Number of rollouts total     0
Train Time (s)               29.574626437854022
(Previous) Eval Time (s)     21.53958335891366
Sample Time (s)              17.532171356026083
Epoch Time (s)               68.64638115279377
Total Train Time (s)         3762.1726420549676
Epoch                        54
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:18:13.586371 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #54 | Epoch Duration: 74.87602186203003
2020-01-11 04:18:13.586678 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #54 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.815654
Z variance train             0.010481994
KL Divergence                15.876492
KL Loss                      1.5876492
QF Loss                      183.3064
VF Loss                      113.64712
Policy Loss                  -370.25305
Q Predictions Mean           366.13324
Q Predictions Std            55.75505
Q Predictions Max            425.95453
Q Predictions Min            -37.47028
V Predictions Mean           361.41504
V Predictions Std            51.241642
V Predictions Max            423.9448
V Predictions Min            0.11735469
Log Pis Mean                 -2.6045291
Log Pis Std                  1.8372096
Log Pis Max                  7.5218086
Log Pis Min                  -10.328311
Policy mu Mean               0.036826774
Policy mu Std                0.3533193
Policy mu Max                1.7458032
Policy mu Min                -2.0753982
Policy log std Mean          -0.8012195
Policy log std Std           0.14225343
Policy log std Max           -0.4298404
Policy log std Min           -1.4865692
Z mean eval                  0.81977236
Z variance eval              0.010752186
total_rewards                [ 35.11648474 626.15006835  23.90444815 366.3985364  756.82788181
 527.3074976  489.49354924 115.14830195  67.4880357  356.52938523]
total_rewards_mean           336.43641891671894
total_rewards_std            251.31539733443165
total_rewards_max            756.8278818107461
total_rewards_min            23.904448149459267
Number of train steps total  56000
Number of env steps total    282000
Number of rollouts total     0
Train Time (s)               31.736543694045395
(Previous) Eval Time (s)     27.768924822099507
Sample Time (s)              17.94925923086703
Epoch Time (s)               77.45472774701193
Total Train Time (s)         3828.825454398524
Epoch                        55
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:19:20.238393 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #55 | Epoch Duration: 66.65149855613708
2020-01-11 04:19:20.238604 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #55 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8218919
Z variance train             0.010781242
KL Divergence                15.723259
KL Loss                      1.572326
QF Loss                      126.047745
VF Loss                      24.756767
Policy Loss                  -383.44342
Q Predictions Mean           379.53662
Q Predictions Std            47.893337
Q Predictions Max            460.86032
Q Predictions Min            19.332478
V Predictions Mean           381.24426
V Predictions Std            45.99956
V Predictions Max            459.09232
V Predictions Min            13.815419
Log Pis Mean                 -2.5722017
Log Pis Std                  1.963226
Log Pis Max                  10.714093
Log Pis Min                  -8.676916
Policy mu Mean               0.05173993
Policy mu Std                0.3470544
Policy mu Max                1.7817911
Policy mu Min                -3.2501433
Policy log std Mean          -0.8172071
Policy log std Std           0.15480001
Policy log std Max           -0.33378327
Policy log std Min           -1.9699277
Z mean eval                  0.82508194
Z variance eval              0.012128641
total_rewards                [138.78504026 309.71567463 597.90323074 490.88451951 420.25055564
 234.08755351 514.55974122 251.22572041 503.12331095 254.10954605]
total_rewards_mean           371.46448929284327
total_rewards_std            145.182861524131
total_rewards_max            597.9032307412066
total_rewards_min            138.78504026430122
Number of train steps total  57000
Number of env steps total    287000
Number of rollouts total     0
Train Time (s)               28.267299289349467
(Previous) Eval Time (s)     16.9654313409701
Sample Time (s)              18.250169344246387
Epoch Time (s)               63.48289997456595
Total Train Time (s)         3900.562148041092
Epoch                        56
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:20:31.978281 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #56 | Epoch Duration: 71.73953056335449
2020-01-11 04:20:31.978537 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #56 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8294733
Z variance train             0.012168719
KL Divergence                15.378234
KL Loss                      1.5378234
QF Loss                      270.92993
VF Loss                      79.93054
Policy Loss                  -384.49094
Q Predictions Mean           380.00385
Q Predictions Std            46.406197
Q Predictions Max            456.5685
Q Predictions Min            -36.683548
V Predictions Mean           377.65118
V Predictions Std            37.77099
V Predictions Max            452.91803
V Predictions Min            13.330762
Log Pis Mean                 -2.7456024
Log Pis Std                  1.8595928
Log Pis Max                  5.9009466
Log Pis Min                  -9.40719
Policy mu Mean               0.07588927
Policy mu Std                0.32940856
Policy mu Max                1.1787354
Policy mu Min                -0.97790885
Policy log std Mean          -0.80016506
Policy log std Std           0.15999217
Policy log std Max           -0.42780262
Policy log std Min           -1.9731579
Z mean eval                  0.82338274
Z variance eval              0.009714234
total_rewards                [241.05433968 570.66894708 324.22649419 822.41786896 372.81451113
 807.97763614 477.20305533 454.689322   739.25941305 326.79786035]
total_rewards_mean           513.7109447907636
total_rewards_std            201.45963408558333
total_rewards_max            822.4178689585283
total_rewards_min            241.0543396788887
Number of train steps total  58000
Number of env steps total    292000
Number of rollouts total     0
Train Time (s)               29.339919089805335
(Previous) Eval Time (s)     25.22174333734438
Sample Time (s)              17.490504308138043
Epoch Time (s)               72.05216673528776
Total Train Time (s)         3970.7330453707837
Epoch                        57
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:21:42.152279 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #57 | Epoch Duration: 70.17351388931274
2020-01-11 04:21:42.152613 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #57 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8244692
Z variance train             0.009706795
KL Divergence                15.951052
KL Loss                      1.5951052
QF Loss                      223.91428
VF Loss                      25.050236
Policy Loss                  -376.42566
Q Predictions Mean           373.89185
Q Predictions Std            49.037125
Q Predictions Max            450.82178
Q Predictions Min            -23.850327
V Predictions Mean           374.55676
V Predictions Std            48.026653
V Predictions Max            455.68216
V Predictions Min            53.922993
Log Pis Mean                 -2.2123842
Log Pis Std                  1.8962841
Log Pis Max                  7.1404395
Log Pis Min                  -8.239906
Policy mu Mean               0.10076999
Policy mu Std                0.339512
Policy mu Max                2.1643429
Policy mu Min                -1.3728828
Policy log std Mean          -0.8335068
Policy log std Std           0.17080231
Policy log std Max           -0.39104778
Policy log std Min           -1.9118208
Z mean eval                  0.82513255
Z variance eval              0.012572715
total_rewards                [368.90885452 647.00137676 213.67339957 647.22561074 439.62405042
  27.00261417 239.37965872 630.17013486 102.07657917 188.90391246]
total_rewards_mean           350.3966191399728
total_rewards_std            220.4549190266164
total_rewards_max            647.2256107417542
total_rewards_min            27.00261416723076
Number of train steps total  59000
Number of env steps total    297000
Number of rollouts total     0
Train Time (s)               29.598319325130433
(Previous) Eval Time (s)     23.342791280709207
Sample Time (s)              18.021445692982525
Epoch Time (s)               70.96255629882216
Total Train Time (s)         4043.0587264583446
Epoch                        58
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:22:54.479468 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #58 | Epoch Duration: 72.32659435272217
2020-01-11 04:22:54.479747 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #58 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.83060616
Z variance train             0.012618229
KL Divergence                15.955157
KL Loss                      1.5955157
QF Loss                      164.91211
VF Loss                      21.745995
Policy Loss                  -385.51056
Q Predictions Mean           385.2481
Q Predictions Std            41.117558
Q Predictions Max            464.0515
Q Predictions Min            96.103485
V Predictions Mean           388.07242
V Predictions Std            39.4396
V Predictions Max            455.17737
V Predictions Min            168.94597
Log Pis Mean                 -2.479903
Log Pis Std                  1.8069555
Log Pis Max                  8.388687
Log Pis Min                  -8.564295
Policy mu Mean               0.07150719
Policy mu Std                0.3476705
Policy mu Max                1.4615638
Policy mu Min                -2.1107488
Policy log std Mean          -0.8306477
Policy log std Std           0.15899397
Policy log std Max           -0.36675587
Policy log std Min           -2.3543298
Z mean eval                  0.8515193
Z variance eval              0.0073999176
total_rewards                [446.34936356 681.64850662 463.22828551 575.02116167 332.25897189
 743.52583015 277.85298072  38.4007201  435.65237003 313.82429598]
total_rewards_mean           430.7762486232876
total_rewards_std            195.85778334756935
total_rewards_max            743.5258301542261
total_rewards_min            38.400720102281
Number of train steps total  60000
Number of env steps total    302000
Number of rollouts total     0
Train Time (s)               29.125379905104637
(Previous) Eval Time (s)     24.706534212920815
Sample Time (s)              18.00436883419752
Epoch Time (s)               71.83628295222297
Total Train Time (s)         4114.679358037654
Epoch                        59
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:24:06.102246 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #59 | Epoch Duration: 71.62226223945618
2020-01-11 04:24:06.102476 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #59 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8519375
Z variance train             0.0073975213
KL Divergence                16.874706
KL Loss                      1.6874707
QF Loss                      491.11786
VF Loss                      63.360203
Policy Loss                  -390.0825
Q Predictions Mean           387.7329
Q Predictions Std            47.7412
Q Predictions Max            468.43832
Q Predictions Min            12.584836
V Predictions Mean           392.90988
V Predictions Std            41.76241
V Predictions Max            464.64505
V Predictions Min            47.81738
Log Pis Mean                 -2.4641416
Log Pis Std                  1.9516811
Log Pis Max                  5.515826
Log Pis Min                  -8.703466
Policy mu Mean               0.03110159
Policy mu Std                0.35070953
Policy mu Max                1.3209782
Policy mu Min                -1.5677104
Policy log std Mean          -0.80660903
Policy log std Std           0.15912214
Policy log std Max           -0.44339174
Policy log std Min           -1.8821325
Z mean eval                  0.8298019
Z variance eval              0.0067842766
total_rewards                [145.47391992 236.96418196  23.79040821 388.04411419 242.18835832
 461.91728669 589.17210775 194.26041394 410.90625942 517.75727711]
total_rewards_mean           321.0474327505891
total_rewards_std            170.74676450189156
total_rewards_max            589.1721077499247
total_rewards_min            23.790408213911903
Number of train steps total  61000
Number of env steps total    307000
Number of rollouts total     0
Train Time (s)               27.45120234414935
(Previous) Eval Time (s)     24.492237322963774
Sample Time (s)              18.861433901824057
Epoch Time (s)               70.80487356893718
Total Train Time (s)         4181.514639220666
Epoch                        60
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:25:12.938419 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #60 | Epoch Duration: 66.83575654029846
2020-01-11 04:25:12.938655 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #60 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8285214
Z variance train             0.006796471
KL Divergence                16.569044
KL Loss                      1.6569045
QF Loss                      218.9649
VF Loss                      51.164642
Policy Loss                  -387.95618
Q Predictions Mean           386.92865
Q Predictions Std            52.132378
Q Predictions Max            471.78928
Q Predictions Min            11.795907
V Predictions Mean           393.12357
V Predictions Std            53.811855
V Predictions Max            470.24222
V Predictions Min            -35.636135
Log Pis Mean                 -2.5605555
Log Pis Std                  1.7180625
Log Pis Max                  3.1372554
Log Pis Min                  -8.488198
Policy mu Mean               0.07915558
Policy mu Std                0.32531354
Policy mu Max                1.3710002
Policy mu Min                -1.2180191
Policy log std Mean          -0.8120457
Policy log std Std           0.15938206
Policy log std Max           -0.36883348
Policy log std Min           -2.1072457
Z mean eval                  0.8429557
Z variance eval              0.009306221
total_rewards                [310.23113309 486.92933728 394.23421628 327.88200602 181.95402881
 494.47216091 282.94824833 583.34448551 348.64386904 392.78978036]
total_rewards_mean           380.3429265631209
total_rewards_std            111.11264115105168
total_rewards_max            583.3444855134767
total_rewards_min            181.95402880533055
Number of train steps total  62000
Number of env steps total    312000
Number of rollouts total     0
Train Time (s)               30.152096850331873
(Previous) Eval Time (s)     20.522795835975558
Sample Time (s)              18.20627854531631
Epoch Time (s)               68.88117123162374
Total Train Time (s)         4257.134144000243
Epoch                        61
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:26:28.558172 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #61 | Epoch Duration: 75.6193528175354
2020-01-11 04:26:28.558368 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #61 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8393904
Z variance train             0.009258442
KL Divergence                16.728
KL Loss                      1.6728001
QF Loss                      280.4834
VF Loss                      68.614395
Policy Loss                  -393.39825
Q Predictions Mean           388.95282
Q Predictions Std            43.047195
Q Predictions Max            481.51376
Q Predictions Min            117.65945
V Predictions Mean           390.44415
V Predictions Std            42.21963
V Predictions Max            484.89893
V Predictions Min            175.50656
Log Pis Mean                 -2.3964663
Log Pis Std                  1.745255
Log Pis Max                  2.4782515
Log Pis Min                  -7.710405
Policy mu Mean               0.052155495
Policy mu Std                0.3777953
Policy mu Max                1.4375519
Policy mu Min                -1.2046444
Policy log std Mean          -0.8221817
Policy log std Std           0.15371157
Policy log std Max           -0.38313463
Policy log std Min           -1.6672883
Z mean eval                  0.82505625
Z variance eval              0.007879742
total_rewards                [ 75.01757223 710.20462102 491.75435451  19.50058944 444.48991626
 250.14153921 163.2977258  486.6860986   70.50135462 282.29139996]
total_rewards_mean           299.3885171650187
total_rewards_std            215.45683385234153
total_rewards_max            710.2046210225742
total_rewards_min            19.500589443738917
Number of train steps total  63000
Number of env steps total    317000
Number of rollouts total     0
Train Time (s)               28.376864572055638
(Previous) Eval Time (s)     27.260662491898984
Sample Time (s)              19.015454946551472
Epoch Time (s)               74.6529820105061
Total Train Time (s)         4320.871291828342
Epoch                        62
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:27:32.298866 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #62 | Epoch Duration: 63.74034285545349
2020-01-11 04:27:32.299156 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #62 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.82351047
Z variance train             0.007921049
KL Divergence                16.949303
KL Loss                      1.6949303
QF Loss                      316.5742
VF Loss                      54.854122
Policy Loss                  -393.5977
Q Predictions Mean           391.0834
Q Predictions Std            53.379986
Q Predictions Max            495.21957
Q Predictions Min            -26.315838
V Predictions Mean           397.92188
V Predictions Std            50.14628
V Predictions Max            493.50244
V Predictions Min            6.9701204
Log Pis Mean                 -2.1641374
Log Pis Std                  1.6734922
Log Pis Max                  3.8049052
Log Pis Min                  -9.059922
Policy mu Mean               0.04013084
Policy mu Std                0.35459864
Policy mu Max                1.3729464
Policy mu Min                -1.2819135
Policy log std Mean          -0.82703316
Policy log std Std           0.16481116
Policy log std Max           -0.403619
Policy log std Min           -1.8935874
Z mean eval                  0.83482087
Z variance eval              0.008805775
total_rewards                [134.51839008 733.82610973 792.7636523  160.06558347 324.42939184
 383.23740833 441.94114436 813.13090426 204.03831279 371.4852417 ]
total_rewards_mean           435.94361388639254
total_rewards_std            244.63746912245415
total_rewards_max            813.1309042602071
total_rewards_min            134.5183900783568
Number of train steps total  64000
Number of env steps total    322000
Number of rollouts total     0
Train Time (s)               29.68661061488092
(Previous) Eval Time (s)     16.347669503185898
Sample Time (s)              18.31430963613093
Epoch Time (s)               64.34858975419775
Total Train Time (s)         4392.12222475186
Epoch                        63
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:28:43.560425 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #63 | Epoch Duration: 71.26103830337524
2020-01-11 04:28:43.560728 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #63 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8354723
Z variance train             0.008811386
KL Divergence                17.294899
KL Loss                      1.7294899
QF Loss                      200.36882
VF Loss                      32.01487
Policy Loss                  -399.8387
Q Predictions Mean           394.98193
Q Predictions Std            59.56516
Q Predictions Max            476.77304
Q Predictions Min            15.22739
V Predictions Mean           402.25146
V Predictions Std            56.10442
V Predictions Max            476.51404
V Predictions Min            -18.084686
Log Pis Mean                 -2.395779
Log Pis Std                  1.845495
Log Pis Max                  5.079619
Log Pis Min                  -8.5970335
Policy mu Mean               0.007030852
Policy mu Std                0.37304667
Policy mu Max                2.455512
Policy mu Min                -1.723046
Policy log std Mean          -0.81091845
Policy log std Std           0.1651433
Policy log std Max           0.35296315
Policy log std Min           -1.5760994
Z mean eval                  0.8534643
Z variance eval              0.008191782
total_rewards                [942.21624566 238.3128602  151.27414029 883.57704243 605.62533239
 982.76759642 419.90659125 704.75183705 664.3989789  217.06366444]
total_rewards_mean           580.9894289031824
total_rewards_std            294.41859485581847
total_rewards_max            982.7675964203404
total_rewards_min            151.2741402878324
Number of train steps total  65000
Number of env steps total    327000
Number of rollouts total     0
Train Time (s)               29.27872125338763
(Previous) Eval Time (s)     23.259806677233428
Sample Time (s)              19.211734858341515
Epoch Time (s)               71.75026278896257
Total Train Time (s)         4465.017082509585
Epoch                        64
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:29:56.449242 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #64 | Epoch Duration: 72.88828229904175
2020-01-11 04:29:56.449494 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #64 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8517602
Z variance train             0.008179852
KL Divergence                17.242907
KL Loss                      1.7242907
QF Loss                      175.18745
VF Loss                      35.014107
Policy Loss                  -403.177
Q Predictions Mean           401.53238
Q Predictions Std            55.300526
Q Predictions Max            485.26593
Q Predictions Min            0.5503644
V Predictions Mean           401.7685
V Predictions Std            55.24972
V Predictions Max            485.13684
V Predictions Min            -27.65972
Log Pis Mean                 -2.7480278
Log Pis Std                  1.795467
Log Pis Max                  3.8670526
Log Pis Min                  -8.811529
Policy mu Mean               0.030107556
Policy mu Std                0.3484083
Policy mu Max                1.1884176
Policy mu Min                -1.6760955
Policy log std Mean          -0.79382217
Policy log std Std           0.16412227
Policy log std Max           -0.21749607
Policy log std Min           -1.788944
Z mean eval                  0.8539375
Z variance eval              0.013584213
total_rewards                [301.89907963 172.94177789 363.24891493 920.04243867 153.87203233
 336.84554515 720.84099284 792.78203643  20.65868762 349.25387236]
total_rewards_mean           413.23853778483783
total_rewards_std            282.7508711693058
total_rewards_max            920.0424386746483
total_rewards_min            20.65868762059067
Number of train steps total  66000
Number of env steps total    332000
Number of rollouts total     0
Train Time (s)               28.188089677132666
(Previous) Eval Time (s)     24.397499246988446
Sample Time (s)              17.994373274967074
Epoch Time (s)               70.57996219908819
Total Train Time (s)         4535.437931260094
Epoch                        65
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:31:06.871663 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #65 | Epoch Duration: 70.42195153236389
2020-01-11 04:31:06.871879 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #65 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.85547066
Z variance train             0.013652215
KL Divergence                16.984009
KL Loss                      1.6984009
QF Loss                      211.30432
VF Loss                      121.861725
Policy Loss                  -408.81824
Q Predictions Mean           405.6739
Q Predictions Std            57.07861
Q Predictions Max            481.3181
Q Predictions Min            -37.072903
V Predictions Mean           409.67725
V Predictions Std            51.62461
V Predictions Max            487.72217
V Predictions Min            -8.63447
Log Pis Mean                 -2.4191892
Log Pis Std                  1.7235364
Log Pis Max                  4.3656664
Log Pis Min                  -8.044631
Policy mu Mean               0.05874502
Policy mu Std                0.36997
Policy mu Max                1.3620276
Policy mu Min                -2.300598
Policy log std Mean          -0.82116
Policy log std Std           0.17130487
Policy log std Max           -0.067070425
Policy log std Min           -1.8818092
Z mean eval                  0.83851415
Z variance eval              0.011162552
total_rewards                [ 156.84360039  659.98323137  630.26815312  470.95069455  356.72436309
  231.69618392  746.93331124 1039.75321391   10.78813207  112.49286037]
total_rewards_mean           441.6433744034297
total_rewards_std            310.06839862030796
total_rewards_max            1039.753213910388
total_rewards_min            10.788132072212498
Number of train steps total  67000
Number of env steps total    337000
Number of rollouts total     0
Train Time (s)               28.72139036701992
(Previous) Eval Time (s)     24.239208452403545
Sample Time (s)              18.27974511915818
Epoch Time (s)               71.24034393858165
Total Train Time (s)         4602.759003023617
Epoch                        66
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:32:14.194480 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #66 | Epoch Duration: 67.32242774963379
2020-01-11 04:32:14.194728 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #66 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8368112
Z variance train             0.0111677265
KL Divergence                17.003735
KL Loss                      1.7003735
QF Loss                      128.47092
VF Loss                      88.440125
Policy Loss                  -405.85986
Q Predictions Mean           402.5008
Q Predictions Std            53.96933
Q Predictions Max            505.89307
Q Predictions Min            25.360115
V Predictions Mean           407.6702
V Predictions Std            54.582314
V Predictions Max            512.01117
V Predictions Min            29.2672
Log Pis Mean                 -2.5501022
Log Pis Std                  2.0528276
Log Pis Max                  6.2108912
Log Pis Min                  -9.508582
Policy mu Mean               0.09444634
Policy mu Std                0.3471666
Policy mu Max                1.7570431
Policy mu Min                -1.3920761
Policy log std Mean          -0.8303436
Policy log std Std           0.19086693
Policy log std Max           -0.4046596
Policy log std Min           -2.168085
Z mean eval                  0.8468239
Z variance eval              0.014052736
total_rewards                [206.0162676  300.64497409 246.88024859 134.7018364  434.40840451
 279.11470379 186.9647246  378.42580129 213.3208934  368.96813043]
total_rewards_mean           274.9445984704198
total_rewards_std            90.77449118231199
total_rewards_max            434.4084045055824
total_rewards_min            134.70183640474255
Number of train steps total  68000
Number of env steps total    342000
Number of rollouts total     0
Train Time (s)               28.462805191986263
(Previous) Eval Time (s)     20.321001078933477
Sample Time (s)              18.033664270769805
Epoch Time (s)               66.81747054168954
Total Train Time (s)         4672.0001046145335
Epoch                        67
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:33:23.438713 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #67 | Epoch Duration: 69.24377584457397
2020-01-11 04:33:23.439017 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #67 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8441876
Z variance train             0.014046376
KL Divergence                16.573364
KL Loss                      1.6573365
QF Loss                      825.82983
VF Loss                      56.095135
Policy Loss                  -412.98703
Q Predictions Mean           408.39594
Q Predictions Std            53.239212
Q Predictions Max            495.04453
Q Predictions Min            -29.534798
V Predictions Mean           411.37146
V Predictions Std            45.800312
V Predictions Max            492.74963
V Predictions Min            25.5616
Log Pis Mean                 -2.4290934
Log Pis Std                  1.817199
Log Pis Max                  7.674161
Log Pis Min                  -7.655017
Policy mu Mean               0.08161472
Policy mu Std                0.3548014
Policy mu Max                1.368913
Policy mu Min                -1.4664874
Policy log std Mean          -0.83379173
Policy log std Std           0.18394679
Policy log std Max           -0.43712375
Policy log std Min           -2.372582
Z mean eval                  0.84082824
Z variance eval              0.009663815
total_rewards                [ 100.09202181  867.10392418  464.11840652  497.0091961   995.99720724
  676.68554305  285.98172585  148.53473851 1099.36735219  398.43203945]
total_rewards_mean           553.3322154887093
total_rewards_std            329.1906437965655
total_rewards_max            1099.3673521916558
total_rewards_min            100.09202181104159
Number of train steps total  69000
Number of env steps total    347000
Number of rollouts total     0
Train Time (s)               29.701967519242316
(Previous) Eval Time (s)     22.74698934983462
Sample Time (s)              18.057226441334933
Epoch Time (s)               70.50618331041187
Total Train Time (s)         4745.17149411561
Epoch                        68
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:34:36.612384 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #68 | Epoch Duration: 73.17313194274902
2020-01-11 04:34:36.612664 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #68 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.83975136
Z variance train             0.009660794
KL Divergence                17.289356
KL Loss                      1.7289356
QF Loss                      553.2752
VF Loss                      322.8106
Policy Loss                  -410.4813
Q Predictions Mean           406.88318
Q Predictions Std            64.020004
Q Predictions Max            518.00745
Q Predictions Min            -3.736102
V Predictions Mean           413.0754
V Predictions Std            55.962517
V Predictions Max            515.7039
V Predictions Min            26.253078
Log Pis Mean                 -2.3719845
Log Pis Std                  1.9176445
Log Pis Max                  7.737073
Log Pis Min                  -7.9933333
Policy mu Mean               0.031534966
Policy mu Std                0.3638374
Policy mu Max                1.2620324
Policy mu Min                -1.8897243
Policy log std Mean          -0.8413021
Policy log std Std           0.17741968
Policy log std Max           -0.44679552
Policy log std Min           -2.329609
Z mean eval                  0.85174286
Z variance eval              0.010183555
total_rewards                [ 446.58068763  540.71577102 1194.8908828  1086.38510411  344.77164732
   12.25340649  586.66805572  459.05239894   86.52423712 1190.66922875]
total_rewards_mean           594.8511419898808
total_rewards_std            407.48394616182327
total_rewards_max            1194.8908827996436
total_rewards_min            12.253406487156498
Number of train steps total  70000
Number of env steps total    352000
Number of rollouts total     0
Train Time (s)               26.36977033223957
(Previous) Eval Time (s)     25.413659621030092
Sample Time (s)              18.025646137539297
Epoch Time (s)               69.80907609080896
Total Train Time (s)         4810.447018534876
Epoch                        69
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:35:41.890007 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #69 | Epoch Duration: 65.27708673477173
2020-01-11 04:35:41.890349 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #69 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8516408
Z variance train             0.010175725
KL Divergence                15.792585
KL Loss                      1.5792586
QF Loss                      236.08167
VF Loss                      268.08154
Policy Loss                  -417.18613
Q Predictions Mean           414.6903
Q Predictions Std            55.270428
Q Predictions Max            511.88654
Q Predictions Min            6.821334
V Predictions Mean           413.49124
V Predictions Std            51.376465
V Predictions Max            502.63312
V Predictions Min            90.6395
Log Pis Mean                 -2.6766286
Log Pis Std                  1.9603842
Log Pis Max                  10.04716
Log Pis Min                  -9.2784605
Policy mu Mean               0.02980247
Policy mu Std                0.35822383
Policy mu Max                1.5350894
Policy mu Min                -1.1630728
Policy log std Mean          -0.821041
Policy log std Std           0.18904957
Policy log std Max           -0.4134515
Policy log std Min           -2.2575736
Z mean eval                  0.875069
Z variance eval              0.010857786
total_rewards                [ 103.86579954 1097.51041926  430.36174349  874.41344021  213.28488153
  296.73801961  277.73670313  296.79760723  253.87202244  743.80851735]
total_rewards_mean           458.83891537900973
total_rewards_std            312.45292763228196
total_rewards_max            1097.5104192552903
total_rewards_min            103.86579954203171
Number of train steps total  71000
Number of env steps total    357000
Number of rollouts total     0
Train Time (s)               25.175520881079137
(Previous) Eval Time (s)     20.881400536745787
Sample Time (s)              17.8567828675732
Epoch Time (s)               63.913704285398126
Total Train Time (s)         4878.051630072296
Epoch                        70
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:36:49.499545 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #70 | Epoch Duration: 67.6089117527008
2020-01-11 04:36:49.499882 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #70 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.86877596
Z variance train             0.010877983
KL Divergence                16.63936
KL Loss                      1.663936
QF Loss                      358.44333
VF Loss                      118.60812
Policy Loss                  -425.98532
Q Predictions Mean           423.19324
Q Predictions Std            49.89845
Q Predictions Max            515.0443
Q Predictions Min            25.544865
V Predictions Mean           432.2786
V Predictions Std            49.734688
V Predictions Max            522.12006
V Predictions Min            14.270392
Log Pis Mean                 -2.4258356
Log Pis Std                  1.8317683
Log Pis Max                  6.922211
Log Pis Min                  -7.982917
Policy mu Mean               0.09911648
Policy mu Std                0.36085728
Policy mu Max                2.419844
Policy mu Min                -1.067773
Policy log std Mean          -0.80934966
Policy log std Std           0.17855637
Policy log std Max           -0.3976169
Policy log std Min           -1.6673486
Z mean eval                  0.8610252
Z variance eval              0.010639413
total_rewards                [112.22701103 295.52550857 818.0740548  252.47572436 197.63967664
 437.74874333 376.7981158  840.16227986 425.4320337   11.49592369]
total_rewards_mean           376.7579071769693
total_rewards_std            259.44433405501235
total_rewards_max            840.1622798553227
total_rewards_min            11.495923685090949
Number of train steps total  72000
Number of env steps total    362000
Number of rollouts total     0
Train Time (s)               31.221636600326747
(Previous) Eval Time (s)     24.576305048074573
Sample Time (s)              18.772111660800874
Epoch Time (s)               74.5700533092022
Total Train Time (s)         4945.698341366369
Epoch                        71
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:37:57.142938 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #71 | Epoch Duration: 67.64282417297363
2020-01-11 04:37:57.143087 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #71 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.85944575
Z variance train             0.010635066
KL Divergence                16.81318
KL Loss                      1.6813182
QF Loss                      168.88153
VF Loss                      37.635365
Policy Loss                  -430.04987
Q Predictions Mean           428.30774
Q Predictions Std            58.378113
Q Predictions Max            519.06696
Q Predictions Min            -22.471199
V Predictions Mean           431.38818
V Predictions Std            56.903416
V Predictions Max            512.8858
V Predictions Min            41.714676
Log Pis Mean                 -2.6603408
Log Pis Std                  1.9885412
Log Pis Max                  11.460071
Log Pis Min                  -10.7600765
Policy mu Mean               0.04871077
Policy mu Std                0.37712482
Policy mu Max                2.913679
Policy mu Min                -2.2351704
Policy log std Mean          -0.7969511
Policy log std Std           0.17499743
Policy log std Max           -0.397489
Policy log std Min           -2.01026
Z mean eval                  0.87266237
Z variance eval              0.0125981
total_rewards                [215.16153248 179.33238021 992.96822315 512.91597725 893.28552246
 183.10588717 427.36084448 669.4791428  334.97903146 707.82427761]
total_rewards_mean           511.6412819076796
total_rewards_std            280.2334437806979
total_rewards_max            992.9682231518893
total_rewards_min            179.33238020564988
Number of train steps total  73000
Number of env steps total    367000
Number of rollouts total     0
Train Time (s)               29.546486858278513
(Previous) Eval Time (s)     17.648739993106574
Sample Time (s)              17.89322559442371
Epoch Time (s)               65.0884524458088
Total Train Time (s)         5017.6182788587175
Epoch                        72
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:39:09.077135 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #72 | Epoch Duration: 71.93387818336487
2020-01-11 04:39:09.077457 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #72 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8744956
Z variance train             0.012673335
KL Divergence                16.848217
KL Loss                      1.6848217
QF Loss                      416.09586
VF Loss                      76.381294
Policy Loss                  -434.5811
Q Predictions Mean           431.69977
Q Predictions Std            55.52825
Q Predictions Max            533.0361
Q Predictions Min            29.705553
V Predictions Mean           428.64734
V Predictions Std            53.933575
V Predictions Max            522.42535
V Predictions Min            3.5056965
Log Pis Mean                 -2.2849455
Log Pis Std                  1.8358706
Log Pis Max                  5.665387
Log Pis Min                  -7.1369405
Policy mu Mean               0.055713966
Policy mu Std                0.3673371
Policy mu Max                1.2504508
Policy mu Min                -1.5459917
Policy log std Mean          -0.84322715
Policy log std Std           0.17575192
Policy log std Max           -0.3724923
Policy log std Min           -2.120945
Z mean eval                  0.90165645
Z variance eval              0.008477689
total_rewards                [427.92560381 665.79542889 888.3970435  259.34490921 307.25747806
 367.13813038 441.68314209 290.88523703 586.50985815 368.18389057]
total_rewards_mean           460.3120721705013
total_rewards_std            187.74714411318485
total_rewards_max            888.397043504485
total_rewards_min            259.3449092138384
Number of train steps total  74000
Number of env steps total    372000
Number of rollouts total     0
Train Time (s)               26.531149704940617
(Previous) Eval Time (s)     24.49380048410967
Sample Time (s)              17.54757996229455
Epoch Time (s)               68.57253015134484
Total Train Time (s)         5087.204788014293
Epoch                        73
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:40:18.654419 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #73 | Epoch Duration: 69.57671070098877
2020-01-11 04:40:18.654659 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #73 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89845675
Z variance train             0.0084323315
KL Divergence                17.096127
KL Loss                      1.7096127
QF Loss                      125.44207
VF Loss                      31.024075
Policy Loss                  -427.49246
Q Predictions Mean           424.15033
Q Predictions Std            51.053448
Q Predictions Max            526.397
Q Predictions Min            88.32458
V Predictions Mean           430.10608
V Predictions Std            47.146706
V Predictions Max            532.7788
V Predictions Min            269.35886
Log Pis Mean                 -2.2575445
Log Pis Std                  1.8603485
Log Pis Max                  5.3433127
Log Pis Min                  -7.189107
Policy mu Mean               0.060424335
Policy mu Std                0.36292365
Policy mu Max                1.3975424
Policy mu Min                -1.7881044
Policy log std Mean          -0.8450152
Policy log std Std           0.1811259
Policy log std Max           -0.3101557
Policy log std Min           -1.8915792
Z mean eval                  0.84945667
Z variance eval              0.009644638
total_rewards                [ 274.79973208 1247.05694114  143.31341709  154.56915758  442.96797453
  995.97069091  845.876161    753.03605467  119.38461755  290.64307794]
total_rewards_mean           526.761782447999
total_rewards_std            383.37848418562885
total_rewards_max            1247.0569411449849
total_rewards_min            119.38461754927896
Number of train steps total  75000
Number of env steps total    377000
Number of rollouts total     0
Train Time (s)               27.566517051309347
(Previous) Eval Time (s)     25.497675474733114
Sample Time (s)              18.488395570311695
Epoch Time (s)               71.55258809635416
Total Train Time (s)         5160.319834402762
Epoch                        74
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:41:31.772361 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #74 | Epoch Duration: 73.11750221252441
2020-01-11 04:41:31.772595 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #74 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8492104
Z variance train             0.009642283
KL Divergence                17.04586
KL Loss                      1.704586
QF Loss                      201.81566
VF Loss                      149.92984
Policy Loss                  -438.33066
Q Predictions Mean           434.3266
Q Predictions Std            57.603077
Q Predictions Max            526.42834
Q Predictions Min            10.857303
V Predictions Mean           439.6697
V Predictions Std            53.636997
V Predictions Max            534.58563
V Predictions Min            5.057658
Log Pis Mean                 -1.9489195
Log Pis Std                  1.9028152
Log Pis Max                  8.679107
Log Pis Min                  -8.247655
Policy mu Mean               0.13461742
Policy mu Std                0.38048416
Policy mu Max                2.0154834
Policy mu Min                -1.0894544
Policy log std Mean          -0.8574904
Policy log std Std           0.17850843
Policy log std Max           -0.38698658
Policy log std Min           -2.2637224
Z mean eval                  0.86273134
Z variance eval              0.0083673345
total_rewards                [ 508.42059677  149.97036833  435.6727781   902.78429328  144.86803548
  267.76429015  441.35780658  520.96299147 1185.88748589  364.31756558]
total_rewards_mean           492.20062116139604
total_rewards_std            310.0223188905692
total_rewards_max            1185.8874858859676
total_rewards_min            144.86803547922176
Number of train steps total  76000
Number of env steps total    382000
Number of rollouts total     0
Train Time (s)               28.245735192205757
(Previous) Eval Time (s)     27.062303002923727
Sample Time (s)              17.81864973437041
Epoch Time (s)               73.1266879294999
Total Train Time (s)         5231.063923754264
Epoch                        75
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:42:42.516142 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #75 | Epoch Duration: 70.74337339401245
2020-01-11 04:42:42.516374 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #75 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8619796
Z variance train             0.008373566
KL Divergence                16.829872
KL Loss                      1.6829872
QF Loss                      191.9412
VF Loss                      43.163147
Policy Loss                  -423.99747
Q Predictions Mean           419.90912
Q Predictions Std            70.27014
Q Predictions Max            526.99756
Q Predictions Min            -3.9518807
V Predictions Mean           426.1836
V Predictions Std            71.94922
V Predictions Max            526.5449
V Predictions Min            -12.281841
Log Pis Mean                 -2.4959111
Log Pis Std                  1.8525425
Log Pis Max                  4.459488
Log Pis Min                  -8.447972
Policy mu Mean               0.08325386
Policy mu Std                0.35506862
Policy mu Max                1.8182597
Policy mu Min                -1.3392097
Policy log std Mean          -0.848264
Policy log std Std           0.18281245
Policy log std Max           -0.06951004
Policy log std Min           -2.0138073
Z mean eval                  0.85716885
Z variance eval              0.009443477
total_rewards                [ 304.97090297 1221.6446047    87.49214106  841.59848379  384.52767816
  166.8297687   485.38148895   53.01830923  983.95041525  603.6730395 ]
total_rewards_mean           513.3086832311905
total_rewards_std            375.92379918340026
total_rewards_max            1221.6446046968692
total_rewards_min            53.018309225123375
Number of train steps total  77000
Number of env steps total    387000
Number of rollouts total     0
Train Time (s)               25.47545846598223
(Previous) Eval Time (s)     24.678714827168733
Sample Time (s)              18.128396009560674
Epoch Time (s)               68.28256930271164
Total Train Time (s)         5295.629320138134
Epoch                        76
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:43:47.083542 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #76 | Epoch Duration: 64.56704306602478
2020-01-11 04:43:47.083712 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #76 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.854722
Z variance train             0.009425341
KL Divergence                17.15297
KL Loss                      1.715297
QF Loss                      181.87695
VF Loss                      21.330187
Policy Loss                  -443.3067
Q Predictions Mean           439.2075
Q Predictions Std            47.36776
Q Predictions Max            520.71716
Q Predictions Min            259.37607
V Predictions Mean           443.55145
V Predictions Std            46.770325
V Predictions Max            526.11176
V Predictions Min            277.72824
Log Pis Mean                 -2.3790102
Log Pis Std                  1.6983881
Log Pis Max                  2.254385
Log Pis Min                  -8.736387
Policy mu Mean               0.049428105
Policy mu Std                0.35566762
Policy mu Max                1.1785556
Policy mu Min                -1.7098535
Policy log std Mean          -0.848078
Policy log std Std           0.1674599
Policy log std Max           -0.40492204
Policy log std Min           -1.4296153
Z mean eval                  0.8648082
Z variance eval              0.007964576
total_rewards                [1063.92091403  360.90229658  183.07833852  221.41740861  372.07232397
  571.97894391  367.62643177  570.77396771 1123.61157037  403.43462874]
total_rewards_mean           523.881682421695
total_rewards_std            308.54394450703865
total_rewards_max            1123.6115703720798
total_rewards_min            183.07833852425176
Number of train steps total  78000
Number of env steps total    392000
Number of rollouts total     0
Train Time (s)               25.81782181886956
(Previous) Eval Time (s)     20.962886189110577
Sample Time (s)              17.889411052688956
Epoch Time (s)               64.6701190606691
Total Train Time (s)         5365.589900386054
Epoch                        77
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:44:57.047228 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #77 | Epoch Duration: 69.963303565979
2020-01-11 04:44:57.047518 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #77 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.86391944
Z variance train             0.007964113
KL Divergence                17.89368
KL Loss                      1.789368
QF Loss                      192.72893
VF Loss                      95.149536
Policy Loss                  -444.94608
Q Predictions Mean           441.27115
Q Predictions Std            59.05033
Q Predictions Max            553.9316
Q Predictions Min            48.16522
V Predictions Mean           440.28625
V Predictions Std            59.905674
V Predictions Max            551.38556
V Predictions Min            11.91044
Log Pis Mean                 -2.2350185
Log Pis Std                  1.8498296
Log Pis Max                  8.144057
Log Pis Min                  -8.8538265
Policy mu Mean               0.07382614
Policy mu Std                0.36646047
Policy mu Max                1.9363172
Policy mu Min                -1.131041
Policy log std Mean          -0.84392715
Policy log std Std           0.16694668
Policy log std Max           -0.39685184
Policy log std Min           -1.7520131
Z mean eval                  0.88922757
Z variance eval              0.012825638
total_rewards                [ 667.57136108  607.22473132  158.64199993  659.28165511  313.16575434
 1198.54966013  487.73154816 1279.53734341 1045.39055474  133.09738907]
total_rewards_mean           655.0191997287395
total_rewards_std            387.80661957788516
total_rewards_max            1279.5373434097833
total_rewards_min            133.0973890744845
Number of train steps total  79000
Number of env steps total    397000
Number of rollouts total     0
Train Time (s)               29.12621673103422
(Previous) Eval Time (s)     26.25577829219401
Sample Time (s)              18.207861001137644
Epoch Time (s)               73.58985602436587
Total Train Time (s)         5439.657263092231
Epoch                        78
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:46:11.118646 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #78 | Epoch Duration: 74.07076096534729
2020-01-11 04:46:11.119093 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #78 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8811839
Z variance train             0.012742428
KL Divergence                15.966177
KL Loss                      1.5966177
QF Loss                      369.10712
VF Loss                      86.50034
Policy Loss                  -445.7383
Q Predictions Mean           442.85388
Q Predictions Std            58.42456
Q Predictions Max            550.65466
Q Predictions Min            217.09685
V Predictions Mean           450.5399
V Predictions Std            56.436455
V Predictions Max            542.1175
V Predictions Min            232.0763
Log Pis Mean                 -2.2513807
Log Pis Std                  1.9754605
Log Pis Max                  6.239049
Log Pis Min                  -10.544867
Policy mu Mean               0.04016282
Policy mu Std                0.38580635
Policy mu Max                1.4558257
Policy mu Min                -1.1502542
Policy log std Mean          -0.87321347
Policy log std Std           0.19835667
Policy log std Max           -0.3758534
Policy log std Min           -2.108231
Z mean eval                  0.90974426
Z variance eval              0.01159615
total_rewards                [ 431.76312648  278.02589813  840.76132977  623.49130624  481.94158819
  297.03928966  525.9386442   202.69162373 1134.60380314  314.25571748]
total_rewards_mean           513.0512327028018
total_rewards_std            274.11694185753765
total_rewards_max            1134.6038031431822
total_rewards_min            202.6916237327428
Number of train steps total  80000
Number of env steps total    402000
Number of rollouts total     0
Train Time (s)               29.019479902926832
(Previous) Eval Time (s)     26.73637876380235
Sample Time (s)              18.116218315903097
Epoch Time (s)               73.87207698263228
Total Train Time (s)         5511.4137733038515
Epoch                        79
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:47:22.876319 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #79 | Epoch Duration: 71.75696611404419
2020-01-11 04:47:22.876567 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #79 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9040292
Z variance train             0.011685118
KL Divergence                16.225798
KL Loss                      1.6225798
QF Loss                      251.62955
VF Loss                      42.43947
Policy Loss                  -450.9991
Q Predictions Mean           448.0122
Q Predictions Std            56.58887
Q Predictions Max            535.96185
Q Predictions Min            214.18678
V Predictions Mean           454.43365
V Predictions Std            56.636303
V Predictions Max            535.30396
V Predictions Min            142.31627
Log Pis Mean                 -2.0942025
Log Pis Std                  1.9565873
Log Pis Max                  3.3991585
Log Pis Min                  -11.731694
Policy mu Mean               0.073094085
Policy mu Std                0.38739422
Policy mu Max                1.3174396
Policy mu Min                -1.1157053
Policy log std Mean          -0.8526318
Policy log std Std           0.19408534
Policy log std Max           -0.3792996
Policy log std Min           -1.8399961
Z mean eval                  0.8834025
Z variance eval              0.013711542
total_rewards                [614.74823057 750.64179949 400.27315586 694.73278344 686.9075298
 537.90059862 186.03693215  56.34266116 464.46453075 674.27578618]
total_rewards_mean           506.63240080307577
total_rewards_std            220.64116176092298
total_rewards_max            750.6417994948641
total_rewards_min            56.342661159907
Number of train steps total  81000
Number of env steps total    407000
Number of rollouts total     0
Train Time (s)               27.825790111906826
(Previous) Eval Time (s)     24.620958198793232
Sample Time (s)              18.255790230818093
Epoch Time (s)               70.70253854151815
Total Train Time (s)         5576.860112561844
Epoch                        80
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:48:28.322614 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #80 | Epoch Duration: 65.44581937789917
2020-01-11 04:48:28.322853 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #80 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8833731
Z variance train             0.01373761
KL Divergence                15.903759
KL Loss                      1.5903759
QF Loss                      324.50745
VF Loss                      29.568558
Policy Loss                  -464.4799
Q Predictions Mean           461.19595
Q Predictions Std            50.9667
Q Predictions Max            559.7302
Q Predictions Min            283.34222
V Predictions Mean           466.5335
V Predictions Std            50.226368
V Predictions Max            557.3526
V Predictions Min            294.02017
Log Pis Mean                 -1.7819204
Log Pis Std                  1.9025948
Log Pis Max                  3.5249252
Log Pis Min                  -8.458919
Policy mu Mean               0.109536834
Policy mu Std                0.39904493
Policy mu Max                1.4544164
Policy mu Min                -1.3747395
Policy log std Mean          -0.8739649
Policy log std Std           0.18586002
Policy log std Max           -0.33763626
Policy log std Min           -1.8437177
Z mean eval                  0.9006885
Z variance eval              0.012483658
total_rewards                [110.99123128  23.10657991 381.17679645 364.84023542 398.67100392
 447.66019614 422.0548361  126.28716951 503.6177394  861.29316546]
total_rewards_mean           363.9698953599858
total_rewards_std            227.0220179751767
total_rewards_max            861.2931654641694
total_rewards_min            23.106579911221242
Number of train steps total  82000
Number of env steps total    412000
Number of rollouts total     0
Train Time (s)               30.366204699035734
(Previous) Eval Time (s)     19.36390263494104
Sample Time (s)              18.141428847797215
Epoch Time (s)               67.87153618177399
Total Train Time (s)         5647.361463692971
Epoch                        81
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:49:38.827229 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #81 | Epoch Duration: 70.50420641899109
2020-01-11 04:49:38.827517 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #81 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9026538
Z variance train             0.012428687
KL Divergence                16.249985
KL Loss                      1.6249985
QF Loss                      281.86002
VF Loss                      27.162075
Policy Loss                  -454.73895
Q Predictions Mean           453.3988
Q Predictions Std            60.783203
Q Predictions Max            578.1537
Q Predictions Min            279.47076
V Predictions Mean           455.8061
V Predictions Std            59.71038
V Predictions Max            575.1079
V Predictions Min            279.30923
Log Pis Mean                 -2.2376766
Log Pis Std                  1.9015914
Log Pis Max                  4.506604
Log Pis Min                  -8.472146
Policy mu Mean               0.087317124
Policy mu Std                0.36840415
Policy mu Max                1.1849056
Policy mu Min                -1.2683777
Policy log std Mean          -0.8414929
Policy log std Std           0.2138206
Policy log std Max           -0.34404635
Policy log std Min           -2.0555825
Z mean eval                  0.9025505
Z variance eval              0.009696717
total_rewards                [ 586.87003542 1148.18197421 1201.79931242  960.27925155  220.70515883
 1082.58940376  597.92621038 1155.13576747  269.56452162 1268.63354428]
total_rewards_mean           849.1685179925335
total_rewards_std            375.8969902441001
total_rewards_max            1268.633544279458
total_rewards_min            220.7051588300596
Number of train steps total  83000
Number of env steps total    417000
Number of rollouts total     0
Train Time (s)               29.295200848020613
(Previous) Eval Time (s)     21.99627081817016
Sample Time (s)              18.829626403283328
Epoch Time (s)               70.1210980694741
Total Train Time (s)         5719.625093003735
Epoch                        82
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:50:51.093976 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #82 | Epoch Duration: 72.26613235473633
2020-01-11 04:50:51.094361 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #82 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89982873
Z variance train             0.009691484
KL Divergence                17.160618
KL Loss                      1.7160618
QF Loss                      253.74275
VF Loss                      44.91256
Policy Loss                  -457.94745
Q Predictions Mean           455.5437
Q Predictions Std            67.04488
Q Predictions Max            556.33185
Q Predictions Min            9.926513
V Predictions Mean           454.57892
V Predictions Std            67.315765
V Predictions Max            545.6175
V Predictions Min            27.088644
Log Pis Mean                 -1.840441
Log Pis Std                  1.6549108
Log Pis Max                  4.809725
Log Pis Min                  -7.0056896
Policy mu Mean               0.110546544
Policy mu Std                0.38209772
Policy mu Max                1.4448639
Policy mu Min                -0.9225507
Policy log std Mean          -0.8849955
Policy log std Std           0.19113588
Policy log std Max           -0.42737123
Policy log std Min           -1.9273899
Z mean eval                  0.90514964
Z variance eval              0.0103235515
total_rewards                [ 306.94880887  631.57777785  726.26075403 1111.19639948   80.02162875
  155.31803594  381.96364822 1104.17747244  303.98814153  228.41827961]
total_rewards_mean           502.9870946721624
total_rewards_std            355.74920673817775
total_rewards_max            1111.1963994841044
total_rewards_min            80.02162875491024
Number of train steps total  84000
Number of env steps total    422000
Number of rollouts total     0
Train Time (s)               29.23836149321869
(Previous) Eval Time (s)     24.14093925943598
Sample Time (s)              18.684030572883785
Epoch Time (s)               72.06333132553846
Total Train Time (s)         5785.505091770552
Epoch                        83
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:51:56.974259 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #83 | Epoch Duration: 65.87968420982361
2020-01-11 04:51:56.974477 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #83 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90323126
Z variance train             0.010347493
KL Divergence                16.776651
KL Loss                      1.6776651
QF Loss                      320.80322
VF Loss                      47.909958
Policy Loss                  -458.73944
Q Predictions Mean           456.70193
Q Predictions Std            72.80827
Q Predictions Max            617.7209
Q Predictions Min            -6.78412
V Predictions Mean           460.7031
V Predictions Std            74.52164
V Predictions Max            614.05145
V Predictions Min            -3.4085107
Log Pis Mean                 -2.0315218
Log Pis Std                  1.6838819
Log Pis Max                  2.6819592
Log Pis Min                  -9.690501
Policy mu Mean               -0.0180435
Policy mu Std                0.39147934
Policy mu Max                1.4155022
Policy mu Min                -1.2754046
Policy log std Mean          -0.84819394
Policy log std Std           0.19703184
Policy log std Max           0.2512148
Policy log std Min           -1.4471748
Z mean eval                  0.91897166
Z variance eval              0.006199686
total_rewards                [ 987.93121195  118.06750999  187.48187108  415.67113326   38.62591939
 1211.58477106  367.89354454 1065.8432061   582.71698111  189.81758228]
total_rewards_mean           516.5633730763448
total_rewards_std            405.6956481470694
total_rewards_max            1211.584771056713
total_rewards_min            38.625919394011376
Number of train steps total  85000
Number of env steps total    427000
Number of rollouts total     0
Train Time (s)               25.955029351171106
(Previous) Eval Time (s)     17.956975222099572
Sample Time (s)              18.23685678699985
Epoch Time (s)               62.14886136027053
Total Train Time (s)         5851.056542440318
Epoch                        84
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:53:02.529510 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #84 | Epoch Duration: 65.55485701560974
2020-01-11 04:53:02.529746 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #84 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9178213
Z variance train             0.00619878
KL Divergence                17.184883
KL Loss                      1.7184883
QF Loss                      577.52
VF Loss                      83.589806
Policy Loss                  -460.991
Q Predictions Mean           455.26624
Q Predictions Std            85.81974
Q Predictions Max            571.4563
Q Predictions Min            -75.254875
V Predictions Mean           459.42706
V Predictions Std            79.97525
V Predictions Max            569.4476
V Predictions Min            18.154758
Log Pis Mean                 -1.9205747
Log Pis Std                  2.2508512
Log Pis Max                  9.621165
Log Pis Min                  -8.97917
Policy mu Mean               0.07638605
Policy mu Std                0.41982308
Policy mu Max                1.961801
Policy mu Min                -1.5184747
Policy log std Mean          -0.8611712
Policy log std Std           0.23078708
Policy log std Max           -0.34424883
Policy log std Min           -2.3094468
Z mean eval                  0.9334629
Z variance eval              0.00734737
total_rewards                [148.11155441 233.65799319 184.37627435 879.64946506 101.54358612
 504.18986421 407.14978792 131.96828084 639.64422074 379.18019442]
total_rewards_mean           360.9471221263981
total_rewards_std            241.26957485652764
total_rewards_max            879.6494650618624
total_rewards_min            101.54358612353448
Number of train steps total  86000
Number of env steps total    432000
Number of rollouts total     0
Train Time (s)               29.133178636897355
(Previous) Eval Time (s)     21.362665604799986
Sample Time (s)              17.63824003515765
Epoch Time (s)               68.13408427685499
Total Train Time (s)         5920.1637005591765
Epoch                        85
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:54:11.635609 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #85 | Epoch Duration: 69.10569906234741
2020-01-11 04:54:11.635841 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #85 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93276435
Z variance train             0.007302965
KL Divergence                17.34316
KL Loss                      1.7343161
QF Loss                      212.94394
VF Loss                      154.04158
Policy Loss                  -480.51068
Q Predictions Mean           476.89587
Q Predictions Std            75.61508
Q Predictions Max            591.67316
Q Predictions Min            -1.7431338
V Predictions Mean           476.4356
V Predictions Std            69.90902
V Predictions Max            592.3153
V Predictions Min            86.05953
Log Pis Mean                 -1.7114418
Log Pis Std                  2.0624304
Log Pis Max                  11.328944
Log Pis Min                  -9.031583
Policy mu Mean               0.04747865
Policy mu Std                0.4126232
Policy mu Max                2.78327
Policy mu Min                -1.743125
Policy log std Mean          -0.8798177
Policy log std Std           0.20818955
Policy log std Max           -0.2522965
Policy log std Min           -1.8112411
Z mean eval                  0.89300555
Z variance eval              0.008531142
total_rewards                [ 210.26877015  732.29502326 1462.97179421  468.15314424 1461.87454177
 1146.57785942  177.18273732  716.44324995   66.72193675  467.57437686]
total_rewards_mean           691.0063433917622
total_rewards_std            488.313972658534
total_rewards_max            1462.9717942097695
total_rewards_min            66.72193675411708
Number of train steps total  87000
Number of env steps total    437000
Number of rollouts total     0
Train Time (s)               26.499555798247457
(Previous) Eval Time (s)     22.333968597929925
Sample Time (s)              18.211380708497018
Epoch Time (s)               67.0449051046744
Total Train Time (s)         5990.744422904681
Epoch                        86
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:55:22.220023 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #86 | Epoch Duration: 70.5839536190033
2020-01-11 04:55:22.220330 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #86 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89293754
Z variance train             0.0085148625
KL Divergence                17.389822
KL Loss                      1.7389822
QF Loss                      256.98694
VF Loss                      109.39192
Policy Loss                  -483.8801
Q Predictions Mean           480.27643
Q Predictions Std            73.41438
Q Predictions Max            586.5225
Q Predictions Min            40.14512
V Predictions Mean           482.69467
V Predictions Std            76.100624
V Predictions Max            585.44666
V Predictions Min            -17.694658
Log Pis Mean                 -2.1331635
Log Pis Std                  1.9013506
Log Pis Max                  2.372901
Log Pis Min                  -8.337246
Policy mu Mean               0.070909455
Policy mu Std                0.39352974
Policy mu Max                1.6094208
Policy mu Min                -1.4642345
Policy log std Mean          -0.87087107
Policy log std Std           0.19539982
Policy log std Max           -0.24049857
Policy log std Min           -1.6992462
Z mean eval                  0.89754355
Z variance eval              0.01025573
total_rewards                [708.57037109 837.38704972  99.73982868 684.18865596 295.49970089
 236.76222723 309.01399264  91.45417895 222.30358953 121.27778029]
total_rewards_mean           360.6197374981506
total_rewards_std            263.10499184616464
total_rewards_max            837.3870497234502
total_rewards_min            91.4541789469804
Number of train steps total  88000
Number of env steps total    442000
Number of rollouts total     0
Train Time (s)               28.818040571641177
(Previous) Eval Time (s)     25.87273733690381
Sample Time (s)              17.95398585917428
Epoch Time (s)               72.64476376771927
Total Train Time (s)         6057.90303584747
Epoch                        87
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:56:29.378001 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #87 | Epoch Duration: 67.15750861167908
2020-01-11 04:56:29.378156 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #87 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8972801
Z variance train             0.010277376
KL Divergence                18.054447
KL Loss                      1.8054447
QF Loss                      269.6501
VF Loss                      88.12098
Policy Loss                  -492.2021
Q Predictions Mean           489.50854
Q Predictions Std            66.09299
Q Predictions Max            609.55096
Q Predictions Min            279.7827
V Predictions Mean           492.22397
V Predictions Std            65.884766
V Predictions Max            609.0162
V Predictions Min            301.29355
Log Pis Mean                 -2.0014515
Log Pis Std                  2.087426
Log Pis Max                  8.848779
Log Pis Min                  -7.468706
Policy mu Mean               0.048163682
Policy mu Std                0.4039579
Policy mu Max                1.2509172
Policy mu Min                -1.3989217
Policy log std Mean          -0.84425026
Policy log std Std           0.22469379
Policy log std Max           -0.28560334
Policy log std Min           -2.3912401
Z mean eval                  0.8847739
Z variance eval              0.007933907
total_rewards                [ 285.98101534  103.71490822  914.63836912   10.75266022  183.16059107
   52.09028476  135.1871068   433.39926096 1496.24896844 1122.91706626]
total_rewards_mean           473.80902311740994
total_rewards_std            492.579574465438
total_rewards_max            1496.2489684425777
total_rewards_min            10.752660216676613
Number of train steps total  89000
Number of env steps total    447000
Number of rollouts total     0
Train Time (s)               28.633769399952143
(Previous) Eval Time (s)     20.38518377300352
Sample Time (s)              18.25331967556849
Epoch Time (s)               67.27227284852415
Total Train Time (s)         6127.735314706806
Epoch                        88
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:57:39.215390 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #88 | Epoch Duration: 69.83706784248352
2020-01-11 04:57:39.215680 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #88 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8846471
Z variance train             0.007912212
KL Divergence                18.269672
KL Loss                      1.8269672
QF Loss                      233.30402
VF Loss                      73.07487
Policy Loss                  -479.98953
Q Predictions Mean           478.0838
Q Predictions Std            76.85981
Q Predictions Max            594.4571
Q Predictions Min            -12.315158
V Predictions Mean           484.29358
V Predictions Std            75.52486
V Predictions Max            599.62915
V Predictions Min            11.912041
Log Pis Mean                 -1.9916635
Log Pis Std                  2.0558898
Log Pis Max                  11.38641
Log Pis Min                  -8.062626
Policy mu Mean               0.04366938
Policy mu Std                0.40903455
Policy mu Max                2.15427
Policy mu Min                -2.1585953
Policy log std Mean          -0.87204635
Policy log std Std           0.20895275
Policy log std Max           -0.27306196
Policy log std Min           -2.2204509
Z mean eval                  0.8870834
Z variance eval              0.0068728095
total_rewards                [  54.0559803   519.96249784 1517.78691471  771.55895468  421.35370636
  165.45432078  244.67435184  370.43430986   71.919989   1348.57880055]
total_rewards_mean           548.5779825912756
total_rewards_std            488.7457230441332
total_rewards_max            1517.7869147093172
total_rewards_min            54.05598029900706
Number of train steps total  90000
Number of env steps total    452000
Number of rollouts total     0
Train Time (s)               28.23309324402362
(Previous) Eval Time (s)     22.94962474424392
Sample Time (s)              18.04565510293469
Epoch Time (s)               69.22837309120223
Total Train Time (s)         6193.647983376402
Epoch                        89
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:58:45.126685 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #89 | Epoch Duration: 65.91076302528381
2020-01-11 04:58:45.126839 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #89 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8877093
Z variance train             0.0068745934
KL Divergence                18.34193
KL Loss                      1.8341931
QF Loss                      171.38467
VF Loss                      216.57437
Policy Loss                  -490.93222
Q Predictions Mean           486.89603
Q Predictions Std            74.73307
Q Predictions Max            601.9922
Q Predictions Min            -12.439505
V Predictions Mean           488.7293
V Predictions Std            68.60335
V Predictions Max            594.7116
V Predictions Min            260.03757
Log Pis Mean                 -2.1914973
Log Pis Std                  2.0944068
Log Pis Max                  4.030856
Log Pis Min                  -8.535101
Policy mu Mean               0.045841657
Policy mu Std                0.4110616
Policy mu Max                2.8978827
Policy mu Min                -1.3687036
Policy log std Mean          -0.85840344
Policy log std Std           0.2156091
Policy log std Max           -0.28884676
Policy log std Min           -1.9897163
Z mean eval                  0.91662425
Z variance eval              0.010734266
total_rewards                [455.98758735 384.98861594  52.34462864 124.53144065 909.22975152
  57.39330634 367.54448442 426.54107371 115.6078139  780.89698501]
total_rewards_mean           367.5065687490085
total_rewards_std            281.77338579491914
total_rewards_max            909.2297515189948
total_rewards_min            52.34462864078665
Number of train steps total  91000
Number of env steps total    457000
Number of rollouts total     0
Train Time (s)               29.554285410791636
(Previous) Eval Time (s)     19.631756325252354
Sample Time (s)              18.251148050650954
Epoch Time (s)               67.43718978669494
Total Train Time (s)         6259.381939907093
Epoch                        90
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:59:50.863539 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #90 | Epoch Duration: 65.73654747009277
2020-01-11 04:59:50.863758 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #90 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9177659
Z variance train             0.010599058
KL Divergence                18.110287
KL Loss                      1.8110287
QF Loss                      193.90836
VF Loss                      48.58844
Policy Loss                  -502.3267
Q Predictions Mean           499.4413
Q Predictions Std            65.27203
Q Predictions Max            603.5955
Q Predictions Min            307.42026
V Predictions Mean           505.37048
V Predictions Std            64.68487
V Predictions Max            614.42487
V Predictions Min            310.98553
Log Pis Mean                 -2.0507026
Log Pis Std                  2.1493714
Log Pis Max                  7.3512197
Log Pis Min                  -12.869061
Policy mu Mean               0.08987801
Policy mu Std                0.39834833
Policy mu Max                1.44141
Policy mu Min                -1.2959312
Policy log std Mean          -0.86183524
Policy log std Std           0.20270754
Policy log std Max           -0.24611598
Policy log std Min           -2.0127895
Z mean eval                  0.88944197
Z variance eval              0.0063047213
total_rewards                [1115.81110168 1085.48487105  445.79657595   84.88103355  399.04564603
  257.14468393   84.37815749  515.1365728  1132.38755058  363.04755986]
total_rewards_mean           548.3113752917557
total_rewards_std            391.75870478718275
total_rewards_max            1132.387550578258
total_rewards_min            84.37815748565238
Number of train steps total  92000
Number of env steps total    462000
Number of rollouts total     0
Train Time (s)               27.4229132020846
(Previous) Eval Time (s)     17.930801848880947
Sample Time (s)              17.897048613522202
Epoch Time (s)               63.25076366448775
Total Train Time (s)         6328.080064993817
Epoch                        91
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:00:59.563198 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #91 | Epoch Duration: 68.69926762580872
2020-01-11 05:00:59.563389 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #91 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8892003
Z variance train             0.0062986994
KL Divergence                18.970448
KL Loss                      1.8970448
QF Loss                      237.7117
VF Loss                      36.76718
Policy Loss                  -499.32098
Q Predictions Mean           497.1927
Q Predictions Std            65.47815
Q Predictions Max            602.02423
Q Predictions Min            296.51855
V Predictions Mean           500.4242
V Predictions Std            65.521965
V Predictions Max            603.37885
V Predictions Min            299.30966
Log Pis Mean                 -1.9147346
Log Pis Std                  2.180499
Log Pis Max                  2.599475
Log Pis Min                  -12.513306
Policy mu Mean               0.014839868
Policy mu Std                0.42083845
Policy mu Max                1.4306606
Policy mu Min                -1.2667437
Policy log std Mean          -0.8684852
Policy log std Std           0.20337415
Policy log std Max           -0.3027559
Policy log std Min           -1.671807
Z mean eval                  0.9113016
Z variance eval              0.006300895
total_rewards                [1318.00537961 1440.98750318 1086.13193845 1236.61491244  793.45831334
  189.9249415   358.12492377  167.58484675  238.831483    415.24394141]
total_rewards_mean           724.4908183456621
total_rewards_std            482.1894300139166
total_rewards_max            1440.9875031817535
total_rewards_min            167.58484675258237
Number of train steps total  93000
Number of env steps total    467000
Number of rollouts total     0
Train Time (s)               28.448352068196982
(Previous) Eval Time (s)     23.379019473213702
Sample Time (s)              18.66235516499728
Epoch Time (s)               70.48972670640796
Total Train Time (s)         6399.757570562884
Epoch                        92
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:02:11.243422 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #92 | Epoch Duration: 71.67986750602722
2020-01-11 05:02:11.243701 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #92 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91219074
Z variance train             0.0062771305
KL Divergence                19.43486
KL Loss                      1.9434861
QF Loss                      386.51633
VF Loss                      105.53774
Policy Loss                  -482.93738
Q Predictions Mean           479.21487
Q Predictions Std            102.071754
Q Predictions Max            615.1769
Q Predictions Min            24.755444
V Predictions Mean           486.96387
V Predictions Std            104.058876
V Predictions Max            621.4715
V Predictions Min            -7.811308
Log Pis Mean                 -1.715427
Log Pis Std                  2.3907008
Log Pis Max                  8.789402
Log Pis Min                  -7.67487
Policy mu Mean               0.08134042
Policy mu Std                0.4212352
Policy mu Max                1.5517304
Policy mu Min                -2.4150648
Policy log std Mean          -0.88528055
Policy log std Std           0.2612167
Policy log std Max           -0.089518845
Policy log std Min           -2.5376537
Z mean eval                  0.9056331
Z variance eval              0.0068972083
total_rewards                [ 698.89071246  656.08813038  453.98250012  433.77446595 -178.12716543
   13.0944061   -31.91643725  311.91519515   74.71559452  267.03810467]
total_rewards_mean           269.9455506661457
total_rewards_std            281.34614359393646
total_rewards_max            698.8907124645934
total_rewards_min            -178.1271654289865
Number of train steps total  94000
Number of env steps total    472000
Number of rollouts total     0
Train Time (s)               25.40580704435706
(Previous) Eval Time (s)     24.568839707877487
Sample Time (s)              18.40154157113284
Epoch Time (s)               68.37618832336739
Total Train Time (s)         6468.328667748719
Epoch                        93
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:03:19.817370 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #93 | Epoch Duration: 68.57345342636108
2020-01-11 05:03:19.817564 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #93 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9057374
Z variance train             0.0068964697
KL Divergence                19.525084
KL Loss                      1.9525083
QF Loss                      237.93059
VF Loss                      126.02294
Policy Loss                  -493.3954
Q Predictions Mean           490.59827
Q Predictions Std            88.61154
Q Predictions Max            631.1925
Q Predictions Min            -32.63671
V Predictions Mean           493.65378
V Predictions Std            81.59534
V Predictions Max            631.7113
V Predictions Min            16.93399
Log Pis Mean                 -2.1137276
Log Pis Std                  2.2702
Log Pis Max                  8.194191
Log Pis Min                  -12.692665
Policy mu Mean               0.07677892
Policy mu Std                0.41471082
Policy mu Max                1.5696093
Policy mu Min                -1.3577975
Policy log std Mean          -0.84690833
Policy log std Std           0.22169943
Policy log std Max           -0.31154573
Policy log std Min           -2.119537
Z mean eval                  0.89785194
Z variance eval              0.01152737
total_rewards                [ 335.81589778  212.51217276 1102.44388957  272.52269952  179.51947171
    1.54531047  618.27947395 1040.05871796  394.88712869  225.67158187]
total_rewards_mean           438.3256344288716
total_rewards_std            350.6245933898691
total_rewards_max            1102.4438895706437
total_rewards_min            1.5453104730182687
Number of train steps total  95000
Number of env steps total    477000
Number of rollouts total     0
Train Time (s)               27.5991197838448
(Previous) Eval Time (s)     24.765818940009922
Sample Time (s)              18.823250792454928
Epoch Time (s)               71.18818951630965
Total Train Time (s)         6538.087598172948
Epoch                        94
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:04:29.578575 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #94 | Epoch Duration: 69.7608437538147
2020-01-11 05:04:29.578879 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #94 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9007139
Z variance train             0.0114909215
KL Divergence                17.698414
KL Loss                      1.7698414
QF Loss                      322.78326
VF Loss                      65.643036
Policy Loss                  -504.89322
Q Predictions Mean           502.8559
Q Predictions Std            81.10711
Q Predictions Max            658.49817
Q Predictions Min            291.4068
V Predictions Mean           508.01862
V Predictions Std            79.07506
V Predictions Max            653.9051
V Predictions Min            307.80606
Log Pis Mean                 -1.7897561
Log Pis Std                  1.9429353
Log Pis Max                  7.565667
Log Pis Min                  -8.576189
Policy mu Mean               0.13285075
Policy mu Std                0.41623408
Policy mu Max                1.5596377
Policy mu Min                -1.1109052
Policy log std Mean          -0.8710474
Policy log std Std           0.21070729
Policy log std Max           -0.29001224
Policy log std Min           -1.8853605
Z mean eval                  0.93662757
Z variance eval              0.011960267
total_rewards                [1461.7694244   719.88378985  209.93637079  349.01276667  243.23739139
 1624.32649159  942.30307002   42.94961311 1372.18889421  769.91954249]
total_rewards_mean           773.5527354510043
total_rewards_std            538.5263740088138
total_rewards_max            1624.32649159495
total_rewards_min            42.94961310740236
Number of train steps total  96000
Number of env steps total    482000
Number of rollouts total     0
Train Time (s)               30.860288931056857
(Previous) Eval Time (s)     23.33815606124699
Sample Time (s)              19.36579220322892
Epoch Time (s)               73.56423719553277
Total Train Time (s)         6614.018606635742
Epoch                        95
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:05:45.509016 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #95 | Epoch Duration: 75.9299144744873
2020-01-11 05:05:45.509168 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #95 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93688357
Z variance train             0.011967393
KL Divergence                16.977098
KL Loss                      1.6977099
QF Loss                      760.291
VF Loss                      132.15764
Policy Loss                  -502.21213
Q Predictions Mean           500.3396
Q Predictions Std            101.759125
Q Predictions Max            634.07776
Q Predictions Min            -29.80446
V Predictions Mean           495.34683
V Predictions Std            99.49116
V Predictions Max            627.2562
V Predictions Min            -3.5114155
Log Pis Mean                 -1.8242346
Log Pis Std                  2.1431136
Log Pis Max                  7.2286444
Log Pis Min                  -7.4501247
Policy mu Mean               0.047625583
Policy mu Std                0.41631305
Policy mu Max                1.8153497
Policy mu Min                -1.4379361
Policy log std Mean          -0.8868216
Policy log std Std           0.23737128
Policy log std Max           -0.3266527
Policy log std Min           -2.2010956
Z mean eval                  0.905454
Z variance eval              0.0088762045
total_rewards                [ 540.64777711  473.95837893 1455.14195925 1656.21055608  660.2323245
  926.44924629  381.24414031  341.21228212   51.81095289  143.9931654 ]
total_rewards_mean           663.09007828831
total_rewards_std            505.9574906075624
total_rewards_max            1656.2105560768464
total_rewards_min            51.81095288642811
Number of train steps total  97000
Number of env steps total    487000
Number of rollouts total     0
Train Time (s)               28.920072271022946
(Previous) Eval Time (s)     25.703523639123887
Sample Time (s)              17.563963770400733
Epoch Time (s)               72.18755968054757
Total Train Time (s)         6686.594522649888
Epoch                        96
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:06:58.089220 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #96 | Epoch Duration: 72.57988023757935
2020-01-11 05:06:58.089572 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #96 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90561354
Z variance train             0.008880566
KL Divergence                16.682642
KL Loss                      1.6682643
QF Loss                      318.3013
VF Loss                      37.02369
Policy Loss                  -513.06726
Q Predictions Mean           511.49243
Q Predictions Std            92.46176
Q Predictions Max            651.31006
Q Predictions Min            9.766531
V Predictions Mean           512.67004
V Predictions Std            93.33987
V Predictions Max            651.3563
V Predictions Min            -6.329755
Log Pis Mean                 -1.6890821
Log Pis Std                  2.0293374
Log Pis Max                  5.301417
Log Pis Min                  -7.1690903
Policy mu Mean               0.070195615
Policy mu Std                0.43034208
Policy mu Max                1.8652425
Policy mu Min                -1.6901947
Policy log std Mean          -0.8578613
Policy log std Std           0.23587285
Policy log std Max           0.28897074
Policy log std Min           -1.9726245
Z mean eval                  0.9428237
Z variance eval              0.010647838
total_rewards                [ 882.57760025  253.91288126  298.36029069   84.71204379   80.51720021
  431.52900384 1274.82953655   70.62816093  856.08136138  586.65915289]
total_rewards_mean           481.9807231780307
total_rewards_std            389.4199576332249
total_rewards_max            1274.8295365469057
total_rewards_min            70.62816092969646
Number of train steps total  98000
Number of env steps total    492000
Number of rollouts total     0
Train Time (s)               29.111507419962436
(Previous) Eval Time (s)     26.095522550866008
Sample Time (s)              18.251847735140473
Epoch Time (s)               73.45887770596892
Total Train Time (s)         6758.267804927193
Epoch                        97
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:08:09.762664 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #97 | Epoch Duration: 71.67285776138306
2020-01-11 05:08:09.762876 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #97 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9442105
Z variance train             0.010630313
KL Divergence                16.696247
KL Loss                      1.6696247
QF Loss                      206.35913
VF Loss                      30.941462
Policy Loss                  -522.108
Q Predictions Mean           519.71783
Q Predictions Std            76.37246
Q Predictions Max            663.9742
Q Predictions Min            293.34735
V Predictions Mean           523.8466
V Predictions Std            75.08536
V Predictions Max            655.66705
V Predictions Min            305.08087
Log Pis Mean                 -1.9483061
Log Pis Std                  1.9345322
Log Pis Max                  3.6533742
Log Pis Min                  -10.318398
Policy mu Mean               0.053976353
Policy mu Std                0.43597484
Policy mu Max                1.5487082
Policy mu Min                -1.655339
Policy log std Mean          -0.82376283
Policy log std Std           0.21410835
Policy log std Max           -0.19745076
Policy log std Min           -1.6112531
Z mean eval                  0.9228816
Z variance eval              0.008249254
total_rewards                [1125.30742343  216.17455967 1606.47092639  531.05072773  170.13296593
  578.68486883  939.64562411  265.54513782 1560.06524277   23.49006381]
total_rewards_mean           701.6567540480639
total_rewards_std            548.1071804541584
total_rewards_max            1606.4709263925897
total_rewards_min            23.49006380554987
Number of train steps total  99000
Number of env steps total    497000
Number of rollouts total     0
Train Time (s)               27.755437857005745
(Previous) Eval Time (s)     24.309221672359854
Sample Time (s)              17.798044360242784
Epoch Time (s)               69.86270388960838
Total Train Time (s)         6822.010434662923
Epoch                        98
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:09:13.506139 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #98 | Epoch Duration: 63.74311375617981
2020-01-11 05:09:13.506343 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #98 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9234649
Z variance train             0.00824218
KL Divergence                16.99391
KL Loss                      1.699391
QF Loss                      274.4343
VF Loss                      91.39545
Policy Loss                  -525.0156
Q Predictions Mean           522.05994
Q Predictions Std            92.59448
Q Predictions Max            637.14197
Q Predictions Min            -39.99301
V Predictions Mean           527.34467
V Predictions Std            87.05605
V Predictions Max            633.77167
V Predictions Min            -2.2198257
Log Pis Mean                 -1.9091476
Log Pis Std                  2.284147
Log Pis Max                  11.390927
Log Pis Min                  -13.559205
Policy mu Mean               0.0025878875
Policy mu Std                0.41426212
Policy mu Max                1.3333538
Policy mu Min                -1.8108767
Policy log std Mean          -0.88368845
Policy log std Std           0.21527727
Policy log std Max           -0.32223663
Policy log std Min           -2.4940262
Z mean eval                  0.9221649
Z variance eval              0.010485623
total_rewards                [ -12.69384207   19.95412632  -73.61949518  265.83454441  133.18005168
  179.86679337 1498.25134646  609.37125064  677.08518015  463.0540157 ]
total_rewards_mean           376.0283971467949
total_rewards_std            447.4054482986671
total_rewards_max            1498.2513464560197
total_rewards_min            -73.61949518051671
Number of train steps total  100000
Number of env steps total    502000
Number of rollouts total     0
Train Time (s)               28.83786243200302
(Previous) Eval Time (s)     18.189358382020146
Sample Time (s)              17.913510717917234
Epoch Time (s)               64.9407315319404
Total Train Time (s)         6892.4540448198095
Epoch                        99
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:10:23.952134 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #99 | Epoch Duration: 70.44566297531128
2020-01-11 05:10:23.952344 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #99 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9217187
Z variance train             0.010440041
KL Divergence                16.61567
KL Loss                      1.661567
QF Loss                      400.36438
VF Loss                      65.689285
Policy Loss                  -526.5787
Q Predictions Mean           521.3028
Q Predictions Std            96.41591
Q Predictions Max            649.63007
Q Predictions Min            -29.513443
V Predictions Mean           524.86066
V Predictions Std            93.21393
V Predictions Max            651.2118
V Predictions Min            -4.9777985
Log Pis Mean                 -1.6687546
Log Pis Std                  2.1531925
Log Pis Max                  5.6738586
Log Pis Min                  -6.987944
Policy mu Mean               0.09685783
Policy mu Std                0.4353304
Policy mu Max                1.5600476
Policy mu Min                -1.2897761
Policy log std Mean          -0.88300073
Policy log std Std           0.22715952
Policy log std Max           -0.23195612
Policy log std Min           -1.8728244
Z mean eval                  0.9265027
Z variance eval              0.0063894144
total_rewards                [ 858.66245426 1188.37252771 1543.10233327  114.93838585 1709.74580543
 1574.46296833  876.49071841 1626.43082839  429.510502    584.12385812]
total_rewards_mean           1050.5840381756648
total_rewards_std            533.6661349121695
total_rewards_max            1709.745805430865
total_rewards_min            114.9383858454425
Number of train steps total  101000
Number of env steps total    507000
Number of rollouts total     0
Train Time (s)               25.852392442058772
(Previous) Eval Time (s)     23.693976424634457
Sample Time (s)              17.40713031310588
Epoch Time (s)               66.95349917979911
Total Train Time (s)         6962.912882679142
Epoch                        100
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:11:34.412395 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #100 | Epoch Duration: 70.45991277694702
2020-01-11 05:11:34.412597 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #100 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9246933
Z variance train             0.006387399
KL Divergence                17.825367
KL Loss                      1.7825367
QF Loss                      798.2456
VF Loss                      51.99299
Policy Loss                  -534.2751
Q Predictions Mean           531.7572
Q Predictions Std            80.09182
Q Predictions Max            668.1297
Q Predictions Min            312.82498
V Predictions Mean           533.17645
V Predictions Std            79.80223
V Predictions Max            663.993
V Predictions Min            309.47998
Log Pis Mean                 -1.5746208
Log Pis Std                  1.9797586
Log Pis Max                  4.109961
Log Pis Min                  -9.486864
Policy mu Mean               0.03110494
Policy mu Std                0.44574216
Policy mu Max                1.6616849
Policy mu Min                -1.6434928
Policy log std Mean          -0.8820347
Policy log std Std           0.2237427
Policy log std Max           -0.14067352
Policy log std Min           -1.4745376
Z mean eval                  0.9319478
Z variance eval              0.0073543303
total_rewards                [1252.90316743 1216.26646775 1619.94302742 1489.08073841  587.6126338
  304.22008113 1581.06820192   44.95542837 1607.24033357  318.3107624 ]
total_rewards_mean           1002.1600842206332
total_rewards_std            589.2010121546733
total_rewards_max            1619.943027419027
total_rewards_min            44.955428367154724
Number of train steps total  102000
Number of env steps total    512000
Number of rollouts total     0
Train Time (s)               29.18674149317667
(Previous) Eval Time (s)     27.20008089626208
Sample Time (s)              17.75314277363941
Epoch Time (s)               74.13996516307816
Total Train Time (s)         7033.686132376082
Epoch                        101
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:12:45.186504 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #101 | Epoch Duration: 70.77375149726868
2020-01-11 05:12:45.186673 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #101 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9313362
Z variance train             0.0073435334
KL Divergence                17.880499
KL Loss                      1.7880499
QF Loss                      273.82507
VF Loss                      52.981216
Policy Loss                  -531.13617
Q Predictions Mean           527.2717
Q Predictions Std            87.608055
Q Predictions Max            657.96344
Q Predictions Min            305.03906
V Predictions Mean           530.53687
V Predictions Std            88.31984
V Predictions Max            656.48773
V Predictions Min            307.77222
Log Pis Mean                 -1.9419544
Log Pis Std                  2.1529524
Log Pis Max                  2.8582006
Log Pis Min                  -10.853488
Policy mu Mean               0.1405366
Policy mu Std                0.44034222
Policy mu Max                1.5635219
Policy mu Min                -1.7372617
Policy log std Mean          -0.8457171
Policy log std Std           0.2107821
Policy log std Max           -0.2669426
Policy log std Min           -1.676594
Z mean eval                  0.91090715
Z variance eval              0.007478288
total_rewards                [ 727.35096465 1450.98613497  721.56422669  -97.50645605 1098.04513958
  284.67849772  120.96001052  993.7023587   979.9078038  1548.34087273]
total_rewards_mean           782.8029553300742
total_rewards_std            517.9920272251637
total_rewards_max            1548.340872730088
total_rewards_min            -97.5064560504042
Number of train steps total  103000
Number of env steps total    517000
Number of rollouts total     0
Train Time (s)               28.538359474856406
(Previous) Eval Time (s)     23.833598298951983
Sample Time (s)              17.839291350450367
Epoch Time (s)               70.21124912425876
Total Train Time (s)         7103.611421211623
Epoch                        102
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:13:55.113059 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #102 | Epoch Duration: 69.92622017860413
2020-01-11 05:13:55.113262 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #102 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9089426
Z variance train             0.0074722967
KL Divergence                17.65146
KL Loss                      1.7651461
QF Loss                      323.5187
VF Loss                      108.858574
Policy Loss                  -532.9915
Q Predictions Mean           530.4663
Q Predictions Std            91.951035
Q Predictions Max            666.5521
Q Predictions Min            256.3717
V Predictions Mean           538.084
V Predictions Std            90.909775
V Predictions Max            665.9169
V Predictions Min            299.8719
Log Pis Mean                 -1.9553893
Log Pis Std                  1.9356816
Log Pis Max                  4.274516
Log Pis Min                  -8.181858
Policy mu Mean               0.071098566
Policy mu Std                0.42678615
Policy mu Max                1.5285197
Policy mu Min                -1.7630622
Policy log std Mean          -0.8328217
Policy log std Std           0.22153625
Policy log std Max           -0.28056914
Policy log std Min           -1.9371855
Z mean eval                  0.94323957
Z variance eval              0.005651037
total_rewards                [ 745.05811646   57.71248903  193.01383426 1052.81579754  732.25975462
 1840.70770001  782.15173674 -117.08642487  763.99466311    6.65009082]
total_rewards_mean           605.7277757713189
total_rewards_std            562.9092478260684
total_rewards_max            1840.7077000054064
total_rewards_min            -117.08642487388741
Number of train steps total  104000
Number of env steps total    522000
Number of rollouts total     0
Train Time (s)               26.311430297326297
(Previous) Eval Time (s)     23.548331582453102
Sample Time (s)              19.448542480822653
Epoch Time (s)               69.30830436060205
Total Train Time (s)         7174.945170136169
Epoch                        103
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:15:06.450599 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #103 | Epoch Duration: 71.33716893196106
2020-01-11 05:15:06.450862 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #103 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9456436
Z variance train             0.00563155
KL Divergence                18.200489
KL Loss                      1.8200489
QF Loss                      258.89798
VF Loss                      548.7111
Policy Loss                  -535.905
Q Predictions Mean           531.2195
Q Predictions Std            109.23093
Q Predictions Max            678.8071
Q Predictions Min            -22.144768
V Predictions Mean           534.9568
V Predictions Std            106.531494
V Predictions Max            685.22064
V Predictions Min            27.477531
Log Pis Mean                 -1.839635
Log Pis Std                  2.0682263
Log Pis Max                  8.329306
Log Pis Min                  -9.040285
Policy mu Mean               0.04804217
Policy mu Std                0.43348682
Policy mu Max                2.129143
Policy mu Min                -2.063205
Policy log std Mean          -0.86717904
Policy log std Std           0.24033666
Policy log std Max           -0.21132433
Policy log std Min           -2.1040478
Z mean eval                  0.9509605
Z variance eval              0.0099251885
total_rewards                [ -14.94437098  -94.83277465  493.73010623  -19.9664555  1573.15966445
  835.00912007 1079.2012047   749.83888503  112.26369334  946.41871721]
total_rewards_mean           565.9877789898529
total_rewards_std            534.535282853877
total_rewards_max            1573.1596644462193
total_rewards_min            -94.83277465316115
Number of train steps total  105000
Number of env steps total    527000
Number of rollouts total     0
Train Time (s)               29.3484818469733
(Previous) Eval Time (s)     25.57682876707986
Sample Time (s)              17.973638800904155
Epoch Time (s)               72.89894941495731
Total Train Time (s)         7246.035560521297
Epoch                        104
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:16:17.544978 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #104 | Epoch Duration: 71.09378170967102
2020-01-11 05:16:17.545389 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #104 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9506505
Z variance train             0.00997875
KL Divergence                17.593203
KL Loss                      1.7593203
QF Loss                      394.25308
VF Loss                      122.285
Policy Loss                  -537.1396
Q Predictions Mean           532.775
Q Predictions Std            117.51915
Q Predictions Max            696.36597
Q Predictions Min            -29.977383
V Predictions Mean           530.6958
V Predictions Std            116.497154
V Predictions Max            686.75543
V Predictions Min            -18.305641
Log Pis Mean                 -1.6802607
Log Pis Std                  2.0464013
Log Pis Max                  4.449562
Log Pis Min                  -7.062427
Policy mu Mean               0.008111075
Policy mu Std                0.44899172
Policy mu Max                1.7564147
Policy mu Min                -1.8301798
Policy log std Mean          -0.8749069
Policy log std Std           0.23340757
Policy log std Max           -0.13692078
Policy log std Min           -1.9243739
Z mean eval                  0.9458065
Z variance eval              0.00739088
total_rewards                [1030.04194024  741.81078068   52.9980295   368.63059168 1458.59216094
  -61.4480189   610.30363318  174.62886075   68.20936072  230.68099083]
total_rewards_mean           467.44483296172893
total_rewards_std            464.4372045490932
total_rewards_max            1458.5921609422655
total_rewards_min            -61.44801890162736
Number of train steps total  106000
Number of env steps total    532000
Number of rollouts total     0
Train Time (s)               30.83392773894593
(Previous) Eval Time (s)     23.771356279030442
Sample Time (s)              18.527797822840512
Epoch Time (s)               73.13308184081689
Total Train Time (s)         7317.371266911272
Epoch                        105
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:17:28.882481 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #105 | Epoch Duration: 71.33684229850769
2020-01-11 05:17:28.882754 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #105 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9474775
Z variance train             0.007391387
KL Divergence                18.038973
KL Loss                      1.8038973
QF Loss                      346.71973
VF Loss                      98.81651
Policy Loss                  -539.8336
Q Predictions Mean           536.6523
Q Predictions Std            100.99715
Q Predictions Max            661.8718
Q Predictions Min            78.81863
V Predictions Mean           545.1063
V Predictions Std            100.422104
V Predictions Max            674.8026
V Predictions Min            12.379625
Log Pis Mean                 -1.6773162
Log Pis Std                  2.0769258
Log Pis Max                  6.2671237
Log Pis Min                  -8.04653
Policy mu Mean               0.06198241
Policy mu Std                0.45783705
Policy mu Max                1.4306692
Policy mu Min                -1.4268115
Policy log std Mean          -0.8509433
Policy log std Std           0.23783992
Policy log std Max           -0.13900283
Policy log std Min           -1.8811239
Z mean eval                  0.9274756
Z variance eval              0.009034363
total_rewards                [ 787.60816385  169.24394727  900.68248665 1554.76665253  390.64279109
   76.42848884  199.39408199  655.65232832 1564.17746233 1747.0594478 ]
total_rewards_mean           804.5655850680089
total_rewards_std            594.2381290187642
total_rewards_max            1747.0594477977527
total_rewards_min            76.42848884233075
Number of train steps total  107000
Number of env steps total    537000
Number of rollouts total     0
Train Time (s)               28.76650984492153
(Previous) Eval Time (s)     21.9748192303814
Sample Time (s)              19.099209067877382
Epoch Time (s)               69.84053814318031
Total Train Time (s)         7387.803015490528
Epoch                        106
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:18:39.318924 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #106 | Epoch Duration: 70.43582081794739
2020-01-11 05:18:39.319364 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #106 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92636174
Z variance train             0.009008432
KL Divergence                17.132687
KL Loss                      1.7132686
QF Loss                      714.8854
VF Loss                      313.5257
Policy Loss                  -536.4504
Q Predictions Mean           532.22217
Q Predictions Std            107.08333
Q Predictions Max            680.3342
Q Predictions Min            -44.91931
V Predictions Mean           540.1336
V Predictions Std            105.03403
V Predictions Max            686.77716
V Predictions Min            20.064234
Log Pis Mean                 -1.7353334
Log Pis Std                  2.0639389
Log Pis Max                  7.5238204
Log Pis Min                  -7.0903177
Policy mu Mean               0.0562478
Policy mu Std                0.44785368
Policy mu Max                1.6351734
Policy mu Min                -1.5075179
Policy log std Mean          -0.8491298
Policy log std Std           0.24542692
Policy log std Max           -0.2207247
Policy log std Min           -2.0503242
Z mean eval                  0.9345024
Z variance eval              0.008168327
total_rewards                [ 796.21668062  959.96474533  159.76007025   67.21583853 1425.22909589
  265.43632188 1802.94413747  644.76807275  311.81709611 1452.29708032]
total_rewards_mean           788.5649139153538
total_rewards_std            578.070314696691
total_rewards_max            1802.9441374665644
total_rewards_min            67.21583852805662
Number of train steps total  108000
Number of env steps total    542000
Number of rollouts total     0
Train Time (s)               27.80497053777799
(Previous) Eval Time (s)     22.5697408108972
Sample Time (s)              18.635151321534067
Epoch Time (s)               69.00986267020926
Total Train Time (s)         7459.351647661999
Epoch                        107
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:19:50.869301 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #107 | Epoch Duration: 71.54964828491211
2020-01-11 05:19:50.869587 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #107 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9356332
Z variance train             0.008163562
KL Divergence                17.632345
KL Loss                      1.7632345
QF Loss                      496.1282
VF Loss                      66.47643
Policy Loss                  -570.6298
Q Predictions Mean           568.3616
Q Predictions Std            89.03212
Q Predictions Max            698.8895
Q Predictions Min            245.97456
V Predictions Mean           572.34454
V Predictions Std            88.56373
V Predictions Max            689.52466
V Predictions Min            228.95636
Log Pis Mean                 -1.5631096
Log Pis Std                  2.2365322
Log Pis Max                  7.1943684
Log Pis Min                  -8.670519
Policy mu Mean               0.10226431
Policy mu Std                0.4789023
Policy mu Max                1.5495156
Policy mu Min                -1.8652332
Policy log std Mean          -0.87709904
Policy log std Std           0.2292549
Policy log std Max           -0.17622912
Policy log std Min           -2.258147
Z mean eval                  0.93591416
Z variance eval              0.009675875
total_rewards                [1565.63553236   40.02724233  231.89762916  859.32523506 1026.38341408
  186.65453621  187.63561893  820.71157214  908.06597689  243.12692937]
total_rewards_mean           606.9463686520609
total_rewards_std            473.4940535022991
total_rewards_max            1565.6355323635169
total_rewards_min            40.02724233287769
Number of train steps total  109000
Number of env steps total    547000
Number of rollouts total     0
Train Time (s)               30.154253859072924
(Previous) Eval Time (s)     25.10922080092132
Sample Time (s)              18.23837898718193
Epoch Time (s)               73.50185364717618
Total Train Time (s)         7535.042568687815
Epoch                        108
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:21:06.560805 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #108 | Epoch Duration: 75.69101691246033
2020-01-11 05:21:06.560966 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #108 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93608224
Z variance train             0.009671235
KL Divergence                17.764137
KL Loss                      1.7764138
QF Loss                      194.7917
VF Loss                      64.84381
Policy Loss                  -556.4995
Q Predictions Mean           555.53955
Q Predictions Std            97.67214
Q Predictions Max            711.8715
Q Predictions Min            305.7707
V Predictions Mean           561.9948
V Predictions Std            98.1311
V Predictions Max            726.71545
V Predictions Min            310.04224
Log Pis Mean                 -1.6498089
Log Pis Std                  1.8926964
Log Pis Max                  3.1932325
Log Pis Min                  -7.8599963
Policy mu Mean               0.007290663
Policy mu Std                0.46618193
Policy mu Max                1.4464076
Policy mu Min                -1.6392533
Policy log std Mean          -0.85117793
Policy log std Std           0.22142354
Policy log std Max           -0.22625408
Policy log std Min           -1.6794343
Z mean eval                  0.9211758
Z variance eval              0.0063700425
total_rewards                [1178.60655304 1367.71059327 1413.83654627 1346.70218043 1544.12296453
  244.89048069 1643.29325411 1286.81365538  544.74965906  153.88966092]
total_rewards_mean           1072.4615547711028
total_rewards_std            518.8035996540342
total_rewards_max            1643.2932541097937
total_rewards_min            153.8896609216666
Number of train steps total  110000
Number of env steps total    552000
Number of rollouts total     0
Train Time (s)               28.16576306009665
(Previous) Eval Time (s)     27.298114887904376
Sample Time (s)              18.19211560720578
Epoch Time (s)               73.6559935552068
Total Train Time (s)         7608.330847520381
Epoch                        109
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:22:19.851714 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #109 | Epoch Duration: 73.29058504104614
2020-01-11 05:22:19.851971 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #109 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9211893
Z variance train             0.006370564
KL Divergence                17.861292
KL Loss                      1.7861292
QF Loss                      381.39624
VF Loss                      60.694958
Policy Loss                  -550.3099
Q Predictions Mean           547.02966
Q Predictions Std            107.51134
Q Predictions Max            694.77026
Q Predictions Min            119.4753
V Predictions Mean           548.9729
V Predictions Std            106.457634
V Predictions Max            705.09534
V Predictions Min            106.38616
Log Pis Mean                 -1.586061
Log Pis Std                  2.108911
Log Pis Max                  3.7704253
Log Pis Min                  -13.572044
Policy mu Mean               0.026321728
Policy mu Std                0.4573756
Policy mu Max                1.4551425
Policy mu Min                -1.8048828
Policy log std Mean          -0.8624879
Policy log std Std           0.21943974
Policy log std Max           -0.30807748
Policy log std Min           -1.9048293
Z mean eval                  0.9253346
Z variance eval              0.0051375898
total_rewards                [ 7.97223290e+02  3.98145625e+02 -1.11344663e+00  3.16377526e+02
  1.10573893e+03  3.22259592e+02  1.44670673e+03  8.36770585e+02
  1.11458466e+03  1.05425708e+02]
total_rewards_mean           644.2119204182914
total_rewards_std            460.1260329169641
total_rewards_max            1446.7067310364218
total_rewards_min            -1.11344662650691
Number of train steps total  111000
Number of env steps total    557000
Number of rollouts total     0
Train Time (s)               27.848459581378847
(Previous) Eval Time (s)     26.932418541051447
Sample Time (s)              19.736338697373867
Epoch Time (s)               74.51721681980416
Total Train Time (s)         7681.01406596601
Epoch                        110
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:23:32.538370 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #110 | Epoch Duration: 72.68617653846741
2020-01-11 05:23:32.538682 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #110 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9233754
Z variance train             0.005137729
KL Divergence                17.927814
KL Loss                      1.7927815
QF Loss                      298.4376
VF Loss                      53.374943
Policy Loss                  -557.88043
Q Predictions Mean           555.7134
Q Predictions Std            104.47747
Q Predictions Max            702.4659
Q Predictions Min            41.38307
V Predictions Mean           559.16974
V Predictions Std            102.044846
V Predictions Max            704.693
V Predictions Min            278.61313
Log Pis Mean                 -1.6755912
Log Pis Std                  2.2006388
Log Pis Max                  6.8382545
Log Pis Min                  -8.163701
Policy mu Mean               0.049754255
Policy mu Std                0.44695705
Policy mu Max                1.7117772
Policy mu Min                -1.6770167
Policy log std Mean          -0.86086357
Policy log std Std           0.24028242
Policy log std Max           -0.27076834
Policy log std Min           -1.8846439
Z mean eval                  0.934618
Z variance eval              0.005353306
total_rewards                [  80.51471877  235.76816394  734.35094287 1503.44025267  651.03471466
  669.76351979  114.79121642  824.74844432  -87.43902626 1693.72812092]
total_rewards_mean           642.0701068093498
total_rewards_std            564.0310142127778
total_rewards_max            1693.7281209237751
total_rewards_min            -87.43902626040912
Number of train steps total  112000
Number of env steps total    562000
Number of rollouts total     0
Train Time (s)               29.725862396880984
(Previous) Eval Time (s)     25.10104104829952
Sample Time (s)              19.19725398812443
Epoch Time (s)               74.02415743330494
Total Train Time (s)         7758.339970597532
Epoch                        111
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:24:49.866738 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #111 | Epoch Duration: 77.32780170440674
2020-01-11 05:24:49.866979 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #111 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93373835
Z variance train             0.0053522643
KL Divergence                17.966564
KL Loss                      1.7966565
QF Loss                      415.03595
VF Loss                      90.33437
Policy Loss                  -567.2175
Q Predictions Mean           563.2324
Q Predictions Std            110.702576
Q Predictions Max            697.09924
Q Predictions Min            -41.999992
V Predictions Mean           573.8457
V Predictions Std            109.30191
V Predictions Max            707.7017
V Predictions Min            36.808857
Log Pis Mean                 -1.8731169
Log Pis Std                  2.227248
Log Pis Max                  8.7775545
Log Pis Min                  -6.7852035
Policy mu Mean               0.016563015
Policy mu Std                0.44016066
Policy mu Max                1.5232313
Policy mu Min                -1.7856113
Policy log std Mean          -0.861519
Policy log std Std           0.24363509
Policy log std Max           -0.16526729
Policy log std Min           -2.1305523
Z mean eval                  0.92993575
Z variance eval              0.011091021
total_rewards                [1868.87674685  531.10801333 1667.89445146  321.74167109  -19.54145183
 1673.37608027  907.15894705  225.5221862  1793.67905816 1640.08354031]
total_rewards_mean           1060.9899242893553
total_rewards_std            706.0237244857826
total_rewards_max            1868.876746850444
total_rewards_min            -19.541451830972047
Number of train steps total  113000
Number of env steps total    567000
Number of rollouts total     0
Train Time (s)               27.85778199089691
(Previous) Eval Time (s)     28.404383037239313
Sample Time (s)              18.84402336133644
Epoch Time (s)               75.10618838947266
Total Train Time (s)         7829.962251307908
Epoch                        112
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:26:01.491755 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #112 | Epoch Duration: 71.62457036972046
2020-01-11 05:26:01.492055 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #112 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9282193
Z variance train             0.011081201
KL Divergence                16.006176
KL Loss                      1.6006176
QF Loss                      354.03253
VF Loss                      88.23481
Policy Loss                  -546.4563
Q Predictions Mean           543.3008
Q Predictions Std            124.87236
Q Predictions Max            707.4615
Q Predictions Min            -42.027477
V Predictions Mean           550.30096
V Predictions Std            123.70221
V Predictions Max            709.3335
V Predictions Min            -11.272998
Log Pis Mean                 -1.6145395
Log Pis Std                  2.3033268
Log Pis Max                  9.009993
Log Pis Min                  -12.723944
Policy mu Mean               0.039035566
Policy mu Std                0.45824483
Policy mu Max                1.9101868
Policy mu Min                -1.8295166
Policy log std Mean          -0.86663175
Policy log std Std           0.22987835
Policy log std Max           -0.15431434
Policy log std Min           -1.9634264
Z mean eval                  0.9161803
Z variance eval              0.007636045
total_rewards                [ 610.82774752  155.80071447 1643.33530171  218.62602825  713.80485178
  782.89045915 1260.21577446  157.24986321  275.61486154  595.4676744 ]
total_rewards_mean           641.3833276471773
total_rewards_std            468.8132231783175
total_rewards_max            1643.33530170607
total_rewards_min            155.8007144674824
Number of train steps total  114000
Number of env steps total    572000
Number of rollouts total     0
Train Time (s)               29.393971015233546
(Previous) Eval Time (s)     24.92244157800451
Sample Time (s)              18.377691863570362
Epoch Time (s)               72.69410445680842
Total Train Time (s)         7894.806881075725
Epoch                        113
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:27:06.339883 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #113 | Epoch Duration: 64.84757542610168
2020-01-11 05:27:06.340148 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #113 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91562384
Z variance train             0.0076542795
KL Divergence                16.927475
KL Loss                      1.6927475
QF Loss                      365.92786
VF Loss                      59.384453
Policy Loss                  -572.1737
Q Predictions Mean           568.54395
Q Predictions Std            112.521416
Q Predictions Max            711.4239
Q Predictions Min            188.7344
V Predictions Mean           569.688
V Predictions Std            115.41657
V Predictions Max            711.0171
V Predictions Min            40.39295
Log Pis Mean                 -1.8047633
Log Pis Std                  2.2897348
Log Pis Max                  5.8924203
Log Pis Min                  -7.435878
Policy mu Mean               0.0531661
Policy mu Std                0.460349
Policy mu Max                1.5776783
Policy mu Min                -1.7546841
Policy log std Mean          -0.84764385
Policy log std Std           0.25891972
Policy log std Max           -0.22153339
Policy log std Min           -2.652592
Z mean eval                  0.9537897
Z variance eval              0.0077698156
total_rewards                [ 869.48111776  -52.54355708  602.4314882  1243.7071344   601.40266744
  872.68789653  289.40103016  597.73274825  340.30294829  455.95759418]
total_rewards_mean           582.0561068145867
total_rewards_std            341.8488570872726
total_rewards_max            1243.7071343975038
total_rewards_min            -52.54355707603433
Number of train steps total  115000
Number of env steps total    577000
Number of rollouts total     0
Train Time (s)               27.15873744804412
(Previous) Eval Time (s)     17.075596934184432
Sample Time (s)              17.938863972667605
Epoch Time (s)               62.17319835489616
Total Train Time (s)         7966.247430819552
Epoch                        114
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:28:17.782195 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #114 | Epoch Duration: 71.44182968139648
2020-01-11 05:28:17.782460 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #114 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9533638
Z variance train             0.0077377246
KL Divergence                16.63058
KL Loss                      1.6630582
QF Loss                      311.76114
VF Loss                      140.95381
Policy Loss                  -572.1971
Q Predictions Mean           570.8267
Q Predictions Std            114.061615
Q Predictions Max            723.68805
Q Predictions Min            305.59128
V Predictions Mean           577.4499
V Predictions Std            113.518074
V Predictions Max            734.57294
V Predictions Min            318.24268
Log Pis Mean                 -1.542867
Log Pis Std                  2.287833
Log Pis Max                  5.411988
Log Pis Min                  -8.755628
Policy mu Mean               0.008277988
Policy mu Std                0.45850083
Policy mu Max                1.5245247
Policy mu Min                -1.6164142
Policy log std Mean          -0.879087
Policy log std Std           0.25145158
Policy log std Max           -0.18966246
Policy log std Min           -2.3329828
Z mean eval                  0.93285215
Z variance eval              0.010292156
total_rewards                [ 637.31652813  936.13993687 1129.01841761   28.05002719  180.50926974
  757.48788045  393.91251291 1020.8736614    13.5984883   -27.35763315]
total_rewards_mean           506.95490894543946
total_rewards_std            423.3936557829409
total_rewards_max            1129.018417610857
total_rewards_min            -27.357633151091747
Number of train steps total  116000
Number of env steps total    582000
Number of rollouts total     0
Train Time (s)               27.177924289833754
(Previous) Eval Time (s)     26.34390235831961
Sample Time (s)              18.49580220831558
Epoch Time (s)               72.01762885646895
Total Train Time (s)         8037.183885743376
Epoch                        115
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:29:28.722369 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #115 | Epoch Duration: 70.93968415260315
2020-01-11 05:29:28.722635 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #115 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93229026
Z variance train             0.010283263
KL Divergence                16.674381
KL Loss                      1.6674381
QF Loss                      536.92737
VF Loss                      132.05301
Policy Loss                  -576.97894
Q Predictions Mean           575.1394
Q Predictions Std            122.7784
Q Predictions Max            751.34534
Q Predictions Min            -69.4539
V Predictions Mean           579.2433
V Predictions Std            115.84004
V Predictions Max            730.6713
V Predictions Min            -9.08072
Log Pis Mean                 -1.5774386
Log Pis Std                  2.2662401
Log Pis Max                  7.689188
Log Pis Min                  -7.1172314
Policy mu Mean               0.03629465
Policy mu Std                0.49120852
Policy mu Max                2.531624
Policy mu Min                -1.7312338
Policy log std Mean          -0.8431407
Policy log std Std           0.24782886
Policy log std Max           -0.0871315
Policy log std Min           -2.6306756
Z mean eval                  0.94343597
Z variance eval              0.006873826
total_rewards                [1602.49712733  358.97492833  -52.00947991  388.45524468  666.79952726
 1594.69384727 1666.59123616  -60.95267191  597.03772727 1649.8898642 ]
total_rewards_mean           841.1977350677267
total_rewards_std            679.8403102978657
total_rewards_max            1666.5912361574847
total_rewards_min            -60.9526719142986
Number of train steps total  117000
Number of env steps total    587000
Number of rollouts total     0
Train Time (s)               29.060352549888194
(Previous) Eval Time (s)     25.265624797903
Sample Time (s)              17.97158039174974
Epoch Time (s)               72.29755773954093
Total Train Time (s)         8108.555500312243
Epoch                        116
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:30:40.096253 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #116 | Epoch Duration: 71.37339973449707
2020-01-11 05:30:40.096538 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #116 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9407573
Z variance train             0.0068937526
KL Divergence                17.99228
KL Loss                      1.799228
QF Loss                      400.43195
VF Loss                      115.97214
Policy Loss                  -574.84143
Q Predictions Mean           571.379
Q Predictions Std            124.56507
Q Predictions Max            733.96606
Q Predictions Min            124.484566
V Predictions Mean           573.31586
V Predictions Std            122.13378
V Predictions Max            735.953
V Predictions Min            159.64833
Log Pis Mean                 -1.8840573
Log Pis Std                  2.1550813
Log Pis Max                  7.1960793
Log Pis Min                  -7.8575335
Policy mu Mean               0.07259525
Policy mu Std                0.46518773
Policy mu Max                2.2190075
Policy mu Min                -1.4040923
Policy log std Mean          -0.8230223
Policy log std Std           0.23280749
Policy log std Max           -0.09776986
Policy log std Min           -1.7668021
Z mean eval                  0.92332065
Z variance eval              0.0044443947
total_rewards                [  49.88695657  161.78167311  473.40392182  625.1317527  1753.69707904
  401.24401318  256.53309779  679.35045107  150.7638645   554.59804125]
total_rewards_mean           510.63908510254385
total_rewards_std            461.5328207458067
total_rewards_max            1753.6970790436537
total_rewards_min            49.88695656890174
Number of train steps total  118000
Number of env steps total    592000
Number of rollouts total     0
Train Time (s)               29.55249900696799
(Previous) Eval Time (s)     24.341188246849924
Sample Time (s)              17.4481344637461
Epoch Time (s)               71.34182171756402
Total Train Time (s)         8177.910752178635
Epoch                        117
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:31:49.455138 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #117 | Epoch Duration: 69.35835123062134
2020-01-11 05:31:49.455436 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #117 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92551214
Z variance train             0.004424981
KL Divergence                18.92207
KL Loss                      1.892207
QF Loss                      298.6646
VF Loss                      115.85767
Policy Loss                  -594.6694
Q Predictions Mean           588.3955
Q Predictions Std            106.39401
Q Predictions Max            733.4352
Q Predictions Min            282.24014
V Predictions Mean           586.7746
V Predictions Std            105.09987
V Predictions Max            718.18414
V Predictions Min            277.93304
Log Pis Mean                 -1.5937026
Log Pis Std                  2.0473685
Log Pis Max                  5.6574802
Log Pis Min                  -8.344028
Policy mu Mean               0.06315845
Policy mu Std                0.46364865
Policy mu Max                1.6655357
Policy mu Min                -1.8443837
Policy log std Mean          -0.86543536
Policy log std Std           0.21423362
Policy log std Max           -0.16028169
Policy log std Min           -1.6414402
Z mean eval                  0.91275537
Z variance eval              0.0048040827
total_rewards                [ 620.22397498  542.60303513  349.65363293 1318.45943407   13.14409393
 1705.522451    108.03928479    6.00810814   63.80864784  609.32685422]
total_rewards_mean           533.6789517023203
total_rewards_std            546.5890121076394
total_rewards_max            1705.5224510006883
total_rewards_min            6.008108139783602
Number of train steps total  119000
Number of env steps total    597000
Number of rollouts total     0
Train Time (s)               26.592080089263618
(Previous) Eval Time (s)     22.357420743908733
Sample Time (s)              17.683137335348874
Epoch Time (s)               66.63263816852123
Total Train Time (s)         8248.548113573343
Epoch                        118
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:33:00.092170 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #118 | Epoch Duration: 70.63651394844055
2020-01-11 05:33:00.092409 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #118 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91496944
Z variance train             0.00480944
KL Divergence                19.255348
KL Loss                      1.9255348
QF Loss                      328.88745
VF Loss                      80.24624
Policy Loss                  -584.7823
Q Predictions Mean           580.8489
Q Predictions Std            116.170074
Q Predictions Max            736.8417
Q Predictions Min            282.6449
V Predictions Mean           580.7568
V Predictions Std            113.77155
V Predictions Max            730.25323
V Predictions Min            277.35403
Log Pis Mean                 -1.7827002
Log Pis Std                  2.2746358
Log Pis Max                  6.7317867
Log Pis Min                  -8.391139
Policy mu Mean               0.05589692
Policy mu Std                0.46951807
Policy mu Max                1.8012033
Policy mu Min                -1.6942004
Policy log std Mean          -0.8433738
Policy log std Std           0.23627877
Policy log std Max           -0.16739535
Policy log std Min           -1.8536198
Z mean eval                  0.9395053
Z variance eval              0.005618044
total_rewards                [7.92962751e+02 1.59718981e+02 1.30173982e+02 8.92861467e+01
 6.76870723e-01 5.07496937e+02 1.73382113e+03 1.20111055e+03
 8.46591742e+02 3.39076850e+02]
total_rewards_mean           580.0915941142248
total_rewards_std            534.0600468959486
total_rewards_max            1733.821128442882
total_rewards_min            0.6768707231070898
Number of train steps total  120000
Number of env steps total    602000
Number of rollouts total     0
Train Time (s)               32.422123988159
(Previous) Eval Time (s)     26.361012667883188
Sample Time (s)              17.44400376966223
Epoch Time (s)               76.22714042570442
Total Train Time (s)         8323.096208659466
Epoch                        119
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:34:14.644528 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #119 | Epoch Duration: 74.55196738243103
2020-01-11 05:34:14.644802 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #119 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9383742
Z variance train             0.00567486
KL Divergence                19.324652
KL Loss                      1.9324652
QF Loss                      287.05954
VF Loss                      97.73711
Policy Loss                  -578.86383
Q Predictions Mean           575.3991
Q Predictions Std            129.45155
Q Predictions Max            739.61957
Q Predictions Min            -44.065582
V Predictions Mean           582.6773
V Predictions Std            128.5334
V Predictions Max            743.0028
V Predictions Min            -4.251669
Log Pis Mean                 -2.0668674
Log Pis Std                  2.0090969
Log Pis Max                  4.4077682
Log Pis Min                  -8.061613
Policy mu Mean               0.04339601
Policy mu Std                0.46051052
Policy mu Max                2.1221783
Policy mu Min                -2.8012545
Policy log std Mean          -0.81090844
Policy log std Std           0.21949492
Policy log std Max           -0.08966583
Policy log std Min           -1.4631684
Z mean eval                  0.9392377
Z variance eval              0.0063231466
total_rewards                [ 361.82852548 1681.29415033  487.87664034 1605.57691569  111.45997177
  681.9167269  1711.33612766 1331.32667584  614.91595821  244.41450166]
total_rewards_mean           883.1946193874892
total_rewards_std            599.1359849536444
total_rewards_max            1711.3361276581288
total_rewards_min            111.45997176709442
Number of train steps total  121000
Number of env steps total    607000
Number of rollouts total     0
Train Time (s)               28.932871445082128
(Previous) Eval Time (s)     24.68553935131058
Sample Time (s)              17.833680057432503
Epoch Time (s)               71.45209085382521
Total Train Time (s)         8393.523124356288
Epoch                        120
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:35:25.074073 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #120 | Epoch Duration: 70.4290554523468
2020-01-11 05:35:25.074306 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #120 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93978167
Z variance train             0.006312574
KL Divergence                19.125546
KL Loss                      1.9125546
QF Loss                      412.12653
VF Loss                      60.414017
Policy Loss                  -584.21594
Q Predictions Mean           580.9603
Q Predictions Std            118.297935
Q Predictions Max            741.43713
Q Predictions Min            268.48798
V Predictions Mean           581.4363
V Predictions Std            117.204956
V Predictions Max            738.0497
V Predictions Min            261.79486
Log Pis Mean                 -1.7907848
Log Pis Std                  2.1331217
Log Pis Max                  4.204361
Log Pis Min                  -9.360911
Policy mu Mean               0.01155327
Policy mu Std                0.47582847
Policy mu Max                1.5303793
Policy mu Min                -1.5980283
Policy log std Mean          -0.8221741
Policy log std Std           0.21486324
Policy log std Max           -0.1379947
Policy log std Min           -1.7666773
Z mean eval                  0.93001926
Z variance eval              0.014714694
total_rewards                [ 362.5348143   958.31427487  267.45553093  658.61443461   96.41467044
 1032.84751597 1609.69387388 -128.1012668  1109.21426843  178.96214747]
total_rewards_mean           614.5950264105654
total_rewards_std            521.9013830417191
total_rewards_max            1609.6938738759623
total_rewards_min            -128.1012667952574
Number of train steps total  122000
Number of env steps total    612000
Number of rollouts total     0
Train Time (s)               27.14835422579199
(Previous) Eval Time (s)     23.662231401074678
Sample Time (s)              17.84651780175045
Epoch Time (s)               68.65710342861712
Total Train Time (s)         8461.68147663027
Epoch                        121
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:36:33.232292 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #121 | Epoch Duration: 68.15779256820679
2020-01-11 05:36:33.232519 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #121 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93251514
Z variance train             0.014671823
KL Divergence                18.034428
KL Loss                      1.8034428
QF Loss                      501.80392
VF Loss                      233.3757
Policy Loss                  -589.69415
Q Predictions Mean           586.8684
Q Predictions Std            126.418106
Q Predictions Max            787.57404
Q Predictions Min            -4.6905065
V Predictions Mean           579.71515
V Predictions Std            124.86651
V Predictions Max            776.0843
V Predictions Min            -2.2315085
Log Pis Mean                 -1.7126689
Log Pis Std                  2.3084404
Log Pis Max                  7.8014393
Log Pis Min                  -7.6947584
Policy mu Mean               0.11122786
Policy mu Std                0.4834446
Policy mu Max                1.6993474
Policy mu Min                -1.9233183
Policy log std Mean          -0.8218816
Policy log std Std           0.25126553
Policy log std Max           -0.24429405
Policy log std Min           -2.3495564
Z mean eval                  0.9338705
Z variance eval              0.0074159494
total_rewards                [ 518.71530997  439.82546137 1350.31154762 1551.24297514 1286.66248667
 1890.8429329  1913.71768832  289.93866584 1709.93354675  595.9927782 ]
total_rewards_mean           1154.7183392778588
total_rewards_std            601.2246601867479
total_rewards_max            1913.7176883182385
total_rewards_min            289.93866583938774
Number of train steps total  123000
Number of env steps total    617000
Number of rollouts total     0
Train Time (s)               29.92198373703286
(Previous) Eval Time (s)     23.162637814879417
Sample Time (s)              17.736866601742804
Epoch Time (s)               70.82148815365508
Total Train Time (s)         8534.061844027601
Epoch                        122
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:37:45.616191 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #122 | Epoch Duration: 72.38353300094604
2020-01-11 05:37:45.616410 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #122 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93293446
Z variance train             0.0074134893
KL Divergence                19.148727
KL Loss                      1.9148728
QF Loss                      352.3419
VF Loss                      56.82625
Policy Loss                  -601.51
Q Predictions Mean           598.95996
Q Predictions Std            119.23402
Q Predictions Max            745.8651
Q Predictions Min            279.31924
V Predictions Mean           603.66003
V Predictions Std            118.598694
V Predictions Max            751.5461
V Predictions Min            255.37276
Log Pis Mean                 -1.5589592
Log Pis Std                  2.1117842
Log Pis Max                  5.5799623
Log Pis Min                  -7.1270285
Policy mu Mean               0.03885386
Policy mu Std                0.47654995
Policy mu Max                1.8606839
Policy mu Min                -1.5619774
Policy log std Mean          -0.8358262
Policy log std Std           0.22709921
Policy log std Max           -0.1614669
Policy log std Min           -1.8453732
Z mean eval                  0.9185494
Z variance eval              0.009443773
total_rewards                [ 271.93353966  118.04975115  882.27410836  110.76591963 1716.56459419
   74.08239101 1918.08877235 1778.36947519 1678.43969723   58.49675643]
total_rewards_mean           860.7065005219904
total_rewards_std            780.0467875672554
total_rewards_max            1918.0887723542278
total_rewards_min            58.49675643406991
Number of train steps total  124000
Number of env steps total    622000
Number of rollouts total     0
Train Time (s)               29.47455327026546
(Previous) Eval Time (s)     24.72436079988256
Sample Time (s)              17.924384823534638
Epoch Time (s)               72.12329889368266
Total Train Time (s)         8603.878644882701
Epoch                        123
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:38:55.435531 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #123 | Epoch Duration: 69.81892824172974
2020-01-11 05:38:55.435817 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #123 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91766226
Z variance train             0.009444478
KL Divergence                19.044281
KL Loss                      1.9044281
QF Loss                      420.94165
VF Loss                      47.634186
Policy Loss                  -587.4625
Q Predictions Mean           585.8115
Q Predictions Std            134.48749
Q Predictions Max            730.6852
Q Predictions Min            -47.56726
V Predictions Mean           588.3467
V Predictions Std            133.55463
V Predictions Max            735.30865
V Predictions Min            -7.051205
Log Pis Mean                 -1.8133187
Log Pis Std                  2.3666909
Log Pis Max                  8.223674
Log Pis Min                  -7.570896
Policy mu Mean               0.043090887
Policy mu Std                0.46301743
Policy mu Max                1.4785199
Policy mu Min                -2.5397434
Policy log std Mean          -0.82477343
Policy log std Std           0.2517493
Policy log std Max           0.44145662
Policy log std Min           -2.0565896
Z mean eval                  0.929797
Z variance eval              0.010721324
total_rewards                [1167.42544852 1663.57846867 1825.06802294  528.7323575   547.90949909
  154.5389332   246.56725463  231.99729975 1658.18817304  502.09088171]
total_rewards_mean           852.6096339034409
total_rewards_std            625.4409120878734
total_rewards_max            1825.068022938739
total_rewards_min            154.53893319535067
Number of train steps total  125000
Number of env steps total    627000
Number of rollouts total     0
Train Time (s)               27.15427488507703
(Previous) Eval Time (s)     22.41965516936034
Sample Time (s)              18.406266757752746
Epoch Time (s)               67.98019681219012
Total Train Time (s)         8673.135308921803
Epoch                        124
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:40:04.700957 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #124 | Epoch Duration: 69.2649154663086
2020-01-11 05:40:04.701164 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #124 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9272634
Z variance train             0.010748374
KL Divergence                18.632656
KL Loss                      1.8632656
QF Loss                      524.6518
VF Loss                      128.64157
Policy Loss                  -588.96014
Q Predictions Mean           586.9171
Q Predictions Std            144.15097
Q Predictions Max            765.19586
Q Predictions Min            -0.586463
V Predictions Mean           591.74194
V Predictions Std            139.79918
V Predictions Max            765.42145
V Predictions Min            80.75149
Log Pis Mean                 -1.6057677
Log Pis Std                  2.2381794
Log Pis Max                  8.917685
Log Pis Min                  -7.148918
Policy mu Mean               0.037810963
Policy mu Std                0.50464386
Policy mu Max                1.933537
Policy mu Min                -1.6187979
Policy log std Mean          -0.8144204
Policy log std Std           0.2506722
Policy log std Max           -0.13655692
Policy log std Min           -2.3056564
Z mean eval                  0.9321602
Z variance eval              0.013728115
total_rewards                [1590.66100769  996.66346737  456.00902291 1321.15298761 1577.76263289
 1790.92371536 1709.5430289  1721.15415515 1637.69762176 1775.42474345]
total_rewards_mean           1457.6992383088827
total_rewards_std            405.4500528990742
total_rewards_max            1790.9237153619679
total_rewards_min            456.0090229131713
Number of train steps total  126000
Number of env steps total    632000
Number of rollouts total     0
Train Time (s)               30.70042227813974
(Previous) Eval Time (s)     23.70405373442918
Sample Time (s)              17.94996698619798
Epoch Time (s)               72.3544429987669
Total Train Time (s)         8749.205912117846
Epoch                        125
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:41:20.766312 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #125 | Epoch Duration: 76.06498742103577
2020-01-11 05:41:20.766502 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #125 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9323524
Z variance train             0.013734673
KL Divergence                18.289227
KL Loss                      1.8289226
QF Loss                      394.44232
VF Loss                      90.56522
Policy Loss                  -584.741
Q Predictions Mean           582.28723
Q Predictions Std            140.697
Q Predictions Max            747.2014
Q Predictions Min            -71.64131
V Predictions Mean           583.5115
V Predictions Std            137.73273
V Predictions Max            753.5011
V Predictions Min            1.9490318
Log Pis Mean                 -1.6476173
Log Pis Std                  2.0764523
Log Pis Max                  7.5368443
Log Pis Min                  -6.8133674
Policy mu Mean               0.102437325
Policy mu Std                0.45170245
Policy mu Max                1.9834675
Policy mu Min                -1.3687713
Policy log std Mean          -0.8581947
Policy log std Std           0.24064074
Policy log std Max           -0.22262546
Policy log std Min           -2.1563585
Z mean eval                  0.930313
Z variance eval              0.01272313
total_rewards                [  82.50057338   96.77479322 1840.26916577  722.89647664  107.27103405
  253.34399556 1501.16850723 1153.92368904  988.55339954  541.91909396]
total_rewards_mean           728.8620728397211
total_rewards_std            595.3648932890351
total_rewards_max            1840.269165772421
total_rewards_min            82.50057337846384
Number of train steps total  127000
Number of env steps total    637000
Number of rollouts total     0
Train Time (s)               28.369376676157117
(Previous) Eval Time (s)     27.414276191033423
Sample Time (s)              18.541628325823694
Epoch Time (s)               74.32528119301423
Total Train Time (s)         8820.435884302016
Epoch                        126
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:42:31.997586 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #126 | Epoch Duration: 71.23093676567078
2020-01-11 05:42:31.997762 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #126 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.928185
Z variance train             0.012692327
KL Divergence                18.358612
KL Loss                      1.8358612
QF Loss                      349.56665
VF Loss                      130.91824
Policy Loss                  -605.8388
Q Predictions Mean           601.458
Q Predictions Std            134.38809
Q Predictions Max            766.88306
Q Predictions Min            -70.76646
V Predictions Mean           602.4508
V Predictions Std            128.71379
V Predictions Max            763.0793
V Predictions Min            -0.47446483
Log Pis Mean                 -1.4604111
Log Pis Std                  2.130357
Log Pis Max                  4.6127567
Log Pis Min                  -8.203983
Policy mu Mean               0.050987177
Policy mu Std                0.47734678
Policy mu Max                1.5213798
Policy mu Min                -1.8028384
Policy log std Mean          -0.85378563
Policy log std Std           0.23925236
Policy log std Max           -0.2787561
Policy log std Min           -1.9103261
Z mean eval                  0.922623
Z variance eval              0.010802831
total_rewards                [ 527.44360748  108.27950348 1143.74344334 1852.29130737 1374.70929929
 1803.93831712 1710.03256058 1885.49891544 1059.20039863  515.05806739]
total_rewards_mean           1198.0195420120401
total_rewards_std            607.2126527167025
total_rewards_max            1885.4989154438736
total_rewards_min            108.27950348286257
Number of train steps total  128000
Number of env steps total    642000
Number of rollouts total     0
Train Time (s)               31.081621384248137
(Previous) Eval Time (s)     24.3195859240368
Sample Time (s)              17.734809149522334
Epoch Time (s)               73.13601645780727
Total Train Time (s)         8891.761330638546
Epoch                        127
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:43:43.326040 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #127 | Epoch Duration: 71.32812404632568
2020-01-11 05:43:43.326224 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #127 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92348033
Z variance train             0.010809407
KL Divergence                17.917023
KL Loss                      1.7917023
QF Loss                      445.812
VF Loss                      98.763245
Policy Loss                  -631.2636
Q Predictions Mean           627.2639
Q Predictions Std            100.20642
Q Predictions Max            752.69165
Q Predictions Min            254.93416
V Predictions Mean           625.6181
V Predictions Std            98.66254
V Predictions Max            740.41895
V Predictions Min            237.06084
Log Pis Mean                 -1.6096487
Log Pis Std                  2.1639252
Log Pis Max                  6.793354
Log Pis Min                  -8.449963
Policy mu Mean               0.0261508
Policy mu Std                0.4741408
Policy mu Max                1.517068
Policy mu Min                -1.6196196
Policy log std Mean          -0.8822725
Policy log std Std           0.23524833
Policy log std Max           -0.27767715
Policy log std Min           -2.448907
Z mean eval                  0.9320487
Z variance eval              0.018525943
total_rewards                [1888.78686047 1862.49799425   99.5790784  1840.61683674 1723.41681381
  320.19780703 1828.58934802  860.06960997  245.46247604 1456.91119725]
total_rewards_mean           1212.6128021973211
total_rewards_std            711.9617817073704
total_rewards_max            1888.7868604681046
total_rewards_min            99.57907839587618
Number of train steps total  129000
Number of env steps total    647000
Number of rollouts total     0
Train Time (s)               26.33798607904464
(Previous) Eval Time (s)     22.511397717054933
Sample Time (s)              17.984405836090446
Epoch Time (s)               66.83378963219002
Total Train Time (s)         8960.60968115693
Epoch                        128
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:44:52.175184 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #128 | Epoch Duration: 68.84881472587585
2020-01-11 05:44:52.175368 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #128 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9325325
Z variance train             0.018584544
KL Divergence                17.267946
KL Loss                      1.7267946
QF Loss                      1954.2333
VF Loss                      105.0964
Policy Loss                  -570.00354
Q Predictions Mean           567.0167
Q Predictions Std            131.49936
Q Predictions Max            735.45233
Q Predictions Min            31.443651
V Predictions Mean           572.9037
V Predictions Std            130.41536
V Predictions Max            742.8759
V Predictions Min            2.3555362
Log Pis Mean                 -1.4757204
Log Pis Std                  2.3463037
Log Pis Max                  7.2162485
Log Pis Min                  -8.57498
Policy mu Mean               -0.0019380865
Policy mu Std                0.50112206
Policy mu Max                1.3944246
Policy mu Min                -1.5521566
Policy log std Mean          -0.87187207
Policy log std Std           0.25397688
Policy log std Max           -0.18504876
Policy log std Min           -2.2483377
Z mean eval                  0.9495449
Z variance eval              0.017732408
total_rewards                [1001.80973102 1962.98049838 1889.45899009 1480.23188023  486.04088029
  923.41274415  182.37223109 1145.1614591  1930.59372811  587.05839683]
total_rewards_mean           1158.912053929565
total_rewards_std            607.6755974194995
total_rewards_max            1962.9804983758152
total_rewards_min            182.37223108684773
Number of train steps total  130000
Number of env steps total    652000
Number of rollouts total     0
Train Time (s)               29.33234988618642
(Previous) Eval Time (s)     24.526102629955858
Sample Time (s)              18.311002573929727
Epoch Time (s)               72.169455090072
Total Train Time (s)         9033.424598601181
Epoch                        129
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:46:04.992128 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #129 | Epoch Duration: 72.81661486625671
2020-01-11 05:46:04.992319 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #129 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9479321
Z variance train             0.01778176
KL Divergence                16.91266
KL Loss                      1.6912661
QF Loss                      311.5598
VF Loss                      54.80452
Policy Loss                  -614.46173
Q Predictions Mean           611.6501
Q Predictions Std            129.83775
Q Predictions Max            769.46954
Q Predictions Min            274.45676
V Predictions Mean           617.7069
V Predictions Std            130.48961
V Predictions Max            767.93384
V Predictions Min            281.38727
Log Pis Mean                 -1.7140651
Log Pis Std                  2.290611
Log Pis Max                  4.587346
Log Pis Min                  -10.829669
Policy mu Mean               0.03296018
Policy mu Std                0.5082161
Policy mu Max                1.5027554
Policy mu Min                -1.6868204
Policy log std Mean          -0.81218404
Policy log std Std           0.23653871
Policy log std Max           -0.13360924
Policy log std Min           -1.6743766
Z mean eval                  0.9438853
Z variance eval              0.01686069
total_rewards                [1569.10451065  296.03607957  234.70024589 1078.58533353 1723.06640993
  604.90967592   30.81194754  420.75549186  558.15020187   29.5783007 ]
total_rewards_mean           654.5698197458734
total_rewards_std            575.2221324387681
total_rewards_max            1723.0664099272144
total_rewards_min            29.57830069830018
Number of train steps total  131000
Number of env steps total    657000
Number of rollouts total     0
Train Time (s)               28.86149015603587
(Previous) Eval Time (s)     25.17295277863741
Sample Time (s)              18.455036654602736
Epoch Time (s)               72.48947958927602
Total Train Time (s)         9108.005001373123
Epoch                        130
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:47:19.576959 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #130 | Epoch Duration: 74.58446455001831
2020-01-11 05:47:19.577247 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #130 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93988484
Z variance train             0.016879803
KL Divergence                16.239616
KL Loss                      1.6239617
QF Loss                      391.141
VF Loss                      67.07724
Policy Loss                  -594.6142
Q Predictions Mean           592.228
Q Predictions Std            147.0053
Q Predictions Max            765.7836
Q Predictions Min            -14.760094
V Predictions Mean           590.80066
V Predictions Std            147.3336
V Predictions Max            759.9931
V Predictions Min            6.0946136
Log Pis Mean                 -1.4341555
Log Pis Std                  2.5201948
Log Pis Max                  8.7747555
Log Pis Min                  -8.553055
Policy mu Mean               -0.018358238
Policy mu Std                0.4934931
Policy mu Max                1.6619216
Policy mu Min                -1.8303086
Policy log std Mean          -0.85910815
Policy log std Std           0.26545608
Policy log std Max           -0.032764375
Policy log std Min           -2.1276364
Z mean eval                  0.9599248
Z variance eval              0.012054667
total_rewards                [ 595.2129721  1722.59343407 1538.37883313 1528.36518867 1595.24540497
 1593.15296746 1686.02571407  406.14310337 1600.38132877 1477.86556249]
total_rewards_mean           1374.3364509081055
total_rewards_std            444.07157411988675
total_rewards_max            1722.5934340696901
total_rewards_min            406.14310336967617
Number of train steps total  132000
Number of env steps total    662000
Number of rollouts total     0
Train Time (s)               29.614381862338632
(Previous) Eval Time (s)     27.267592686694115
Sample Time (s)              18.331947466358542
Epoch Time (s)               75.21392201539129
Total Train Time (s)         9183.55745117087
Epoch                        131
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:48:35.131982 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #131 | Epoch Duration: 75.55449891090393
2020-01-11 05:48:35.132244 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #131 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9599142
Z variance train             0.012048892
KL Divergence                16.523834
KL Loss                      1.6523834
QF Loss                      658.43695
VF Loss                      62.705807
Policy Loss                  -616.90784
Q Predictions Mean           613.37946
Q Predictions Std            140.44853
Q Predictions Max            779.4036
Q Predictions Min            -29.928007
V Predictions Mean           615.42426
V Predictions Std            137.59193
V Predictions Max            773.9059
V Predictions Min            35.00443
Log Pis Mean                 -1.4662322
Log Pis Std                  2.2660909
Log Pis Max                  10.8426695
Log Pis Min                  -7.181153
Policy mu Mean               0.021306185
Policy mu Std                0.5147457
Policy mu Max                1.7396464
Policy mu Min                -2.8540013
Policy log std Mean          -0.81264335
Policy log std Std           0.23238827
Policy log std Max           -0.14009604
Policy log std Min           -1.64065
Z mean eval                  0.9272725
Z variance eval              0.01558467
total_rewards                [1817.29347194 1890.00279539 1349.58138687  874.505863     62.18686765
  683.97063542 1100.0214828   219.42622055  580.97680619 1139.52447702]
total_rewards_mean           971.7490006846976
total_rewards_std            581.7012634699877
total_rewards_max            1890.0027953857896
total_rewards_min            62.186867650540606
Number of train steps total  133000
Number of env steps total    667000
Number of rollouts total     0
Train Time (s)               28.519165951292962
(Previous) Eval Time (s)     27.607852045912296
Sample Time (s)              18.332689722068608
Epoch Time (s)               74.45970771927387
Total Train Time (s)         9255.594023917336
Epoch                        132
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:49:47.170158 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #132 | Epoch Duration: 72.03773140907288
2020-01-11 05:49:47.170343 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #132 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9285264
Z variance train             0.015506836
KL Divergence                16.82597
KL Loss                      1.682597
QF Loss                      408.0681
VF Loss                      295.50977
Policy Loss                  -614.3654
Q Predictions Mean           609.24207
Q Predictions Std            143.69841
Q Predictions Max            787.2321
Q Predictions Min            14.35407
V Predictions Mean           613.85956
V Predictions Std            142.07922
V Predictions Max            785.93695
V Predictions Min            21.292439
Log Pis Mean                 -1.5237851
Log Pis Std                  2.471336
Log Pis Max                  9.4638
Log Pis Min                  -7.7910385
Policy mu Mean               0.048613288
Policy mu Std                0.50475997
Policy mu Max                1.6300956
Policy mu Min                -1.7266674
Policy log std Mean          -0.8362593
Policy log std Std           0.26224133
Policy log std Max           -0.093515694
Policy log std Min           -2.5465417
Z mean eval                  0.9459686
Z variance eval              0.010901848
total_rewards                [1723.49204541 1830.51225832 1877.71639268  248.63453708 1344.96811032
 1752.99621713 1840.98676548  103.69684484 1599.77341729 1174.70611874]
total_rewards_mean           1349.7482707270933
total_rewards_std            625.4409414870605
total_rewards_max            1877.7163926764815
total_rewards_min            103.69684483667237
Number of train steps total  134000
Number of env steps total    672000
Number of rollouts total     0
Train Time (s)               30.52769614942372
(Previous) Eval Time (s)     25.185590866021812
Sample Time (s)              17.82089738594368
Epoch Time (s)               73.53418440138921
Total Train Time (s)         9330.712644591462
Epoch                        133
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:51:02.289778 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #133 | Epoch Duration: 75.11929631233215
2020-01-11 05:51:02.289959 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #133 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.945666
Z variance train             0.010883558
KL Divergence                17.568356
KL Loss                      1.7568356
QF Loss                      464.03375
VF Loss                      76.57423
Policy Loss                  -622.8328
Q Predictions Mean           619.5637
Q Predictions Std            136.5143
Q Predictions Max            788.4484
Q Predictions Min            43.910103
V Predictions Mean           619.2096
V Predictions Std            132.18068
V Predictions Max            782.1267
V Predictions Min            125.69851
Log Pis Mean                 -1.729158
Log Pis Std                  2.437623
Log Pis Max                  4.9716425
Log Pis Min                  -7.732907
Policy mu Mean               0.074693926
Policy mu Std                0.48519778
Policy mu Max                2.1606472
Policy mu Min                -1.7605885
Policy log std Mean          -0.84857315
Policy log std Std           0.24001229
Policy log std Max           -0.22770134
Policy log std Min           -2.000152
Z mean eval                  0.91918737
Z variance eval              0.01051235
total_rewards                [  49.96979001 1901.54414577  121.22798402 1434.07471134  603.08084641
   -6.05247443 1523.15594145 1749.36582203  225.18282719 1543.67108951]
total_rewards_mean           914.5220683299891
total_rewards_std            741.8748657742692
total_rewards_max            1901.5441457681366
total_rewards_min            -6.0524744324720565
Number of train steps total  135000
Number of env steps total    677000
Number of rollouts total     0
Train Time (s)               29.08489962760359
(Previous) Eval Time (s)     26.770401720888913
Sample Time (s)              19.838583051692694
Epoch Time (s)               75.6938844001852
Total Train Time (s)         9403.823047568556
Epoch                        134
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:52:15.401771 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #134 | Epoch Duration: 73.11169075965881
2020-01-11 05:52:15.401984 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #134 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9186031
Z variance train             0.010492741
KL Divergence                17.625233
KL Loss                      1.7625233
QF Loss                      490.44766
VF Loss                      91.17157
Policy Loss                  -619.77344
Q Predictions Mean           615.4346
Q Predictions Std            132.11887
Q Predictions Max            770.6629
Q Predictions Min            -20.750174
V Predictions Mean           614.1891
V Predictions Std            129.86707
V Predictions Max            764.3712
V Predictions Min            -14.134573
Log Pis Mean                 -1.7180107
Log Pis Std                  2.1829348
Log Pis Max                  6.5231485
Log Pis Min                  -7.9608836
Policy mu Mean               0.016135775
Policy mu Std                0.5104664
Policy mu Max                2.3355143
Policy mu Min                -1.7539515
Policy log std Mean          -0.822973
Policy log std Std           0.23386031
Policy log std Max           -0.29776126
Policy log std Min           -2.3085666
Z mean eval                  0.901194
Z variance eval              0.007522373
total_rewards                [1038.72980211 1979.0409154  1032.04429372   92.84142411  384.89555777
 1333.64603133 1291.49162828  131.27315726  628.94943948  701.366222  ]
total_rewards_mean           861.427847144595
total_rewards_std            561.0837470699469
total_rewards_max            1979.0409154013712
total_rewards_min            92.84142411272106
Number of train steps total  136000
Number of env steps total    682000
Number of rollouts total     0
Train Time (s)               28.89182218303904
(Previous) Eval Time (s)     24.18790235929191
Sample Time (s)              19.067602030467242
Epoch Time (s)               72.14732657279819
Total Train Time (s)         9479.674215978011
Epoch                        135
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:53:31.256805 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #135 | Epoch Duration: 75.85463333129883
2020-01-11 05:53:31.257187 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #135 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9012583
Z variance train             0.0075200596
KL Divergence                18.028666
KL Loss                      1.8028666
QF Loss                      384.039
VF Loss                      57.551105
Policy Loss                  -624.37946
Q Predictions Mean           620.12085
Q Predictions Std            140.20262
Q Predictions Max            786.6228
Q Predictions Min            246.22581
V Predictions Mean           621.50305
V Predictions Std            140.60127
V Predictions Max            788.9514
V Predictions Min            242.99313
Log Pis Mean                 -1.4573505
Log Pis Std                  2.3482819
Log Pis Max                  7.485525
Log Pis Min                  -8.524056
Policy mu Mean               0.023633918
Policy mu Std                0.50201106
Policy mu Max                1.8015378
Policy mu Min                -1.4821355
Policy log std Mean          -0.82407403
Policy log std Std           0.24680708
Policy log std Max           -0.21921584
Policy log std Min           -2.468577
Z mean eval                  0.9241473
Z variance eval              0.009922966
total_rewards                [ 206.03174591 1761.60127488 1627.07957869 1060.47813961 1551.32663562
 1853.76440632 1224.85777095 1693.49258031  537.058625   1836.57025941]
total_rewards_mean           1335.2261016687014
total_rewards_std            544.2495120574645
total_rewards_max            1853.764406323
total_rewards_min            206.03174590540448
Number of train steps total  137000
Number of env steps total    687000
Number of rollouts total     0
Train Time (s)               27.966662431135774
(Previous) Eval Time (s)     27.8948365887627
Sample Time (s)              18.90930665563792
Epoch Time (s)               74.7708056755364
Total Train Time (s)         9550.144697886426
Epoch                        136
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:54:41.730750 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #136 | Epoch Duration: 70.47328639030457
2020-01-11 05:54:41.731033 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #136 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9236954
Z variance train             0.009910343
KL Divergence                17.750977
KL Loss                      1.7750977
QF Loss                      361.69293
VF Loss                      67.85152
Policy Loss                  -639.7775
Q Predictions Mean           636.9262
Q Predictions Std            133.47603
Q Predictions Max            807.1732
Q Predictions Min            273.8186
V Predictions Mean           645.13684
V Predictions Std            133.90244
V Predictions Max            815.0414
V Predictions Min            269.05127
Log Pis Mean                 -1.6239429
Log Pis Std                  2.245696
Log Pis Max                  6.7256155
Log Pis Min                  -11.315355
Policy mu Mean               0.06255646
Policy mu Std                0.5084589
Policy mu Max                1.8444197
Policy mu Min                -2.0426433
Policy log std Mean          -0.8459985
Policy log std Std           0.21757518
Policy log std Max           -0.29776555
Policy log std Min           -1.5406699
Z mean eval                  0.9082568
Z variance eval              0.0076393983
total_rewards                [1735.75599786 1920.49900858   23.41311187  667.82479898 1902.691088
 1780.76937748 1819.7071479  1973.90915452  864.01222109 1409.40583635]
total_rewards_mean           1409.7987742621187
total_rewards_std            632.7988589711126
total_rewards_max            1973.9091545215579
total_rewards_min            23.413111867850237
Number of train steps total  138000
Number of env steps total    692000
Number of rollouts total     0
Train Time (s)               28.981465303804725
(Previous) Eval Time (s)     23.597023084759712
Sample Time (s)              19.203291514422745
Epoch Time (s)               71.78177990298718
Total Train Time (s)         9625.52886929363
Epoch                        137
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:55:57.118370 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #137 | Epoch Duration: 75.38712310791016
2020-01-11 05:55:57.118584 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #137 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90853655
Z variance train             0.007637997
KL Divergence                18.423914
KL Loss                      1.8423914
QF Loss                      395.03027
VF Loss                      81.978195
Policy Loss                  -608.94727
Q Predictions Mean           605.93164
Q Predictions Std            157.13176
Q Predictions Max            861.59955
Q Predictions Min            -6.241667
V Predictions Mean           609.8098
V Predictions Std            152.3219
V Predictions Max            862.4472
V Predictions Min            254.71857
Log Pis Mean                 -1.3556722
Log Pis Std                  2.486811
Log Pis Max                  8.817165
Log Pis Min                  -8.340255
Policy mu Mean               0.11268709
Policy mu Std                0.5125263
Policy mu Max                2.0374002
Policy mu Min                -1.904864
Policy log std Mean          -0.8243618
Policy log std Std           0.245731
Policy log std Max           -0.24120533
Policy log std Min           -2.31642
Z mean eval                  0.9204157
Z variance eval              0.00854682
total_rewards                [1691.66469952   -1.94486599  543.98681289  669.69153061  308.99447898
  560.61908126 1276.63729202  853.3263151  1233.35643965 1040.20497197]
total_rewards_mean           817.653675602426
total_rewards_std            478.6962203007225
total_rewards_max            1691.6646995237254
total_rewards_min            -1.9448659871621459
Number of train steps total  139000
Number of env steps total    697000
Number of rollouts total     0
Train Time (s)               28.07877901615575
(Previous) Eval Time (s)     27.202037318143994
Sample Time (s)              18.29703260678798
Epoch Time (s)               73.57784894108772
Total Train Time (s)         9696.895501424558
Epoch                        138
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:57:08.489161 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #138 | Epoch Duration: 71.37038135528564
2020-01-11 05:57:08.489448 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #138 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92057484
Z variance train             0.00854736
KL Divergence                18.425297
KL Loss                      1.8425297
QF Loss                      350.51962
VF Loss                      132.88945
Policy Loss                  -638.0074
Q Predictions Mean           634.8308
Q Predictions Std            142.52472
Q Predictions Max            806.1523
Q Predictions Min            269.72568
V Predictions Mean           633.3617
V Predictions Std            139.86047
V Predictions Max            800.72266
V Predictions Min            269.2627
Log Pis Mean                 -1.3647679
Log Pis Std                  2.1125517
Log Pis Max                  7.1362724
Log Pis Min                  -6.77959
Policy mu Mean               0.05853194
Policy mu Std                0.49389848
Policy mu Max                1.6362002
Policy mu Min                -1.6674223
Policy log std Mean          -0.842612
Policy log std Std           0.24365227
Policy log std Max           -0.09224659
Policy log std Min           -2.1876867
Z mean eval                  0.9251506
Z variance eval              0.013192644
total_rewards                [ 660.20154884 1816.81904954  721.66616398  285.83458178 1010.0662638
 2012.50430449 2024.86118653  448.58114976  247.03855007  667.94545054]
total_rewards_mean           989.5518249318923
total_rewards_std            665.2779372225956
total_rewards_max            2024.861186526312
total_rewards_min            247.03855007064254
Number of train steps total  140000
Number of env steps total    702000
Number of rollouts total     0
Train Time (s)               27.822292170021683
(Previous) Eval Time (s)     24.994215907063335
Sample Time (s)              18.720075080171227
Epoch Time (s)               71.53658315725625
Total Train Time (s)         9760.151200733613
Epoch                        139
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:58:11.744908 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #139 | Epoch Duration: 63.255260944366455
2020-01-11 05:58:11.745059 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #139 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9247104
Z variance train             0.012985548
KL Divergence                17.088428
KL Loss                      1.7088429
QF Loss                      314.86826
VF Loss                      62.476032
Policy Loss                  -633.7744
Q Predictions Mean           629.71594
Q Predictions Std            150.2704
Q Predictions Max            801.55756
Q Predictions Min            256.61642
V Predictions Mean           637.933
V Predictions Std            151.18481
V Predictions Max            813.40137
V Predictions Min            272.35608
Log Pis Mean                 -1.8380275
Log Pis Std                  2.1348042
Log Pis Max                  3.9868977
Log Pis Min                  -8.357658
Policy mu Mean               0.028512698
Policy mu Std                0.48503232
Policy mu Max                1.6408877
Policy mu Min                -1.542851
Policy log std Mean          -0.80684394
Policy log std Std           0.22353147
Policy log std Max           -0.2341192
Policy log std Min           -1.62058
Z mean eval                  0.90486133
Z variance eval              0.018021524
total_rewards                [  24.59544164  495.62904107 1684.80815138 1807.75065892  421.11287332
 1377.4709615   567.12535489 1228.74215441 1931.09536355  229.18830167]
total_rewards_mean           976.7518302357861
total_rewards_std            670.8360446485635
total_rewards_max            1931.0953635535213
total_rewards_min            24.595441641105303
Number of train steps total  141000
Number of env steps total    707000
Number of rollouts total     0
Train Time (s)               30.410462585277855
(Previous) Eval Time (s)     16.71258370531723
Sample Time (s)              18.119282532017678
Epoch Time (s)               65.24232882261276
Total Train Time (s)         9830.267237536144
Epoch                        140
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:59:21.863419 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #140 | Epoch Duration: 70.11823987960815
2020-01-11 05:59:21.863580 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #140 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9051405
Z variance train             0.017994132
KL Divergence                16.755068
KL Loss                      1.6755068
QF Loss                      364.55322
VF Loss                      238.68216
Policy Loss                  -596.56854
Q Predictions Mean           593.87305
Q Predictions Std            154.05687
Q Predictions Max            798.2194
Q Predictions Min            160.28125
V Predictions Mean           604.773
V Predictions Std            157.05525
V Predictions Max            818.3068
V Predictions Min            140.7622
Log Pis Mean                 -1.7491469
Log Pis Std                  2.3560505
Log Pis Max                  5.0092735
Log Pis Min                  -9.979656
Policy mu Mean               0.05041992
Policy mu Std                0.46379966
Policy mu Max                1.4834678
Policy mu Min                -1.4813888
Policy log std Mean          -0.82741636
Policy log std Std           0.25784835
Policy log std Max           -0.22695494
Policy log std Min           -2.0793512
Z mean eval                  0.917424
Z variance eval              0.011448516
total_rewards                [1448.43901648  288.70085901 1044.69534995 1502.63568382 1503.70932206
 1944.91596972 1836.63878622 1947.7163177  1133.66295126 1714.51494878]
total_rewards_mean           1436.5629205002256
total_rewards_std            482.58987078717456
total_rewards_max            1947.7163176968131
total_rewards_min            288.7008590061935
Number of train steps total  142000
Number of env steps total    712000
Number of rollouts total     0
Train Time (s)               30.997672335710377
(Previous) Eval Time (s)     21.588199437130243
Sample Time (s)              17.80849422328174
Epoch Time (s)               70.39436599612236
Total Train Time (s)         9902.273371849675
Epoch                        141
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:00:33.870673 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #141 | Epoch Duration: 72.00692439079285
2020-01-11 06:00:33.870880 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #141 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.917425
Z variance train             0.011449711
KL Divergence                17.676369
KL Loss                      1.7676369
QF Loss                      473.34973
VF Loss                      323.5993
Policy Loss                  -626.0733
Q Predictions Mean           625.00684
Q Predictions Std            161.81921
Q Predictions Max            812.94086
Q Predictions Min            199.162
V Predictions Mean           632.95776
V Predictions Std            163.77701
V Predictions Max            824.781
V Predictions Min            169.13756
Log Pis Mean                 -1.5609127
Log Pis Std                  2.4143474
Log Pis Max                  8.155786
Log Pis Min                  -11.658497
Policy mu Mean               0.06290851
Policy mu Std                0.46876803
Policy mu Max                1.8997895
Policy mu Min                -1.5678461
Policy log std Mean          -0.8614733
Policy log std Std           0.2630684
Policy log std Max           -0.27542853
Policy log std Min           -2.3097134
Z mean eval                  0.908568
Z variance eval              0.013539565
total_rewards                [ 761.94945078 2057.58677184  124.01460794 1367.42071029  134.32021599
  723.58933298  453.47678151  524.15031745   45.78716213  161.67653496]
total_rewards_mean           635.397188586411
total_rewards_std            609.2936397610074
total_rewards_max            2057.5867718401373
total_rewards_min            45.787162125388406
Number of train steps total  143000
Number of env steps total    717000
Number of rollouts total     0
Train Time (s)               30.394436572212726
(Previous) Eval Time (s)     23.200424344278872
Sample Time (s)              17.665865031071007
Epoch Time (s)               71.2607259475626
Total Train Time (s)         9976.106280725915
Epoch                        142
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:01:47.708495 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #142 | Epoch Duration: 73.83742952346802
2020-01-11 06:01:47.708803 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #142 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9095706
Z variance train             0.013467049
KL Divergence                17.664955
KL Loss                      1.7664956
QF Loss                      408.8717
VF Loss                      124.08498
Policy Loss                  -650.91235
Q Predictions Mean           645.69196
Q Predictions Std            143.30312
Q Predictions Max            823.6267
Q Predictions Min            255.3677
V Predictions Mean           643.565
V Predictions Std            141.96007
V Predictions Max            810.9438
V Predictions Min            247.37363
Log Pis Mean                 -1.5302296
Log Pis Std                  2.314149
Log Pis Max                  5.4921875
Log Pis Min                  -7.5824695
Policy mu Mean               0.021701457
Policy mu Std                0.50995195
Policy mu Max                2.0500832
Policy mu Min                -1.8308868
Policy log std Mean          -0.8323365
Policy log std Std           0.22407083
Policy log std Max           -0.24733943
Policy log std Min           -1.7905512
Z mean eval                  0.89017373
Z variance eval              0.012604618
total_rewards                [1968.89059904 1993.41671501  587.63849443   32.90153989  520.37626785
 2054.33841165  486.67835838  592.7756872   457.8001292   612.25459548]
total_rewards_mean           930.7070798148554
total_rewards_std            720.9894919859797
total_rewards_max            2054.338411652913
total_rewards_min            32.90153989279237
Number of train steps total  144000
Number of env steps total    722000
Number of rollouts total     0
Train Time (s)               29.195325307082385
(Previous) Eval Time (s)     25.776809541042894
Sample Time (s)              17.787635514046997
Epoch Time (s)               72.75977036217228
Total Train Time (s)         10046.505752534606
Epoch                        143
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:02:58.111269 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #143 | Epoch Duration: 70.40221309661865
2020-01-11 06:02:58.111529 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #143 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8903147
Z variance train             0.012617876
KL Divergence                18.048744
KL Loss                      1.8048744
QF Loss                      366.0871
VF Loss                      77.30139
Policy Loss                  -643.3987
Q Predictions Mean           640.03125
Q Predictions Std            165.94196
Q Predictions Max            840.25867
Q Predictions Min            187.35776
V Predictions Mean           639.43884
V Predictions Std            165.1104
V Predictions Max            839.4346
V Predictions Min            182.12556
Log Pis Mean                 -1.6191585
Log Pis Std                  2.2381902
Log Pis Max                  6.2417235
Log Pis Min                  -8.650156
Policy mu Mean               -0.035209376
Policy mu Std                0.5044118
Policy mu Max                1.5565891
Policy mu Min                -1.9885725
Policy log std Mean          -0.8417373
Policy log std Std           0.25326136
Policy log std Max           -0.12587422
Policy log std Min           -1.8342724
Z mean eval                  0.8996881
Z variance eval              0.011662972
total_rewards                [ 591.45149753  345.67937023  951.62817071  857.26456438 2079.00825088
  532.4808096  1518.4072794   564.63668933 2074.41127575 1903.48196269]
total_rewards_mean           1141.8449870498791
total_rewards_std            650.2553471673391
total_rewards_max            2079.0082508825335
total_rewards_min            345.67937023390846
Number of train steps total  145000
Number of env steps total    727000
Number of rollouts total     0
Train Time (s)               28.220627430826426
(Previous) Eval Time (s)     23.41894706292078
Sample Time (s)              19.156648965086788
Epoch Time (s)               70.79622345883399
Total Train Time (s)         10114.577296478208
Epoch                        144
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:04:06.182528 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #144 | Epoch Duration: 68.07081747055054
2020-01-11 06:04:06.182706 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #144 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89797103
Z variance train             0.011631569
KL Divergence                18.377655
KL Loss                      1.8377656
QF Loss                      419.43402
VF Loss                      62.713215
Policy Loss                  -642.8635
Q Predictions Mean           640.34143
Q Predictions Std            150.05637
Q Predictions Max            818.9276
Q Predictions Min            261.22467
V Predictions Mean           644.25903
V Predictions Std            149.90411
V Predictions Max            820.58527
V Predictions Min            260.35464
Log Pis Mean                 -1.5542231
Log Pis Std                  2.2507882
Log Pis Max                  4.4429245
Log Pis Min                  -9.99245
Policy mu Mean               0.07058515
Policy mu Std                0.5210765
Policy mu Max                1.6544337
Policy mu Min                -2.3840227
Policy log std Mean          -0.8276099
Policy log std Std           0.25305334
Policy log std Max           -0.25579002
Policy log std Min           -1.7333331
Z mean eval                  0.9091851
Z variance eval              0.011651826
total_rewards                [ 106.77788512 1601.61189791  764.34090545  421.52936821 1788.03167952
  728.62032858 1908.47831193  353.48679286  510.19957029  679.6644748 ]
total_rewards_mean           886.2741214668519
total_rewards_std            608.3652424590794
total_rewards_max            1908.4783119254962
total_rewards_min            106.7778851217985
Number of train steps total  146000
Number of env steps total    732000
Number of rollouts total     0
Train Time (s)               26.81197093706578
(Previous) Eval Time (s)     20.693224384449422
Sample Time (s)              17.731096330098808
Epoch Time (s)               65.23629165161401
Total Train Time (s)         10182.041289628018
Epoch                        145
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:05:13.651264 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #145 | Epoch Duration: 67.46835803985596
2020-01-11 06:05:13.651582 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #145 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9084271
Z variance train             0.011655411
KL Divergence                19.069817
KL Loss                      1.9069817
QF Loss                      1230.5527
VF Loss                      218.75893
Policy Loss                  -622.1475
Q Predictions Mean           620.1351
Q Predictions Std            180.2072
Q Predictions Max            831.0746
Q Predictions Min            11.8205185
V Predictions Mean           622.7031
V Predictions Std            178.66995
V Predictions Max            827.1804
V Predictions Min            16.867277
Log Pis Mean                 -1.9277898
Log Pis Std                  2.2445226
Log Pis Max                  4.107145
Log Pis Min                  -8.620928
Policy mu Mean               0.040712908
Policy mu Std                0.48362207
Policy mu Max                1.9210367
Policy mu Min                -1.6639516
Policy log std Mean          -0.79881394
Policy log std Std           0.2562126
Policy log std Max           -0.19149134
Policy log std Min           -2.1063666
Z mean eval                  0.89827156
Z variance eval              0.013001548
total_rewards                [-1.33231948e+00  1.90658576e+03  4.53228518e+02  9.32341489e+02
  1.81228684e+03  2.88470283e+02  1.92052751e+03  1.67524576e+03
  1.92566741e+03  7.25867022e+02]
total_rewards_mean           1163.888828010688
total_rewards_std            725.3224552398417
total_rewards_max            1925.667413808008
total_rewards_min            -1.3323194802410472
Number of train steps total  147000
Number of env steps total    737000
Number of rollouts total     0
Train Time (s)               27.530126952100545
(Previous) Eval Time (s)     22.924964776728302
Sample Time (s)              17.944698134902865
Epoch Time (s)               68.39978986373171
Total Train Time (s)         10249.548463187646
Epoch                        146
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:06:21.174672 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #146 | Epoch Duration: 67.52282691001892
2020-01-11 06:06:21.174953 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #146 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89835215
Z variance train             0.013000285
KL Divergence                18.62936
KL Loss                      1.862936
QF Loss                      466.75122
VF Loss                      108.71352
Policy Loss                  -676.6872
Q Predictions Mean           674.88324
Q Predictions Std            145.16856
Q Predictions Max            837.8988
Q Predictions Min            3.6540985
V Predictions Mean           677.9096
V Predictions Std            145.30048
V Predictions Max            841.486
V Predictions Min            54.31743
Log Pis Mean                 -1.5749726
Log Pis Std                  2.1676018
Log Pis Max                  4.443273
Log Pis Min                  -9.006422
Policy mu Mean               0.092131004
Policy mu Std                0.5058444
Policy mu Max                1.9665378
Policy mu Min                -1.4605763
Policy log std Mean          -0.8425616
Policy log std Std           0.22823821
Policy log std Max           -0.25582
Policy log std Min           -1.8779831
Z mean eval                  0.880006
Z variance eval              0.012387248
total_rewards                [1779.53577771 1871.84593643  338.78805029 1989.29747092  402.53832391
 1957.48856785   17.05251797  713.57660601  816.03424067 -115.87843033]
total_rewards_mean           977.0279061424577
total_rewards_std            798.7128345015045
total_rewards_max            1989.2974709185803
total_rewards_min            -115.87843033262719
Number of train steps total  148000
Number of env steps total    742000
Number of rollouts total     0
Train Time (s)               29.859377013053745
(Previous) Eval Time (s)     22.047685915138572
Sample Time (s)              18.20669518550858
Epoch Time (s)               70.1137581137009
Total Train Time (s)         10319.748274452519
Epoch                        147
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:07:31.361143 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #147 | Epoch Duration: 70.1860032081604
2020-01-11 06:07:31.361326 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #147 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.879134
Z variance train             0.0123890955
KL Divergence                18.676178
KL Loss                      1.8676178
QF Loss                      379.21143
VF Loss                      275.96436
Policy Loss                  -652.8471
Q Predictions Mean           650.3395
Q Predictions Std            160.8327
Q Predictions Max            844.0251
Q Predictions Min            14.758818
V Predictions Mean           655.22546
V Predictions Std            161.24026
V Predictions Max            846.11096
V Predictions Min            9.25386
Log Pis Mean                 -1.555784
Log Pis Std                  2.509221
Log Pis Max                  12.944628
Log Pis Min                  -8.957582
Policy mu Mean               0.038894054
Policy mu Std                0.52852
Policy mu Max                1.9196326
Policy mu Min                -2.0956552
Policy log std Mean          -0.80721885
Policy log std Std           0.25073934
Policy log std Max           -0.24950168
Policy log std Min           -2.3141239
Z mean eval                  0.9124463
Z variance eval              0.015449459
total_rewards                [  53.82588795  980.70627416  883.0612138   154.92564634  365.75981048
 1705.50805931 1543.59213319 1947.44634563  874.37811575 1444.43186687]
total_rewards_mean           995.363535346742
total_rewards_std            626.8714254149498
total_rewards_max            1947.446345634622
total_rewards_min            53.82588795458246
Number of train steps total  149000
Number of env steps total    747000
Number of rollouts total     0
Train Time (s)               29.72472459077835
(Previous) Eval Time (s)     22.119629006832838
Sample Time (s)              18.433625378180295
Epoch Time (s)               70.27797897579148
Total Train Time (s)         10391.109975380357
Epoch                        148
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:08:42.724747 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #148 | Epoch Duration: 71.36326217651367
2020-01-11 06:08:42.724935 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #148 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90357286
Z variance train             0.015358025
KL Divergence                18.63355
KL Loss                      1.863355
QF Loss                      426.25763
VF Loss                      255.50893
Policy Loss                  -649.53156
Q Predictions Mean           648.90497
Q Predictions Std            135.12512
Q Predictions Max            822.77277
Q Predictions Min            223.03157
V Predictions Mean           662.6289
V Predictions Std            132.87671
V Predictions Max            829.4267
V Predictions Min            246.29543
Log Pis Mean                 -1.4258556
Log Pis Std                  2.0725584
Log Pis Max                  5.4326577
Log Pis Min                  -7.1637306
Policy mu Mean               0.086065024
Policy mu Std                0.5150606
Policy mu Max                1.8590984
Policy mu Min                -1.6856395
Policy log std Mean          -0.8258761
Policy log std Std           0.23422629
Policy log std Max           -0.23406172
Policy log std Min           -1.7017121
Z mean eval                  0.85630214
Z variance eval              0.011521732
total_rewards                [ 929.88185917  521.78217654 1969.97539039 1730.2948863   347.44828731
  607.519506    596.2633091  1774.11557935 1743.93182222  144.0548688 ]
total_rewards_mean           1036.526768519325
total_rewards_std            657.4685708461914
total_rewards_max            1969.975390394198
total_rewards_min            144.0548687973281
Number of train steps total  150000
Number of env steps total    752000
Number of rollouts total     0
Train Time (s)               26.853410922922194
(Previous) Eval Time (s)     23.204610178712755
Sample Time (s)              17.58566414192319
Epoch Time (s)               67.64368524355814
Total Train Time (s)         10454.678124137688
Epoch                        149
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:09:46.294116 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #149 | Epoch Duration: 63.56903696060181
2020-01-11 06:09:46.294335 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #149 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.85504675
Z variance train             0.011547072
KL Divergence                18.80973
KL Loss                      1.8809731
QF Loss                      1388.336
VF Loss                      181.08945
Policy Loss                  -637.11633
Q Predictions Mean           634.2253
Q Predictions Std            173.19899
Q Predictions Max            830.1429
Q Predictions Min            -13.317922
V Predictions Mean           645.04395
V Predictions Std            176.48724
V Predictions Max            847.74066
V Predictions Min            1.9697835
Log Pis Mean                 -1.6051924
Log Pis Std                  2.407291
Log Pis Max                  12.324188
Log Pis Min                  -9.368057
Policy mu Mean               0.00784995
Policy mu Std                0.48987573
Policy mu Max                3.2286918
Policy mu Min                -1.6747029
Policy log std Mean          -0.8331885
Policy log std Std           0.27647358
Policy log std Max           0.10874951
Policy log std Min           -2.617632
Z mean eval                  0.85994005
Z variance eval              0.023715867
total_rewards                [ 623.48470914 1734.36845019 1703.88166538  204.05588348  366.27581258
 1846.52375868 1530.09795422  351.39927188 1939.76895728 1817.55475914]
total_rewards_mean           1211.7411221979123
total_rewards_std            687.9790138252583
total_rewards_max            1939.7689572758545
total_rewards_min            204.05588348234082
Number of train steps total  151000
Number of env steps total    757000
Number of rollouts total     0
Train Time (s)               29.32195745781064
(Previous) Eval Time (s)     19.12965409224853
Sample Time (s)              17.806370487902313
Epoch Time (s)               66.25798203796148
Total Train Time (s)         10526.650386486668
Epoch                        150
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:10:58.293681 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #150 | Epoch Duration: 71.99916338920593
2020-01-11 06:10:58.294039 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #150 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.85647994
Z variance train             0.023713771
KL Divergence                17.747902
KL Loss                      1.7747902
QF Loss                      709.91754
VF Loss                      124.25536
Policy Loss                  -653.227
Q Predictions Mean           647.17285
Q Predictions Std            162.72675
Q Predictions Max            864.3616
Q Predictions Min            244.9196
V Predictions Mean           651.0779
V Predictions Std            161.62405
V Predictions Max            862.8964
V Predictions Min            242.18436
Log Pis Mean                 -1.4750034
Log Pis Std                  2.0765362
Log Pis Max                  7.4247293
Log Pis Min                  -7.229202
Policy mu Mean               0.047685772
Policy mu Std                0.5416347
Policy mu Max                2.0861592
Policy mu Min                -2.0827558
Policy log std Mean          -0.81985325
Policy log std Std           0.25548357
Policy log std Max           -0.22441661
Policy log std Min           -2.2744262
Z mean eval                  0.8640095
Z variance eval              0.017216139
total_rewards                [1857.83656392 2032.58782334  233.20690308 1146.31297328 1219.41741856
 1170.3962345  2056.75744645 1873.75925602  129.57978106 1916.1831151 ]
total_rewards_mean           1363.6037515308358
total_rewards_std            681.4555537978547
total_rewards_max            2056.7574464458403
total_rewards_min            129.5797810575071
Number of train steps total  152000
Number of env steps total    762000
Number of rollouts total     0
Train Time (s)               28.707666736096144
(Previous) Eval Time (s)     24.87046319618821
Sample Time (s)              17.617588182911277
Epoch Time (s)               71.19571811519563
Total Train Time (s)         10598.755681519397
Epoch                        151
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:12:10.377053 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #151 | Epoch Duration: 72.08277988433838
2020-01-11 06:12:10.377266 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #151 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.86073047
Z variance train             0.017210923
KL Divergence                18.478731
KL Loss                      1.8478731
QF Loss                      369.6625
VF Loss                      63.347923
Policy Loss                  -683.8194
Q Predictions Mean           680.3884
Q Predictions Std            152.70874
Q Predictions Max            833.2236
Q Predictions Min            249.95857
V Predictions Mean           685.5464
V Predictions Std            151.01556
V Predictions Max            836.1672
V Predictions Min            271.19467
Log Pis Mean                 -1.4237335
Log Pis Std                  2.3517842
Log Pis Max                  6.0113673
Log Pis Min                  -8.730392
Policy mu Mean               0.08503021
Policy mu Std                0.51419574
Policy mu Max                1.6406927
Policy mu Min                -1.5027243
Policy log std Mean          -0.84222937
Policy log std Std           0.24615228
Policy log std Max           -0.1696893
Policy log std Min           -1.7917128
Z mean eval                  0.83359766
Z variance eval              0.01284537
total_rewards                [-233.12312117 1748.79979532 1734.61229418 -203.3531843  1641.69858642
 1616.4203643  1652.8198267  1892.21193026  980.46890096 1824.17470788]
total_rewards_mean           1265.4730100552583
total_rewards_std            778.3226254311963
total_rewards_max            1892.2119302583815
total_rewards_min            -233.1231211700349
Number of train steps total  153000
Number of env steps total    767000
Number of rollouts total     0
Train Time (s)               29.444951817858964
(Previous) Eval Time (s)     25.7572530368343
Sample Time (s)              18.244487741030753
Epoch Time (s)               73.44669259572402
Total Train Time (s)         10673.145579653326
Epoch                        152
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:13:24.771247 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #152 | Epoch Duration: 74.3938422203064
2020-01-11 06:13:24.771448 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #152 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8358003
Z variance train             0.012814531
KL Divergence                19.161572
KL Loss                      1.9161571
QF Loss                      524.028
VF Loss                      167.21095
Policy Loss                  -667.7607
Q Predictions Mean           665.30676
Q Predictions Std            156.0321
Q Predictions Max            838.50085
Q Predictions Min            136.14018
V Predictions Mean           660.2969
V Predictions Std            154.16377
V Predictions Max            839.9037
V Predictions Min            242.2048
Log Pis Mean                 -1.3958502
Log Pis Std                  2.1240273
Log Pis Max                  9.002701
Log Pis Min                  -6.7675886
Policy mu Mean               0.08300631
Policy mu Std                0.49723852
Policy mu Max                2.1460521
Policy mu Min                -1.6199809
Policy log std Mean          -0.8609295
Policy log std Std           0.25580567
Policy log std Max           -0.26068568
Policy log std Min           -2.271402
Z mean eval                  0.88277894
Z variance eval              0.016129224
total_rewards                [ 546.35789106  706.9707542   992.66237776  208.54343479 1491.48531546
 1981.6405239  1598.15747284  781.13825202  691.99817411  954.12451663]
total_rewards_mean           995.3078712787217
total_rewards_std            512.4190591448593
total_rewards_max            1981.6405239029493
total_rewards_min            208.543434785733
Number of train steps total  154000
Number of env steps total    772000
Number of rollouts total     0
Train Time (s)               28.30528148636222
(Previous) Eval Time (s)     26.704110990744084
Sample Time (s)              18.485154449939728
Epoch Time (s)               73.49454692704603
Total Train Time (s)         10739.89920715196
Epoch                        153
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:14:31.528690 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #153 | Epoch Duration: 66.75704646110535
2020-01-11 06:14:31.529012 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #153 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8835473
Z variance train             0.016122717
KL Divergence                19.187675
KL Loss                      1.9187676
QF Loss                      776.55334
VF Loss                      213.54031
Policy Loss                  -651.98553
Q Predictions Mean           650.0544
Q Predictions Std            159.85634
Q Predictions Max            822.1803
Q Predictions Min            -25.30179
V Predictions Mean           656.0431
V Predictions Std            161.00763
V Predictions Max            833.8243
V Predictions Min            8.457481
Log Pis Mean                 -1.687397
Log Pis Std                  2.3711977
Log Pis Max                  7.687954
Log Pis Min                  -8.727292
Policy mu Mean               0.089260414
Policy mu Std                0.49155602
Policy mu Max                2.115038
Policy mu Min                -1.6012601
Policy log std Mean          -0.8330164
Policy log std Std           0.24957313
Policy log std Max           -0.17461342
Policy log std Min           -2.4209518
Z mean eval                  0.8392459
Z variance eval              0.02388299
total_rewards                [1827.43659151 2115.3991638   961.56829298  282.44688361  201.220357
  436.23092682 1882.49971879  604.79303935 1718.74368808   15.17625159]
total_rewards_mean           1004.5514913551136
total_rewards_std            763.0378761061654
total_rewards_max            2115.3991638044126
total_rewards_min            15.17625159494655
Number of train steps total  155000
Number of env steps total    777000
Number of rollouts total     0
Train Time (s)               29.112132034264505
(Previous) Eval Time (s)     19.96628424525261
Sample Time (s)              17.840877323411405
Epoch Time (s)               66.91929360292852
Total Train Time (s)         10807.424677927978
Epoch                        154
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:15:39.054581 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #154 | Epoch Duration: 67.52534508705139
2020-01-11 06:15:39.054777 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #154 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.83940065
Z variance train             0.023942556
KL Divergence                17.654251
KL Loss                      1.7654251
QF Loss                      404.1903
VF Loss                      139.67285
Policy Loss                  -674.8828
Q Predictions Mean           670.26624
Q Predictions Std            158.59286
Q Predictions Max            868.25653
Q Predictions Min            -27.719616
V Predictions Mean           669.99927
V Predictions Std            159.84239
V Predictions Max            861.7731
V Predictions Min            -2.7180939
Log Pis Mean                 -1.5462672
Log Pis Std                  2.5222745
Log Pis Max                  13.4037895
Log Pis Min                  -10.527397
Policy mu Mean               0.111161366
Policy mu Std                0.5013446
Policy mu Max                2.3691034
Policy mu Min                -1.873896
Policy log std Mean          -0.8345094
Policy log std Std           0.24211667
Policy log std Max           -0.14097744
Policy log std Min           -2.7480762
Z mean eval                  0.8500563
Z variance eval              0.015989978
total_rewards                [ 587.9549107  1320.87376877 1453.19544931 1317.65778249  906.3274405
 1388.66158957  124.11613689 1686.31781337  156.3621917   610.19383398]
total_rewards_mean           955.1660917281795
total_rewards_std            531.0973150669297
total_rewards_max            1686.3178133707336
total_rewards_min            124.11613689081646
Number of train steps total  156000
Number of env steps total    782000
Number of rollouts total     0
Train Time (s)               29.13166152499616
(Previous) Eval Time (s)     20.572052797768265
Sample Time (s)              18.410617765504867
Epoch Time (s)               68.1143320882693
Total Train Time (s)         10873.459612285718
Epoch                        155
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:16:45.091070 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #155 | Epoch Duration: 66.03616285324097
2020-01-11 06:16:45.091245 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #155 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.85039604
Z variance train             0.015976965
KL Divergence                18.406199
KL Loss                      1.8406199
QF Loss                      445.0116
VF Loss                      70.54905
Policy Loss                  -706.28516
Q Predictions Mean           704.35864
Q Predictions Std            144.6762
Q Predictions Max            862.34204
Q Predictions Min            204.42072
V Predictions Mean           705.51733
V Predictions Std            143.06686
V Predictions Max            861.85016
V Predictions Min            189.39597
Log Pis Mean                 -1.3102605
Log Pis Std                  2.1395104
Log Pis Max                  6.1136093
Log Pis Min                  -5.799201
Policy mu Mean               0.0819083
Policy mu Std                0.5230206
Policy mu Max                2.2022932
Policy mu Min                -1.4978125
Policy log std Mean          -0.8318039
Policy log std Std           0.22289382
Policy log std Max           -0.23646879
Policy log std Min           -1.7228558
Z mean eval                  0.8239563
Z variance eval              0.01223985
total_rewards                [1164.86788653   79.35925941  310.43788202  -32.85977666  340.27621296
 1080.69783318 1821.00807936   68.66315957  830.89032353  640.42438302]
total_rewards_mean           630.3765242924649
total_rewards_std            564.9711308803119
total_rewards_max            1821.0080793623679
total_rewards_min            -32.85977666274139
Number of train steps total  157000
Number of env steps total    787000
Number of rollouts total     0
Train Time (s)               27.92843603203073
(Previous) Eval Time (s)     18.493584422860295
Sample Time (s)              17.416934304405004
Epoch Time (s)               63.83895475929603
Total Train Time (s)         10938.21437683003
Epoch                        156
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:17:49.847326 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #156 | Epoch Duration: 64.75594353675842
2020-01-11 06:17:49.847519 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #156 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.81929505
Z variance train             0.012208215
KL Divergence                18.870152
KL Loss                      1.8870152
QF Loss                      1843.17
VF Loss                      225.20175
Policy Loss                  -678.17206
Q Predictions Mean           676.22314
Q Predictions Std            162.50578
Q Predictions Max            878.7579
Q Predictions Min            98.33727
V Predictions Mean           689.2041
V Predictions Std            165.29251
V Predictions Max            897.5724
V Predictions Min            77.32502
Log Pis Mean                 -1.4177811
Log Pis Std                  2.479952
Log Pis Max                  11.606152
Log Pis Min                  -8.3928995
Policy mu Mean               0.005645452
Policy mu Std                0.5322652
Policy mu Max                1.7613058
Policy mu Min                -1.6533433
Policy log std Mean          -0.8355279
Policy log std Std           0.2757006
Policy log std Max           -0.27688462
Policy log std Min           -2.9816594
Z mean eval                  0.82134944
Z variance eval              0.018221855
total_rewards                [ 366.96136426 1913.77541472 2031.45585385 1996.90954789 2019.56999251
  528.07695084 1742.0768972  2051.30527029 1986.62395896 1962.9645395 ]
total_rewards_mean           1659.971979001591
total_rewards_std            612.9197243258919
total_rewards_max            2051.305270289362
total_rewards_min            366.96136426320726
Number of train steps total  158000
Number of env steps total    792000
Number of rollouts total     0
Train Time (s)               27.886773185338825
(Previous) Eval Time (s)     19.410297045018524
Sample Time (s)              18.38802718091756
Epoch Time (s)               65.68509741127491
Total Train Time (s)         11011.31378668407
Epoch                        157
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:19:02.948323 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #157 | Epoch Duration: 73.1006727218628
2020-01-11 06:19:02.948544 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #157 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.82063067
Z variance train             0.018218134
KL Divergence                18.624554
KL Loss                      1.8624554
QF Loss                      302.99762
VF Loss                      125.69975
Policy Loss                  -679.37915
Q Predictions Mean           677.77966
Q Predictions Std            160.37462
Q Predictions Max            885.9108
Q Predictions Min            51.52686
V Predictions Mean           688.3916
V Predictions Std            162.4301
V Predictions Max            895.68915
V Predictions Min            12.905504
Log Pis Mean                 -1.3377583
Log Pis Std                  2.2561507
Log Pis Max                  4.98987
Log Pis Min                  -7.9197288
Policy mu Mean               0.013239624
Policy mu Std                0.53496367
Policy mu Max                1.8540194
Policy mu Min                -2.142886
Policy log std Mean          -0.82945037
Policy log std Std           0.23860341
Policy log std Max           0.0014126301
Policy log std Min           -1.8130844
Z mean eval                  0.859046
Z variance eval              0.015188031
total_rewards                [ 522.12453671 2017.49083459 2042.95701632 1953.49648948 1931.20499183
 1808.49064269 1124.14865884  983.99207259 1799.76216636 1774.98288851]
total_rewards_mean           1595.8650297911927
total_rewards_std            498.6685384622348
total_rewards_max            2042.9570163162387
total_rewards_min            522.1245367095037
Number of train steps total  159000
Number of env steps total    797000
Number of rollouts total     0
Train Time (s)               27.03338007396087
(Previous) Eval Time (s)     26.825535694137216
Sample Time (s)              17.658912940882146
Epoch Time (s)               71.51782870898023
Total Train Time (s)         11082.953349633142
Epoch                        158
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:20:14.589385 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #158 | Epoch Duration: 71.6407253742218
2020-01-11 06:20:14.589581 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #158 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8589137
Z variance train             0.015205884
KL Divergence                19.211285
KL Loss                      1.9211285
QF Loss                      670.8261
VF Loss                      201.34457
Policy Loss                  -667.2383
Q Predictions Mean           663.7522
Q Predictions Std            172.48964
Q Predictions Max            865.90564
Q Predictions Min            35.59107
V Predictions Mean           661.73926
V Predictions Std            167.18927
V Predictions Max            854.0969
V Predictions Min            -10.345655
Log Pis Mean                 -1.6343888
Log Pis Std                  2.666569
Log Pis Max                  10.662579
Log Pis Min                  -9.115431
Policy mu Mean               0.0043432796
Policy mu Std                0.5039334
Policy mu Max                1.5973685
Policy mu Min                -1.9595082
Policy log std Mean          -0.8711726
Policy log std Std           0.25066125
Policy log std Max           -0.22747415
Policy log std Min           -2.2192645
Z mean eval                  0.8372712
Z variance eval              0.01930528
total_rewards                [ 343.82068129  906.48481054 1643.33481385 1930.03758832  255.87709216
 1424.41124566 1080.97283427 1626.05379322 1008.89964939 1813.41765226]
total_rewards_mean           1203.331016095517
total_rewards_std            556.6688608457655
total_rewards_max            1930.0375883166207
total_rewards_min            255.87709216487784
Number of train steps total  160000
Number of env steps total    802000
Number of rollouts total     0
Train Time (s)               29.234118363820016
(Previous) Eval Time (s)     26.948137484956533
Sample Time (s)              18.345661351457238
Epoch Time (s)               74.52791720023379
Total Train Time (s)         11154.534230449703
Epoch                        159
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:21:26.175432 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #159 | Epoch Duration: 71.58568024635315
2020-01-11 06:21:26.175731 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #159 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8383981
Z variance train             0.019275973
KL Divergence                18.27675
KL Loss                      1.8276751
QF Loss                      507.7168
VF Loss                      55.441467
Policy Loss                  -693.8158
Q Predictions Mean           692.8254
Q Predictions Std            159.94984
Q Predictions Max            894.0006
Q Predictions Min            -20.397339
V Predictions Mean           694.00586
V Predictions Std            160.23997
V Predictions Max            896.4122
V Predictions Min            3.85586
Log Pis Mean                 -1.3495185
Log Pis Std                  2.2379127
Log Pis Max                  4.7451878
Log Pis Min                  -10.6568575
Policy mu Mean               0.106793776
Policy mu Std                0.5166639
Policy mu Max                1.7742065
Policy mu Min                -1.8012741
Policy log std Mean          -0.85483146
Policy log std Std           0.25441787
Policy log std Max           -0.19163638
Policy log std Min           -1.8324256
Z mean eval                  0.81971425
Z variance eval              0.016213765
total_rewards                [ 760.13971962 2110.10422067 2123.87195519  102.66048465 2249.00601045
 1551.16476154  444.8590491  1612.45784576 1836.16259859 2053.80233456]
total_rewards_mean           1484.4228980146559
total_rewards_std            732.6845992265396
total_rewards_max            2249.006010454035
total_rewards_min            102.66048465472345
Number of train steps total  161000
Number of env steps total    807000
Number of rollouts total     0
Train Time (s)               29.040245671290904
(Previous) Eval Time (s)     24.005552266724408
Sample Time (s)              18.28751004813239
Epoch Time (s)               71.3333079861477
Total Train Time (s)         11221.872854422312
Epoch                        160
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:22:33.517871 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #160 | Epoch Duration: 67.34189176559448
2020-01-11 06:22:33.518125 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #160 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.81859475
Z variance train             0.016160341
KL Divergence                18.338444
KL Loss                      1.8338444
QF Loss                      1436.306
VF Loss                      75.17243
Policy Loss                  -655.32416
Q Predictions Mean           651.75696
Q Predictions Std            186.61226
Q Predictions Max            855.7373
Q Predictions Min            142.566
V Predictions Mean           658.76
V Predictions Std            186.10435
V Predictions Max            864.2512
V Predictions Min            218.54579
Log Pis Mean                 -1.6641235
Log Pis Std                  2.39077
Log Pis Max                  7.6026297
Log Pis Min                  -9.53433
Policy mu Mean               0.07262607
Policy mu Std                0.49408624
Policy mu Max                1.8856342
Policy mu Min                -2.3359969
Policy log std Mean          -0.83355355
Policy log std Std           0.2591551
Policy log std Max           -0.17919415
Policy log std Min           -2.238822
Z mean eval                  0.85721254
Z variance eval              0.018971283
total_rewards                [2035.14872987  875.48997486  555.30740494  881.19463226  282.85953535
  615.90903404 1870.83475449 2251.46905335  582.56907012  651.65760566]
total_rewards_mean           1060.2439794945117
total_rewards_std            674.1323141910816
total_rewards_max            2251.469053353365
total_rewards_min            282.85953535125316
Number of train steps total  162000
Number of env steps total    812000
Number of rollouts total     0
Train Time (s)               29.600194244179875
(Previous) Eval Time (s)     20.013828482013196
Sample Time (s)              17.674477976746857
Epoch Time (s)               67.28850070293993
Total Train Time (s)         11286.944368782453
Epoch                        161
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:23:38.591572 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #161 | Epoch Duration: 65.07324743270874
2020-01-11 06:23:38.591780 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #161 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8589817
Z variance train             0.018972555
KL Divergence                16.738398
KL Loss                      1.6738398
QF Loss                      359.05762
VF Loss                      84.37394
Policy Loss                  -686.3024
Q Predictions Mean           681.5365
Q Predictions Std            175.04514
Q Predictions Max            883.4891
Q Predictions Min            245.21808
V Predictions Mean           688.334
V Predictions Std            173.04872
V Predictions Max            894.43024
V Predictions Min            255.1423
Log Pis Mean                 -1.5097852
Log Pis Std                  2.3671343
Log Pis Max                  8.928699
Log Pis Min                  -12.937976
Policy mu Mean               0.08868053
Policy mu Std                0.5127865
Policy mu Max                2.0093558
Policy mu Min                -1.6403543
Policy log std Mean          -0.8332268
Policy log std Std           0.2507778
Policy log std Max           -0.22605261
Policy log std Min           -2.060954
Z mean eval                  0.85218287
Z variance eval              0.027251292
total_rewards                [ 585.84817935 1306.78241052   91.44106495  325.41634325  936.29309634
 1823.65489956  100.16225018  258.99003511 1845.35963445 1161.7243738 ]
total_rewards_mean           843.5672287494265
total_rewards_std            639.0246395086347
total_rewards_max            1845.359634448304
total_rewards_min            91.44106495205617
Number of train steps total  163000
Number of env steps total    817000
Number of rollouts total     0
Train Time (s)               28.412486587185413
(Previous) Eval Time (s)     17.798308444209397
Sample Time (s)              17.93325679237023
Epoch Time (s)               64.14405182376504
Total Train Time (s)         11353.447631548624
Epoch                        162
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:24:45.095026 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #162 | Epoch Duration: 66.50306868553162
2020-01-11 06:24:45.095197 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #162 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8504039
Z variance train             0.027313258
KL Divergence                16.637985
KL Loss                      1.6637986
QF Loss                      418.01624
VF Loss                      124.23507
Policy Loss                  -685.4981
Q Predictions Mean           683.4579
Q Predictions Std            169.43224
Q Predictions Max            874.25165
Q Predictions Min            212.3936
V Predictions Mean           685.5866
V Predictions Std            167.85205
V Predictions Max            867.69946
V Predictions Min            203.65747
Log Pis Mean                 -1.3207201
Log Pis Std                  2.3097928
Log Pis Max                  6.185344
Log Pis Min                  -7.9579554
Policy mu Mean               0.062515885
Policy mu Std                0.55408514
Policy mu Max                1.8206956
Policy mu Min                -1.5519388
Policy log std Mean          -0.830903
Policy log std Std           0.24614589
Policy log std Max           -0.1944567
Policy log std Min           -2.0572631
Z mean eval                  0.8568629
Z variance eval              0.029809928
total_rewards                [ 142.67514326 1808.72447904 1852.48042485  310.29570105  222.70174002
   46.88924047   80.4851718   172.2236538   649.10816451  154.43906513]
total_rewards_mean           544.0022783937324
total_rewards_std            662.8385282191495
total_rewards_max            1852.4804248502946
total_rewards_min            46.88924047391596
Number of train steps total  164000
Number of env steps total    822000
Number of rollouts total     0
Train Time (s)               27.881848933175206
(Previous) Eval Time (s)     20.157012501731515
Sample Time (s)              18.879665868822485
Epoch Time (s)               66.9185273037292
Total Train Time (s)         11420.810725977179
Epoch                        163
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:25:52.462223 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #163 | Epoch Duration: 67.36682963371277
2020-01-11 06:25:52.462527 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #163 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8581769
Z variance train             0.029800754
KL Divergence                17.315815
KL Loss                      1.7315816
QF Loss                      652.584
VF Loss                      157.25107
Policy Loss                  -721.72845
Q Predictions Mean           720.10077
Q Predictions Std            155.57018
Q Predictions Max            907.26385
Q Predictions Min            261.29297
V Predictions Mean           724.0337
V Predictions Std            154.35606
V Predictions Max            897.2245
V Predictions Min            271.29312
Log Pis Mean                 -1.2240045
Log Pis Std                  2.21259
Log Pis Max                  6.932263
Log Pis Min                  -8.127363
Policy mu Mean               0.049534492
Policy mu Std                0.53461844
Policy mu Max                2.0804791
Policy mu Min                -1.8455963
Policy log std Mean          -0.82787937
Policy log std Std           0.25278488
Policy log std Max           -0.19142976
Policy log std Min           -1.9381236
Z mean eval                  0.8382813
Z variance eval              0.027647907
total_rewards                [1852.04776444 2091.81513941 1901.41943292  182.28244726 2039.11227947
  923.10064689 1612.0814742  2205.25314896 2081.34998883 1647.62102268]
total_rewards_mean           1653.6083345042975
total_rewards_std            602.403821670194
total_rewards_max            2205.253148956153
total_rewards_min            182.28244725571454
Number of train steps total  165000
Number of env steps total    827000
Number of rollouts total     0
Train Time (s)               29.706959596835077
(Previous) Eval Time (s)     20.604984725359827
Sample Time (s)              19.19059603707865
Epoch Time (s)               69.50254035927355
Total Train Time (s)         11494.411059441045
Epoch                        164
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:27:06.066720 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #164 | Epoch Duration: 73.603919506073
2020-01-11 06:27:06.067051 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #164 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.839214
Z variance train             0.027578663
KL Divergence                16.90505
KL Loss                      1.690505
QF Loss                      746.7398
VF Loss                      87.03931
Policy Loss                  -680.4221
Q Predictions Mean           675.121
Q Predictions Std            178.70526
Q Predictions Max            876.3501
Q Predictions Min            10.266909
V Predictions Mean           678.54865
V Predictions Std            177.75647
V Predictions Max            881.5423
V Predictions Min            -4.708802
Log Pis Mean                 -1.2749817
Log Pis Std                  2.6396494
Log Pis Max                  9.768925
Log Pis Min                  -7.236408
Policy mu Mean               0.01721117
Policy mu Std                0.51277006
Policy mu Max                1.6643797
Policy mu Min                -2.1986485
Policy log std Mean          -0.86633
Policy log std Std           0.28708795
Policy log std Max           0.3494112
Policy log std Min           -2.525789
Z mean eval                  0.892186
Z variance eval              0.026422957
total_rewards                [ -24.57983964  128.61130523   12.78801489  738.24718417 1632.7330469
 1635.82456805  195.97484927 1733.84005181  252.89606792  371.54847907]
total_rewards_mean           667.788372767837
total_rewards_std            684.9274229236449
total_rewards_max            1733.840051809805
total_rewards_min            -24.57983963725237
Number of train steps total  166000
Number of env steps total    832000
Number of rollouts total     0
Train Time (s)               30.84274872392416
(Previous) Eval Time (s)     24.706053988076746
Sample Time (s)              18.808499751146883
Epoch Time (s)               74.35730246314779
Total Train Time (s)         11565.020014057867
Epoch                        165
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:28:16.679707 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #165 | Epoch Duration: 70.61229825019836
2020-01-11 06:28:16.680113 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #165 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89628905
Z variance train             0.026472379
KL Divergence                16.658329
KL Loss                      1.6658329
QF Loss                      596.56226
VF Loss                      109.80812
Policy Loss                  -697.94305
Q Predictions Mean           692.01184
Q Predictions Std            180.13072
Q Predictions Max            876.5499
Q Predictions Min            26.875193
V Predictions Mean           691.3163
V Predictions Std            179.96864
V Predictions Max            882.24066
V Predictions Min            15.583972
Log Pis Mean                 -1.499231
Log Pis Std                  2.427178
Log Pis Max                  6.425311
Log Pis Min                  -11.05109
Policy mu Mean               -0.019551676
Policy mu Std                0.5507241
Policy mu Max                1.8044037
Policy mu Min                -1.8308594
Policy log std Mean          -0.8236116
Policy log std Std           0.23662171
Policy log std Max           -0.2843007
Policy log std Min           -1.7155436
Z mean eval                  0.84702367
Z variance eval              0.026544679
total_rewards                [1077.40314247  100.88654648  775.6848584   670.68585783 1053.50974314
   18.1571009   841.04183378  869.4235102   261.89983614  234.41504435]
total_rewards_mean           590.3107473683992
total_rewards_std            378.7898314581747
total_rewards_max            1077.403142465769
total_rewards_min            18.15710089620944
Number of train steps total  167000
Number of env steps total    837000
Number of rollouts total     0
Train Time (s)               28.51159847807139
(Previous) Eval Time (s)     20.96070344839245
Sample Time (s)              18.449741607066244
Epoch Time (s)               67.92204353353009
Total Train Time (s)         11633.16342164483
Epoch                        166
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:29:24.823693 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #166 | Epoch Duration: 68.14334225654602
2020-01-11 06:29:24.823937 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #166 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.84481496
Z variance train             0.026529152
KL Divergence                16.891838
KL Loss                      1.6891838
QF Loss                      518.12695
VF Loss                      81.167534
Policy Loss                  -708.0543
Q Predictions Mean           703.9048
Q Predictions Std            160.00446
Q Predictions Max            884.7737
Q Predictions Min            235.79633
V Predictions Mean           704.31036
V Predictions Std            157.06717
V Predictions Max            876.1826
V Predictions Min            252.71864
Log Pis Mean                 -1.4891322
Log Pis Std                  2.3003564
Log Pis Max                  6.4874797
Log Pis Min                  -7.446602
Policy mu Mean               0.072967455
Policy mu Std                0.50085604
Policy mu Max                1.9078966
Policy mu Min                -1.5741192
Policy log std Mean          -0.83470976
Policy log std Std           0.23365209
Policy log std Max           -0.20122176
Policy log std Min           -1.8578936
Z mean eval                  0.870463
Z variance eval              0.030650835
total_rewards                [  84.03175381 1736.69693773 1871.12017407  345.86100482  469.62324468
  213.83742735  324.27006806 1859.97658563  459.28056768  706.02875626]
total_rewards_mean           807.0726520087037
total_rewards_std            683.4162078372583
total_rewards_max            1871.120174065453
total_rewards_min            84.0317538099378
Number of train steps total  168000
Number of env steps total    842000
Number of rollouts total     0
Train Time (s)               27.983199211768806
(Previous) Eval Time (s)     21.18171532638371
Sample Time (s)              18.14640617929399
Epoch Time (s)               67.3113207174465
Total Train Time (s)         11701.012787937652
Epoch                        167
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:30:32.678985 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #167 | Epoch Duration: 67.85484385490417
2020-01-11 06:30:32.679284 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #167 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8691641
Z variance train             0.030689854
KL Divergence                16.488808
KL Loss                      1.6488808
QF Loss                      350.76242
VF Loss                      112.307724
Policy Loss                  -682.3855
Q Predictions Mean           680.4442
Q Predictions Std            189.66057
Q Predictions Max            918.0946
Q Predictions Min            232.34802
V Predictions Mean           686.78
V Predictions Std            186.346
V Predictions Max            910.0638
V Predictions Min            207.90962
Log Pis Mean                 -1.2944736
Log Pis Std                  2.3472505
Log Pis Max                  8.338856
Log Pis Min                  -7.7377386
Policy mu Mean               0.11312613
Policy mu Std                0.5333121
Policy mu Max                1.7683764
Policy mu Min                -2.5891182
Policy log std Mean          -0.8158159
Policy log std Std           0.23595595
Policy log std Max           -0.26914334
Policy log std Min           -1.7107108
Z mean eval                  0.8395545
Z variance eval              0.03394622
total_rewards                [ 825.29173369 1939.1491775  2056.93881562 2070.85551949 2050.19006289
  112.28631772 1757.08400022 1417.97884857  770.12684288  238.64935378]
total_rewards_mean           1323.8550672364304
total_rewards_std            734.7698986599058
total_rewards_max            2070.855519489429
total_rewards_min            112.28631771780181
Number of train steps total  169000
Number of env steps total    847000
Number of rollouts total     0
Train Time (s)               30.89216466108337
(Previous) Eval Time (s)     21.72492211777717
Sample Time (s)              17.6157740582712
Epoch Time (s)               70.23286083713174
Total Train Time (s)         11772.715725000016
Epoch                        168
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:31:44.382711 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #168 | Epoch Duration: 71.70319199562073
2020-01-11 06:31:44.382935 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #168 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.840114
Z variance train             0.033917565
KL Divergence                16.13276
KL Loss                      1.6132759
QF Loss                      906.88
VF Loss                      565.3959
Policy Loss                  -705.5114
Q Predictions Mean           699.3705
Q Predictions Std            181.24774
Q Predictions Max            929.7482
Q Predictions Min            -4.4322705
V Predictions Mean           708.90857
V Predictions Std            175.4598
V Predictions Max            928.9248
V Predictions Min            245.98099
Log Pis Mean                 -1.2583615
Log Pis Std                  2.6365347
Log Pis Max                  13.351006
Log Pis Min                  -9.634598
Policy mu Mean               0.0241085
Policy mu Std                0.5295954
Policy mu Max                1.7060848
Policy mu Min                -2.265985
Policy log std Mean          -0.8614832
Policy log std Std           0.2743311
Policy log std Max           -0.21921939
Policy log std Min           -2.845683
Z mean eval                  0.85675776
Z variance eval              0.034800533
total_rewards                [2040.06058546  113.74814724    4.89136893  464.38804256 1821.85913285
 2012.85059414  158.70931897  793.32203818 1957.81357392 2021.31917001]
total_rewards_mean           1138.8961972268962
total_rewards_std            858.1184316915886
total_rewards_max            2040.0605854586183
total_rewards_min            4.891368933198978
Number of train steps total  170000
Number of env steps total    852000
Number of rollouts total     0
Train Time (s)               28.57452674722299
(Previous) Eval Time (s)     23.194986963178962
Sample Time (s)              17.769222935196012
Epoch Time (s)               69.53873664559796
Total Train Time (s)         11841.898914819118
Epoch                        169
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:32:53.571938 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #169 | Epoch Duration: 69.18865942955017
2020-01-11 06:32:53.572369 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #169 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.85928345
Z variance train             0.034847748
KL Divergence                16.64136
KL Loss                      1.6641359
QF Loss                      348.17383
VF Loss                      149.27103
Policy Loss                  -727.5866
Q Predictions Mean           724.46405
Q Predictions Std            168.20879
Q Predictions Max            898.45245
Q Predictions Min            6.564848
V Predictions Mean           717.26074
V Predictions Std            167.27638
V Predictions Max            887.7491
V Predictions Min            3.7743044
Log Pis Mean                 -1.5036134
Log Pis Std                  2.2249968
Log Pis Max                  5.9708424
Log Pis Min                  -7.5427976
Policy mu Mean               0.011917435
Policy mu Std                0.50822943
Policy mu Max                1.7471153
Policy mu Min                -1.8906325
Policy log std Mean          -0.84347904
Policy log std Std           0.25301343
Policy log std Max           -0.27984264
Policy log std Min           -1.8337873
Z mean eval                  0.84158504
Z variance eval              0.02618215
total_rewards                [  -7.74200268   25.23024193  294.57849251  715.70336717  793.88924929
 2077.29385121 1288.55451498 1304.49705267 1009.23324179  523.70428773]
total_rewards_mean           802.4942296602969
total_rewards_std            613.1922631297936
total_rewards_max            2077.293851213811
total_rewards_min            -7.742002684540969
Number of train steps total  171000
Number of env steps total    857000
Number of rollouts total     0
Train Time (s)               30.06943271169439
(Previous) Eval Time (s)     22.844591620843858
Sample Time (s)              18.217409506905824
Epoch Time (s)               71.13143383944407
Total Train Time (s)         11907.439108082093
Epoch                        170
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:33:59.113258 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #170 | Epoch Duration: 65.54063630104065
2020-01-11 06:33:59.113500 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #170 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8407677
Z variance train             0.026149089
KL Divergence                17.07975
KL Loss                      1.707975
QF Loss                      936.65625
VF Loss                      802.1537
Policy Loss                  -711.9905
Q Predictions Mean           708.79175
Q Predictions Std            172.28856
Q Predictions Max            906.95856
Q Predictions Min            7.415257
V Predictions Mean           716.3684
V Predictions Std            165.439
V Predictions Max            906.4319
V Predictions Min            18.610523
Log Pis Mean                 -0.9547513
Log Pis Std                  2.564943
Log Pis Max                  9.866013
Log Pis Min                  -7.3819647
Policy mu Mean               0.07058053
Policy mu Std                0.55858856
Policy mu Max                1.8992869
Policy mu Min                -1.7835675
Policy log std Mean          -0.86715734
Policy log std Std           0.2642844
Policy log std Max           -0.3284905
Policy log std Min           -2.7509356
Z mean eval                  0.83967626
Z variance eval              0.029775133
total_rewards                [-119.79434458 2032.77403649   59.05693092 1631.11277824 2149.40279482
 2010.64738102 2187.83776496 2015.67558629 1259.24956783  856.67567613]
total_rewards_mean           1408.2638172112638
total_rewards_std            825.2446851965815
total_rewards_max            2187.83776496264
total_rewards_min            -119.79434458371934
Number of train steps total  172000
Number of env steps total    862000
Number of rollouts total     0
Train Time (s)               27.261728992685676
(Previous) Eval Time (s)     17.253469021990895
Sample Time (s)              17.72076769405976
Epoch Time (s)               62.23596570873633
Total Train Time (s)         11977.017407105304
Epoch                        171
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:35:08.692999 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #171 | Epoch Duration: 69.57932877540588
2020-01-11 06:35:08.693192 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #171 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8412026
Z variance train             0.02978054
KL Divergence                16.855568
KL Loss                      1.6855568
QF Loss                      479.73364
VF Loss                      86.770325
Policy Loss                  -694.1629
Q Predictions Mean           690.0977
Q Predictions Std            188.15797
Q Predictions Max            930.3285
Q Predictions Min            -0.67645985
V Predictions Mean           691.1305
V Predictions Std            185.35548
V Predictions Max            919.86676
V Predictions Min            68.09013
Log Pis Mean                 -1.457758
Log Pis Std                  2.377034
Log Pis Max                  8.070157
Log Pis Min                  -11.5057335
Policy mu Mean               0.063185245
Policy mu Std                0.51950675
Policy mu Max                2.3425202
Policy mu Min                -2.2377992
Policy log std Mean          -0.835044
Policy log std Std           0.25034952
Policy log std Max           0.00073844194
Policy log std Min           -1.7164302
Z mean eval                  0.8407365
Z variance eval              0.025280306
total_rewards                [-130.75253838 1899.32523884 1274.71905524 1869.01741466 2039.09649255
 1956.2257999  1940.15552883 1004.7848722   969.54075568   48.19422722]
total_rewards_mean           1287.030684674425
total_rewards_std            766.7495995682775
total_rewards_max            2039.0964925463657
total_rewards_min            -130.75253837970652
Number of train steps total  173000
Number of env steps total    867000
Number of rollouts total     0
Train Time (s)               26.65781770274043
(Previous) Eval Time (s)     24.59654729999602
Sample Time (s)              17.988059483934194
Epoch Time (s)               69.24242448667064
Total Train Time (s)         12046.31554286601
Epoch                        172
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:36:17.993855 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #172 | Epoch Duration: 69.3005256652832
2020-01-11 06:36:17.994083 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #172 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8411976
Z variance train             0.025193473
KL Divergence                17.80541
KL Loss                      1.7805411
QF Loss                      707.7095
VF Loss                      171.95027
Policy Loss                  -718.5083
Q Predictions Mean           715.6007
Q Predictions Std            166.4117
Q Predictions Max            911.3505
Q Predictions Min            231.57767
V Predictions Mean           721.2289
V Predictions Std            166.62042
V Predictions Max            908.9998
V Predictions Min            242.43852
Log Pis Mean                 -1.0402656
Log Pis Std                  2.2490914
Log Pis Max                  5.935773
Log Pis Min                  -7.7202973
Policy mu Mean               0.07919889
Policy mu Std                0.5325241
Policy mu Max                1.9077272
Policy mu Min                -1.6626987
Policy log std Mean          -0.86430943
Policy log std Std           0.25962403
Policy log std Max           -0.19115394
Policy log std Min           -2.1532793
Z mean eval                  0.8605944
Z variance eval              0.050263762
total_rewards                [1108.14728764  439.85065309 1985.09560761  550.16610989 1406.78691856
 2279.23308591  240.24499661 1024.86021637  514.65569579 2157.95961168]
total_rewards_mean           1170.7000183144278
total_rewards_std            718.542287247133
total_rewards_max            2279.233085912082
total_rewards_min            240.2449966053982
Number of train steps total  174000
Number of env steps total    872000
Number of rollouts total     0
Train Time (s)               28.575186701025814
(Previous) Eval Time (s)     24.654290392063558
Sample Time (s)              17.891711182892323
Epoch Time (s)               71.1211882759817
Total Train Time (s)         12115.34684197884
Epoch                        173
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:37:27.027477 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #173 | Epoch Duration: 69.03322052955627
2020-01-11 06:37:27.027679 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #173 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8610811
Z variance train             0.050257016
KL Divergence                17.181091
KL Loss                      1.7181091
QF Loss                      545.1564
VF Loss                      86.07829
Policy Loss                  -734.63446
Q Predictions Mean           733.2798
Q Predictions Std            204.54573
Q Predictions Max            955.97626
Q Predictions Min            -0.17340088
V Predictions Mean           739.78546
V Predictions Std            203.56535
V Predictions Max            953.6128
V Predictions Min            36.648212
Log Pis Mean                 -1.556454
Log Pis Std                  2.5158002
Log Pis Max                  8.9661045
Log Pis Min                  -10.198595
Policy mu Mean               0.049106747
Policy mu Std                0.5622167
Policy mu Max                1.7762742
Policy mu Min                -2.0176435
Policy log std Mean          -0.81311595
Policy log std Std           0.26167572
Policy log std Max           -0.15886694
Policy log std Min           -2.1550412
Z mean eval                  0.8566271
Z variance eval              0.04794312
total_rewards                [2185.52931298 1271.78234092  532.16847465 1793.23744674 1363.7803126
 2103.91029543 2232.56287672 2245.36489692  377.06015225  958.48884511]
total_rewards_mean           1506.3884954310831
total_rewards_std            676.3150560473216
total_rewards_max            2245.3648969175742
total_rewards_min            377.0601522461853
Number of train steps total  175000
Number of env steps total    877000
Number of rollouts total     0
Train Time (s)               28.419509518891573
(Previous) Eval Time (s)     22.56601796578616
Sample Time (s)              18.05018411995843
Epoch Time (s)               69.03571160463616
Total Train Time (s)         12183.718220593873
Epoch                        174
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:38:35.402409 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #174 | Epoch Duration: 68.37455677986145
2020-01-11 06:38:35.402636 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #174 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8568085
Z variance train             0.04788716
KL Divergence                17.35931
KL Loss                      1.735931
QF Loss                      652.12
VF Loss                      440.83813
Policy Loss                  -727.83624
Q Predictions Mean           724.21924
Q Predictions Std            171.79634
Q Predictions Max            925.35626
Q Predictions Min            28.965996
V Predictions Mean           723.21344
V Predictions Std            175.2356
V Predictions Max            926.7712
V Predictions Min            -7.995717
Log Pis Mean                 -0.8621923
Log Pis Std                  2.4835079
Log Pis Max                  13.417464
Log Pis Min                  -8.019941
Policy mu Mean               0.07686843
Policy mu Std                0.5464167
Policy mu Max                1.7751083
Policy mu Min                -2.0091054
Policy log std Mean          -0.8790087
Policy log std Std           0.29353985
Policy log std Max           -0.100274086
Policy log std Min           -2.8746662
Z mean eval                  0.8457901
Z variance eval              0.02643313
total_rewards                [1874.75804599  672.28584647 1963.75547135  809.12349459  593.71717439
  260.49134757 1225.67272089 1900.91122633 1026.73173149 1013.04729292]
total_rewards_mean           1134.049435199861
total_rewards_std            568.6437335423357
total_rewards_max            1963.755471349753
total_rewards_min            260.4913475712446
Number of train steps total  176000
Number of env steps total    882000
Number of rollouts total     0
Train Time (s)               29.48955184686929
(Previous) Eval Time (s)     21.90450272196904
Sample Time (s)              18.812772476579994
Epoch Time (s)               70.20682704541832
Total Train Time (s)         12254.052187489346
Epoch                        175
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:39:45.738697 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #175 | Epoch Duration: 70.33580875396729
2020-01-11 06:39:45.739003 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #175 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.84643924
Z variance train             0.026472684
KL Divergence                18.12807
KL Loss                      1.8128071
QF Loss                      371.21344
VF Loss                      105.77424
Policy Loss                  -732.6789
Q Predictions Mean           728.72327
Q Predictions Std            159.90356
Q Predictions Max            926.8915
Q Predictions Min            220.51965
V Predictions Mean           738.0039
V Predictions Std            160.37701
V Predictions Max            929.3978
V Predictions Min            222.03004
Log Pis Mean                 -1.2926075
Log Pis Std                  2.243682
Log Pis Max                  4.9958982
Log Pis Min                  -8.383234
Policy mu Mean               0.17146835
Policy mu Std                0.5460621
Policy mu Max                1.921153
Policy mu Min                -1.5716945
Policy log std Mean          -0.8062627
Policy log std Std           0.24410155
Policy log std Max           -0.2278493
Policy log std Min           -1.9379048
Z mean eval                  0.9204925
Z variance eval              0.02550289
total_rewards                [1898.16792314 1987.4370985  1899.6505527  1871.12681316 2035.79924365
 1008.15061324 1085.71927349 2039.47080867  914.58107199 2166.61493366]
total_rewards_mean           1690.671833219879
total_rewards_std            459.21406004928633
total_rewards_max            2166.614933660819
total_rewards_min            914.5810719875202
Number of train steps total  177000
Number of env steps total    887000
Number of rollouts total     0
Train Time (s)               29.20315606612712
(Previous) Eval Time (s)     22.033164065796882
Sample Time (s)              19.123558080289513
Epoch Time (s)               70.35987821221352
Total Train Time (s)         12327.862378204241
Epoch                        176
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:40:59.553177 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #176 | Epoch Duration: 73.81397151947021
2020-01-11 06:40:59.553458 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #176 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.919098
Z variance train             0.025507282
KL Divergence                18.126266
KL Loss                      1.8126267
QF Loss                      662.5781
VF Loss                      226.05968
Policy Loss                  -713.4545
Q Predictions Mean           708.75507
Q Predictions Std            185.58939
Q Predictions Max            913.1171
Q Predictions Min            -32.447357
V Predictions Mean           714.6035
V Predictions Std            178.45241
V Predictions Max            923.3242
V Predictions Min            -10.161637
Log Pis Mean                 -0.91810936
Log Pis Std                  2.5736651
Log Pis Max                  14.69406
Log Pis Min                  -8.370752
Policy mu Mean               0.06999507
Policy mu Std                0.5464093
Policy mu Max                2.4320307
Policy mu Min                -2.0773475
Policy log std Mean          -0.8695598
Policy log std Std           0.26716492
Policy log std Max           -0.30698383
Policy log std Min           -2.4641707
Z mean eval                  0.8552531
Z variance eval              0.025018254
total_rewards                [2329.18059166 1405.57573284 2378.3683995   604.98978841 2201.52289254
 2498.44096816 2136.8231797  2098.12471606 1095.02013729 1502.7649366 ]
total_rewards_mean           1825.0811342773109
total_rewards_std            602.3773974168325
total_rewards_max            2498.4409681629336
total_rewards_min            604.9897884101707
Number of train steps total  178000
Number of env steps total    892000
Number of rollouts total     0
Train Time (s)               27.331809140276164
(Previous) Eval Time (s)     25.48692612396553
Sample Time (s)              18.69181605707854
Epoch Time (s)               71.51055132132024
Total Train Time (s)         12399.40685383603
Epoch                        177
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:42:11.101578 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #177 | Epoch Duration: 71.54778933525085
2020-01-11 06:42:11.101966 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #177 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8556145
Z variance train             0.024952829
KL Divergence                17.962946
KL Loss                      1.7962946
QF Loss                      481.80185
VF Loss                      85.99346
Policy Loss                  -696.53815
Q Predictions Mean           691.49634
Q Predictions Std            191.83244
Q Predictions Max            901.43933
Q Predictions Min            -3.9948504
V Predictions Mean           701.3196
V Predictions Std            193.8325
V Predictions Max            913.71124
V Predictions Min            -3.1759353
Log Pis Mean                 -1.429558
Log Pis Std                  2.625893
Log Pis Max                  10.055319
Log Pis Min                  -9.64174
Policy mu Mean               0.07324208
Policy mu Std                0.57043743
Policy mu Max                2.3322566
Policy mu Min                -2.5309603
Policy log std Mean          -0.8037821
Policy log std Std           0.25952414
Policy log std Max           0.34999764
Policy log std Min           -2.614459
Z mean eval                  0.8708495
Z variance eval              0.030618599
total_rewards                [2069.21194855 2101.87828211 2010.78370359  314.20028187 2148.42183099
 1337.13594912 2202.06466508 2063.47002013 2077.17874152  998.14823338]
total_rewards_mean           1732.2493656329923
total_rewards_std            604.6686957879214
total_rewards_max            2202.064665077902
total_rewards_min            314.20028187228996
Number of train steps total  179000
Number of env steps total    897000
Number of rollouts total     0
Train Time (s)               27.34305260423571
(Previous) Eval Time (s)     25.523855725303292
Sample Time (s)              17.883623816538602
Epoch Time (s)               70.7505321460776
Total Train Time (s)         12470.33214721037
Epoch                        178
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:43:22.027585 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #178 | Epoch Duration: 70.92540144920349
2020-01-11 06:43:22.027787 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #178 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.868755
Z variance train             0.030600185
KL Divergence                17.900427
KL Loss                      1.7900428
QF Loss                      682.70874
VF Loss                      236.09634
Policy Loss                  -743.08704
Q Predictions Mean           737.5663
Q Predictions Std            176.9481
Q Predictions Max            972.55066
Q Predictions Min            244.26822
V Predictions Mean           743.1163
V Predictions Std            176.83263
V Predictions Max            974.67694
V Predictions Min            233.17052
Log Pis Mean                 -1.1787941
Log Pis Std                  2.4707072
Log Pis Max                  9.467156
Log Pis Min                  -9.718966
Policy mu Mean               0.0465495
Policy mu Std                0.5561664
Policy mu Max                2.1083717
Policy mu Min                -2.3338141
Policy log std Mean          -0.85436124
Policy log std Std           0.2587233
Policy log std Max           -0.21161407
Policy log std Min           -2.5709107
Z mean eval                  0.8676276
Z variance eval              0.02520902
total_rewards                [2142.47450581   60.97555794 2076.44226707 1328.66403883  438.57497257
  596.08346265  178.23996317  837.66648739 1594.99403586 1366.23176101]
total_rewards_mean           1062.034705230497
total_rewards_std            712.9804920849298
total_rewards_max            2142.4745058107865
total_rewards_min            60.97555793698825
Number of train steps total  180000
Number of env steps total    902000
Number of rollouts total     0
Train Time (s)               28.09499430283904
(Previous) Eval Time (s)     25.698440115898848
Sample Time (s)              18.378966903313994
Epoch Time (s)               72.17240132205188
Total Train Time (s)         12532.743869298603
Epoch                        179
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:44:24.440699 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #179 | Epoch Duration: 62.41274833679199
2020-01-11 06:44:24.440911 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #179 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8682227
Z variance train             0.025201404
KL Divergence                18.294306
KL Loss                      1.8294306
QF Loss                      825.3965
VF Loss                      122.49331
Policy Loss                  -736.4164
Q Predictions Mean           733.349
Q Predictions Std            177.53261
Q Predictions Max            926.8512
Q Predictions Min            243.92854
V Predictions Mean           730.9352
V Predictions Std            177.85379
V Predictions Max            924.5342
V Predictions Min            252.8749
Log Pis Mean                 -1.1313009
Log Pis Std                  2.5030136
Log Pis Max                  9.620572
Log Pis Min                  -7.7574105
Policy mu Mean               0.053234003
Policy mu Std                0.5128173
Policy mu Max                2.4192913
Policy mu Min                -1.8367319
Policy log std Mean          -0.8800797
Policy log std Std           0.27451918
Policy log std Max           -0.17440629
Policy log std Min           -2.0780408
Z mean eval                  0.8739525
Z variance eval              0.02013875
total_rewards                [1740.95647144 2316.10811653 2119.7278062  2238.90364986  626.83119461
  741.870367   1115.62567221 2238.8758663   268.93566494 1261.38441521]
total_rewards_mean           1466.921922429197
total_rewards_std            724.3282620176321
total_rewards_max            2316.1081165286582
total_rewards_min            268.935664939743
Number of train steps total  181000
Number of env steps total    907000
Number of rollouts total     0
Train Time (s)               28.56016511004418
(Previous) Eval Time (s)     15.938420477788895
Sample Time (s)              17.881663914304227
Epoch Time (s)               62.3802495021373
Total Train Time (s)         12602.556869996246
Epoch                        180
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:45:34.259433 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #180 | Epoch Duration: 69.81833338737488
2020-01-11 06:45:34.259702 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #180 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8741754
Z variance train             0.02016257
KL Divergence                19.160942
KL Loss                      1.9160942
QF Loss                      411.91693
VF Loss                      58.059483
Policy Loss                  -759.9483
Q Predictions Mean           757.73083
Q Predictions Std            171.66335
Q Predictions Max            966.8772
Q Predictions Min            240.449
V Predictions Mean           757.6356
V Predictions Std            170.49353
V Predictions Max            970.70514
V Predictions Min            248.57509
Log Pis Mean                 -1.2127361
Log Pis Std                  2.4416635
Log Pis Max                  5.9788218
Log Pis Min                  -8.283618
Policy mu Mean               0.03156731
Policy mu Std                0.5467192
Policy mu Max                1.8892338
Policy mu Min                -1.8510666
Policy log std Mean          -0.82565343
Policy log std Std           0.2384649
Policy log std Max           -0.23432305
Policy log std Min           -1.9782104
Z mean eval                  0.87306595
Z variance eval              0.02190827
total_rewards                [2188.74503894 2230.19269002 2115.3571283  2106.53630665 2183.84440608
  179.30388586 2232.24038882 2080.84639711 2271.31268019 1347.67333456]
total_rewards_mean           1893.6052256519263
total_rewards_std            625.1733862339848
total_rewards_max            2271.312680185492
total_rewards_min            179.30388585970067
Number of train steps total  182000
Number of env steps total    912000
Number of rollouts total     0
Train Time (s)               29.235582598950714
(Previous) Eval Time (s)     23.376185717061162
Sample Time (s)              17.38278878806159
Epoch Time (s)               69.99455710407346
Total Train Time (s)         12672.578340969048
Epoch                        181
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:46:44.283968 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #181 | Epoch Duration: 70.02400326728821
2020-01-11 06:46:44.284293 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #181 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8726398
Z variance train             0.021892166
KL Divergence                18.180283
KL Loss                      1.8180283
QF Loss                      465.25778
VF Loss                      76.83553
Policy Loss                  -762.1639
Q Predictions Mean           759.17316
Q Predictions Std            165.87518
Q Predictions Max            963.8808
Q Predictions Min            221.17044
V Predictions Mean           760.33655
V Predictions Std            164.19884
V Predictions Max            958.2248
V Predictions Min            227.80829
Log Pis Mean                 -1.2216116
Log Pis Std                  2.5828168
Log Pis Max                  6.160179
Log Pis Min                  -12.202311
Policy mu Mean               0.05528848
Policy mu Std                0.5525125
Policy mu Max                2.1214824
Policy mu Min                -1.8841625
Policy log std Mean          -0.85996276
Policy log std Std           0.22529174
Policy log std Max           -0.32111496
Policy log std Min           -1.7585512
Z mean eval                  0.8799903
Z variance eval              0.018881489
total_rewards                [1843.32896117 1977.52508967 1810.26342374  663.75607002 1849.83860432
 2020.99535434 2008.79007029 2099.54077611 1976.82414834 2010.23500122]
total_rewards_mean           1826.109749922943
total_rewards_std            397.22000333586453
total_rewards_max            2099.540776109031
total_rewards_min            663.7560700232461
Number of train steps total  183000
Number of env steps total    917000
Number of rollouts total     0
Train Time (s)               31.623645420651883
(Previous) Eval Time (s)     23.405321639031172
Sample Time (s)              19.240056965965778
Epoch Time (s)               74.26902402564883
Total Train Time (s)         12748.37468412472
Epoch                        182
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:48:00.083767 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #182 | Epoch Duration: 75.799143075943
2020-01-11 06:48:00.084137 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #182 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8793726
Z variance train             0.01886909
KL Divergence                18.458748
KL Loss                      1.8458748
QF Loss                      906.72876
VF Loss                      437.86304
Policy Loss                  -730.36926
Q Predictions Mean           726.8118
Q Predictions Std            192.54695
Q Predictions Max            929.32043
Q Predictions Min            38.868187
V Predictions Mean           734.83057
V Predictions Std            191.97173
V Predictions Max            919.7631
V Predictions Min            -6.9750156
Log Pis Mean                 -1.1821618
Log Pis Std                  2.4251003
Log Pis Max                  12.569532
Log Pis Min                  -6.593288
Policy mu Mean               0.055929463
Policy mu Std                0.5393329
Policy mu Max                1.9315346
Policy mu Min                -1.5320044
Policy log std Mean          -0.8428937
Policy log std Std           0.25400668
Policy log std Max           -0.24941438
Policy log std Min           -2.5510762
Z mean eval                  0.8743399
Z variance eval              0.017366495
total_rewards                [1594.58361656 1525.14282588 1390.65828932 1301.3159428   311.38976028
   97.99512525 2156.43095359   54.43820317   59.37601346  322.20109184]
total_rewards_mean           881.3531822154175
total_rewards_std            748.0200899494829
total_rewards_max            2156.430953594225
total_rewards_min            54.43820316924995
Number of train steps total  184000
Number of env steps total    922000
Number of rollouts total     0
Train Time (s)               29.084878670983016
(Previous) Eval Time (s)     24.935098596848547
Sample Time (s)              18.813554979860783
Epoch Time (s)               72.83353224769235
Total Train Time (s)         12813.502388271969
Epoch                        183
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:49:05.211749 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #183 | Epoch Duration: 65.12742185592651
2020-01-11 06:49:05.221432 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #183 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8737136
Z variance train             0.017404102
KL Divergence                18.447975
KL Loss                      1.8447975
QF Loss                      492.07953
VF Loss                      129.45131
Policy Loss                  -755.9767
Q Predictions Mean           751.91626
Q Predictions Std            173.53044
Q Predictions Max            929.8318
Q Predictions Min            -19.637028
V Predictions Mean           747.60583
V Predictions Std            169.18918
V Predictions Max            919.3156
V Predictions Min            -1.6032854
Log Pis Mean                 -1.2698572
Log Pis Std                  2.6983123
Log Pis Max                  8.03458
Log Pis Min                  -9.241719
Policy mu Mean               0.04592763
Policy mu Std                0.56265277
Policy mu Max                2.2447019
Policy mu Min                -2.120943
Policy log std Mean          -0.84001726
Policy log std Std           0.261182
Policy log std Max           -0.31261447
Policy log std Min           -2.1280737
Z mean eval                  0.90394175
Z variance eval              0.022685822
total_rewards                [2191.71915023 2200.73636151 2370.27578387 2217.17972223 1152.13299132
  906.56167094  957.73041537 2315.32599332 2407.75863454  909.72497761]
total_rewards_mean           1762.9145700954257
total_rewards_std            644.5491787284456
total_rewards_max            2407.7586345449386
total_rewards_min            906.5616709379423
Number of train steps total  185000
Number of env steps total    927000
Number of rollouts total     0
Train Time (s)               26.224016495049
(Previous) Eval Time (s)     17.228648360818624
Sample Time (s)              17.286542269401252
Epoch Time (s)               60.73920712526888
Total Train Time (s)         12880.015577212442
Epoch                        184
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:50:11.729346 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #184 | Epoch Duration: 66.5076699256897
2020-01-11 06:50:11.729610 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #184 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.902372
Z variance train             0.022583509
KL Divergence                19.122757
KL Loss                      1.9122757
QF Loss                      697.23755
VF Loss                      86.28881
Policy Loss                  -739.5411
Q Predictions Mean           736.4267
Q Predictions Std            189.18413
Q Predictions Max            942.12885
Q Predictions Min            43.218746
V Predictions Mean           741.395
V Predictions Std            185.36818
V Predictions Max            938.04083
V Predictions Min            204.72293
Log Pis Mean                 -1.2023066
Log Pis Std                  2.502295
Log Pis Max                  7.022338
Log Pis Min                  -7.1060915
Policy mu Mean               -0.028083827
Policy mu Std                0.565167
Policy mu Max                2.0255067
Policy mu Min                -2.3577187
Policy log std Mean          -0.8419125
Policy log std Std           0.25021097
Policy log std Max           -0.23205328
Policy log std Min           -2.1697662
Z mean eval                  0.89414656
Z variance eval              0.019970123
total_rewards                [ -10.93413727 1215.43233948 2233.73100218  371.02669357 2093.91891594
  859.77551684  910.71542488 2148.00703608  335.93869044 1620.60436092]
total_rewards_mean           1177.8215843047333
total_rewards_std            777.0607412878763
total_rewards_max            2233.731002183781
total_rewards_min            -10.934137265943635
Number of train steps total  186000
Number of env steps total    932000
Number of rollouts total     0
Train Time (s)               31.012923560105264
(Previous) Eval Time (s)     22.99685845617205
Sample Time (s)              18.93228387553245
Epoch Time (s)               72.94206589180976
Total Train Time (s)         12948.552953191102
Epoch                        185
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:51:20.267935 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #185 | Epoch Duration: 68.53817796707153
2020-01-11 06:51:20.268118 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #185 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8962326
Z variance train             0.020012388
KL Divergence                18.743097
KL Loss                      1.8743098
QF Loss                      285.50848
VF Loss                      163.62527
Policy Loss                  -750.8156
Q Predictions Mean           747.11475
Q Predictions Std            186.96844
Q Predictions Max            956.2516
Q Predictions Min            239.73314
V Predictions Mean           739.81995
V Predictions Std            184.81636
V Predictions Max            945.30505
V Predictions Min            244.19284
Log Pis Mean                 -1.210207
Log Pis Std                  2.5027776
Log Pis Max                  5.491795
Log Pis Min                  -9.11908
Policy mu Mean               0.02901471
Policy mu Std                0.53416604
Policy mu Max                1.9860158
Policy mu Min                -2.164637
Policy log std Mean          -0.8492007
Policy log std Std           0.24213395
Policy log std Max           -0.24086457
Policy log std Min           -1.9544163
Z mean eval                  0.8636014
Z variance eval              0.019201482
total_rewards                [1713.20687616 1902.99410399  105.95723974  157.66477887 1489.90185773
 1120.54437305 1771.77854086 1997.98024548  864.25197074 1864.13807761]
total_rewards_mean           1298.841806424154
total_rewards_std            674.6215855220277
total_rewards_max            1997.9802454796381
total_rewards_min            105.95723973972969
Number of train steps total  187000
Number of env steps total    937000
Number of rollouts total     0
Train Time (s)               28.97566079488024
(Previous) Eval Time (s)     18.592617864254862
Sample Time (s)              18.268889965955168
Epoch Time (s)               65.83716862509027
Total Train Time (s)         13016.183401833288
Epoch                        186
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:52:27.901115 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #186 | Epoch Duration: 67.63283824920654
2020-01-11 06:52:27.901319 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #186 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8647753
Z variance train             0.019235719
KL Divergence                18.521847
KL Loss                      1.8521847
QF Loss                      3249.751
VF Loss                      254.05707
Policy Loss                  -738.25775
Q Predictions Mean           736.5505
Q Predictions Std            198.88306
Q Predictions Max            973.5285
Q Predictions Min            1.8749263
V Predictions Mean           724.7416
V Predictions Std            197.72264
V Predictions Max            946.7163
V Predictions Min            0.91933554
Log Pis Mean                 -1.3147349
Log Pis Std                  2.5389647
Log Pis Max                  9.1434
Log Pis Min                  -6.4438047
Policy mu Mean               0.053190686
Policy mu Std                0.5426712
Policy mu Max                2.368954
Policy mu Min                -1.937347
Policy log std Mean          -0.83365476
Policy log std Std           0.27345642
Policy log std Max           -0.26366305
Policy log std Min           -2.2092574
Z mean eval                  0.8751733
Z variance eval              0.019587966
total_rewards                [1385.66425975 2059.56285801 2308.39448125  244.15675527 2108.14762408
 1770.61747447 2089.08138464  450.81543173 1974.44429459 2148.30328223]
total_rewards_mean           1653.9187846027046
total_rewards_std            696.8639927773589
total_rewards_max            2308.3944812502236
total_rewards_min            244.15675526680482
Number of train steps total  188000
Number of env steps total    942000
Number of rollouts total     0
Train Time (s)               32.11724514234811
(Previous) Eval Time (s)     20.387987199705094
Sample Time (s)              17.47785374522209
Epoch Time (s)               69.9830860872753
Total Train Time (s)         13088.752103735693
Epoch                        187
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:53:40.474780 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #187 | Epoch Duration: 72.57326745986938
2020-01-11 06:53:40.475088 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #187 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8775104
Z variance train             0.019617941
KL Divergence                19.007753
KL Loss                      1.9007753
QF Loss                      403.2577
VF Loss                      41.3908
Policy Loss                  -782.3217
Q Predictions Mean           782.86383
Q Predictions Std            165.3155
Q Predictions Max            964.0278
Q Predictions Min            19.003048
V Predictions Mean           783.05225
V Predictions Std            164.55417
V Predictions Max            951.9716
V Predictions Min            -5.1851244
Log Pis Mean                 -1.4493183
Log Pis Std                  2.5068314
Log Pis Max                  7.756547
Log Pis Min                  -10.317197
Policy mu Mean               0.050269663
Policy mu Std                0.5237905
Policy mu Max                3.1015553
Policy mu Min                -3.5315585
Policy log std Mean          -0.86250275
Policy log std Std           0.2350915
Policy log std Max           0.24803722
Policy log std Min           -1.8725421
Z mean eval                  0.8731159
Z variance eval              0.024157632
total_rewards                [  20.90108074   87.96816631   53.89642629  -64.31493235  585.16481846
 1125.38772275 2115.98686081   26.90402392  754.68003853 2128.77235249]
total_rewards_mean           683.5346557961481
total_rewards_std            808.162949794226
total_rewards_max            2128.772352487796
total_rewards_min            -64.31493234801457
Number of train steps total  189000
Number of env steps total    947000
Number of rollouts total     0
Train Time (s)               26.264216877985746
(Previous) Eval Time (s)     22.977845061570406
Sample Time (s)              18.86725711915642
Epoch Time (s)               68.10931905871257
Total Train Time (s)         13155.072982177138
Epoch                        188
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:54:46.796248 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #188 | Epoch Duration: 66.32093214988708
2020-01-11 06:54:46.796457 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #188 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.87364113
Z variance train             0.024209276
KL Divergence                18.877565
KL Loss                      1.8877566
QF Loss                      533.1825
VF Loss                      83.53441
Policy Loss                  -751.4411
Q Predictions Mean           749.03906
Q Predictions Std            198.52193
Q Predictions Max            952.40326
Q Predictions Min            18.196493
V Predictions Mean           749.43396
V Predictions Std            199.21477
V Predictions Max            955.26874
V Predictions Min            -10.198326
Log Pis Mean                 -1.3018508
Log Pis Std                  2.7328053
Log Pis Max                  13.272774
Log Pis Min                  -8.555173
Policy mu Mean               0.024094678
Policy mu Std                0.52759826
Policy mu Max                2.2832208
Policy mu Min                -2.2932255
Policy log std Mean          -0.8753852
Policy log std Std           0.27389798
Policy log std Max           0.5049715
Policy log std Min           -2.1921206
Z mean eval                  0.88190097
Z variance eval              0.024216924
total_rewards                [ -17.29082887  -53.50291856 2286.58190064 1271.61650908 2124.00090916
 2137.42238827  318.28405535 1938.03225469  866.84234911  739.04772564]
total_rewards_mean           1161.1034344507898
total_rewards_std            871.8859043312906
total_rewards_max            2286.5819006426427
total_rewards_min            -53.502918564965384
Number of train steps total  190000
Number of env steps total    952000
Number of rollouts total     0
Train Time (s)               29.00051109213382
(Previous) Eval Time (s)     21.189141983166337
Sample Time (s)              18.0175939979963
Epoch Time (s)               68.20724707329646
Total Train Time (s)         13223.319765531924
Epoch                        189
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:55:55.047951 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #189 | Epoch Duration: 68.25133395195007
2020-01-11 06:55:55.048211 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #189 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.87979734
Z variance train             0.024113659
KL Divergence                19.197378
KL Loss                      1.9197378
QF Loss                      1353.0837
VF Loss                      172.51352
Policy Loss                  -739.0921
Q Predictions Mean           734.66833
Q Predictions Std            204.25272
Q Predictions Max            949.8206
Q Predictions Min            210.83197
V Predictions Mean           732.07275
V Predictions Std            200.93326
V Predictions Max            929.8687
V Predictions Min            215.44904
Log Pis Mean                 -1.4036326
Log Pis Std                  2.5675552
Log Pis Max                  8.591467
Log Pis Min                  -8.693478
Policy mu Mean               0.08655454
Policy mu Std                0.5629345
Policy mu Max                1.9513339
Policy mu Min                -1.6992968
Policy log std Mean          -0.81590986
Policy log std Std           0.24232693
Policy log std Max           -0.21062109
Policy log std Min           -2.080449
Z mean eval                  0.8852352
Z variance eval              0.02279171
total_rewards                [1224.85399158  -90.43909451   49.28727995  287.12299295  789.94408461
  329.79890503 1627.130255    805.17127828  113.19223459  408.25760271]
total_rewards_mean           554.4319530201545
total_rewards_std            522.2534686412735
total_rewards_max            1627.1302550009182
total_rewards_min            -90.4390945119713
Number of train steps total  191000
Number of env steps total    957000
Number of rollouts total     0
Train Time (s)               26.825892340857536
(Previous) Eval Time (s)     21.232864140998572
Sample Time (s)              17.342768262140453
Epoch Time (s)               65.40152474399656
Total Train Time (s)         13288.13678842457
Epoch                        190
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:56:59.867033 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #190 | Epoch Duration: 64.81863927841187
2020-01-11 06:56:59.867283 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #190 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.88910085
Z variance train             0.022963423
KL Divergence                20.010227
KL Loss                      2.0010228
QF Loss                      532.71216
VF Loss                      581.77704
Policy Loss                  -766.92004
Q Predictions Mean           762.4806
Q Predictions Std            199.51477
Q Predictions Max            978.70276
Q Predictions Min            236.89261
V Predictions Mean           760.0293
V Predictions Std            199.62852
V Predictions Max            969.9219
V Predictions Min            244.38753
Log Pis Mean                 -1.3203142
Log Pis Std                  2.4146914
Log Pis Max                  6.9748588
Log Pis Min                  -8.40484
Policy mu Mean               0.063762575
Policy mu Std                0.53212416
Policy mu Max                1.9847884
Policy mu Min                -1.8779364
Policy log std Mean          -0.8381679
Policy log std Std           0.2640294
Policy log std Max           -0.14890596
Policy log std Min           -2.6090004
Z mean eval                  0.88088
Z variance eval              0.021960767
total_rewards                [ 391.77148418   75.69023205 1367.23868495  982.39873554 1841.24140633
  775.71138943 1667.80479728   28.11800085    7.74795832 2206.05412794]
total_rewards_mean           934.3776816889509
total_rewards_std            768.3776851281269
total_rewards_max            2206.054127936799
total_rewards_min            7.747958323033578
Number of train steps total  192000
Number of env steps total    962000
Number of rollouts total     0
Train Time (s)               30.01040680380538
(Previous) Eval Time (s)     20.649663225281984
Sample Time (s)              18.583789599128067
Epoch Time (s)               69.24385962821543
Total Train Time (s)         13356.54096602602
Epoch                        191
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:58:08.274079 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #191 | Epoch Duration: 68.40657711029053
2020-01-11 06:58:08.274313 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #191 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.88125527
Z variance train             0.02192007
KL Divergence                19.933834
KL Loss                      1.9933834
QF Loss                      944.901
VF Loss                      79.104355
Policy Loss                  -769.0296
Q Predictions Mean           766.2587
Q Predictions Std            171.3724
Q Predictions Max            944.64575
Q Predictions Min            225.16934
V Predictions Mean           764.8581
V Predictions Std            170.71083
V Predictions Max            942.0686
V Predictions Min            240.30284
Log Pis Mean                 -1.374546
Log Pis Std                  2.2841647
Log Pis Max                  6.2473736
Log Pis Min                  -7.7369633
Policy mu Mean               0.1125497
Policy mu Std                0.5264177
Policy mu Max                3.5909023
Policy mu Min                -1.954858
Policy log std Mean          -0.8274686
Policy log std Std           0.23638877
Policy log std Max           -0.20421499
Policy log std Min           -1.9192991
Z mean eval                  0.8925492
Z variance eval              0.020297581
total_rewards                [-143.35230564  541.42321655 2081.7666602   482.77291749 2332.21559443
 1035.67467646 1225.916201   1898.63172701  664.67614933 2014.1990676 ]
total_rewards_mean           1213.3923904421893
total_rewards_std            792.187920694563
total_rewards_max            2332.2155944309216
total_rewards_min            -143.35230564321012
Number of train steps total  193000
Number of env steps total    967000
Number of rollouts total     0
Train Time (s)               28.50868816813454
(Previous) Eval Time (s)     19.81201552832499
Sample Time (s)              17.744069560430944
Epoch Time (s)               66.06477325689048
Total Train Time (s)         13426.20925429603
Epoch                        192
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:59:17.946455 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #192 | Epoch Duration: 69.67193841934204
2020-01-11 06:59:17.946700 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #192 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89580727
Z variance train             0.020310318
KL Divergence                20.2604
KL Loss                      2.02604
QF Loss                      783.073
VF Loss                      343.1824
Policy Loss                  -754.3293
Q Predictions Mean           753.3158
Q Predictions Std            213.16777
Q Predictions Max            969.9456
Q Predictions Min            -45.51585
V Predictions Mean           755.126
V Predictions Std            208.82748
V Predictions Max            968.6226
V Predictions Min            78.56482
Log Pis Mean                 -0.9746195
Log Pis Std                  2.621958
Log Pis Max                  11.028948
Log Pis Min                  -7.699609
Policy mu Mean               0.019951526
Policy mu Std                0.59351724
Policy mu Max                2.367992
Policy mu Min                -2.2559695
Policy log std Mean          -0.8300984
Policy log std Std           0.26013547
Policy log std Max           -0.23556647
Policy log std Min           -2.5878918
Z mean eval                  0.86791784
Z variance eval              0.022265604
total_rewards                [ 153.78306034 2271.09476251  254.06189104 2179.95489171 1003.96766703
  808.9184569    92.6672996  2054.00152968 2315.02619682 2423.78403868]
total_rewards_mean           1355.7259794311262
total_rewards_std            934.9987769048618
total_rewards_max            2423.7840386844573
total_rewards_min            92.66729960019313
Number of train steps total  194000
Number of env steps total    972000
Number of rollouts total     0
Train Time (s)               31.358881333377212
(Previous) Eval Time (s)     23.41888768505305
Sample Time (s)              18.204966923687607
Epoch Time (s)               72.98273594211787
Total Train Time (s)         13497.695158869494
Epoch                        193
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:00:29.436252 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #193 | Epoch Duration: 71.48933839797974
2020-01-11 07:00:29.436563 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #193 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.86866647
Z variance train             0.022205573
KL Divergence                19.758121
KL Loss                      1.9758122
QF Loss                      477.93018
VF Loss                      52.057034
Policy Loss                  -748.995
Q Predictions Mean           745.5253
Q Predictions Std            207.87117
Q Predictions Max            956.8949
Q Predictions Min            3.6012578
V Predictions Mean           749.9586
V Predictions Std            206.14888
V Predictions Max            947.0319
V Predictions Min            -4.0817356
Log Pis Mean                 -1.0532839
Log Pis Std                  2.4660828
Log Pis Max                  6.4892497
Log Pis Min                  -7.482943
Policy mu Mean               0.024234308
Policy mu Std                0.55862045
Policy mu Max                1.9678422
Policy mu Min                -2.1582026
Policy log std Mean          -0.8431473
Policy log std Std           0.26111755
Policy log std Max           -0.20538437
Policy log std Min           -1.8710679
Z mean eval                  0.87206984
Z variance eval              0.029930478
total_rewards                [2050.00242065 1339.02185674 1403.8458454   284.56967114 1465.62472792
 2351.88687129 1583.20733948 2278.2144282   433.2650301   147.30323123]
total_rewards_mean           1333.6941422148634
total_rewards_std            764.5588826525651
total_rewards_max            2351.8868712903695
total_rewards_min            147.30323122644998
Number of train steps total  195000
Number of env steps total    977000
Number of rollouts total     0
Train Time (s)               27.819790630135685
(Previous) Eval Time (s)     21.9251685612835
Sample Time (s)              18.787655923049897
Epoch Time (s)               68.53261511446908
Total Train Time (s)         13563.85675640963
Epoch                        194
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:01:35.600066 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #194 | Epoch Duration: 66.1632821559906
2020-01-11 07:01:35.600249 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #194 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8712457
Z variance train             0.029932851
KL Divergence                18.475334
KL Loss                      1.8475335
QF Loss                      449.6406
VF Loss                      113.92348
Policy Loss                  -744.4924
Q Predictions Mean           740.14154
Q Predictions Std            214.48346
Q Predictions Max            961.5616
Q Predictions Min            -10.077074
V Predictions Mean           740.92944
V Predictions Std            213.45663
V Predictions Max            963.89374
V Predictions Min            -0.25517833
Log Pis Mean                 -1.4537323
Log Pis Std                  2.4160001
Log Pis Max                  6.0031214
Log Pis Min                  -11.20072
Policy mu Mean               0.052930377
Policy mu Std                0.5007635
Policy mu Max                1.8068177
Policy mu Min                -1.9341162
Policy log std Mean          -0.8529836
Policy log std Std           0.2407441
Policy log std Max           -0.26996854
Policy log std Min           -1.9189122
Z mean eval                  0.8871309
Z variance eval              0.039280094
total_rewards                [2432.83567341 1419.75374769  915.0600546  2313.59913791  537.63696547
 2236.74321114 1076.73351426 2381.94907699 1444.67566188 2476.34365864]
total_rewards_mean           1723.5330701988696
total_rewards_std            690.16515419835
total_rewards_max            2476.3436586403577
total_rewards_min            537.6369654732226
Number of train steps total  196000
Number of env steps total    982000
Number of rollouts total     0
Train Time (s)               26.59854738600552
(Previous) Eval Time (s)     19.555524681229144
Sample Time (s)              17.734105933923274
Epoch Time (s)               63.88817800115794
Total Train Time (s)         13634.633739105426
Epoch                        195
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:02:46.378933 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #195 | Epoch Duration: 70.77853441238403
2020-01-11 07:02:46.379129 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #195 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.88698006
Z variance train             0.03922988
KL Divergence                18.343733
KL Loss                      1.8343734
QF Loss                      544.96045
VF Loss                      162.99254
Policy Loss                  -745.0145
Q Predictions Mean           737.7122
Q Predictions Std            207.32504
Q Predictions Max            964.263
Q Predictions Min            -59.953598
V Predictions Mean           737.6669
V Predictions Std            201.62746
V Predictions Max            952.2441
V Predictions Min            -9.183401
Log Pis Mean                 -1.1942711
Log Pis Std                  2.736752
Log Pis Max                  8.470852
Log Pis Min                  -10.039185
Policy mu Mean               0.046334222
Policy mu Std                0.55335903
Policy mu Max                2.0048935
Policy mu Min                -2.044038
Policy log std Mean          -0.86412615
Policy log std Std           0.26481628
Policy log std Max           0.64285517
Policy log std Min           -2.63751
Z mean eval                  0.8968269
Z variance eval              0.029029077
total_rewards                [ 755.72939029 1344.69581277 2292.9543006   775.00485123 2277.17023896
 1460.58866948 1881.41116794 2323.06640886  816.23621146 1909.84429449]
total_rewards_mean           1583.6701346081077
total_rewards_std            610.4433303210541
total_rewards_max            2323.0664088588414
total_rewards_min            755.7293902942895
Number of train steps total  197000
Number of env steps total    987000
Number of rollouts total     0
Train Time (s)               27.92179656494409
(Previous) Eval Time (s)     26.445563103072345
Sample Time (s)              19.26329720998183
Epoch Time (s)               73.63065687799826
Total Train Time (s)         13706.39338889718
Epoch                        196
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:03:58.142607 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #196 | Epoch Duration: 71.7633101940155
2020-01-11 07:03:58.142824 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #196 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8979575
Z variance train             0.028978419
KL Divergence                18.65589
KL Loss                      1.865589
QF Loss                      750.35565
VF Loss                      221.05447
Policy Loss                  -804.00037
Q Predictions Mean           803.36786
Q Predictions Std            178.9386
Q Predictions Max            1000.3932
Q Predictions Min            -21.051651
V Predictions Mean           810.7643
V Predictions Std            179.99898
V Predictions Max            1007.4158
V Predictions Min            -6.6305656
Log Pis Mean                 -1.1524757
Log Pis Std                  2.417353
Log Pis Max                  5.357071
Log Pis Min                  -11.044561
Policy mu Mean               0.05485282
Policy mu Std                0.52791214
Policy mu Max                1.7546166
Policy mu Min                -1.8221585
Policy log std Mean          -0.8848065
Policy log std Std           0.24940194
Policy log std Max           -0.27564642
Policy log std Min           -2.0863433
Z mean eval                  0.9056298
Z variance eval              0.029114861
total_rewards                [2193.37316502 1601.55070983 2082.32121281 1936.69865351 1455.39021612
 2221.78575827 1913.52689851 2142.27843787 1088.44125313  854.18310669]
total_rewards_mean           1748.9549411772837
total_rewards_std            457.6076744501541
total_rewards_max            2221.785758273415
total_rewards_min            854.1831066906346
Number of train steps total  198000
Number of env steps total    992000
Number of rollouts total     0
Train Time (s)               27.133638376835734
(Previous) Eval Time (s)     24.577912437729537
Sample Time (s)              18.144684536382556
Epoch Time (s)               69.85623535094783
Total Train Time (s)         13777.07408453431
Epoch                        197
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:05:08.827060 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #197 | Epoch Duration: 70.68402814865112
2020-01-11 07:05:08.827347 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #197 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9054338
Z variance train             0.029024068
KL Divergence                18.519707
KL Loss                      1.8519707
QF Loss                      701.00507
VF Loss                      192.76607
Policy Loss                  -759.21857
Q Predictions Mean           754.8726
Q Predictions Std            218.16666
Q Predictions Max            992.0588
Q Predictions Min            54.049484
V Predictions Mean           754.3285
V Predictions Std            214.75429
V Predictions Max            991.78186
V Predictions Min            101.56822
Log Pis Mean                 -1.2815385
Log Pis Std                  2.4552248
Log Pis Max                  8.736111
Log Pis Min                  -7.187215
Policy mu Mean               0.05136023
Policy mu Std                0.56274194
Policy mu Max                2.356771
Policy mu Min                -2.0973518
Policy log std Mean          -0.81666684
Policy log std Std           0.2589386
Policy log std Max           -0.08154011
Policy log std Min           -2.5298235
Z mean eval                  0.91253203
Z variance eval              0.031991117
total_rewards                [ 178.298219    911.16719696  323.81801532  940.20333177 2046.60847207
  483.83490665  565.56577592 2128.81320264  867.32750944  635.1905374 ]
total_rewards_mean           908.0827167146215
total_rewards_std            635.2047626336996
total_rewards_max            2128.813202635631
total_rewards_min            178.29821899814846
Number of train steps total  199000
Number of env steps total    997000
Number of rollouts total     0
Train Time (s)               25.14725627982989
(Previous) Eval Time (s)     25.405394199304283
Sample Time (s)              18.16912735067308
Epoch Time (s)               68.72177782980725
Total Train Time (s)         13847.563493852504
Epoch                        198
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:06:19.317394 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #198 | Epoch Duration: 70.4898293018341
2020-01-11 07:06:19.317578 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #198 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9158577
Z variance train             0.03186357
KL Divergence                18.734627
KL Loss                      1.8734627
QF Loss                      1092.4833
VF Loss                      758.1558
Policy Loss                  -784.4798
Q Predictions Mean           783.2052
Q Predictions Std            185.34488
Q Predictions Max            991.52155
Q Predictions Min            118.110214
V Predictions Mean           786.8938
V Predictions Std            178.35399
V Predictions Max            994.23553
V Predictions Min            147.27306
Log Pis Mean                 -0.825767
Log Pis Std                  2.4281282
Log Pis Max                  8.106259
Log Pis Min                  -7.996271
Policy mu Mean               0.06954099
Policy mu Std                0.5195311
Policy mu Max                1.8817027
Policy mu Min                -1.8917319
Policy log std Mean          -0.8977649
Policy log std Std           0.25397813
Policy log std Max           -0.34323633
Policy log std Min           -2.1783638
Z mean eval                  0.89058465
Z variance eval              0.022910353
total_rewards                [ -19.01503335 1065.43501945  853.95413534 2459.95157911 1568.94790539
 2163.86523659  641.06718705 1219.22198012  205.18492856 2305.84526468]
total_rewards_mean           1246.4458202940398
total_rewards_std            823.4223622376807
total_rewards_max            2459.951579107579
total_rewards_min            -19.01503335203031
Number of train steps total  200000
Number of env steps total    1002000
Number of rollouts total     0
Train Time (s)               30.895132947713137
(Previous) Eval Time (s)     27.173105917871
Sample Time (s)              18.183656515087932
Epoch Time (s)               76.25189538067207
Total Train Time (s)         13918.151952947956
Epoch                        199
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:07:29.922140 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #199 | Epoch Duration: 70.60444116592407
2020-01-11 07:07:29.922291 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #199 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8906479
Z variance train             0.02286815
KL Divergence                18.907333
KL Loss                      1.8907334
QF Loss                      848.42896
VF Loss                      136.0881
Policy Loss                  -772.1053
Q Predictions Mean           769.3457
Q Predictions Std            194.34763
Q Predictions Max            961.7341
Q Predictions Min            232.44545
V Predictions Mean           776.56384
V Predictions Std            197.71729
V Predictions Max            971.9921
V Predictions Min            237.56888
Log Pis Mean                 -1.5170102
Log Pis Std                  2.371862
Log Pis Max                  7.497196
Log Pis Min                  -7.2317476
Policy mu Mean               0.08358185
Policy mu Std                0.53121644
Policy mu Max                2.008035
Policy mu Min                -1.9791582
Policy log std Mean          -0.84992325
Policy log std Std           0.25137198
Policy log std Max           -0.29922295
Policy log std Min           -2.2921774
Z mean eval                  0.89058053
Z variance eval              0.023963755
total_rewards                [1091.73154989 1214.84904136 1926.4928525  2267.79332083 1965.90939677
 2124.87794718 1979.14607352  641.23194314 2103.32270476  659.92340023]
total_rewards_mean           1597.5278230175938
total_rewards_std            597.3788329326694
total_rewards_max            2267.79332082657
total_rewards_min            641.2319431424112
Number of train steps total  201000
Number of env steps total    1007000
Number of rollouts total     0
Train Time (s)               30.36908079497516
(Previous) Eval Time (s)     21.525334787089378
Sample Time (s)              17.887564107310027
Epoch Time (s)               69.78197968937457
Total Train Time (s)         13993.819289547857
Epoch                        200
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:08:45.593023 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #200 | Epoch Duration: 75.67059278488159
2020-01-11 07:08:45.593242 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #200 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8945117
Z variance train             0.023934994
KL Divergence                18.859058
KL Loss                      1.8859059
QF Loss                      441.66974
VF Loss                      135.42293
Policy Loss                  -799.57855
Q Predictions Mean           794.2169
Q Predictions Std            180.22546
Q Predictions Max            1001.343
Q Predictions Min            27.275545
V Predictions Mean           792.7636
V Predictions Std            176.76263
V Predictions Max            995.7561
V Predictions Min            16.14297
Log Pis Mean                 -0.80970055
Log Pis Std                  2.348429
Log Pis Max                  6.2134476
Log Pis Min                  -8.9256115
Policy mu Mean               0.024012335
Policy mu Std                0.56122553
Policy mu Max                1.8939772
Policy mu Min                -1.694551
Policy log std Mean          -0.87410116
Policy log std Std           0.24853435
Policy log std Max           -0.22701311
Policy log std Min           -2.1445003
Z mean eval                  0.9038037
Z variance eval              0.028720671
total_rewards                [2184.11130368 2144.60661721 2222.6977667  2326.68177967 2013.33022662
 2165.11204575 2038.0306477  1526.86441514 2114.50694926 2265.92753381]
total_rewards_mean           2100.186928553695
total_rewards_std            211.49981297954895
total_rewards_max            2326.68177967016
total_rewards_min            1526.864415137425
Number of train steps total  202000
Number of env steps total    1012000
Number of rollouts total     0
Train Time (s)               30.376308771781623
(Previous) Eval Time (s)     27.413634659722447
Sample Time (s)              17.65865120338276
Epoch Time (s)               75.44859463488683
Total Train Time (s)         14069.75552587118
Epoch                        201
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:10:01.531002 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #201 | Epoch Duration: 75.9375991821289
2020-01-11 07:10:01.531187 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #201 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90567684
Z variance train             0.028724033
KL Divergence                18.590467
KL Loss                      1.8590468
QF Loss                      456.96906
VF Loss                      233.41457
Policy Loss                  -803.87445
Q Predictions Mean           799.9772
Q Predictions Std            172.52011
Q Predictions Max            1019.10614
Q Predictions Min            223.27382
V Predictions Mean           795.05145
V Predictions Std            170.87495
V Predictions Max            988.5003
V Predictions Min            226.53273
Log Pis Mean                 -1.1262268
Log Pis Std                  2.2255926
Log Pis Max                  4.47002
Log Pis Min                  -7.44232
Policy mu Mean               0.011461891
Policy mu Std                0.53084695
Policy mu Max                2.0701127
Policy mu Min                -1.6301701
Policy log std Mean          -0.89333946
Policy log std Std           0.24378821
Policy log std Max           -0.27941206
Policy log std Min           -1.8930974
Z mean eval                  0.8806221
Z variance eval              0.029801458
total_rewards                [ 936.04071393 2111.24160459 1951.16666818  118.27778329 1670.07020642
  682.44120035  529.39633829 2252.99647584 1542.6841086   442.70584199]
total_rewards_mean           1223.7020941477522
total_rewards_std            732.6024154206535
total_rewards_max            2252.99647584225
total_rewards_min            118.27778328507051
Number of train steps total  203000
Number of env steps total    1017000
Number of rollouts total     0
Train Time (s)               27.910317370668054
(Previous) Eval Time (s)     27.902349766343832
Sample Time (s)              18.97931686323136
Epoch Time (s)               74.79198400024325
Total Train Time (s)         14143.055136910174
Epoch                        202
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:11:14.834290 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #202 | Epoch Duration: 73.3029522895813
2020-01-11 07:11:14.834534 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #202 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8804908
Z variance train             0.029891005
KL Divergence                18.42997
KL Loss                      1.842997
QF Loss                      855.98224
VF Loss                      131.40791
Policy Loss                  -804.4717
Q Predictions Mean           803.177
Q Predictions Std            193.33957
Q Predictions Max            1009.3441
Q Predictions Min            241.07903
V Predictions Mean           810.06635
V Predictions Std            194.17552
V Predictions Max            1019.6454
V Predictions Min            250.73491
Log Pis Mean                 -1.140413
Log Pis Std                  2.3267167
Log Pis Max                  5.5854297
Log Pis Min                  -6.5538588
Policy mu Mean               0.08884521
Policy mu Std                0.5571324
Policy mu Max                2.1267245
Policy mu Min                -1.8032532
Policy log std Mean          -0.84809905
Policy log std Std           0.242117
Policy log std Max           -0.2490685
Policy log std Min           -2.0255928
Z mean eval                  0.8827019
Z variance eval              0.03518176
total_rewards                [ -20.32278301  457.82633213 2406.15677411  307.17430733  134.12598829
 1239.55279353 2303.19182458 2427.28333796 1260.96372087  863.35409986]
total_rewards_mean           1137.9306395655633
total_rewards_std            907.2701217009902
total_rewards_max            2427.283337960801
total_rewards_min            -20.322783007888873
Number of train steps total  204000
Number of env steps total    1022000
Number of rollouts total     0
Train Time (s)               26.63246754836291
(Previous) Eval Time (s)     26.4129351307638
Sample Time (s)              18.631400095298886
Epoch Time (s)               71.6768027744256
Total Train Time (s)         14210.291365849786
Epoch                        203
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:12:22.072510 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #203 | Epoch Duration: 67.23780179023743
2020-01-11 07:12:22.072691 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #203 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8829891
Z variance train             0.035297073
KL Divergence                17.860533
KL Loss                      1.7860533
QF Loss                      525.61084
VF Loss                      101.3382
Policy Loss                  -776.6174
Q Predictions Mean           774.32275
Q Predictions Std            211.98941
Q Predictions Max            983.6099
Q Predictions Min            -0.26490688
V Predictions Mean           774.6382
V Predictions Std            208.093
V Predictions Max            984.16815
V Predictions Min            225.53302
Log Pis Mean                 -1.2534204
Log Pis Std                  2.5990665
Log Pis Max                  14.839266
Log Pis Min                  -9.235204
Policy mu Mean               0.03367264
Policy mu Std                0.52562875
Policy mu Max                1.858425
Policy mu Min                -1.9017699
Policy log std Mean          -0.8803842
Policy log std Std           0.30193305
Policy log std Max           -0.2733818
Policy log std Min           -3.553193
Z mean eval                  0.89781487
Z variance eval              0.0312997
total_rewards                [1676.16929247 1225.09604315  193.06945134 2376.31286665 2202.52338983
 1981.01350095 2231.81701117  748.23539425  479.08763023 2292.27946109]
total_rewards_mean           1540.560404113962
total_rewards_std            778.5715197361307
total_rewards_max            2376.3128666519015
total_rewards_min            193.06945133606445
Number of train steps total  205000
Number of env steps total    1027000
Number of rollouts total     0
Train Time (s)               28.79831184912473
(Previous) Eval Time (s)     21.973597540985793
Sample Time (s)              17.92754489928484
Epoch Time (s)               68.69945428939536
Total Train Time (s)         14279.538690280635
Epoch                        204
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:13:31.322487 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #204 | Epoch Duration: 69.24965691566467
2020-01-11 07:13:31.322713 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #204 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8973526
Z variance train             0.031276457
KL Divergence                17.96555
KL Loss                      1.7965549
QF Loss                      403.4271
VF Loss                      151.23807
Policy Loss                  -799.22906
Q Predictions Mean           797.103
Q Predictions Std            200.02907
Q Predictions Max            980.2731
Q Predictions Min            108.248314
V Predictions Mean           798.9917
V Predictions Std            200.9212
V Predictions Max            980.70374
V Predictions Min            24.288494
Log Pis Mean                 -1.2900681
Log Pis Std                  2.6066272
Log Pis Max                  8.370832
Log Pis Min                  -9.744072
Policy mu Mean               0.05669637
Policy mu Std                0.56285024
Policy mu Max                1.789504
Policy mu Min                -1.9620239
Policy log std Mean          -0.83544075
Policy log std Std           0.23489538
Policy log std Max           -0.24632272
Policy log std Min           -1.8458288
Z mean eval                  0.9031631
Z variance eval              0.027595114
total_rewards                [1398.66194004 2213.96704104 1544.30580514  408.81025422 1971.15064587
  318.14562103  706.71734744   54.79309238 2119.95999748  244.42926195]
total_rewards_mean           1098.0941006581154
total_rewards_std            799.6802009604243
total_rewards_max            2213.9670410356875
total_rewards_min            54.79309238208869
Number of train steps total  206000
Number of env steps total    1032000
Number of rollouts total     0
Train Time (s)               30.213288402184844
(Previous) Eval Time (s)     22.52349223801866
Sample Time (s)              17.914285367820412
Epoch Time (s)               70.65106600802392
Total Train Time (s)         14344.83722382877
Epoch                        205
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:14:36.623785 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #205 | Epoch Duration: 65.30090117454529
2020-01-11 07:14:36.623977 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #205 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90321076
Z variance train             0.027547345
KL Divergence                17.391289
KL Loss                      1.739129
QF Loss                      824.23846
VF Loss                      97.69083
Policy Loss                  -807.2435
Q Predictions Mean           804.9173
Q Predictions Std            197.37158
Q Predictions Max            1007.78973
Q Predictions Min            -1.8903414
V Predictions Mean           808.3379
V Predictions Std            198.43568
V Predictions Max            1020.40686
V Predictions Min            0.12350327
Log Pis Mean                 -1.1462691
Log Pis Std                  2.568298
Log Pis Max                  7.062255
Log Pis Min                  -11.070309
Policy mu Mean               0.07177378
Policy mu Std                0.54421866
Policy mu Max                1.7884396
Policy mu Min                -2.2891846
Policy log std Mean          -0.8468722
Policy log std Std           0.24939147
Policy log std Max           -0.16986823
Policy log std Min           -1.9807522
Z mean eval                  0.8762329
Z variance eval              0.036821656
total_rewards                [2050.21116435 1205.41632806 1979.62513498  275.59552874 2237.35177561
 2455.00673181 1859.46104275 1447.275927   1303.44252416  740.76302332]
total_rewards_mean           1555.4149180779766
total_rewards_std            655.0422512354537
total_rewards_max            2455.0067318094684
total_rewards_min            275.5955287383438
Number of train steps total  207000
Number of env steps total    1037000
Number of rollouts total     0
Train Time (s)               28.739350656978786
(Previous) Eval Time (s)     17.17299790820107
Sample Time (s)              18.6428523985669
Epoch Time (s)               64.55520096374676
Total Train Time (s)         14415.044206094462
Epoch                        206
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:15:46.832016 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #206 | Epoch Duration: 70.20790004730225
2020-01-11 07:15:46.832182 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #206 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.87346154
Z variance train             0.036746852
KL Divergence                16.638008
KL Loss                      1.6638008
QF Loss                      617.9413
VF Loss                      289.8471
Policy Loss                  -799.7429
Q Predictions Mean           797.6231
Q Predictions Std            204.34491
Q Predictions Max            1003.3285
Q Predictions Min            218.59396
V Predictions Mean           814.6506
V Predictions Std            204.56708
V Predictions Max            1025.0734
V Predictions Min            234.37273
Log Pis Mean                 -1.4472255
Log Pis Std                  2.7123132
Log Pis Max                  12.335918
Log Pis Min                  -9.073878
Policy mu Mean               0.032146446
Policy mu Std                0.5343999
Policy mu Max                2.0274546
Policy mu Min                -2.5104728
Policy log std Mean          -0.8561432
Policy log std Std           0.24762134
Policy log std Max           -0.35917333
Policy log std Min           -2.0769289
Z mean eval                  0.8851673
Z variance eval              0.020749325
total_rewards                [1911.74988083  686.77878835 2058.74660245 2057.5829502  2065.60582671
 1150.42768075 2107.67467057 2600.86571624 2074.94836731  610.91417373]
total_rewards_mean           1732.5294657126901
total_rewards_std            636.9919552782229
total_rewards_max            2600.865716241743
total_rewards_min            610.9141737289619
Number of train steps total  208000
Number of env steps total    1042000
Number of rollouts total     0
Train Time (s)               26.929682314861566
(Previous) Eval Time (s)     22.8253586278297
Sample Time (s)              17.96392533974722
Epoch Time (s)               67.71896628243849
Total Train Time (s)         14483.41589210229
Epoch                        207
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:16:55.208813 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #207 | Epoch Duration: 68.37647080421448
2020-01-11 07:16:55.209092 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #207 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8849479
Z variance train             0.020743672
KL Divergence                17.629402
KL Loss                      1.7629403
QF Loss                      768.5258
VF Loss                      122.129036
Policy Loss                  -794.5579
Q Predictions Mean           794.1497
Q Predictions Std            207.48384
Q Predictions Max            1033.8372
Q Predictions Min            220.02042
V Predictions Mean           799.1256
V Predictions Std            206.60397
V Predictions Max            1021.6264
V Predictions Min            223.11275
Log Pis Mean                 -1.1558583
Log Pis Std                  2.5831301
Log Pis Max                  7.7282557
Log Pis Min                  -7.8760605
Policy mu Mean               0.11762868
Policy mu Std                0.542327
Policy mu Max                2.2223527
Policy mu Min                -1.6708615
Policy log std Mean          -0.87643206
Policy log std Std           0.2591348
Policy log std Max           -0.251207
Policy log std Min           -2.4027772
Z mean eval                  0.9084314
Z variance eval              0.019732177
total_rewards                [1562.14131051  388.17810116  565.10205288  718.08914061 1489.9329919
    9.51883718  516.35605399  991.10854874   82.80864567  257.01775838]
total_rewards_mean           658.0253441022903
total_rewards_std            513.5963960019877
total_rewards_max            1562.1413105143984
total_rewards_min            9.518837183432671
Number of train steps total  209000
Number of env steps total    1047000
Number of rollouts total     0
Train Time (s)               27.40230122068897
(Previous) Eval Time (s)     23.482582970988005
Sample Time (s)              17.938337035942823
Epoch Time (s)               68.8232212276198
Total Train Time (s)         14546.780740627088
Epoch                        208
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:17:58.577382 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #208 | Epoch Duration: 63.36807584762573
2020-01-11 07:17:58.577614 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #208 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9083842
Z variance train             0.019767616
KL Divergence                18.404278
KL Loss                      1.8404278
QF Loss                      856.37866
VF Loss                      135.41064
Policy Loss                  -787.02264
Q Predictions Mean           783.9774
Q Predictions Std            214.93921
Q Predictions Max            1000.36536
Q Predictions Min            221.67377
V Predictions Mean           782.78467
V Predictions Std            212.78755
V Predictions Max            988.0756
V Predictions Min            233.87428
Log Pis Mean                 -1.2592716
Log Pis Std                  2.6258624
Log Pis Max                  10.243604
Log Pis Min                  -8.943987
Policy mu Mean               0.07771649
Policy mu Std                0.5636447
Policy mu Max                2.134429
Policy mu Min                -1.9341282
Policy log std Mean          -0.8342283
Policy log std Std           0.26306245
Policy log std Max           -0.16484612
Policy log std Min           -2.3455458
Z mean eval                  0.90461886
Z variance eval              0.022450346
total_rewards                [2160.69661773 2339.47802927  138.90879441 2533.36831153  772.16253135
  447.83318548  980.77522443    7.43543659   10.89790437  421.8085942 ]
total_rewards_mean           981.3364629368155
total_rewards_std            942.6352190180471
total_rewards_max            2533.3683115296153
total_rewards_min            7.4354365918411
Number of train steps total  210000
Number of env steps total    1052000
Number of rollouts total     0
Train Time (s)               28.841260695829988
(Previous) Eval Time (s)     18.02712775580585
Sample Time (s)              17.35856654215604
Epoch Time (s)               64.22695499379188
Total Train Time (s)         14611.346849665977
Epoch                        209
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:19:03.144727 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #209 | Epoch Duration: 64.56694340705872
2020-01-11 07:19:03.144921 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #209 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9024445
Z variance train             0.022607824
KL Divergence                18.031265
KL Loss                      1.8031266
QF Loss                      1686.3484
VF Loss                      393.88782
Policy Loss                  -806.0708
Q Predictions Mean           806.12476
Q Predictions Std            203.00731
Q Predictions Max            1011.66394
Q Predictions Min            205.02965
V Predictions Mean           822.8347
V Predictions Std            205.06853
V Predictions Max            1027.5499
V Predictions Min            213.97063
Log Pis Mean                 -1.0069355
Log Pis Std                  2.4699655
Log Pis Max                  5.7573524
Log Pis Min                  -8.752551
Policy mu Mean               0.031035664
Policy mu Std                0.584122
Policy mu Max                1.7856367
Policy mu Min                -1.9904797
Policy log std Mean          -0.8417694
Policy log std Std           0.23779659
Policy log std Max           -0.23152414
Policy log std Min           -2.1534355
Z mean eval                  0.89252186
Z variance eval              0.033848226
total_rewards                [2085.98798239 1887.66943398  261.93982187   22.6137016  1966.42290689
 1819.72810313  305.98611814 1176.07960971  721.98083532  125.07535387]
total_rewards_mean           1037.3483866904246
total_rewards_std            800.922542596365
total_rewards_max            2085.9879823926944
total_rewards_min            22.613701599334508
Number of train steps total  211000
Number of env steps total    1057000
Number of rollouts total     0
Train Time (s)               27.869472796097398
(Previous) Eval Time (s)     18.366830586921424
Sample Time (s)              18.04380439268425
Epoch Time (s)               64.28010777570307
Total Train Time (s)         14675.32212604722
Epoch                        210
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:20:07.121901 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #210 | Epoch Duration: 63.976848125457764
2020-01-11 07:20:07.122100 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #210 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8945365
Z variance train             0.03383287
KL Divergence                17.290298
KL Loss                      1.7290299
QF Loss                      514.4214
VF Loss                      158.9614
Policy Loss                  -788.39233
Q Predictions Mean           789.45337
Q Predictions Std            192.11093
Q Predictions Max            996.03705
Q Predictions Min            25.257902
V Predictions Mean           798.4634
V Predictions Std            192.50197
V Predictions Max            1007.32007
V Predictions Min            42.758213
Log Pis Mean                 -1.3542039
Log Pis Std                  2.6811476
Log Pis Max                  10.149639
Log Pis Min                  -8.144724
Policy mu Mean               0.043736286
Policy mu Std                0.5393474
Policy mu Max                1.9221625
Policy mu Min                -1.9893032
Policy log std Mean          -0.8561361
Policy log std Std           0.24776016
Policy log std Max           -0.27879536
Policy log std Min           -2.4199133
Z mean eval                  0.88714886
Z variance eval              0.031584736
total_rewards                [2369.9480596   141.37491813 2521.04420094 1239.30584679 1995.56970279
 2504.91331114 2353.87333408 1352.10588926 2361.52359593 2381.68692555]
total_rewards_mean           1922.1345784221025
total_rewards_std            738.7283391885023
total_rewards_max            2521.044200939252
total_rewards_min            141.37491812982532
Number of train steps total  212000
Number of env steps total    1062000
Number of rollouts total     0
Train Time (s)               29.67068298580125
(Previous) Eval Time (s)     18.06321822386235
Sample Time (s)              17.782120381481946
Epoch Time (s)               65.51602159114555
Total Train Time (s)         14747.84284120053
Epoch                        211
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:21:19.648008 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #211 | Epoch Duration: 72.52572536468506
2020-01-11 07:21:19.648340 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #211 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8869726
Z variance train             0.031611077
KL Divergence                17.483042
KL Loss                      1.7483042
QF Loss                      537.842
VF Loss                      126.03917
Policy Loss                  -789.8076
Q Predictions Mean           787.5867
Q Predictions Std            211.8005
Q Predictions Max            1008.1305
Q Predictions Min            37.188503
V Predictions Mean           788.3047
V Predictions Std            213.99661
V Predictions Max            1021.5934
V Predictions Min            -2.1434934
Log Pis Mean                 -1.0111163
Log Pis Std                  2.4170465
Log Pis Max                  7.0783777
Log Pis Min                  -7.11218
Policy mu Mean               0.010273598
Policy mu Std                0.5404193
Policy mu Max                1.916156
Policy mu Min                -1.8778374
Policy log std Mean          -0.86662674
Policy log std Std           0.2603531
Policy log std Max           -0.29046428
Policy log std Min           -2.3661375
Z mean eval                  0.89198035
Z variance eval              0.036585145
total_rewards                [   5.40751882 1920.14238846 2298.41954277  428.13158812 2286.08033446
 1236.77283535 2407.84179934  889.98879787  745.9758606  2489.73738971]
total_rewards_mean           1470.849805548992
total_rewards_std            872.9168555402147
total_rewards_max            2489.737389711995
total_rewards_min            5.407518816512831
Number of train steps total  213000
Number of env steps total    1067000
Number of rollouts total     0
Train Time (s)               26.6726816999726
(Previous) Eval Time (s)     25.072553584352136
Sample Time (s)              18.100710086524487
Epoch Time (s)               69.84594537084922
Total Train Time (s)         14815.12896725582
Epoch                        212
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:22:26.936237 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #212 | Epoch Duration: 67.28766989707947
2020-01-11 07:22:26.936456 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #212 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8947116
Z variance train             0.0362212
KL Divergence                17.471848
KL Loss                      1.7471848
QF Loss                      1759.3068
VF Loss                      116.052315
Policy Loss                  -832.3073
Q Predictions Mean           825.8048
Q Predictions Std            184.92119
Q Predictions Max            1006.59357
Q Predictions Min            1.7569026
V Predictions Mean           831.1207
V Predictions Std            181.17007
V Predictions Max            1007.264
V Predictions Min            95.754524
Log Pis Mean                 -0.8394961
Log Pis Std                  2.2123382
Log Pis Max                  6.7734795
Log Pis Min                  -6.8441286
Policy mu Mean               0.08837642
Policy mu Std                0.5497942
Policy mu Max                1.9524139
Policy mu Min                -1.7903124
Policy log std Mean          -0.8781552
Policy log std Std           0.2632846
Policy log std Max           -0.2673131
Policy log std Min           -2.164072
Z mean eval                  0.90413535
Z variance eval              0.018557696
total_rewards                [ 381.33556978  820.85933058  675.81176601 2290.58301071  693.56277151
 1638.3997565  1844.29456608  498.88719272  376.99002825  535.66904669]
total_rewards_mean           975.6393038827715
total_rewards_std            651.8247604409669
total_rewards_max            2290.5830107133224
total_rewards_min            376.9900282491399
Number of train steps total  214000
Number of env steps total    1072000
Number of rollouts total     0
Train Time (s)               30.140503004658967
(Previous) Eval Time (s)     22.513982620090246
Sample Time (s)              17.681880647782236
Epoch Time (s)               70.33636627253145
Total Train Time (s)         14881.749787615146
Epoch                        213
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:23:33.561474 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #213 | Epoch Duration: 66.62481880187988
2020-01-11 07:23:33.561785 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #213 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90347767
Z variance train             0.018531341
KL Divergence                18.626493
KL Loss                      1.8626493
QF Loss                      568.1511
VF Loss                      61.84188
Policy Loss                  -787.95917
Q Predictions Mean           786.8675
Q Predictions Std            227.66776
Q Predictions Max            1028.5934
Q Predictions Min            212.26985
V Predictions Mean           790.08875
V Predictions Std            225.0276
V Predictions Max            1028.7299
V Predictions Min            225.65405
Log Pis Mean                 -1.23243
Log Pis Std                  2.3765402
Log Pis Max                  5.7190523
Log Pis Min                  -12.600009
Policy mu Mean               0.083908126
Policy mu Std                0.5547246
Policy mu Max                2.013625
Policy mu Min                -1.6895576
Policy log std Mean          -0.8259723
Policy log std Std           0.23702359
Policy log std Max           -0.12667763
Policy log std Min           -1.8341922
Z mean eval                  0.8973285
Z variance eval              0.035978705
total_rewards                [ 227.62468239 2260.18836328 2594.89207597  818.01420189 1300.96147514
   56.86542161 2594.33029878  141.03938536  101.73306241 1163.0013587 ]
total_rewards_mean           1125.8650325537371
total_rewards_std            984.6955802894042
total_rewards_max            2594.892075970778
total_rewards_min            56.86542161068731
Number of train steps total  215000
Number of env steps total    1077000
Number of rollouts total     0
Train Time (s)               28.63473399821669
(Previous) Eval Time (s)     18.802097885869443
Sample Time (s)              17.973972861655056
Epoch Time (s)               65.41080474574119
Total Train Time (s)         14943.86301723402
Epoch                        214
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:24:35.677117 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #214 | Epoch Duration: 62.11510491371155
2020-01-11 07:24:35.677339 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #214 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89784926
Z variance train             0.036065355
KL Divergence                17.290255
KL Loss                      1.7290255
QF Loss                      635.154
VF Loss                      139.5032
Policy Loss                  -788.28674
Q Predictions Mean           787.8086
Q Predictions Std            201.69826
Q Predictions Max            991.06274
Q Predictions Min            186.92863
V Predictions Mean           793.558
V Predictions Std            201.04147
V Predictions Max            998.8019
V Predictions Min            193.23799
Log Pis Mean                 -0.83330435
Log Pis Std                  2.650124
Log Pis Max                  6.5685263
Log Pis Min                  -9.885757
Policy mu Mean               0.04184378
Policy mu Std                0.5751649
Policy mu Max                2.047103
Policy mu Min                -2.0661225
Policy log std Mean          -0.8615378
Policy log std Std           0.25581637
Policy log std Max           -0.22651112
Policy log std Min           -2.0573723
Z mean eval                  0.9392789
Z variance eval              0.029702146
total_rewards                [ 530.38865555 1791.365245    961.65742118 1198.43919199  613.53996382
  303.97210199 2503.62106763 2521.7401443  1078.49201175  796.3883729 ]
total_rewards_mean           1229.9604176118673
total_rewards_std            749.4543589963122
total_rewards_max            2521.740144303598
total_rewards_min            303.972101989894
Number of train steps total  216000
Number of env steps total    1082000
Number of rollouts total     0
Train Time (s)               27.96670295810327
(Previous) Eval Time (s)     15.506105312146246
Sample Time (s)              17.84178548352793
Epoch Time (s)               61.314593753777444
Total Train Time (s)         15005.942031174432
Epoch                        215
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:25:37.759182 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #215 | Epoch Duration: 62.081666231155396
2020-01-11 07:25:37.759384 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #215 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9393878
Z variance train             0.029693102
KL Divergence                17.859283
KL Loss                      1.7859284
QF Loss                      1361.7339
VF Loss                      242.82521
Policy Loss                  -847.44495
Q Predictions Mean           844.21484
Q Predictions Std            170.06021
Q Predictions Max            1035.6644
Q Predictions Min            222.5475
V Predictions Mean           848.3185
V Predictions Std            170.17303
V Predictions Max            1035.3434
V Predictions Min            222.15816
Log Pis Mean                 -1.0354838
Log Pis Std                  2.6122646
Log Pis Max                  12.907438
Log Pis Min                  -6.3273125
Policy mu Mean               0.0069793668
Policy mu Std                0.55884165
Policy mu Max                2.2465382
Policy mu Min                -2.0521688
Policy log std Mean          -0.84710485
Policy log std Std           0.24445076
Policy log std Max           -0.25978154
Policy log std Min           -2.762173
Z mean eval                  0.92467225
Z variance eval              0.024528122
total_rewards                [2418.9830316  1137.74539539  768.8388211  1637.231412    495.1942294
 1376.47833956  365.90274791 2334.728472    746.59145216  708.791052  ]
total_rewards_mean           1199.0484953097534
total_rewards_std            694.6182933748029
total_rewards_max            2418.9830315969702
total_rewards_min            365.9027479077893
Number of train steps total  217000
Number of env steps total    1087000
Number of rollouts total     0
Train Time (s)               27.764920444227755
(Previous) Eval Time (s)     16.272896519862115
Sample Time (s)              17.893636564724147
Epoch Time (s)               61.93145352881402
Total Train Time (s)         15071.82841291232
Epoch                        216
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:26:43.647410 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #216 | Epoch Duration: 65.88787865638733
2020-01-11 07:26:43.647608 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #216 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92642146
Z variance train             0.024475481
KL Divergence                18.345163
KL Loss                      1.8345164
QF Loss                      1071.9058
VF Loss                      62.374092
Policy Loss                  -809.4266
Q Predictions Mean           809.1603
Q Predictions Std            215.13521
Q Predictions Max            1008.23773
Q Predictions Min            -5.658721
V Predictions Mean           810.6455
V Predictions Std            215.60829
V Predictions Max            995.2769
V Predictions Min            8.625889
Log Pis Mean                 -1.2813556
Log Pis Std                  2.3102703
Log Pis Max                  6.7366915
Log Pis Min                  -8.328246
Policy mu Mean               0.07403428
Policy mu Std                0.5401834
Policy mu Max                1.9165871
Policy mu Min                -1.9018227
Policy log std Mean          -0.8652717
Policy log std Std           0.24876621
Policy log std Max           -0.16493535
Policy log std Min           -2.1409082
Z mean eval                  0.8957459
Z variance eval              0.018374834
total_rewards                [2460.28124683 1082.09644498  931.49396531  382.5236999    66.13985549
  565.05657017  159.02066319  878.64247496 2124.11239767 1832.8710142 ]
total_rewards_mean           1048.2238332700042
total_rewards_std            790.0900633804579
total_rewards_max            2460.2812468348807
total_rewards_min            66.13985548944619
Number of train steps total  218000
Number of env steps total    1092000
Number of rollouts total     0
Train Time (s)               28.12252569012344
(Previous) Eval Time (s)     20.22901846189052
Sample Time (s)              17.89639313099906
Epoch Time (s)               66.24793728301302
Total Train Time (s)         15136.424479247537
Epoch                        217
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:27:48.247664 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #217 | Epoch Duration: 64.59987902641296
2020-01-11 07:27:48.247971 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #217 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8968312
Z variance train             0.01834917
KL Divergence                18.426125
KL Loss                      1.8426125
QF Loss                      950.63074
VF Loss                      178.8994
Policy Loss                  -816.6303
Q Predictions Mean           814.5304
Q Predictions Std            193.53888
Q Predictions Max            1026.563
Q Predictions Min            207.51018
V Predictions Mean           820.20764
V Predictions Std            190.26506
V Predictions Max            1029.8453
V Predictions Min            214.78523
Log Pis Mean                 -0.96770394
Log Pis Std                  2.434821
Log Pis Max                  8.236074
Log Pis Min                  -7.3010635
Policy mu Mean               0.06371875
Policy mu Std                0.5381957
Policy mu Max                2.472687
Policy mu Min                -1.7068977
Policy log std Mean          -0.87762904
Policy log std Std           0.27998847
Policy log std Max           -0.27224267
Policy log std Min           -2.5690274
Z mean eval                  0.9060708
Z variance eval              0.021648325
total_rewards                [2222.67593643 1491.31154983 1809.54299589 2363.1495623   669.84168996
 2364.19343261  178.27542078  499.46796152  462.10593922 2454.7994412 ]
total_rewards_mean           1451.5363929723646
total_rewards_std            866.750956489586
total_rewards_max            2454.7994411977375
total_rewards_min            178.2754207816086
Number of train steps total  219000
Number of env steps total    1097000
Number of rollouts total     0
Train Time (s)               26.688435908872634
(Previous) Eval Time (s)     18.58064903272316
Sample Time (s)              17.816187313757837
Epoch Time (s)               63.08527225535363
Total Train Time (s)         15205.229816776235
Epoch                        218
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:28:57.053754 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #218 | Epoch Duration: 68.8055830001831
2020-01-11 07:28:57.053907 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #218 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9068383
Z variance train             0.021685498
KL Divergence                18.07195
KL Loss                      1.8071951
QF Loss                      494.04956
VF Loss                      405.53973
Policy Loss                  -856.5457
Q Predictions Mean           852.7414
Q Predictions Std            194.58252
Q Predictions Max            1071.4625
Q Predictions Min            -27.493866
V Predictions Mean           838.56445
V Predictions Std            191.67322
V Predictions Max            1052.7864
V Predictions Min            -11.763226
Log Pis Mean                 -1.0623286
Log Pis Std                  2.1935651
Log Pis Max                  7.2935386
Log Pis Min                  -6.5441465
Policy mu Mean               0.09327859
Policy mu Std                0.53720707
Policy mu Max                2.1664755
Policy mu Min                -1.6611142
Policy log std Mean          -0.8879358
Policy log std Std           0.24512666
Policy log std Max           -0.07132316
Policy log std Min           -2.1211004
Z mean eval                  0.91414595
Z variance eval              0.026000211
total_rewards                [ 383.17166711   27.14714813 2009.83596025  291.10781858 1511.59444373
 1402.23308006 1182.92671367 2376.39393521 2035.33190197 1398.9627284 ]
total_rewards_mean           1261.8705397113931
total_rewards_std            758.0224955994016
total_rewards_max            2376.393935214166
total_rewards_min            27.147148134258835
Number of train steps total  220000
Number of env steps total    1102000
Number of rollouts total     0
Train Time (s)               26.771545572206378
(Previous) Eval Time (s)     24.300636899191886
Sample Time (s)              18.84773922059685
Epoch Time (s)               69.91992169199511
Total Train Time (s)         15277.303198188078
Epoch                        219
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:30:09.132281 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #219 | Epoch Duration: 72.07821106910706
2020-01-11 07:30:09.132586 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #219 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9139678
Z variance train             0.025973916
KL Divergence                17.425251
KL Loss                      1.7425251
QF Loss                      2751.239
VF Loss                      78.38382
Policy Loss                  -825.1565
Q Predictions Mean           821.9261
Q Predictions Std            233.43355
Q Predictions Max            1058.0006
Q Predictions Min            5.8307695
V Predictions Mean           827.43445
V Predictions Std            229.88484
V Predictions Max            1057.906
V Predictions Min            208.62733
Log Pis Mean                 -1.0683224
Log Pis Std                  2.6198132
Log Pis Max                  10.490007
Log Pis Min                  -7.219631
Policy mu Mean               -0.012612167
Policy mu Std                0.52553385
Policy mu Max                2.1058424
Policy mu Min                -2.1959448
Policy log std Mean          -0.8637483
Policy log std Std           0.29057425
Policy log std Max           -0.16861534
Policy log std Min           -2.4656043
Z mean eval                  0.9270501
Z variance eval              0.03876052
total_rewards                [1763.8815406   132.29180934  289.16075986 2431.29644905 2493.10053618
 1361.53759402 2390.06924898   33.05706674 2282.10112811 2005.72229954]
total_rewards_mean           1518.2218432433342
total_rewards_std            953.2778250400548
total_rewards_max            2493.100536183139
total_rewards_min            33.05706674037029
Number of train steps total  221000
Number of env steps total    1107000
Number of rollouts total     0
Train Time (s)               28.653937176335603
(Previous) Eval Time (s)     26.45857953513041
Sample Time (s)              17.938303749077022
Epoch Time (s)               73.05082046054304
Total Train Time (s)         15342.067889573518
Epoch                        220
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:31:13.898211 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #220 | Epoch Duration: 64.76540756225586
2020-01-11 07:31:13.898415 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #220 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9281769
Z variance train             0.038834848
KL Divergence                17.203314
KL Loss                      1.7203314
QF Loss                      550.9136
VF Loss                      70.49881
Policy Loss                  -794.78705
Q Predictions Mean           791.4546
Q Predictions Std            237.48991
Q Predictions Max            1029.5773
Q Predictions Min            27.317963
V Predictions Mean           794.3877
V Predictions Std            234.74466
V Predictions Max            1027.4131
V Predictions Min            121.32347
Log Pis Mean                 -1.3199965
Log Pis Std                  2.7774656
Log Pis Max                  12.639208
Log Pis Min                  -8.847277
Policy mu Mean               0.04751617
Policy mu Std                0.54268557
Policy mu Max                2.0173116
Policy mu Min                -2.4470263
Policy log std Mean          -0.8635516
Policy log std Std           0.30446765
Policy log std Max           -0.16584808
Policy log std Min           -2.9638443
Z mean eval                  0.9094385
Z variance eval              0.03164023
total_rewards                [2238.52087907 2296.61835269 1228.1168675   236.7110324  2366.73228179
 1609.43693567  714.8597745   205.52707998  555.11343965 2458.3081025 ]
total_rewards_mean           1390.9944745750875
total_rewards_std            871.6354130665395
total_rewards_max            2458.3081025003835
total_rewards_min            205.5270799845606
Number of train steps total  222000
Number of env steps total    1112000
Number of rollouts total     0
Train Time (s)               27.808329130988568
(Previous) Eval Time (s)     18.172865212894976
Sample Time (s)              17.584256776608527
Epoch Time (s)               63.56545112049207
Total Train Time (s)         15406.177709036972
Epoch                        221
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:32:18.013534 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #221 | Epoch Duration: 64.11495161056519
2020-01-11 07:32:18.013819 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #221 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9091095
Z variance train             0.031555254
KL Divergence                17.029755
KL Loss                      1.7029755
QF Loss                      671.249
VF Loss                      96.49398
Policy Loss                  -819.93524
Q Predictions Mean           814.40857
Q Predictions Std            210.31802
Q Predictions Max            1022.6197
Q Predictions Min            7.084676
V Predictions Mean           821.4592
V Predictions Std            208.98848
V Predictions Max            1020.3874
V Predictions Min            0.4064145
Log Pis Mean                 -0.96458167
Log Pis Std                  2.7318428
Log Pis Max                  11.568736
Log Pis Min                  -9.027813
Policy mu Mean               0.008153314
Policy mu Std                0.58859175
Policy mu Max                2.363624
Policy mu Min                -3.0434442
Policy log std Mean          -0.8632195
Policy log std Std           0.2691812
Policy log std Max           -0.01478982
Policy log std Min           -2.1242082
Z mean eval                  0.91746825
Z variance eval              0.039557457
total_rewards                [1567.28951741 1864.49127715 2399.15086927 2519.24044955 2356.26899794
 2149.42709319 1702.77152299   45.52410238  -67.44517553 2270.87478848]
total_rewards_mean           1680.7593442830864
total_rewards_std            895.5817458955551
total_rewards_max            2519.2404495464502
total_rewards_min            -67.44517552761985
Number of train steps total  223000
Number of env steps total    1117000
Number of rollouts total     0
Train Time (s)               28.235947703011334
(Previous) Eval Time (s)     18.722053282894194
Sample Time (s)              17.824303622357547
Epoch Time (s)               64.78230460826308
Total Train Time (s)         15478.359337669332
Epoch                        222
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:33:30.198334 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #222 | Epoch Duration: 72.18428659439087
2020-01-11 07:33:30.198582 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #222 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9184491
Z variance train             0.039501064
KL Divergence                17.255842
KL Loss                      1.7255843
QF Loss                      576.1752
VF Loss                      341.14944
Policy Loss                  -827.44635
Q Predictions Mean           821.38403
Q Predictions Std            217.59818
Q Predictions Max            1056.7068
Q Predictions Min            21.999746
V Predictions Mean           832.6506
V Predictions Std            211.61577
V Predictions Max            1056.3374
V Predictions Min            214.95676
Log Pis Mean                 -0.87287736
Log Pis Std                  2.754186
Log Pis Max                  6.7591324
Log Pis Min                  -7.895851
Policy mu Mean               0.0061069583
Policy mu Std                0.5619878
Policy mu Max                2.895223
Policy mu Min                -1.8646858
Policy log std Mean          -0.8649121
Policy log std Std           0.28139427
Policy log std Max           -0.21048516
Policy log std Min           -2.4031897
Z mean eval                  0.9377812
Z variance eval              0.024368484
total_rewards                [ 136.56125837  217.34120147  384.01488422  234.746271   2237.09391652
  338.14167251 1235.3972916  1229.64441655  614.53607139  304.01136536]
total_rewards_mean           693.1488349001845
total_rewards_std            639.6205656116102
total_rewards_max            2237.0939165197397
total_rewards_min            136.56125837218107
Number of train steps total  224000
Number of env steps total    1122000
Number of rollouts total     0
Train Time (s)               29.412406876683235
(Previous) Eval Time (s)     26.123737435322255
Sample Time (s)              18.456664081197232
Epoch Time (s)               73.99280839320272
Total Train Time (s)         15545.289501605555
Epoch                        223
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:34:37.129848 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #223 | Epoch Duration: 66.93108749389648
2020-01-11 07:34:37.130052 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #223 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93749046
Z variance train             0.024322769
KL Divergence                17.935135
KL Loss                      1.7935135
QF Loss                      413.14978
VF Loss                      78.57461
Policy Loss                  -840.55566
Q Predictions Mean           837.4485
Q Predictions Std            210.48456
Q Predictions Max            1075.3888
Q Predictions Min            198.44936
V Predictions Mean           842.53406
V Predictions Std            209.02586
V Predictions Max            1080.1627
V Predictions Min            221.34961
Log Pis Mean                 -1.1271112
Log Pis Std                  2.6177485
Log Pis Max                  9.421644
Log Pis Min                  -9.662814
Policy mu Mean               0.01176643
Policy mu Std                0.5727739
Policy mu Max                2.2183883
Policy mu Min                -2.865027
Policy log std Mean          -0.8589066
Policy log std Std           0.24825938
Policy log std Max           -0.27027333
Policy log std Min           -1.8763418
Z mean eval                  0.9136569
Z variance eval              0.021621902
total_rewards                [1967.37334416 1635.82432602 1183.82670483  366.23769795 1374.26606089
 1610.85584899   70.85212182   69.81080101  283.771744    437.79841369]
total_rewards_mean           900.0617063363783
total_rewards_std            688.9481304440313
total_rewards_max            1967.373344162491
total_rewards_min            69.81080101483357
Number of train steps total  225000
Number of env steps total    1127000
Number of rollouts total     0
Train Time (s)               29.149119480978698
(Previous) Eval Time (s)     19.061650540214032
Sample Time (s)              18.029907611198723
Epoch Time (s)               66.24067763239145
Total Train Time (s)         15606.506213911343
Epoch                        224
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:35:38.352558 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #224 | Epoch Duration: 61.22230815887451
2020-01-11 07:35:38.352916 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #224 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91369456
Z variance train             0.021674167
KL Divergence                18.814661
KL Loss                      1.8814662
QF Loss                      971.2253
VF Loss                      79.558205
Policy Loss                  -839.0036
Q Predictions Mean           837.39075
Q Predictions Std            212.42094
Q Predictions Max            1044.7859
Q Predictions Min            215.71754
V Predictions Mean           834.9824
V Predictions Std            210.67114
V Predictions Max            1036.7474
V Predictions Min            214.86694
Log Pis Mean                 -0.8280182
Log Pis Std                  2.5967412
Log Pis Max                  8.388755
Log Pis Min                  -8.087148
Policy mu Mean               0.027600214
Policy mu Std                0.57143384
Policy mu Max                2.04182
Policy mu Min                -2.2770827
Policy log std Mean          -0.8697031
Policy log std Std           0.2547841
Policy log std Max           -0.25721276
Policy log std Min           -1.856753
Z mean eval                  0.9252744
Z variance eval              0.020353753
total_rewards                [2548.44179607 2479.65712515 2617.37575136 2386.70191591  898.53074114
 2624.33201496  637.18303835  299.74755635 2327.43908462 1946.9968275 ]
total_rewards_mean           1876.640585139877
total_rewards_std            858.5193198646183
total_rewards_max            2624.3320149604087
total_rewards_min            299.74755635482654
Number of train steps total  226000
Number of env steps total    1132000
Number of rollouts total     0
Train Time (s)               28.49449265189469
(Previous) Eval Time (s)     14.042975133284926
Sample Time (s)              17.6553426948376
Epoch Time (s)               60.192810480017215
Total Train Time (s)         15675.953453442082
Epoch                        225
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:36:47.801562 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #225 | Epoch Duration: 69.4483995437622
2020-01-11 07:36:47.801810 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #225 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92705756
Z variance train             0.020275984
KL Divergence                18.776077
KL Loss                      1.8776077
QF Loss                      1619.238
VF Loss                      290.6661
Policy Loss                  -854.2941
Q Predictions Mean           847.57947
Q Predictions Std            206.76564
Q Predictions Max            1066.149
Q Predictions Min            182.9307
V Predictions Mean           840.65796
V Predictions Std            204.25488
V Predictions Max            1059.8483
V Predictions Min            188.4418
Log Pis Mean                 -0.57301825
Log Pis Std                  2.6486452
Log Pis Max                  13.022369
Log Pis Min                  -8.275018
Policy mu Mean               -0.01336365
Policy mu Std                0.5733943
Policy mu Max                2.1299152
Policy mu Min                -2.025824
Policy log std Mean          -0.8901856
Policy log std Std           0.26033682
Policy log std Max           -0.15134126
Policy log std Min           -2.1268198
Z mean eval                  0.981654
Z variance eval              0.023398394
total_rewards                [2053.06612156  237.91860566  901.31203928 -115.88443666 2559.34473596
  532.7291043   392.17336859 2434.59525874 2401.69982764  757.83325865]
total_rewards_mean           1215.4787883728434
total_rewards_std            978.8342361399658
total_rewards_max            2559.3447359629267
total_rewards_min            -115.884436662653
Number of train steps total  227000
Number of env steps total    1137000
Number of rollouts total     0
Train Time (s)               30.020164217799902
(Previous) Eval Time (s)     23.29830720881
Sample Time (s)              17.94073812616989
Epoch Time (s)               71.2592095527798
Total Train Time (s)         15748.43804164324
Epoch                        226
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:38:00.287572 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #226 | Epoch Duration: 72.48560118675232
2020-01-11 07:38:00.287755 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #226 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98162186
Z variance train             0.023420507
KL Divergence                18.673647
KL Loss                      1.8673648
QF Loss                      450.99048
VF Loss                      102.48361
Policy Loss                  -842.3549
Q Predictions Mean           841.5033
Q Predictions Std            225.27696
Q Predictions Max            1063.1108
Q Predictions Min            219.432
V Predictions Mean           848.22424
V Predictions Std            224.8701
V Predictions Max            1063.0592
V Predictions Min            236.44518
Log Pis Mean                 -1.5547327
Log Pis Std                  2.4192765
Log Pis Max                  8.002946
Log Pis Min                  -7.2453756
Policy mu Mean               0.061014
Policy mu Std                0.5286211
Policy mu Max                1.7970911
Policy mu Min                -2.6620095
Policy log std Mean          -0.84574693
Policy log std Std           0.23530088
Policy log std Max           -0.2513343
Policy log std Min           -2.0481844
Z mean eval                  0.92845076
Z variance eval              0.03262732
total_rewards                [  47.19171256 1290.41563226 1834.51189383  673.45081675  338.22792081
 1904.51635267  351.93395575 2391.70152913  121.2325556    92.33261909]
total_rewards_mean           904.5514988460945
total_rewards_std            831.4524842108991
total_rewards_max            2391.701529130529
total_rewards_min            47.19171256383579
Number of train steps total  228000
Number of env steps total    1142000
Number of rollouts total     0
Train Time (s)               29.062598083168268
(Previous) Eval Time (s)     24.524388436693698
Sample Time (s)              18.643157300539315
Epoch Time (s)               72.23014382040128
Total Train Time (s)         15815.686804668047
Epoch                        227
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:39:07.542239 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #227 | Epoch Duration: 67.25430989265442
2020-01-11 07:39:07.542484 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #227 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9250368
Z variance train             0.032602843
KL Divergence                18.034376
KL Loss                      1.8034376
QF Loss                      2709.16
VF Loss                      250.66768
Policy Loss                  -842.9089
Q Predictions Mean           839.8943
Q Predictions Std            227.44241
Q Predictions Max            1079.2368
Q Predictions Min            175.62207
V Predictions Mean           841.7057
V Predictions Std            226.13388
V Predictions Max            1077.7185
V Predictions Min            168.42834
Log Pis Mean                 -0.8948122
Log Pis Std                  2.5300004
Log Pis Max                  10.768778
Log Pis Min                  -7.7116895
Policy mu Mean               0.0028438005
Policy mu Std                0.5550159
Policy mu Max                2.8535564
Policy mu Min                -2.002683
Policy log std Mean          -0.89320934
Policy log std Std           0.28551954
Policy log std Max           -0.29363543
Policy log std Min           -2.692379
Z mean eval                  0.91205835
Z variance eval              0.022687811
total_rewards                [2379.94772056 1205.57668326 2354.02200233 2478.54120502  610.08127508
 2356.03049641 2329.7098148  2755.0543595   133.40943484 2619.28443759]
total_rewards_mean           1922.1657429387888
total_rewards_std            876.0331729152709
total_rewards_max            2755.0543595024074
total_rewards_min            133.40943483973234
Number of train steps total  229000
Number of env steps total    1147000
Number of rollouts total     0
Train Time (s)               27.832549849990755
(Previous) Eval Time (s)     19.548228680621833
Sample Time (s)              17.930450518149883
Epoch Time (s)               65.31122904876247
Total Train Time (s)         15886.237439440563
Epoch                        228
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:40:18.094293 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #228 | Epoch Duration: 70.5516152381897
2020-01-11 07:40:18.094506 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #228 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91019475
Z variance train             0.022694202
KL Divergence                18.06128
KL Loss                      1.8061279
QF Loss                      2013.354
VF Loss                      248.75926
Policy Loss                  -858.71405
Q Predictions Mean           856.98816
Q Predictions Std            206.52283
Q Predictions Max            1072.3768
Q Predictions Min            153.83926
V Predictions Mean           867.09735
V Predictions Std            204.93277
V Predictions Max            1074.5107
V Predictions Min            29.666124
Log Pis Mean                 -0.7039119
Log Pis Std                  2.6992962
Log Pis Max                  12.091978
Log Pis Min                  -10.46785
Policy mu Mean               0.001063617
Policy mu Std                0.5560648
Policy mu Max                2.025539
Policy mu Min                -3.1367114
Policy log std Mean          -0.9100698
Policy log std Std           0.25699154
Policy log std Max           -0.16548389
Policy log std Min           -2.0650413
Z mean eval                  0.9203684
Z variance eval              0.027721401
total_rewards                [2562.63906623 1033.13131059  538.06881697 1588.82742082 2351.41257206
 2658.92404091 2660.53614542 2290.12675259 1239.23996176  556.75176959]
total_rewards_mean           1747.965785694066
total_rewards_std            816.2331476492619
total_rewards_max            2660.536145422041
total_rewards_min            538.0688169710055
Number of train steps total  230000
Number of env steps total    1152000
Number of rollouts total     0
Train Time (s)               29.800752037670463
(Previous) Eval Time (s)     24.7883133739233
Sample Time (s)              17.509353656787425
Epoch Time (s)               72.09841906838119
Total Train Time (s)         15952.60121538397
Epoch                        229
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:41:24.463964 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #229 | Epoch Duration: 66.36925101280212
2020-01-11 07:41:24.464256 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #229 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91989976
Z variance train             0.027716005
KL Divergence                18.033333
KL Loss                      1.8033333
QF Loss                      816.5305
VF Loss                      137.99306
Policy Loss                  -898.3069
Q Predictions Mean           897.17993
Q Predictions Std            169.05388
Q Predictions Max            1105.1049
Q Predictions Min            215.50974
V Predictions Mean           890.7461
V Predictions Std            167.625
V Predictions Max            1096.3989
V Predictions Min            214.943
Log Pis Mean                 -0.95398754
Log Pis Std                  2.6050642
Log Pis Max                  5.406732
Log Pis Min                  -9.362825
Policy mu Mean               -0.021483228
Policy mu Std                0.5608888
Policy mu Max                1.7009593
Policy mu Min                -1.7945235
Policy log std Mean          -0.88994515
Policy log std Std           0.23671593
Policy log std Max           -0.27770928
Policy log std Min           -1.801943
Z mean eval                  0.923089
Z variance eval              0.033486355
total_rewards                [2456.52748702 1592.00973415 2599.43455085 2440.37147677 2232.23413693
   74.21418933 2440.13234233 2494.39399912  138.30978998  309.95320689]
total_rewards_mean           1677.7580913358192
total_rewards_std            1020.4213803039936
total_rewards_max            2599.434550853751
total_rewards_min            74.21418933244863
Number of train steps total  231000
Number of env steps total    1157000
Number of rollouts total     0
Train Time (s)               28.170271749142557
(Previous) Eval Time (s)     19.05885041691363
Sample Time (s)              19.11378706758842
Epoch Time (s)               66.3429092336446
Total Train Time (s)         16019.805853934027
Epoch                        230
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:42:31.669146 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #230 | Epoch Duration: 67.20465302467346
2020-01-11 07:42:31.669338 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #230 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92314684
Z variance train             0.03350187
KL Divergence                18.132278
KL Loss                      1.8132279
QF Loss                      2694.8228
VF Loss                      151.33786
Policy Loss                  -850.9246
Q Predictions Mean           846.3528
Q Predictions Std            207.17007
Q Predictions Max            1063.4609
Q Predictions Min            93.68702
V Predictions Mean           852.8944
V Predictions Std            203.22891
V Predictions Max            1067.0903
V Predictions Min            212.91208
Log Pis Mean                 -1.0755652
Log Pis Std                  2.793683
Log Pis Max                  11.046738
Log Pis Min                  -12.295298
Policy mu Mean               0.047238827
Policy mu Std                0.5618612
Policy mu Max                2.0302832
Policy mu Min                -2.4063277
Policy log std Mean          -0.87856567
Policy log std Std           0.26683146
Policy log std Max           -0.21510988
Policy log std Min           -2.3919735
Z mean eval                  0.94813406
Z variance eval              0.025260508
total_rewards                [2453.07416568 2533.17967925 2568.70007881 2116.60023387 2116.19402886
 1259.70959882 2047.85862502 2140.52883897 2499.68365731 2715.6911649 ]
total_rewards_mean           2245.1220071499065
total_rewards_std            396.38258212753834
total_rewards_max            2715.6911649023655
total_rewards_min            1259.7095988244673
Number of train steps total  232000
Number of env steps total    1162000
Number of rollouts total     0
Train Time (s)               27.31170838791877
(Previous) Eval Time (s)     19.920290583744645
Sample Time (s)              18.586598872672766
Epoch Time (s)               65.81859784433618
Total Train Time (s)         16090.204400309362
Epoch                        231
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:43:42.071330 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #231 | Epoch Duration: 70.4018383026123
2020-01-11 07:43:42.071551 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #231 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9487171
Z variance train             0.025373623
KL Divergence                19.433857
KL Loss                      1.9433857
QF Loss                      561.36487
VF Loss                      193.94096
Policy Loss                  -855.43463
Q Predictions Mean           854.9358
Q Predictions Std            213.34668
Q Predictions Max            1075.6041
Q Predictions Min            221.63835
V Predictions Mean           860.71106
V Predictions Std            213.40805
V Predictions Max            1071.6904
V Predictions Min            216.09567
Log Pis Mean                 -0.79476994
Log Pis Std                  2.4518855
Log Pis Max                  8.317295
Log Pis Min                  -9.8723545
Policy mu Mean               0.05016307
Policy mu Std                0.54279256
Policy mu Max                1.9017622
Policy mu Min                -2.3266168
Policy log std Mean          -0.90368354
Policy log std Std           0.25619972
Policy log std Max           -0.11162126
Policy log std Min           -2.153827
Z mean eval                  0.94387037
Z variance eval              0.027456308
total_rewards                [ 466.53516618  110.21934179 2504.84609365 2460.75030651 2090.31579784
 2196.97435727 2537.48825308 2371.4159792  2509.175921   2517.28193208]
total_rewards_mean           1976.500314860122
total_rewards_std            859.3639166427015
total_rewards_max            2537.4882530795185
total_rewards_min            110.21934178950758
Number of train steps total  233000
Number of env steps total    1167000
Number of rollouts total     0
Train Time (s)               29.792110482230783
(Previous) Eval Time (s)     24.503184537403286
Sample Time (s)              19.536089454311877
Epoch Time (s)               73.83138447394595
Total Train Time (s)         16163.817209887784
Epoch                        232
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:44:55.685616 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #232 | Epoch Duration: 73.61390423774719
2020-01-11 07:44:55.685771 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #232 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94447595
Z variance train             0.027416756
KL Divergence                18.951515
KL Loss                      1.8951515
QF Loss                      586.92285
VF Loss                      280.0288
Policy Loss                  -876.40826
Q Predictions Mean           874.82983
Q Predictions Std            197.70332
Q Predictions Max            1094.0547
Q Predictions Min            210.69334
V Predictions Mean           890.0152
V Predictions Std            196.78296
V Predictions Max            1110.0778
V Predictions Min            223.92195
Log Pis Mean                 -1.1550047
Log Pis Std                  2.3625703
Log Pis Max                  5.020261
Log Pis Min                  -9.083185
Policy mu Mean               0.05947338
Policy mu Std                0.56150395
Policy mu Max                1.8174933
Policy mu Min                -1.7410431
Policy log std Mean          -0.88496923
Policy log std Std           0.23535351
Policy log std Max           -0.27407044
Policy log std Min           -1.8603656
Z mean eval                  0.9547799
Z variance eval              0.03211764
total_rewards                [1018.20922969 2106.54541255  183.16494059 2351.09909373  143.52272667
 2151.76152791  864.7356517   958.23793809 1419.43744705  209.71639787]
total_rewards_mean           1140.643036583699
total_rewards_std            800.017647208707
total_rewards_max            2351.0990937270217
total_rewards_min            143.52272666981648
Number of train steps total  234000
Number of env steps total    1172000
Number of rollouts total     0
Train Time (s)               29.919786021113396
(Previous) Eval Time (s)     24.28535736259073
Sample Time (s)              18.607818891759962
Epoch Time (s)               72.81296227546409
Total Train Time (s)         16233.780147992074
Epoch                        233
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:46:05.652924 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #233 | Epoch Duration: 69.96701908111572
2020-01-11 07:46:05.653128 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #233 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95348614
Z variance train             0.03213029
KL Divergence                18.658949
KL Loss                      1.8658949
QF Loss                      693.5288
VF Loss                      83.65359
Policy Loss                  -872.024
Q Predictions Mean           870.979
Q Predictions Std            234.94759
Q Predictions Max            1101.5432
Q Predictions Min            209.16667
V Predictions Mean           871.2866
V Predictions Std            234.02538
V Predictions Max            1090.5815
V Predictions Min            225.36995
Log Pis Mean                 -0.9741608
Log Pis Std                  2.34593
Log Pis Max                  5.4712353
Log Pis Min                  -8.617279
Policy mu Mean               0.057672527
Policy mu Std                0.5609868
Policy mu Max                2.1191506
Policy mu Min                -2.37908
Policy log std Mean          -0.8669294
Policy log std Std           0.26083255
Policy log std Max           -0.20655382
Policy log std Min           -2.1280048
Z mean eval                  0.92606336
Z variance eval              0.020759046
total_rewards                [2449.25149704   67.48646409  168.66940601 2391.6448842  2341.50170104
  681.62137164 2464.33175506 2633.35029788 2581.13511224  536.76554066]
total_rewards_mean           1631.5758029862616
total_rewards_std            1050.5467311939788
total_rewards_max            2633.350297875907
total_rewards_min            67.48646408668391
Number of train steps total  235000
Number of env steps total    1177000
Number of rollouts total     0
Train Time (s)               28.53042808594182
(Previous) Eval Time (s)     21.43909792881459
Sample Time (s)              17.925816202070564
Epoch Time (s)               67.89534221682698
Total Train Time (s)         16300.515857206192
Epoch                        234
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:47:12.391859 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #234 | Epoch Duration: 66.73852896690369
2020-01-11 07:47:12.392107 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #234 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9226878
Z variance train             0.020677451
KL Divergence                19.307821
KL Loss                      1.9307822
QF Loss                      617.7543
VF Loss                      140.99167
Policy Loss                  -834.87604
Q Predictions Mean           830.46606
Q Predictions Std            246.76636
Q Predictions Max            1071.7705
Q Predictions Min            -42.778374
V Predictions Mean           833.8989
V Predictions Std            244.87611
V Predictions Max            1080.8641
V Predictions Min            21.176619
Log Pis Mean                 -1.0376773
Log Pis Std                  2.8892283
Log Pis Max                  12.868138
Log Pis Min                  -8.117537
Policy mu Mean               0.011214128
Policy mu Std                0.55234975
Policy mu Max                1.9714632
Policy mu Min                -2.7544994
Policy log std Mean          -0.8731276
Policy log std Std           0.30051216
Policy log std Max           -0.24227345
Policy log std Min           -2.9539776
Z mean eval                  0.92460716
Z variance eval              0.028665274
total_rewards                [2338.97943326 2559.17924558 2362.71230621 2512.71519683 2625.63051348
 2330.2878741  2658.9211787  2480.04116178 2564.4033351   211.48153675]
total_rewards_mean           2264.435178178156
total_rewards_std            693.1980679705587
total_rewards_max            2658.921178699514
total_rewards_min            211.48153675085288
Number of train steps total  236000
Number of env steps total    1182000
Number of rollouts total     0
Train Time (s)               29.92368688667193
(Previous) Eval Time (s)     20.281927614938468
Sample Time (s)              19.082693099975586
Epoch Time (s)               69.28830760158598
Total Train Time (s)         16376.853166677058
Epoch                        235
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:48:28.730723 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #235 | Epoch Duration: 76.3384051322937
2020-01-11 07:48:28.730936 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #235 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92395514
Z variance train             0.028751556
KL Divergence                18.1916
KL Loss                      1.8191601
QF Loss                      805.85266
VF Loss                      142.9092
Policy Loss                  -875.96356
Q Predictions Mean           875.1934
Q Predictions Std            218.02007
Q Predictions Max            1087.4946
Q Predictions Min            16.324814
V Predictions Mean           876.0127
V Predictions Std            217.48543
V Predictions Max            1083.6952
V Predictions Min            40.549244
Log Pis Mean                 -0.9335752
Log Pis Std                  2.6137292
Log Pis Max                  10.710255
Log Pis Min                  -9.163162
Policy mu Mean               -0.0086597325
Policy mu Std                0.5446572
Policy mu Max                1.7443776
Policy mu Min                -3.5917652
Policy log std Mean          -0.9080618
Policy log std Std           0.25775385
Policy log std Max           -0.25101638
Policy log std Min           -2.4548185
Z mean eval                  0.9175102
Z variance eval              0.026960135
total_rewards                [2393.69915036 1432.13798542 2475.53036218 2331.12472814 2364.22929179
 2493.80751692  365.89039365 2403.68342288 1720.86917368  715.78252345]
total_rewards_mean           1869.6754548454464
total_rewards_std            747.0144594557341
total_rewards_max            2493.8075169201074
total_rewards_min            365.89039364873554
Number of train steps total  237000
Number of env steps total    1187000
Number of rollouts total     0
Train Time (s)               29.768539554905146
(Previous) Eval Time (s)     27.33171678520739
Sample Time (s)              18.039172504097223
Epoch Time (s)               75.13942884420976
Total Train Time (s)         16451.15907862829
Epoch                        236
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:49:43.039534 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #236 | Epoch Duration: 74.30843305587769
2020-01-11 07:49:43.039705 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #236 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91694593
Z variance train             0.026947614
KL Divergence                18.094028
KL Loss                      1.8094028
QF Loss                      3389.8027
VF Loss                      147.08281
Policy Loss                  -847.45026
Q Predictions Mean           847.6128
Q Predictions Std            227.63483
Q Predictions Max            1082.5323
Q Predictions Min            166.2647
V Predictions Mean           848.9758
V Predictions Std            228.82222
V Predictions Max            1090.2217
V Predictions Min            95.570755
Log Pis Mean                 -1.0085747
Log Pis Std                  2.6481757
Log Pis Max                  11.157551
Log Pis Min                  -9.709049
Policy mu Mean               0.057696484
Policy mu Std                0.55623215
Policy mu Max                2.2823532
Policy mu Min                -2.8908389
Policy log std Mean          -0.8784978
Policy log std Std           0.26841566
Policy log std Max           -0.19126701
Policy log std Min           -2.5670805
Z mean eval                  0.9167549
Z variance eval              0.013845904
total_rewards                [ -27.09079031 2479.88172784 1243.16762704 1497.46654987 2491.51773265
  812.25154158  816.73318426  466.07435819  396.00684431  227.89608833]
total_rewards_mean           1040.3904863746304
total_rewards_std            841.1150396242894
total_rewards_max            2491.5177326485286
total_rewards_min            -27.090790306539375
Number of train steps total  238000
Number of env steps total    1192000
Number of rollouts total     0
Train Time (s)               30.76295567676425
(Previous) Eval Time (s)     26.500440466683358
Sample Time (s)              17.964437508024275
Epoch Time (s)               75.22783365147188
Total Train Time (s)         16515.87262905063
Epoch                        237
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:50:47.760826 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #237 | Epoch Duration: 64.72094631195068
2020-01-11 07:50:47.761128 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #237 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91776884
Z variance train             0.013848138
KL Divergence                19.020594
KL Loss                      1.9020594
QF Loss                      2354.4631
VF Loss                      136.37617
Policy Loss                  -871.6082
Q Predictions Mean           871.38477
Q Predictions Std            192.63985
Q Predictions Max            1079.733
Q Predictions Min            226.7762
V Predictions Mean           868.6595
V Predictions Std            190.83728
V Predictions Max            1065.7261
V Predictions Min            234.14694
Log Pis Mean                 -0.6515087
Log Pis Std                  2.566628
Log Pis Max                  6.867543
Log Pis Min                  -8.52327
Policy mu Mean               0.036140583
Policy mu Std                0.56612414
Policy mu Max                2.1106708
Policy mu Min                -2.0340884
Policy log std Mean          -0.907969
Policy log std Std           0.25834283
Policy log std Max           -0.26996148
Policy log std Min           -2.185688
Z mean eval                  0.92575055
Z variance eval              0.020540796
total_rewards                [2423.29098922 1537.80799446 2385.87011613 2079.19721458 2525.85224761
 2321.36651056 1704.23818041  240.38452368   59.13322501 2582.88420723]
total_rewards_mean           1786.0025208887237
total_rewards_std            880.9229241163138
total_rewards_max            2582.884207228649
total_rewards_min            59.13322501232846
Number of train steps total  239000
Number of env steps total    1197000
Number of rollouts total     0
Train Time (s)               29.242495893035084
(Previous) Eval Time (s)     15.993195435963571
Sample Time (s)              18.60471291327849
Epoch Time (s)               63.840404242277145
Total Train Time (s)         16586.165507470258
Epoch                        238
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:51:58.052310 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #238 | Epoch Duration: 70.29093194007874
2020-01-11 07:51:58.052508 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #238 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9259178
Z variance train             0.020543773
KL Divergence                18.582336
KL Loss                      1.8582337
QF Loss                      776.50146
VF Loss                      59.18593
Policy Loss                  -862.619
Q Predictions Mean           860.4193
Q Predictions Std            235.78293
Q Predictions Max            1082.0684
Q Predictions Min            -53.02841
V Predictions Mean           866.4869
V Predictions Std            233.88759
V Predictions Max            1089.933
V Predictions Min            24.761454
Log Pis Mean                 -1.2439322
Log Pis Std                  2.3841915
Log Pis Max                  6.399221
Log Pis Min                  -9.462927
Policy mu Mean               0.049122505
Policy mu Std                0.5589335
Policy mu Max                1.9004985
Policy mu Min                -2.2823858
Policy log std Mean          -0.8565633
Policy log std Std           0.23408434
Policy log std Max           -0.21092623
Policy log std Min           -1.8323127
Z mean eval                  0.9141979
Z variance eval              0.018110137
total_rewards                [ -25.8934468  1907.39636297  873.70382012 1712.87705017 1438.04847718
 2471.90848957 2402.90174094 2281.87302207 2543.08409753 2260.31796689]
total_rewards_mean           1786.6217580631135
total_rewards_std            784.313378313766
total_rewards_max            2543.0840975262836
total_rewards_min            -25.89344680020273
Number of train steps total  240000
Number of env steps total    1202000
Number of rollouts total     0
Train Time (s)               27.56171403825283
(Previous) Eval Time (s)     22.443370413035154
Sample Time (s)              17.96428428031504
Epoch Time (s)               67.96936873160303
Total Train Time (s)         16655.156342037953
Epoch                        239
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:53:07.049342 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #239 | Epoch Duration: 68.99666571617126
2020-01-11 07:53:07.049617 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #239 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9161021
Z variance train             0.018077785
KL Divergence                18.822546
KL Loss                      1.8822546
QF Loss                      675.7075
VF Loss                      354.84177
Policy Loss                  -865.1475
Q Predictions Mean           861.61554
Q Predictions Std            228.33687
Q Predictions Max            1065.7267
Q Predictions Min            148.26912
V Predictions Mean           854.80054
V Predictions Std            225.15446
V Predictions Max            1060.0963
V Predictions Min            192.72966
Log Pis Mean                 -0.79853517
Log Pis Std                  2.2763014
Log Pis Max                  7.8523026
Log Pis Min                  -6.0916386
Policy mu Mean               -0.028463943
Policy mu Std                0.5614306
Policy mu Max                2.6091104
Policy mu Min                -2.3750253
Policy log std Mean          -0.8858993
Policy log std Std           0.2552359
Policy log std Max           -0.27007908
Policy log std Min           -1.9561714
Z mean eval                  0.93567026
Z variance eval              0.024351873
total_rewards                [2317.9594825  2328.14023434 2473.93112532 1917.9322927  2556.06769913
 2379.13836659 2561.7016233  1119.67619625  475.15381843 1471.71362076]
total_rewards_mean           1960.1414459312896
total_rewards_std            676.159101008116
total_rewards_max            2561.7016232989386
total_rewards_min            475.1538184275004
Number of train steps total  241000
Number of env steps total    1207000
Number of rollouts total     0
Train Time (s)               28.466538733337075
(Previous) Eval Time (s)     23.470369229093194
Sample Time (s)              18.723596394993365
Epoch Time (s)               70.66050435742363
Total Train Time (s)         16729.246614432894
Epoch                        240
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:54:21.139962 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #240 | Epoch Duration: 74.09014058113098
2020-01-11 07:54:21.140129 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #240 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.934855
Z variance train             0.024463544
KL Divergence                18.718185
KL Loss                      1.8718185
QF Loss                      719.3566
VF Loss                      108.4
Policy Loss                  -886.5573
Q Predictions Mean           887.4689
Q Predictions Std            212.87627
Q Predictions Max            1089.9382
Q Predictions Min            216.155
V Predictions Mean           881.7864
V Predictions Std            210.68626
V Predictions Max            1084.747
V Predictions Min            214.82474
Log Pis Mean                 -0.76414543
Log Pis Std                  2.4371269
Log Pis Max                  6.7055864
Log Pis Min                  -6.5195947
Policy mu Mean               0.026045006
Policy mu Std                0.57097477
Policy mu Max                2.386206
Policy mu Min                -2.0089734
Policy log std Mean          -0.89183164
Policy log std Std           0.26828775
Policy log std Max           -0.28032345
Policy log std Min           -2.510981
Z mean eval                  0.96724796
Z variance eval              0.019093374
total_rewards                [1429.50274073 2402.22208869 1339.93249324 2419.99133563 2199.3008643
 2592.07530796 1439.61326462 1521.7208105  2662.26918696 1478.68896276]
total_rewards_mean           1948.531705539177
total_rewards_std            521.178056738443
total_rewards_max            2662.2691869586383
total_rewards_min            1339.9324932398656
Number of train steps total  242000
Number of env steps total    1212000
Number of rollouts total     0
Train Time (s)               30.351242681965232
(Previous) Eval Time (s)     26.899706471245736
Sample Time (s)              18.808598613832146
Epoch Time (s)               76.05954776704311
Total Train Time (s)         16804.027149961796
Epoch                        241
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:55:35.928683 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #241 | Epoch Duration: 74.78837871551514
2020-01-11 07:55:35.929007 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #241 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9678152
Z variance train             0.019130567
KL Divergence                19.18555
KL Loss                      1.9185551
QF Loss                      856.3222
VF Loss                      146.04062
Policy Loss                  -859.6999
Q Predictions Mean           857.29736
Q Predictions Std            232.89159
Q Predictions Max            1054.3989
Q Predictions Min            216.98288
V Predictions Mean           862.05273
V Predictions Std            234.24654
V Predictions Max            1050.5956
V Predictions Min            214.35141
Log Pis Mean                 -1.1726682
Log Pis Std                  2.4236436
Log Pis Max                  9.41299
Log Pis Min                  -8.184031
Policy mu Mean               -0.065621495
Policy mu Std                0.5436402
Policy mu Max                2.1874952
Policy mu Min                -2.0277183
Policy log std Mean          -0.87105006
Policy log std Std           0.27296472
Policy log std Max           -0.22068033
Policy log std Min           -1.8953905
Z mean eval                  0.93447447
Z variance eval              0.024046373
total_rewards                [2682.51174065 1623.88559441 2666.73474716 1696.08418686 1129.45642895
 2068.32831666 2622.08425534 2883.42416399  496.10377874 2612.50866055]
total_rewards_mean           2048.112187330062
total_rewards_std            754.1783069564478
total_rewards_max            2883.424163988776
total_rewards_min            496.10377874155336
Number of train steps total  243000
Number of env steps total    1217000
Number of rollouts total     0
Train Time (s)               29.60092037776485
(Previous) Eval Time (s)     25.62809456884861
Sample Time (s)              19.113515711855143
Epoch Time (s)               74.3425306584686
Total Train Time (s)         16876.760841942392
Epoch                        242
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:56:48.666376 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #242 | Epoch Duration: 72.7371153831482
2020-01-11 07:56:48.666633 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #242 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93588513
Z variance train             0.024099652
KL Divergence                19.369547
KL Loss                      1.9369547
QF Loss                      458.3742
VF Loss                      122.97567
Policy Loss                  -882.27405
Q Predictions Mean           880.3296
Q Predictions Std            208.96896
Q Predictions Max            1078.0721
Q Predictions Min            100.2208
V Predictions Mean           882.5998
V Predictions Std            206.72406
V Predictions Max            1074.4629
V Predictions Min            164.13931
Log Pis Mean                 -0.659799
Log Pis Std                  2.5024707
Log Pis Max                  8.661798
Log Pis Min                  -7.843589
Policy mu Mean               -0.01851742
Policy mu Std                0.5387945
Policy mu Max                2.0275943
Policy mu Min                -2.0359364
Policy log std Mean          -0.93394405
Policy log std Std           0.28805912
Policy log std Max           -0.22492546
Policy log std Min           -2.6974554
Z mean eval                  0.91299057
Z variance eval              0.017941229
total_rewards                [ 997.46554713  428.39627568 2355.81034688 2081.48687546  789.9118435
  416.70307239  880.20476917 1186.49874649 1041.93054144 2467.47164141]
total_rewards_mean           1264.587965955026
total_rewards_std            722.7199381503664
total_rewards_max            2467.471641409008
total_rewards_min            416.70307238584303
Number of train steps total  244000
Number of env steps total    1222000
Number of rollouts total     0
Train Time (s)               29.8542733611539
(Previous) Eval Time (s)     24.022348961792886
Sample Time (s)              18.108993301633745
Epoch Time (s)               71.98561562458053
Total Train Time (s)         16944.395703725517
Epoch                        243
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:57:56.306155 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #243 | Epoch Duration: 67.6391909122467
2020-01-11 07:57:56.306565 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #243 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91547954
Z variance train             0.017938029
KL Divergence                19.783312
KL Loss                      1.9783312
QF Loss                      442.56415
VF Loss                      213.9078
Policy Loss                  -876.2862
Q Predictions Mean           870.90076
Q Predictions Std            233.20142
Q Predictions Max            1093.7684
Q Predictions Min            -89.513336
V Predictions Mean           869.6437
V Predictions Std            229.92938
V Predictions Max            1075.3048
V Predictions Min            -9.078875
Log Pis Mean                 -1.2117219
Log Pis Std                  2.4132934
Log Pis Max                  5.6706796
Log Pis Min                  -8.137093
Policy mu Mean               0.07374394
Policy mu Std                0.52144414
Policy mu Max                1.8923658
Policy mu Min                -1.6465585
Policy log std Mean          -0.888872
Policy log std Std           0.26287088
Policy log std Max           -0.18041608
Policy log std Min           -1.9675432
Z mean eval                  0.9361016
Z variance eval              0.01661494
total_rewards                [2761.51090296 1580.17854103  142.44135687 1563.32921392 2307.94585312
  869.09087042 2462.83438896 2745.02857896 2669.82633776 1189.0748407 ]
total_rewards_mean           1829.1260884716182
total_rewards_std            857.596161607723
total_rewards_max            2761.5109029604255
total_rewards_min            142.4413568711096
Number of train steps total  245000
Number of env steps total    1227000
Number of rollouts total     0
Train Time (s)               27.074757282156497
(Previous) Eval Time (s)     19.675610238220543
Sample Time (s)              18.908982569817454
Epoch Time (s)               65.6593500901945
Total Train Time (s)         17014.89533511363
Epoch                        244
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:59:06.807289 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #244 | Epoch Duration: 70.50050592422485
2020-01-11 07:59:06.807483 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #244 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93390894
Z variance train             0.016607486
KL Divergence                20.40672
KL Loss                      2.040672
QF Loss                      824.6384
VF Loss                      102.19244
Policy Loss                  -893.64636
Q Predictions Mean           892.29694
Q Predictions Std            228.65637
Q Predictions Max            1084.3021
Q Predictions Min            72.19458
V Predictions Mean           897.823
V Predictions Std            230.8403
V Predictions Max            1080.9226
V Predictions Min            0.55825555
Log Pis Mean                 -0.8780793
Log Pis Std                  2.656591
Log Pis Max                  13.503624
Log Pis Min                  -6.844331
Policy mu Mean               -0.019897513
Policy mu Std                0.5864003
Policy mu Max                2.36396
Policy mu Min                -2.143478
Policy log std Mean          -0.8732109
Policy log std Std           0.26942235
Policy log std Max           0.55272704
Policy log std Min           -1.9617503
Z mean eval                  0.9474513
Z variance eval              0.027131319
total_rewards                [ 348.00341875 2005.84685497  104.78258074  488.47531104 1328.04401988
 2556.40203341 2371.63879679   98.45415322 2428.87786861 2686.0906575 ]
total_rewards_mean           1441.6615694907637
total_rewards_std            1032.376941485801
total_rewards_max            2686.090657501207
total_rewards_min            98.45415322212813
Number of train steps total  246000
Number of env steps total    1232000
Number of rollouts total     0
Train Time (s)               31.09782271878794
(Previous) Eval Time (s)     24.51645251410082
Sample Time (s)              17.590647883713245
Epoch Time (s)               73.204923116602
Total Train Time (s)         17082.863311520778
Epoch                        245
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:00:14.777179 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #245 | Epoch Duration: 67.96950650215149
2020-01-11 08:00:14.777444 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #245 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9495875
Z variance train             0.02734389
KL Divergence                18.446524
KL Loss                      1.8446524
QF Loss                      900.0399
VF Loss                      368.12128
Policy Loss                  -872.7542
Q Predictions Mean           871.78986
Q Predictions Std            238.32224
Q Predictions Max            1089.475
Q Predictions Min            213.83105
V Predictions Mean           886.8794
V Predictions Std            238.74405
V Predictions Max            1100.5553
V Predictions Min            213.4425
Log Pis Mean                 -0.9878991
Log Pis Std                  2.6940753
Log Pis Max                  7.7957497
Log Pis Min                  -8.419519
Policy mu Mean               0.006849708
Policy mu Std                0.56122893
Policy mu Max                1.7756138
Policy mu Min                -2.8177884
Policy log std Mean          -0.8843515
Policy log std Std           0.2681175
Policy log std Max           -0.21539813
Policy log std Min           -2.2024732
Z mean eval                  0.9252349
Z variance eval              0.03635185
total_rewards                [ -33.20314946 2132.17843261 2525.22171065 2490.80929745 2713.21927639
  641.18978179 2669.07704896 2491.0188345  1502.78370664 2464.27231353]
total_rewards_mean           1959.6567253079454
total_rewards_std            903.2411284265617
total_rewards_max            2713.2192763943603
total_rewards_min            -33.20314945938235
Number of train steps total  247000
Number of env steps total    1237000
Number of rollouts total     0
Train Time (s)               29.071815295144916
(Previous) Eval Time (s)     19.280711516272277
Sample Time (s)              18.308447387069464
Epoch Time (s)               66.66097419848666
Total Train Time (s)         17156.531640710775
Epoch                        246
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:01:28.447073 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #246 | Epoch Duration: 73.66947412490845
2020-01-11 08:01:28.447273 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #246 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92302144
Z variance train             0.036803864
KL Divergence                17.063265
KL Loss                      1.7063265
QF Loss                      691.8236
VF Loss                      230.6611
Policy Loss                  -893.92175
Q Predictions Mean           889.3595
Q Predictions Std            234.98196
Q Predictions Max            1120.3484
Q Predictions Min            22.20405
V Predictions Mean           884.6437
V Predictions Std            233.42838
V Predictions Max            1095.4895
V Predictions Min            13.525678
Log Pis Mean                 -1.0957136
Log Pis Std                  2.5449362
Log Pis Max                  8.295882
Log Pis Min                  -9.225952
Policy mu Mean               0.021498784
Policy mu Std                0.51721776
Policy mu Max                1.9084185
Policy mu Min                -2.0526884
Policy log std Mean          -0.90725356
Policy log std Std           0.29540712
Policy log std Max           -0.2226212
Policy log std Min           -2.5323744
Z mean eval                  0.92721385
Z variance eval              0.027410096
total_rewards                [2534.79071062 2421.03092273 1503.72348089 1635.00775249  616.13582041
  608.73404861 2811.90109014  627.3955128  1324.15952151 2861.48578586]
total_rewards_mean           1694.436464607136
total_rewards_std            866.1369816419368
total_rewards_max            2861.4857858553237
total_rewards_min            608.7340486136297
Number of train steps total  248000
Number of env steps total    1242000
Number of rollouts total     0
Train Time (s)               28.24726201593876
(Previous) Eval Time (s)     26.288922999054193
Sample Time (s)              17.74338366277516
Epoch Time (s)               72.27956867776811
Total Train Time (s)         17225.98938885238
Epoch                        247
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:02:37.908133 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #247 | Epoch Duration: 69.46070528030396
2020-01-11 08:02:37.908328 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #247 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9247314
Z variance train             0.027466753
KL Divergence                17.402533
KL Loss                      1.7402533
QF Loss                      887.06024
VF Loss                      89.31756
Policy Loss                  -911.62695
Q Predictions Mean           908.6611
Q Predictions Std            216.20866
Q Predictions Max            1105.6494
Q Predictions Min            -24.318949
V Predictions Mean           908.3584
V Predictions Std            215.04579
V Predictions Max            1117.8622
V Predictions Min            58.205643
Log Pis Mean                 -0.9198636
Log Pis Std                  2.4527397
Log Pis Max                  6.6362877
Log Pis Min                  -7.6783214
Policy mu Mean               0.044838578
Policy mu Std                0.56051755
Policy mu Max                2.6646624
Policy mu Min                -2.1802428
Policy log std Mean          -0.9009171
Policy log std Std           0.25781897
Policy log std Max           -0.12001526
Policy log std Min           -2.1470733
Z mean eval                  0.93986005
Z variance eval              0.024759984
total_rewards                [2444.86364977 1223.46498136 2631.28258415 1870.81879934 2518.34443334
  380.66763683  542.65689774 -104.14213498   70.80832693  368.42775681]
total_rewards_mean           1194.7192931291218
total_rewards_std            1027.488949293791
total_rewards_max            2631.282584149887
total_rewards_min            -104.14213497736563
Number of train steps total  249000
Number of env steps total    1247000
Number of rollouts total     0
Train Time (s)               29.67462343722582
(Previous) Eval Time (s)     23.469773364253342
Sample Time (s)              18.401101747062057
Epoch Time (s)               71.54549854854122
Total Train Time (s)         17289.95708027389
Epoch                        248
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:03:41.880649 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #248 | Epoch Duration: 63.97214603424072
2020-01-11 08:03:41.880910 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #248 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9365717
Z variance train             0.024676982
KL Divergence                17.996782
KL Loss                      1.7996782
QF Loss                      631.28
VF Loss                      119.38758
Policy Loss                  -912.5642
Q Predictions Mean           910.65906
Q Predictions Std            224.4157
Q Predictions Max            1125.1448
Q Predictions Min            -1.1237154
V Predictions Mean           918.9562
V Predictions Std            222.34587
V Predictions Max            1123.5726
V Predictions Min            37.523537
Log Pis Mean                 -0.70512664
Log Pis Std                  2.341211
Log Pis Max                  8.061026
Log Pis Min                  -7.6862183
Policy mu Mean               -0.0067550903
Policy mu Std                0.5478292
Policy mu Max                2.0626774
Policy mu Min                -1.9113902
Policy log std Mean          -0.91291225
Policy log std Std           0.24769886
Policy log std Max           -0.1966967
Policy log std Min           -2.1856816
Z mean eval                  0.94765884
Z variance eval              0.02200008
total_rewards                [ 392.69172248 1640.06847946 2649.51270225  920.12542629 2445.96976122
  488.15564007 2618.19472013  826.75619855  165.26975044 1853.59166844]
total_rewards_mean           1400.0336069329765
total_rewards_std            912.8136901963834
total_rewards_max            2649.512702251577
total_rewards_min            165.26975044434477
Number of train steps total  250000
Number of env steps total    1252000
Number of rollouts total     0
Train Time (s)               27.34389538085088
(Previous) Eval Time (s)     15.896087189670652
Sample Time (s)              18.442212029360235
Epoch Time (s)               61.68219459988177
Total Train Time (s)         17358.24344996875
Epoch                        249
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:04:50.169860 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #249 | Epoch Duration: 68.28875041007996
2020-01-11 08:04:50.170041 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #249 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94873685
Z variance train             0.021986105
KL Divergence                18.487553
KL Loss                      1.8487552
QF Loss                      864.0531
VF Loss                      212.73207
Policy Loss                  -896.11615
Q Predictions Mean           896.00006
Q Predictions Std            230.13423
Q Predictions Max            1113.6277
Q Predictions Min            184.87746
V Predictions Mean           905.3037
V Predictions Std            230.08817
V Predictions Max            1130.2028
V Predictions Min            213.85753
Log Pis Mean                 -0.77122045
Log Pis Std                  2.608098
Log Pis Max                  6.968402
Log Pis Min                  -9.727021
Policy mu Mean               0.019139115
Policy mu Std                0.55602723
Policy mu Max                1.9995441
Policy mu Min                -2.0016105
Policy log std Mean          -0.8973024
Policy log std Std           0.25918734
Policy log std Max           -0.18904263
Policy log std Min           -2.004994
Z mean eval                  0.9392859
Z variance eval              0.036138322
total_rewards                [ 789.01752322 1105.43859018 1810.52486591 1903.06109997 2558.60225392
 2595.55756882 2566.31038292 2522.48860589 1860.8929106  2614.76241758]
total_rewards_mean           2032.6656219006643
total_rewards_std            629.2103721781617
total_rewards_max            2614.762417575725
total_rewards_min            789.0175232219351
Number of train steps total  251000
Number of env steps total    1257000
Number of rollouts total     0
Train Time (s)               28.871503327973187
(Previous) Eval Time (s)     22.502339004073292
Sample Time (s)              18.20539720263332
Epoch Time (s)               69.5792395346798
Total Train Time (s)         17430.198141679168
Epoch                        250
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:06:02.128130 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #250 | Epoch Duration: 71.95792889595032
2020-01-11 08:06:02.128393 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #250 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9369464
Z variance train             0.03614458
KL Divergence                17.756351
KL Loss                      1.7756351
QF Loss                      1687.636
VF Loss                      269.56427
Policy Loss                  -904.8086
Q Predictions Mean           904.0029
Q Predictions Std            239.76398
Q Predictions Max            1165.2555
Q Predictions Min            -8.975048
V Predictions Mean           909.8237
V Predictions Std            235.63187
V Predictions Max            1178.8087
V Predictions Min            49.143604
Log Pis Mean                 -1.0225815
Log Pis Std                  2.7232208
Log Pis Max                  9.105858
Log Pis Min                  -8.7782955
Policy mu Mean               -0.020806652
Policy mu Std                0.5507915
Policy mu Max                2.3486767
Policy mu Min                -2.6107872
Policy log std Mean          -0.90752137
Policy log std Std           0.2753307
Policy log std Max           -0.25930423
Policy log std Min           -2.3936028
Z mean eval                  0.9711261
Z variance eval              0.044641256
total_rewards                [2689.78305015 2632.02372201 2676.70905149 2853.25425016 1366.79502981
  639.62139005   41.26334957 2743.26762685 2798.20864909 2549.44337002]
total_rewards_mean           2099.0369489188593
total_rewards_std            976.8750696278405
total_rewards_max            2853.254250155883
total_rewards_min            41.263349569099866
Number of train steps total  252000
Number of env steps total    1262000
Number of rollouts total     0
Train Time (s)               28.745271385181695
(Previous) Eval Time (s)     24.8807053421624
Sample Time (s)              18.550352044869214
Epoch Time (s)               72.17632877221331
Total Train Time (s)         17499.37430734327
Epoch                        251
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:07:11.307587 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #251 | Epoch Duration: 69.17900609970093
2020-01-11 08:07:11.307808 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #251 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9692615
Z variance train             0.044568248
KL Divergence                17.773617
KL Loss                      1.7773618
QF Loss                      1060.8872
VF Loss                      208.18037
Policy Loss                  -900.7518
Q Predictions Mean           897.0504
Q Predictions Std            233.6057
Q Predictions Max            1110.1827
Q Predictions Min            220.83504
V Predictions Mean           892.5353
V Predictions Std            232.40524
V Predictions Max            1110.0829
V Predictions Min            198.45192
Log Pis Mean                 -1.0141639
Log Pis Std                  2.4278219
Log Pis Max                  7.121056
Log Pis Min                  -7.963864
Policy mu Mean               0.008327452
Policy mu Std                0.5460385
Policy mu Max                3.0509303
Policy mu Min                -1.6251389
Policy log std Mean          -0.9021312
Policy log std Std           0.26110443
Policy log std Max           -0.14059585
Policy log std Min           -2.4727058
Z mean eval                  0.95378524
Z variance eval              0.025737846
total_rewards                [ 713.87330022  677.60380713 2061.5743183  2250.75837824 2035.46133829
  494.56244176  200.05566953 1054.18198782 1572.77841841 2262.11271832]
total_rewards_mean           1332.29623780232
total_rewards_std            752.6243425046742
total_rewards_max            2262.1127183170083
total_rewards_min            200.05566953122934
Number of train steps total  253000
Number of env steps total    1267000
Number of rollouts total     0
Train Time (s)               30.217944227159023
(Previous) Eval Time (s)     21.88304568314925
Sample Time (s)              18.601145889610052
Epoch Time (s)               70.70213579991832
Total Train Time (s)         17564.76422792673
Epoch                        252
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:08:16.702721 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #252 | Epoch Duration: 65.39470386505127
2020-01-11 08:08:16.703037 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #252 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9523082
Z variance train             0.025788287
KL Divergence                18.28426
KL Loss                      1.828426
QF Loss                      618.2805
VF Loss                      172.43774
Policy Loss                  -897.6215
Q Predictions Mean           895.47485
Q Predictions Std            214.39062
Q Predictions Max            1106.3302
Q Predictions Min            192.85399
V Predictions Mean           905.6917
V Predictions Std            212.40698
V Predictions Max            1123.5273
V Predictions Min            220.44884
Log Pis Mean                 -0.702381
Log Pis Std                  2.5493464
Log Pis Max                  7.9760265
Log Pis Min                  -6.8761296
Policy mu Mean               0.04831638
Policy mu Std                0.55169046
Policy mu Max                2.0295484
Policy mu Min                -2.3989275
Policy log std Mean          -0.9253608
Policy log std Std           0.27224866
Policy log std Max           -0.23610914
Policy log std Min           -2.486945
Z mean eval                  0.9448649
Z variance eval              0.029942747
total_rewards                [  41.18816205  989.11057351  311.13511585  190.38212221  271.714661
 1082.69802891  798.76201095  595.62086488 2659.23679817 1232.9856366 ]
total_rewards_mean           817.2833974121476
total_rewards_std            725.5486103385207
total_rewards_max            2659.236798168392
total_rewards_min            41.1881620544665
Number of train steps total  254000
Number of env steps total    1272000
Number of rollouts total     0
Train Time (s)               27.45206371601671
(Previous) Eval Time (s)     16.57528018997982
Sample Time (s)              18.84845507470891
Epoch Time (s)               62.87579898070544
Total Train Time (s)         17623.4816097226
Epoch                        253
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:09:15.424718 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #253 | Epoch Duration: 58.721431255340576
2020-01-11 08:09:15.425005 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #253 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94295454
Z variance train             0.029953087
KL Divergence                17.798903
KL Loss                      1.7798903
QF Loss                      1218.8525
VF Loss                      102.96335
Policy Loss                  -909.7947
Q Predictions Mean           911.30505
Q Predictions Std            222.38817
Q Predictions Max            1132.3975
Q Predictions Min            157.60432
V Predictions Mean           912.88324
V Predictions Std            225.71
V Predictions Max            1137.1237
V Predictions Min            40.556866
Log Pis Mean                 -0.6133996
Log Pis Std                  3.1183186
Log Pis Max                  12.516827
Log Pis Min                  -11.725645
Policy mu Mean               0.02742127
Policy mu Std                0.58601123
Policy mu Max                2.3689942
Policy mu Min                -2.4511094
Policy log std Mean          -0.8993959
Policy log std Std           0.28722015
Policy log std Max           -0.1872521
Policy log std Min           -2.8568451
Z mean eval                  0.93744755
Z variance eval              0.02690569
total_rewards                [2357.86865498  -26.04434143  556.55530455 1077.86008247 2596.3004861
 2463.65072367 1938.57246575  800.4428763  2729.68127686 1864.15985353]
total_rewards_mean           1635.9047382788417
total_rewards_std            916.8037345760059
total_rewards_max            2729.6812768552136
total_rewards_min            -26.04434143038262
Number of train steps total  255000
Number of env steps total    1277000
Number of rollouts total     0
Train Time (s)               28.10335302213207
(Previous) Eval Time (s)     12.420615163166076
Sample Time (s)              18.614548318088055
Epoch Time (s)               59.1385165033862
Total Train Time (s)         17694.618922865484
Epoch                        254
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:10:26.586368 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #254 | Epoch Duration: 71.1611180305481
2020-01-11 08:10:26.586676 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #254 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9372778
Z variance train             0.026927466
KL Divergence                18.345335
KL Loss                      1.8345336
QF Loss                      929.20447
VF Loss                      99.8484
Policy Loss                  -912.0884
Q Predictions Mean           910.978
Q Predictions Std            228.86916
Q Predictions Max            1122.9913
Q Predictions Min            3.0897772
V Predictions Mean           907.87866
V Predictions Std            228.91576
V Predictions Max            1111.8221
V Predictions Min            3.8389404
Log Pis Mean                 -0.7919455
Log Pis Std                  2.7592142
Log Pis Max                  13.631057
Log Pis Min                  -7.789043
Policy mu Mean               0.064500436
Policy mu Std                0.5541392
Policy mu Max                2.2510757
Policy mu Min                -2.1698506
Policy log std Mean          -0.9033371
Policy log std Std           0.28052866
Policy log std Max           -0.19608164
Policy log std Min           -2.5883994
Z mean eval                  0.9554559
Z variance eval              0.028318385
total_rewards                [ 206.55123216 2544.01969103  979.54894422 2801.62218341 2907.5863429
 1118.13704425  952.6613602  1991.87794842 1496.80350125  771.62406099]
total_rewards_mean           1577.0432308830873
total_rewards_std            887.0120463907294
total_rewards_max            2907.5863428961934
total_rewards_min            206.55123216081793
Number of train steps total  256000
Number of env steps total    1282000
Number of rollouts total     0
Train Time (s)               29.554026904981583
(Previous) Eval Time (s)     24.442884634714574
Sample Time (s)              18.676864847540855
Epoch Time (s)               72.67377638723701
Total Train Time (s)         17762.281220743433
Epoch                        255
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:11:34.233828 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #255 | Epoch Duration: 67.64689326286316
2020-01-11 08:11:34.234148 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #255 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9557166
Z variance train             0.02830882
KL Divergence                18.556149
KL Loss                      1.8556149
QF Loss                      551.9176
VF Loss                      70.25395
Policy Loss                  -891.6634
Q Predictions Mean           889.64136
Q Predictions Std            258.397
Q Predictions Max            1139.0432
Q Predictions Min            211.28194
V Predictions Mean           892.45984
V Predictions Std            259.70703
V Predictions Max            1126.8702
V Predictions Min            224.25919
Log Pis Mean                 -1.0996405
Log Pis Std                  2.454031
Log Pis Max                  8.873881
Log Pis Min                  -8.857151
Policy mu Mean               0.03160839
Policy mu Std                0.55124724
Policy mu Max                1.9847487
Policy mu Min                -1.9066821
Policy log std Mean          -0.87705547
Policy log std Std           0.2598276
Policy log std Max           -0.17224836
Policy log std Min           -2.1101272
Z mean eval                  0.95902216
Z variance eval              0.028317148
total_rewards                [ -28.69973504 1703.02787005 1110.54670517 1409.14340384 1298.73668489
 1413.5044823   874.59612276 1531.84023104  419.32116973  892.12294939]
total_rewards_mean           1062.4139884138299
total_rewards_std            509.9774759641445
total_rewards_max            1703.027870054469
total_rewards_min            -28.699735038920366
Number of train steps total  257000
Number of env steps total    1287000
Number of rollouts total     0
Train Time (s)               29.615179917775095
(Previous) Eval Time (s)     19.415687709115446
Sample Time (s)              19.0076373629272
Epoch Time (s)               68.03850498981774
Total Train Time (s)         17828.213258637115
Epoch                        256
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:12:40.166400 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #256 | Epoch Duration: 65.93203616142273
2020-01-11 08:12:40.166602 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #256 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95608366
Z variance train             0.02820541
KL Divergence                17.814482
KL Loss                      1.7814482
QF Loss                      2928.693
VF Loss                      2077.1306
Policy Loss                  -904.8279
Q Predictions Mean           900.1463
Q Predictions Std            242.3305
Q Predictions Max            1113.2496
Q Predictions Min            49.949696
V Predictions Mean           919.55566
V Predictions Std            232.49184
V Predictions Max            1137.9342
V Predictions Min            220.44789
Log Pis Mean                 -0.8812002
Log Pis Std                  2.824293
Log Pis Max                  12.02819
Log Pis Min                  -11.538235
Policy mu Mean               -0.05733068
Policy mu Std                0.54770327
Policy mu Max                2.2589426
Policy mu Min                -3.4361825
Policy log std Mean          -0.9161228
Policy log std Std           0.26949656
Policy log std Max           -0.16801363
Policy log std Min           -2.7833662
Z mean eval                  0.9743804
Z variance eval              0.025839994
total_rewards                [1581.0693333  2533.64945465 2521.91674962 1870.10757966 2593.56677903
 2388.29893387 2711.13949003 2649.54139756 2515.39766722 1367.54550296]
total_rewards_mean           2273.223288788703
total_rewards_std            458.19194163567977
total_rewards_max            2711.1394900299756
total_rewards_min            1367.5455029620603
Number of train steps total  258000
Number of env steps total    1292000
Number of rollouts total     0
Train Time (s)               31.864231899846345
(Previous) Eval Time (s)     17.308948644436896
Sample Time (s)              18.443651183042675
Epoch Time (s)               67.61683172732592
Total Train Time (s)         17903.35017370293
Epoch                        257
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:13:55.305441 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #257 | Epoch Duration: 75.1386935710907
2020-01-11 08:13:55.305596 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #257 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9797969
Z variance train             0.025819376
KL Divergence                18.32274
KL Loss                      1.8322741
QF Loss                      1017.46625
VF Loss                      566.675
Policy Loss                  -915.82446
Q Predictions Mean           918.78186
Q Predictions Std            236.59567
Q Predictions Max            1172.9167
Q Predictions Min            182.0911
V Predictions Mean           931.19635
V Predictions Std            237.79002
V Predictions Max            1182.9382
V Predictions Min            212.43553
Log Pis Mean                 -0.7309377
Log Pis Std                  2.5701873
Log Pis Max                  7.1124563
Log Pis Min                  -10.644365
Policy mu Mean               -0.013894947
Policy mu Std                0.5666858
Policy mu Max                2.4704862
Policy mu Min                -2.798747
Policy log std Mean          -0.91282326
Policy log std Std           0.25961065
Policy log std Max           -0.23753095
Policy log std Min           -2.4096613
Z mean eval                  0.94236296
Z variance eval              0.02254998
total_rewards                [1623.90878118 2753.43644334 2600.19241283 2795.36802836 2491.52994709
  120.64003533 2785.007311    263.01485697 2339.75025458  646.19177854]
total_rewards_mean           1841.9039849206947
total_rewards_std            1039.5761241606613
total_rewards_max            2795.3680283584495
total_rewards_min            120.64003533014515
Number of train steps total  259000
Number of env steps total    1297000
Number of rollouts total     0
Train Time (s)               28.966166269034147
(Previous) Eval Time (s)     24.83051085891202
Sample Time (s)              18.142430834006518
Epoch Time (s)               71.93910796195269
Total Train Time (s)         17970.864580288064
Epoch                        258
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:15:02.826609 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #258 | Epoch Duration: 67.52085781097412
2020-01-11 08:15:02.826877 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #258 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.942224
Z variance train             0.022569606
KL Divergence                18.836836
KL Loss                      1.8836836
QF Loss                      642.1618
VF Loss                      112.799484
Policy Loss                  -925.8782
Q Predictions Mean           926.0701
Q Predictions Std            232.56647
Q Predictions Max            1176.2289
Q Predictions Min            27.266499
V Predictions Mean           926.14233
V Predictions Std            231.08913
V Predictions Max            1172.3293
V Predictions Min            4.810712
Log Pis Mean                 -1.0211531
Log Pis Std                  2.5194926
Log Pis Max                  5.779808
Log Pis Min                  -9.526345
Policy mu Mean               0.04571762
Policy mu Std                0.57074213
Policy mu Max                1.82378
Policy mu Min                -2.5523293
Policy log std Mean          -0.9078686
Policy log std Std           0.25279802
Policy log std Max           -0.11361337
Policy log std Min           -1.9657531
Z mean eval                  0.95122087
Z variance eval              0.015711647
total_rewards                [2745.67533573 1298.58461177 2365.94112692   60.92758547   35.42328444
 1257.93296663  194.45701743 2807.29395779 2465.2225721  2596.17401672]
total_rewards_mean           1582.7632475009143
total_rewards_std            1099.7660916424613
total_rewards_max            2807.29395779026
total_rewards_min            35.42328444348435
Number of train steps total  260000
Number of env steps total    1302000
Number of rollouts total     0
Train Time (s)               30.471297970972955
(Previous) Eval Time (s)     20.411914727650583
Sample Time (s)              18.664497023448348
Epoch Time (s)               69.54770972207189
Total Train Time (s)         18041.573182887398
Epoch                        259
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:16:13.535361 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #259 | Epoch Duration: 70.70829439163208
2020-01-11 08:16:13.535560 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #259 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9479469
Z variance train             0.015701333
KL Divergence                19.665289
KL Loss                      1.9665289
QF Loss                      529.76587
VF Loss                      102.62699
Policy Loss                  -934.32587
Q Predictions Mean           933.71216
Q Predictions Std            230.26512
Q Predictions Max            1133.148
Q Predictions Min            29.49901
V Predictions Mean           931.9986
V Predictions Std            227.85965
V Predictions Max            1138.7079
V Predictions Min            5.6386595
Log Pis Mean                 -0.90521574
Log Pis Std                  2.3459744
Log Pis Max                  7.1766567
Log Pis Min                  -8.43993
Policy mu Mean               0.047162183
Policy mu Std                0.5337778
Policy mu Max                2.5592947
Policy mu Min                -1.899666
Policy log std Mean          -0.919437
Policy log std Std           0.26092398
Policy log std Max           -0.1349914
Policy log std Min           -2.0178359
Z mean eval                  0.95758504
Z variance eval              0.018248824
total_rewards                [2644.02731142 2873.60999535 3031.82620615 2677.57364495  182.46760229
 2587.31832388 2098.37098216 2986.37898594   27.05295042 2957.12315171]
total_rewards_mean           2206.5749154261
total_rewards_std            1082.3399180158237
total_rewards_max            3031.82620614799
total_rewards_min            27.052950421668136
Number of train steps total  261000
Number of env steps total    1307000
Number of rollouts total     0
Train Time (s)               29.135387738700956
(Previous) Eval Time (s)     21.572190378792584
Sample Time (s)              18.875350617337972
Epoch Time (s)               69.58292873483151
Total Train Time (s)         18110.719359093346
Epoch                        260
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:17:22.691061 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #260 | Epoch Duration: 69.15528988838196
2020-01-11 08:17:22.691373 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #260 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95863754
Z variance train             0.01821758
KL Divergence                19.866184
KL Loss                      1.9866184
QF Loss                      1189.854
VF Loss                      160.9096
Policy Loss                  -923.5161
Q Predictions Mean           923.8302
Q Predictions Std            235.56296
Q Predictions Max            1141.3666
Q Predictions Min            223.13422
V Predictions Mean           927.5819
V Predictions Std            236.59834
V Predictions Max            1152.739
V Predictions Min            151.24644
Log Pis Mean                 -0.90968966
Log Pis Std                  2.4748971
Log Pis Max                  8.393955
Log Pis Min                  -7.207617
Policy mu Mean               0.014843491
Policy mu Std                0.5447495
Policy mu Max                2.4103827
Policy mu Min                -2.553052
Policy log std Mean          -0.8872611
Policy log std Std           0.24596652
Policy log std Max           -0.1873379
Policy log std Min           -2.5966277
Z mean eval                  0.9661409
Z variance eval              0.018426586
total_rewards                [2417.47892181 2073.4993313   326.12355887 2466.40141903  865.95312419
 1746.97781979 2664.73791582 2515.00056652 2536.84246128  743.39379977]
total_rewards_mean           1835.6408918387192
total_rewards_std            827.8519102171477
total_rewards_max            2664.737915819428
total_rewards_min            326.1235588727875
Number of train steps total  262000
Number of env steps total    1312000
Number of rollouts total     0
Train Time (s)               28.850722576957196
(Previous) Eval Time (s)     21.144186593126506
Sample Time (s)              19.047022285405546
Epoch Time (s)               69.04193145548925
Total Train Time (s)         18180.52626497438
Epoch                        261
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:18:32.496157 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #261 | Epoch Duration: 69.80453610420227
2020-01-11 08:18:32.496397 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #261 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96569645
Z variance train             0.018424755
KL Divergence                20.05821
KL Loss                      2.005821
QF Loss                      481.88998
VF Loss                      134.48859
Policy Loss                  -955.27594
Q Predictions Mean           953.0349
Q Predictions Std            232.09865
Q Predictions Max            1215.4187
Q Predictions Min            208.60507
V Predictions Mean           956.2883
V Predictions Std            229.3073
V Predictions Max            1232.298
V Predictions Min            225.07124
Log Pis Mean                 -1.1542563
Log Pis Std                  2.4929826
Log Pis Max                  6.7018137
Log Pis Min                  -8.480636
Policy mu Mean               0.032985955
Policy mu Std                0.5303168
Policy mu Max                2.0935614
Policy mu Min                -1.9592499
Policy log std Mean          -0.89708984
Policy log std Std           0.25194874
Policy log std Max           -0.13511807
Policy log std Min           -2.0002584
Z mean eval                  0.9562416
Z variance eval              0.028705826
total_rewards                [2673.89588026 2638.18142864 2573.69689669 2507.09258191 2504.37492638
 2692.90799797 2793.69367195 2472.59168313 2482.99962143 2649.24305343]
total_rewards_mean           2598.867774179379
total_rewards_std            101.91632856930026
total_rewards_max            2793.693671954397
total_rewards_min            2472.5916831286895
Number of train steps total  263000
Number of env steps total    1317000
Number of rollouts total     0
Train Time (s)               28.588969186879694
(Previous) Eval Time (s)     21.906475526746362
Sample Time (s)              18.241868307814002
Epoch Time (s)               68.73731302144006
Total Train Time (s)         18254.54895925196
Epoch                        262
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:19:46.522341 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #262 | Epoch Duration: 74.02575159072876
2020-01-11 08:19:46.522562 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #262 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9566061
Z variance train             0.02852979
KL Divergence                18.768143
KL Loss                      1.8768142
QF Loss                      1497.6605
VF Loss                      147.8255
Policy Loss                  -949.18085
Q Predictions Mean           945.08325
Q Predictions Std            219.85867
Q Predictions Max            1142.8955
Q Predictions Min            24.605213
V Predictions Mean           952.37366
V Predictions Std            220.35413
V Predictions Max            1161.9943
V Predictions Min            20.174118
Log Pis Mean                 -0.92969894
Log Pis Std                  2.7634943
Log Pis Max                  10.929201
Log Pis Min                  -12.921792
Policy mu Mean               0.042914666
Policy mu Std                0.5612136
Policy mu Max                2.5755172
Policy mu Min                -2.2567084
Policy log std Mean          -0.8927113
Policy log std Std           0.25580645
Policy log std Max           -0.1816293
Policy log std Min           -2.3957195
Z mean eval                  0.9422768
Z variance eval              0.023592463
total_rewards                [2311.12998609 1876.53620347 2578.76138597 2674.219349   2542.51521942
  491.88003057  714.59089295 2715.33036934  481.15718334  972.82005296]
total_rewards_mean           1735.894067310844
total_rewards_std            910.9756897708318
total_rewards_max            2715.3303693439702
total_rewards_min            481.15718334295997
Number of train steps total  264000
Number of env steps total    1322000
Number of rollouts total     0
Train Time (s)               29.770463815890253
(Previous) Eval Time (s)     27.194626914337277
Sample Time (s)              17.562837024684995
Epoch Time (s)               74.52792775491253
Total Train Time (s)         18320.48717993498
Epoch                        263
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:20:52.465351 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #263 | Epoch Duration: 65.9425859451294
2020-01-11 08:20:52.465628 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #263 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94229853
Z variance train             0.02361604
KL Divergence                19.093214
KL Loss                      1.9093214
QF Loss                      1343.4504
VF Loss                      324.5171
Policy Loss                  -932.8443
Q Predictions Mean           933.1562
Q Predictions Std            230.99886
Q Predictions Max            1141.5325
Q Predictions Min            217.40785
V Predictions Mean           939.5511
V Predictions Std            230.56235
V Predictions Max            1153.8776
V Predictions Min            217.99712
Log Pis Mean                 -1.068821
Log Pis Std                  2.5195622
Log Pis Max                  10.198889
Log Pis Min                  -9.6985
Policy mu Mean               -0.0072131553
Policy mu Std                0.5277378
Policy mu Max                2.0445693
Policy mu Min                -1.6975014
Policy log std Mean          -0.89496636
Policy log std Std           0.25325644
Policy log std Max           -0.2899487
Policy log std Min           -2.8082244
Z mean eval                  0.93767816
Z variance eval              0.022560755
total_rewards                [ 480.58611292 2316.94700398 2237.48659826 2145.21470229 2145.75820784
 2219.88649086 1540.17366325 2160.58209698 2526.94960176 2435.52428713]
total_rewards_mean           2020.9108765272322
total_rewards_std            570.6459665542699
total_rewards_max            2526.9496017616893
total_rewards_min            480.5861129238513
Number of train steps total  265000
Number of env steps total    1327000
Number of rollouts total     0
Train Time (s)               27.616259199101478
(Previous) Eval Time (s)     18.609000836964697
Sample Time (s)              18.261350391432643
Epoch Time (s)               64.48661042749882
Total Train Time (s)         18393.623733310495
Epoch                        264
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:22:05.603159 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #264 | Epoch Duration: 73.13734173774719
2020-01-11 08:22:05.603375 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #264 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93655765
Z variance train             0.022485124
KL Divergence                19.928944
KL Loss                      1.9928944
QF Loss                      671.58984
VF Loss                      364.00177
Policy Loss                  -927.1595
Q Predictions Mean           929.21936
Q Predictions Std            251.09755
Q Predictions Max            1178.5479
Q Predictions Min            27.824406
V Predictions Mean           937.34326
V Predictions Std            251.94325
V Predictions Max            1186.6084
V Predictions Min            43.67303
Log Pis Mean                 -0.5886258
Log Pis Std                  2.9512146
Log Pis Max                  14.817766
Log Pis Min                  -7.9653544
Policy mu Mean               -0.028695853
Policy mu Std                0.55096203
Policy mu Max                1.9703089
Policy mu Min                -2.5072446
Policy log std Mean          -0.9422263
Policy log std Std           0.3024558
Policy log std Max           -0.16707164
Policy log std Min           -3.200778
Z mean eval                  0.9350117
Z variance eval              0.019623805
total_rewards                [2705.4835373  2772.54010091 1704.68980366 2668.50541348 2715.39705883
 2639.93563577 2848.43321871 2583.35819394   78.58540037 2709.26746287]
total_rewards_mean           2342.6195825845894
total_rewards_std            814.3157693073841
total_rewards_max            2848.4332187129257
total_rewards_min            78.58540037322302
Number of train steps total  266000
Number of env steps total    1332000
Number of rollouts total     0
Train Time (s)               28.598074399400502
(Previous) Eval Time (s)     27.259424154181033
Sample Time (s)              18.259149289689958
Epoch Time (s)               74.1166478432715
Total Train Time (s)         18464.477830617223
Epoch                        265
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:23:16.459263 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #265 | Epoch Duration: 70.85575151443481
2020-01-11 08:23:16.459449 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #265 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9346911
Z variance train             0.01965185
KL Divergence                19.912933
KL Loss                      1.9912933
QF Loss                      877.54834
VF Loss                      254.60023
Policy Loss                  -940.7421
Q Predictions Mean           941.505
Q Predictions Std            217.9322
Q Predictions Max            1192.389
Q Predictions Min            217.17151
V Predictions Mean           942.2827
V Predictions Std            215.67148
V Predictions Max            1166.7902
V Predictions Min            212.58684
Log Pis Mean                 -1.0352967
Log Pis Std                  2.4439616
Log Pis Max                  9.812263
Log Pis Min                  -7.0683756
Policy mu Mean               0.040859863
Policy mu Std                0.5374054
Policy mu Max                1.9172431
Policy mu Min                -2.4562085
Policy log std Mean          -0.9089472
Policy log std Std           0.24512118
Policy log std Max           -0.20901263
Policy log std Min           -2.1651902
Z mean eval                  0.9613374
Z variance eval              0.020611543
total_rewards                [2680.14739566 2536.52402795 1949.01509215 2516.72350792 2382.86782997
 2407.38702888  252.28407178 2658.380261   2241.39581776  707.59915006]
total_rewards_mean           2033.2324183125195
total_rewards_std            808.5862117722824
total_rewards_max            2680.1473956610107
total_rewards_min            252.2840717782916
Number of train steps total  267000
Number of env steps total    1337000
Number of rollouts total     0
Train Time (s)               26.430531528778374
(Previous) Eval Time (s)     23.998253948055208
Sample Time (s)              18.647133784368634
Epoch Time (s)               69.07591926120222
Total Train Time (s)         18536.592202575877
Epoch                        266
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:24:28.576989 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #266 | Epoch Duration: 72.11740326881409
2020-01-11 08:24:28.577149 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #266 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.960807
Z variance train             0.02060557
KL Divergence                19.985966
KL Loss                      1.9985965
QF Loss                      848.369
VF Loss                      90.53276
Policy Loss                  -945.1085
Q Predictions Mean           944.59845
Q Predictions Std            237.18134
Q Predictions Max            1175.7645
Q Predictions Min            157.97496
V Predictions Mean           946.76355
V Predictions Std            236.71411
V Predictions Max            1162.2561
V Predictions Min            167.97229
Log Pis Mean                 -1.0641508
Log Pis Std                  2.5813777
Log Pis Max                  11.421577
Log Pis Min                  -9.829818
Policy mu Mean               0.005550222
Policy mu Std                0.5447575
Policy mu Max                2.9853616
Policy mu Min                -1.9979098
Policy log std Mean          -0.8969818
Policy log std Std           0.24545677
Policy log std Max           -0.14156938
Policy log std Min           -1.9388577
Z mean eval                  0.97309196
Z variance eval              0.018782884
total_rewards                [ 189.86782478 1984.9485672   169.390612    710.19842791 2621.10821352
 1847.49814351 2744.62611879 2746.91371919 2189.5445928  2665.22773077]
total_rewards_mean           1786.9323950472312
total_rewards_std            991.835737290704
total_rewards_max            2746.9137191923583
total_rewards_min            169.39061199952283
Number of train steps total  268000
Number of env steps total    1342000
Number of rollouts total     0
Train Time (s)               28.390909078065306
(Previous) Eval Time (s)     27.03944656299427
Sample Time (s)              17.81749355746433
Epoch Time (s)               73.24784919852391
Total Train Time (s)         18603.635010964237
Epoch                        267
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:25:35.621091 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #267 | Epoch Duration: 67.04381585121155
2020-01-11 08:25:35.621250 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #267 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9730695
Z variance train             0.018711997
KL Divergence                20.780556
KL Loss                      2.0780556
QF Loss                      1632.5986
VF Loss                      541.0375
Policy Loss                  -954.1827
Q Predictions Mean           952.113
Q Predictions Std            220.11331
Q Predictions Max            1230.9729
Q Predictions Min            163.06963
V Predictions Mean           937.4934
V Predictions Std            213.63902
V Predictions Max            1210.862
V Predictions Min            162.02379
Log Pis Mean                 -0.9475565
Log Pis Std                  2.7196786
Log Pis Max                  8.868357
Log Pis Min                  -10.539837
Policy mu Mean               -0.012185356
Policy mu Std                0.54432154
Policy mu Max                1.9378135
Policy mu Min                -2.4087427
Policy log std Mean          -0.9466716
Policy log std Std           0.27746677
Policy log std Max           -0.25460112
Policy log std Min           -2.2659364
Z mean eval                  0.97276336
Z variance eval              0.017586034
total_rewards                [2118.88200635  120.5940651   329.50211996 2326.20381677  466.47801754
 1697.53646997 2394.63603113   33.50403503 1788.2756482  2518.88318757]
total_rewards_mean           1379.4495397605426
total_rewards_std            968.1181621215087
total_rewards_max            2518.883187566143
total_rewards_min            33.50403503151371
Number of train steps total  269000
Number of env steps total    1347000
Number of rollouts total     0
Train Time (s)               29.834383898880333
(Previous) Eval Time (s)     20.835119815077633
Sample Time (s)              17.9646168127656
Epoch Time (s)               68.63412052672356
Total Train Time (s)         18675.349455229472
Epoch                        268
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:26:47.340377 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #268 | Epoch Duration: 71.7190055847168
2020-01-11 08:26:47.340572 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #268 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97230065
Z variance train             0.017570833
KL Divergence                20.717579
KL Loss                      2.071758
QF Loss                      596.39453
VF Loss                      245.22083
Policy Loss                  -951.20544
Q Predictions Mean           949.2621
Q Predictions Std            241.83994
Q Predictions Max            1188.2013
Q Predictions Min            211.91777
V Predictions Mean           961.394
V Predictions Std            239.36082
V Predictions Max            1201.4502
V Predictions Min            223.86209
Log Pis Mean                 -0.9304898
Log Pis Std                  2.75157
Log Pis Max                  9.401225
Log Pis Min                  -8.143623
Policy mu Mean               0.024979781
Policy mu Std                0.5215995
Policy mu Max                1.9342264
Policy mu Min                -2.1527903
Policy log std Mean          -0.93968385
Policy log std Std           0.2694295
Policy log std Max           -0.2599188
Policy log std Min           -1.9815333
Z mean eval                  0.94810647
Z variance eval              0.020062488
total_rewards                [2770.01899255 2787.94925448 2747.60794526 1028.91994683 2710.94018341
 1458.22553726 2762.06632807 2827.7981631  1359.95149886  932.56037185]
total_rewards_mean           2138.6038221688914
total_rewards_std            783.4307266399943
total_rewards_max            2827.798163103256
total_rewards_min            932.5603718521982
Number of train steps total  270000
Number of env steps total    1352000
Number of rollouts total     0
Train Time (s)               31.75892403628677
(Previous) Eval Time (s)     23.91973400488496
Sample Time (s)              18.408568614162505
Epoch Time (s)               74.08722665533423
Total Train Time (s)         18750.266314502805
Epoch                        269
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:28:02.258844 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #269 | Epoch Duration: 74.9181261062622
2020-01-11 08:28:02.259086 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #269 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94911146
Z variance train             0.020023603
KL Divergence                20.824099
KL Loss                      2.0824099
QF Loss                      1281.7631
VF Loss                      93.952774
Policy Loss                  -975.1322
Q Predictions Mean           974.3658
Q Predictions Std            199.88245
Q Predictions Max            1166.4221
Q Predictions Min            -31.952728
V Predictions Mean           976.9514
V Predictions Std            197.24785
V Predictions Max            1165.0695
V Predictions Min            27.624989
Log Pis Mean                 -0.93354267
Log Pis Std                  2.4731035
Log Pis Max                  8.485842
Log Pis Min                  -8.36191
Policy mu Mean               -0.0031338627
Policy mu Std                0.55512494
Policy mu Max                2.2712328
Policy mu Min                -1.8365124
Policy log std Mean          -0.9092028
Policy log std Std           0.26113936
Policy log std Max           -0.20468473
Policy log std Min           -2.8673708
Z mean eval                  0.9840268
Z variance eval              0.017936615
total_rewards                [ 558.98559429 1067.98359828 1400.31502007  613.64153043  585.80703615
  188.49335824  860.552264   2443.59770402  234.89846713  582.8014091 ]
total_rewards_mean           853.7075981723258
total_rewards_std            631.4728539315911
total_rewards_max            2443.597704015351
total_rewards_min            188.49335824351155
Number of train steps total  271000
Number of env steps total    1357000
Number of rollouts total     0
Train Time (s)               28.919176320079714
(Previous) Eval Time (s)     24.750281310174614
Sample Time (s)              18.591629980131984
Epoch Time (s)               72.26108761038631
Total Train Time (s)         18809.965902919415
Epoch                        270
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:29:01.961064 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #270 | Epoch Duration: 59.70177984237671
2020-01-11 08:29:01.961241 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #270 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97856176
Z variance train             0.017903369
KL Divergence                20.889008
KL Loss                      2.0889008
QF Loss                      604.50397
VF Loss                      406.5916
Policy Loss                  -974.7683
Q Predictions Mean           970.25
Q Predictions Std            205.47226
Q Predictions Max            1148.0773
Q Predictions Min            201.18466
V Predictions Mean           957.1553
V Predictions Std            201.8206
V Predictions Max            1134.1938
V Predictions Min            185.1465
Log Pis Mean                 -0.814245
Log Pis Std                  2.2504127
Log Pis Max                  8.664513
Log Pis Min                  -7.1079226
Policy mu Mean               0.016407836
Policy mu Std                0.52810484
Policy mu Max                2.1576633
Policy mu Min                -2.419011
Policy log std Mean          -0.9317478
Policy log std Std           0.25369886
Policy log std Max           -0.28760326
Policy log std Min           -2.1760304
Z mean eval                  0.96157044
Z variance eval              0.018411702
total_rewards                [ 724.62354845 2448.75235289 1090.76516313 2777.7195147  1070.66569208
 2770.04637958 2235.41778433 2178.07902307  298.72112767 1901.97477906]
total_rewards_mean           1749.6765364948417
total_rewards_std            841.4646240515457
total_rewards_max            2777.719514695438
total_rewards_min            298.72112767087657
Number of train steps total  272000
Number of env steps total    1362000
Number of rollouts total     0
Train Time (s)               28.27397532714531
(Previous) Eval Time (s)     12.190696700941771
Sample Time (s)              17.389723810832947
Epoch Time (s)               57.85439583892003
Total Train Time (s)         18878.89904190181
Epoch                        271
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:30:10.895864 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #271 | Epoch Duration: 68.9344642162323
2020-01-11 08:30:10.896040 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #271 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96388274
Z variance train             0.018394046
KL Divergence                21.228397
KL Loss                      2.1228397
QF Loss                      842.16315
VF Loss                      95.63217
Policy Loss                  -945.97003
Q Predictions Mean           945.38385
Q Predictions Std            238.84924
Q Predictions Max            1241.5853
Q Predictions Min            25.553167
V Predictions Mean           951.07996
V Predictions Std            240.26776
V Predictions Max            1237.9379
V Predictions Min            9.523024
Log Pis Mean                 -0.9939533
Log Pis Std                  2.7943068
Log Pis Max                  9.7239065
Log Pis Min                  -12.136492
Policy mu Mean               0.016068427
Policy mu Std                0.5811491
Policy mu Max                2.2883022
Policy mu Min                -2.6678658
Policy log std Mean          -0.88006943
Policy log std Std           0.25522658
Policy log std Max           -0.2343775
Policy log std Min           -2.4360814
Z mean eval                  0.94661725
Z variance eval              0.017932173
total_rewards                [2643.81661764 2592.11422213 1907.20418241 2778.57784015 2699.87921409
 2498.24431953 2830.23376493 2422.25524592 2612.87922146 2578.11420457]
total_rewards_mean           2556.3318832835175
total_rewards_std            245.0193562930265
total_rewards_max            2830.2337649290344
total_rewards_min            1907.2041824074274
Number of train steps total  273000
Number of env steps total    1367000
Number of rollouts total     0
Train Time (s)               26.906636844854802
(Previous) Eval Time (s)     23.27047092700377
Sample Time (s)              17.50559878302738
Epoch Time (s)               67.68270655488595
Total Train Time (s)         18949.28200466791
Epoch                        272
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:31:21.281999 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #272 | Epoch Duration: 70.38579964637756
2020-01-11 08:31:21.282171 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #272 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9476099
Z variance train             0.017984526
KL Divergence                21.434166
KL Loss                      2.1434166
QF Loss                      1259.5568
VF Loss                      331.2734
Policy Loss                  -952.659
Q Predictions Mean           951.494
Q Predictions Std            248.72667
Q Predictions Max            1195.1526
Q Predictions Min            61.474785
V Predictions Mean           964.6294
V Predictions Std            251.23184
V Predictions Max            1205.0487
V Predictions Min            11.611884
Log Pis Mean                 -0.6042479
Log Pis Std                  2.5802462
Log Pis Max                  9.855669
Log Pis Min                  -11.8867035
Policy mu Mean               0.061376624
Policy mu Std                0.5479968
Policy mu Max                3.0108676
Policy mu Min                -1.9970524
Policy log std Mean          -0.9368279
Policy log std Std           0.26901367
Policy log std Max           -0.16654408
Policy log std Min           -2.4300387
Z mean eval                  0.9845239
Z variance eval              0.029411893
total_rewards                [1957.94386817 2455.67712336 1327.17467798 2425.1599182  2327.03106003
 1386.01366687  646.53991737 2234.2483797   826.39706223 1456.84278006]
total_rewards_mean           1704.302845397929
total_rewards_std            633.3652822701233
total_rewards_max            2455.677123363509
total_rewards_min            646.5399173747008
Number of train steps total  274000
Number of env steps total    1372000
Number of rollouts total     0
Train Time (s)               29.613697161898017
(Previous) Eval Time (s)     25.97328896773979
Sample Time (s)              19.21489203348756
Epoch Time (s)               74.80187816312537
Total Train Time (s)         19018.243637294974
Epoch                        273
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:32:30.245560 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #273 | Epoch Duration: 68.96322798728943
2020-01-11 08:32:30.245790 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #273 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9834347
Z variance train             0.02943967
KL Divergence                21.31956
KL Loss                      2.1319559
QF Loss                      1264.8815
VF Loss                      252.52661
Policy Loss                  -970.0892
Q Predictions Mean           969.9731
Q Predictions Std            253.18262
Q Predictions Max            1177.8267
Q Predictions Min            27.10243
V Predictions Mean           971.15076
V Predictions Std            252.24634
V Predictions Max            1184.4899
V Predictions Min            121.64522
Log Pis Mean                 -0.64262843
Log Pis Std                  2.9535525
Log Pis Max                  12.361588
Log Pis Min                  -10.93326
Policy mu Mean               0.040661514
Policy mu Std                0.568814
Policy mu Max                2.924331
Policy mu Min                -2.1224544
Policy log std Mean          -0.91623235
Policy log std Std           0.28145573
Policy log std Max           0.04530078
Policy log std Min           -2.6083484
Z mean eval                  0.9413112
Z variance eval              0.02506803
total_rewards                [2748.00553297  101.42249601 1142.09011423 2956.24659172 2938.79909345
 2829.5584564  1806.3086598  3047.07633022  790.57475491   87.3320663 ]
total_rewards_mean           1844.7414096016662
total_rewards_std            1157.4920141599582
total_rewards_max            3047.0763302198056
total_rewards_min            87.33206630156067
Number of train steps total  275000
Number of env steps total    1377000
Number of rollouts total     0
Train Time (s)               27.75840541580692
(Previous) Eval Time (s)     20.134307294152677
Sample Time (s)              17.95676493551582
Epoch Time (s)               65.84947764547542
Total Train Time (s)         19081.374750651885
Epoch                        274
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:33:33.379572 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #274 | Epoch Duration: 63.13360095024109
2020-01-11 08:33:33.379769 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #274 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9420477
Z variance train             0.025109794
KL Divergence                21.160007
KL Loss                      2.116001
QF Loss                      609.8369
VF Loss                      165.52493
Policy Loss                  -963.55695
Q Predictions Mean           961.8228
Q Predictions Std            256.38867
Q Predictions Max            1194.0923
Q Predictions Min            192.20062
V Predictions Mean           960.4851
V Predictions Std            257.50616
V Predictions Max            1185.6235
V Predictions Min            189.03493
Log Pis Mean                 -0.6180699
Log Pis Std                  2.8699381
Log Pis Max                  8.320943
Log Pis Min                  -9.18242
Policy mu Mean               0.01849006
Policy mu Std                0.58698756
Policy mu Max                2.0264938
Policy mu Min                -3.0681586
Policy log std Mean          -0.920218
Policy log std Std           0.25651285
Policy log std Max           -0.22916245
Policy log std Min           -2.2610042
Z mean eval                  0.9607369
Z variance eval              0.023676531
total_rewards                [2787.7601588  2591.79667255 2385.82477972 2608.86573367    5.65514661
 1004.12976302 2926.11938001 1530.81425021 2650.92575052 2744.28008078]
total_rewards_mean           2123.6171715895057
total_rewards_std            914.4514218327171
total_rewards_max            2926.119380014972
total_rewards_min            5.655146611401172
Number of train steps total  276000
Number of env steps total    1382000
Number of rollouts total     0
Train Time (s)               28.94559695199132
(Previous) Eval Time (s)     17.418141006026417
Sample Time (s)              17.694401894696057
Epoch Time (s)               64.0581398527138
Total Train Time (s)         19151.671235559974
Epoch                        275
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:34:43.678046 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #275 | Epoch Duration: 70.29811120033264
2020-01-11 08:34:43.678210 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #275 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96206367
Z variance train             0.023673156
KL Divergence                21.225895
KL Loss                      2.1225896
QF Loss                      612.12366
VF Loss                      96.99818
Policy Loss                  -951.90497
Q Predictions Mean           949.9511
Q Predictions Std            262.55035
Q Predictions Max            1169.5952
Q Predictions Min            46.80893
V Predictions Mean           955.66315
V Predictions Std            261.17352
V Predictions Max            1173.6406
V Predictions Min            43.6692
Log Pis Mean                 -0.9899842
Log Pis Std                  2.547952
Log Pis Max                  10.013716
Log Pis Min                  -8.898963
Policy mu Mean               -0.0044309366
Policy mu Std                0.5395897
Policy mu Max                1.8894162
Policy mu Min                -2.727322
Policy log std Mean          -0.9306141
Policy log std Std           0.2782037
Policy log std Max           -0.24921727
Policy log std Min           -3.1583633
Z mean eval                  0.9411913
Z variance eval              0.01900946
total_rewards                [2473.12049841 1094.67684958  839.526845   2284.49411419 2404.98721218
 2853.31058717 2938.84879781  257.83229776 2784.54997784  729.6461021 ]
total_rewards_mean           1866.0993282038767
total_rewards_std            965.9115187137352
total_rewards_max            2938.8487978085386
total_rewards_min            257.83229776187045
Number of train steps total  277000
Number of env steps total    1387000
Number of rollouts total     0
Train Time (s)               27.214037312660366
(Previous) Eval Time (s)     23.657817136030644
Sample Time (s)              17.427150243427604
Epoch Time (s)               68.29900469211861
Total Train Time (s)         19216.881542794872
Epoch                        276
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:35:48.890612 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #276 | Epoch Duration: 65.21225476264954
2020-01-11 08:35:48.890805 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #276 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94131726
Z variance train             0.01895076
KL Divergence                20.969387
KL Loss                      2.0969388
QF Loss                      688.0587
VF Loss                      290.23523
Policy Loss                  -965.6133
Q Predictions Mean           964.79083
Q Predictions Std            241.15952
Q Predictions Max            1157.556
Q Predictions Min            -13.843012
V Predictions Mean           974.4971
V Predictions Std            242.74596
V Predictions Max            1180.0726
V Predictions Min            15.781375
Log Pis Mean                 -0.9325637
Log Pis Std                  2.3628807
Log Pis Max                  6.875214
Log Pis Min                  -8.764905
Policy mu Mean               -0.0025807477
Policy mu Std                0.5530358
Policy mu Max                1.8832563
Policy mu Min                -1.795576
Policy log std Mean          -0.93661064
Policy log std Std           0.26013044
Policy log std Max           -0.22256637
Policy log std Min           -2.2319117
Z mean eval                  0.9665712
Z variance eval              0.018633017
total_rewards                [2749.35707921  686.36090638 1099.03044294 2482.08710882  328.11385861
 2679.42332113 1585.42713021 2459.70932354 2609.53769395 1871.62007758]
total_rewards_mean           1855.0666942354285
total_rewards_std            845.5366013891415
total_rewards_max            2749.3570792099663
total_rewards_min            328.1138586147534
Number of train steps total  278000
Number of env steps total    1392000
Number of rollouts total     0
Train Time (s)               30.134988063015044
(Previous) Eval Time (s)     20.5707746129483
Sample Time (s)              18.03553053177893
Epoch Time (s)               68.74129320774227
Total Train Time (s)         19288.395596046932
Epoch                        277
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:37:00.407721 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #277 | Epoch Duration: 71.51675629615784
2020-01-11 08:37:00.407914 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #277 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9659751
Z variance train             0.018577872
KL Divergence                21.342896
KL Loss                      2.1342895
QF Loss                      674.29065
VF Loss                      287.6961
Policy Loss                  -969.2947
Q Predictions Mean           968.3994
Q Predictions Std            248.41695
Q Predictions Max            1201.7563
Q Predictions Min            0.96247566
V Predictions Mean           980.1164
V Predictions Std            244.24626
V Predictions Max            1208.7864
V Predictions Min            6.0451813
Log Pis Mean                 -0.44868708
Log Pis Std                  2.9203372
Log Pis Max                  10.719087
Log Pis Min                  -12.413293
Policy mu Mean               0.05370553
Policy mu Std                0.58334374
Policy mu Max                2.7794292
Policy mu Min                -2.9407995
Policy log std Mean          -0.9143796
Policy log std Std           0.25854474
Policy log std Max           -0.19749957
Policy log std Min           -1.8903401
Z mean eval                  0.9817233
Z variance eval              0.013863939
total_rewards                [2564.60923081 2527.82046308  416.5956276   135.79511109 1288.20614402
 2509.00365213 2711.09890859  861.56968375 2725.226881    695.11905839]
total_rewards_mean           1643.5044760469657
total_rewards_std            1005.2365625994341
total_rewards_max            2725.2268810006813
total_rewards_min            135.795111092296
Number of train steps total  279000
Number of env steps total    1397000
Number of rollouts total     0
Train Time (s)               26.916435678955168
(Previous) Eval Time (s)     23.345904739107937
Sample Time (s)              18.035858403425664
Epoch Time (s)               68.29819882148877
Total Train Time (s)         19351.935573165305
Epoch                        278
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:38:03.949473 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #278 | Epoch Duration: 63.54137420654297
2020-01-11 08:38:03.949641 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #278 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9816324
Z variance train             0.013869239
KL Divergence                21.434872
KL Loss                      2.1434872
QF Loss                      471.97577
VF Loss                      83.84941
Policy Loss                  -1017.2503
Q Predictions Mean           1016.02264
Q Predictions Std            186.81361
Q Predictions Max            1231.208
Q Predictions Min            197.51277
V Predictions Mean           1016.30774
V Predictions Std            185.22737
V Predictions Max            1215.5858
V Predictions Min            202.81985
Log Pis Mean                 -0.33598834
Log Pis Std                  2.6981494
Log Pis Max                  8.769824
Log Pis Min                  -7.336196
Policy mu Mean               -0.000827322
Policy mu Std                0.5666678
Policy mu Max                2.382897
Policy mu Min                -2.2416494
Policy log std Mean          -0.9437562
Policy log std Std           0.25680655
Policy log std Max           -0.2794544
Policy log std Min           -2.4850667
Z mean eval                  1.0034134
Z variance eval              0.013064869
total_rewards                [2699.42816611 1222.20132363 2772.91826125 2785.61883157  118.23092954
 1702.04660164 1129.01841665  634.59467924  142.43857271  -44.14110322]
total_rewards_mean           1316.2354679112743
total_rewards_std            1073.0913172176186
total_rewards_max            2785.618831574092
total_rewards_min            -44.14110322497466
Number of train steps total  280000
Number of env steps total    1402000
Number of rollouts total     0
Train Time (s)               28.214889065828174
(Previous) Eval Time (s)     18.588782225269824
Sample Time (s)              18.44725735904649
Epoch Time (s)               65.25092865014449
Total Train Time (s)         19414.048739335965
Epoch                        279
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:39:06.064657 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #279 | Epoch Duration: 62.11488127708435
2020-01-11 08:39:06.064850 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #279 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.00324
Z variance train             0.013069252
KL Divergence                21.890858
KL Loss                      2.1890857
QF Loss                      1217.9052
VF Loss                      84.050476
Policy Loss                  -984.87854
Q Predictions Mean           981.9866
Q Predictions Std            238.74878
Q Predictions Max            1197.3895
Q Predictions Min            66.39337
V Predictions Mean           981.7793
V Predictions Std            233.32538
V Predictions Max            1187.1978
V Predictions Min            203.93323
Log Pis Mean                 -1.083596
Log Pis Std                  2.8087487
Log Pis Max                  9.799165
Log Pis Min                  -9.629069
Policy mu Mean               0.048304453
Policy mu Std                0.5501197
Policy mu Max                2.2579613
Policy mu Min                -1.7856241
Policy log std Mean          -0.91756916
Policy log std Std           0.2615818
Policy log std Max           -0.17663443
Policy log std Min           -2.2849445
Z mean eval                  0.9725062
Z variance eval              0.018030861
total_rewards                [2723.11805861 3019.20253593 2672.02604322  462.66381342 2682.74947059
 1213.52823829  346.92597061 2717.06575985 2751.31612838 2960.77607325]
total_rewards_mean           2154.93720921386
total_rewards_std            997.7839451072631
total_rewards_max            3019.2025359322497
total_rewards_min            346.9259706109066
Number of train steps total  281000
Number of env steps total    1407000
Number of rollouts total     0
Train Time (s)               28.39891829714179
(Previous) Eval Time (s)     15.452423000242561
Sample Time (s)              18.006762318313122
Epoch Time (s)               61.85810361569747
Total Train Time (s)         19482.796999422833
Epoch                        280
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:40:14.815767 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #280 | Epoch Duration: 68.75079321861267
2020-01-11 08:40:14.815943 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #280 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97250384
Z variance train             0.018100059
KL Divergence                20.451563
KL Loss                      2.0451562
QF Loss                      965.86646
VF Loss                      180.21439
Policy Loss                  -999.5759
Q Predictions Mean           997.17175
Q Predictions Std            209.71596
Q Predictions Max            1215.5778
Q Predictions Min            186.88666
V Predictions Mean           991.49316
V Predictions Std            206.88573
V Predictions Max            1217.4894
V Predictions Min            196.11752
Log Pis Mean                 -0.5740268
Log Pis Std                  2.4754252
Log Pis Max                  12.710774
Log Pis Min                  -7.1575313
Policy mu Mean               0.0007742818
Policy mu Std                0.5809941
Policy mu Max                1.9940453
Policy mu Min                -3.5542603
Policy log std Mean          -0.91457456
Policy log std Std           0.25755316
Policy log std Max           -0.15064347
Policy log std Min           -2.531649
Z mean eval                  0.98456347
Z variance eval              0.01333523
total_rewards                [1498.73083882 2780.5673771  2743.59852653  188.36265347  585.94620545
   78.74244782  275.07372816 1795.6138714  1368.48739427  750.51643075]
total_rewards_mean           1206.5639473782646
total_rewards_std            952.2634908305721
total_rewards_max            2780.5673771045213
total_rewards_min            78.7424478171285
Number of train steps total  282000
Number of env steps total    1412000
Number of rollouts total     0
Train Time (s)               29.398831170983613
(Previous) Eval Time (s)     22.344789501279593
Sample Time (s)              18.054657140746713
Epoch Time (s)               69.79827781300992
Total Train Time (s)         19547.40380659001
Epoch                        281
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:41:19.425027 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #281 | Epoch Duration: 64.60894560813904
2020-01-11 08:41:19.425210 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #281 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98316395
Z variance train             0.013319841
KL Divergence                21.13892
KL Loss                      2.113892
QF Loss                      1097.8367
VF Loss                      170.1114
Policy Loss                  -977.745
Q Predictions Mean           976.5045
Q Predictions Std            240.53084
Q Predictions Max            1206.1165
Q Predictions Min            187.35388
V Predictions Mean           976.7007
V Predictions Std            235.86725
V Predictions Max            1196.5977
V Predictions Min            192.52643
Log Pis Mean                 -0.59395635
Log Pis Std                  2.5288472
Log Pis Max                  9.159933
Log Pis Min                  -7.7777705
Policy mu Mean               0.00093196565
Policy mu Std                0.57756716
Policy mu Max                2.3353224
Policy mu Min                -2.9391282
Policy log std Mean          -0.9078336
Policy log std Std           0.27221707
Policy log std Max           -0.24292979
Policy log std Min           -2.7346108
Z mean eval                  0.9891645
Z variance eval              0.012197351
total_rewards                [1429.48783107  536.21369272 1281.89997937  451.33097444 1222.97288966
 2085.95209523  632.17533606  206.5228879  2003.30347524  301.29791586]
total_rewards_mean           1015.1157077545179
total_rewards_std            653.1837587471001
total_rewards_max            2085.9520952292614
total_rewards_min            206.52288790371244
Number of train steps total  283000
Number of env steps total    1417000
Number of rollouts total     0
Train Time (s)               26.604722534306347
(Previous) Eval Time (s)     17.155190762598068
Sample Time (s)              17.677926021628082
Epoch Time (s)               61.4378393185325
Total Train Time (s)         19606.636247057468
Epoch                        282
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:42:18.664179 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #282 | Epoch Duration: 59.23879361152649
2020-01-11 08:42:18.664454 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #282 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98751765
Z variance train             0.012199576
KL Divergence                21.708883
KL Loss                      2.1708884
QF Loss                      785.8716
VF Loss                      142.16093
Policy Loss                  -985.7951
Q Predictions Mean           983.2407
Q Predictions Std            246.9486
Q Predictions Max            1244.2126
Q Predictions Min            189.71196
V Predictions Mean           984.02893
V Predictions Std            242.29588
V Predictions Max            1242.8679
V Predictions Min            204.53743
Log Pis Mean                 -0.928576
Log Pis Std                  2.4446416
Log Pis Max                  6.6338334
Log Pis Min                  -8.163437
Policy mu Mean               0.0046418835
Policy mu Std                0.5543156
Policy mu Max                2.0014572
Policy mu Min                -2.2173867
Policy log std Mean          -0.889307
Policy log std Std           0.257624
Policy log std Max           -0.16574174
Policy log std Min           -2.3974257
Z mean eval                  0.9948322
Z variance eval              0.012822755
total_rewards                [2699.70729982 1504.44859205 1762.67179006 2716.26600341 2432.39734827
  791.6969955   402.8677789  2604.73577124 1696.99249457 1024.48677434]
total_rewards_mean           1763.6270848152028
total_rewards_std            797.0408724686304
total_rewards_max            2716.2660034090477
total_rewards_min            402.8677789024126
Number of train steps total  284000
Number of env steps total    1422000
Number of rollouts total     0
Train Time (s)               30.072708372958004
(Previous) Eval Time (s)     14.955827474128455
Sample Time (s)              17.804980455432087
Epoch Time (s)               62.83351630251855
Total Train Time (s)         19677.204993563704
Epoch                        283
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:43:29.235173 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #283 | Epoch Duration: 70.57050085067749
2020-01-11 08:43:29.235417 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #283 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9971854
Z variance train             0.012848785
KL Divergence                21.699654
KL Loss                      2.1699655
QF Loss                      898.6343
VF Loss                      163.88783
Policy Loss                  -994.92535
Q Predictions Mean           993.7029
Q Predictions Std            242.70284
Q Predictions Max            1226.5186
Q Predictions Min            153.05249
V Predictions Mean           993.5508
V Predictions Std            239.93051
V Predictions Max            1225.629
V Predictions Min            208.95844
Log Pis Mean                 -0.7192426
Log Pis Std                  2.4939601
Log Pis Max                  9.487399
Log Pis Min                  -7.852015
Policy mu Mean               0.044583343
Policy mu Std                0.5687089
Policy mu Max                2.0252037
Policy mu Min                -1.8942013
Policy log std Mean          -0.92668605
Policy log std Std           0.26300696
Policy log std Max           -0.022086322
Policy log std Min           -2.4736533
Z mean eval                  0.9706335
Z variance eval              0.008642638
total_rewards                [2467.80041285  587.95463136  882.19724784 2762.14012742  175.42332907
 2662.32534308 1958.09438381 2728.22393296 2816.90644963   32.81364111]
total_rewards_mean           1707.3879499120376
total_rewards_std            1096.5314031433863
total_rewards_max            2816.906449627369
total_rewards_min            32.813641114243815
Number of train steps total  285000
Number of env steps total    1427000
Number of rollouts total     0
Train Time (s)               27.451157657895237
(Previous) Eval Time (s)     22.692499585915357
Sample Time (s)              18.536211075261235
Epoch Time (s)               68.67986831907183
Total Train Time (s)         19742.32780171372
Epoch                        284
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:44:34.363958 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #284 | Epoch Duration: 65.12831902503967
2020-01-11 08:44:34.364282 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #284 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.970693
Z variance train             0.008618806
KL Divergence                22.765413
KL Loss                      2.2765415
QF Loss                      1331.8992
VF Loss                      155.51062
Policy Loss                  -992.31055
Q Predictions Mean           991.55927
Q Predictions Std            248.14049
Q Predictions Max            1234.3345
Q Predictions Min            -37.054924
V Predictions Mean           990.41516
V Predictions Std            242.96033
V Predictions Max            1228.0107
V Predictions Min            48.16532
Log Pis Mean                 -0.93615496
Log Pis Std                  2.3824651
Log Pis Max                  6.7202396
Log Pis Min                  -9.345359
Policy mu Mean               0.02586007
Policy mu Std                0.5279806
Policy mu Max                1.740595
Policy mu Min                -1.7286052
Policy log std Mean          -0.94259536
Policy log std Std           0.26272786
Policy log std Max           -0.25017303
Policy log std Min           -2.2158425
Z mean eval                  0.95114404
Z variance eval              0.017058374
total_rewards                [ 332.99439752 1642.49913357   27.070355   1077.52011488  309.80611934
 2739.95030839 1943.51510007  683.92907002 2839.34482115  279.96415068]
total_rewards_mean           1187.6593570613284
total_rewards_std            992.6580463874773
total_rewards_max            2839.3448211478626
total_rewards_min            27.07035500297172
Number of train steps total  286000
Number of env steps total    1432000
Number of rollouts total     0
Train Time (s)               27.93633846612647
(Previous) Eval Time (s)     19.14062048867345
Sample Time (s)              17.75099237728864
Epoch Time (s)               64.82795133208856
Total Train Time (s)         19800.618681967724
Epoch                        285
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:45:32.656063 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #285 | Epoch Duration: 58.29156565666199
2020-01-11 08:45:32.656238 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #285 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95248014
Z variance train             0.017053977
KL Divergence                21.107704
KL Loss                      2.1107705
QF Loss                      1206.1846
VF Loss                      140.18236
Policy Loss                  -992.99304
Q Predictions Mean           989.87305
Q Predictions Std            237.9048
Q Predictions Max            1223.4258
Q Predictions Min            163.29108
V Predictions Mean           988.4863
V Predictions Std            235.45836
V Predictions Max            1224.2012
V Predictions Min            177.5927
Log Pis Mean                 -0.81303906
Log Pis Std                  2.6881888
Log Pis Max                  7.3159285
Log Pis Min                  -11.50816
Policy mu Mean               0.04995314
Policy mu Std                0.5570719
Policy mu Max                2.3145258
Policy mu Min                -2.0927672
Policy log std Mean          -0.90815794
Policy log std Std           0.26572114
Policy log std Max           -0.087248385
Policy log std Min           -2.2150912
Z mean eval                  0.9889906
Z variance eval              0.019622155
total_rewards                [ 406.4961589  2735.2403834  2256.54527646 2681.63750842 2734.5834724
 2667.71993843 3003.22224094  419.0213502  2667.17918206 2885.03424668]
total_rewards_mean           2245.6679757892043
total_rewards_std            934.1614084381222
total_rewards_max            3003.2222409421006
total_rewards_min            406.496158900822
Number of train steps total  287000
Number of env steps total    1437000
Number of rollouts total     0
Train Time (s)               27.558294726070017
(Previous) Eval Time (s)     12.60396349336952
Sample Time (s)              17.731458948459476
Epoch Time (s)               57.89371716789901
Total Train Time (s)         19870.875338524114
Epoch                        286
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:46:42.916172 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #286 | Epoch Duration: 70.2597599029541
2020-01-11 08:46:42.916350 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #286 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98837614
Z variance train             0.01967522
KL Divergence                20.933096
KL Loss                      2.0933096
QF Loss                      719.3629
VF Loss                      447.44626
Policy Loss                  -1040.2999
Q Predictions Mean           1039.502
Q Predictions Std            205.80202
Q Predictions Max            1251.9819
Q Predictions Min            -20.169662
V Predictions Mean           1027.4536
V Predictions Std            203.28615
V Predictions Max            1228.1858
V Predictions Min            83.012344
Log Pis Mean                 -0.5114736
Log Pis Std                  2.63809
Log Pis Max                  10.702351
Log Pis Min                  -8.33171
Policy mu Mean               -0.004221846
Policy mu Std                0.56447
Policy mu Max                1.8380836
Policy mu Min                -2.8506522
Policy log std Mean          -0.97039473
Policy log std Std           0.27283934
Policy log std Max           -0.27633703
Policy log std Min           -2.8501194
Z mean eval                  0.9845462
Z variance eval              0.018725166
total_rewards                [2928.93013424 2720.69585193 1367.54376988 1497.81386086 2965.9145651
 2823.08764161  726.98358529 3161.61636713  894.99426944 3056.83636711]
total_rewards_mean           2214.4416412597975
total_rewards_std            921.5737459552788
total_rewards_max            3161.6163671322174
total_rewards_min            726.9835852940932
Number of train steps total  288000
Number of env steps total    1442000
Number of rollouts total     0
Train Time (s)               27.176779748871922
(Previous) Eval Time (s)     24.969716851133853
Sample Time (s)              17.410834246315062
Epoch Time (s)               69.55733084632084
Total Train Time (s)         19940.23902124772
Epoch                        287
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:47:52.281096 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #287 | Epoch Duration: 69.3646068572998
2020-01-11 08:47:52.281250 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #287 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9850215
Z variance train             0.018688682
KL Divergence                20.70414
KL Loss                      2.070414
QF Loss                      709.7019
VF Loss                      108.89184
Policy Loss                  -979.53485
Q Predictions Mean           977.0354
Q Predictions Std            265.1939
Q Predictions Max            1191.0099
Q Predictions Min            49.783646
V Predictions Mean           979.60785
V Predictions Std            260.8798
V Predictions Max            1192.9882
V Predictions Min            153.99817
Log Pis Mean                 -0.7638339
Log Pis Std                  2.5294235
Log Pis Max                  12.705559
Log Pis Min                  -9.052983
Policy mu Mean               -0.027720567
Policy mu Std                0.57078594
Policy mu Max                2.1787262
Policy mu Min                -2.119836
Policy log std Mean          -0.92665136
Policy log std Std           0.27204382
Policy log std Max           -0.25070179
Policy log std Min           -2.7723763
Z mean eval                  0.9585146
Z variance eval              0.01313054
total_rewards                [ 173.46733619 2711.57495616 3093.06830189  637.65057556 2832.87590981
 2417.67244897 1631.93738465 2896.83091811 2857.00666904 2813.49608625]
total_rewards_mean           2206.558058663878
total_rewards_std            983.4041434954028
total_rewards_max            3093.068301885775
total_rewards_min            173.46733619451743
Number of train steps total  289000
Number of env steps total    1447000
Number of rollouts total     0
Train Time (s)               28.780223749112338
(Previous) Eval Time (s)     24.776719061192125
Sample Time (s)              17.826332496013492
Epoch Time (s)               71.38327530631796
Total Train Time (s)         20010.33339024894
Epoch                        288
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:49:02.379807 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #288 | Epoch Duration: 70.09841060638428
2020-01-11 08:49:02.380007 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #288 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95845044
Z variance train             0.013111906
KL Divergence                20.81727
KL Loss                      2.081727
QF Loss                      646.1208
VF Loss                      200.48392
Policy Loss                  -996.09894
Q Predictions Mean           995.6133
Q Predictions Std            244.66774
Q Predictions Max            1224.1925
Q Predictions Min            196.79826
V Predictions Mean           995.9641
V Predictions Std            244.56224
V Predictions Max            1207.1105
V Predictions Min            197.73965
Log Pis Mean                 -0.7080251
Log Pis Std                  2.7925863
Log Pis Max                  9.470972
Log Pis Min                  -9.027713
Policy mu Mean               -0.031487748
Policy mu Std                0.5478889
Policy mu Max                1.9953502
Policy mu Min                -2.0607772
Policy log std Mean          -0.9604434
Policy log std Std           0.27524307
Policy log std Max           -0.18056703
Policy log std Min           -2.6511383
Z mean eval                  0.9918542
Z variance eval              0.015914151
total_rewards                [ 175.1280809  2916.09860516 2658.63312517 2514.3688019  2824.065807
  996.62272491 2117.53112209 2317.38034675 2749.10655149 2044.71302201]
total_rewards_mean           2131.3648187370677
total_rewards_std            840.1639135807231
total_rewards_max            2916.098605160666
total_rewards_min            175.12808090034164
Number of train steps total  290000
Number of env steps total    1452000
Number of rollouts total     0
Train Time (s)               28.847811996005476
(Previous) Eval Time (s)     23.49155746260658
Sample Time (s)              17.597696573473513
Epoch Time (s)               69.93706603208557
Total Train Time (s)         20079.25471341377
Epoch                        289
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:50:11.305794 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #289 | Epoch Duration: 68.92560172080994
2020-01-11 08:50:11.306083 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #289 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9934894
Z variance train             0.015923847
KL Divergence                20.458597
KL Loss                      2.0458598
QF Loss                      1241.4775
VF Loss                      183.3079
Policy Loss                  -1010.36523
Q Predictions Mean           1007.79565
Q Predictions Std            217.00061
Q Predictions Max            1220.8066
Q Predictions Min            178.89714
V Predictions Mean           1007.571
V Predictions Std            216.96475
V Predictions Max            1218.4756
V Predictions Min            151.69254
Log Pis Mean                 -0.51056874
Log Pis Std                  2.7699246
Log Pis Max                  11.811334
Log Pis Min                  -8.23887
Policy mu Mean               0.019389648
Policy mu Std                0.5457267
Policy mu Max                3.127679
Policy mu Min                -2.108801
Policy log std Mean          -0.9753953
Policy log std Std           0.26657647
Policy log std Max           -0.099070966
Policy log std Min           -2.4155777
Z mean eval                  0.96355516
Z variance eval              0.015808854
total_rewards                [ -68.9823651   460.16492087 2655.48731578 2951.56464719  783.13901203
 2949.71229195  862.86310531 2528.00028379 2807.94684815 2675.23755519]
total_rewards_mean           1860.5133615153204
total_rewards_std            1133.8274276808754
total_rewards_max            2951.564647191349
total_rewards_min            -68.98236510066928
Number of train steps total  291000
Number of env steps total    1457000
Number of rollouts total     0
Train Time (s)               26.626282849814743
(Previous) Eval Time (s)     22.47982009127736
Sample Time (s)              17.621487942989916
Epoch Time (s)               66.72759088408202
Total Train Time (s)         20144.424559214152
Epoch                        290
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:51:16.477759 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #290 | Epoch Duration: 65.17147517204285
2020-01-11 08:51:16.477952 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #290 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9626733
Z variance train             0.015825724
KL Divergence                20.707602
KL Loss                      2.0707603
QF Loss                      2185.0244
VF Loss                      194.93944
Policy Loss                  -1025.5912
Q Predictions Mean           1024.2404
Q Predictions Std            189.85712
Q Predictions Max            1208.8654
Q Predictions Min            184.60144
V Predictions Mean           1028.6564
V Predictions Std            187.37125
V Predictions Max            1213.5773
V Predictions Min            196.70107
Log Pis Mean                 -0.4822239
Log Pis Std                  2.6981933
Log Pis Max                  16.139519
Log Pis Min                  -6.839864
Policy mu Mean               0.039995044
Policy mu Std                0.5623378
Policy mu Max                3.024603
Policy mu Min                -2.620271
Policy log std Mean          -0.9427496
Policy log std Std           0.25161842
Policy log std Max           -0.24505255
Policy log std Min           -2.473021
Z mean eval                  0.9883525
Z variance eval              0.022509474
total_rewards                [  -8.47007751 1791.93701403  884.84843609 2841.53444638 2704.59417001
 2883.44003365 2845.76471514 1144.46259465  632.74019097 2950.6745771 ]
total_rewards_mean           1867.1526100516032
total_rewards_std            1065.3574134016267
total_rewards_max            2950.6745771025962
total_rewards_min            -8.470077514965151
Number of train steps total  292000
Number of env steps total    1462000
Number of rollouts total     0
Train Time (s)               28.75298480130732
(Previous) Eval Time (s)     20.923448436893523
Sample Time (s)              19.132541581522673
Epoch Time (s)               68.80897481972352
Total Train Time (s)         20209.910300896503
Epoch                        291
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:52:21.965794 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #291 | Epoch Duration: 65.48771262168884
2020-01-11 08:52:21.965973 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #291 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98841065
Z variance train             0.022491682
KL Divergence                20.451347
KL Loss                      2.0451348
QF Loss                      674.43176
VF Loss                      130.64
Policy Loss                  -1003.15424
Q Predictions Mean           1001.9164
Q Predictions Std            240.91226
Q Predictions Max            1231.6685
Q Predictions Min            174.65114
V Predictions Mean           996.5497
V Predictions Std            237.06786
V Predictions Max            1228.6523
V Predictions Min            177.61948
Log Pis Mean                 -0.57096475
Log Pis Std                  2.566654
Log Pis Max                  7.6027565
Log Pis Min                  -8.184429
Policy mu Mean               0.055970725
Policy mu Std                0.5325196
Policy mu Max                2.0776591
Policy mu Min                -1.9488724
Policy log std Mean          -0.9462828
Policy log std Std           0.26630655
Policy log std Max           -0.22602636
Policy log std Min           -2.255158
Z mean eval                  1.0062072
Z variance eval              0.018455029
total_rewards                [2652.67525419 1418.48994409  360.73408203 2749.02153333 2762.89996925
 2785.15988748 2750.59822665 2785.13683016 2532.12198297 2802.60331712]
total_rewards_mean           2359.9441027270273
total_rewards_std            776.0427314418394
total_rewards_max            2802.603317123706
total_rewards_min            360.7340820271248
Number of train steps total  293000
Number of env steps total    1467000
Number of rollouts total     0
Train Time (s)               25.911016115918756
(Previous) Eval Time (s)     17.601829512044787
Sample Time (s)              18.252729852683842
Epoch Time (s)               61.765575480647385
Total Train Time (s)         20276.338876459282
Epoch                        292
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:53:28.397927 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #292 | Epoch Duration: 66.43180418014526
2020-01-11 08:53:28.398133 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #292 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0068252
Z variance train             0.018499652
KL Divergence                20.740566
KL Loss                      2.0740566
QF Loss                      3644.1084
VF Loss                      913.843
Policy Loss                  -1040.1288
Q Predictions Mean           1038.3839
Q Predictions Std            222.88094
Q Predictions Max            1235.9335
Q Predictions Min            192.49425
V Predictions Mean           1030.4087
V Predictions Std            218.46826
V Predictions Max            1222.0157
V Predictions Min            182.03763
Log Pis Mean                 -0.66768134
Log Pis Std                  2.60504
Log Pis Max                  10.854344
Log Pis Min                  -9.150272
Policy mu Mean               0.0466723
Policy mu Std                0.56529564
Policy mu Max                2.17443
Policy mu Min                -2.6273994
Policy log std Mean          -0.9448849
Policy log std Std           0.2845296
Policy log std Max           -0.18558556
Policy log std Min           -2.975766
Z mean eval                  0.9796325
Z variance eval              0.015150445
total_rewards                [ 569.80748132  623.33920323  152.53973074  750.27249412 2531.67834375
 2627.67182987  458.16253188 2731.16781594 1825.35656875  830.08686451]
total_rewards_mean           1310.00828641145
total_rewards_std            956.1594134945669
total_rewards_max            2731.1678159407156
total_rewards_min            152.53973073905468
Number of train steps total  294000
Number of env steps total    1472000
Number of rollouts total     0
Train Time (s)               31.104777714703232
(Previous) Eval Time (s)     22.26776241278276
Sample Time (s)              17.60227844817564
Epoch Time (s)               70.97481857566163
Total Train Time (s)         20338.26529416954
Epoch                        293
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:54:30.329960 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #293 | Epoch Duration: 61.93164253234863
2020-01-11 08:54:30.330228 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #293 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9791769
Z variance train             0.01514214
KL Divergence                20.034925
KL Loss                      2.0034926
QF Loss                      719.5033
VF Loss                      115.81386
Policy Loss                  -1003.71356
Q Predictions Mean           1002.64636
Q Predictions Std            243.11014
Q Predictions Max            1273.7958
Q Predictions Min            181.99736
V Predictions Mean           1003.2544
V Predictions Std            243.20854
V Predictions Max            1273.9158
V Predictions Min            174.48927
Log Pis Mean                 -0.6012325
Log Pis Std                  2.9178607
Log Pis Max                  19.126907
Log Pis Min                  -6.6868396
Policy mu Mean               0.04281719
Policy mu Std                0.5643686
Policy mu Max                3.366173
Policy mu Min                -4.378579
Policy log std Mean          -0.9440088
Policy log std Std           0.28387585
Policy log std Max           -0.23371673
Policy log std Min           -2.8292577
Z mean eval                  1.012339
Z variance eval              0.014743145
total_rewards                [ 752.7806644  2807.67197286 2434.34237801 1122.35859333 2753.14999045
 1268.64485868  124.50133193 2306.98728434  991.25512423  694.38750721]
total_rewards_mean           1525.6079705443694
total_rewards_std            913.912564417465
total_rewards_max            2807.671972863221
total_rewards_min            124.50133193252728
Number of train steps total  295000
Number of env steps total    1477000
Number of rollouts total     0
Train Time (s)               28.249680125620216
(Previous) Eval Time (s)     13.224280964583158
Sample Time (s)              17.689317076466978
Epoch Time (s)               59.16327816667035
Total Train Time (s)         20401.578219010495
Epoch                        294
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:55:33.646450 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #294 | Epoch Duration: 63.31600499153137
2020-01-11 08:55:33.646701 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #294 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.014199
Z variance train             0.014645775
KL Divergence                20.644096
KL Loss                      2.0644097
QF Loss                      643.27844
VF Loss                      231.60207
Policy Loss                  -1070.6542
Q Predictions Mean           1068.0854
Q Predictions Std            197.62715
Q Predictions Max            1278.5927
Q Predictions Min            -62.931873
V Predictions Mean           1058.1372
V Predictions Std            188.49379
V Predictions Max            1256.3541
V Predictions Min            -3.317434
Log Pis Mean                 -0.2672299
Log Pis Std                  2.830993
Log Pis Max                  20.9891
Log Pis Min                  -6.8864107
Policy mu Mean               0.023029428
Policy mu Std                0.6090449
Policy mu Max                2.054446
Policy mu Min                -3.196817
Policy log std Mean          -0.9357914
Policy log std Std           0.24300279
Policy log std Max           -0.22364318
Policy log std Min           -2.6083837
Z mean eval                  0.98116094
Z variance eval              0.020908691
total_rewards                [2915.35188468  952.37607084 3183.16685483 3274.68853424  126.14950054
 2193.17668745 2794.66449498 3129.51198426 3058.74375515 2227.876807  ]
total_rewards_mean           2385.570657397904
total_rewards_std            1005.0990202098066
total_rewards_max            3274.688534243922
total_rewards_min            126.14950054189484
Number of train steps total  296000
Number of env steps total    1482000
Number of rollouts total     0
Train Time (s)               31.445467167999595
(Previous) Eval Time (s)     17.376690763048828
Sample Time (s)              17.398818348534405
Epoch Time (s)               66.22097627958283
Total Train Time (s)         20476.63697717944
Epoch                        295
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:56:48.707194 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #295 | Epoch Duration: 75.06030321121216
2020-01-11 08:56:48.707367 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #295 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98099434
Z variance train             0.020935306
KL Divergence                20.43367
KL Loss                      2.0433671
QF Loss                      1733.4856
VF Loss                      303.79425
Policy Loss                  -1009.3521
Q Predictions Mean           1008.0818
Q Predictions Std            271.49478
Q Predictions Max            1240.0647
Q Predictions Min            9.2720785
V Predictions Mean           998.53613
V Predictions Std            265.36163
V Predictions Max            1226.1014
V Predictions Min            159.82417
Log Pis Mean                 -0.6731702
Log Pis Std                  2.4474409
Log Pis Max                  10.403327
Log Pis Min                  -7.7080727
Policy mu Mean               0.0019396106
Policy mu Std                0.5173705
Policy mu Max                1.692059
Policy mu Min                -1.8655103
Policy log std Mean          -0.9721993
Policy log std Std           0.30363813
Policy log std Max           -0.13763654
Policy log std Min           -2.708753
Z mean eval                  1.0203621
Z variance eval              0.015834445
total_rewards                [  74.44250899 2597.50346452 3093.62722267 2657.71473621 2312.02586743
  414.22663678  405.31989716  109.45159763 2068.16369417 1633.15588055]
total_rewards_mean           1536.563150611233
total_rewards_std            1114.1853604634698
total_rewards_max            3093.6272226703495
total_rewards_min            74.44250898974366
Number of train steps total  297000
Number of env steps total    1487000
Number of rollouts total     0
Train Time (s)               28.72117742104456
(Previous) Eval Time (s)     26.215742751024663
Sample Time (s)              18.446811047382653
Epoch Time (s)               73.38373121945187
Total Train Time (s)         20543.16864346806
Epoch                        296
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:57:55.243741 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #296 | Epoch Duration: 66.53622388839722
2020-01-11 08:57:55.243965 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #296 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0218171
Z variance train             0.01584483
KL Divergence                21.281424
KL Loss                      2.1281424
QF Loss                      7941.8164
VF Loss                      255.9177
Policy Loss                  -1013.5749
Q Predictions Mean           1015.9099
Q Predictions Std            253.49915
Q Predictions Max            1254.2598
Q Predictions Min            -14.918844
V Predictions Mean           1024.1212
V Predictions Std            251.16422
V Predictions Max            1260.8378
V Predictions Min            5.0513434
Log Pis Mean                 -0.8360374
Log Pis Std                  2.7956026
Log Pis Max                  11.445609
Log Pis Min                  -11.703376
Policy mu Mean               0.028285515
Policy mu Std                0.5517872
Policy mu Max                2.0793483
Policy mu Min                -2.085218
Policy log std Mean          -0.92284966
Policy log std Std           0.26031077
Policy log std Max           -0.18233222
Policy log std Min           -2.215471
Z mean eval                  1.0061617
Z variance eval              0.013323833
total_rewards                [3093.43755615 2886.20232327 2423.96372768 2729.14742816 2844.77289667
  533.5924521  2641.8788851  1864.05170912 2341.85772469 2956.88990029]
total_rewards_mean           2431.579460322486
total_rewards_std            718.1045136517845
total_rewards_max            3093.437556152457
total_rewards_min            533.5924520962541
Number of train steps total  298000
Number of env steps total    1492000
Number of rollouts total     0
Train Time (s)               28.527733487077057
(Previous) Eval Time (s)     19.367927559651434
Sample Time (s)              18.35458673769608
Epoch Time (s)               66.25024778442457
Total Train Time (s)         20615.036079605576
Epoch                        297
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:59:07.112403 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #297 | Epoch Duration: 71.86828088760376
2020-01-11 08:59:07.112610 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #297 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0061135
Z variance train             0.013313946
KL Divergence                21.242277
KL Loss                      2.1242278
QF Loss                      1160.8334
VF Loss                      141.23807
Policy Loss                  -1052.7239
Q Predictions Mean           1048.9817
Q Predictions Std            197.95969
Q Predictions Max            1260.3365
Q Predictions Min            45.098785
V Predictions Mean           1059.7166
V Predictions Std            194.4307
V Predictions Max            1254.0142
V Predictions Min            191.63202
Log Pis Mean                 -0.2333852
Log Pis Std                  2.614247
Log Pis Max                  13.2809105
Log Pis Min                  -8.200191
Policy mu Mean               -0.0016814738
Policy mu Std                0.5642091
Policy mu Max                1.974562
Policy mu Min                -2.044259
Policy log std Mean          -0.9796079
Policy log std Std           0.28237224
Policy log std Max           -0.17808956
Policy log std Min           -2.9520044
Z mean eval                  1.0069494
Z variance eval              0.025677016
total_rewards                [2912.43392646 2805.28728411 2876.39001051 3021.71382266  431.75149965
    5.85752725 2708.58110965  710.81308168 2995.0803427  2854.3674384 ]
total_rewards_mean           2132.2276043069774
total_rewards_std            1159.2396965549456
total_rewards_max            3021.713822661875
total_rewards_min            5.857527246786799
Number of train steps total  299000
Number of env steps total    1497000
Number of rollouts total     0
Train Time (s)               28.183228339999914
(Previous) Eval Time (s)     24.985637047793716
Sample Time (s)              17.3959924983792
Epoch Time (s)               70.56485788617283
Total Train Time (s)         20683.694337628316
Epoch                        298
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:00:15.777619 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #298 | Epoch Duration: 68.66482782363892
2020-01-11 09:00:15.777911 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #298 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0057617
Z variance train             0.025836026
KL Divergence                19.829573
KL Loss                      1.9829572
QF Loss                      4567.0127
VF Loss                      189.60066
Policy Loss                  -1033.5544
Q Predictions Mean           1030.2817
Q Predictions Std            235.61568
Q Predictions Max            1201.6774
Q Predictions Min            172.0043
V Predictions Mean           1037.1929
V Predictions Std            235.4988
V Predictions Max            1207.4465
V Predictions Min            170.61995
Log Pis Mean                 -0.60154045
Log Pis Std                  2.630797
Log Pis Max                  8.961423
Log Pis Min                  -8.553708
Policy mu Mean               0.045447223
Policy mu Std                0.5616901
Policy mu Max                1.9632881
Policy mu Min                -2.4202948
Policy log std Mean          -0.94319475
Policy log std Std           0.26335096
Policy log std Max           -0.1349113
Policy log std Min           -2.056931
Z mean eval                  0.99307954
Z variance eval              0.020947676
total_rewards                [2790.10892499 2693.53489233 1688.2942517  2959.65491308 2990.93220755
 2770.01966561 2887.01168752 2141.37762698 2852.43866473 2651.29056886]
total_rewards_mean           2642.4663403352915
total_rewards_std            390.9240560678031
total_rewards_max            2990.932207551882
total_rewards_min            1688.294251700738
Number of train steps total  300000
Number of env steps total    1502000
Number of rollouts total     0
Train Time (s)               28.33671235991642
(Previous) Eval Time (s)     23.085308710113168
Sample Time (s)              17.737847020849586
Epoch Time (s)               69.15986809087917
Total Train Time (s)         20756.971401505172
Epoch                        299
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:01:29.056998 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #299 | Epoch Duration: 73.27887082099915
2020-01-11 09:01:29.057207 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #299 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9926506
Z variance train             0.021014784
KL Divergence                20.328236
KL Loss                      2.0328236
QF Loss                      1622.7433
VF Loss                      249.09515
Policy Loss                  -1053.3785
Q Predictions Mean           1052.5216
Q Predictions Std            237.02556
Q Predictions Max            1274.7701
Q Predictions Min            74.2307
V Predictions Mean           1055.4099
V Predictions Std            234.5965
V Predictions Max            1267.1003
V Predictions Min            81.902725
Log Pis Mean                 -0.40585116
Log Pis Std                  2.6753666
Log Pis Max                  9.8624325
Log Pis Min                  -9.818968
Policy mu Mean               0.0047626486
Policy mu Std                0.56891555
Policy mu Max                2.0737352
Policy mu Min                -2.6034935
Policy log std Mean          -0.95753485
Policy log std Std           0.2792751
Policy log std Max           -0.26344126
Policy log std Min           -2.6404853
Z mean eval                  0.98853046
Z variance eval              0.030718114
total_rewards                [2397.30429474 2986.10400615 2873.76965494 1066.81986145 3036.15833092
 3031.8148493  2815.58087241  818.39795359 2834.53814709 3062.92445615]
total_rewards_mean           2492.34124267447
total_rewards_std            797.8994451665416
total_rewards_max            3062.924456145404
total_rewards_min            818.3979535923171
Number of train steps total  301000
Number of env steps total    1507000
Number of rollouts total     0
Train Time (s)               27.884153217077255
(Previous) Eval Time (s)     27.20401699002832
Sample Time (s)              18.392523063346744
Epoch Time (s)               73.48069327045232
Total Train Time (s)         20826.045789769385
Epoch                        300
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:02:38.138766 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #300 | Epoch Duration: 69.08136248588562
2020-01-11 09:02:38.139066 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #300 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98808277
Z variance train             0.03067493
KL Divergence                19.887707
KL Loss                      1.9887707
QF Loss                      584.20355
VF Loss                      100.844185
Policy Loss                  -1036.4213
Q Predictions Mean           1035.9457
Q Predictions Std            216.26062
Q Predictions Max            1303.0645
Q Predictions Min            168.20717
V Predictions Mean           1031.2152
V Predictions Std            213.4179
V Predictions Max            1285.3353
V Predictions Min            167.57693
Log Pis Mean                 -0.33005565
Log Pis Std                  2.8552094
Log Pis Max                  11.172192
Log Pis Min                  -6.9492397
Policy mu Mean               0.037132524
Policy mu Std                0.56902117
Policy mu Max                2.2893949
Policy mu Min                -1.946026
Policy log std Mean          -0.9851533
Policy log std Std           0.27211595
Policy log std Max           -0.14332122
Policy log std Min           -2.296825
Z mean eval                  0.9663043
Z variance eval              0.023973797
total_rewards                [2067.96754229 2763.02919031 1265.1095861    95.29481099 2754.51933991
  577.25960303  169.14326372 2962.73205621 2154.97005989  239.45896939]
total_rewards_mean           1504.9484421844404
total_rewards_std            1109.0508542352488
total_rewards_max            2962.7320562055716
total_rewards_min            95.2948109931715
Number of train steps total  302000
Number of env steps total    1512000
Number of rollouts total     0
Train Time (s)               29.425149991177022
(Previous) Eval Time (s)     22.80436234967783
Sample Time (s)              17.870709882117808
Epoch Time (s)               70.10022222297266
Total Train Time (s)         20887.91647733096
Epoch                        301
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:03:40.011522 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #301 | Epoch Duration: 61.87222599983215
2020-01-11 09:03:40.011734 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #301 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9668237
Z variance train             0.024052186
KL Divergence                20.100212
KL Loss                      2.0100212
QF Loss                      911.77014
VF Loss                      93.012665
Policy Loss                  -1084.4312
Q Predictions Mean           1085.2336
Q Predictions Std            195.27063
Q Predictions Max            1307.8561
Q Predictions Min            150.87776
V Predictions Mean           1081.7743
V Predictions Std            192.38812
V Predictions Max            1290.2275
V Predictions Min            145.37112
Log Pis Mean                 -0.6295414
Log Pis Std                  2.7149692
Log Pis Max                  7.3654737
Log Pis Min                  -8.132061
Policy mu Mean               0.033812556
Policy mu Std                0.6035768
Policy mu Max                2.1058316
Policy mu Min                -2.715131
Policy log std Mean          -0.9195733
Policy log std Std           0.2389767
Policy log std Max           -0.17569554
Policy log std Min           -1.9084489
Z mean eval                  0.97807866
Z variance eval              0.023461908
total_rewards                [ 273.85611612  485.3184871  2580.80407028    7.21649025  683.67451132
  448.19827746 3150.05712265 1785.83711689 2873.08909021 2039.95626073]
total_rewards_mean           1432.8007543011875
total_rewards_std            1124.2055862362092
total_rewards_max            3150.0571226503585
total_rewards_min            7.21649025136494
Number of train steps total  303000
Number of env steps total    1517000
Number of rollouts total     0
Train Time (s)               26.48399672936648
(Previous) Eval Time (s)     14.576075269840658
Sample Time (s)              18.115101367700845
Epoch Time (s)               59.175173366907984
Total Train Time (s)         20947.871640178375
Epoch                        302
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:04:39.971994 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #302 | Epoch Duration: 59.95994424819946
2020-01-11 09:04:39.972248 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #302 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9773372
Z variance train             0.023382917
KL Divergence                19.3237
KL Loss                      1.9323701
QF Loss                      1150.8115
VF Loss                      302.50897
Policy Loss                  -1032.224
Q Predictions Mean           1030.9424
Q Predictions Std            245.8133
Q Predictions Max            1226.1471
Q Predictions Min            37.185295
V Predictions Mean           1046.2551
V Predictions Std            246.69434
V Predictions Max            1250.4598
V Predictions Min            38.397957
Log Pis Mean                 -0.7324753
Log Pis Std                  2.5872047
Log Pis Max                  9.286767
Log Pis Min                  -7.519699
Policy mu Mean               0.016574968
Policy mu Std                0.5395583
Policy mu Max                2.217634
Policy mu Min                -2.4487972
Policy log std Mean          -0.9573746
Policy log std Std           0.27179262
Policy log std Max           -0.19288945
Policy log std Min           -2.5444453
Z mean eval                  0.9738925
Z variance eval              0.026530767
total_rewards                [2496.81504488 2833.67125659 2049.54822297 1551.68855328 2668.10659036
 2736.73910795 2659.84603171 2662.87573502 2622.02643641 2639.25757845]
total_rewards_mean           2492.057455762021
total_rewards_std            371.9657012344663
total_rewards_max            2833.6712565869975
total_rewards_min            1551.6885532775516
Number of train steps total  304000
Number of env steps total    1522000
Number of rollouts total     0
Train Time (s)               28.283010341227055
(Previous) Eval Time (s)     15.360579940024763
Sample Time (s)              17.332224453333765
Epoch Time (s)               60.97581473458558
Total Train Time (s)         21020.24897094723
Epoch                        303
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:05:52.354235 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #303 | Epoch Duration: 72.38176846504211
2020-01-11 09:05:52.354545 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #303 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9748564
Z variance train             0.026517471
KL Divergence                19.451626
KL Loss                      1.9451627
QF Loss                      890.87646
VF Loss                      199.21815
Policy Loss                  -1040.8842
Q Predictions Mean           1036.7302
Q Predictions Std            228.52597
Q Predictions Max            1249.9775
Q Predictions Min            -7.068587
V Predictions Mean           1049.4438
V Predictions Std            226.6762
V Predictions Max            1255.1283
V Predictions Min            -17.287848
Log Pis Mean                 -0.42143223
Log Pis Std                  2.5535932
Log Pis Max                  6.882023
Log Pis Min                  -8.06723
Policy mu Mean               0.10246697
Policy mu Std                0.5665942
Policy mu Max                2.159653
Policy mu Min                -2.1354103
Policy log std Mean          -0.96956456
Policy log std Std           0.2745529
Policy log std Max           -0.21829695
Policy log std Min           -2.2841036
Z mean eval                  0.99834573
Z variance eval              0.026705569
total_rewards                [2971.83478853 1021.27003757 3027.99202226  714.20113987 2813.19260475
 1287.36476476  164.15476974  807.66304678  -73.64639371  926.07614781]
total_rewards_mean           1366.010292836647
total_rewards_std            1095.78465635753
total_rewards_max            3027.9920222627043
total_rewards_min            -73.64639371392383
Number of train steps total  305000
Number of env steps total    1527000
Number of rollouts total     0
Train Time (s)               29.291408041957766
(Previous) Eval Time (s)     26.766230867709965
Sample Time (s)              18.656755515839905
Epoch Time (s)               74.71439442550763
Total Train Time (s)         21085.895788887516
Epoch                        304
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:06:58.004226 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #304 | Epoch Duration: 65.6494402885437
2020-01-11 09:06:58.004445 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #304 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0001984
Z variance train             0.026716804
KL Divergence                19.539986
KL Loss                      1.9539986
QF Loss                      917.94727
VF Loss                      434.02164
Policy Loss                  -1008.2492
Q Predictions Mean           1008.3783
Q Predictions Std            267.87622
Q Predictions Max            1254.4891
Q Predictions Min            75.094124
V Predictions Mean           1005.18146
V Predictions Std            266.46893
V Predictions Max            1250.1052
V Predictions Min            53.59222
Log Pis Mean                 -0.9320471
Log Pis Std                  2.9036002
Log Pis Max                  9.770605
Log Pis Min                  -10.581258
Policy mu Mean               0.01932251
Policy mu Std                0.561569
Policy mu Max                2.1387355
Policy mu Min                -2.1742446
Policy log std Mean          -0.9176662
Policy log std Std           0.2960008
Policy log std Max           -0.14139885
Policy log std Min           -2.5208669
Z mean eval                  1.0081497
Z variance eval              0.017283274
total_rewards                [ 905.6870811   204.44272999 2903.05751898  286.17725739 1480.46565143
 2659.90401279  504.34631348  306.46171885 2727.98586275  410.91454017]
total_rewards_mean           1238.9442686947696
total_rewards_std            1060.5558358062733
total_rewards_max            2903.057518978202
total_rewards_min            204.4427299897942
Number of train steps total  306000
Number of env steps total    1532000
Number of rollouts total     0
Train Time (s)               30.797388850711286
(Previous) Eval Time (s)     17.700955886859447
Sample Time (s)              17.230112145189196
Epoch Time (s)               65.72845688275993
Total Train Time (s)         21148.273979478516
Epoch                        305
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:08:00.385921 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #305 | Epoch Duration: 62.38131403923035
2020-01-11 09:08:00.386120 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #305 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0068719
Z variance train             0.017299287
KL Divergence                20.407143
KL Loss                      2.0407143
QF Loss                      1375.2338
VF Loss                      195.81284
Policy Loss                  -1057.4172
Q Predictions Mean           1054.9971
Q Predictions Std            228.2878
Q Predictions Max            1260.2094
Q Predictions Min            -28.397121
V Predictions Mean           1063.0122
V Predictions Std            226.18924
V Predictions Max            1255.0864
V Predictions Min            16.330431
Log Pis Mean                 -0.33964083
Log Pis Std                  2.5071208
Log Pis Max                  7.1939316
Log Pis Min                  -6.9316354
Policy mu Mean               0.044372175
Policy mu Std                0.5349126
Policy mu Max                2.0193293
Policy mu Min                -1.8697464
Policy log std Mean          -0.99112225
Policy log std Std           0.27059308
Policy log std Max           -0.23299927
Policy log std Min           -2.2806473
Z mean eval                  1.0195557
Z variance eval              0.02092285
total_rewards                [ 357.14100575 2604.93782599  612.80841893 2744.725734   2819.8178194
   83.04225197  496.83013617  957.09886351 2297.78433928 2904.0830428 ]
total_rewards_mean           1587.8269437791964
total_rewards_std            1115.5724276261722
total_rewards_max            2904.0830428016925
total_rewards_min            83.04225196505193
Number of train steps total  307000
Number of env steps total    1537000
Number of rollouts total     0
Train Time (s)               30.022724030073732
(Previous) Eval Time (s)     14.35351020982489
Sample Time (s)              17.63049224158749
Epoch Time (s)               62.00672648148611
Total Train Time (s)         21215.486346770544
Epoch                        306
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:09:07.603767 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #306 | Epoch Duration: 67.21745729446411
2020-01-11 09:09:07.604092 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #306 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0217844
Z variance train             0.020969925
KL Divergence                20.145203
KL Loss                      2.0145204
QF Loss                      923.868
VF Loss                      431.26752
Policy Loss                  -1053.7152
Q Predictions Mean           1054.4565
Q Predictions Std            218.00517
Q Predictions Max            1255.0039
Q Predictions Min            59.956005
V Predictions Mean           1061.3998
V Predictions Std            217.06105
V Predictions Max            1267.7164
V Predictions Min            172.23132
Log Pis Mean                 -0.5588993
Log Pis Std                  2.7477708
Log Pis Max                  10.633938
Log Pis Min                  -7.860686
Policy mu Mean               0.021653915
Policy mu Std                0.57688785
Policy mu Max                2.3648608
Policy mu Min                -1.7907964
Policy log std Mean          -0.9512547
Policy log std Std           0.2965987
Policy log std Max           -0.21922368
Policy log std Min           -2.938651
Z mean eval                  0.97390306
Z variance eval              0.03262391
total_rewards                [1622.86560642 3050.67340109 2044.54994303  378.40473728 2930.88701872
 3149.1042869   518.64531108 2478.46880763 1241.74614027 2882.25631506]
total_rewards_mean           2029.76015674847
total_rewards_std            991.5898703640505
total_rewards_max            3149.10428689897
total_rewards_min            378.4047372784942
Number of train steps total  308000
Number of env steps total    1542000
Number of rollouts total     0
Train Time (s)               30.678619049023837
(Previous) Eval Time (s)     19.56393198762089
Sample Time (s)              17.92216497566551
Epoch Time (s)               68.16471601231024
Total Train Time (s)         21282.61849936424
Epoch                        307
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:10:14.740514 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #307 | Epoch Duration: 67.13618874549866
2020-01-11 09:10:14.740745 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #307 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9744889
Z variance train             0.032605015
KL Divergence                19.692396
KL Loss                      1.9692396
QF Loss                      2277.3997
VF Loss                      248.07684
Policy Loss                  -1035.1415
Q Predictions Mean           1034.3914
Q Predictions Std            264.2236
Q Predictions Max            1316.9464
Q Predictions Min            163.7661
V Predictions Mean           1030.8706
V Predictions Std            261.74542
V Predictions Max            1317.1694
V Predictions Min            162.8198
Log Pis Mean                 -0.022179686
Log Pis Std                  2.9477115
Log Pis Max                  18.182037
Log Pis Min                  -7.305978
Policy mu Mean               0.035587147
Policy mu Std                0.59914905
Policy mu Max                2.2279582
Policy mu Min                -2.7574012
Policy log std Mean          -0.9607788
Policy log std Std           0.26507685
Policy log std Max           -0.25102645
Policy log std Min           -2.2056317
Z mean eval                  1.0123551
Z variance eval              0.03401237
total_rewards                [2632.96351506 2091.61993651  318.4116312  2708.03420312 2688.24788185
  936.13642488 2793.66799518 1217.33618456  609.58635514 2717.33159822]
total_rewards_mean           1871.333572571625
total_rewards_std            941.7173417254581
total_rewards_max            2793.6679951784154
total_rewards_min            318.41163120262814
Number of train steps total  309000
Number of env steps total    1547000
Number of rollouts total     0
Train Time (s)               28.473962591961026
(Previous) Eval Time (s)     18.53511200286448
Sample Time (s)              18.390847377479076
Epoch Time (s)               65.39992197230458
Total Train Time (s)         21349.180088550318
Epoch                        308
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:11:21.309024 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #308 | Epoch Duration: 66.56806707382202
2020-01-11 09:11:21.309304 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #308 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0128176
Z variance train             0.034120187
KL Divergence                19.474382
KL Loss                      1.9474382
QF Loss                      526.2445
VF Loss                      68.427826
Policy Loss                  -1055.6942
Q Predictions Mean           1056.9686
Q Predictions Std            244.31229
Q Predictions Max            1256.946
Q Predictions Min            176.80331
V Predictions Mean           1055.5361
V Predictions Std            243.7173
V Predictions Max            1251.9637
V Predictions Min            156.54538
Log Pis Mean                 -0.6904525
Log Pis Std                  2.4308412
Log Pis Max                  6.5655975
Log Pis Min                  -8.058447
Policy mu Mean               0.05097173
Policy mu Std                0.56259215
Policy mu Max                2.2043304
Policy mu Min                -2.1036327
Policy log std Mean          -0.94507945
Policy log std Std           0.25678396
Policy log std Max           -0.16305715
Policy log std Min           -1.950237
Z mean eval                  0.98297226
Z variance eval              0.036143783
total_rewards                [2670.80484494 2935.71669101 2972.33166543  235.99731055  197.49070248
 2057.74673683 1192.81849069 3112.84178125 2999.54596498 2873.89337288]
total_rewards_mean           2124.918756104404
total_rewards_std            1101.4421138287184
total_rewards_max            3112.8417812532275
total_rewards_min            197.49070248301607
Number of train steps total  310000
Number of env steps total    1552000
Number of rollouts total     0
Train Time (s)               28.8198460964486
(Previous) Eval Time (s)     19.702971911989152
Sample Time (s)              18.379524159710854
Epoch Time (s)               66.9023421681486
Total Train Time (s)         21415.855576032307
Epoch                        309
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:12:27.984732 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #309 | Epoch Duration: 66.67521238327026
2020-01-11 09:12:27.984918 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #309 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98296916
Z variance train             0.03606073
KL Divergence                19.34702
KL Loss                      1.9347019
QF Loss                      495.4521
VF Loss                      134.56197
Policy Loss                  -1050.15
Q Predictions Mean           1049.1448
Q Predictions Std            260.22656
Q Predictions Max            1283.812
Q Predictions Min            140.66919
V Predictions Mean           1056.9084
V Predictions Std            260.60306
V Predictions Max            1286.3862
V Predictions Min            154.43176
Log Pis Mean                 -0.53169197
Log Pis Std                  2.624324
Log Pis Max                  10.853621
Log Pis Min                  -7.913077
Policy mu Mean               0.015351791
Policy mu Std                0.5920282
Policy mu Max                2.2115064
Policy mu Min                -2.8509035
Policy log std Mean          -0.9317231
Policy log std Std           0.2573614
Policy log std Max           -0.16682088
Policy log std Min           -1.9824841
Z mean eval                  1.0099905
Z variance eval              0.029047698
total_rewards                [1381.33737994  513.94150129  339.69932673  761.82258274 2976.67117209
  381.01398533  204.58949766 2712.79656799  569.14877987 2545.4747663 ]
total_rewards_mean           1238.649555993919
total_rewards_std            1036.132617168523
total_rewards_max            2976.6711720893873
total_rewards_min            204.58949766220752
Number of train steps total  311000
Number of env steps total    1557000
Number of rollouts total     0
Train Time (s)               28.00510703213513
(Previous) Eval Time (s)     19.475480790715665
Sample Time (s)              17.451713774818927
Epoch Time (s)               64.93230159766972
Total Train Time (s)         21478.569676911924
Epoch                        310
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:13:30.703624 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #310 | Epoch Duration: 62.71852159500122
2020-01-11 09:13:30.703892 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #310 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0083933
Z variance train             0.0289159
KL Divergence                19.987972
KL Loss                      1.9987973
QF Loss                      1603.1385
VF Loss                      508.02585
Policy Loss                  -1075.1838
Q Predictions Mean           1076.196
Q Predictions Std            223.29945
Q Predictions Max            1270.4182
Q Predictions Min            139.27246
V Predictions Mean           1081.5203
V Predictions Std            221.7275
V Predictions Max            1280.5603
V Predictions Min            166.53925
Log Pis Mean                 -0.2417176
Log Pis Std                  2.5691257
Log Pis Max                  8.968539
Log Pis Min                  -6.7913094
Policy mu Mean               -0.029698249
Policy mu Std                0.59569937
Policy mu Max                2.2214077
Policy mu Min                -2.554051
Policy log std Mean          -0.9246405
Policy log std Std           0.24383873
Policy log std Max           -0.18587571
Policy log std Min           -2.0281847
Z mean eval                  0.9964177
Z variance eval              0.025899982
total_rewards                [-108.23995826  165.98676928 2860.07745859  821.21604958  588.44105136
  203.78499639 2846.89883879  245.17695769 2890.85053045  837.30458994]
total_rewards_mean           1135.149728381008
total_rewards_std            1166.999957465907
total_rewards_max            2890.850530452948
total_rewards_min            -108.23995826332323
Number of train steps total  312000
Number of env steps total    1562000
Number of rollouts total     0
Train Time (s)               28.266807966399938
(Previous) Eval Time (s)     17.26143078599125
Sample Time (s)              18.038191513624042
Epoch Time (s)               63.56643026601523
Total Train Time (s)         21540.99831008725
Epoch                        311
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:14:33.139495 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #311 | Epoch Duration: 62.43537735939026
2020-01-11 09:14:33.139827 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #311 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9954174
Z variance train             0.02593919
KL Divergence                19.754168
KL Loss                      1.9754168
QF Loss                      933.122
VF Loss                      390.14407
Policy Loss                  -1064.9244
Q Predictions Mean           1062.904
Q Predictions Std            250.78664
Q Predictions Max            1275.238
Q Predictions Min            70.75218
V Predictions Mean           1065.5565
V Predictions Std            248.00319
V Predictions Max            1268.3618
V Predictions Min            57.329464
Log Pis Mean                 -0.43172938
Log Pis Std                  2.704872
Log Pis Max                  11.265795
Log Pis Min                  -6.886937
Policy mu Mean               0.018788476
Policy mu Std                0.5860016
Policy mu Max                1.9649295
Policy mu Min                -2.1390142
Policy log std Mean          -0.94780827
Policy log std Std           0.26564586
Policy log std Max           -0.073820174
Policy log std Min           -2.5965614
Z mean eval                  0.9902836
Z variance eval              0.022057746
total_rewards                [2569.61526483  541.63850524 3151.27142669 2814.12609263  378.13750944
 3101.21395149 3134.11092981 2476.51913335 2949.6673949    36.46230214]
total_rewards_mean           2115.2762510509465
total_rewards_std            1200.8479293405762
total_rewards_max            3151.2714266901635
total_rewards_min            36.46230213687012
Number of train steps total  313000
Number of env steps total    1567000
Number of rollouts total     0
Train Time (s)               29.892063884064555
(Previous) Eval Time (s)     16.13005932699889
Sample Time (s)              17.67887875251472
Epoch Time (s)               63.701001963578165
Total Train Time (s)         21615.771813700907
Epoch                        312
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:15:47.916986 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #312 | Epoch Duration: 74.77689599990845
2020-01-11 09:15:47.917286 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #312 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.987426
Z variance train             0.022024896
KL Divergence                19.836
KL Loss                      1.9836
QF Loss                      725.2283
VF Loss                      233.98712
Policy Loss                  -1064.6079
Q Predictions Mean           1062.55
Q Predictions Std            234.20879
Q Predictions Max            1258.637
Q Predictions Min            146.78354
V Predictions Mean           1061.1318
V Predictions Std            230.5557
V Predictions Max            1254.967
V Predictions Min            149.86627
Log Pis Mean                 -0.09228193
Log Pis Std                  2.7093494
Log Pis Max                  14.304205
Log Pis Min                  -8.265812
Policy mu Mean               0.048306413
Policy mu Std                0.5700121
Policy mu Max                2.2198477
Policy mu Min                -2.8673377
Policy log std Mean          -1.005068
Policy log std Std           0.28490657
Policy log std Max           -0.18511516
Policy log std Min           -2.6872807
Z mean eval                  0.97519237
Z variance eval              0.018285884
total_rewards                [ -25.95277186 2737.92611431 2683.38360004 2916.51965103  133.17530259
 2553.41240835 1693.88681608 2833.75973475 2564.11317201 2872.24452159]
total_rewards_mean           2096.246854889579
total_rewards_std            1073.4337858612428
total_rewards_max            2916.519651034905
total_rewards_min            -25.952771862634933
Number of train steps total  314000
Number of env steps total    1572000
Number of rollouts total     0
Train Time (s)               30.863842546008527
(Previous) Eval Time (s)     27.205626524984837
Sample Time (s)              18.733370623085648
Epoch Time (s)               76.80283969407901
Total Train Time (s)         21687.44222687278
Epoch                        313
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:16:59.591531 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #313 | Epoch Duration: 71.67401385307312
2020-01-11 09:16:59.591757 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #313 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9748524
Z variance train             0.01829255
KL Divergence                20.83434
KL Loss                      2.0834339
QF Loss                      872.8684
VF Loss                      276.0911
Policy Loss                  -1032.8549
Q Predictions Mean           1031.3083
Q Predictions Std            278.76392
Q Predictions Max            1299.0631
Q Predictions Min            133.26567
V Predictions Mean           1028.2958
V Predictions Std            276.49695
V Predictions Max            1259.9866
V Predictions Min            144.749
Log Pis Mean                 -0.2763607
Log Pis Std                  2.5242074
Log Pis Max                  9.596468
Log Pis Min                  -8.150757
Policy mu Mean               -0.005370942
Policy mu Std                0.5865445
Policy mu Max                2.2683582
Policy mu Min                -2.4513416
Policy log std Mean          -0.97095644
Policy log std Std           0.2893315
Policy log std Max           -0.12743753
Policy log std Min           -2.3888345
Z mean eval                  0.9670744
Z variance eval              0.012972856
total_rewards                [2735.30121939  681.83026764 2783.03441286 2753.27944318  246.13932427
 2981.62517469 2560.2971364   953.94562795 2978.14434312 2418.32148742]
total_rewards_mean           2109.1918436916103
total_rewards_std            995.947822784549
total_rewards_max            2981.625174689766
total_rewards_min            246.13932427123177
Number of train steps total  315000
Number of env steps total    1577000
Number of rollouts total     0
Train Time (s)               31.091162621974945
(Previous) Eval Time (s)     22.07644093595445
Sample Time (s)              18.66854906314984
Epoch Time (s)               71.83615262107924
Total Train Time (s)         21757.28445451986
Epoch                        314
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:18:09.438604 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #314 | Epoch Duration: 69.84662532806396
2020-01-11 09:18:09.438885 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #314 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.966821
Z variance train             0.01289892
KL Divergence                21.634922
KL Loss                      2.1634922
QF Loss                      1170.2654
VF Loss                      123.68385
Policy Loss                  -1043.095
Q Predictions Mean           1042.5042
Q Predictions Std            243.55159
Q Predictions Max            1284.4198
Q Predictions Min            116.063705
V Predictions Mean           1046.9941
V Predictions Std            241.63222
V Predictions Max            1274.0424
V Predictions Min            132.37039
Log Pis Mean                 -0.14640181
Log Pis Std                  2.5346987
Log Pis Max                  8.548422
Log Pis Min                  -6.758331
Policy mu Mean               0.032971404
Policy mu Std                0.5911001
Policy mu Max                2.3634233
Policy mu Min                -2.6865149
Policy log std Mean          -0.9558002
Policy log std Std           0.2734966
Policy log std Max           -0.0448038
Policy log std Min           -2.5305243
Z mean eval                  0.9984436
Z variance eval              0.01559138
total_rewards                [2989.45513957  887.21851681 1568.09903886  800.30221745  971.36831882
 1157.05646335 -192.79359138 2776.8980831  3045.38416948 2475.07304766]
total_rewards_mean           1647.8061403725144
total_rewards_std            1053.6501285762552
total_rewards_max            3045.3841694797775
total_rewards_min            -192.7935913808174
Number of train steps total  316000
Number of env steps total    1582000
Number of rollouts total     0
Train Time (s)               26.902330433949828
(Previous) Eval Time (s)     20.08660934586078
Sample Time (s)              18.154490866232663
Epoch Time (s)               65.14343064604327
Total Train Time (s)         21821.576526679564
Epoch                        315
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:19:13.735020 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #315 | Epoch Duration: 64.29591298103333
2020-01-11 09:19:13.735254 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #315 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99882126
Z variance train             0.015602732
KL Divergence                22.130861
KL Loss                      2.2130861
QF Loss                      643.3672
VF Loss                      442.56396
Policy Loss                  -1056.049
Q Predictions Mean           1055.723
Q Predictions Std            252.07036
Q Predictions Max            1275.042
Q Predictions Min            129.08159
V Predictions Mean           1061.749
V Predictions Std            254.4967
V Predictions Max            1286.2076
V Predictions Min            135.86641
Log Pis Mean                 -0.66313183
Log Pis Std                  2.717858
Log Pis Max                  13.30518
Log Pis Min                  -7.418049
Policy mu Mean               -0.014722718
Policy mu Std                0.5621886
Policy mu Max                2.8403554
Policy mu Min                -2.3219209
Policy log std Mean          -0.9450085
Policy log std Std           0.298629
Policy log std Max           -0.14436966
Policy log std Min           -3.3191886
Z mean eval                  0.97591764
Z variance eval              0.013024275
total_rewards                [ 924.62814142 3196.35511449 3231.99597701  542.00876189   63.71621038
 3219.53871469 2980.76948339  654.7160254  1706.20510758 3209.1364589 ]
total_rewards_mean           1972.9069995154382
total_rewards_std            1256.2004689825567
total_rewards_max            3231.9959770115374
total_rewards_min            63.716210380880995
Number of train steps total  317000
Number of env steps total    1587000
Number of rollouts total     0
Train Time (s)               29.09198392322287
(Previous) Eval Time (s)     19.238745351787657
Sample Time (s)              17.525610058568418
Epoch Time (s)               65.85633933357894
Total Train Time (s)         21885.33779255068
Epoch                        316
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:20:17.502606 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #316 | Epoch Duration: 63.767141819000244
2020-01-11 09:20:17.502877 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #316 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97466326
Z variance train             0.01305854
KL Divergence                22.018286
KL Loss                      2.2018287
QF Loss                      826.7205
VF Loss                      264.31268
Policy Loss                  -1079.7457
Q Predictions Mean           1076.1172
Q Predictions Std            214.29944
Q Predictions Max            1272.006
Q Predictions Min            114.241806
V Predictions Mean           1077.0756
V Predictions Std            204.61739
V Predictions Max            1267.2852
V Predictions Min            130.63199
Log Pis Mean                 -0.044703424
Log Pis Std                  2.6479826
Log Pis Max                  9.772928
Log Pis Min                  -9.396
Policy mu Mean               -0.000706502
Policy mu Std                0.58705574
Policy mu Max                2.017875
Policy mu Min                -2.4167557
Policy log std Mean          -0.97443116
Policy log std Std           0.26359004
Policy log std Max           -0.23424101
Policy log std Min           -2.4275227
Z mean eval                  0.98596716
Z variance eval              0.012809718
total_rewards                [2926.54149955 2556.26849224 2416.41687521 1169.86822588   50.7607313
 2623.10933283 1384.99654809 2436.44709398  647.26076417 2905.27735798]
total_rewards_mean           1911.6946921228905
total_rewards_std            967.3883450949139
total_rewards_max            2926.5414995544324
total_rewards_min            50.76073130133009
Number of train steps total  318000
Number of env steps total    1592000
Number of rollouts total     0
Train Time (s)               30.159846077207476
(Previous) Eval Time (s)     17.149245463777333
Sample Time (s)              17.701962357386947
Epoch Time (s)               65.01105389837176
Total Train Time (s)         21955.902055298444
Epoch                        317
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:21:28.070565 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #317 | Epoch Duration: 70.56747484207153
2020-01-11 09:21:28.070811 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #317 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9849966
Z variance train             0.012770134
KL Divergence                22.291204
KL Loss                      2.2291205
QF Loss                      792.337
VF Loss                      478.48566
Policy Loss                  -1054.5106
Q Predictions Mean           1051.8027
Q Predictions Std            261.92236
Q Predictions Max            1279.8124
Q Predictions Min            74.89922
V Predictions Mean           1062.5817
V Predictions Std            252.77342
V Predictions Max            1280.7369
V Predictions Min            167.79266
Log Pis Mean                 -0.15189835
Log Pis Std                  2.8485022
Log Pis Max                  16.146328
Log Pis Min                  -6.6520367
Policy mu Mean               0.06077254
Policy mu Std                0.5570097
Policy mu Max                2.3565886
Policy mu Min                -3.685113
Policy log std Mean          -0.9580292
Policy log std Std           0.27290022
Policy log std Max           -0.1781525
Policy log std Min           -2.1881433
Z mean eval                  1.001871
Z variance eval              0.034555323
total_rewards                [ 265.51322932 2224.60067231 2923.63894203 1384.02908429 2188.86312779
 3218.22459679 2775.84471127  175.22896344 3001.56487585 2166.04658348]
total_rewards_mean           2032.35547865642
total_rewards_std            1037.4545090490315
total_rewards_max            3218.2245967925187
total_rewards_min            175.2289634402405
Number of train steps total  319000
Number of env steps total    1597000
Number of rollouts total     0
Train Time (s)               27.461160372011364
(Previous) Eval Time (s)     22.705373084172606
Sample Time (s)              17.542715571355075
Epoch Time (s)               67.70924902753904
Total Train Time (s)         22023.630448984448
Epoch                        318
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:22:35.804977 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #318 | Epoch Duration: 67.73394751548767
2020-01-11 09:22:35.805272 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #318 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0058444
Z variance train             0.034425598
KL Divergence                20.595821
KL Loss                      2.0595822
QF Loss                      856.1541
VF Loss                      382.12778
Policy Loss                  -1065.182
Q Predictions Mean           1064.6072
Q Predictions Std            243.97984
Q Predictions Max            1255.6918
Q Predictions Min            -12.725475
V Predictions Mean           1079.0403
V Predictions Std            243.824
V Predictions Max            1270.5356
V Predictions Min            5.196602
Log Pis Mean                 -0.25671428
Log Pis Std                  2.7569087
Log Pis Max                  11.661677
Log Pis Min                  -8.698469
Policy mu Mean               0.06887941
Policy mu Std                0.5905398
Policy mu Max                2.26439
Policy mu Min                -2.0738547
Policy log std Mean          -0.9562479
Policy log std Std           0.27300483
Policy log std Max           -0.21260399
Policy log std Min           -2.7473927
Z mean eval                  0.9746453
Z variance eval              0.03365044
total_rewards                [2814.29358389 3009.79706345 3126.47330629 2188.13845068 1374.26751184
 1917.67176476 2521.86607152 1763.4718661  3096.58397117  879.51708403]
total_rewards_mean           2269.2080673716137
total_rewards_std            738.0352099814648
total_rewards_max            3126.473306286732
total_rewards_min            879.5170840285793
Number of train steps total  320000
Number of env steps total    1602000
Number of rollouts total     0
Train Time (s)               27.65380699187517
(Previous) Eval Time (s)     22.72979160770774
Sample Time (s)              18.16176707483828
Epoch Time (s)               68.54536567442119
Total Train Time (s)         22089.771465452388
Epoch                        319
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:23:41.948711 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #319 | Epoch Duration: 66.14322447776794
2020-01-11 09:23:41.948929 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #319 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.974738
Z variance train             0.03359967
KL Divergence                20.004345
KL Loss                      2.0004346
QF Loss                      726.9928
VF Loss                      198.33728
Policy Loss                  -1084.5934
Q Predictions Mean           1085.2432
Q Predictions Std            191.83139
Q Predictions Max            1270.3906
Q Predictions Min            104.1647
V Predictions Mean           1089.9955
V Predictions Std            189.44006
V Predictions Max            1258.1178
V Predictions Min            109.797005
Log Pis Mean                 -0.24178466
Log Pis Std                  2.4811432
Log Pis Max                  9.701738
Log Pis Min                  -7.4779835
Policy mu Mean               0.07483011
Policy mu Std                0.5726705
Policy mu Max                1.9429824
Policy mu Min                -2.1070774
Policy log std Mean          -0.97870016
Policy log std Std           0.25777346
Policy log std Max           -0.22234148
Policy log std Min           -2.7074509
Z mean eval                  0.99879247
Z variance eval              0.030614322
total_rewards                [2937.40335418 3098.30839311 2978.76162305 2781.09670616 1064.84095488
 3197.64931359  803.69297144 3148.34959318 3171.18597324 3116.80958199]
total_rewards_mean           2629.809846481594
total_rewards_std            858.1475494207601
total_rewards_max            3197.6493135863843
total_rewards_min            803.6929714393368
Number of train steps total  321000
Number of env steps total    1607000
Number of rollouts total     0
Train Time (s)               30.690022793132812
(Previous) Eval Time (s)     20.32734536798671
Sample Time (s)              17.684594008605927
Epoch Time (s)               68.70196216972545
Total Train Time (s)         22160.67503310833
Epoch                        320
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:24:52.857534 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #320 | Epoch Duration: 70.90841245651245
2020-01-11 09:24:52.857805 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #320 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99821454
Z variance train             0.030591387
KL Divergence                19.944836
KL Loss                      1.9944836
QF Loss                      1449.4352
VF Loss                      202.6426
Policy Loss                  -1093.2168
Q Predictions Mean           1094.5577
Q Predictions Std            222.96254
Q Predictions Max            1329.3243
Q Predictions Min            52.297325
V Predictions Mean           1095.341
V Predictions Std            223.4137
V Predictions Max            1327.4106
V Predictions Min            9.876013
Log Pis Mean                 -0.16722977
Log Pis Std                  2.709308
Log Pis Max                  13.64159
Log Pis Min                  -6.619955
Policy mu Mean               0.022690516
Policy mu Std                0.5563431
Policy mu Max                2.6666744
Policy mu Min                -2.6739113
Policy log std Mean          -1.0088687
Policy log std Std           0.28489065
Policy log std Max           -0.15619773
Policy log std Min           -3.037221
Z mean eval                  0.97624207
Z variance eval              0.034670375
total_rewards                [ 958.84376379  850.26465579  277.46785358  252.02916651  968.0612621
 2816.78417151 2950.99415269  118.08769987 2919.93923806 3023.68151439]
total_rewards_mean           1513.6153478274373
total_rewards_std            1188.9047973445731
total_rewards_max            3023.681514388823
total_rewards_min            118.08769986674234
Number of train steps total  322000
Number of env steps total    1612000
Number of rollouts total     0
Train Time (s)               29.901661458890885
(Previous) Eval Time (s)     22.53346274001524
Sample Time (s)              17.944726647343487
Epoch Time (s)               70.37985084624961
Total Train Time (s)         22222.951304684393
Epoch                        321
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:25:55.140020 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #321 | Epoch Duration: 62.28188180923462
2020-01-11 09:25:55.140379 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #321 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9767278
Z variance train             0.03467516
KL Divergence                20.041985
KL Loss                      2.0041986
QF Loss                      1475.1702
VF Loss                      462.14923
Policy Loss                  -1074.9425
Q Predictions Mean           1076.4208
Q Predictions Std            224.1386
Q Predictions Max            1269.2736
Q Predictions Min            132.19637
V Predictions Mean           1086.9026
V Predictions Std            225.57411
V Predictions Max            1275.9735
V Predictions Min            99.01111
Log Pis Mean                 -0.62034583
Log Pis Std                  2.6546636
Log Pis Max                  6.9960203
Log Pis Min                  -7.172279
Policy mu Mean               -0.00975695
Policy mu Std                0.58887297
Policy mu Max                2.2391338
Policy mu Min                -2.849246
Policy log std Mean          -0.94262177
Policy log std Std           0.2581516
Policy log std Max           -0.041246712
Policy log std Min           -2.0124457
Z mean eval                  0.9803184
Z variance eval              0.02375439
total_rewards                [2645.90709915 2844.47820487 2998.71318097  889.63359098  529.03512208
 2983.97354399  123.31046013 3053.64588049  130.58142626 3035.86137969]
total_rewards_mean           1923.5139888626206
total_rewards_std            1250.3595234984627
total_rewards_max            3053.6458804930353
total_rewards_min            123.31046012733187
Number of train steps total  323000
Number of env steps total    1617000
Number of rollouts total     0
Train Time (s)               30.26470291102305
(Previous) Eval Time (s)     14.43516037799418
Sample Time (s)              18.380587627645582
Epoch Time (s)               63.08045091666281
Total Train Time (s)         22293.397516037337
Epoch                        322
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:27:05.591368 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #322 | Epoch Duration: 70.45074462890625
2020-01-11 09:27:05.591657 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #322 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9806329
Z variance train             0.023701012
KL Divergence                20.216911
KL Loss                      2.021691
QF Loss                      1112.6448
VF Loss                      157.41843
Policy Loss                  -1090.6416
Q Predictions Mean           1089.1376
Q Predictions Std            207.30418
Q Predictions Max            1320.1935
Q Predictions Min            56.752083
V Predictions Mean           1088.7197
V Predictions Std            208.79684
V Predictions Max            1308.9404
V Predictions Min            52.176926
Log Pis Mean                 -0.1669769
Log Pis Std                  2.6918292
Log Pis Max                  9.953959
Log Pis Min                  -7.2973347
Policy mu Mean               0.013734487
Policy mu Std                0.53599834
Policy mu Max                2.0844297
Policy mu Min                -2.668159
Policy log std Mean          -1.0189979
Policy log std Std           0.28351295
Policy log std Max           -0.26024675
Policy log std Min           -2.5155816
Z mean eval                  0.9890879
Z variance eval              0.022424335
total_rewards                [1488.25438799 1174.06410716 3029.67343244 2776.38761203  390.48479127
 1753.08095597 2745.36016618 2726.14239595 1571.58553199 3088.4920766 ]
total_rewards_mean           2074.35254575778
total_rewards_std            874.8989939782011
total_rewards_max            3088.4920765963243
total_rewards_min            390.48479127282735
Number of train steps total  324000
Number of env steps total    1622000
Number of rollouts total     0
Train Time (s)               31.52818787889555
(Previous) Eval Time (s)     21.80515002971515
Sample Time (s)              18.025173804722726
Epoch Time (s)               71.35851171333343
Total Train Time (s)         22364.762533692643
Epoch                        323
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:28:16.959117 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #323 | Epoch Duration: 71.36722421646118
2020-01-11 09:28:16.959329 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #323 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9921525
Z variance train             0.022460109
KL Divergence                20.142967
KL Loss                      2.0142968
QF Loss                      1016.7467
VF Loss                      202.12787
Policy Loss                  -1101.4417
Q Predictions Mean           1103.9224
Q Predictions Std            226.05779
Q Predictions Max            1299.9816
Q Predictions Min            35.63227
V Predictions Mean           1092.1149
V Predictions Std            222.552
V Predictions Max            1283.343
V Predictions Min            -6.5670557
Log Pis Mean                 -0.114468634
Log Pis Std                  2.4941616
Log Pis Max                  7.839177
Log Pis Min                  -6.8054266
Policy mu Mean               0.04943592
Policy mu Std                0.57480246
Policy mu Max                2.2311726
Policy mu Min                -2.410113
Policy log std Mean          -0.97220874
Policy log std Std           0.23967835
Policy log std Max           -0.26414067
Policy log std Min           -2.017599
Z mean eval                  0.9936797
Z variance eval              0.016033791
total_rewards                [1660.49223179  120.69982837 1820.89596072 2565.74823491 2972.95948338
 2803.01078415 2773.27247923 2962.03045339 2722.17904503 2328.34433788]
total_rewards_mean           2272.963283884845
total_rewards_std            836.5629929601043
total_rewards_max            2972.959483377803
total_rewards_min            120.69982836765386
Number of train steps total  325000
Number of env steps total    1627000
Number of rollouts total     0
Train Time (s)               29.308257713913918
(Previous) Eval Time (s)     21.813563061878085
Sample Time (s)              18.154324313160032
Epoch Time (s)               69.27614508895203
Total Train Time (s)         22434.50226959586
Epoch                        324
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:29:26.703664 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #324 | Epoch Duration: 69.74416184425354
2020-01-11 09:29:26.703924 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #324 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99147666
Z variance train             0.016040092
KL Divergence                20.913792
KL Loss                      2.0913792
QF Loss                      1603.6948
VF Loss                      288.3218
Policy Loss                  -1083.8842
Q Predictions Mean           1089.606
Q Predictions Std            249.32156
Q Predictions Max            1294.2864
Q Predictions Min            118.5723
V Predictions Mean           1094.5493
V Predictions Std            247.6931
V Predictions Max            1300.3693
V Predictions Min            118.10072
Log Pis Mean                 -0.65554214
Log Pis Std                  2.6224554
Log Pis Max                  7.481987
Log Pis Min                  -12.786793
Policy mu Mean               -0.048769962
Policy mu Std                0.574395
Policy mu Max                2.646734
Policy mu Min                -2.3316944
Policy log std Mean          -0.94945574
Policy log std Std           0.26214415
Policy log std Max           -0.20389777
Policy log std Min           -2.2997065
Z mean eval                  1.0238006
Z variance eval              0.014227906
total_rewards                [1189.67011023  916.66954123 3145.7230457  3041.58347196 1485.80367793
 2634.54805274  139.54676563  903.36101535 2414.1645964   964.93338668]
total_rewards_mean           1683.6003663841832
total_rewards_std            989.9786439026681
total_rewards_max            3145.7230456951547
total_rewards_min            139.54676563469624
Number of train steps total  326000
Number of env steps total    1632000
Number of rollouts total     0
Train Time (s)               27.147306659258902
(Previous) Eval Time (s)     22.281231049913913
Sample Time (s)              18.541803745087236
Epoch Time (s)               67.97034145426005
Total Train Time (s)         22501.08815042721
Epoch                        325
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:30:33.295777 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #325 | Epoch Duration: 66.59164214134216
2020-01-11 09:30:33.296115 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #325 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.023588
Z variance train             0.014199247
KL Divergence                21.738
KL Loss                      2.1738002
QF Loss                      616.00073
VF Loss                      294.96143
Policy Loss                  -1083.8007
Q Predictions Mean           1084.0403
Q Predictions Std            218.75444
Q Predictions Max            1269.7762
Q Predictions Min            126.78726
V Predictions Mean           1094.5511
V Predictions Std            221.24179
V Predictions Max            1277.4681
V Predictions Min            135.1063
Log Pis Mean                 -0.6593369
Log Pis Std                  2.644576
Log Pis Max                  16.54529
Log Pis Min                  -9.30226
Policy mu Mean               0.014793524
Policy mu Std                0.5424812
Policy mu Max                2.5422237
Policy mu Min                -2.2762716
Policy log std Mean          -0.978638
Policy log std Std           0.28326595
Policy log std Max           -0.27180976
Policy log std Min           -3.3776119
Z mean eval                  1.013221
Z variance eval              0.016625134
total_rewards                [2012.25806774 2962.67257713 1446.09640963  270.76107372 1464.41178371
 3151.91837862 1992.99844774 2919.39568346 1228.16081108 3092.10580326]
total_rewards_mean           2054.077903608296
total_rewards_std            918.8177163050285
total_rewards_max            3151.9183786169588
total_rewards_min            270.7610737220083
Number of train steps total  327000
Number of env steps total    1637000
Number of rollouts total     0
Train Time (s)               29.999400584958494
(Previous) Eval Time (s)     20.90222475398332
Sample Time (s)              18.109129247721285
Epoch Time (s)               69.0107545866631
Total Train Time (s)         22568.640735561494
Epoch                        326
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:31:40.851427 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #326 | Epoch Duration: 67.55508255958557
2020-01-11 09:31:40.851618 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #326 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0108467
Z variance train             0.016693287
KL Divergence                21.542694
KL Loss                      2.1542695
QF Loss                      2300.1143
VF Loss                      298.67313
Policy Loss                  -1095.2426
Q Predictions Mean           1093.7769
Q Predictions Std            244.64972
Q Predictions Max            1309.5902
Q Predictions Min            66.785355
V Predictions Mean           1086.2628
V Predictions Std            237.25066
V Predictions Max            1294.487
V Predictions Min            99.09465
Log Pis Mean                 -0.41249755
Log Pis Std                  2.7143507
Log Pis Max                  12.777639
Log Pis Min                  -8.445118
Policy mu Mean               -0.017540082
Policy mu Std                0.5753869
Policy mu Max                2.1969516
Policy mu Min                -2.268235
Policy log std Mean          -0.9741813
Policy log std Std           0.28423056
Policy log std Max           -0.11344057
Policy log std Min           -2.4397233
Z mean eval                  0.98627186
Z variance eval              0.015672084
total_rewards                [1909.78817934 2718.13052556 2924.42198946 2769.27123235 2808.36871235
 2870.59418883  162.17477904  203.19612928 3057.47963266  571.38650523]
total_rewards_mean           1999.4811874087268
total_rewards_std            1146.5984814435212
total_rewards_max            3057.479632655103
total_rewards_min            162.17477903649603
Number of train steps total  328000
Number of env steps total    1642000
Number of rollouts total     0
Train Time (s)               30.92589187808335
(Previous) Eval Time (s)     19.446241817437112
Sample Time (s)              19.155502691864967
Epoch Time (s)               69.52763638738543
Total Train Time (s)         22641.76695746137
Epoch                        327
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:32:53.981176 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #327 | Epoch Duration: 73.12939524650574
2020-01-11 09:32:53.981399 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #327 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98505765
Z variance train             0.015669426
KL Divergence                21.895735
KL Loss                      2.1895735
QF Loss                      1258.0299
VF Loss                      730.30914
Policy Loss                  -1112.8584
Q Predictions Mean           1109.6134
Q Predictions Std            209.02751
Q Predictions Max            1286.0167
Q Predictions Min            147.48439
V Predictions Mean           1105.794
V Predictions Std            203.87537
V Predictions Max            1274.434
V Predictions Min            147.98721
Log Pis Mean                 -0.12019431
Log Pis Std                  2.5969553
Log Pis Max                  9.855599
Log Pis Min                  -7.523113
Policy mu Mean               0.051058814
Policy mu Std                0.6254677
Policy mu Max                2.3373315
Policy mu Min                -2.5957355
Policy log std Mean          -0.9497503
Policy log std Std           0.26105043
Policy log std Max           -0.09415853
Policy log std Min           -2.5332599
Z mean eval                  1.01311
Z variance eval              0.0130971
total_rewards                [ 909.01872284   10.17386052 3238.23525829 1223.94052071 3101.76356484
 2968.09407752 1931.73705137 1909.7262078  2084.49554622  221.42968541]
total_rewards_mean           1759.8614495542013
total_rewards_std            1097.3981954313551
total_rewards_max            3238.2352582942112
total_rewards_min            10.173860520195158
Number of train steps total  329000
Number of env steps total    1647000
Number of rollouts total     0
Train Time (s)               27.71290743490681
(Previous) Eval Time (s)     23.047663446050137
Sample Time (s)              20.623641851358116
Epoch Time (s)               71.38421273231506
Total Train Time (s)         22708.451891373377
Epoch                        328
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:34:00.670786 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #328 | Epoch Duration: 66.68915033340454
2020-01-11 09:34:00.671065 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #328 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0133297
Z variance train             0.013067925
KL Divergence                21.980524
KL Loss                      2.1980524
QF Loss                      933.6843
VF Loss                      229.54549
Policy Loss                  -1068.1036
Q Predictions Mean           1067.8319
Q Predictions Std            270.42514
Q Predictions Max            1292.7567
Q Predictions Min            40.31384
V Predictions Mean           1072.6982
V Predictions Std            274.43942
V Predictions Max            1297.6467
V Predictions Min            46.721237
Log Pis Mean                 -0.43380854
Log Pis Std                  2.8808007
Log Pis Max                  11.471288
Log Pis Min                  -10.779967
Policy mu Mean               0.0480293
Policy mu Std                0.58608437
Policy mu Max                2.252428
Policy mu Min                -2.1639228
Policy log std Mean          -0.97255325
Policy log std Std           0.3025141
Policy log std Max           -0.18034935
Policy log std Min           -2.9356532
Z mean eval                  1.0141777
Z variance eval              0.016378138
total_rewards                [-109.67131953  947.51590451 3037.04057285  179.38526949 2666.9312125
 2767.75352015 2955.95716157 3127.82881186 2935.8113375  2881.0018504 ]
total_rewards_mean           2138.9554321305964
total_rewards_std            1209.4396482068814
total_rewards_max            3127.82881186464
total_rewards_min            -109.67131952717804
Number of train steps total  330000
Number of env steps total    1652000
Number of rollouts total     0
Train Time (s)               27.531206801068038
(Previous) Eval Time (s)     18.352235348895192
Sample Time (s)              18.813197372481227
Epoch Time (s)               64.69663952244446
Total Train Time (s)         22777.244588541333
Epoch                        329
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:35:09.468374 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #329 | Epoch Duration: 68.79711771011353
2020-01-11 09:35:09.468662 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #329 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0145495
Z variance train             0.01636235
KL Divergence                21.83104
KL Loss                      2.183104
QF Loss                      736.398
VF Loss                      379.4298
Policy Loss                  -1080.7457
Q Predictions Mean           1080.5568
Q Predictions Std            262.12393
Q Predictions Max            1301.4941
Q Predictions Min            42.67697
V Predictions Mean           1082.592
V Predictions Std            263.42746
V Predictions Max            1301.015
V Predictions Min            28.612276
Log Pis Mean                 -0.5427434
Log Pis Std                  2.8709419
Log Pis Max                  13.663339
Log Pis Min                  -7.5593815
Policy mu Mean               0.054412667
Policy mu Std                0.5819468
Policy mu Max                2.5031855
Policy mu Min                -2.4969573
Policy log std Mean          -0.96899456
Policy log std Std           0.2745832
Policy log std Max           -0.1563955
Policy log std Min           -2.125781
Z mean eval                  1.0093956
Z variance eval              0.015691474
total_rewards                [ 344.06724436 3111.2437811   284.30800747  610.16978257  877.07448412
 3049.67510441  687.74851337  649.95202675  772.16182603  215.6980281 ]
total_rewards_mean           1060.2098798265365
total_rewards_std            1030.4795738249024
total_rewards_max            3111.24378110261
total_rewards_min            215.69802809536387
Number of train steps total  331000
Number of env steps total    1657000
Number of rollouts total     0
Train Time (s)               26.59391111601144
(Previous) Eval Time (s)     22.452404668089002
Sample Time (s)              17.590869171079248
Epoch Time (s)               66.63718495517969
Total Train Time (s)         22830.98341786256
Epoch                        330
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:36:03.209723 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #330 | Epoch Duration: 53.740864753723145
2020-01-11 09:36:03.209904 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #330 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0134088
Z variance train             0.015688574
KL Divergence                21.902447
KL Loss                      2.1902447
QF Loss                      874.6952
VF Loss                      434.8271
Policy Loss                  -1097.7456
Q Predictions Mean           1100.6458
Q Predictions Std            239.73419
Q Predictions Max            1327.8904
Q Predictions Min            157.22928
V Predictions Mean           1108.8557
V Predictions Std            239.09964
V Predictions Max            1327.3464
V Predictions Min            155.84111
Log Pis Mean                 -0.30314165
Log Pis Std                  2.9428074
Log Pis Max                  19.106916
Log Pis Min                  -8.381808
Policy mu Mean               0.03747081
Policy mu Std                0.6118906
Policy mu Max                4.7597833
Policy mu Min                -4.3533955
Policy log std Mean          -0.9632702
Policy log std Std           0.28059873
Policy log std Max           -0.061739028
Policy log std Min           -2.754671
Z mean eval                  0.97996014
Z variance eval              0.015619941
total_rewards                [-186.47013621  561.80895595 2965.71578644  455.23839156 3234.79346133
 1373.33174974 2922.02583636 3129.48276837  150.50215097 3353.20800506]
total_rewards_mean           1795.963696958536
total_rewards_std            1380.0991836370301
total_rewards_max            3353.2080050648988
total_rewards_min            -186.4701362064267
Number of train steps total  332000
Number of env steps total    1662000
Number of rollouts total     0
Train Time (s)               27.307886332273483
(Previous) Eval Time (s)     9.555800077971071
Sample Time (s)              17.513841789681464
Epoch Time (s)               54.37752819992602
Total Train Time (s)         22900.23929539742
Epoch                        331
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:37:12.468285 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #331 | Epoch Duration: 69.2582528591156
2020-01-11 09:37:12.468473 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #331 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9801356
Z variance train             0.015643282
KL Divergence                22.443674
KL Loss                      2.2443674
QF Loss                      1542.4608
VF Loss                      287.54306
Policy Loss                  -1103.0114
Q Predictions Mean           1101.9076
Q Predictions Std            232.7878
Q Predictions Max            1312.2278
Q Predictions Min            162.67868
V Predictions Mean           1100.1897
V Predictions Std            230.95238
V Predictions Max            1307.3473
V Predictions Min            165.50882
Log Pis Mean                 -0.40033856
Log Pis Std                  2.6982915
Log Pis Max                  9.422277
Log Pis Min                  -8.950502
Policy mu Mean               -0.01276851
Policy mu Std                0.5712364
Policy mu Max                2.0056565
Policy mu Min                -1.837507
Policy log std Mean          -0.9786337
Policy log std Std           0.29005307
Policy log std Max           -0.20102847
Policy log std Min           -2.8527937
Z mean eval                  1.0061114
Z variance eval              0.012132977
total_rewards                [3264.73560543 3111.55222609 3091.95093977 3164.83424697 3119.39033538
 3047.42383527 3073.22557472 3325.20231088 3112.18897573 3074.85845154]
total_rewards_mean           3138.5362501784475
total_rewards_std            84.87813161375037
total_rewards_max            3325.202310878456
total_rewards_min            3047.4238352736725
Number of train steps total  333000
Number of env steps total    1667000
Number of rollouts total     0
Train Time (s)               31.253624157980084
(Previous) Eval Time (s)     24.436217478942126
Sample Time (s)              18.26610183203593
Epoch Time (s)               73.95594346895814
Total Train Time (s)         22977.252759761177
Epoch                        332
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:38:29.483976 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #332 | Epoch Duration: 77.01535940170288
2020-01-11 09:38:29.484135 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #332 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0057746
Z variance train             0.012118997
KL Divergence                22.706846
KL Loss                      2.2706847
QF Loss                      958.2926
VF Loss                      146.52968
Policy Loss                  -1113.2942
Q Predictions Mean           1112.181
Q Predictions Std            220.28905
Q Predictions Max            1301.858
Q Predictions Min            42.649998
V Predictions Mean           1114.5435
V Predictions Std            218.79814
V Predictions Max            1303.9652
V Predictions Min            27.517145
Log Pis Mean                 -0.2512936
Log Pis Std                  2.841677
Log Pis Max                  12.135904
Log Pis Min                  -6.8263865
Policy mu Mean               0.014362231
Policy mu Std                0.5613972
Policy mu Max                1.8486516
Policy mu Min                -1.9904436
Policy log std Mean          -1.0077544
Policy log std Std           0.303988
Policy log std Max           -0.21158332
Policy log std Min           -3.3083353
Z mean eval                  0.98039734
Z variance eval              0.01395447
total_rewards                [3212.89759065 1795.2768866  3126.27605596 3114.3169011  3386.30782871
 1335.6649466  1546.06011425 3073.88009889 3100.86251999 3272.51397862]
total_rewards_mean           2696.4056921362762
total_rewards_std            756.7749736851883
total_rewards_max            3386.307828711522
total_rewards_min            1335.664946598414
Number of train steps total  334000
Number of env steps total    1672000
Number of rollouts total     0
Train Time (s)               26.145671343896538
(Previous) Eval Time (s)     27.495289932005107
Sample Time (s)              18.90292161051184
Epoch Time (s)               72.54388288641348
Total Train Time (s)         23046.899279094767
Epoch                        333
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:39:39.133781 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #333 | Epoch Duration: 69.64952111244202
2020-01-11 09:39:39.133971 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #333 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98250306
Z variance train             0.014020848
KL Divergence                22.594975
KL Loss                      2.2594974
QF Loss                      11426.663
VF Loss                      1501.8892
Policy Loss                  -1114.4635
Q Predictions Mean           1110.7932
Q Predictions Std            209.51442
Q Predictions Max            1314.1178
Q Predictions Min            -49.061455
V Predictions Mean           1103.9962
V Predictions Std            199.2326
V Predictions Max            1299.5178
V Predictions Min            153.7362
Log Pis Mean                 -0.27356648
Log Pis Std                  2.6017087
Log Pis Max                  11.206686
Log Pis Min                  -9.097956
Policy mu Mean               0.030752879
Policy mu Std                0.5932675
Policy mu Max                2.0018454
Policy mu Min                -2.0251951
Policy log std Mean          -0.9664303
Policy log std Std           0.275216
Policy log std Max           -0.0020769835
Policy log std Min           -3.1481304
Z mean eval                  0.9855746
Z variance eval              0.015951067
total_rewards                [2947.42313435 2988.16841616 2955.38856696 3078.11256179 1638.58010997
 2559.81288295 3261.89318863 3192.92637344 3290.95618573 1169.28722408]
total_rewards_mean           2708.2548644052613
total_rewards_std            689.1332263619211
total_rewards_max            3290.9561857306335
total_rewards_min            1169.287224079873
Number of train steps total  335000
Number of env steps total    1677000
Number of rollouts total     0
Train Time (s)               30.098564783111215
(Previous) Eval Time (s)     24.600595560856164
Sample Time (s)              18.092898750677705
Epoch Time (s)               72.79205909464508
Total Train Time (s)         23118.764009451494
Epoch                        334
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:40:51.003016 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #334 | Epoch Duration: 71.86890459060669
2020-01-11 09:40:51.003249 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #334 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9857038
Z variance train             0.015856652
KL Divergence                22.903809
KL Loss                      2.290381
QF Loss                      729.42444
VF Loss                      283.00958
Policy Loss                  -1101.5433
Q Predictions Mean           1100.4724
Q Predictions Std            222.38223
Q Predictions Max            1301.8585
Q Predictions Min            4.0107846
V Predictions Mean           1095.3679
V Predictions Std            219.32332
V Predictions Max            1288.9491
V Predictions Min            34.744167
Log Pis Mean                 -0.24278314
Log Pis Std                  2.4804995
Log Pis Max                  11.56436
Log Pis Min                  -8.404519
Policy mu Mean               0.0795421
Policy mu Std                0.5795621
Policy mu Max                2.8574622
Policy mu Min                -2.2091978
Policy log std Mean          -0.94147545
Policy log std Std           0.25114918
Policy log std Max           -0.15013409
Policy log std Min           -1.9367919
Z mean eval                  1.0075462
Z variance eval              0.015700078
total_rewards                [1449.27270503 3088.36637412 1130.40408853  252.93768704 3013.92192989
 2788.0577749  1225.36512473 2998.28822529 1663.76780118 3037.55992194]
total_rewards_mean           2064.794163265771
total_rewards_std            984.3564825209534
total_rewards_max            3088.3663741205232
total_rewards_min            252.93768703909274
Number of train steps total  336000
Number of env steps total    1682000
Number of rollouts total     0
Train Time (s)               30.345483750104904
(Previous) Eval Time (s)     23.67708579869941
Sample Time (s)              19.075644710101187
Epoch Time (s)               73.0982142589055
Total Train Time (s)         23191.790534154512
Epoch                        335
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:42:04.032557 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #335 | Epoch Duration: 73.02912497520447
2020-01-11 09:42:04.032724 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #335 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0084544
Z variance train             0.015699312
KL Divergence                22.964191
KL Loss                      2.2964191
QF Loss                      644.23535
VF Loss                      124.45215
Policy Loss                  -1073.1874
Q Predictions Mean           1074.2439
Q Predictions Std            277.87787
Q Predictions Max            1273.442
Q Predictions Min            111.43658
V Predictions Mean           1079.0271
V Predictions Std            278.01294
V Predictions Max            1285.9485
V Predictions Min            111.15867
Log Pis Mean                 -0.23913115
Log Pis Std                  2.8329732
Log Pis Max                  10.394018
Log Pis Min                  -7.0644073
Policy mu Mean               0.0101633975
Policy mu Std                0.59020734
Policy mu Max                2.6376216
Policy mu Min                -2.447815
Policy log std Mean          -0.9490113
Policy log std Std           0.29378635
Policy log std Max           -0.18623269
Policy log std Min           -2.3823
Z mean eval                  1.0585359
Z variance eval              0.0143991355
total_rewards                [2748.91939787 2854.23782415 2968.91687925  -58.6388457  1856.43361716
  339.36813916 1032.36394852  255.09230477  396.61484879 1440.18977742]
total_rewards_mean           1383.3497891402917
total_rewards_std            1109.4316031224064
total_rewards_max            2968.9168792525234
total_rewards_min            -58.63884570443368
Number of train steps total  337000
Number of env steps total    1687000
Number of rollouts total     0
Train Time (s)               27.790129837114364
(Previous) Eval Time (s)     23.607661546673626
Sample Time (s)              18.21917873248458
Epoch Time (s)               69.61697011627257
Total Train Time (s)         23258.84704296058
Epoch                        336
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:43:11.092594 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #336 | Epoch Duration: 67.05972409248352
2020-01-11 09:43:11.092836 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #336 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0597084
Z variance train             0.0142875705
KL Divergence                24.064793
KL Loss                      2.4064794
QF Loss                      955.69324
VF Loss                      353.61298
Policy Loss                  -1129.9073
Q Predictions Mean           1128.947
Q Predictions Std            235.53001
Q Predictions Max            1342.2135
Q Predictions Min            61.66643
V Predictions Mean           1116.9443
V Predictions Std            232.19313
V Predictions Max            1327.3599
V Predictions Min            62.647293
Log Pis Mean                 -0.12697978
Log Pis Std                  2.6838152
Log Pis Max                  9.938757
Log Pis Min                  -8.741535
Policy mu Mean               0.044260193
Policy mu Std                0.5883558
Policy mu Max                2.1718018
Policy mu Min                -2.116065
Policy log std Mean          -0.9881339
Policy log std Std           0.27029583
Policy log std Max           -0.2166661
Policy log std Min           -2.425599
Z mean eval                  0.9894913
Z variance eval              0.013674943
total_rewards                [ 348.27133472 1639.76277605  620.35734945  368.16740248 3061.52435774
 -109.53870167 2474.60649786 3113.18277295  584.88327987  685.53840808]
total_rewards_mean           1278.675547751233
total_rewards_std            1139.8666402106435
total_rewards_max            3113.18277294976
total_rewards_min            -109.53870166870782
Number of train steps total  338000
Number of env steps total    1692000
Number of rollouts total     0
Train Time (s)               29.828878290951252
(Previous) Eval Time (s)     21.05007706908509
Sample Time (s)              19.27167836483568
Epoch Time (s)               70.15063372487202
Total Train Time (s)         23326.74126715213
Epoch                        337
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:44:18.989938 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #337 | Epoch Duration: 67.89692234992981
2020-01-11 09:44:18.990125 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #337 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9895727
Z variance train             0.0136191845
KL Divergence                23.6035
KL Loss                      2.3603501
QF Loss                      483.7822
VF Loss                      180.73303
Policy Loss                  -1129.1919
Q Predictions Mean           1132.02
Q Predictions Std            210.75204
Q Predictions Max            1350.0256
Q Predictions Min            126.762215
V Predictions Mean           1137.1193
V Predictions Std            213.21234
V Predictions Max            1343.9484
V Predictions Min            118.6183
Log Pis Mean                 -0.5265158
Log Pis Std                  2.395001
Log Pis Max                  8.30299
Log Pis Min                  -6.5455317
Policy mu Mean               0.002255537
Policy mu Std                0.5534995
Policy mu Max                1.818382
Policy mu Min                -1.9700211
Policy log std Mean          -0.9719348
Policy log std Std           0.26262876
Policy log std Max           -0.1879493
Policy log std Min           -2.406204
Z mean eval                  1.0064907
Z variance eval              0.012592685
total_rewards                [ 961.82237782 3099.40220154 3287.62616448  646.55201357 3070.24123785
 3231.35342943 2321.92580719   81.34760261 3239.8635076   920.03034903]
total_rewards_mean           2086.016469111829
total_rewards_std            1218.7050104506732
total_rewards_max            3287.6261644754486
total_rewards_min            81.34760261138914
Number of train steps total  339000
Number of env steps total    1697000
Number of rollouts total     0
Train Time (s)               26.95043887803331
(Previous) Eval Time (s)     18.79604686331004
Sample Time (s)              18.1165960887447
Epoch Time (s)               63.86308183008805
Total Train Time (s)         23396.78976703575
Epoch                        338
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:45:29.041841 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #338 | Epoch Duration: 70.05155873298645
2020-01-11 09:45:29.042068 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #338 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0051088
Z variance train             0.012593739
KL Divergence                23.759153
KL Loss                      2.3759153
QF Loss                      915.0687
VF Loss                      203.14198
Policy Loss                  -1117.911
Q Predictions Mean           1117.1389
Q Predictions Std            235.59557
Q Predictions Max            1359.5723
Q Predictions Min            99.75943
V Predictions Mean           1111.5612
V Predictions Std            232.50467
V Predictions Max            1355.5189
V Predictions Min            102.075226
Log Pis Mean                 0.0012730733
Log Pis Std                  2.815766
Log Pis Max                  16.12265
Log Pis Min                  -9.113911
Policy mu Mean               0.034475062
Policy mu Std                0.6325057
Policy mu Max                2.6324263
Policy mu Min                -3.27812
Policy log std Mean          -0.9366188
Policy log std Std           0.27007928
Policy log std Max           -0.18944788
Policy log std Min           -2.595179
Z mean eval                  1.0653112
Z variance eval              0.020901611
total_rewards                [1227.42425877  684.80109851  600.89691616 2680.81287372 2015.06274758
  156.87961183 2808.1075737  2801.30826338  390.46006706 1104.12048544]
total_rewards_mean           1446.98738961487
total_rewards_std            988.6889752494366
total_rewards_max            2808.1075736978405
total_rewards_min            156.87961183312802
Number of train steps total  340000
Number of env steps total    1702000
Number of rollouts total     0
Train Time (s)               28.763451101258397
(Previous) Eval Time (s)     24.984167526010424
Sample Time (s)              17.628152278717607
Epoch Time (s)               71.37577090598643
Total Train Time (s)         23461.292512598913
Epoch                        339
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:46:33.551514 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #339 | Epoch Duration: 64.50913333892822
2020-01-11 09:46:33.551960 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #339 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0634041
Z variance train             0.020959137
KL Divergence                23.092806
KL Loss                      2.3092806
QF Loss                      2181.1392
VF Loss                      222.3195
Policy Loss                  -1157.6672
Q Predictions Mean           1157.204
Q Predictions Std            177.55844
Q Predictions Max            1357.7142
Q Predictions Min            136.96725
V Predictions Mean           1162.2233
V Predictions Std            174.142
V Predictions Max            1351.7695
V Predictions Min            150.87085
Log Pis Mean                 -0.11877778
Log Pis Std                  3.0626338
Log Pis Max                  10.375174
Log Pis Min                  -7.6926894
Policy mu Mean               -0.04435087
Policy mu Std                0.6157241
Policy mu Max                2.553758
Policy mu Min                -2.4193523
Policy log std Mean          -0.9862424
Policy log std Std           0.27491507
Policy log std Max           -0.17310524
Policy log std Min           -2.2921767
Z mean eval                  0.99839145
Z variance eval              0.015132224
total_rewards                [ 806.82691867 3160.61200699 3140.52678248  663.75250207 2937.69049124
 3082.08724353 3094.07340833 3118.39462603 1317.31327084 1062.3079433 ]
total_rewards_mean           2238.3585193472777
total_rewards_std            1055.0924176698907
total_rewards_max            3160.6120069898852
total_rewards_min            663.7525020700627
Number of train steps total  341000
Number of env steps total    1707000
Number of rollouts total     0
Train Time (s)               30.28406098810956
(Previous) Eval Time (s)     18.117219371255487
Sample Time (s)              18.056381749920547
Epoch Time (s)               66.4576621092856
Total Train Time (s)         23534.112977497745
Epoch                        340
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:47:46.373264 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #340 | Epoch Duration: 72.82108426094055
2020-01-11 09:47:46.373471 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #340 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99843633
Z variance train             0.015100582
KL Divergence                23.128551
KL Loss                      2.3128552
QF Loss                      1051.849
VF Loss                      60.90102
Policy Loss                  -1132.3905
Q Predictions Mean           1134.3567
Q Predictions Std            229.92581
Q Predictions Max            1339.6111
Q Predictions Min            111.18436
V Predictions Mean           1132.7079
V Predictions Std            231.83633
V Predictions Max            1333.8518
V Predictions Min            122.32173
Log Pis Mean                 -0.5684651
Log Pis Std                  2.4536588
Log Pis Max                  10.543291
Log Pis Min                  -7.4283695
Policy mu Mean               0.056919143
Policy mu Std                0.56682813
Policy mu Max                3.2122946
Policy mu Min                -2.2092412
Policy log std Mean          -0.9384762
Policy log std Std           0.2520016
Policy log std Max           -0.08661628
Policy log std Min           -2.503862
Z mean eval                  1.0120938
Z variance eval              0.015579127
total_rewards                [1222.15263142 3021.21079038 2945.66332501  523.02942623 2882.9082599
 3051.20291988 1020.17636398 1577.32508019 3040.58899098 2804.81237997]
total_rewards_mean           2208.907016795431
total_rewards_std            950.8432691757293
total_rewards_max            3051.202919879922
total_rewards_min            523.0294262348935
Number of train steps total  342000
Number of env steps total    1712000
Number of rollouts total     0
Train Time (s)               29.17287139268592
(Previous) Eval Time (s)     24.480346056167036
Sample Time (s)              17.6835624887608
Epoch Time (s)               71.33677993761376
Total Train Time (s)         23602.103146431968
Epoch                        341
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:48:54.369796 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #341 | Epoch Duration: 67.996084690094
2020-01-11 09:48:54.370134 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #341 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.012646
Z variance train             0.015566254
KL Divergence                23.408136
KL Loss                      2.3408136
QF Loss                      8504.771
VF Loss                      634.44867
Policy Loss                  -1129.1666
Q Predictions Mean           1131.9376
Q Predictions Std            211.33183
Q Predictions Max            1334.1078
Q Predictions Min            151.39996
V Predictions Mean           1145.8435
V Predictions Std            212.23349
V Predictions Max            1335.6917
V Predictions Min            166.52692
Log Pis Mean                 -0.19506562
Log Pis Std                  2.8894563
Log Pis Max                  10.981052
Log Pis Min                  -9.987757
Policy mu Mean               0.038590923
Policy mu Std                0.5931163
Policy mu Max                2.2683482
Policy mu Min                -3.013198
Policy log std Mean          -0.9701901
Policy log std Std           0.28739268
Policy log std Max           -0.0998981
Policy log std Min           -2.977436
Z mean eval                  1.0061404
Z variance eval              0.013730337
total_rewards                [-160.76807282 2910.08904214 3083.42826781 2918.51261039 2013.29093666
 2953.9213003  2884.19678994 1216.63600485 3095.04606946 2742.49581631]
total_rewards_mean           2365.684876504854
total_rewards_std            1011.6046760907965
total_rewards_max            3095.0460694631665
total_rewards_min            -160.7680728162801
Number of train steps total  343000
Number of env steps total    1717000
Number of rollouts total     0
Train Time (s)               29.991128124762326
(Previous) Eval Time (s)     21.139308491256088
Sample Time (s)              18.474988873116672
Epoch Time (s)               69.60542548913509
Total Train Time (s)         23676.23834009003
Epoch                        342
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:50:08.509244 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #342 | Epoch Duration: 74.13889646530151
2020-01-11 09:50:08.509514 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #342 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0021851
Z variance train             0.013741235
KL Divergence                23.527172
KL Loss                      2.3527172
QF Loss                      529.3707
VF Loss                      175.79672
Policy Loss                  -1113.5261
Q Predictions Mean           1113.3152
Q Predictions Std            267.33856
Q Predictions Max            1362.2213
Q Predictions Min            59.64902
V Predictions Mean           1104.59
V Predictions Std            264.79172
V Predictions Max            1354.8634
V Predictions Min            39.760944
Log Pis Mean                 -0.44912222
Log Pis Std                  2.7602115
Log Pis Max                  9.698363
Log Pis Min                  -8.120164
Policy mu Mean               0.010129589
Policy mu Std                0.56122214
Policy mu Max                2.300055
Policy mu Min                -2.4373324
Policy log std Mean          -0.9729006
Policy log std Std           0.2749512
Policy log std Max           -0.18550432
Policy log std Min           -2.588779
Z mean eval                  0.99899626
Z variance eval              0.011868527
total_rewards                [2347.15621746 3085.92956803  969.09641351 3078.13858161 1604.60706619
 3243.95043207 3175.68054427 2988.35680414 2975.55875133 3211.26751191]
total_rewards_mean           2667.97418905201
total_rewards_std            744.6285198790628
total_rewards_max            3243.950432065898
total_rewards_min            969.0964135102514
Number of train steps total  344000
Number of env steps total    1722000
Number of rollouts total     0
Train Time (s)               31.200308417901397
(Previous) Eval Time (s)     25.67247076611966
Sample Time (s)              19.216132619418204
Epoch Time (s)               76.08891180343926
Total Train Time (s)         23751.552873493172
Epoch                        343
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:51:23.826483 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #343 | Epoch Duration: 75.31677746772766
2020-01-11 09:51:23.826670 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #343 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9991425
Z variance train             0.011851093
KL Divergence                23.61214
KL Loss                      2.3612142
QF Loss                      681.8482
VF Loss                      123.613716
Policy Loss                  -1119.0637
Q Predictions Mean           1117.032
Q Predictions Std            243.25952
Q Predictions Max            1355.1346
Q Predictions Min            84.89583
V Predictions Mean           1115.5583
V Predictions Std            243.80424
V Predictions Max            1357.8877
V Predictions Min            90.407394
Log Pis Mean                 -0.3214483
Log Pis Std                  2.9116178
Log Pis Max                  10.344496
Log Pis Min                  -9.428064
Policy mu Mean               0.040066212
Policy mu Std                0.58150506
Policy mu Max                2.366848
Policy mu Min                -1.8184624
Policy log std Mean          -0.98428345
Policy log std Std           0.28501055
Policy log std Max           -0.17060858
Policy log std Min           -2.4851542
Z mean eval                  1.0478674
Z variance eval              0.011888896
total_rewards                [3071.41800698 1399.46182292 3090.93220896 2262.64977786  336.78875019
 2911.90869744 3081.14287068 3326.39815689 3059.77353246 2833.48932151]
total_rewards_mean           2537.3963145882194
total_rewards_std            906.8422216343856
total_rewards_max            3326.3981568875483
total_rewards_min            336.7887501897336
Number of train steps total  345000
Number of env steps total    1727000
Number of rollouts total     0
Train Time (s)               28.445981533266604
(Previous) Eval Time (s)     24.900008044671267
Sample Time (s)              17.63771555479616
Epoch Time (s)               70.98370513273403
Total Train Time (s)         23824.778746361844
Epoch                        344
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:52:37.055437 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #344 | Epoch Duration: 73.22863245010376
2020-01-11 09:52:37.055627 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #344 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0503956
Z variance train             0.0118877385
KL Divergence                23.524467
KL Loss                      2.3524468
QF Loss                      953.94775
VF Loss                      643.85913
Policy Loss                  -1131.5868
Q Predictions Mean           1131.8326
Q Predictions Std            236.75076
Q Predictions Max            1333.1141
Q Predictions Min            75.219406
V Predictions Mean           1138.1904
V Predictions Std            232.07797
V Predictions Max            1337.3877
V Predictions Min            28.03419
Log Pis Mean                 -0.22509284
Log Pis Std                  2.6278906
Log Pis Max                  10.221614
Log Pis Min                  -8.52687
Policy mu Mean               0.014011652
Policy mu Std                0.5798057
Policy mu Max                2.6053495
Policy mu Min                -2.093813
Policy log std Mean          -0.99760866
Policy log std Std           0.26708522
Policy log std Max           -0.20095092
Policy log std Min           -2.7023783
Z mean eval                  1.0210333
Z variance eval              0.013089339
total_rewards                [3187.92755587 2913.1492654  3147.66261991 2985.14398022 1779.4372261
  551.33094675 2477.039782   1313.62867489 3099.00355701 3175.90566792]
total_rewards_mean           2463.0229276055093
total_rewards_std            884.6058311857405
total_rewards_max            3187.927555871457
total_rewards_min            551.3309467478733
Number of train steps total  346000
Number of env steps total    1732000
Number of rollouts total     0
Train Time (s)               30.55469521973282
(Previous) Eval Time (s)     27.144625267013907
Sample Time (s)              17.700904830824584
Epoch Time (s)               75.40022531757131
Total Train Time (s)         23895.77500326652
Epoch                        345
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:53:48.058329 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #345 | Epoch Duration: 71.00252437591553
2020-01-11 09:53:48.058641 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #345 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0233264
Z variance train             0.013159819
KL Divergence                23.42455
KL Loss                      2.342455
QF Loss                      1950.8151
VF Loss                      583.3455
Policy Loss                  -1138.8539
Q Predictions Mean           1136.176
Q Predictions Std            231.14006
Q Predictions Max            1351.795
Q Predictions Min            10.133749
V Predictions Mean           1133.0787
V Predictions Std            227.39757
V Predictions Max            1357.2972
V Predictions Min            78.32524
Log Pis Mean                 -0.12351492
Log Pis Std                  2.6494067
Log Pis Max                  9.951696
Log Pis Min                  -6.0199137
Policy mu Mean               0.059942633
Policy mu Std                0.59608084
Policy mu Max                2.6035168
Policy mu Min                -2.0299034
Policy log std Mean          -0.9619647
Policy log std Std           0.2943348
Policy log std Max           -0.20197773
Policy log std Min           -3.5277417
Z mean eval                  1.0152324
Z variance eval              0.014301151
total_rewards                [1919.73093423  694.99003256 3292.21477951 3495.42936504 3314.4928653
 3221.90753859  366.1989113  3134.7998546  3284.1291801  3391.27558428]
total_rewards_mean           2611.5169045508474
total_rewards_std            1124.222160008246
total_rewards_max            3495.4293650365753
total_rewards_min            366.19891130105276
Number of train steps total  347000
Number of env steps total    1737000
Number of rollouts total     0
Train Time (s)               29.277839341200888
(Previous) Eval Time (s)     22.74661434534937
Sample Time (s)              18.04166539432481
Epoch Time (s)               70.06611908087507
Total Train Time (s)         23968.444123731926
Epoch                        346
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:55:00.730312 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #346 | Epoch Duration: 72.6714415550232
2020-01-11 09:55:00.730497 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #346 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.016099
Z variance train             0.014342857
KL Divergence                22.985184
KL Loss                      2.2985184
QF Loss                      868.6992
VF Loss                      876.0865
Policy Loss                  -1122.3066
Q Predictions Mean           1122.8259
Q Predictions Std            241.61356
Q Predictions Max            1318.1366
Q Predictions Min            137.66273
V Predictions Mean           1111.2498
V Predictions Std            241.68336
V Predictions Max            1309.7128
V Predictions Min            133.37546
Log Pis Mean                 -0.13698567
Log Pis Std                  2.6683178
Log Pis Max                  11.361408
Log Pis Min                  -6.7082357
Policy mu Mean               0.009386364
Policy mu Std                0.59610707
Policy mu Max                2.2855594
Policy mu Min                -2.6740198
Policy log std Mean          -0.98364043
Policy log std Std           0.295514
Policy log std Max           -0.21451795
Policy log std Min           -3.0903282
Z mean eval                  1.0061524
Z variance eval              0.013825262
total_rewards                [3036.3049446  3123.81338005 2499.42823278 3225.442933   3006.34862075
 3383.11481456 3018.13214963 2710.69153237 3084.54751374 3263.21465026]
total_rewards_mean           3035.1038771728513
total_rewards_std            247.58781370378227
total_rewards_max            3383.114814562514
total_rewards_min            2499.4282327754527
Number of train steps total  348000
Number of env steps total    1742000
Number of rollouts total     0
Train Time (s)               25.97595457592979
(Previous) Eval Time (s)     25.351656186860055
Sample Time (s)              18.42848982801661
Epoch Time (s)               69.75610059080645
Total Train Time (s)         24038.397015915718
Epoch                        347
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:56:10.686615 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #347 | Epoch Duration: 69.95595240592957
2020-01-11 09:56:10.686827 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #347 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0047374
Z variance train             0.013784816
KL Divergence                22.978567
KL Loss                      2.2978568
QF Loss                      947.1095
VF Loss                      320.28424
Policy Loss                  -1133.5465
Q Predictions Mean           1133.7617
Q Predictions Std            224.21912
Q Predictions Max            1343.9856
Q Predictions Min            47.69711
V Predictions Mean           1120.0757
V Predictions Std            219.77686
V Predictions Max            1332.5707
V Predictions Min            53.727222
Log Pis Mean                 -0.17436305
Log Pis Std                  2.7216983
Log Pis Max                  15.206807
Log Pis Min                  -8.443073
Policy mu Mean               0.03972049
Policy mu Std                0.57565856
Policy mu Max                2.61658
Policy mu Min                -2.2030704
Policy log std Mean          -0.9781349
Policy log std Std           0.2669909
Policy log std Max           -0.20717508
Policy log std Min           -2.986608
Z mean eval                  1.027374
Z variance eval              0.007649748
total_rewards                [ 858.09034437  596.00474523  515.80730139 2728.08616755 3031.39256064
   84.47355462 1381.22751859 2287.04974511 2899.54823876 3241.31866956]
total_rewards_mean           1762.2998845834277
total_rewards_std            1139.7996539998096
total_rewards_max            3241.318669561993
total_rewards_min            84.47355462493428
Number of train steps total  349000
Number of env steps total    1747000
Number of rollouts total     0
Train Time (s)               28.461923066992313
(Previous) Eval Time (s)     25.551175964064896
Sample Time (s)              17.916298083029687
Epoch Time (s)               71.9293971140869
Total Train Time (s)         24101.813871048857
Epoch                        348
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:57:14.107835 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #348 | Epoch Duration: 63.42081928253174
2020-01-11 09:57:14.108064 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #348 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0279965
Z variance train             0.0076353317
KL Divergence                24.696949
KL Loss                      2.4696949
QF Loss                      1769.1106
VF Loss                      194.13562
Policy Loss                  -1141.7802
Q Predictions Mean           1145.0074
Q Predictions Std            241.42737
Q Predictions Max            1353.715
Q Predictions Min            4.625004
V Predictions Mean           1150.8037
V Predictions Std            240.73193
V Predictions Max            1344.6644
V Predictions Min            14.192532
Log Pis Mean                 -0.09663627
Log Pis Std                  2.9284766
Log Pis Max                  13.985065
Log Pis Min                  -8.067235
Policy mu Mean               -0.010002548
Policy mu Std                0.6607612
Policy mu Max                3.1375005
Policy mu Min                -2.9943266
Policy log std Mean          -0.94692546
Policy log std Std           0.25859433
Policy log std Max           -0.24249518
Policy log std Min           -2.0995965
Z mean eval                  1.043331
Z variance eval              0.010283906
total_rewards                [2830.89102761 2918.74732766 3169.85552961 3032.20905355 2031.55525604
 2983.84654327 3048.83228467 3105.94978928 3130.5458637  3241.06225186]
total_rewards_mean           2949.3494927248757
total_rewards_std            326.5490414088069
total_rewards_max            3241.062251857391
total_rewards_min            2031.5552560386027
Number of train steps total  350000
Number of env steps total    1752000
Number of rollouts total     0
Train Time (s)               30.89896528236568
(Previous) Eval Time (s)     17.042256526183337
Sample Time (s)              18.205460749100894
Epoch Time (s)               66.14668255764991
Total Train Time (s)         24176.888787053525
Epoch                        349
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:58:29.184840 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #349 | Epoch Duration: 75.07661128044128
2020-01-11 09:58:29.184993 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #349 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0421137
Z variance train             0.010282113
KL Divergence                24.46883
KL Loss                      2.446883
QF Loss                      711.8219
VF Loss                      115.42007
Policy Loss                  -1162.5277
Q Predictions Mean           1162.9414
Q Predictions Std            201.64297
Q Predictions Max            1357.8354
Q Predictions Min            10.596499
V Predictions Mean           1160.4403
V Predictions Std            200.65007
V Predictions Max            1333.9377
V Predictions Min            1.8635069
Log Pis Mean                 -0.15805644
Log Pis Std                  2.5731454
Log Pis Max                  8.966317
Log Pis Min                  -8.428847
Policy mu Mean               -0.045564108
Policy mu Std                0.5831258
Policy mu Max                1.9893576
Policy mu Min                -2.201113
Policy log std Mean          -0.9968686
Policy log std Std           0.2666649
Policy log std Max           0.17035675
Policy log std Min           -2.1928613
Z mean eval                  1.0179751
Z variance eval              0.01309344
total_rewards                [ 725.0227942  3571.54941839 2063.20269461  583.50660071 1030.02928877
  925.00155516  958.52606606 1375.74696853 3421.11467048 3419.06222223]
total_rewards_mean           1807.2762279136616
total_rewards_std            1154.9236855293016
total_rewards_max            3571.5494183896053
total_rewards_min            583.5066007088792
Number of train steps total  351000
Number of env steps total    1757000
Number of rollouts total     0
Train Time (s)               30.73679610528052
(Previous) Eval Time (s)     25.971876721829176
Sample Time (s)              18.23699684534222
Epoch Time (s)               74.94566967245191
Total Train Time (s)         24242.03011422651
Epoch                        350
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:59:34.333029 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #350 | Epoch Duration: 65.14787435531616
2020-01-11 09:59:34.333337 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #350 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0201255
Z variance train             0.0130569395
KL Divergence                23.714508
KL Loss                      2.371451
QF Loss                      1085.0593
VF Loss                      196.24672
Policy Loss                  -1149.7734
Q Predictions Mean           1147.9031
Q Predictions Std            210.47319
Q Predictions Max            1375.7311
Q Predictions Min            57.119873
V Predictions Mean           1140.1796
V Predictions Std            211.88382
V Predictions Max            1363.57
V Predictions Min            39.945023
Log Pis Mean                 -0.2042175
Log Pis Std                  2.5747724
Log Pis Max                  8.523798
Log Pis Min                  -7.495237
Policy mu Mean               0.016942088
Policy mu Std                0.60405105
Policy mu Max                2.2705548
Policy mu Min                -2.0706096
Policy log std Mean          -0.9848777
Policy log std Std           0.23309116
Policy log std Max           -0.2047475
Policy log std Min           -2.1437297
Z mean eval                  1.0382478
Z variance eval              0.015079315
total_rewards                [3317.74266806 3108.19440897 3046.34903227  254.68992717  935.11963782
 3224.09826855 2960.57616969 3065.28555697 3500.05580061 3388.41306612]
total_rewards_mean           2680.0524536223406
total_rewards_std            1065.2964675508138
total_rewards_max            3500.0558006147576
total_rewards_min            254.68992717393064
Number of train steps total  352000
Number of env steps total    1762000
Number of rollouts total     0
Train Time (s)               26.677798813208938
(Previous) Eval Time (s)     16.173750557936728
Sample Time (s)              19.6432752199471
Epoch Time (s)               62.494824591092765
Total Train Time (s)         24312.767424063757
Epoch                        351
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:00:45.075698 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #351 | Epoch Duration: 70.74211764335632
2020-01-11 10:00:45.076002 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #351 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0395072
Z variance train             0.015084542
KL Divergence                22.677511
KL Loss                      2.2677512
QF Loss                      768.61
VF Loss                      319.9837
Policy Loss                  -1135.1593
Q Predictions Mean           1133.7302
Q Predictions Std            237.34637
Q Predictions Max            1350.322
Q Predictions Min            52.11398
V Predictions Mean           1134.6414
V Predictions Std            233.54732
V Predictions Max            1351.8501
V Predictions Min            58.588627
Log Pis Mean                 -0.041531906
Log Pis Std                  2.7290103
Log Pis Max                  12.009189
Log Pis Min                  -7.414036
Policy mu Mean               -0.055245966
Policy mu Std                0.6157071
Policy mu Max                2.353957
Policy mu Min                -2.3876235
Policy log std Mean          -0.9782201
Policy log std Std           0.27312654
Policy log std Max           -0.19204748
Policy log std Min           -2.56414
Z mean eval                  1.0066975
Z variance eval              0.012123516
total_rewards                [ 398.9245151    62.65138576 1710.44362826 3172.87039303 3321.21251161
 1498.31709131  857.12777707 3272.07565356 1906.94809532 3264.46529654]
total_rewards_mean           1946.5036347564333
total_rewards_std            1194.8541489612896
total_rewards_max            3321.212511607302
total_rewards_min            62.651385762017725
Number of train steps total  353000
Number of env steps total    1767000
Number of rollouts total     0
Train Time (s)               28.313547597732395
(Previous) Eval Time (s)     24.420731232035905
Sample Time (s)              18.143305318430066
Epoch Time (s)               70.87758414819837
Total Train Time (s)         24375.54909896385
Epoch                        352
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:01:47.860021 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #352 | Epoch Duration: 62.783809423446655
2020-01-11 10:01:47.860207 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #352 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0075824
Z variance train             0.012092894
KL Divergence                23.946135
KL Loss                      2.3946135
QF Loss                      1170.1936
VF Loss                      569.232
Policy Loss                  -1162.9058
Q Predictions Mean           1160.9248
Q Predictions Std            221.4864
Q Predictions Max            1356.2285
Q Predictions Min            109.30809
V Predictions Mean           1162.3456
V Predictions Std            219.98776
V Predictions Max            1357.3015
V Predictions Min            142.18544
Log Pis Mean                 -0.46135747
Log Pis Std                  2.7501864
Log Pis Max                  14.613127
Log Pis Min                  -9.430922
Policy mu Mean               0.031094845
Policy mu Std                0.5877112
Policy mu Max                2.3381498
Policy mu Min                -2.3357341
Policy log std Mean          -0.96597505
Policy log std Std           0.27442017
Policy log std Max           -0.18238133
Policy log std Min           -3.1193838
Z mean eval                  1.0462314
Z variance eval              0.009773475
total_rewards                [3182.01150558 3016.54039299 1664.95998553 1292.46835558 3324.48042914
 3185.00457663 3140.20407638 1759.75137823 3359.23660438 1633.56726304]
total_rewards_mean           2555.822456746556
total_rewards_std            803.2458192904763
total_rewards_max            3359.2366043768193
total_rewards_min            1292.4683555803435
Number of train steps total  354000
Number of env steps total    1772000
Number of rollouts total     0
Train Time (s)               29.52053381688893
(Previous) Eval Time (s)     16.32666878402233
Sample Time (s)              17.421928016934544
Epoch Time (s)               63.2691306178458
Total Train Time (s)         24445.61304865824
Epoch                        353
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:02:57.931881 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #353 | Epoch Duration: 70.07148671150208
2020-01-11 10:02:57.932121 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #353 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0465553
Z variance train             0.00977569
KL Divergence                24.31175
KL Loss                      2.431175
QF Loss                      6096.42
VF Loss                      181.58435
Policy Loss                  -1157.1759
Q Predictions Mean           1157.9965
Q Predictions Std            210.44006
Q Predictions Max            1330.3423
Q Predictions Min            19.885221
V Predictions Mean           1161.9243
V Predictions Std            210.66046
V Predictions Max            1335.6797
V Predictions Min            2.1584418
Log Pis Mean                 -0.041750822
Log Pis Std                  2.6157863
Log Pis Max                  15.470556
Log Pis Min                  -6.0335917
Policy mu Mean               -0.022597253
Policy mu Std                0.5985908
Policy mu Max                2.173489
Policy mu Min                -2.2734122
Policy log std Mean          -0.969661
Policy log std Std           0.2788658
Policy log std Max           0.5422113
Policy log std Min           -3.2825923
Z mean eval                  1.0432452
Z variance eval              0.008254779
total_rewards                [ -98.2889366  3052.89986224 1802.1979627  3389.61250017 1719.33866363
 1982.1213579   772.01090628 1464.58881104 3167.68089243 2636.099869  ]
total_rewards_mean           1988.8261888776583
total_rewards_std            1054.6150522535943
total_rewards_max            3389.6125001657642
total_rewards_min            -98.28893659695717
Number of train steps total  355000
Number of env steps total    1777000
Number of rollouts total     0
Train Time (s)               26.253711177036166
(Previous) Eval Time (s)     23.12875723093748
Sample Time (s)              18.943053773604333
Epoch Time (s)               68.32552218157798
Total Train Time (s)         24513.365216060076
Epoch                        354
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:04:05.689133 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #354 | Epoch Duration: 67.7568154335022
2020-01-11 10:04:05.689417 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #354 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0447825
Z variance train             0.00830835
KL Divergence                24.733458
KL Loss                      2.4733458
QF Loss                      654.9707
VF Loss                      106.065735
Policy Loss                  -1151.6271
Q Predictions Mean           1151.6099
Q Predictions Std            249.7721
Q Predictions Max            1369.3843
Q Predictions Min            31.631598
V Predictions Mean           1149.1311
V Predictions Std            246.43918
V Predictions Max            1366.3828
V Predictions Min            46.095436
Log Pis Mean                 -0.28579655
Log Pis Std                  2.5759733
Log Pis Max                  9.048721
Log Pis Min                  -8.179902
Policy mu Mean               0.018237159
Policy mu Std                0.58994246
Policy mu Max                2.2614188
Policy mu Min                -3.007348
Policy log std Mean          -0.9699839
Policy log std Std           0.25816268
Policy log std Max           0.010779619
Policy log std Min           -1.9892654
Z mean eval                  1.0380774
Z variance eval              0.009039312
total_rewards                [3198.79473063  324.0424702  3362.08563488 1833.43562356 3207.26444149
 3275.92652993 3311.86152638 3164.72914986 2926.71064185 3040.07881045]
total_rewards_mean           2764.492955922661
total_rewards_std            915.8643875396552
total_rewards_max            3362.085634880485
total_rewards_min            324.0424701985459
Number of train steps total  356000
Number of env steps total    1782000
Number of rollouts total     0
Train Time (s)               29.014781466685236
(Previous) Eval Time (s)     22.559735811781138
Sample Time (s)              18.836914707440883
Epoch Time (s)               70.41143198590726
Total Train Time (s)         24584.276095107663
Epoch                        355
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:05:16.606460 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #355 | Epoch Duration: 70.91678857803345
2020-01-11 10:05:16.606742 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #355 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0373826
Z variance train             0.009022741
KL Divergence                24.393145
KL Loss                      2.4393146
QF Loss                      1064.1086
VF Loss                      400.58017
Policy Loss                  -1145.0913
Q Predictions Mean           1142.2723
Q Predictions Std            246.50769
Q Predictions Max            1361.4999
Q Predictions Min            18.507275
V Predictions Mean           1143.6528
V Predictions Std            241.58209
V Predictions Max            1362.4935
V Predictions Min            43.218563
Log Pis Mean                 -0.0054832287
Log Pis Std                  2.667461
Log Pis Max                  11.247547
Log Pis Min                  -6.803172
Policy mu Mean               0.050650094
Policy mu Std                0.58867234
Policy mu Max                2.7147877
Policy mu Min                -2.140011
Policy log std Mean          -0.9908124
Policy log std Std           0.27263546
Policy log std Max           -0.007361412
Policy log std Min           -2.6998906
Z mean eval                  1.0252656
Z variance eval              0.009264717
total_rewards                [ 479.61154777 1382.4446049   445.99135663 3145.22703541 2083.93104995
 3133.50412601  874.79031439 3048.45574543  -98.92868088  245.43717875]
total_rewards_mean           1474.0464278348836
total_rewards_std            1216.3221838765137
total_rewards_max            3145.2270354051134
total_rewards_min            -98.92868087606033
Number of train steps total  357000
Number of env steps total    1787000
Number of rollouts total     0
Train Time (s)               29.966282036155462
(Previous) Eval Time (s)     23.06476165819913
Sample Time (s)              18.88575069885701
Epoch Time (s)               71.9167943932116
Total Train Time (s)         24650.616974751465
Epoch                        356
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:06:22.951409 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #356 | Epoch Duration: 66.34435224533081
2020-01-11 10:06:22.951747 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #356 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0256771
Z variance train             0.009265149
KL Divergence                24.37878
KL Loss                      2.4378781
QF Loss                      1532.7361
VF Loss                      581.71735
Policy Loss                  -1152.8535
Q Predictions Mean           1149.6577
Q Predictions Std            237.84938
Q Predictions Max            1405.1414
Q Predictions Min            30.422865
V Predictions Mean           1140.9219
V Predictions Std            233.00122
V Predictions Max            1369.7915
V Predictions Min            18.320124
Log Pis Mean                 0.03599602
Log Pis Std                  2.7919323
Log Pis Max                  16.125668
Log Pis Min                  -6.5550556
Policy mu Mean               0.05765555
Policy mu Std                0.61162806
Policy mu Max                2.5846517
Policy mu Min                -1.9966733
Policy log std Mean          -1.001014
Policy log std Std           0.3169511
Policy log std Max           -0.10182595
Policy log std Min           -3.500032
Z mean eval                  1.0127617
Z variance eval              0.012167757
total_rewards                [ -17.02782152 3187.39863065 3401.6996909  2889.46232155 3340.80557509
 3282.54035065 1028.2233201   237.84103974 1930.5541996  2741.51726894]
total_rewards_mean           2202.301457569224
total_rewards_std            1259.8355934708295
total_rewards_max            3401.699690895034
total_rewards_min            -17.02782151555922
Number of train steps total  358000
Number of env steps total    1792000
Number of rollouts total     0
Train Time (s)               31.04513581423089
(Previous) Eval Time (s)     17.491982927080244
Sample Time (s)              18.196650312282145
Epoch Time (s)               66.73376905359328
Total Train Time (s)         24721.351392933168
Epoch                        357
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:07:33.690008 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #357 | Epoch Duration: 70.73802995681763
2020-01-11 10:07:33.690250 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #357 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0122802
Z variance train             0.0121364035
KL Divergence                23.68524
KL Loss                      2.368524
QF Loss                      739.5372
VF Loss                      364.73215
Policy Loss                  -1164.8077
Q Predictions Mean           1162.6089
Q Predictions Std            211.00215
Q Predictions Max            1353.9429
Q Predictions Min            47.32496
V Predictions Mean           1152.9216
V Predictions Std            206.82526
V Predictions Max            1333.6292
V Predictions Min            45.22043
Log Pis Mean                 -0.19207689
Log Pis Std                  2.6932464
Log Pis Max                  12.17292
Log Pis Min                  -6.8126955
Policy mu Mean               -0.015851378
Policy mu Std                0.605812
Policy mu Max                2.5369692
Policy mu Min                -2.1886215
Policy log std Mean          -0.9674889
Policy log std Std           0.27999315
Policy log std Max           -0.107601404
Policy log std Min           -3.1618648
Z mean eval                  1.075789
Z variance eval              0.0069881068
total_rewards                [3303.3488628  3427.49132471  832.61515693  740.81305263  804.97516635
 2515.16692121 3173.02846484 1668.94325346 3022.56283724 3169.6400597 ]
total_rewards_mean           2265.8585099869088
total_rewards_std            1075.6741928239255
total_rewards_max            3427.491324714769
total_rewards_min            740.8130526319536
Number of train steps total  359000
Number of env steps total    1797000
Number of rollouts total     0
Train Time (s)               29.885734441690147
(Previous) Eval Time (s)     21.495961582753807
Sample Time (s)              19.290673398878425
Epoch Time (s)               70.67236942332238
Total Train Time (s)         24789.487816771027
Epoch                        358
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:08:41.830508 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #358 | Epoch Duration: 68.14007925987244
2020-01-11 10:08:41.830701 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #358 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0760843
Z variance train             0.006981538
KL Divergence                24.70729
KL Loss                      2.470729
QF Loss                      774.6759
VF Loss                      166.45413
Policy Loss                  -1143.9615
Q Predictions Mean           1145.081
Q Predictions Std            235.39838
Q Predictions Max            1392.8934
Q Predictions Min            71.93862
V Predictions Mean           1147.5027
V Predictions Std            236.07841
V Predictions Max            1386.843
V Predictions Min            43.013283
Log Pis Mean                 -0.37903827
Log Pis Std                  2.3906214
Log Pis Max                  8.815872
Log Pis Min                  -5.574041
Policy mu Mean               0.021543559
Policy mu Std                0.58726007
Policy mu Max                2.336184
Policy mu Min                -1.9915444
Policy log std Mean          -0.95940447
Policy log std Std           0.26626435
Policy log std Max           -0.08507943
Policy log std Min           -2.554189
Z mean eval                  1.0680902
Z variance eval              0.0065347487
total_rewards                [1391.64339074  211.90056861 2864.87919458 3386.20514931   44.58614624
 3161.88673757  898.88527569 3219.14961124 3015.22546686   28.06911687]
total_rewards_mean           1822.2430657718917
total_rewards_std            1367.940075390081
total_rewards_max            3386.205149313493
total_rewards_min            28.06911686763499
Number of train steps total  360000
Number of env steps total    1802000
Number of rollouts total     0
Train Time (s)               26.953898450825363
(Previous) Eval Time (s)     18.963293965905905
Sample Time (s)              17.924877545796335
Epoch Time (s)               63.8420699625276
Total Train Time (s)         24849.9554443229
Epoch                        359
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:09:42.303945 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #359 | Epoch Duration: 60.473053216934204
2020-01-11 10:09:42.304232 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #359 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0637071
Z variance train             0.006522103
KL Divergence                24.901663
KL Loss                      2.4901664
QF Loss                      3551.6826
VF Loss                      2799.9177
Policy Loss                  -1175.2859
Q Predictions Mean           1173.7268
Q Predictions Std            225.82033
Q Predictions Max            1378.0248
Q Predictions Min            69.4518
V Predictions Mean           1167.8003
V Predictions Std            206.5182
V Predictions Max            1356.5171
V Predictions Min            50.905552
Log Pis Mean                 -0.19054055
Log Pis Std                  2.760766
Log Pis Max                  12.2237835
Log Pis Min                  -9.081968
Policy mu Mean               0.0057059317
Policy mu Std                0.59721303
Policy mu Max                2.4101193
Policy mu Min                -2.3082714
Policy log std Mean          -0.9792311
Policy log std Std           0.26841965
Policy log std Max           -0.24240011
Policy log std Min           -3.1648507
Z mean eval                  1.0457815
Z variance eval              0.010492642
total_rewards                [3354.65903397 2370.6495908  3325.55535112 3457.76617954 3635.61123302
 3264.29982807 3258.03629123 3468.13815244 3343.41471201 3230.75982078]
total_rewards_mean           3270.889019296238
total_rewards_std            321.6159786574033
total_rewards_max            3635.611233017636
total_rewards_min            2370.6495907987046
Number of train steps total  361000
Number of env steps total    1807000
Number of rollouts total     0
Train Time (s)               28.18517016293481
(Previous) Eval Time (s)     15.593964114785194
Sample Time (s)              18.43208595085889
Epoch Time (s)               62.211220228578895
Total Train Time (s)         24922.10704424884
Epoch                        360
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:10:54.460849 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #360 | Epoch Duration: 72.15629720687866
2020-01-11 10:10:54.461188 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #360 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0449626
Z variance train             0.010493597
KL Divergence                23.585905
KL Loss                      2.3585906
QF Loss                      620.4259
VF Loss                      157.39912
Policy Loss                  -1152.9886
Q Predictions Mean           1155.4225
Q Predictions Std            241.76884
Q Predictions Max            1378.4563
Q Predictions Min            -83.25872
V Predictions Mean           1160.157
V Predictions Std            239.08698
V Predictions Max            1383.8972
V Predictions Min            -41.581394
Log Pis Mean                 -0.08151417
Log Pis Std                  2.7882752
Log Pis Max                  20.858198
Log Pis Min                  -7.485083
Policy mu Mean               -0.022362687
Policy mu Std                0.59208244
Policy mu Max                2.4046035
Policy mu Min                -2.9802341
Policy log std Mean          -0.9718932
Policy log std Std           0.26663798
Policy log std Max           0.11088157
Policy log std Min           -2.051501
Z mean eval                  1.0590037
Z variance eval              0.009858945
total_rewards                [ 483.76547782   28.54050708 3014.94314556 1057.00604383 2856.43865174
 1122.20482853  503.40159478 2907.21902356 2980.05751154 3222.45774198]
total_rewards_mean           1817.6034526397223
total_rewards_std            1216.3084383086027
total_rewards_max            3222.4577419813095
total_rewards_min            28.540507080453956
Number of train steps total  362000
Number of env steps total    1812000
Number of rollouts total     0
Train Time (s)               27.918184106238186
(Previous) Eval Time (s)     25.538680035620928
Sample Time (s)              18.270645547658205
Epoch Time (s)               71.72750968951732
Total Train Time (s)         24988.777156427503
Epoch                        361
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:12:01.136911 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #361 | Epoch Duration: 66.67551326751709
2020-01-11 10:12:01.137120 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #361 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0618149
Z variance train             0.009839431
KL Divergence                24.063753
KL Loss                      2.4063754
QF Loss                      639.477
VF Loss                      149.66188
Policy Loss                  -1155.4257
Q Predictions Mean           1160.385
Q Predictions Std            263.57193
Q Predictions Max            1364.4692
Q Predictions Min            38.441105
V Predictions Mean           1149.8937
V Predictions Std            262.18936
V Predictions Max            1354.974
V Predictions Min            11.132352
Log Pis Mean                 -0.08006829
Log Pis Std                  2.686722
Log Pis Max                  11.4818125
Log Pis Min                  -7.4674115
Policy mu Mean               0.102088846
Policy mu Std                0.5870343
Policy mu Max                3.4542403
Policy mu Min                -2.702118
Policy log std Mean          -0.9871503
Policy log std Std           0.29382813
Policy log std Max           0.13086021
Policy log std Min           -2.6009436
Z mean eval                  1.0032803
Z variance eval              0.013326155
total_rewards                [2970.8099039  3378.52287665 3448.3199317  3123.83352664 1985.13309318
 1342.19647751 1525.14600336 2277.24851573 3042.84861413 2764.23576575]
total_rewards_mean           2585.8294708539784
total_rewards_std            719.6066297804192
total_rewards_max            3448.319931699777
total_rewards_min            1342.1964775069657
Number of train steps total  363000
Number of env steps total    1817000
Number of rollouts total     0
Train Time (s)               25.342100691981614
(Previous) Eval Time (s)     20.48636183794588
Sample Time (s)              17.559597632382065
Epoch Time (s)               63.38806016230956
Total Train Time (s)         25053.743741394486
Epoch                        362
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:13:06.106613 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #362 | Epoch Duration: 64.9692394733429
2020-01-11 10:13:06.106916 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #362 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0036101
Z variance train             0.013353085
KL Divergence                22.925726
KL Loss                      2.2925727
QF Loss                      5121.66
VF Loss                      1059.9408
Policy Loss                  -1151.9246
Q Predictions Mean           1155.6599
Q Predictions Std            239.86865
Q Predictions Max            1375.0029
Q Predictions Min            33.98103
V Predictions Mean           1160.2214
V Predictions Std            242.89249
V Predictions Max            1371.4227
V Predictions Min            43.728447
Log Pis Mean                 -0.123962015
Log Pis Std                  2.872815
Log Pis Max                  15.845196
Log Pis Min                  -7.2494535
Policy mu Mean               0.005212531
Policy mu Std                0.5765674
Policy mu Max                2.123018
Policy mu Min                -2.4022439
Policy log std Mean          -1.0142832
Policy log std Std           0.29468098
Policy log std Max           -0.09346056
Policy log std Min           -3.610756
Z mean eval                  1.0231822
Z variance eval              0.012037283
total_rewards                [2067.24068104  482.50072245  645.72571112 2145.83635452   28.04430841
 3214.94047119 2371.35642679 1212.53371031  484.35507097  802.09687635]
total_rewards_mean           1345.463033316562
total_rewards_std            986.5756862296187
total_rewards_max            3214.9404711929365
total_rewards_min            28.044308414193175
Number of train steps total  364000
Number of env steps total    1822000
Number of rollouts total     0
Train Time (s)               30.0210149330087
(Previous) Eval Time (s)     22.06723247701302
Sample Time (s)              18.52584096090868
Epoch Time (s)               70.6140883709304
Total Train Time (s)         25120.67944658175
Epoch                        363
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:14:13.047302 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #363 | Epoch Duration: 66.94019556045532
2020-01-11 10:14:13.047546 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #363 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0236328
Z variance train             0.012035395
KL Divergence                23.701986
KL Loss                      2.3701987
QF Loss                      1181.0798
VF Loss                      144.47455
Policy Loss                  -1177.718
Q Predictions Mean           1175.4615
Q Predictions Std            216.33766
Q Predictions Max            1383.1791
Q Predictions Min            16.341318
V Predictions Mean           1176.737
V Predictions Std            214.51854
V Predictions Max            1378.2094
V Predictions Min            21.476507
Log Pis Mean                 0.3048653
Log Pis Std                  2.761308
Log Pis Max                  14.556942
Log Pis Min                  -7.858931
Policy mu Mean               0.0016439937
Policy mu Std                0.6615638
Policy mu Max                3.1797209
Policy mu Min                -3.0917335
Policy log std Mean          -0.9975946
Policy log std Std           0.25155777
Policy log std Max           -0.16727364
Policy log std Min           -2.0693984
Z mean eval                  1.0216628
Z variance eval              0.0111947525
total_rewards                [3165.49580875  750.96377708 3155.18534683 1344.83712387 3390.79493963
  833.71412266 3060.80915541 1349.52967517 3183.83649653 3220.72095866]
total_rewards_mean           2345.588740456924
total_rewards_std            1059.3600568145098
total_rewards_max            3390.794939625774
total_rewards_min            750.9637770760891
Number of train steps total  365000
Number of env steps total    1827000
Number of rollouts total     0
Train Time (s)               28.04392139893025
(Previous) Eval Time (s)     18.393006114289165
Sample Time (s)              17.55563693959266
Epoch Time (s)               63.992564452812076
Total Train Time (s)         25190.69720222894
Epoch                        364
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:15:23.069475 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #364 | Epoch Duration: 70.02173948287964
2020-01-11 10:15:23.069706 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #364 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0197966
Z variance train             0.011194621
KL Divergence                23.663296
KL Loss                      2.3663297
QF Loss                      673.8032
VF Loss                      1345.2748
Policy Loss                  -1159.1014
Q Predictions Mean           1161.0303
Q Predictions Std            244.6821
Q Predictions Max            1380.5332
Q Predictions Min            64.51013
V Predictions Mean           1158.3918
V Predictions Std            247.74518
V Predictions Max            1374.3674
V Predictions Min            64.30359
Log Pis Mean                 -0.046598844
Log Pis Std                  2.8418815
Log Pis Max                  12.352081
Log Pis Min                  -8.671959
Policy mu Mean               0.0029845897
Policy mu Std                0.57989305
Policy mu Max                1.978957
Policy mu Min                -2.6850097
Policy log std Mean          -1.0189064
Policy log std Std           0.29130706
Policy log std Max           -0.1544118
Policy log std Min           -2.6675167
Z mean eval                  1.062602
Z variance eval              0.013833182
total_rewards                [3062.99939656 1281.87404207 3181.74127921 3194.64051149 2512.06472946
 3164.0179612  3051.24111372 3351.54093118 3287.83376148 2426.43513141]
total_rewards_mean           2851.43888577807
total_rewards_std            600.7620857337072
total_rewards_max            3351.540931182404
total_rewards_min            1281.8740420726156
Number of train steps total  366000
Number of env steps total    1832000
Number of rollouts total     0
Train Time (s)               29.28731579799205
(Previous) Eval Time (s)     24.421881386078894
Sample Time (s)              18.962535026017576
Epoch Time (s)               72.67173221008852
Total Train Time (s)         25264.659541579895
Epoch                        365
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:16:37.034841 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #365 | Epoch Duration: 73.96495985984802
2020-01-11 10:16:37.035052 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #365 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0625287
Z variance train             0.013813421
KL Divergence                23.597359
KL Loss                      2.359736
QF Loss                      2263.7808
VF Loss                      1612.9154
Policy Loss                  -1197.0409
Q Predictions Mean           1198.7228
Q Predictions Std            182.68376
Q Predictions Max            1385.6255
Q Predictions Min            129.94493
V Predictions Mean           1189.3203
V Predictions Std            187.70807
V Predictions Max            1374.4464
V Predictions Min            116.73331
Log Pis Mean                 0.0168011
Log Pis Std                  2.6196222
Log Pis Max                  14.825928
Log Pis Min                  -7.8164864
Policy mu Mean               0.035983544
Policy mu Std                0.5812685
Policy mu Max                2.4412792
Policy mu Min                -1.9614339
Policy log std Mean          -0.9898204
Policy log std Std           0.2587075
Policy log std Max           -0.216174
Policy log std Min           -2.9412947
Z mean eval                  0.9985846
Z variance eval              0.012759608
total_rewards                [3187.41409141  692.52472889 1973.86511667 3464.95967685  231.56227415
 2753.88139024 2192.05613218 1690.26413938   22.01711206 3153.6395359 ]
total_rewards_mean           1936.2184197736303
total_rewards_std            1195.7167006444456
total_rewards_max            3464.9596768467263
total_rewards_min            22.01711206394866
Number of train steps total  367000
Number of env steps total    1837000
Number of rollouts total     0
Train Time (s)               28.117284012958407
(Previous) Eval Time (s)     25.71473567839712
Sample Time (s)              18.450358969625086
Epoch Time (s)               72.28237866098061
Total Train Time (s)         25328.819939220324
Epoch                        366
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:17:41.200546 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #366 | Epoch Duration: 64.16532588005066
2020-01-11 10:17:41.200767 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #366 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99789107
Z variance train             0.012859581
KL Divergence                23.492151
KL Loss                      2.3492153
QF Loss                      1289.2523
VF Loss                      191.56331
Policy Loss                  -1149.4481
Q Predictions Mean           1150.8457
Q Predictions Std            271.5522
Q Predictions Max            1398.8682
Q Predictions Min            -14.353775
V Predictions Mean           1146.5598
V Predictions Std            269.4657
V Predictions Max            1392.8811
V Predictions Min            -54.99979
Log Pis Mean                 -0.47027016
Log Pis Std                  2.8284056
Log Pis Max                  7.9969454
Log Pis Min                  -10.431415
Policy mu Mean               0.01105339
Policy mu Std                0.58571464
Policy mu Max                2.5301073
Policy mu Min                -2.1010184
Policy log std Mean          -0.99023193
Policy log std Std           0.27137902
Policy log std Max           -0.13735545
Policy log std Min           -2.4623098
Z mean eval                  1.0078168
Z variance eval              0.015146121
total_rewards                [3296.2969192    19.29102013 3227.4495938   652.21816703 3360.732837
 3546.54674942 2508.73299382 3267.93360824 1525.66228998 3428.92854361]
total_rewards_mean           2483.37927222308
total_rewards_std            1223.39223365784
total_rewards_max            3546.5467494191153
total_rewards_min            19.29102013498741
Number of train steps total  368000
Number of env steps total    1842000
Number of rollouts total     0
Train Time (s)               27.667590137105435
(Previous) Eval Time (s)     17.597398161888123
Sample Time (s)              18.1715099317953
Epoch Time (s)               63.43649823078886
Total Train Time (s)         25394.132659547962
Epoch                        367
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:18:46.520431 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #367 | Epoch Duration: 65.31945562362671
2020-01-11 10:18:46.520746 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #367 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0077013
Z variance train             0.015090826
KL Divergence                23.755703
KL Loss                      2.3755703
QF Loss                      732.1476
VF Loss                      277.006
Policy Loss                  -1154.2109
Q Predictions Mean           1152.5327
Q Predictions Std            269.187
Q Predictions Max            1388.4186
Q Predictions Min            31.744371
V Predictions Mean           1155.7515
V Predictions Std            265.15744
V Predictions Max            1407.7207
V Predictions Min            34.148216
Log Pis Mean                 0.08371865
Log Pis Std                  2.690371
Log Pis Max                  11.144128
Log Pis Min                  -5.3005867
Policy mu Mean               -0.018881764
Policy mu Std                0.61857593
Policy mu Max                2.4571939
Policy mu Min                -2.0929189
Policy log std Mean          -1.0032415
Policy log std Std           0.28839284
Policy log std Max           -0.1362716
Policy log std Min           -2.5621696
Z mean eval                  1.0208021
Z variance eval              0.014149666
total_rewards                [2692.08768162 1619.7138192  1168.58306974 3552.30755099 3556.4251081
 3552.24930352  361.08190489 3247.56918005 3203.05489008  762.77214327]
total_rewards_mean           2371.5844651464104
total_rewards_std            1199.8440678978766
total_rewards_max            3556.425108102014
total_rewards_min            361.0819048878168
Number of train steps total  369000
Number of env steps total    1847000
Number of rollouts total     0
Train Time (s)               31.143161787185818
(Previous) Eval Time (s)     19.480037606321275
Sample Time (s)              17.856969045940787
Epoch Time (s)               68.48016843944788
Total Train Time (s)         25466.222683897242
Epoch                        368
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:19:58.616393 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #368 | Epoch Duration: 72.09537291526794
2020-01-11 10:19:58.616747 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #368 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0196617
Z variance train             0.014085782
KL Divergence                24.278812
KL Loss                      2.4278812
QF Loss                      976.25867
VF Loss                      127.73022
Policy Loss                  -1178.5627
Q Predictions Mean           1178.856
Q Predictions Std            236.86852
Q Predictions Max            1414.6337
Q Predictions Min            43.213158
V Predictions Mean           1180.533
V Predictions Std            237.63005
V Predictions Max            1416.5416
V Predictions Min            40.998608
Log Pis Mean                 -0.013660543
Log Pis Std                  2.8212543
Log Pis Max                  12.377348
Log Pis Min                  -7.3643312
Policy mu Mean               0.02259176
Policy mu Std                0.5926204
Policy mu Max                2.0171452
Policy mu Min                -2.332323
Policy log std Mean          -0.99907005
Policy log std Std           0.25760266
Policy log std Max           -0.07908833
Policy log std Min           -2.1455817
Z mean eval                  1.0217491
Z variance eval              0.0122233415
total_rewards                [3137.42104847  618.9005031  3487.36180326 1075.978664   3071.05353825
 2759.85693356 3362.96486727 2490.37300688 1986.61223935 2424.98424431]
total_rewards_mean           2441.5506848444847
total_rewards_std            912.1963028194808
total_rewards_max            3487.3618032583163
total_rewards_min            618.9005030981023
Number of train steps total  370000
Number of env steps total    1852000
Number of rollouts total     0
Train Time (s)               27.393707429990172
(Previous) Eval Time (s)     23.09492112090811
Sample Time (s)              17.798045669682324
Epoch Time (s)               68.28667422058061
Total Train Time (s)         25531.495930894744
Epoch                        369
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:21:03.894873 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #369 | Epoch Duration: 65.27786755561829
2020-01-11 10:21:03.895116 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #369 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0224347
Z variance train             0.012248352
KL Divergence                23.624554
KL Loss                      2.3624554
QF Loss                      1856.1693
VF Loss                      277.39386
Policy Loss                  -1156.9843
Q Predictions Mean           1155.8037
Q Predictions Std            279.1057
Q Predictions Max            1414.6279
Q Predictions Min            11.815375
V Predictions Mean           1157.7917
V Predictions Std            274.46658
V Predictions Max            1411.4762
V Predictions Min            69.72299
Log Pis Mean                 -0.38878012
Log Pis Std                  2.7502365
Log Pis Max                  14.469484
Log Pis Min                  -7.44635
Policy mu Mean               0.007865584
Policy mu Std                0.5942808
Policy mu Max                2.7786279
Policy mu Min                -2.2512217
Policy log std Mean          -0.9753272
Policy log std Std           0.27462184
Policy log std Max           -0.17324638
Policy log std Min           -2.0314221
Z mean eval                  1.002944
Z variance eval              0.015217835
total_rewards                [1784.75672215   70.23625263 3432.92326207  805.47152419 3619.33815055
 3193.19563086 1189.47063135 3383.30624241 1172.79595054  392.3830829 ]
total_rewards_mean           1904.387744964819
total_rewards_std            1305.5356249192414
total_rewards_max            3619.3381505516645
total_rewards_min            70.23625262810815
Number of train steps total  371000
Number of env steps total    1857000
Number of rollouts total     0
Train Time (s)               27.379461736883968
(Previous) Eval Time (s)     20.085813351906836
Sample Time (s)              17.55261391075328
Epoch Time (s)               65.01788899954408
Total Train Time (s)         25591.94446252659
Epoch                        370
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:22:04.351079 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #370 | Epoch Duration: 60.45574426651001
2020-01-11 10:22:04.351375 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #370 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0016794
Z variance train             0.01523073
KL Divergence                23.049194
KL Loss                      2.3049195
QF Loss                      669.91516
VF Loss                      114.663315
Policy Loss                  -1161.0602
Q Predictions Mean           1162.0059
Q Predictions Std            265.20084
Q Predictions Max            1429.4048
Q Predictions Min            -7.951243
V Predictions Mean           1165.1333
V Predictions Std            267.90622
V Predictions Max            1431.6854
V Predictions Min            -23.064991
Log Pis Mean                 -0.35160238
Log Pis Std                  2.4914253
Log Pis Max                  7.678337
Log Pis Min                  -9.571658
Policy mu Mean               0.02492949
Policy mu Std                0.58350694
Policy mu Max                2.093635
Policy mu Min                -2.0693378
Policy log std Mean          -0.97636735
Policy log std Std           0.25859582
Policy log std Max           -0.10462266
Policy log std Min           -2.1855147
Z mean eval                  1.011009
Z variance eval              0.01308158
total_rewards                [ 778.62996084 3237.66360814 3127.27922914 3418.80619877 3415.90575717
 3295.86336886 1297.46167359 3435.09189073 3509.16289845 3328.5688521 ]
total_rewards_mean           2884.443343779742
total_rewards_std            936.1993833437823
total_rewards_max            3509.162898452535
total_rewards_min            778.6299608364366
Number of train steps total  372000
Number of env steps total    1862000
Number of rollouts total     0
Train Time (s)               26.800557070877403
(Previous) Eval Time (s)     15.523325381800532
Sample Time (s)              19.05318430857733
Epoch Time (s)               61.377066761255264
Total Train Time (s)         25660.426981495228
Epoch                        371
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:23:12.835724 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #371 | Epoch Duration: 68.484126329422
2020-01-11 10:23:12.835981 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #371 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0108707
Z variance train             0.013088484
KL Divergence                23.51001
KL Loss                      2.351001
QF Loss                      1405.0403
VF Loss                      146.55876
Policy Loss                  -1168.8564
Q Predictions Mean           1168.39
Q Predictions Std            270.31683
Q Predictions Max            1370.2363
Q Predictions Min            22.094458
V Predictions Mean           1166.0286
V Predictions Std            270.60843
V Predictions Max            1375.757
V Predictions Min            25.760954
Log Pis Mean                 -0.061355792
Log Pis Std                  3.1471374
Log Pis Max                  14.51868
Log Pis Min                  -7.690611
Policy mu Mean               0.027299624
Policy mu Std                0.60326743
Policy mu Max                2.8626223
Policy mu Min                -4.110896
Policy log std Mean          -1.0000567
Policy log std Std           0.2891319
Policy log std Max           -0.007569909
Policy log std Min           -2.343452
Z mean eval                  1.04422
Z variance eval              0.01766969
total_rewards                [3229.09104339 2243.3856982  3427.8286269   636.1804456  1991.2885348
 3351.2148975    30.95799865 3202.08692486 3563.95576472 2621.66626124]
total_rewards_mean           2429.7656195852933
total_rewards_std            1166.2777721968298
total_rewards_max            3563.955764716834
total_rewards_min            30.95799865436243
Number of train steps total  373000
Number of env steps total    1867000
Number of rollouts total     0
Train Time (s)               29.28902501333505
(Previous) Eval Time (s)     22.630080560222268
Sample Time (s)              18.252115786541253
Epoch Time (s)               70.17122136009857
Total Train Time (s)         25730.712596795987
Epoch                        372
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:24:23.124997 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #372 | Epoch Duration: 70.28877449035645
2020-01-11 10:24:23.125251 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #372 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.045638
Z variance train             0.017741209
KL Divergence                23.646852
KL Loss                      2.3646853
QF Loss                      802.5237
VF Loss                      116.602646
Policy Loss                  -1195.5557
Q Predictions Mean           1195.4558
Q Predictions Std            261.41025
Q Predictions Max            1465.7681
Q Predictions Min            8.498764
V Predictions Mean           1201.5568
V Predictions Std            262.32278
V Predictions Max            1472.5807
V Predictions Min            12.799059
Log Pis Mean                 -0.20470989
Log Pis Std                  2.7787702
Log Pis Max                  7.8815823
Log Pis Min                  -9.263371
Policy mu Mean               0.018775161
Policy mu Std                0.62571096
Policy mu Max                2.6958952
Policy mu Min                -2.5717256
Policy log std Mean          -0.9620676
Policy log std Std           0.2637561
Policy log std Max           -0.074310064
Policy log std Min           -2.005996
Z mean eval                  1.0203168
Z variance eval              0.016080774
total_rewards                [2804.33441223 1466.60989697 1925.449097   3157.55742734 3155.28621261
 3211.78533307 3012.37807475 3096.61510784 3151.33122157 2238.95050224]
total_rewards_mean           2722.029728562668
total_rewards_std            589.6551115598594
total_rewards_max            3211.785333070973
total_rewards_min            1466.6098969738973
Number of train steps total  374000
Number of env steps total    1872000
Number of rollouts total     0
Train Time (s)               29.482706129085273
(Previous) Eval Time (s)     22.747342112008482
Sample Time (s)              17.590391299221665
Epoch Time (s)               69.82043954031542
Total Train Time (s)         25802.332088989206
Epoch                        373
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:25:34.749909 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #373 | Epoch Duration: 71.6244912147522
2020-01-11 10:25:34.750182 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #373 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0225546
Z variance train             0.016065344
KL Divergence                23.632172
KL Loss                      2.363217
QF Loss                      968.2206
VF Loss                      198.81842
Policy Loss                  -1147.9031
Q Predictions Mean           1144.5768
Q Predictions Std            302.63495
Q Predictions Max            1396.3557
Q Predictions Min            -60.480442
V Predictions Mean           1141.54
V Predictions Std            297.48282
V Predictions Max            1397.1034
V Predictions Min            2.7326775
Log Pis Mean                 -0.60770744
Log Pis Std                  2.7190197
Log Pis Max                  8.807031
Log Pis Min                  -8.721594
Policy mu Mean               0.00819079
Policy mu Std                0.5416429
Policy mu Max                2.348038
Policy mu Min                -2.0560477
Policy log std Mean          -0.9921553
Policy log std Std           0.30887777
Policy log std Max           -0.2241832
Policy log std Min           -3.0978794
Z mean eval                  1.0160518
Z variance eval              0.020595126
total_rewards                [2949.6609004   559.53385346  775.44981026 1601.08560548 2544.98811743
  506.22934748  101.95819461 3307.14710766 2554.42854284  142.47578029]
total_rewards_mean           1504.2957259899244
total_rewards_std            1173.6938883804592
total_rewards_max            3307.1471076625003
total_rewards_min            101.95819460599688
Number of train steps total  375000
Number of env steps total    1877000
Number of rollouts total     0
Train Time (s)               30.94963203696534
(Previous) Eval Time (s)     24.551102834753692
Sample Time (s)              17.770217281766236
Epoch Time (s)               73.27095215348527
Total Train Time (s)         25863.7463203785
Epoch                        374
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:26:36.170460 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #374 | Epoch Duration: 61.42004656791687
2020-01-11 10:26:36.170750 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #374 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0165979
Z variance train             0.020605592
KL Divergence                22.657368
KL Loss                      2.2657368
QF Loss                      1013.3858
VF Loss                      134.36499
Policy Loss                  -1188.3947
Q Predictions Mean           1185.9052
Q Predictions Std            236.74762
Q Predictions Max            1365.7303
Q Predictions Min            20.313332
V Predictions Mean           1183.5774
V Predictions Std            232.7039
V Predictions Max            1362.0132
V Predictions Min            1.0790703
Log Pis Mean                 0.090322316
Log Pis Std                  2.7926939
Log Pis Max                  9.689169
Log Pis Min                  -8.924161
Policy mu Mean               -0.0034580105
Policy mu Std                0.61340827
Policy mu Max                2.5084398
Policy mu Min                -2.5517778
Policy log std Mean          -0.98142016
Policy log std Std           0.25919577
Policy log std Max           -0.20571029
Policy log std Min           -2.2731497
Z mean eval                  1.0221052
Z variance eval              0.015920747
total_rewards                [3334.30875572 2499.39824159 3478.61631746 3486.55756024  837.90831697
 3309.11412606 1354.52450805 2589.73035842 3301.1917083   637.75918007]
total_rewards_mean           2482.910907287792
total_rewards_std            1071.044625778834
total_rewards_max            3486.5575602367953
total_rewards_min            637.7591800657244
Number of train steps total  376000
Number of env steps total    1882000
Number of rollouts total     0
Train Time (s)               28.544296248350292
(Previous) Eval Time (s)     12.699880904052407
Sample Time (s)              17.79243152309209
Epoch Time (s)               59.03660867549479
Total Train Time (s)         25930.994730154052
Epoch                        375
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:27:43.424093 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #375 | Epoch Duration: 67.25309944152832
2020-01-11 10:27:43.424340 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #375 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0230918
Z variance train             0.015908897
KL Divergence                22.349503
KL Loss                      2.2349503
QF Loss                      768.90894
VF Loss                      283.6929
Policy Loss                  -1197.8757
Q Predictions Mean           1197.8643
Q Predictions Std            245.26874
Q Predictions Max            1419.1854
Q Predictions Min            24.647226
V Predictions Mean           1193.3506
V Predictions Std            244.28537
V Predictions Max            1407.6006
V Predictions Min            10.357453
Log Pis Mean                 -0.20856783
Log Pis Std                  2.8414772
Log Pis Max                  11.155365
Log Pis Min                  -8.903247
Policy mu Mean               -0.07298273
Policy mu Std                0.5649299
Policy mu Max                2.992684
Policy mu Min                -3.8154356
Policy log std Mean          -1.0361423
Policy log std Std           0.2745973
Policy log std Max           -0.010664821
Policy log std Min           -2.2525203
Z mean eval                  1.0573933
Z variance eval              0.020054761
total_rewards                [2189.69119019 3303.39228182 2154.22282923 3228.18956486 2121.16730235
 3221.30681306 3143.38482232 3251.67854628 3185.29913024    3.88553379]
total_rewards_mean           2580.221801414772
total_rewards_std            983.3708334162748
total_rewards_max            3303.392281816563
total_rewards_min            3.885533794404168
Number of train steps total  377000
Number of env steps total    1887000
Number of rollouts total     0
Train Time (s)               29.002927834633738
(Previous) Eval Time (s)     20.916093311738223
Sample Time (s)              17.569444163236767
Epoch Time (s)               67.48846530960873
Total Train Time (s)         26003.24495009845
Epoch                        376
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:28:55.675837 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #376 | Epoch Duration: 72.25131058692932
2020-01-11 10:28:55.676033 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #376 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.05808
Z variance train             0.020042863
KL Divergence                22.016598
KL Loss                      2.20166
QF Loss                      1137.9629
VF Loss                      628.5109
Policy Loss                  -1184.3527
Q Predictions Mean           1184.2063
Q Predictions Std            255.86426
Q Predictions Max            1403.1555
Q Predictions Min            24.234632
V Predictions Mean           1193.5178
V Predictions Std            252.27242
V Predictions Max            1404.463
V Predictions Min            29.419266
Log Pis Mean                 -0.2426928
Log Pis Std                  3.0077958
Log Pis Max                  13.384534
Log Pis Min                  -9.066222
Policy mu Mean               -0.027830966
Policy mu Std                0.59705657
Policy mu Max                2.316385
Policy mu Min                -2.6999116
Policy log std Mean          -1.01073
Policy log std Std           0.28353742
Policy log std Max           -0.2595017
Policy log std Min           -3.1027837
Z mean eval                  1.0305147
Z variance eval              0.014270465
total_rewards                [3178.6100353  1331.64513561 3473.53114932 3562.72436889 1895.60418989
 3181.70437501 3516.98598363  944.78279167  167.27716728 3370.30163752]
total_rewards_mean           2462.316683412414
total_rewards_std            1198.7705072008278
total_rewards_max            3562.72436889388
total_rewards_min            167.27716727596848
Number of train steps total  378000
Number of env steps total    1892000
Number of rollouts total     0
Train Time (s)               31.60717121185735
(Previous) Eval Time (s)     25.678648785687983
Sample Time (s)              17.302924726624042
Epoch Time (s)               74.58874472416937
Total Train Time (s)         26073.90886657918
Epoch                        377
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:30:06.342381 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #377 | Epoch Duration: 70.66620659828186
2020-01-11 10:30:06.342575 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #377 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0303425
Z variance train             0.014245967
KL Divergence                21.792673
KL Loss                      2.1792674
QF Loss                      1440.5986
VF Loss                      221.65627
Policy Loss                  -1199.2542
Q Predictions Mean           1197.7542
Q Predictions Std            232.76978
Q Predictions Max            1430.9026
Q Predictions Min            -7.855971
V Predictions Mean           1201.8525
V Predictions Std            235.31784
V Predictions Max            1429.6461
V Predictions Min            -7.0425615
Log Pis Mean                 0.057953052
Log Pis Std                  2.5905108
Log Pis Max                  11.54875
Log Pis Min                  -7.010535
Policy mu Mean               0.047207944
Policy mu Std                0.5725133
Policy mu Max                2.313557
Policy mu Min                -2.1201758
Policy log std Mean          -1.0217855
Policy log std Std           0.2839266
Policy log std Max           0.45994788
Policy log std Min           -3.1033654
Z mean eval                  1.0144086
Z variance eval              0.010158809
total_rewards                [2879.13589264 1959.83436898 3353.17947351 3207.85491942 3266.93956304
  147.5548402  3049.48975421 3471.39215907 3062.58445237 3163.06735427]
total_rewards_mean           2756.1032777701757
total_rewards_std            955.6413379712618
total_rewards_max            3471.3921590702453
total_rewards_min            147.55484019910227
Number of train steps total  379000
Number of env steps total    1897000
Number of rollouts total     0
Train Time (s)               27.415950094815344
(Previous) Eval Time (s)     21.75582858035341
Sample Time (s)              17.861740121617913
Epoch Time (s)               67.03351879678667
Total Train Time (s)         26143.318876290694
Epoch                        378
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:31:15.755088 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #378 | Epoch Duration: 69.41239213943481
2020-01-11 10:31:15.755286 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #378 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0132198
Z variance train             0.010155834
KL Divergence                22.83934
KL Loss                      2.283934
QF Loss                      912.1067
VF Loss                      362.69043
Policy Loss                  -1170.2474
Q Predictions Mean           1170.2788
Q Predictions Std            296.39066
Q Predictions Max            1421.2925
Q Predictions Min            -6.2564907
V Predictions Mean           1172.3525
V Predictions Std            293.26505
V Predictions Max            1429.1099
V Predictions Min            -5.866732
Log Pis Mean                 0.3004769
Log Pis Std                  2.904497
Log Pis Max                  12.634815
Log Pis Min                  -6.560395
Policy mu Mean               -0.03104674
Policy mu Std                0.6514288
Policy mu Max                2.615424
Policy mu Min                -4.013384
Policy log std Mean          -0.97558624
Policy log std Std           0.2949194
Policy log std Max           0.10460627
Policy log std Min           -2.8465598
Z mean eval                  0.9998208
Z variance eval              0.010428933
total_rewards                [3104.00438585 2031.25216361 1731.53828865 3344.17494127 2655.25865196
 3314.59680391 2751.12661888 3206.7965753  3287.46573286 3458.22948804]
total_rewards_mean           2888.444365032552
total_rewards_std            562.7988566054809
total_rewards_max            3458.2294880418476
total_rewards_min            1731.5382886473978
Number of train steps total  380000
Number of env steps total    1902000
Number of rollouts total     0
Train Time (s)               29.18954784795642
(Previous) Eval Time (s)     24.134368921164423
Sample Time (s)              17.31459088390693
Epoch Time (s)               70.63850765302777
Total Train Time (s)         26214.81342214765
Epoch                        379
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:32:27.253430 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #379 | Epoch Duration: 71.49798130989075
2020-01-11 10:32:27.253633 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #379 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0028666
Z variance train             0.010535859
KL Divergence                22.602468
KL Loss                      2.260247
QF Loss                      566.4612
VF Loss                      111.43121
Policy Loss                  -1237.9932
Q Predictions Mean           1241.6711
Q Predictions Std            168.34511
Q Predictions Max            1426.0077
Q Predictions Min            40.367786
V Predictions Mean           1240.1074
V Predictions Std            170.01643
V Predictions Max            1420.2969
V Predictions Min            13.80443
Log Pis Mean                 -0.08363356
Log Pis Std                  2.225029
Log Pis Max                  6.5432167
Log Pis Min                  -5.9612455
Policy mu Mean               0.05707327
Policy mu Std                0.5617658
Policy mu Max                2.2694564
Policy mu Min                -2.0145202
Policy log std Mean          -1.018088
Policy log std Std           0.23529434
Policy log std Max           -0.10002327
Policy log std Min           -1.9047709
Z mean eval                  1.0229577
Z variance eval              0.009778999
total_rewards                [ 236.33878105 1158.64666706 1533.94368574 3199.60457514 3409.08364202
  194.05723159  425.68457027  956.95784336   86.24431202 1904.62011316]
total_rewards_mean           1310.5181421407428
total_rewards_std            1149.1602929769126
total_rewards_max            3409.0836420165824
total_rewards_min            86.24431202395735
Number of train steps total  381000
Number of env steps total    1907000
Number of rollouts total     0
Train Time (s)               28.04586952412501
(Previous) Eval Time (s)     24.99357152171433
Sample Time (s)              17.539942231494933
Epoch Time (s)               70.57938327733427
Total Train Time (s)         26273.903616505675
Epoch                        380
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:33:26.349018 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #380 | Epoch Duration: 59.09521532058716
2020-01-11 10:33:26.349243 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #380 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0231442
Z variance train             0.009771677
KL Divergence                23.06784
KL Loss                      2.3067842
QF Loss                      600.39185
VF Loss                      120.9145
Policy Loss                  -1213.2959
Q Predictions Mean           1214.2478
Q Predictions Std            241.83835
Q Predictions Max            1418.596
Q Predictions Min            -3.8010879
V Predictions Mean           1215.7573
V Predictions Std            241.88281
V Predictions Max            1417.674
V Predictions Min            -21.19251
Log Pis Mean                 0.28313833
Log Pis Std                  2.5670078
Log Pis Max                  6.580591
Log Pis Min                  -8.327183
Policy mu Mean               -0.013348484
Policy mu Std                0.6261296
Policy mu Max                2.1722329
Policy mu Min                -1.9547642
Policy log std Mean          -0.9935914
Policy log std Std           0.25789675
Policy log std Max           -0.24468344
Policy log std Min           -2.341473
Z mean eval                  1.0367639
Z variance eval              0.011086758
total_rewards                [1091.79741687  167.75981945 3580.06058729 1457.06716284 2023.14787453
 3175.87709756 3508.46106165 2636.65600589 3015.13632957   61.26744543]
total_rewards_mean           2071.723080109278
total_rewards_std            1255.987883578021
total_rewards_max            3580.060587293167
total_rewards_min            61.26744543447601
Number of train steps total  382000
Number of env steps total    1912000
Number of rollouts total     0
Train Time (s)               29.520756314042956
(Previous) Eval Time (s)     13.509073142893612
Sample Time (s)              17.61034297477454
Epoch Time (s)               60.64017243171111
Total Train Time (s)         26338.12843935564
Epoch                        381
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:34:30.578703 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #381 | Epoch Duration: 64.22925782203674
2020-01-11 10:34:30.579018 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #381 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0348824
Z variance train             0.011087444
KL Divergence                21.9109
KL Loss                      2.19109
QF Loss                      1438.5999
VF Loss                      210.70047
Policy Loss                  -1191.7826
Q Predictions Mean           1192.9404
Q Predictions Std            270.54672
Q Predictions Max            1446.428
Q Predictions Min            -15.725668
V Predictions Mean           1194.9235
V Predictions Std            271.4147
V Predictions Max            1445.1146
V Predictions Min            -14.959059
Log Pis Mean                 0.052661434
Log Pis Std                  2.6993556
Log Pis Max                  13.3622875
Log Pis Min                  -9.777869
Policy mu Mean               -0.02467445
Policy mu Std                0.5990467
Policy mu Max                2.378943
Policy mu Min                -3.106833
Policy log std Mean          -1.0090189
Policy log std Std           0.2778159
Policy log std Max           -0.22376102
Policy log std Min           -2.297546
Z mean eval                  1.0524162
Z variance eval              0.011304838
total_rewards                [ 260.38921751 3380.85329995 2650.08792702 1157.56245366 3463.85272857
 3417.45183414 2357.6787455  3738.12823581 1009.93107371 3495.07098533]
total_rewards_mean           2493.1006501195006
total_rewards_std            1189.5531271666985
total_rewards_max            3738.1282358053377
total_rewards_min            260.38921751378496
Number of train steps total  383000
Number of env steps total    1917000
Number of rollouts total     0
Train Time (s)               29.991975399199873
(Previous) Eval Time (s)     17.09781954996288
Sample Time (s)              17.82621411094442
Epoch Time (s)               64.91600906010717
Total Train Time (s)         26406.6405782355
Epoch                        382
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:35:39.092298 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #382 | Epoch Duration: 68.51305890083313
2020-01-11 10:35:39.092454 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #382 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0509878
Z variance train             0.011316538
KL Divergence                21.266985
KL Loss                      2.1266985
QF Loss                      753.2881
VF Loss                      138.66962
Policy Loss                  -1214.0651
Q Predictions Mean           1212.0759
Q Predictions Std            257.0746
Q Predictions Max            1432.83
Q Predictions Min            -36.192482
V Predictions Mean           1214.5167
V Predictions Std            246.044
V Predictions Max            1446.1039
V Predictions Min            1.1523967
Log Pis Mean                 0.23141599
Log Pis Std                  2.9715106
Log Pis Max                  15.462575
Log Pis Min                  -8.314453
Policy mu Mean               0.011508183
Policy mu Std                0.60473907
Policy mu Max                2.4328065
Policy mu Min                -2.6101592
Policy log std Mean          -1.0342249
Policy log std Std           0.3079703
Policy log std Max           0.42876488
Policy log std Min           -3.3521552
Z mean eval                  1.0567974
Z variance eval              0.010010403
total_rewards                [2946.45736742 3183.3308927  3276.35835882 2736.30768654 3358.80019866
 3316.8667579  3286.77210357 3424.62304809 3464.19455694 2139.2256438 ]
total_rewards_mean           3113.293661444376
total_rewards_std            387.572476746389
total_rewards_max            3464.194556935303
total_rewards_min            2139.2256438015206
Number of train steps total  384000
Number of env steps total    1922000
Number of rollouts total     0
Train Time (s)               30.521932407747954
(Previous) Eval Time (s)     20.69458209304139
Sample Time (s)              17.888990581966937
Epoch Time (s)               69.10550508275628
Total Train Time (s)         26479.99452613108
Epoch                        383
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:36:52.448982 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #383 | Epoch Duration: 73.35637497901917
2020-01-11 10:36:52.449164 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #383 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0569109
Z variance train             0.009992817
KL Divergence                21.661882
KL Loss                      2.1661882
QF Loss                      1966.2461
VF Loss                      514.6378
Policy Loss                  -1223.3708
Q Predictions Mean           1218.8303
Q Predictions Std            241.44887
Q Predictions Max            1452.9934
Q Predictions Min            12.00476
V Predictions Mean           1214.0162
V Predictions Std            239.46152
V Predictions Max            1438.7603
V Predictions Min            -6.8282022
Log Pis Mean                 -0.034023672
Log Pis Std                  2.9607043
Log Pis Max                  14.550201
Log Pis Min                  -7.4333973
Policy mu Mean               -0.011306488
Policy mu Std                0.6296047
Policy mu Max                2.3015938
Policy mu Min                -2.1532648
Policy log std Mean          -0.9782955
Policy log std Std           0.27447984
Policy log std Max           0.023048043
Policy log std Min           -2.4225578
Z mean eval                  1.0512835
Z variance eval              0.018827341
total_rewards                [3518.84406396  220.0649005  3322.13399421 3112.71656217 3449.82083429
   58.71786244 2948.6520979  3311.66209005  919.06673461 3579.47785791]
total_rewards_mean           2444.1156998042643
total_rewards_std            1365.392515199504
total_rewards_max            3579.4778579097074
total_rewards_min            58.71786243939472
Number of train steps total  385000
Number of env steps total    1927000
Number of rollouts total     0
Train Time (s)               29.70361338974908
(Previous) Eval Time (s)     24.945083762984723
Sample Time (s)              17.848449467215687
Epoch Time (s)               72.49714661994949
Total Train Time (s)         26550.307875978295
Epoch                        384
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:38:02.765722 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #384 | Epoch Duration: 70.31641411781311
2020-01-11 10:38:02.765913 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #384 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0517212
Z variance train             0.018854612
KL Divergence                21.418507
KL Loss                      2.1418507
QF Loss                      1074.149
VF Loss                      315.19733
Policy Loss                  -1228.5913
Q Predictions Mean           1226.3215
Q Predictions Std            261.81613
Q Predictions Max            1436.6536
Q Predictions Min            46.394882
V Predictions Mean           1236.0687
V Predictions Std            258.84515
V Predictions Max            1443.835
V Predictions Min            42.31669
Log Pis Mean                 0.12344618
Log Pis Std                  2.8143826
Log Pis Max                  18.812769
Log Pis Min                  -7.696678
Policy mu Mean               -0.019603342
Policy mu Std                0.60414404
Policy mu Max                2.094396
Policy mu Min                -2.606269
Policy log std Mean          -1.0049255
Policy log std Std           0.2818865
Policy log std Max           -0.17132843
Policy log std Min           -2.9003563
Z mean eval                  1.0616057
Z variance eval              0.020881694
total_rewards                [3424.21245377 3399.74146157 1172.48012301 3650.53699688 1556.51294956
 3556.49455241 3154.65186967 3520.24138492 3306.75700742 3419.73460113]
total_rewards_mean           3016.1363400344117
total_rewards_std            840.1404204339071
total_rewards_max            3650.5369968844434
total_rewards_min            1172.4801230081437
Number of train steps total  386000
Number of env steps total    1932000
Number of rollouts total     0
Train Time (s)               28.638402921147645
(Previous) Eval Time (s)     22.76405272586271
Sample Time (s)              18.323875037953258
Epoch Time (s)               69.72633068496361
Total Train Time (s)         26624.416993611958
Epoch                        385
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:39:16.877201 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #385 | Epoch Duration: 74.11114835739136
2020-01-11 10:39:16.877396 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #385 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0578473
Z variance train             0.02084304
KL Divergence                21.61423
KL Loss                      2.161423
QF Loss                      1028.904
VF Loss                      180.3489
Policy Loss                  -1210.0295
Q Predictions Mean           1206.0979
Q Predictions Std            282.33624
Q Predictions Max            1435.4734
Q Predictions Min            22.700026
V Predictions Mean           1217.8136
V Predictions Std            273.1966
V Predictions Max            1457.7477
V Predictions Min            22.594017
Log Pis Mean                 0.05765997
Log Pis Std                  2.8762722
Log Pis Max                  8.560275
Log Pis Min                  -7.4809484
Policy mu Mean               0.030859668
Policy mu Std                0.60284865
Policy mu Max                2.7023942
Policy mu Min                -2.2272158
Policy log std Mean          -1.0311527
Policy log std Std           0.30866402
Policy log std Max           -0.18387681
Policy log std Min           -2.7871323
Z mean eval                  1.0818704
Z variance eval              0.01147574
total_rewards                [3483.36284906 3057.88660798 3194.30550672 3711.16358407 3397.98414798
 3336.18525097 3425.56099782 3229.60135951 3251.25194792 1539.11272357]
total_rewards_mean           3162.6414975594885
total_rewards_std            567.3205652128071
total_rewards_max            3711.16358407138
total_rewards_min            1539.1127235700565
Number of train steps total  387000
Number of env steps total    1937000
Number of rollouts total     0
Train Time (s)               29.388784326147288
(Previous) Eval Time (s)     27.148575555998832
Sample Time (s)              18.3025098759681
Epoch Time (s)               74.83986975811422
Total Train Time (s)         26698.053674626164
Epoch                        386
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:40:30.520017 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #386 | Epoch Duration: 73.6424446105957
2020-01-11 10:40:30.520288 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #386 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.082698
Z variance train             0.011462295
KL Divergence                22.193398
KL Loss                      2.2193398
QF Loss                      1385.1622
VF Loss                      2772.8406
Policy Loss                  -1224.3577
Q Predictions Mean           1223.7224
Q Predictions Std            257.01236
Q Predictions Max            1450.689
Q Predictions Min            5.320549
V Predictions Mean           1217.7296
V Predictions Std            254.54047
V Predictions Max            1439.9255
V Predictions Min            10.407814
Log Pis Mean                 0.5125929
Log Pis Std                  3.1171217
Log Pis Max                  19.719353
Log Pis Min                  -7.657277
Policy mu Mean               -0.007163902
Policy mu Std                0.6332844
Policy mu Max                3.8168461
Policy mu Min                -3.497353
Policy log std Mean          -1.0488383
Policy log std Std           0.319269
Policy log std Max           -0.18782163
Policy log std Min           -3.0696726
Z mean eval                  1.0227177
Z variance eval              0.012962492
total_rewards                [3407.40496558 2431.0353613  3394.34965495 3736.74222949 3509.85241622
 3619.25426201 3755.19204875 3479.15251816 2149.36988599 3185.95322406]
total_rewards_mean           3266.8306566522338
total_rewards_std            517.4448783935865
total_rewards_max            3755.1920487538337
total_rewards_min            2149.36988599373
Number of train steps total  388000
Number of env steps total    1942000
Number of rollouts total     0
Train Time (s)               28.58073744829744
(Previous) Eval Time (s)     25.950757063925266
Sample Time (s)              18.805471973028034
Epoch Time (s)               73.33696648525074
Total Train Time (s)         26772.31982140802
Epoch                        387
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:41:44.788469 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #387 | Epoch Duration: 74.2679934501648
2020-01-11 10:41:44.788719 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #387 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0225388
Z variance train             0.012972387
KL Divergence                22.287981
KL Loss                      2.2287982
QF Loss                      722.59216
VF Loss                      272.89444
Policy Loss                  -1233.9706
Q Predictions Mean           1235.0463
Q Predictions Std            226.40154
Q Predictions Max            1474.131
Q Predictions Min            -64.916145
V Predictions Mean           1227.579
V Predictions Std            222.46902
V Predictions Max            1463.6058
V Predictions Min            -5.128584
Log Pis Mean                 0.014269888
Log Pis Std                  2.2931988
Log Pis Max                  5.9445763
Log Pis Min                  -6.7508698
Policy mu Mean               0.0253812
Policy mu Std                0.5776474
Policy mu Max                2.0321772
Policy mu Min                -2.236875
Policy log std Mean          -1.0055891
Policy log std Std           0.25701782
Policy log std Max           -0.21242118
Policy log std Min           -2.3132377
Z mean eval                  1.0454532
Z variance eval              0.016665548
total_rewards                [3336.357514   3484.85784295 3322.31700647 1915.77870466  866.5200153
  891.77014873  116.05764449 3426.56161572 3369.56971846 3188.07927328]
total_rewards_mean           2391.7869484054418
total_rewards_std            1248.8322656136754
total_rewards_max            3484.8578429450154
total_rewards_min            116.05764448719813
Number of train steps total  389000
Number of env steps total    1947000
Number of rollouts total     0
Train Time (s)               26.98362998198718
(Previous) Eval Time (s)     26.881407937034965
Sample Time (s)              18.34110075002536
Epoch Time (s)               72.2061386690475
Total Train Time (s)         26837.040263689123
Epoch                        388
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:42:49.514278 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #388 | Epoch Duration: 64.72541427612305
2020-01-11 10:42:49.514456 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #388 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.046294
Z variance train             0.016630324
KL Divergence                22.014383
KL Loss                      2.2014384
QF Loss                      1395.7681
VF Loss                      305.12762
Policy Loss                  -1212.2916
Q Predictions Mean           1211.5579
Q Predictions Std            285.95224
Q Predictions Max            1451.0148
Q Predictions Min            -8.033325
V Predictions Mean           1211.0203
V Predictions Std            276.7515
V Predictions Max            1457.2222
V Predictions Min            2.678422
Log Pis Mean                 0.022926563
Log Pis Std                  2.5630553
Log Pis Max                  13.267937
Log Pis Min                  -6.99057
Policy mu Mean               0.05047497
Policy mu Std                0.5605451
Policy mu Max                2.217451
Policy mu Min                -2.5269866
Policy log std Mean          -1.0297856
Policy log std Std           0.27659088
Policy log std Max           -0.15613568
Policy log std Min           -2.3807368
Z mean eval                  1.015579
Z variance eval              0.013128025
total_rewards                [ 771.97181017 1424.88815795 1539.97230983 3568.13873873 1354.71061304
 3264.75907336 2831.36822995 2425.50264958 3487.89977831 3398.13845298]
total_rewards_mean           2406.734981389244
total_rewards_std            995.5920059837189
total_rewards_max            3568.1387387342206
total_rewards_min            771.9718101655657
Number of train steps total  390000
Number of env steps total    1952000
Number of rollouts total     0
Train Time (s)               28.949527125805616
(Previous) Eval Time (s)     19.400366230867803
Sample Time (s)              17.356937545351684
Epoch Time (s)               65.7068309020251
Total Train Time (s)         26902.349132534117
Epoch                        389
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:43:54.825673 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #389 | Epoch Duration: 65.31108331680298
2020-01-11 10:43:54.825827 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #389 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.015118
Z variance train             0.013141696
KL Divergence                22.247347
KL Loss                      2.2247348
QF Loss                      1006.3773
VF Loss                      232.89566
Policy Loss                  -1210.1515
Q Predictions Mean           1208.8124
Q Predictions Std            264.41248
Q Predictions Max            1468.0334
Q Predictions Min            -73.24062
V Predictions Mean           1212.3013
V Predictions Std            247.9929
V Predictions Max            1450.5251
V Predictions Min            22.51017
Log Pis Mean                 0.31812555
Log Pis Std                  3.018902
Log Pis Max                  16.64677
Log Pis Min                  -9.508872
Policy mu Mean               0.07506052
Policy mu Std                0.5968284
Policy mu Max                2.5928578
Policy mu Min                -2.4898293
Policy log std Mean          -1.0541928
Policy log std Std           0.30133823
Policy log std Max           -0.0017048717
Policy log std Min           -3.497045
Z mean eval                  1.0393207
Z variance eval              0.015171552
total_rewards                [3240.79504298 3335.27306549  915.91097499 1937.06103962 1497.95176308
 3216.37310687  555.14770434   45.78625726 3453.57233102 1597.33847088]
total_rewards_mean           1979.5209756540382
total_rewards_std            1200.4464679874764
total_rewards_max            3453.5723310171597
total_rewards_min            45.78625725504332
Number of train steps total  391000
Number of env steps total    1957000
Number of rollouts total     0
Train Time (s)               29.883494519628584
(Previous) Eval Time (s)     19.004317802842706
Sample Time (s)              17.992655725218356
Epoch Time (s)               66.88046804768965
Total Train Time (s)         26968.63005190855
Epoch                        390
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:45:01.110533 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #390 | Epoch Duration: 66.2845687866211
2020-01-11 10:45:01.110713 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #390 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0385231
Z variance train             0.015219035
KL Divergence                22.067163
KL Loss                      2.2067163
QF Loss                      817.26135
VF Loss                      110.36641
Policy Loss                  -1235.6171
Q Predictions Mean           1238.783
Q Predictions Std            231.53546
Q Predictions Max            1425.3033
Q Predictions Min            90.68267
V Predictions Mean           1237.3049
V Predictions Std            233.30084
V Predictions Max            1417.8411
V Predictions Min            70.6947
Log Pis Mean                 0.4431402
Log Pis Std                  2.531648
Log Pis Max                  7.9098406
Log Pis Min                  -7.470559
Policy mu Mean               0.016398298
Policy mu Std                0.60735047
Policy mu Max                2.1860125
Policy mu Min                -2.7409878
Policy log std Mean          -1.048714
Policy log std Std           0.26665688
Policy log std Max           -0.023424268
Policy log std Min           -2.0673633
Z mean eval                  1.0238584
Z variance eval              0.012122169
total_rewards                [3519.02356585 3551.88893274 3344.77337024  370.7064836  1103.03575233
 3383.88942286 3189.06400454 3673.48935643 1439.04885169  285.52797554]
total_rewards_mean           2386.044771582295
total_rewards_std            1337.0382985958768
total_rewards_max            3673.4893564299864
total_rewards_min            285.5279755397886
Number of train steps total  392000
Number of env steps total    1962000
Number of rollouts total     0
Train Time (s)               28.921060161665082
(Previous) Eval Time (s)     18.408096320927143
Sample Time (s)              18.43119227932766
Epoch Time (s)               65.76034876191989
Total Train Time (s)         27035.08206286514
Epoch                        391
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:46:07.564371 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #391 | Epoch Duration: 66.45353245735168
2020-01-11 10:46:07.564567 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #391 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0234256
Z variance train             0.012095703
KL Divergence                22.183123
KL Loss                      2.2183123
QF Loss                      3807.2202
VF Loss                      564.5994
Policy Loss                  -1198.5582
Q Predictions Mean           1199.8213
Q Predictions Std            278.46988
Q Predictions Max            1445.9375
Q Predictions Min            39.90635
V Predictions Mean           1210.2139
V Predictions Std            268.5165
V Predictions Max            1445.4298
V Predictions Min            46.796455
Log Pis Mean                 -0.0054866336
Log Pis Std                  2.7546623
Log Pis Max                  10.02842
Log Pis Min                  -6.656881
Policy mu Mean               -0.02493708
Policy mu Std                0.59379774
Policy mu Max                2.2744706
Policy mu Min                -2.3082361
Policy log std Mean          -1.0027106
Policy log std Std           0.28578058
Policy log std Max           0.21152163
Policy log std Min           -2.3413825
Z mean eval                  1.0528127
Z variance eval              0.011742557
total_rewards                [3422.11887155 2428.40494552 3299.24202352 3505.16927297 3566.25155607
 3581.26188801 2518.52191443   82.67917155 2655.74199366  488.79847873]
total_rewards_mean           2554.819011601568
total_rewards_std            1212.1683353496246
total_rewards_max            3581.261888006244
total_rewards_min            82.6791715513009
Number of train steps total  393000
Number of env steps total    1967000
Number of rollouts total     0
Train Time (s)               29.65652137529105
(Previous) Eval Time (s)     19.10098840110004
Sample Time (s)              17.753801554441452
Epoch Time (s)               66.51131133083254
Total Train Time (s)         27102.86704754457
Epoch                        392
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:47:15.357352 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #392 | Epoch Duration: 67.79259037971497
2020-01-11 10:47:15.357705 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #392 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0509272
Z variance train             0.011750316
KL Divergence                23.38034
KL Loss                      2.3380342
QF Loss                      1664.0724
VF Loss                      879.1885
Policy Loss                  -1225.4886
Q Predictions Mean           1226.0969
Q Predictions Std            255.5227
Q Predictions Max            1494.959
Q Predictions Min            -54.804348
V Predictions Mean           1237.0382
V Predictions Std            247.13701
V Predictions Max            1497.5869
V Predictions Min            6.763589
Log Pis Mean                 0.21956635
Log Pis Std                  2.782402
Log Pis Max                  19.50631
Log Pis Min                  -5.9312973
Policy mu Mean               0.028762117
Policy mu Std                0.59592897
Policy mu Max                2.337904
Policy mu Min                -3.4713247
Policy log std Mean          -1.0579816
Policy log std Std           0.26358476
Policy log std Max           -0.31518537
Policy log std Min           -2.609423
Z mean eval                  1.0654922
Z variance eval              0.008919427
total_rewards                [3418.50538577 2909.73729758   80.90076673 3427.79069246 3250.92875312
 1219.47850448 3435.47832494 3360.31216966 3629.05322804 3420.03155423]
total_rewards_mean           2815.2216676998737
total_rewards_std            1125.6478907377145
total_rewards_max            3629.0532280372463
total_rewards_min            80.90076673090532
Number of train steps total  394000
Number of env steps total    1972000
Number of rollouts total     0
Train Time (s)               28.77635719301179
(Previous) Eval Time (s)     20.381918503902853
Sample Time (s)              18.178436217829585
Epoch Time (s)               67.33671191474423
Total Train Time (s)         27175.026320975274
Epoch                        393
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:48:27.523261 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #393 | Epoch Duration: 72.16523051261902
2020-01-11 10:48:27.523568 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #393 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0663022
Z variance train             0.008933568
KL Divergence                24.21429
KL Loss                      2.4214292
QF Loss                      1353.2733
VF Loss                      267.19855
Policy Loss                  -1236.3802
Q Predictions Mean           1237.9307
Q Predictions Std            231.02068
Q Predictions Max            1436.8904
Q Predictions Min            46.096275
V Predictions Mean           1233.5593
V Predictions Std            230.37222
V Predictions Max            1432.0747
V Predictions Min            35.222244
Log Pis Mean                 0.21612601
Log Pis Std                  3.2130096
Log Pis Max                  18.277414
Log Pis Min                  -8.622486
Policy mu Mean               -0.09217122
Policy mu Std                0.6152752
Policy mu Max                3.0737114
Policy mu Min                -3.7096035
Policy log std Mean          -1.0300287
Policy log std Std           0.2786347
Policy log std Max           -0.19305766
Policy log std Min           -2.5406487
Z mean eval                  1.0247693
Z variance eval              0.010469964
total_rewards                [3344.2626181  3529.87881964 3384.10925769 3562.18315086 3070.68171955
 3208.01923476 3684.82669305 3221.74919304 3446.74056648 3276.96413604]
total_rewards_mean           3372.9415389196
total_rewards_std            177.40876364432881
total_rewards_max            3684.8266930498025
total_rewards_min            3070.6817195459716
Number of train steps total  395000
Number of env steps total    1977000
Number of rollouts total     0
Train Time (s)               28.65399013599381
(Previous) Eval Time (s)     25.210089810192585
Sample Time (s)              18.148823202122003
Epoch Time (s)               72.0129031483084
Total Train Time (s)         27248.675501455087
Epoch                        394
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:49:41.172287 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #394 | Epoch Duration: 73.6485505104065
2020-01-11 10:49:41.172494 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #394 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.024792
Z variance train             0.010447821
KL Divergence                24.178127
KL Loss                      2.4178128
QF Loss                      907.26733
VF Loss                      726.6972
Policy Loss                  -1235.6896
Q Predictions Mean           1236.9268
Q Predictions Std            238.1016
Q Predictions Max            1441.9896
Q Predictions Min            -72.00098
V Predictions Mean           1243.6311
V Predictions Std            229.20807
V Predictions Max            1444.9115
V Predictions Min            -49.147823
Log Pis Mean                 0.055819996
Log Pis Std                  3.0725229
Log Pis Max                  16.45005
Log Pis Min                  -8.03491
Policy mu Mean               0.0013206373
Policy mu Std                0.56844586
Policy mu Max                1.9779466
Policy mu Min                -2.4291985
Policy log std Mean          -1.0617554
Policy log std Std           0.30286857
Policy log std Max           -0.11479008
Policy log std Min           -3.1350117
Z mean eval                  1.0291598
Z variance eval              0.011800496
total_rewards                [ 953.04026752 3444.41137503 3499.80366513 2825.4675083  3276.44730943
 3542.27280771 3370.93025001  208.0006365  3356.25758209  115.37901387]
total_rewards_mean           2459.201041559417
total_rewards_std            1359.943604857778
total_rewards_max            3542.2728077060624
total_rewards_min            115.37901387036837
Number of train steps total  396000
Number of env steps total    1982000
Number of rollouts total     0
Train Time (s)               31.011681609321386
(Previous) Eval Time (s)     26.845414764247835
Sample Time (s)              18.156284825410694
Epoch Time (s)               76.01338119897991
Total Train Time (s)         27316.98590753833
Epoch                        395
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:50:49.488195 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #395 | Epoch Duration: 68.31554913520813
2020-01-11 10:50:49.488438 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #395 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0277545
Z variance train             0.011823526
KL Divergence                23.720608
KL Loss                      2.3720608
QF Loss                      1169.8658
VF Loss                      232.01788
Policy Loss                  -1243.625
Q Predictions Mean           1242.6257
Q Predictions Std            231.56128
Q Predictions Max            1466.9832
Q Predictions Min            -28.033007
V Predictions Mean           1246.0483
V Predictions Std            227.60295
V Predictions Max            1456.517
V Predictions Min            -30.484308
Log Pis Mean                 -0.1299129
Log Pis Std                  2.7845945
Log Pis Max                  8.494994
Log Pis Min                  -12.564507
Policy mu Mean               0.06132878
Policy mu Std                0.6189654
Policy mu Max                2.5571077
Policy mu Min                -2.745516
Policy log std Mean          -1.0108404
Policy log std Std           0.2537963
Policy log std Max           -0.20694822
Policy log std Min           -2.478437
Z mean eval                  1.0345285
Z variance eval              0.008241205
total_rewards                [1408.34963404 3390.64486731 3256.08387292 1949.16384243 3502.88630046
  554.0299666  2769.57837725 3583.02229039 3497.82406592 2742.61196353]
total_rewards_mean           2665.419518083493
total_rewards_std            983.8241430159544
total_rewards_max            3583.02229039075
total_rewards_min            554.0299665980289
Number of train steps total  397000
Number of env steps total    1987000
Number of rollouts total     0
Train Time (s)               29.559227658901364
(Previous) Eval Time (s)     19.1472585410811
Sample Time (s)              18.609555622097105
Epoch Time (s)               67.31604182207957
Total Train Time (s)         27386.20635916572
Epoch                        396
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:51:58.712692 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #396 | Epoch Duration: 69.2240629196167
2020-01-11 10:51:58.712906 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #396 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0362618
Z variance train             0.008212467
KL Divergence                24.526754
KL Loss                      2.4526756
QF Loss                      1054.8037
VF Loss                      208.22154
Policy Loss                  -1265.8489
Q Predictions Mean           1265.6692
Q Predictions Std            194.42413
Q Predictions Max            1449.6799
Q Predictions Min            27.110807
V Predictions Mean           1258.7396
V Predictions Std            191.66484
V Predictions Max            1453.2587
V Predictions Min            41.69674
Log Pis Mean                 0.4371667
Log Pis Std                  2.7617729
Log Pis Max                  12.03377
Log Pis Min                  -6.4059143
Policy mu Mean               -0.008728874
Policy mu Std                0.6126996
Policy mu Max                1.94693
Policy mu Min                -2.692942
Policy log std Mean          -1.0422175
Policy log std Std           0.2829179
Policy log std Max           -0.15577328
Policy log std Min           -2.9762692
Z mean eval                  1.046572
Z variance eval              0.016482329
total_rewards                [3396.89169967 3466.91399619 1821.70709735 1637.94332362 3773.58547955
 2023.14401835 3655.5014436  3565.97853126 3324.11236042 1998.1736328 ]
total_rewards_mean           2866.3951582806467
total_rewards_std            827.7682377066825
total_rewards_max            3773.585479549008
total_rewards_min            1637.9433236158347
Number of train steps total  398000
Number of env steps total    1992000
Number of rollouts total     0
Train Time (s)               28.273642234969884
(Previous) Eval Time (s)     21.05492576956749
Sample Time (s)              17.738529645372182
Epoch Time (s)               67.06709764990956
Total Train Time (s)         27457.07885859534
Epoch                        397
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:53:09.590463 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #397 | Epoch Duration: 70.87731218338013
2020-01-11 10:53:09.590760 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #397 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0466254
Z variance train             0.016487952
KL Divergence                24.040466
KL Loss                      2.4040468
QF Loss                      1215.1504
VF Loss                      309.08215
Policy Loss                  -1249.1364
Q Predictions Mean           1249.3165
Q Predictions Std            223.10568
Q Predictions Max            1453.3112
Q Predictions Min            -52.36399
V Predictions Mean           1247.6559
V Predictions Std            223.19844
V Predictions Max            1466.9657
V Predictions Min            -43.55745
Log Pis Mean                 0.31805015
Log Pis Std                  2.6940093
Log Pis Max                  10.766855
Log Pis Min                  -7.4615774
Policy mu Mean               0.0064634006
Policy mu Std                0.6258503
Policy mu Max                2.9079504
Policy mu Min                -2.4418294
Policy log std Mean          -1.0130165
Policy log std Std           0.2804107
Policy log std Max           -0.16843992
Policy log std Min           -2.484094
Z mean eval                  1.0816616
Z variance eval              0.014829735
total_rewards                [3502.26865326 3468.55263342 1973.10654229 2576.32607907 3657.45226296
 2106.62142138 3038.63864241 3426.31723709 3394.39040723 3596.26308291]
total_rewards_mean           3073.9936962009815
total_rewards_std            597.9762550303795
total_rewards_max            3657.4522629585263
total_rewards_min            1973.1065422924921
Number of train steps total  399000
Number of env steps total    1997000
Number of rollouts total     0
Train Time (s)               29.082295547705144
(Previous) Eval Time (s)     24.86483641061932
Sample Time (s)              18.4708295292221
Epoch Time (s)               72.41796148754656
Total Train Time (s)         27528.853926868178
Epoch                        398
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:54:21.370982 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #398 | Epoch Duration: 71.78001856803894
2020-01-11 10:54:21.371167 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #398 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.081453
Z variance train             0.014833188
KL Divergence                24.768337
KL Loss                      2.4768338
QF Loss                      1156.1611
VF Loss                      156.65033
Policy Loss                  -1254.4802
Q Predictions Mean           1254.8806
Q Predictions Std            233.79121
Q Predictions Max            1482.4004
Q Predictions Min            -43.938915
V Predictions Mean           1253.8372
V Predictions Std            230.35756
V Predictions Max            1480.602
V Predictions Min            -40.847908
Log Pis Mean                 0.24772312
Log Pis Std                  2.9983628
Log Pis Max                  16.945532
Log Pis Min                  -6.2650175
Policy mu Mean               0.0042068316
Policy mu Std                0.6225109
Policy mu Max                2.4886425
Policy mu Min                -3.1032972
Policy log std Mean          -1.0270791
Policy log std Std           0.26259565
Policy log std Max           -0.1908356
Policy log std Min           -2.522553
Z mean eval                  1.0547526
Z variance eval              0.01669091
total_rewards                [3517.71199249 3605.32867222 3478.00197043 3521.17740753 3864.13207643
 3901.03616056 3723.25007586 3726.25925595 3646.44127239 3764.90081085]
total_rewards_mean           3674.8239694702147
total_rewards_std            138.84507230488344
total_rewards_max            3901.036160555114
total_rewards_min            3478.0019704252627
Number of train steps total  400000
Number of env steps total    2002000
Number of rollouts total     0
Train Time (s)               29.10091269388795
(Previous) Eval Time (s)     24.226507554296404
Sample Time (s)              18.05635688500479
Epoch Time (s)               71.38377713318914
Total Train Time (s)         27603.49722452322
Epoch                        399
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:55:36.017615 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #399 | Epoch Duration: 74.64631199836731
2020-01-11 10:55:36.017763 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #399 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.054989
Z variance train             0.016713772
KL Divergence                24.102146
KL Loss                      2.4102147
QF Loss                      1635.2173
VF Loss                      249.47406
Policy Loss                  -1243.3888
Q Predictions Mean           1242.4647
Q Predictions Std            260.53687
Q Predictions Max            1490.0443
Q Predictions Min            -28.54375
V Predictions Mean           1235.5449
V Predictions Std            262.1988
V Predictions Max            1486.3638
V Predictions Min            -37.67232
Log Pis Mean                 0.29584068
Log Pis Std                  2.8834383
Log Pis Max                  19.557907
Log Pis Min                  -7.259055
Policy mu Mean               0.018670723
Policy mu Std                0.57728064
Policy mu Max                2.4115553
Policy mu Min                -2.6615815
Policy log std Mean          -1.042136
Policy log std Std           0.2781719
Policy log std Max           -0.2232539
Policy log std Min           -2.4585657
Z mean eval                  1.0297515
Z variance eval              0.01799798
total_rewards                [3464.70142623 3660.63257372 2662.89480216 3631.60203299 3510.93191656
 3679.92590081  466.98870218 3621.62058712  988.742397   3638.03323212]
total_rewards_mean           2932.6073570890017
total_rewards_std            1144.4509061714386
total_rewards_max            3679.925900810565
total_rewards_min            466.9887021809758
Number of train steps total  401000
Number of env steps total    2007000
Number of rollouts total     0
Train Time (s)               29.051479432731867
(Previous) Eval Time (s)     27.488725210074335
Sample Time (s)              18.93669390399009
Epoch Time (s)               75.47689854679629
Total Train Time (s)         27676.585334953386
Epoch                        400
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:56:49.109581 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #400 | Epoch Duration: 73.0916919708252
2020-01-11 10:56:49.109756 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #400 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.028415
Z variance train             0.018081412
KL Divergence                24.175777
KL Loss                      2.4175777
QF Loss                      1098.3085
VF Loss                      207.02734
Policy Loss                  -1254.4192
Q Predictions Mean           1255.6882
Q Predictions Std            208.5065
Q Predictions Max            1481.3231
Q Predictions Min            -44.84877
V Predictions Mean           1254.1958
V Predictions Std            203.53302
V Predictions Max            1468.9604
V Predictions Min            -19.496727
Log Pis Mean                 0.1330543
Log Pis Std                  2.7038026
Log Pis Max                  10.211344
Log Pis Min                  -7.3203325
Policy mu Mean               0.025125833
Policy mu Std                0.61979383
Policy mu Max                2.5480874
Policy mu Min                -2.4233334
Policy log std Mean          -1.0218045
Policy log std Std           0.25866055
Policy log std Max           -0.19174826
Policy log std Min           -2.1018896
Z mean eval                  1.0528758
Z variance eval              0.013488037
total_rewards                [3630.99507196 3475.82306013 3496.39982369 3459.14381983 3523.34672775
  660.87117657 3595.56213921  357.06397192 3437.76845788 2412.79426157]
total_rewards_mean           2804.9768510493063
total_rewards_std            1196.7923910833183
total_rewards_max            3630.9950719597723
total_rewards_min            357.06397191757344
Number of train steps total  402000
Number of env steps total    2012000
Number of rollouts total     0
Train Time (s)               27.58769515203312
(Previous) Eval Time (s)     25.103173847775906
Sample Time (s)              18.91261049453169
Epoch Time (s)               71.60347949434072
Total Train Time (s)         27743.539875992574
Epoch                        401
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:57:56.070614 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #401 | Epoch Duration: 66.96067786216736
2020-01-11 10:57:56.070904 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #401 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0533209
Z variance train             0.013436018
KL Divergence                24.386425
KL Loss                      2.4386425
QF Loss                      749.6886
VF Loss                      225.15797
Policy Loss                  -1256.2903
Q Predictions Mean           1254.446
Q Predictions Std            225.30197
Q Predictions Max            1460.9377
Q Predictions Min            18.534927
V Predictions Mean           1248.4197
V Predictions Std            221.47786
V Predictions Max            1454.2733
V Predictions Min            38.847286
Log Pis Mean                 0.045999587
Log Pis Std                  2.8739114
Log Pis Max                  9.0148325
Log Pis Min                  -11.771747
Policy mu Mean               0.013946354
Policy mu Std                0.564439
Policy mu Max                2.3920803
Policy mu Min                -3.0188615
Policy log std Mean          -1.0599768
Policy log std Std           0.25818634
Policy log std Max           -0.19843364
Policy log std Min           -2.1267958
Z mean eval                  1.0593894
Z variance eval              0.008440833
total_rewards                [1545.11898448  453.1495477  3185.82445514 3463.70896418  881.93657694
  690.81133053 3508.58835993 3276.86549028 2818.61992089   10.98187536]
total_rewards_mean           1983.5605505410542
total_rewards_std            1328.2387157650571
total_rewards_max            3508.588359926419
total_rewards_min            10.981875356219687
Number of train steps total  403000
Number of env steps total    2017000
Number of rollouts total     0
Train Time (s)               29.492519821971655
(Previous) Eval Time (s)     20.460044874809682
Sample Time (s)              18.456272875890136
Epoch Time (s)               68.40883757267147
Total Train Time (s)         27806.728930150624
Epoch                        402
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:58:59.264025 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #402 | Epoch Duration: 63.192925453186035
2020-01-11 10:58:59.264210 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #402 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0585124
Z variance train             0.008398524
KL Divergence                25.299067
KL Loss                      2.5299067
QF Loss                      1158.7092
VF Loss                      134.0683
Policy Loss                  -1228.0912
Q Predictions Mean           1225.9724
Q Predictions Std            275.5941
Q Predictions Max            1448.646
Q Predictions Min            -99.18271
V Predictions Mean           1223.4918
V Predictions Std            275.40256
V Predictions Max            1443.6198
V Predictions Min            -88.68722
Log Pis Mean                 0.16058648
Log Pis Std                  2.7141426
Log Pis Max                  9.131649
Log Pis Min                  -7.8885016
Policy mu Mean               0.01835439
Policy mu Std                0.6132275
Policy mu Max                2.145347
Policy mu Min                -2.306374
Policy log std Mean          -1.0367663
Policy log std Std           0.2622695
Policy log std Max           -0.2781378
Policy log std Min           -2.537051
Z mean eval                  1.0456655
Z variance eval              0.014814412
total_rewards                [2962.46917034 3479.43435904 3417.58355074 3304.8835964  3435.20975578
 3385.01603138  439.34011085 3505.58599924 3480.41663186 3522.24180064]
total_rewards_mean           3093.2181006271435
total_rewards_std            898.0800375878118
total_rewards_max            3522.2418006362277
total_rewards_min            439.34011084961935
Number of train steps total  404000
Number of env steps total    2022000
Number of rollouts total     0
Train Time (s)               27.152486614882946
(Previous) Eval Time (s)     15.243855691049248
Sample Time (s)              18.567901492118835
Epoch Time (s)               60.96424379805103
Total Train Time (s)         27876.63447500253
Epoch                        403
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:00:09.174212 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #403 | Epoch Duration: 69.90983057022095
2020-01-11 11:00:09.174470 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #403 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0462264
Z variance train             0.0148589555
KL Divergence                24.128464
KL Loss                      2.4128463
QF Loss                      1277.4769
VF Loss                      210.29837
Policy Loss                  -1248.2622
Q Predictions Mean           1249.7869
Q Predictions Std            269.0279
Q Predictions Max            1502.8978
Q Predictions Min            -49.32745
V Predictions Mean           1246.3411
V Predictions Std            269.0706
V Predictions Max            1504.4071
V Predictions Min            -36.96441
Log Pis Mean                 0.5595161
Log Pis Std                  2.639003
Log Pis Max                  13.0980215
Log Pis Min                  -7.447267
Policy mu Mean               0.06770039
Policy mu Std                0.6451735
Policy mu Max                2.1237013
Policy mu Min                -2.1491888
Policy log std Mean          -1.023655
Policy log std Std           0.28063613
Policy log std Max           0.13259739
Policy log std Min           -2.3076553
Z mean eval                  1.0557529
Z variance eval              0.02068292
total_rewards                [2474.32730485 3492.3501323  3642.76950582 3668.0961374  3405.35062537
 3605.39534922 3357.49972222 3463.1723326  3547.88003288  813.02756269]
total_rewards_mean           3146.9868705346175
total_rewards_std            843.7038824107187
total_rewards_max            3668.0961373965633
total_rewards_min            813.0275626863724
Number of train steps total  405000
Number of env steps total    2027000
Number of rollouts total     0
Train Time (s)               30.265500674955547
(Previous) Eval Time (s)     24.189097337890416
Sample Time (s)              17.59563397197053
Epoch Time (s)               72.05023198481649
Total Train Time (s)         27949.4270477416
Epoch                        404
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:01:21.975111 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #404 | Epoch Duration: 72.80041790008545
2020-01-11 11:01:21.975424 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #404 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0562332
Z variance train             0.020692833
KL Divergence                22.103596
KL Loss                      2.2103596
QF Loss                      972.4932
VF Loss                      295.9957
Policy Loss                  -1244.756
Q Predictions Mean           1244.9856
Q Predictions Std            203.93077
Q Predictions Max            1429.4154
Q Predictions Min            -61.15948
V Predictions Mean           1240.0784
V Predictions Std            205.38344
V Predictions Max            1428.2971
V Predictions Min            -19.853243
Log Pis Mean                 0.6721425
Log Pis Std                  2.6276984
Log Pis Max                  9.019787
Log Pis Min                  -7.1295066
Policy mu Mean               0.023425078
Policy mu Std                0.6368032
Policy mu Max                2.1663845
Policy mu Min                -2.4168286
Policy log std Mean          -1.0522134
Policy log std Std           0.28248766
Policy log std Max           -0.13139284
Policy log std Min           -2.659694
Z mean eval                  1.0247356
Z variance eval              0.020058716
total_rewards                [3379.20710029 3558.12409422 3650.26661318 3455.40731163 1377.7015725
 3541.69339433 3110.6959807  3532.5445362  1353.53809968 3736.92247932]
total_rewards_mean           3069.6101182046914
total_rewards_std            866.724873639584
total_rewards_max            3736.9224793219696
total_rewards_min            1353.5380996767071
Number of train steps total  406000
Number of env steps total    2032000
Number of rollouts total     0
Train Time (s)               29.309824408032
(Previous) Eval Time (s)     24.93895454937592
Sample Time (s)              17.853008361998945
Epoch Time (s)               72.10178731940687
Total Train Time (s)         28020.21086443495
Epoch                        405
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:02:32.764649 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #405 | Epoch Duration: 70.78897404670715
2020-01-11 11:02:32.764936 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #405 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0218151
Z variance train             0.020120662
KL Divergence                21.723694
KL Loss                      2.1723695
QF Loss                      845.57056
VF Loss                      418.32828
Policy Loss                  -1288.5062
Q Predictions Mean           1286.6401
Q Predictions Std            197.27808
Q Predictions Max            1481.0618
Q Predictions Min            123.41127
V Predictions Mean           1272.7156
V Predictions Std            194.34767
V Predictions Max            1465.9474
V Predictions Min            121.0065
Log Pis Mean                 0.45955816
Log Pis Std                  2.811684
Log Pis Max                  14.451015
Log Pis Min                  -7.373371
Policy mu Mean               -0.029751718
Policy mu Std                0.61934453
Policy mu Max                2.50002
Policy mu Min                -2.6400309
Policy log std Mean          -1.0725443
Policy log std Std           0.263068
Policy log std Max           -0.14996964
Policy log std Min           -2.3771358
Z mean eval                  1.0289682
Z variance eval              0.02575163
total_rewards                [3732.54490513  963.03662177 3587.70533967 3687.20071873 3393.35203044
 3416.00349985 3661.19020531 3607.69510167 3692.02397816 3620.04675338]
total_rewards_mean           3336.0799154107917
total_rewards_std            798.2225792116099
total_rewards_max            3732.544905125728
total_rewards_min            963.0366217656297
Number of train steps total  407000
Number of env steps total    2037000
Number of rollouts total     0
Train Time (s)               27.84059527795762
(Previous) Eval Time (s)     23.62583946203813
Sample Time (s)              18.398297767620534
Epoch Time (s)               69.86473250761628
Total Train Time (s)         28090.97124556359
Epoch                        406
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:03:43.528810 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #406 | Epoch Duration: 70.76366639137268
2020-01-11 11:03:43.528999 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #406 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0304788
Z variance train             0.02586495
KL Divergence                22.767109
KL Loss                      2.276711
QF Loss                      977.2705
VF Loss                      106.615875
Policy Loss                  -1250.3114
Q Predictions Mean           1250.4675
Q Predictions Std            255.83995
Q Predictions Max            1502.9548
Q Predictions Min            -33.15708
V Predictions Mean           1250.1603
V Predictions Std            255.17178
V Predictions Max            1492.6967
V Predictions Min            -20.338797
Log Pis Mean                 0.44683257
Log Pis Std                  2.7462738
Log Pis Max                  12.354706
Log Pis Min                  -6.2083693
Policy mu Mean               0.032008335
Policy mu Std                0.6248356
Policy mu Max                2.99713
Policy mu Min                -2.566301
Policy log std Mean          -1.0093486
Policy log std Std           0.29806706
Policy log std Max           -0.17766571
Policy log std Min           -2.9795423
Z mean eval                  1.0375646
Z variance eval              0.020107862
total_rewards                [3757.12032016 3444.35685899 2276.63623262  308.21232235 3280.02159706
 3167.37926979 3814.63114415 4078.10609393 1142.61213209 3782.98331827]
total_rewards_mean           2905.2059289399444
total_rewards_std            1201.8784553287949
total_rewards_max            4078.106093927807
total_rewards_min            308.21232235292854
Number of train steps total  408000
Number of env steps total    2042000
Number of rollouts total     0
Train Time (s)               28.9607048118487
(Previous) Eval Time (s)     24.524467123206705
Sample Time (s)              18.346290751360357
Epoch Time (s)               71.83146268641576
Total Train Time (s)         28159.40707808826
Epoch                        407
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:04:51.967624 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #407 | Epoch Duration: 68.43848156929016
2020-01-11 11:04:51.967856 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #407 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0346751
Z variance train             0.020184232
KL Divergence                23.404087
KL Loss                      2.3404088
QF Loss                      1116.686
VF Loss                      169.87257
Policy Loss                  -1258.776
Q Predictions Mean           1261.6115
Q Predictions Std            261.559
Q Predictions Max            1460.4043
Q Predictions Min            -11.979231
V Predictions Mean           1263.4939
V Predictions Std            259.57773
V Predictions Max            1463.4037
V Predictions Min            -8.638794
Log Pis Mean                 0.5068393
Log Pis Std                  2.763177
Log Pis Max                  11.157181
Log Pis Min                  -7.9018197
Policy mu Mean               0.027877647
Policy mu Std                0.61609423
Policy mu Max                2.724535
Policy mu Min                -2.738413
Policy log std Mean          -1.0455512
Policy log std Std           0.2831245
Policy log std Max           -0.14798385
Policy log std Min           -2.5138345
Z mean eval                  1.0315354
Z variance eval              0.027310371
total_rewards                [3596.12876692 3321.07530839 3618.66293618 2690.26151362 3501.35190859
 3519.91746259 3433.35118753 3517.61565265 3982.25092527 3471.30089769]
total_rewards_mean           3465.191655942639
total_rewards_std            306.1758297918866
total_rewards_max            3982.250925274782
total_rewards_min            2690.261513615177
Number of train steps total  409000
Number of env steps total    2047000
Number of rollouts total     0
Train Time (s)               30.452992506325245
(Previous) Eval Time (s)     21.131157004274428
Sample Time (s)              17.739109160844237
Epoch Time (s)               69.32325867144391
Total Train Time (s)         28234.27797506936
Epoch                        408
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:06:06.843755 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #408 | Epoch Duration: 74.87572121620178
2020-01-11 11:06:06.843974 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #408 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.031718
Z variance train             0.027416784
KL Divergence                22.222908
KL Loss                      2.2222908
QF Loss                      975.5089
VF Loss                      404.97092
Policy Loss                  -1267.3384
Q Predictions Mean           1267.8674
Q Predictions Std            242.33194
Q Predictions Max            1469.9993
Q Predictions Min            -42.93161
V Predictions Mean           1267.4402
V Predictions Std            240.19978
V Predictions Max            1465.3098
V Predictions Min            -30.020716
Log Pis Mean                 0.5220923
Log Pis Std                  2.712396
Log Pis Max                  9.549077
Log Pis Min                  -8.31182
Policy mu Mean               0.014251463
Policy mu Std                0.60748947
Policy mu Max                2.4356914
Policy mu Min                -2.396843
Policy log std Mean          -1.0575044
Policy log std Std           0.26476336
Policy log std Max           -0.18948495
Policy log std Min           -2.5759826
Z mean eval                  1.1069338
Z variance eval              0.022020495
total_rewards                [3371.91968848 3725.03302158 2088.99294085 3221.69768464 3446.85396707
 3294.58325736 3387.42083342 3572.20061783 3503.76180133 3372.83563513]
total_rewards_mean           3298.5299447695725
total_rewards_std            425.279691370872
total_rewards_max            3725.033021579816
total_rewards_min            2088.9929408543176
Number of train steps total  410000
Number of env steps total    2052000
Number of rollouts total     0
Train Time (s)               29.013433302287012
(Previous) Eval Time (s)     26.683333337306976
Sample Time (s)              17.59465883485973
Epoch Time (s)               73.29142547445372
Total Train Time (s)         28306.839406716637
Epoch                        409
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:07:19.407040 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #409 | Epoch Duration: 72.56289768218994
2020-01-11 11:07:19.407237 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #409 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1062992
Z variance train             0.021937931
KL Divergence                22.587427
KL Loss                      2.2587428
QF Loss                      772.4008
VF Loss                      118.10523
Policy Loss                  -1234.9392
Q Predictions Mean           1234.5833
Q Predictions Std            265.32233
Q Predictions Max            1492.1692
Q Predictions Min            41.749058
V Predictions Mean           1231.3901
V Predictions Std            267.29138
V Predictions Max            1479.7029
V Predictions Min            23.197771
Log Pis Mean                 0.16630892
Log Pis Std                  2.679351
Log Pis Max                  8.111682
Log Pis Min                  -7.473866
Policy mu Mean               -0.0029980545
Policy mu Std                0.6235056
Policy mu Max                2.5985548
Policy mu Min                -2.451088
Policy log std Mean          -1.000438
Policy log std Std           0.26572588
Policy log std Max           -0.028321147
Policy log std Min           -2.2212305
Z mean eval                  1.0573986
Z variance eval              0.01700563
total_rewards                [3361.15108025 3527.87718682 3023.2076831  3331.89716625 3455.35412109
  393.97555935 3348.00587362  614.83025642   65.5338724  1580.34408581]
total_rewards_mean           2270.21768851043
total_rewards_std            1364.8928329509174
total_rewards_max            3527.877186819695
total_rewards_min            65.53387239637644
Number of train steps total  411000
Number of env steps total    2057000
Number of rollouts total     0
Train Time (s)               26.203156913165003
(Previous) Eval Time (s)     25.954531471710652
Sample Time (s)              18.079477542545646
Epoch Time (s)               70.2371659274213
Total Train Time (s)         28368.925090515055
Epoch                        410
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:08:21.496887 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #410 | Epoch Duration: 62.08951187133789
2020-01-11 11:08:21.497083 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #410 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0557501
Z variance train             0.017014643
KL Divergence                22.941362
KL Loss                      2.2941363
QF Loss                      11156.942
VF Loss                      727.07074
Policy Loss                  -1243.3372
Q Predictions Mean           1248.0471
Q Predictions Std            266.0849
Q Predictions Max            1473.1975
Q Predictions Min            -23.31509
V Predictions Mean           1250.9221
V Predictions Std            265.27646
V Predictions Max            1491.4198
V Predictions Min            15.084437
Log Pis Mean                 0.26325747
Log Pis Std                  2.962155
Log Pis Max                  21.38328
Log Pis Min                  -6.960455
Policy mu Mean               0.077849016
Policy mu Std                0.6252382
Policy mu Max                5.6533947
Policy mu Min                -3.466384
Policy log std Mean          -1.0280011
Policy log std Std           0.28393084
Policy log std Max           0.4067024
Policy log std Min           -2.880978
Z mean eval                  1.0505645
Z variance eval              0.03102937
total_rewards                [-326.44977865 3926.26642034  375.92426315 3588.98652443  315.92093944
 3653.47848743 3539.18027429 3516.64306924  373.61039465 3925.55604514]
total_rewards_mean           2288.9116639453055
total_rewards_std            1733.2909828163565
total_rewards_max            3926.2664203399177
total_rewards_min            -326.44977864998225
Number of train steps total  412000
Number of env steps total    2062000
Number of rollouts total     0
Train Time (s)               26.076556679792702
(Previous) Eval Time (s)     17.80658055935055
Sample Time (s)              17.614294703118503
Epoch Time (s)               61.497431942261755
Total Train Time (s)         28432.5011514551
Epoch                        411
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:09:25.076156 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #411 | Epoch Duration: 63.57893919944763
2020-01-11 11:09:25.076350 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #411 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0484036
Z variance train             0.031093622
KL Divergence                22.149801
KL Loss                      2.2149801
QF Loss                      1125.9036
VF Loss                      142.98544
Policy Loss                  -1255.8557
Q Predictions Mean           1257.3408
Q Predictions Std            255.85849
Q Predictions Max            1497.1029
Q Predictions Min            -6.184212
V Predictions Mean           1260.5823
V Predictions Std            256.40793
V Predictions Max            1498.0302
V Predictions Min            -10.591026
Log Pis Mean                 0.09626585
Log Pis Std                  2.5877435
Log Pis Max                  7.000787
Log Pis Min                  -7.1602077
Policy mu Mean               -0.030464254
Policy mu Std                0.62011176
Policy mu Max                2.7904365
Policy mu Min                -2.1669614
Policy log std Mean          -1.0324359
Policy log std Std           0.26993677
Policy log std Max           -0.12366009
Policy log std Min           -2.0647697
Z mean eval                  1.0390964
Z variance eval              0.023878101
total_rewards                [3292.78629966 3358.69263785 1790.49216224   26.63843261 2400.34561241
  222.68882485 1142.80523616 1155.5995912  3774.39162808  226.72467536]
total_rewards_mean           1739.1165100429407
total_rewards_std            1335.464979704403
total_rewards_max            3774.3916280819644
total_rewards_min            26.63843260981199
Number of train steps total  413000
Number of env steps total    2067000
Number of rollouts total     0
Train Time (s)               28.791951623745263
(Previous) Eval Time (s)     19.887802805751562
Sample Time (s)              17.371915604919195
Epoch Time (s)               66.05167003441602
Total Train Time (s)         28496.22135794675
Epoch                        412
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:10:28.831778 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #412 | Epoch Duration: 63.7552330493927
2020-01-11 11:10:28.832124 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #412 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0381944
Z variance train             0.023932464
KL Divergence                22.31923
KL Loss                      2.2319229
QF Loss                      909.6017
VF Loss                      1082.1539
Policy Loss                  -1303.5891
Q Predictions Mean           1304.0143
Q Predictions Std            233.70923
Q Predictions Max            1504.4498
Q Predictions Min            -48.32577
V Predictions Mean           1300.3123
V Predictions Std            219.61913
V Predictions Max            1502.1007
V Predictions Min            -36.272736
Log Pis Mean                 0.6429194
Log Pis Std                  2.809693
Log Pis Max                  15.038869
Log Pis Min                  -9.554406
Policy mu Mean               -0.045701794
Policy mu Std                0.63579047
Policy mu Max                2.1622112
Policy mu Min                -2.4745052
Policy log std Mean          -1.0553443
Policy log std Std           0.33312064
Policy log std Max           -0.25650233
Policy log std Min           -3.2399564
Z mean eval                  1.0584862
Z variance eval              0.017032374
total_rewards                [3421.92156601 3267.98377109 3405.78816308 3361.23306449 3541.53441434
 3497.44266255 3470.49894649 3535.17049085 1110.3007101  1171.53677473]
total_rewards_mean           2978.341056372929
total_rewards_std            922.1183210948433
total_rewards_max            3541.534414343292
total_rewards_min            1110.300710103818
Number of train steps total  414000
Number of env steps total    2072000
Number of rollouts total     0
Train Time (s)               31.96719653485343
(Previous) Eval Time (s)     17.591049937997013
Sample Time (s)              18.36682831728831
Epoch Time (s)               67.92507479013875
Total Train Time (s)         28573.472863965668
Epoch                        413
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:11:46.057566 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #413 | Epoch Duration: 77.2252037525177
2020-01-11 11:11:46.057758 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #413 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0624945
Z variance train             0.017030649
KL Divergence                23.023418
KL Loss                      2.302342
QF Loss                      1881.2415
VF Loss                      208.19608
Policy Loss                  -1275.7854
Q Predictions Mean           1270.5605
Q Predictions Std            251.75633
Q Predictions Max            1518.5524
Q Predictions Min            -48.758076
V Predictions Mean           1277.7657
V Predictions Std            245.44572
V Predictions Max            1516.591
V Predictions Min            15.782855
Log Pis Mean                 0.80115473
Log Pis Std                  3.0042992
Log Pis Max                  18.594864
Log Pis Min                  -7.0677156
Policy mu Mean               -0.016725501
Policy mu Std                0.6444763
Policy mu Max                3.2607813
Policy mu Min                -3.44138
Policy log std Mean          -1.0707378
Policy log std Std           0.300926
Policy log std Max           -0.19389307
Policy log std Min           -2.7119255
Z mean eval                  1.0528983
Z variance eval              0.016634751
total_rewards                [1080.05386833 3466.75282729 3432.93518456 1770.74456894 2937.62421226
 3903.91138092 2394.06470198 3290.57292818 3840.32657049 3502.77075896]
total_rewards_mean           2961.9757001923854
total_rewards_std            884.2826800262086
total_rewards_max            3903.911380924118
total_rewards_min            1080.0538683304433
Number of train steps total  415000
Number of env steps total    2077000
Number of rollouts total     0
Train Time (s)               27.712494731880724
(Previous) Eval Time (s)     26.890903221908957
Sample Time (s)              18.658813728485256
Epoch Time (s)               73.26221168227494
Total Train Time (s)         28642.126417996362
Epoch                        414
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:12:54.716304 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #414 | Epoch Duration: 68.65838527679443
2020-01-11 11:12:54.716524 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #414 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0512275
Z variance train             0.016605895
KL Divergence                23.246693
KL Loss                      2.3246694
QF Loss                      1094.2517
VF Loss                      267.24054
Policy Loss                  -1276.1503
Q Predictions Mean           1273.1102
Q Predictions Std            231.78494
Q Predictions Max            1478.9692
Q Predictions Min            58.804382
V Predictions Mean           1265.2759
V Predictions Std            231.84538
V Predictions Max            1497.7284
V Predictions Min            56.113743
Log Pis Mean                 0.54269904
Log Pis Std                  2.54152
Log Pis Max                  8.884384
Log Pis Min                  -5.536247
Policy mu Mean               -0.013485349
Policy mu Std                0.673295
Policy mu Max                2.8704038
Policy mu Min                -2.7540998
Policy log std Mean          -1.007618
Policy log std Std           0.25372413
Policy log std Max           0.06383002
Policy log std Min           -2.3427694
Z mean eval                  1.0447603
Z variance eval              0.014768308
total_rewards                [3375.12548595 3670.97897526 3349.11772617 3007.46486208 3363.46124075
 3399.51043115 3496.65740286 2617.06313941 3722.74251805 3370.94689398]
total_rewards_mean           3337.3068675661516
total_rewards_std            303.330152797277
total_rewards_max            3722.742518050768
total_rewards_min            2617.0631394077777
Number of train steps total  416000
Number of env steps total    2082000
Number of rollouts total     0
Train Time (s)               28.507669985760003
(Previous) Eval Time (s)     22.286747300066054
Sample Time (s)              18.20703994948417
Epoch Time (s)               69.00145723531023
Total Train Time (s)         28714.976770827547
Epoch                        415
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:14:07.579778 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #415 | Epoch Duration: 72.86307668685913
2020-01-11 11:14:07.579982 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #415 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.044411
Z variance train             0.0147730755
KL Divergence                22.9468
KL Loss                      2.29468
QF Loss                      537.59155
VF Loss                      66.127144
Policy Loss                  -1268.1317
Q Predictions Mean           1270.8556
Q Predictions Std            226.89786
Q Predictions Max            1455.9547
Q Predictions Min            20.804956
V Predictions Mean           1269.4767
V Predictions Std            224.50865
V Predictions Max            1446.7374
V Predictions Min            17.352774
Log Pis Mean                 0.30264542
Log Pis Std                  2.9672241
Log Pis Max                  23.314163
Log Pis Min                  -7.9298005
Policy mu Mean               0.021548009
Policy mu Std                0.60868984
Policy mu Max                4.8966103
Policy mu Min                -4.79128
Policy log std Mean          -1.0518298
Policy log std Std           0.24745356
Policy log std Max           0.29217088
Policy log std Min           -2.0422401
Z mean eval                  1.0404581
Z variance eval              0.013763194
total_rewards                [3608.16254043 1864.47392851 3756.38265251 2868.60806051  258.09769744
 3717.00081263 3511.37298102 2932.10386565 3657.91194705 2396.3962489 ]
total_rewards_mean           2857.0510734650293
total_rewards_std            1055.4492867358906
total_rewards_max            3756.382652507839
total_rewards_min            258.09769743766526
Number of train steps total  417000
Number of env steps total    2087000
Number of rollouts total     0
Train Time (s)               28.425003950018436
(Previous) Eval Time (s)     26.14800935704261
Sample Time (s)              18.129377319011837
Epoch Time (s)               72.70239062607288
Total Train Time (s)         28786.060752250254
Epoch                        416
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:15:18.657847 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #416 | Epoch Duration: 71.0777153968811
2020-01-11 11:15:18.658026 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #416 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0373724
Z variance train             0.013753462
KL Divergence                23.247782
KL Loss                      2.3247783
QF Loss                      796.5761
VF Loss                      199.7285
Policy Loss                  -1271.0345
Q Predictions Mean           1269.6835
Q Predictions Std            252.73743
Q Predictions Max            1457.2744
Q Predictions Min            -31.972158
V Predictions Mean           1267.8823
V Predictions Std            251.53452
V Predictions Max            1466.1068
V Predictions Min            -54.744713
Log Pis Mean                 0.5137918
Log Pis Std                  2.734793
Log Pis Max                  11.184172
Log Pis Min                  -7.6642494
Policy mu Mean               0.052814364
Policy mu Std                0.58829135
Policy mu Max                2.4662101
Policy mu Min                -2.2540638
Policy log std Mean          -1.0647244
Policy log std Std           0.2633021
Policy log std Max           -0.052528143
Policy log std Min           -2.1938052
Z mean eval                  1.0559231
Z variance eval              0.008804823
total_rewards                [1074.33409412 1275.14760762  112.15983472  929.89536759 2429.17657006
 3320.76841168 3916.64319679 1816.92017601 3902.90231601 4043.523477  ]
total_rewards_mean           2282.1471051604303
total_rewards_std            1368.5009828697919
total_rewards_max            4043.5234770018888
total_rewards_min            112.15983472132758
Number of train steps total  418000
Number of env steps total    2092000
Number of rollouts total     0
Train Time (s)               29.19131122995168
(Previous) Eval Time (s)     24.522983917035162
Sample Time (s)              17.940703351981938
Epoch Time (s)               71.65499849896878
Total Train Time (s)         28852.607675765175
Epoch                        417
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:16:25.212366 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #417 | Epoch Duration: 66.55419063568115
2020-01-11 11:16:25.212583 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #417 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0568593
Z variance train             0.008795155
KL Divergence                23.86961
KL Loss                      2.386961
QF Loss                      1203.623
VF Loss                      320.14624
Policy Loss                  -1266.4169
Q Predictions Mean           1269.989
Q Predictions Std            281.73563
Q Predictions Max            1512.5817
Q Predictions Min            -11.678167
V Predictions Mean           1272.3435
V Predictions Std            277.37946
V Predictions Max            1502.4398
V Predictions Min            -13.374748
Log Pis Mean                 0.3801093
Log Pis Std                  3.1318054
Log Pis Max                  14.627616
Log Pis Min                  -6.936606
Policy mu Mean               0.0133601455
Policy mu Std                0.6211473
Policy mu Max                4.1455827
Policy mu Min                -2.5561512
Policy log std Mean          -1.0707664
Policy log std Std           0.30377227
Policy log std Max           0.031576037
Policy log std Min           -2.5044832
Z mean eval                  1.0422834
Z variance eval              0.010057168
total_rewards                [1242.6559875  3530.10664349 3819.41700807 3752.43484271 3451.55849716
 3705.32179858 3850.91333683  406.27679574 3668.46986035 3228.74371392]
total_rewards_mean           3065.589848435372
total_rewards_std            1149.6028139790571
total_rewards_max            3850.913336828613
total_rewards_min            406.27679574132753
Number of train steps total  419000
Number of env steps total    2097000
Number of rollouts total     0
Train Time (s)               28.101313071791083
(Previous) Eval Time (s)     19.421887035947293
Sample Time (s)              17.886772455181926
Epoch Time (s)               65.4099725629203
Total Train Time (s)         28922.53182137618
Epoch                        418
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:17:35.138445 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #418 | Epoch Duration: 69.92568755149841
2020-01-11 11:17:35.138614 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #418 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0441236
Z variance train             0.010025866
KL Divergence                23.586369
KL Loss                      2.3586369
QF Loss                      1360.8495
VF Loss                      285.28827
Policy Loss                  -1297.6124
Q Predictions Mean           1296.5853
Q Predictions Std            212.48305
Q Predictions Max            1513.3207
Q Predictions Min            -28.833803
V Predictions Mean           1292.3503
V Predictions Std            202.41078
V Predictions Max            1496.5961
V Predictions Min            -16.308146
Log Pis Mean                 0.40778
Log Pis Std                  2.8247619
Log Pis Max                  16.328205
Log Pis Min                  -8.960055
Policy mu Mean               0.0151219
Policy mu Std                0.6384834
Policy mu Max                2.161544
Policy mu Min                -2.1640015
Policy log std Mean          -1.0363479
Policy log std Std           0.275484
Policy log std Max           -0.14900929
Policy log std Min           -3.4597132
Z mean eval                  1.0790076
Z variance eval              0.006274765
total_rewards                [3610.63695045 3762.54520359 3801.15856476 3053.49147079 3962.32325179
 2278.84838173 3174.4406598   437.5328175  3962.74942231 3727.15887377]
total_rewards_mean           3177.0885596489393
total_rewards_std            1038.4558371467033
total_rewards_max            3962.7494223100134
total_rewards_min            437.53281749683254
Number of train steps total  420000
Number of env steps total    2102000
Number of rollouts total     0
Train Time (s)               28.86885364493355
(Previous) Eval Time (s)     23.937303092330694
Sample Time (s)              18.02577371848747
Epoch Time (s)               70.83193045575172
Total Train Time (s)         28991.2155023627
Epoch                        419
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:18:43.831359 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #419 | Epoch Duration: 68.6926109790802
2020-01-11 11:18:43.831528 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #419 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0787302
Z variance train             0.006281691
KL Divergence                24.576704
KL Loss                      2.4576705
QF Loss                      803.85583
VF Loss                      230.96187
Policy Loss                  -1296.8712
Q Predictions Mean           1297.3716
Q Predictions Std            218.20111
Q Predictions Max            1518.2867
Q Predictions Min            13.915966
V Predictions Mean           1305.8068
V Predictions Std            215.67607
V Predictions Max            1516.5997
V Predictions Min            23.764755
Log Pis Mean                 0.5678083
Log Pis Std                  2.742947
Log Pis Max                  10.94832
Log Pis Min                  -7.657794
Policy mu Mean               -0.0137686115
Policy mu Std                0.6798118
Policy mu Max                2.782322
Policy mu Min                -2.4016712
Policy log std Mean          -1.0137372
Policy log std Std           0.25865555
Policy log std Max           -0.17038935
Policy log std Min           -2.0059404
Z mean eval                  1.0467976
Z variance eval              0.010301196
total_rewards                [3834.94508993 3843.53752011 3608.38167913  916.02757307   13.26327558
 3873.81428705 3357.87077256   25.43573243 3565.03547286  831.18447719]
total_rewards_mean           2386.9495879903598
total_rewards_std            1613.899864201506
total_rewards_max            3873.814287054397
total_rewards_min            13.26327557646918
Number of train steps total  421000
Number of env steps total    2107000
Number of rollouts total     0
Train Time (s)               30.639387178234756
(Previous) Eval Time (s)     21.797592056915164
Sample Time (s)              18.56189763965085
Epoch Time (s)               70.99887687480077
Total Train Time (s)         29058.00180266658
Epoch                        420
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:19:50.620408 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #420 | Epoch Duration: 66.78869795799255
2020-01-11 11:19:50.620756 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #420 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0487154
Z variance train             0.0102943685
KL Divergence                24.193995
KL Loss                      2.4193995
QF Loss                      599.2288
VF Loss                      135.95668
Policy Loss                  -1279.1598
Q Predictions Mean           1282.9412
Q Predictions Std            262.77295
Q Predictions Max            1511.4211
Q Predictions Min            15.517498
V Predictions Mean           1286.7295
V Predictions Std            262.86368
V Predictions Max            1519.387
V Predictions Min            26.72686
Log Pis Mean                 0.36191684
Log Pis Std                  2.8221946
Log Pis Max                  10.4140415
Log Pis Min                  -8.05389
Policy mu Mean               0.013288796
Policy mu Std                0.6057645
Policy mu Max                2.5039732
Policy mu Min                -2.666607
Policy log std Mean          -1.0680436
Policy log std Std           0.28250247
Policy log std Max           -0.087436914
Policy log std Min           -2.3910613
Z mean eval                  1.0614427
Z variance eval              0.008412227
total_rewards                [  30.08270665 3867.70264779 3763.43952886 3761.0576575  3866.09505183
 3804.97814782 3213.18400371 3633.69489785 3799.98239657 3889.00512013]
total_rewards_mean           3362.922215871606
total_rewards_std            1126.6618382436786
total_rewards_max            3889.005120126879
total_rewards_min            30.08270665428774
Number of train steps total  422000
Number of env steps total    2112000
Number of rollouts total     0
Train Time (s)               30.08667631307617
(Previous) Eval Time (s)     17.58707834687084
Sample Time (s)              18.432790552265942
Epoch Time (s)               66.10654521221295
Total Train Time (s)         29133.595023395028
Epoch                        421
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:21:06.214391 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #421 | Epoch Duration: 75.59338784217834
2020-01-11 11:21:06.214618 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #421 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0600941
Z variance train             0.008422314
KL Divergence                24.501621
KL Loss                      2.4501622
QF Loss                      2833.1545
VF Loss                      804.3265
Policy Loss                  -1293.7634
Q Predictions Mean           1289.6296
Q Predictions Std            256.08194
Q Predictions Max            1537.0006
Q Predictions Min            -41.786915
V Predictions Mean           1296.937
V Predictions Std            239.77109
V Predictions Max            1534.87
V Predictions Min            -31.770018
Log Pis Mean                 0.811823
Log Pis Std                  3.2507987
Log Pis Max                  18.31849
Log Pis Min                  -10.9166565
Policy mu Mean               0.014005346
Policy mu Std                0.6271881
Policy mu Max                2.7125065
Policy mu Min                -3.3566895
Policy log std Mean          -1.088593
Policy log std Std           0.29104963
Policy log std Max           -0.051550746
Policy log std Min           -2.884182
Z mean eval                  1.0700431
Z variance eval              0.007232681
total_rewards                [3571.03487746 1338.16559983 3051.24501477 3927.8051982  2571.91326609
  146.98439407 3555.13946047 2754.26815264  463.0245477     6.36246428]
total_rewards_mean           2138.5942975503376
total_rewards_std            1435.9893976536025
total_rewards_max            3927.805198201396
total_rewards_min            6.362464276989963
Number of train steps total  423000
Number of env steps total    2117000
Number of rollouts total     0
Train Time (s)               29.162534767296165
(Previous) Eval Time (s)     27.073609681334347
Sample Time (s)              17.821830628439784
Epoch Time (s)               74.0579750770703
Total Train Time (s)         29196.560908357147
Epoch                        422
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:22:09.186334 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #422 | Epoch Duration: 62.971529722213745
2020-01-11 11:22:09.186563 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #422 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0701482
Z variance train             0.007219774
KL Divergence                24.26477
KL Loss                      2.4264772
QF Loss                      4516.853
VF Loss                      1357.132
Policy Loss                  -1299.6868
Q Predictions Mean           1298.2854
Q Predictions Std            272.42944
Q Predictions Max            1542.5481
Q Predictions Min            -7.584041
V Predictions Mean           1298.2698
V Predictions Std            267.226
V Predictions Max            1536.0548
V Predictions Min            11.145004
Log Pis Mean                 0.44894636
Log Pis Std                  2.8519344
Log Pis Max                  11.840395
Log Pis Min                  -6.8406
Policy mu Mean               -0.044539772
Policy mu Std                0.6190645
Policy mu Max                2.1214764
Policy mu Min                -2.673555
Policy log std Mean          -1.0557787
Policy log std Std           0.30397925
Policy log std Max           -0.031184316
Policy log std Min           -3.2343946
Z mean eval                  1.0936134
Z variance eval              0.010656958
total_rewards                [3357.64657051 3477.62652667 3510.89530768 3551.83360301 3368.50812858
 3562.46225477 3525.46852664   69.33533147 3658.76858077 3727.95973316]
total_rewards_mean           3181.0504563267073
total_rewards_std            1042.8209745048487
total_rewards_max            3727.9597331623368
total_rewards_min            69.33533147184056
Number of train steps total  424000
Number of env steps total    2122000
Number of rollouts total     0
Train Time (s)               30.381432875059545
(Previous) Eval Time (s)     15.986870479304343
Sample Time (s)              17.42694468703121
Epoch Time (s)               63.7952480413951
Total Train Time (s)         29268.38717988832
Epoch                        423
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:23:21.019076 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #423 | Epoch Duration: 71.83230543136597
2020-01-11 11:23:21.019371 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #423 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0933454
Z variance train             0.010650964
KL Divergence                24.005964
KL Loss                      2.4005964
QF Loss                      881.5773
VF Loss                      115.029045
Policy Loss                  -1323.984
Q Predictions Mean           1323.7458
Q Predictions Std            221.27855
Q Predictions Max            1535.2625
Q Predictions Min            -32.665886
V Predictions Mean           1321.1864
V Predictions Std            222.14168
V Predictions Max            1533.1941
V Predictions Min            -31.890968
Log Pis Mean                 0.7299856
Log Pis Std                  2.9224772
Log Pis Max                  11.497317
Log Pis Min                  -7.4142885
Policy mu Mean               -0.0014221959
Policy mu Std                0.6205678
Policy mu Max                2.6850812
Policy mu Min                -2.4318588
Policy log std Mean          -1.0861251
Policy log std Std           0.295327
Policy log std Max           -0.19644511
Policy log std Min           -2.8840315
Z mean eval                  1.030404
Z variance eval              0.0083595235
total_rewards                [3623.78405168 3558.25245328 3504.97085265 3309.29292883 2106.32619856
 3363.38562783  623.86353806 1464.38711123 1123.20527962 3593.24145432]
total_rewards_mean           2627.070949607271
total_rewards_std            1116.6815351594416
total_rewards_max            3623.7840516822826
total_rewards_min            623.8635380631254
Number of train steps total  425000
Number of env steps total    2127000
Number of rollouts total     0
Train Time (s)               29.278022427111864
(Previous) Eval Time (s)     24.023643969092518
Sample Time (s)              17.70877118036151
Epoch Time (s)               71.01043757656589
Total Train Time (s)         29336.68654482579
Epoch                        424
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:24:29.324649 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #424 | Epoch Duration: 68.30504179000854
2020-01-11 11:24:29.324896 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #424 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.030564
Z variance train             0.008348809
KL Divergence                24.37411
KL Loss                      2.437411
QF Loss                      948.4378
VF Loss                      1358.3618
Policy Loss                  -1299.868
Q Predictions Mean           1295.2559
Q Predictions Std            256.54825
Q Predictions Max            1502.7789
Q Predictions Min            -64.444244
V Predictions Mean           1298.7388
V Predictions Std            254.36911
V Predictions Max            1512.0537
V Predictions Min            -59.19246
Log Pis Mean                 0.529914
Log Pis Std                  2.7848387
Log Pis Max                  8.98697
Log Pis Min                  -6.1457334
Policy mu Mean               0.020760205
Policy mu Std                0.62546444
Policy mu Max                2.2023919
Policy mu Min                -2.1214745
Policy log std Mean          -1.0576774
Policy log std Std           0.26224276
Policy log std Max           -0.29039556
Policy log std Min           -2.8171067
Z mean eval                  1.0316029
Z variance eval              0.012443478
total_rewards                [3555.31603101 3785.3514776  3835.67009291 3483.02795461 1578.09111907
 3617.9380968  3684.03150358 3620.03708035 3501.24832983 3362.04646968]
total_rewards_mean           3402.275815543714
total_rewards_std            622.6475728273845
total_rewards_max            3835.670092909439
total_rewards_min            1578.091119069835
Number of train steps total  426000
Number of env steps total    2132000
Number of rollouts total     0
Train Time (s)               29.61568156303838
(Previous) Eval Time (s)     21.317927749827504
Sample Time (s)              17.928072622045875
Epoch Time (s)               68.86168193491176
Total Train Time (s)         29409.62780708447
Epoch                        425
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:25:42.268035 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #425 | Epoch Duration: 72.94296479225159
2020-01-11 11:25:42.268233 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #425 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0333822
Z variance train             0.012473051
KL Divergence                23.874897
KL Loss                      2.3874898
QF Loss                      668.4201
VF Loss                      161.95842
Policy Loss                  -1295.8524
Q Predictions Mean           1296.6072
Q Predictions Std            239.31898
Q Predictions Max            1561.5859
Q Predictions Min            -4.207455
V Predictions Mean           1293.3171
V Predictions Std            240.62675
V Predictions Max            1536.6061
V Predictions Min            -27.225903
Log Pis Mean                 0.31638682
Log Pis Std                  2.8238504
Log Pis Max                  12.689434
Log Pis Min                  -6.9007034
Policy mu Mean               0.030393291
Policy mu Std                0.61609626
Policy mu Max                2.2526112
Policy mu Min                -2.528969
Policy log std Mean          -1.0588437
Policy log std Std           0.2584722
Policy log std Max           -0.15452462
Policy log std Min           -2.1969867
Z mean eval                  1.087022
Z variance eval              0.00976536
total_rewards                [3699.8865941  3488.65516037  553.22319055  420.00302893 3613.42593361
 3636.9002827  3507.11315597 3813.70614334 3744.56655953 3481.67283331]
total_rewards_mean           2995.915288241728
total_rewards_std            1259.33165823615
total_rewards_max            3813.706143335109
total_rewards_min            420.0030289339293
Number of train steps total  427000
Number of env steps total    2137000
Number of rollouts total     0
Train Time (s)               30.713317258283496
(Previous) Eval Time (s)     25.39892021473497
Sample Time (s)              17.63853061525151
Epoch Time (s)               73.75076808826998
Total Train Time (s)         29481.664352966473
Epoch                        426
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:26:54.308589 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #426 | Epoch Duration: 72.04021334648132
2020-01-11 11:26:54.308789 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #426 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.086029
Z variance train             0.009766084
KL Divergence                24.277376
KL Loss                      2.4277377
QF Loss                      1089.5758
VF Loss                      154.65202
Policy Loss                  -1312.4042
Q Predictions Mean           1313.7422
Q Predictions Std            236.96298
Q Predictions Max            1524.4938
Q Predictions Min            -48.447662
V Predictions Mean           1316.4397
V Predictions Std            237.14862
V Predictions Max            1525.4728
V Predictions Min            -26.594673
Log Pis Mean                 0.57200825
Log Pis Std                  2.7316806
Log Pis Max                  8.702864
Log Pis Min                  -7.468652
Policy mu Mean               -0.009125156
Policy mu Std                0.62709695
Policy mu Max                2.5770774
Policy mu Min                -2.3581893
Policy log std Mean          -1.0441107
Policy log std Std           0.28707102
Policy log std Max           0.4381103
Policy log std Min           -2.4495683
Z mean eval                  1.06702
Z variance eval              0.01210654
total_rewards                [3554.34331044 1319.35800406 1608.7678071  3417.0999175  3512.83687802
 3881.75356567 4009.93310385 3674.50108969 3863.65585744 2598.42589445]
total_rewards_mean           3144.067542820957
total_rewards_std            919.5852120257148
total_rewards_max            4009.9331038472155
total_rewards_min            1319.3580040558563
Number of train steps total  428000
Number of env steps total    2142000
Number of rollouts total     0
Train Time (s)               29.990325233899057
(Previous) Eval Time (s)     23.68805923918262
Sample Time (s)              18.1999242301099
Epoch Time (s)               71.87830870319158
Total Train Time (s)         29552.585163829848
Epoch                        427
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:28:05.233128 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #427 | Epoch Duration: 70.92417001724243
2020-01-11 11:28:05.233310 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #427 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0702375
Z variance train             0.012071235
KL Divergence                24.357872
KL Loss                      2.4357872
QF Loss                      956.2626
VF Loss                      257.12744
Policy Loss                  -1310.7561
Q Predictions Mean           1312.7086
Q Predictions Std            244.71252
Q Predictions Max            1550.7836
Q Predictions Min            -20.632843
V Predictions Mean           1319.523
V Predictions Std            251.65514
V Predictions Max            1546.5586
V Predictions Min            -49.83162
Log Pis Mean                 0.46296167
Log Pis Std                  2.5202725
Log Pis Max                  9.5314
Log Pis Min                  -5.9350615
Policy mu Mean               -0.0053336266
Policy mu Std                0.6247478
Policy mu Max                2.2730105
Policy mu Min                -2.220027
Policy log std Mean          -1.040374
Policy log std Std           0.26929978
Policy log std Max           -0.16134405
Policy log std Min           -2.0250425
Z mean eval                  1.0577545
Z variance eval              0.009383815
total_rewards                [3589.18899695 3811.88665243  171.43107477 3702.32414475   28.42877915
 1588.84246348 1723.2853905  3626.41520963 3977.92933934 3833.16363825]
total_rewards_mean           2605.289568924842
total_rewards_std            1497.8954068589821
total_rewards_max            3977.9293393446633
total_rewards_min            28.428779149490257
Number of train steps total  429000
Number of env steps total    2147000
Number of rollouts total     0
Train Time (s)               31.11813125014305
(Previous) Eval Time (s)     22.733583624009043
Sample Time (s)              17.622312035411596
Epoch Time (s)               71.47402690956369
Total Train Time (s)         29621.442919312976
Epoch                        428
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:29:14.099688 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #428 | Epoch Duration: 68.86620593070984
2020-01-11 11:29:14.099986 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #428 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0581205
Z variance train             0.0094721755
KL Divergence                25.369335
KL Loss                      2.5369337
QF Loss                      1523.785
VF Loss                      621.7776
Policy Loss                  -1325.9587
Q Predictions Mean           1328.6942
Q Predictions Std            212.58548
Q Predictions Max            1571.7921
Q Predictions Min            67.067894
V Predictions Mean           1335.8997
V Predictions Std            206.72012
V Predictions Max            1581.6462
V Predictions Min            65.43292
Log Pis Mean                 0.2412125
Log Pis Std                  2.8074589
Log Pis Max                  12.823129
Log Pis Min                  -10.479114
Policy mu Mean               -0.014928247
Policy mu Std                0.57944053
Policy mu Max                2.0247862
Policy mu Min                -3.0129015
Policy log std Mean          -1.0539556
Policy log std Std           0.27160156
Policy log std Max           -0.13073903
Policy log std Min           -2.948822
Z mean eval                  1.0694709
Z variance eval              0.011644522
total_rewards                [3691.46586116  520.31616706 3587.91810629  855.32487817 3621.1936898
  326.33264253 3339.78480908 3399.27995769 3630.62233869 3351.16207278]
total_rewards_mean           2632.3400523245314
total_rewards_std            1362.0115245586194
total_rewards_max            3691.4658611615123
total_rewards_min            326.33264253258534
Number of train steps total  430000
Number of env steps total    2152000
Number of rollouts total     0
Train Time (s)               31.30647953879088
(Previous) Eval Time (s)     20.125471976120025
Sample Time (s)              17.84033152181655
Epoch Time (s)               69.27228303672746
Total Train Time (s)         29693.484568559565
Epoch                        429
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:30:26.143226 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #429 | Epoch Duration: 72.04306244850159
2020-01-11 11:30:26.143435 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #429 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0691421
Z variance train             0.01163623
KL Divergence                24.97993
KL Loss                      2.4979932
QF Loss                      1184.7954
VF Loss                      326.23325
Policy Loss                  -1287.7218
Q Predictions Mean           1287.5117
Q Predictions Std            275.87088
Q Predictions Max            1529.0557
Q Predictions Min            -26.56804
V Predictions Mean           1274.6581
V Predictions Std            271.85678
V Predictions Max            1511.422
V Predictions Min            -42.194317
Log Pis Mean                 0.6155426
Log Pis Std                  2.7563586
Log Pis Max                  8.639948
Log Pis Min                  -6.1575174
Policy mu Mean               -0.008756502
Policy mu Std                0.6089073
Policy mu Max                2.2555747
Policy mu Min                -2.3450468
Policy log std Mean          -1.068762
Policy log std Std           0.2963861
Policy log std Max           -0.08631301
Policy log std Min           -2.8726134
Z mean eval                  1.0736632
Z variance eval              0.010116921
total_rewards                [2638.20996617 2917.56181015  301.77848173  177.58133854  508.01061848
 1479.3320351  2479.88054509   20.07697835 3597.71816664  190.35209318]
total_rewards_mean           1431.0502033441594
total_rewards_std            1291.9905521360656
total_rewards_max            3597.718166643505
total_rewards_min            20.076978348491597
Number of train steps total  431000
Number of env steps total    2157000
Number of rollouts total     0
Train Time (s)               27.77892647124827
(Previous) Eval Time (s)     22.895962121896446
Sample Time (s)              18.378744402434677
Epoch Time (s)               69.05363299557939
Total Train Time (s)         29752.41693174839
Epoch                        430
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:31:25.078842 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #430 | Epoch Duration: 58.93524956703186
2020-01-11 11:31:25.079025 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #430 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0746133
Z variance train             0.010070978
KL Divergence                25.677841
KL Loss                      2.567784
QF Loss                      581.3268
VF Loss                      395.69183
Policy Loss                  -1314.7102
Q Predictions Mean           1314.6416
Q Predictions Std            250.708
Q Predictions Max            1554.9888
Q Predictions Min            -44.073742
V Predictions Mean           1331.2332
V Predictions Std            252.6921
V Predictions Max            1566.3883
V Predictions Min            -42.77895
Log Pis Mean                 0.46532172
Log Pis Std                  2.8109295
Log Pis Max                  9.052944
Log Pis Min                  -12.011862
Policy mu Mean               -0.0003613776
Policy mu Std                0.61906874
Policy mu Max                2.7740865
Policy mu Min                -2.556682
Policy log std Mean          -1.067328
Policy log std Std           0.28771985
Policy log std Max           -0.05349028
Policy log std Min           -2.2713957
Z mean eval                  1.0709836
Z variance eval              0.008510722
total_rewards                [3721.82778994 1788.34357681 4084.64326938 2522.94705181  948.67498229
 1588.25575552  297.26864962  570.58818545  212.13687615 1251.02322191]
total_rewards_mean           1698.570935887247
total_rewards_std            1292.0857680099507
total_rewards_max            4084.6432693763804
total_rewards_min            212.1368761451839
Number of train steps total  432000
Number of env steps total    2162000
Number of rollouts total     0
Train Time (s)               29.465267692692578
(Previous) Eval Time (s)     12.77725771209225
Sample Time (s)              17.78388315392658
Epoch Time (s)               60.02640855871141
Total Train Time (s)         29813.83090714831
Epoch                        431
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:32:26.497637 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #431 | Epoch Duration: 61.41847085952759
2020-01-11 11:32:26.497849 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #431 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0710193
Z variance train             0.008541191
KL Divergence                25.772614
KL Loss                      2.5772614
QF Loss                      3767.8843
VF Loss                      264.56506
Policy Loss                  -1312.0533
Q Predictions Mean           1308.771
Q Predictions Std            272.24307
Q Predictions Max            1537.0663
Q Predictions Min            -31.741724
V Predictions Mean           1314.3372
V Predictions Std            264.7517
V Predictions Max            1538.0094
V Predictions Min            -34.130417
Log Pis Mean                 0.6992408
Log Pis Std                  3.262123
Log Pis Max                  18.983334
Log Pis Min                  -8.420227
Policy mu Mean               -0.03261416
Policy mu Std                0.6583898
Policy mu Max                4.0998297
Policy mu Min                -4.3407254
Policy log std Mean          -1.0541805
Policy log std Std           0.29389986
Policy log std Max           0.28358865
Policy log std Min           -2.6189222
Z mean eval                  1.0503325
Z variance eval              0.0076401224
total_rewards                [2258.26216021 4138.23339125 3885.521874   3262.20711841 4010.05010413
 3856.98620817 3552.31784091 3748.02470301 3774.73237772 3897.3564784 ]
total_rewards_mean           3638.3692256192953
total_rewards_std            514.6047599835686
total_rewards_max            4138.233391250433
total_rewards_min            2258.262160208185
Number of train steps total  433000
Number of env steps total    2167000
Number of rollouts total     0
Train Time (s)               27.72600162308663
(Previous) Eval Time (s)     14.168975558597594
Sample Time (s)              17.179934763815254
Epoch Time (s)               59.07491194549948
Total Train Time (s)         29887.10801331699
Epoch                        432
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:33:39.777648 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #432 | Epoch Duration: 73.27961158752441
2020-01-11 11:33:39.777840 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #432 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0495851
Z variance train             0.007630737
KL Divergence                26.783604
KL Loss                      2.6783605
QF Loss                      1483.7668
VF Loss                      235.68245
Policy Loss                  -1331.3495
Q Predictions Mean           1337.4932
Q Predictions Std            217.41895
Q Predictions Max            1566.8334
Q Predictions Min            -27.738495
V Predictions Mean           1328.8726
V Predictions Std            213.37119
V Predictions Max            1549.7449
V Predictions Min            -33.080914
Log Pis Mean                 0.35739917
Log Pis Std                  2.8208156
Log Pis Max                  9.975852
Log Pis Min                  -9.358074
Policy mu Mean               -0.032635927
Policy mu Std                0.6020931
Policy mu Max                2.9940395
Policy mu Min                -2.8400574
Policy log std Mean          -1.0863564
Policy log std Std           0.25536644
Policy log std Max           -0.032941163
Policy log std Min           -2.311278
Z mean eval                  1.0571568
Z variance eval              0.008998729
total_rewards                [3876.57010589  593.38236338 3669.64969315 3711.7884496  2055.4796935
 3624.74022999  111.23467763  723.56237203 2002.15154264 3904.88441135]
total_rewards_mean           2427.3443539168416
total_rewards_std            1444.2985109010554
total_rewards_max            3904.8844113494906
total_rewards_min            111.23467762959947
Number of train steps total  434000
Number of env steps total    2172000
Number of rollouts total     0
Train Time (s)               31.26923719001934
(Previous) Eval Time (s)     28.373378434218466
Sample Time (s)              18.973213008604944
Epoch Time (s)               78.61582863284275
Total Train Time (s)         29956.99852428306
Epoch                        433
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:34:49.672823 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #433 | Epoch Duration: 69.89482855796814
2020-01-11 11:34:49.673028 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #433 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0587628
Z variance train             0.009074429
KL Divergence                25.633358
KL Loss                      2.563336
QF Loss                      742.8892
VF Loss                      227.70045
Policy Loss                  -1327.761
Q Predictions Mean           1327.5447
Q Predictions Std            238.38712
Q Predictions Max            1543.9049
Q Predictions Min            -60.57432
V Predictions Mean           1323.261
V Predictions Std            237.72746
V Predictions Max            1546.6663
V Predictions Min            -49.830353
Log Pis Mean                 0.54368436
Log Pis Std                  3.0007687
Log Pis Max                  12.307491
Log Pis Min                  -11.23862
Policy mu Mean               0.017987909
Policy mu Std                0.63978016
Policy mu Max                2.1933758
Policy mu Min                -2.3852644
Policy log std Mean          -1.0374842
Policy log std Std           0.27688763
Policy log std Max           -0.099843204
Policy log std Min           -2.5292559
Z mean eval                  1.098253
Z variance eval              0.013045509
total_rewards                [3710.04139936 3740.47370561 3489.76143454 3167.93591847 3913.29047897
 3657.79702683 3579.93720894 3431.42226895  218.66773286 3610.7616336 ]
total_rewards_mean           3252.008880814118
total_rewards_std            1028.7629364501781
total_rewards_max            3913.2904789682
total_rewards_min            218.66773286320392
Number of train steps total  435000
Number of env steps total    2177000
Number of rollouts total     0
Train Time (s)               28.093750606290996
(Previous) Eval Time (s)     19.652031775098294
Sample Time (s)              18.227117963600904
Epoch Time (s)               65.9729003449902
Total Train Time (s)         30029.41681254795
Epoch                        434
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:36:02.096181 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #434 | Epoch Duration: 72.42298245429993
2020-01-11 11:36:02.096400 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #434 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1003354
Z variance train             0.013037709
KL Divergence                24.731398
KL Loss                      2.4731398
QF Loss                      7505.991
VF Loss                      122.94977
Policy Loss                  -1322.4244
Q Predictions Mean           1320.425
Q Predictions Std            255.46597
Q Predictions Max            1579.414
Q Predictions Min            -18.729607
V Predictions Mean           1328.1947
V Predictions Std            255.0157
V Predictions Max            1591.3323
V Predictions Min            -11.269333
Log Pis Mean                 0.5527642
Log Pis Std                  2.7136078
Log Pis Max                  10.0971365
Log Pis Min                  -6.5874367
Policy mu Mean               0.007349462
Policy mu Std                0.6231501
Policy mu Max                2.4218752
Policy mu Min                -2.8739705
Policy log std Mean          -1.0653812
Policy log std Std           0.2618531
Policy log std Max           -0.17184913
Policy log std Min           -2.3339376
Z mean eval                  1.0490278
Z variance eval              0.015008169
total_rewards                [3299.46378248 3289.34995665   68.45169826 3509.49488856 3412.79667149
 3820.58791013 3297.0858213  3264.26284054  465.00981444 3719.13662598]
total_rewards_mean           2814.5640009840617
total_rewards_std            1289.5072902494915
total_rewards_max            3820.5879101313844
total_rewards_min            68.4516982638421
Number of train steps total  436000
Number of env steps total    2182000
Number of rollouts total     0
Train Time (s)               29.439416707027704
(Previous) Eval Time (s)     26.101815572939813
Sample Time (s)              18.040454090572894
Epoch Time (s)               73.58168637054041
Total Train Time (s)         30101.528963815887
Epoch                        435
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:37:14.217626 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #435 | Epoch Duration: 72.12100458145142
2020-01-11 11:37:14.217912 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #435 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0495939
Z variance train             0.015034998
KL Divergence                24.063845
KL Loss                      2.4063845
QF Loss                      1599.9375
VF Loss                      152.42168
Policy Loss                  -1331.6836
Q Predictions Mean           1333.4998
Q Predictions Std            219.21367
Q Predictions Max            1549.1688
Q Predictions Min            -3.4233398
V Predictions Mean           1330.2997
V Predictions Std            220.82892
V Predictions Max            1541.9421
V Predictions Min            -19.116905
Log Pis Mean                 0.45273244
Log Pis Std                  2.894439
Log Pis Max                  14.48131
Log Pis Min                  -7.7920403
Policy mu Mean               -0.05802469
Policy mu Std                0.6225029
Policy mu Max                2.1979575
Policy mu Min                -2.6082675
Policy log std Mean          -1.0629292
Policy log std Std           0.27874964
Policy log std Max           -0.16762036
Policy log std Min           -2.7627938
Z mean eval                  1.0580713
Z variance eval              0.015056695
total_rewards                [-2.84958433e+02  1.47465241e+03  4.13554124e+03  2.42568530e+02
 -3.32100701e+02  4.07325159e+03  3.66957814e+03  5.00768985e+02
  4.43364311e+03  4.34343267e+00]
total_rewards_mean           1791.7288302238544
total_rewards_std            1933.6461067387568
total_rewards_max            4433.643111475591
total_rewards_min            -332.1007010034532
Number of train steps total  437000
Number of env steps total    2187000
Number of rollouts total     0
Train Time (s)               29.866602295078337
(Previous) Eval Time (s)     24.640759146306664
Sample Time (s)              18.09798266319558
Epoch Time (s)               72.60534410458058
Total Train Time (s)         30166.98032857012
Epoch                        436
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:38:19.670317 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #436 | Epoch Duration: 65.45219349861145
2020-01-11 11:38:19.670492 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #436 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0585878
Z variance train             0.015086522
KL Divergence                23.233131
KL Loss                      2.3233132
QF Loss                      1213.8032
VF Loss                      390.9227
Policy Loss                  -1321.2837
Q Predictions Mean           1320.9182
Q Predictions Std            228.09966
Q Predictions Max            1523.9208
Q Predictions Min            43.009647
V Predictions Mean           1318.6952
V Predictions Std            229.51971
V Predictions Max            1518.8794
V Predictions Min            55.276695
Log Pis Mean                 0.811272
Log Pis Std                  2.7251945
Log Pis Max                  11.970748
Log Pis Min                  -6.9708376
Policy mu Mean               0.013172978
Policy mu Std                0.6086841
Policy mu Max                2.411912
Policy mu Min                -3.8096836
Policy log std Mean          -1.091534
Policy log std Std           0.29090768
Policy log std Max           0.24671412
Policy log std Min           -3.0419564
Z mean eval                  1.0878621
Z variance eval              0.012560177
total_rewards                [3109.24670455 4062.73871289 3532.14389093 2482.42927541 3269.61770689
 3383.10990841 3705.7745283  3359.71479226  791.09627756 3419.16732739]
total_rewards_mean           3111.503912460121
total_rewards_std            864.2921956566514
total_rewards_max            4062.7387128940877
total_rewards_min            791.0962775610247
Number of train steps total  438000
Number of env steps total    2192000
Number of rollouts total     0
Train Time (s)               28.32713548792526
(Previous) Eval Time (s)     17.487311420030892
Sample Time (s)              17.834964760113508
Epoch Time (s)               63.64941166806966
Total Train Time (s)         30237.084345593117
Epoch                        437
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:39:29.779310 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #437 | Epoch Duration: 70.10866165161133
2020-01-11 11:39:29.779518 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #437 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0879385
Z variance train             0.012574126
KL Divergence                24.259804
KL Loss                      2.4259803
QF Loss                      6691.507
VF Loss                      376.23077
Policy Loss                  -1349.1205
Q Predictions Mean           1354.8354
Q Predictions Std            242.24693
Q Predictions Max            1567.843
Q Predictions Min            66.967735
V Predictions Mean           1349.1462
V Predictions Std            237.21933
V Predictions Max            1560.0944
V Predictions Min            78.515076
Log Pis Mean                 0.7081783
Log Pis Std                  2.8459682
Log Pis Max                  11.662335
Log Pis Min                  -5.553728
Policy mu Mean               0.023569247
Policy mu Std                0.6096608
Policy mu Max                2.4995594
Policy mu Min                -2.1792967
Policy log std Mean          -1.0741796
Policy log std Std           0.30671254
Policy log std Max           -0.081835866
Policy log std Min           -3.089797
Z mean eval                  1.1049716
Z variance eval              0.014416302
total_rewards                [2487.79214327 3734.33348737 2193.2381709  3947.33293195 3778.72929666
  559.7361604  2008.23015721  109.98440422  856.8308449  1324.38386887]
total_rewards_mean           2100.0591465750736
total_rewards_std            1324.7241007440775
total_rewards_max            3947.33293195117
total_rewards_min            109.98440422089556
Number of train steps total  439000
Number of env steps total    2197000
Number of rollouts total     0
Train Time (s)               30.07841057702899
(Previous) Eval Time (s)     23.94627104094252
Sample Time (s)              18.40123756788671
Epoch Time (s)               72.42591918585822
Total Train Time (s)         30305.982162879314
Epoch                        438
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:40:38.684494 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #438 | Epoch Duration: 68.90478491783142
2020-01-11 11:40:38.684784 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #438 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1065642
Z variance train             0.014422134
KL Divergence                23.324467
KL Loss                      2.3324468
QF Loss                      845.35803
VF Loss                      199.05063
Policy Loss                  -1340.637
Q Predictions Mean           1337.6715
Q Predictions Std            229.35417
Q Predictions Max            1559.7865
Q Predictions Min            55.178425
V Predictions Mean           1331.4893
V Predictions Std            224.01299
V Predictions Max            1553.0758
V Predictions Min            51.87338
Log Pis Mean                 0.6696466
Log Pis Std                  2.7205245
Log Pis Max                  9.231951
Log Pis Min                  -7.246661
Policy mu Mean               0.022728488
Policy mu Std                0.6372393
Policy mu Max                2.4898102
Policy mu Min                -2.867058
Policy log std Mean          -1.0772028
Policy log std Std           0.27241406
Policy log std Max           -0.22930515
Policy log std Min           -3.0347648
Z mean eval                  1.0811508
Z variance eval              0.011911904
total_rewards                [3364.84798733 3603.79422617 3351.46886607 3180.40170138 3018.85190621
 2885.94193361 3420.0305249  3566.74620668 3147.15221102 3062.20106551]
total_rewards_mean           3260.1436628889023
total_rewards_std            226.6106116107278
total_rewards_max            3603.794226171798
total_rewards_min            2885.9419336144456
Number of train steps total  440000
Number of env steps total    2202000
Number of rollouts total     0
Train Time (s)               29.48206761199981
(Previous) Eval Time (s)     20.424841993954033
Sample Time (s)              17.480748950969428
Epoch Time (s)               67.38765855692327
Total Train Time (s)         30380.067578955088
Epoch                        439
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:41:52.776067 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #439 | Epoch Duration: 74.09103751182556
2020-01-11 11:41:52.776332 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #439 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0813714
Z variance train             0.011945286
KL Divergence                23.490211
KL Loss                      2.3490212
QF Loss                      1278.2991
VF Loss                      362.53363
Policy Loss                  -1366.8444
Q Predictions Mean           1368.7031
Q Predictions Std            214.98448
Q Predictions Max            1574.8436
Q Predictions Min            -13.78725
V Predictions Mean           1355.5813
V Predictions Std            215.83047
V Predictions Max            1576.5492
V Predictions Min            -38.3026
Log Pis Mean                 0.4367814
Log Pis Std                  2.6346278
Log Pis Max                  8.964181
Log Pis Min                  -7.408823
Policy mu Mean               0.07344269
Policy mu Std                0.59854454
Policy mu Max                2.1404397
Policy mu Min                -2.40949
Policy log std Mean          -1.0937961
Policy log std Std           0.25733906
Policy log std Max           -0.19713545
Policy log std Min           -2.2679303
Z mean eval                  1.0533487
Z variance eval              0.009072176
total_rewards                [4049.14367569 3651.94444551 4044.03190104 4105.7920959   227.14272394
 3913.40854637 4062.59483422 3900.32756179 4178.88500312 3880.30587813]
total_rewards_mean           3601.357666570876
total_rewards_std            1133.5634427068378
total_rewards_max            4178.885003119315
total_rewards_min            227.14272394362152
Number of train steps total  441000
Number of env steps total    2207000
Number of rollouts total     0
Train Time (s)               29.97774903802201
(Previous) Eval Time (s)     27.127947306726128
Sample Time (s)              17.851188539061695
Epoch Time (s)               74.95688488380983
Total Train Time (s)         30452.386190173216
Epoch                        440
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:43:05.101330 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #440 | Epoch Duration: 72.32478713989258
2020-01-11 11:43:05.101581 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #440 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0539954
Z variance train             0.009065164
KL Divergence                23.376099
KL Loss                      2.33761
QF Loss                      937.2561
VF Loss                      230.22185
Policy Loss                  -1354.6337
Q Predictions Mean           1353.7704
Q Predictions Std            228.67993
Q Predictions Max            1569.6654
Q Predictions Min            22.731276
V Predictions Mean           1343.4279
V Predictions Std            227.56812
V Predictions Max            1562.6841
V Predictions Min            14.156682
Log Pis Mean                 0.613675
Log Pis Std                  2.685998
Log Pis Max                  8.790777
Log Pis Min                  -8.97053
Policy mu Mean               -0.013053318
Policy mu Std                0.6454385
Policy mu Max                2.5259163
Policy mu Min                -2.6347163
Policy log std Mean          -1.0646542
Policy log std Std           0.26307985
Policy log std Max           -0.26413757
Policy log std Min           -2.0739317
Z mean eval                  1.092067
Z variance eval              0.009120641
total_rewards                [ 294.53484113 1716.3677149   848.15663309 1629.39954017 1452.23381837
 2266.05888307 1044.35478468 1154.25596379  461.25394804  350.8903702 ]
total_rewards_mean           1121.7506497440222
total_rewards_std            618.59560025962
total_rewards_max            2266.058883066388
total_rewards_min            294.5348411285508
Number of train steps total  442000
Number of env steps total    2212000
Number of rollouts total     0
Train Time (s)               27.361390699632466
(Previous) Eval Time (s)     24.495536717120558
Sample Time (s)              17.863890434149653
Epoch Time (s)               69.72081785090268
Total Train Time (s)         30512.002051467076
Epoch                        441
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:44:04.720660 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #441 | Epoch Duration: 59.61888384819031
2020-01-11 11:44:04.720852 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #441 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0931377
Z variance train             0.009115665
KL Divergence                24.18061
KL Loss                      2.418061
QF Loss                      1901.4628
VF Loss                      401.1145
Policy Loss                  -1373.926
Q Predictions Mean           1376.2375
Q Predictions Std            185.96928
Q Predictions Max            1597.5751
Q Predictions Min            -9.805397
V Predictions Mean           1383.6653
V Predictions Std            185.05104
V Predictions Max            1594.0809
V Predictions Min            -9.521034
Log Pis Mean                 0.9296463
Log Pis Std                  2.871258
Log Pis Max                  13.679313
Log Pis Min                  -5.1571903
Policy mu Mean               -0.028959025
Policy mu Std                0.6551293
Policy mu Max                3.1360855
Policy mu Min                -2.4333398
Policy log std Mean          -1.0765926
Policy log std Std           0.28407642
Policy log std Max           -0.21938413
Policy log std Min           -2.614553
Z mean eval                  1.048715
Z variance eval              0.012206019
total_rewards                [3877.61069236 3756.55153857 1665.37784267 3711.43669664 2657.90956793
 3800.39798501  258.50714577  187.63135805 1296.90713952 3885.3239946 ]
total_rewards_mean           2509.765396110872
total_rewards_std            1452.3710503353136
total_rewards_max            3885.3239945954524
total_rewards_min            187.6313580501273
Number of train steps total  443000
Number of env steps total    2217000
Number of rollouts total     0
Train Time (s)               30.547622358892113
(Previous) Eval Time (s)     14.39331097714603
Sample Time (s)              17.715539888478816
Epoch Time (s)               62.65647322451696
Total Train Time (s)         30579.67299662251
Epoch                        442
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:45:12.400118 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #442 | Epoch Duration: 67.6790714263916
2020-01-11 11:45:12.400440 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #442 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0493839
Z variance train             0.012230244
KL Divergence                22.509315
KL Loss                      2.2509315
QF Loss                      2775.6
VF Loss                      136.40167
Policy Loss                  -1370.4296
Q Predictions Mean           1370.356
Q Predictions Std            197.59856
Q Predictions Max            1601.2827
Q Predictions Min            -45.049232
V Predictions Mean           1367.0828
V Predictions Std            194.89973
V Predictions Max            1580.6647
V Predictions Min            -6.869009
Log Pis Mean                 0.7792388
Log Pis Std                  2.797814
Log Pis Max                  10.351512
Log Pis Min                  -5.9367876
Policy mu Mean               -0.015469344
Policy mu Std                0.63583463
Policy mu Max                2.7173162
Policy mu Min                -2.5866091
Policy log std Mean          -1.0693376
Policy log std Std           0.25174338
Policy log std Max           -0.24277246
Policy log std Min           -2.4439154
Z mean eval                  1.0650156
Z variance eval              0.010422664
total_rewards                [3571.52696249 3453.08138592 1466.43185544 3946.50693019 3613.71461345
 2752.52098017  866.53999135 3868.65807107   77.97413199 2307.00527224]
total_rewards_mean           2592.396019430216
total_rewards_std            1299.261682467285
total_rewards_max            3946.50693018594
total_rewards_min            77.974131986174
Number of train steps total  444000
Number of env steps total    2222000
Number of rollouts total     0
Train Time (s)               29.389230945147574
(Previous) Eval Time (s)     19.415568508207798
Sample Time (s)              18.378259778022766
Epoch Time (s)               67.18305923137814
Total Train Time (s)         30646.314450425096
Epoch                        443
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:46:19.044148 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #443 | Epoch Duration: 66.6434690952301
2020-01-11 11:46:19.044345 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #443 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0629449
Z variance train             0.010453919
KL Divergence                23.05419
KL Loss                      2.305419
QF Loss                      1143.2238
VF Loss                      568.18896
Policy Loss                  -1338.8114
Q Predictions Mean           1342.6318
Q Predictions Std            261.77756
Q Predictions Max            1588.0275
Q Predictions Min            -67.394005
V Predictions Mean           1357.7228
V Predictions Std            262.71426
V Predictions Max            1609.5344
V Predictions Min            -49.28499
Log Pis Mean                 0.5038228
Log Pis Std                  2.9030097
Log Pis Max                  12.562794
Log Pis Min                  -9.994015
Policy mu Mean               -0.017141804
Policy mu Std                0.6412618
Policy mu Max                2.8528788
Policy mu Min                -2.477166
Policy log std Mean          -1.0641346
Policy log std Std           0.2810739
Policy log std Max           -0.078052044
Policy log std Min           -2.19732
Z mean eval                  1.1064638
Z variance eval              0.012377968
total_rewards                [ 234.67052742  604.3613764  1117.04641565 2441.85455589 3487.21186907
 1123.97903821 1720.39413468 2177.41005006 1600.7548577  3748.96237431]
total_rewards_mean           1825.6645199385662
total_rewards_std            1097.371445967555
total_rewards_max            3748.9623743095804
total_rewards_min            234.670527415079
Number of train steps total  445000
Number of env steps total    2227000
Number of rollouts total     0
Train Time (s)               28.17510622087866
(Previous) Eval Time (s)     18.87564251385629
Sample Time (s)              17.12777049932629
Epoch Time (s)               64.17851923406124
Total Train Time (s)         30706.686098861042
Epoch                        444
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:47:19.423675 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #444 | Epoch Duration: 60.37914562225342
2020-01-11 11:47:19.423984 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #444 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1048262
Z variance train             0.012376884
KL Divergence                22.687572
KL Loss                      2.2687573
QF Loss                      4264.949
VF Loss                      301.09885
Policy Loss                  -1352.7983
Q Predictions Mean           1351.8398
Q Predictions Std            260.81363
Q Predictions Max            1591.2631
Q Predictions Min            -100.130325
V Predictions Mean           1360.1804
V Predictions Std            252.41245
V Predictions Max            1598.5525
V Predictions Min            -71.32655
Log Pis Mean                 0.9347005
Log Pis Std                  2.9044766
Log Pis Max                  11.960793
Log Pis Min                  -8.353277
Policy mu Mean               0.023803798
Policy mu Std                0.6434313
Policy mu Max                2.9970977
Policy mu Min                -2.2640574
Policy log std Mean          -1.09329
Policy log std Std           0.3301016
Policy log std Max           -0.021545112
Policy log std Min           -2.9603636
Z mean eval                  1.06616
Z variance eval              0.009974401
total_rewards                [2906.95002519 3701.55021101 3647.95305446 3647.32558641 3867.97634401
 1336.52711885  146.40823373 3001.43364115  832.06057945  949.44101635]
total_rewards_mean           2403.762581061649
total_rewards_std            1354.731723814615
total_rewards_max            3867.976344005345
total_rewards_min            146.40823372541087
Number of train steps total  446000
Number of env steps total    2232000
Number of rollouts total     0
Train Time (s)               24.893646298907697
(Previous) Eval Time (s)     15.07595290709287
Sample Time (s)              17.988527222536504
Epoch Time (s)               57.95812642853707
Total Train Time (s)         30766.929475953802
Epoch                        445
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:48:19.670755 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #445 | Epoch Duration: 60.24654269218445
2020-01-11 11:48:19.670961 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #445 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0654503
Z variance train             0.009993525
KL Divergence                22.697474
KL Loss                      2.2697475
QF Loss                      1079.8958
VF Loss                      248.12384
Policy Loss                  -1384.9521
Q Predictions Mean           1384.8206
Q Predictions Std            211.20175
Q Predictions Max            1597.2446
Q Predictions Min            -67.401306
V Predictions Mean           1376.906
V Predictions Std            206.12016
V Predictions Max            1588.2932
V Predictions Min            -27.710283
Log Pis Mean                 0.93784374
Log Pis Std                  2.9475374
Log Pis Max                  13.090261
Log Pis Min                  -6.9606433
Policy mu Mean               0.014507851
Policy mu Std                0.6775348
Policy mu Max                2.4540687
Policy mu Min                -2.4001942
Policy log std Mean          -1.0706426
Policy log std Std           0.27686572
Policy log std Max           0.07519233
Policy log std Min           -2.3962746
Z mean eval                  1.0906957
Z variance eval              0.00900548
total_rewards                [1154.51100238 1985.04068866 4070.62440877 3694.24549413 3249.66481087
  177.23108429  721.955014   3853.6172137  4119.18831357 3762.27936253]
total_rewards_mean           2678.8357392911394
total_rewards_std            1442.7363284418636
total_rewards_max            4119.188313570192
total_rewards_min            177.23108428897262
Number of train steps total  447000
Number of env steps total    2237000
Number of rollouts total     0
Train Time (s)               29.832450463902205
(Previous) Eval Time (s)     17.364068838767707
Sample Time (s)              17.84863160131499
Epoch Time (s)               65.0451509039849
Total Train Time (s)         30833.587288181297
Epoch                        446
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:49:26.334541 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #446 | Epoch Duration: 66.66340780258179
2020-01-11 11:49:26.334778 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #446 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0861691
Z variance train             0.009023195
KL Divergence                23.30608
KL Loss                      2.3306081
QF Loss                      1874.386
VF Loss                      111.85326
Policy Loss                  -1339.7482
Q Predictions Mean           1342.5641
Q Predictions Std            290.40762
Q Predictions Max            1575.0511
Q Predictions Min            -67.25959
V Predictions Mean           1340.3401
V Predictions Std            288.09488
V Predictions Max            1573.2388
V Predictions Min            -71.69675
Log Pis Mean                 0.66746026
Log Pis Std                  2.5749645
Log Pis Max                  11.027925
Log Pis Min                  -6.0651
Policy mu Mean               -0.004319664
Policy mu Std                0.66235065
Policy mu Max                2.5618076
Policy mu Min                -2.6038625
Policy log std Mean          -1.0286477
Policy log std Std           0.27298778
Policy log std Max           -0.07566732
Policy log std Min           -2.4157887
Z mean eval                  1.0606854
Z variance eval              0.008303578
total_rewards                [3876.84690876  835.79071982 3763.46488608 1455.12036945 3796.47566585
   61.98646687 3676.61570955 3862.66397567 3612.9322602   292.72571246]
total_rewards_mean           2523.4622674708044
total_rewards_std            1559.6354347662154
total_rewards_max            3876.846908758647
total_rewards_min            61.986466865591936
Number of train steps total  448000
Number of env steps total    2242000
Number of rollouts total     0
Train Time (s)               26.161186492070556
(Previous) Eval Time (s)     18.98200487298891
Sample Time (s)              17.742613119073212
Epoch Time (s)               62.88580448413268
Total Train Time (s)         30895.069155672565
Epoch                        447
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:50:27.819179 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #447 | Epoch Duration: 61.484227895736694
2020-01-11 11:50:27.819370 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #447 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.060099
Z variance train             0.008295623
KL Divergence                23.607841
KL Loss                      2.3607843
QF Loss                      712.9872
VF Loss                      384.67007
Policy Loss                  -1336.942
Q Predictions Mean           1340.7643
Q Predictions Std            290.9149
Q Predictions Max            1627.8501
Q Predictions Min            -94.95982
V Predictions Mean           1353.4296
V Predictions Std            288.93198
V Predictions Max            1646.3708
V Predictions Min            -61.19758
Log Pis Mean                 0.52016187
Log Pis Std                  3.0607374
Log Pis Max                  10.394989
Log Pis Min                  -9.941018
Policy mu Mean               0.02634035
Policy mu Std                0.63114923
Policy mu Max                2.6869922
Policy mu Min                -2.8359015
Policy log std Mean          -1.0713158
Policy log std Std           0.28904948
Policy log std Max           0.26245558
Policy log std Min           -2.151949
Z mean eval                  1.0990368
Z variance eval              0.009570032
total_rewards                [3962.44569554 2904.37489858 2412.83894634 3200.42328893 4025.00163926
 3739.53453555 3586.31173414 3763.22626855 3837.80816224 4098.89901364]
total_rewards_mean           3553.086418276033
total_rewards_std            519.0996675969077
total_rewards_max            4098.899013639854
total_rewards_min            2412.838946339737
Number of train steps total  449000
Number of env steps total    2247000
Number of rollouts total     0
Train Time (s)               27.26124212378636
(Previous) Eval Time (s)     17.580112335272133
Sample Time (s)              18.030823660083115
Epoch Time (s)               62.87217811914161
Total Train Time (s)         30964.594491664786
Epoch                        448
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:51:37.349492 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #448 | Epoch Duration: 69.52998471260071
2020-01-11 11:51:37.349682 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #448 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1005704
Z variance train             0.009597065
KL Divergence                23.0448
KL Loss                      2.30448
QF Loss                      3275.7773
VF Loss                      326.63333
Policy Loss                  -1382.8318
Q Predictions Mean           1384.002
Q Predictions Std            203.8752
Q Predictions Max            1624.6921
Q Predictions Min            62.02896
V Predictions Mean           1371.2634
V Predictions Std            206.04805
V Predictions Max            1613.4359
V Predictions Min            -7.991645
Log Pis Mean                 0.9461623
Log Pis Std                  2.6312468
Log Pis Max                  8.802568
Log Pis Min                  -6.463123
Policy mu Mean               0.038853478
Policy mu Std                0.6256248
Policy mu Max                2.4761639
Policy mu Min                -2.0638483
Policy log std Mean          -1.1066281
Policy log std Std           0.2842509
Policy log std Max           -0.22890627
Policy log std Min           -2.7477465
Z mean eval                  1.0749555
Z variance eval              0.012003965
total_rewards                [3734.59310888 4024.15768521 4024.46812873 3932.27009402 4007.38726468
 4100.02397158  205.05317388 4033.97736601  970.26204564 3782.17325941]
total_rewards_mean           3281.436609803445
total_rewards_std            1362.0746229861923
total_rewards_max            4100.023971577484
total_rewards_min            205.05317387800483
Number of train steps total  450000
Number of env steps total    2252000
Number of rollouts total     0
Train Time (s)               25.577107690740377
(Previous) Eval Time (s)     24.23759741988033
Sample Time (s)              17.45194842526689
Epoch Time (s)               67.2666535358876
Total Train Time (s)         31029.938822967466
Epoch                        449
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:52:42.699221 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #449 | Epoch Duration: 65.34938025474548
2020-01-11 11:52:42.699486 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #449 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0747726
Z variance train             0.011983251
KL Divergence                22.469574
KL Loss                      2.2469575
QF Loss                      1692.0917
VF Loss                      1298.7114
Policy Loss                  -1371.221
Q Predictions Mean           1368.3883
Q Predictions Std            237.32521
Q Predictions Max            1588.5764
Q Predictions Min            -39.124123
V Predictions Mean           1361.4606
V Predictions Std            223.67355
V Predictions Max            1565.8468
V Predictions Min            -45.68942
Log Pis Mean                 0.8807971
Log Pis Std                  3.1942754
Log Pis Max                  14.450936
Log Pis Min                  -6.5866942
Policy mu Mean               -0.007411213
Policy mu Std                0.62666184
Policy mu Max                2.7673156
Policy mu Min                -2.453128
Policy log std Mean          -1.1053765
Policy log std Std           0.33469558
Policy log std Max           -0.15366161
Policy log std Min           -3.2868633
Z mean eval                  1.0771885
Z variance eval              0.008028266
total_rewards                [ 302.17653792 1130.8989689  4071.84704891 4119.62965241 2204.36415739
 4027.52046896 4142.99385884 3702.54745649 3855.46296855 4013.28316812]
total_rewards_mean           3157.0724286490863
total_rewards_std            1348.1432246215904
total_rewards_max            4142.993858835105
total_rewards_min            302.17653791547707
Number of train steps total  451000
Number of env steps total    2257000
Number of rollouts total     0
Train Time (s)               29.316928475163877
(Previous) Eval Time (s)     22.32000614888966
Sample Time (s)              18.527893145103008
Epoch Time (s)               70.16482776915655
Total Train Time (s)         31099.0415158025
Epoch                        450
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:53:51.806213 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #450 | Epoch Duration: 69.10653758049011
2020-01-11 11:53:51.806387 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #450 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0767843
Z variance train             0.0080503905
KL Divergence                23.189617
KL Loss                      2.3189619
QF Loss                      5275.7617
VF Loss                      1549.9572
Policy Loss                  -1315.7367
Q Predictions Mean           1317.1938
Q Predictions Std            340.63113
Q Predictions Max            1618.0481
Q Predictions Min            -67.15119
V Predictions Mean           1323.5151
V Predictions Std            334.8702
V Predictions Max            1628.1713
V Predictions Min            -88.39059
Log Pis Mean                 0.673018
Log Pis Std                  3.0663764
Log Pis Max                  11.457758
Log Pis Min                  -6.9303007
Policy mu Mean               0.03013332
Policy mu Std                0.66458386
Policy mu Max                2.4576905
Policy mu Min                -2.8948529
Policy log std Mean          -1.0553819
Policy log std Std           0.3251353
Policy log std Max           -0.17610562
Policy log std Min           -3.104601
Z mean eval                  1.0436525
Z variance eval              0.013474246
total_rewards                [3651.1426192  3672.5518905  3136.44979189 3664.74697934  396.18060862
 3667.14820993 3850.89892608 3213.80393703 3802.23691499 3874.09228738]
total_rewards_mean           3292.9252164951495
total_rewards_std            994.0368545020297
total_rewards_max            3874.0922873826444
total_rewards_min            396.18060861732255
Number of train steps total  452000
Number of env steps total    2262000
Number of rollouts total     0
Train Time (s)               29.73053283104673
(Previous) Eval Time (s)     21.261458958964795
Sample Time (s)              17.769365868531168
Epoch Time (s)               68.76135765854269
Total Train Time (s)         31169.890871409327
Epoch                        451
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:55:02.661767 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #451 | Epoch Duration: 70.85519886016846
2020-01-11 11:55:02.662078 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #451 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0452547
Z variance train             0.013527093
KL Divergence                22.68624
KL Loss                      2.268624
QF Loss                      1575.1299
VF Loss                      625.1023
Policy Loss                  -1363.3517
Q Predictions Mean           1363.4531
Q Predictions Std            209.9646
Q Predictions Max            1566.7765
Q Predictions Min            52.88953
V Predictions Mean           1370.5875
V Predictions Std            206.4659
V Predictions Max            1578.6254
V Predictions Min            44.64984
Log Pis Mean                 1.0171752
Log Pis Std                  2.8353202
Log Pis Max                  12.143886
Log Pis Min                  -6.1610937
Policy mu Mean               0.020013947
Policy mu Std                0.6217519
Policy mu Max                2.5116773
Policy mu Min                -2.571972
Policy log std Mean          -1.1253705
Policy log std Std           0.2872307
Policy log std Max           -0.17449474
Policy log std Min           -2.7323523
Z mean eval                  1.0630624
Z variance eval              0.011897012
total_rewards                [3497.24796212 3417.33671725  570.08317637 3766.77501009 3973.16574318
 4482.84323934 3998.76700959  353.9582656  4156.44471593  409.74356004]
total_rewards_mean           2862.636539951358
total_rewards_std            1609.873249582994
total_rewards_max            4482.843239341043
total_rewards_min            353.95826559587033
Number of train steps total  453000
Number of env steps total    2267000
Number of rollouts total     0
Train Time (s)               27.231262462213635
(Previous) Eval Time (s)     23.35498704202473
Sample Time (s)              18.077934691682458
Epoch Time (s)               68.66418419592083
Total Train Time (s)         31238.137548081577
Epoch                        452
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:56:10.915238 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #452 | Epoch Duration: 68.25290822982788
2020-01-11 11:56:10.915529 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #452 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0623678
Z variance train             0.0118678035
KL Divergence                23.238394
KL Loss                      2.3238394
QF Loss                      631.0583
VF Loss                      73.78441
Policy Loss                  -1368.5203
Q Predictions Mean           1369.0469
Q Predictions Std            283.19684
Q Predictions Max            1602.6414
Q Predictions Min            -70.00415
V Predictions Mean           1368.2815
V Predictions Std            282.72653
V Predictions Max            1607.9911
V Predictions Min            -69.587585
Log Pis Mean                 0.5274494
Log Pis Std                  2.7923617
Log Pis Max                  10.221006
Log Pis Min                  -7.245244
Policy mu Mean               -0.0034056234
Policy mu Std                0.64666784
Policy mu Max                2.3964443
Policy mu Min                -2.6193585
Policy log std Mean          -1.0503533
Policy log std Std           0.2866833
Policy log std Max           -0.11648202
Policy log std Min           -2.1974359
Z mean eval                  1.083688
Z variance eval              0.01562194
total_rewards                [3763.4380713   913.6983864  3979.27106218   90.70619713 3618.27563674
 2915.36686485 3973.93039871 3926.19921462 3977.31768502 3842.6187257 ]
total_rewards_mean           3100.0822242648997
total_rewards_std            1346.0779677160558
total_rewards_max            3979.2710621753818
total_rewards_min            90.70619713172397
Number of train steps total  454000
Number of env steps total    2272000
Number of rollouts total     0
Train Time (s)               28.742477805819362
(Previous) Eval Time (s)     22.943402274977416
Sample Time (s)              18.237005597446114
Epoch Time (s)               69.92288567824289
Total Train Time (s)         31309.43041100353
Epoch                        453
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:57:22.210417 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #453 | Epoch Duration: 71.29469180107117
2020-01-11 11:57:22.210622 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #453 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0833267
Z variance train             0.015646549
KL Divergence                22.492128
KL Loss                      2.249213
QF Loss                      4797.5195
VF Loss                      526.933
Policy Loss                  -1380.3143
Q Predictions Mean           1380.8835
Q Predictions Std            254.09642
Q Predictions Max            1652.4194
Q Predictions Min            -135.35385
V Predictions Mean           1376.9137
V Predictions Std            255.20988
V Predictions Max            1648.9441
V Predictions Min            -112.96536
Log Pis Mean                 0.6104242
Log Pis Std                  2.7511082
Log Pis Max                  9.563387
Log Pis Min                  -6.105235
Policy mu Mean               -0.00067453086
Policy mu Std                0.6105196
Policy mu Max                3.0149302
Policy mu Min                -2.558341
Policy log std Mean          -1.0810394
Policy log std Std           0.25047624
Policy log std Max           -0.115773976
Policy log std Min           -2.1239915
Z mean eval                  1.0665356
Z variance eval              0.01413161
total_rewards                [3558.44934107 1380.11053036 3876.58372003 4037.40453974 3074.8450793
 3633.09086916 3900.60905493 4087.74108988 3691.72239639 4207.81599854]
total_rewards_mean           3544.8372619406773
total_rewards_std            784.2206883671483
total_rewards_max            4207.815998540045
total_rewards_min            1380.1105303647844
Number of train steps total  455000
Number of env steps total    2277000
Number of rollouts total     0
Train Time (s)               28.378696685191244
(Previous) Eval Time (s)     24.314897644799203
Sample Time (s)              18.111733279190958
Epoch Time (s)               70.8053276091814
Total Train Time (s)         31380.803056891542
Epoch                        454
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:58:33.588540 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #454 | Epoch Duration: 71.37776708602905
2020-01-11 11:58:33.588751 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #454 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0654197
Z variance train             0.014119235
KL Divergence                22.499939
KL Loss                      2.249994
QF Loss                      2985.776
VF Loss                      549.35077
Policy Loss                  -1393.7114
Q Predictions Mean           1393.0194
Q Predictions Std            198.51515
Q Predictions Max            1601.9106
Q Predictions Min            -25.69689
V Predictions Mean           1387.9355
V Predictions Std            200.93723
V Predictions Max            1600.4526
V Predictions Min            -32.199158
Log Pis Mean                 1.149518
Log Pis Std                  2.8517427
Log Pis Max                  11.490227
Log Pis Min                  -9.08453
Policy mu Mean               0.011587471
Policy mu Std                0.60766435
Policy mu Max                2.7438776
Policy mu Min                -2.4987514
Policy log std Mean          -1.1360781
Policy log std Std           0.27636704
Policy log std Max           -0.1200462
Policy log std Min           -2.7182858
Z mean eval                  1.1419154
Z variance eval              0.013263707
total_rewards                [3664.95264803 3914.37771593 4089.01857387 3947.51962676 1134.15766884
  957.75088302 3482.00992894 2950.83479354 3808.24339879 4188.00493585]
total_rewards_mean           3213.687017358172
total_rewards_std            1133.8824932034336
total_rewards_max            4188.004935853402
total_rewards_min            957.7508830206156
Number of train steps total  456000
Number of env steps total    2282000
Number of rollouts total     0
Train Time (s)               30.043722114991397
(Previous) Eval Time (s)     24.887025642208755
Sample Time (s)              17.39198022009805
Epoch Time (s)               72.3227279772982
Total Train Time (s)         31451.896682607476
Epoch                        455
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:59:44.687297 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #455 | Epoch Duration: 71.09835815429688
2020-01-11 11:59:44.687544 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #455 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1416199
Z variance train             0.013321263
KL Divergence                22.873013
KL Loss                      2.2873013
QF Loss                      895.69275
VF Loss                      308.80707
Policy Loss                  -1376.2068
Q Predictions Mean           1380.0125
Q Predictions Std            252.0122
Q Predictions Max            1593.6501
Q Predictions Min            -33.893597
V Predictions Mean           1386.4943
V Predictions Std            252.65372
V Predictions Max            1610.3207
V Predictions Min            -34.021038
Log Pis Mean                 1.0898994
Log Pis Std                  2.916763
Log Pis Max                  10.279496
Log Pis Min                  -7.0635824
Policy mu Mean               -0.02688041
Policy mu Std                0.65793604
Policy mu Max                2.3449767
Policy mu Min                -2.5367272
Policy log std Mean          -1.091752
Policy log std Std           0.29701546
Policy log std Max           -0.12840009
Policy log std Min           -2.8332064
Z mean eval                  1.0678152
Z variance eval              0.012985771
total_rewards                [3888.95983216 3828.40995121 3915.68221528 3808.00334419 1098.93414519
  854.51546897 3666.73178227 3570.11611522 1665.16447086 3944.78996386]
total_rewards_mean           3024.1307289205324
total_rewards_std            1209.2628295991149
total_rewards_max            3944.7899638609383
total_rewards_min            854.5154689672526
Number of train steps total  457000
Number of env steps total    2287000
Number of rollouts total     0
Train Time (s)               28.691308772191405
(Previous) Eval Time (s)     23.662357504013926
Sample Time (s)              17.649808942805976
Epoch Time (s)               70.0034752190113
Total Train Time (s)         31520.030158194248
Epoch                        456
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:00:52.825684 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #456 | Epoch Duration: 68.13794660568237
2020-01-11 12:00:52.825882 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #456 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0675659
Z variance train             0.012956113
KL Divergence                23.021765
KL Loss                      2.3021765
QF Loss                      4926.8203
VF Loss                      698.73914
Policy Loss                  -1347.2972
Q Predictions Mean           1349.9431
Q Predictions Std            310.9519
Q Predictions Max            1595.2625
Q Predictions Min            -99.39636
V Predictions Mean           1349.2256
V Predictions Std            303.70255
V Predictions Max            1602.6617
V Predictions Min            -89.978546
Log Pis Mean                 0.9267147
Log Pis Std                  3.0736072
Log Pis Max                  12.528967
Log Pis Min                  -6.1377654
Policy mu Mean               0.016209124
Policy mu Std                0.6895156
Policy mu Max                2.2184985
Policy mu Min                -2.4862418
Policy log std Mean          -1.036162
Policy log std Std           0.30873084
Policy log std Max           -0.093298316
Policy log std Min           -2.4349887
Z mean eval                  1.0641477
Z variance eval              0.011827157
total_rewards                [4122.16883888   88.38934363 3391.62589597 4302.95703788 3517.4253755
 2903.94084892 3581.14024716 3882.66794335 4042.70306173 3716.75380567]
total_rewards_mean           3354.9772398671303
total_rewards_std            1154.2299489981042
total_rewards_max            4302.9570378753115
total_rewards_min            88.38934362651014
Number of train steps total  458000
Number of env steps total    2292000
Number of rollouts total     0
Train Time (s)               28.0563609697856
(Previous) Eval Time (s)     21.796536766923964
Sample Time (s)              18.015422673430294
Epoch Time (s)               67.86832041013986
Total Train Time (s)         31589.022189214826
Epoch                        457
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:02:01.819700 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #457 | Epoch Duration: 68.99365234375
2020-01-11 12:02:01.819897 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #457 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0647185
Z variance train             0.011831108
KL Divergence                23.480795
KL Loss                      2.3480794
QF Loss                      1060.9629
VF Loss                      122.09188
Policy Loss                  -1355.8093
Q Predictions Mean           1354.1575
Q Predictions Std            293.13385
Q Predictions Max            1628.3406
Q Predictions Min            -71.398605
V Predictions Mean           1356.7872
V Predictions Std            289.78366
V Predictions Max            1623.5825
V Predictions Min            -77.25946
Log Pis Mean                 0.73450005
Log Pis Std                  2.793908
Log Pis Max                  16.230328
Log Pis Min                  -7.489187
Policy mu Mean               -0.0058305156
Policy mu Std                0.6721033
Policy mu Max                2.6955333
Policy mu Min                -2.6336195
Policy log std Mean          -1.0293555
Policy log std Std           0.27141148
Policy log std Max           -0.22400397
Policy log std Min           -2.5474417
Z mean eval                  1.086438
Z variance eval              0.0153942155
total_rewards                [3602.03150933 2350.15992381 3613.02817514 3583.84680727 3881.97314704
  348.72344076 3735.2602031  3801.85811126 3235.50878511 3424.48546473]
total_rewards_mean           3157.687556755437
total_rewards_std            1023.6767734663059
total_rewards_max            3881.9731470417837
total_rewards_min            348.72344075904243
Number of train steps total  459000
Number of env steps total    2297000
Number of rollouts total     0
Train Time (s)               29.563075298909098
(Previous) Eval Time (s)     22.921571015845984
Sample Time (s)              17.571580092422664
Epoch Time (s)               70.05622640717775
Total Train Time (s)         31662.9773844718
Epoch                        458
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:03:15.781457 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #458 | Epoch Duration: 73.96140170097351
2020-01-11 12:03:15.781714 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #458 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0865064
Z variance train             0.015387021
KL Divergence                23.221756
KL Loss                      2.3221757
QF Loss                      1018.1295
VF Loss                      197.69557
Policy Loss                  -1379.5796
Q Predictions Mean           1378.9758
Q Predictions Std            237.72296
Q Predictions Max            1623.8405
Q Predictions Min            -44.171944
V Predictions Mean           1371.0674
V Predictions Std            238.56664
V Predictions Max            1591.3582
V Predictions Min            -51.523376
Log Pis Mean                 0.48005286
Log Pis Std                  2.6951275
Log Pis Max                  13.184718
Log Pis Min                  -4.7181463
Policy mu Mean               0.075120896
Policy mu Std                0.6049716
Policy mu Max                2.2277417
Policy mu Min                -2.4792655
Policy log std Mean          -1.1102161
Policy log std Std           0.29058632
Policy log std Max           -0.18963903
Policy log std Min           -3.2883348
Z mean eval                  1.0824351
Z variance eval              0.012338904
total_rewards                [2986.925425   3811.97501069 3748.92489702  498.44647899 3740.79538154
 3941.85288997  373.32099579 4178.15924536 4086.80002667 3873.96880304]
total_rewards_mean           3124.116915406961
total_rewards_std            1378.1293489495029
total_rewards_max            4178.159245359569
total_rewards_min            373.32099578509207
Number of train steps total  460000
Number of env steps total    2302000
Number of rollouts total     0
Train Time (s)               29.317169232293963
(Previous) Eval Time (s)     26.826454396825284
Sample Time (s)              18.536416373681277
Epoch Time (s)               74.68004000280052
Total Train Time (s)         31734.450252521317
Epoch                        459
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:04:27.261255 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #459 | Epoch Duration: 71.47931981086731
2020-01-11 12:04:27.261542 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #459 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.082517
Z variance train             0.012336068
KL Divergence                24.049376
KL Loss                      2.4049375
QF Loss                      1696.9991
VF Loss                      332.4685
Policy Loss                  -1367.889
Q Predictions Mean           1368.7671
Q Predictions Std            311.1323
Q Predictions Max            1623.8966
Q Predictions Min            -78.79816
V Predictions Mean           1376.6235
V Predictions Std            306.81668
V Predictions Max            1635.6736
V Predictions Min            -65.24351
Log Pis Mean                 0.76885355
Log Pis Std                  2.8970888
Log Pis Max                  11.961159
Log Pis Min                  -6.409392
Policy mu Mean               0.021683853
Policy mu Std                0.6605351
Policy mu Max                2.8217618
Policy mu Min                -2.4836574
Policy log std Mean          -1.0348175
Policy log std Std           0.30183598
Policy log std Max           -0.14972526
Policy log std Min           -2.7188206
Z mean eval                  1.0775121
Z variance eval              0.013546589
total_rewards                [4141.76412025 3914.87298362  309.58037326 4001.41735361 3496.92478023
 3584.69363335 3829.64140304 3657.84520384 1791.52280208 3941.09776265]
total_rewards_mean           3266.936041592501
total_rewards_std            1171.5465015178527
total_rewards_max            4141.764120247316
total_rewards_min            309.5803732589222
Number of train steps total  461000
Number of env steps total    2307000
Number of rollouts total     0
Train Time (s)               29.694924669340253
(Previous) Eval Time (s)     23.625451458152384
Sample Time (s)              17.774020954035223
Epoch Time (s)               71.09439708152786
Total Train Time (s)         31804.629081483465
Epoch                        460
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:05:37.444263 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #460 | Epoch Duration: 70.18251466751099
2020-01-11 12:05:37.444423 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #460 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0784876
Z variance train             0.013513456
KL Divergence                23.069553
KL Loss                      2.3069553
QF Loss                      760.3934
VF Loss                      311.15518
Policy Loss                  -1400.2574
Q Predictions Mean           1401.6517
Q Predictions Std            238.27109
Q Predictions Max            1616.3932
Q Predictions Min            -97.85625
V Predictions Mean           1409.3105
V Predictions Std            236.05962
V Predictions Max            1627.008
V Predictions Min            -101.65543
Log Pis Mean                 0.7352971
Log Pis Std                  2.9597526
Log Pis Max                  18.834904
Log Pis Min                  -13.240385
Policy mu Mean               0.027320638
Policy mu Std                0.65708774
Policy mu Max                3.4232087
Policy mu Min                -2.7739878
Policy log std Mean          -1.0586843
Policy log std Std           0.28496552
Policy log std Max           0.22555196
Policy log std Min           -2.4452622
Z mean eval                  1.0677361
Z variance eval              0.008135353
total_rewards                [ 883.90971135 1067.96454385 3832.18570677 4046.59933965 3907.45180923
 1222.45614533 3851.07849809 3433.31962133  246.39250082 3983.11906872]
total_rewards_mean           2647.447694516006
total_rewards_std            1489.955699646891
total_rewards_max            4046.5993396495546
total_rewards_min            246.39250082433676
Number of train steps total  462000
Number of env steps total    2312000
Number of rollouts total     0
Train Time (s)               30.447391911409795
(Previous) Eval Time (s)     22.71328029828146
Sample Time (s)              18.154194094240665
Epoch Time (s)               71.31486630393192
Total Train Time (s)         31871.69262360502
Epoch                        461
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:06:44.513479 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #461 | Epoch Duration: 67.06889581680298
2020-01-11 12:06:44.513750 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #461 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.06925
Z variance train             0.008135505
KL Divergence                24.088247
KL Loss                      2.4088247
QF Loss                      1480.0562
VF Loss                      287.00497
Policy Loss                  -1394.7943
Q Predictions Mean           1393.0929
Q Predictions Std            208.3188
Q Predictions Max            1623.9764
Q Predictions Min            5.480918
V Predictions Mean           1384.8934
V Predictions Std            204.98723
V Predictions Max            1612.4445
V Predictions Min            -21.120031
Log Pis Mean                 0.6351534
Log Pis Std                  2.787583
Log Pis Max                  18.231575
Log Pis Min                  -6.220312
Policy mu Mean               0.0647221
Policy mu Std                0.5927191
Policy mu Max                2.1765876
Policy mu Min                -2.146244
Policy log std Mean          -1.1055863
Policy log std Std           0.26951253
Policy log std Max           -0.2369067
Policy log std Min           -3.6854515
Z mean eval                  1.0762959
Z variance eval              0.011386721
total_rewards                [4128.17295499 3842.72368885 3804.94013416 3962.0974448  3739.18401744
  615.35166905 3801.4526125  4133.70837148 3999.24703226 4048.97504036]
total_rewards_mean           3607.585296588997
total_rewards_std            1006.1969748043971
total_rewards_max            4133.708371482591
total_rewards_min            615.3516690487229
Number of train steps total  463000
Number of env steps total    2317000
Number of rollouts total     0
Train Time (s)               29.574937601108104
(Previous) Eval Time (s)     18.46697222115472
Sample Time (s)              18.35427095880732
Epoch Time (s)               66.39618078107014
Total Train Time (s)         31944.26143216295
Epoch                        462
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:07:57.085619 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #462 | Epoch Duration: 72.5716757774353
2020-01-11 12:07:57.085795 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #462 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0764334
Z variance train             0.011329441
KL Divergence                23.731419
KL Loss                      2.373142
QF Loss                      751.27893
VF Loss                      154.1344
Policy Loss                  -1395.1572
Q Predictions Mean           1396.66
Q Predictions Std            235.80661
Q Predictions Max            1630.6016
Q Predictions Min            -47.68991
V Predictions Mean           1401.2744
V Predictions Std            235.40988
V Predictions Max            1637.3054
V Predictions Min            -35.47266
Log Pis Mean                 1.2981796
Log Pis Std                  2.6848264
Log Pis Max                  14.52965
Log Pis Min                  -4.688011
Policy mu Mean               -0.011046826
Policy mu Std                0.6464905
Policy mu Max                2.6490912
Policy mu Min                -2.8716433
Policy log std Mean          -1.1060617
Policy log std Std           0.30043498
Policy log std Max           -0.089722335
Policy log std Min           -3.0563054
Z mean eval                  1.1250994
Z variance eval              0.0058645224
total_rewards                [3953.4070025  3839.50481154 2679.25615569 1047.28569659 3770.49781346
  931.82419606 1801.07400815 4165.66382667 3376.5235938  1204.57683736]
total_rewards_mean           2676.9613941800835
total_rewards_std            1245.741212045302
total_rewards_max            4165.663826670275
total_rewards_min            931.824196055031
Number of train steps total  464000
Number of env steps total    2322000
Number of rollouts total     0
Train Time (s)               28.52777083031833
(Previous) Eval Time (s)     24.642132255248725
Sample Time (s)              18.55962284654379
Epoch Time (s)               71.72952593211085
Total Train Time (s)         32010.70213933289
Epoch                        463
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:09:03.533184 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #463 | Epoch Duration: 66.44722414016724
2020-01-11 12:09:03.533439 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #463 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.125769
Z variance train             0.005845685
KL Divergence                25.064388
KL Loss                      2.506439
QF Loss                      8112.8447
VF Loss                      991.28375
Policy Loss                  -1391.0691
Q Predictions Mean           1399.992
Q Predictions Std            267.70004
Q Predictions Max            1622.2458
Q Predictions Min            -80.29511
V Predictions Mean           1400.0295
V Predictions Std            270.24036
V Predictions Max            1625.942
V Predictions Min            -64.88725
Log Pis Mean                 1.3197262
Log Pis Std                  3.0637648
Log Pis Max                  13.891224
Log Pis Min                  -6.5852795
Policy mu Mean               -0.05958164
Policy mu Std                0.701224
Policy mu Max                2.6506934
Policy mu Min                -3.6044023
Policy log std Mean          -1.0680103
Policy log std Std           0.32341862
Policy log std Max           -0.17173475
Policy log std Min           -2.9692073
Z mean eval                  1.085866
Z variance eval              0.012203334
total_rewards                [3056.26040589  285.07331737  392.10400484 2602.38439448 4011.25740335
 2290.5579995    67.53231532   93.05266382 2996.23135479  575.11183496]
total_rewards_mean           1636.956569432254
total_rewards_std            1421.6220918740019
total_rewards_max            4011.25740334939
total_rewards_min            67.53231532074923
Number of train steps total  465000
Number of env steps total    2327000
Number of rollouts total     0
Train Time (s)               28.78531481605023
(Previous) Eval Time (s)     19.359498501755297
Sample Time (s)              18.02837149007246
Epoch Time (s)               66.17318480787799
Total Train Time (s)         32070.410295757465
Epoch                        464
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:10:03.245474 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #464 | Epoch Duration: 59.711849212646484
2020-01-11 12:10:03.245666 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #464 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.084232
Z variance train             0.012161488
KL Divergence                23.372946
KL Loss                      2.3372946
QF Loss                      6786.8306
VF Loss                      210.26302
Policy Loss                  -1381.3042
Q Predictions Mean           1380.7122
Q Predictions Std            252.87242
Q Predictions Max            1635.9398
Q Predictions Min            -83.64698
V Predictions Mean           1382.2368
V Predictions Std            243.1667
V Predictions Max            1628.5126
V Predictions Min            -71.71966
Log Pis Mean                 1.0153638
Log Pis Std                  2.8810413
Log Pis Max                  11.321984
Log Pis Min                  -8.1404085
Policy mu Mean               0.0018932663
Policy mu Std                0.6388944
Policy mu Max                2.3607452
Policy mu Min                -2.7424679
Policy log std Mean          -1.1001812
Policy log std Std           0.3067739
Policy log std Max           -0.2293716
Policy log std Min           -3.1037223
Z mean eval                  1.080426
Z variance eval              0.013373582
total_rewards                [3981.32041345 4094.51109109 3875.37512745 4256.30602043 3798.09662685
  860.73692196 3867.69523862 4248.56143494 3542.15025362 4112.91902748]
total_rewards_mean           3663.7672155888627
total_rewards_std            956.9421421488615
total_rewards_max            4256.306020431541
total_rewards_min            860.7369219623597
Number of train steps total  466000
Number of env steps total    2332000
Number of rollouts total     0
Train Time (s)               31.601566702127457
(Previous) Eval Time (s)     12.89787045866251
Sample Time (s)              17.675252890214324
Epoch Time (s)               62.17469005100429
Total Train Time (s)         32146.246726593934
Epoch                        465
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:11:19.086485 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #465 | Epoch Duration: 75.84067487716675
2020-01-11 12:11:19.086712 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #465 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.080226
Z variance train             0.013507003
KL Divergence                23.391401
KL Loss                      2.3391402
QF Loss                      4334.227
VF Loss                      958.3298
Policy Loss                  -1389.4758
Q Predictions Mean           1388.063
Q Predictions Std            272.27502
Q Predictions Max            1624.3849
Q Predictions Min            -89.43961
V Predictions Mean           1375.1655
V Predictions Std            267.0549
V Predictions Max            1618.5015
V Predictions Min            -89.60887
Log Pis Mean                 1.014451
Log Pis Std                  2.974439
Log Pis Max                  13.773092
Log Pis Min                  -11.602759
Policy mu Mean               0.041334674
Policy mu Std                0.6578067
Policy mu Max                3.074046
Policy mu Min                -2.5224767
Policy log std Mean          -1.0662048
Policy log std Std           0.29237837
Policy log std Max           -0.03129089
Policy log std Min           -2.919458
Z mean eval                  1.1207589
Z variance eval              0.009911003
total_rewards                [2577.89260044 4153.43552597 4003.10020378 4050.11384695 3854.45912791
 3599.71527616 4003.45449334 4009.13406363 3817.79575669 2634.38942827]
total_rewards_mean           3670.3490323149003
total_rewards_std            551.4844794370381
total_rewards_max            4153.435525970397
total_rewards_min            2577.892600439238
Number of train steps total  467000
Number of env steps total    2337000
Number of rollouts total     0
Train Time (s)               29.32144682155922
(Previous) Eval Time (s)     26.56353534385562
Sample Time (s)              19.191311849281192
Epoch Time (s)               75.07629401469603
Total Train Time (s)         32219.69369828375
Epoch                        466
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:12:32.537023 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #466 | Epoch Duration: 73.45017623901367
2020-01-11 12:12:32.537309 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #466 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1203436
Z variance train             0.009886744
KL Divergence                23.76534
KL Loss                      2.3765342
QF Loss                      1572.5503
VF Loss                      292.80615
Policy Loss                  -1374.0531
Q Predictions Mean           1373.9355
Q Predictions Std            301.61392
Q Predictions Max            1629.7102
Q Predictions Min            -128.55046
V Predictions Mean           1368.897
V Predictions Std            301.42618
V Predictions Max            1612.3336
V Predictions Min            -113.00409
Log Pis Mean                 0.7827728
Log Pis Std                  2.7818375
Log Pis Max                  13.523774
Log Pis Min                  -7.0334654
Policy mu Mean               0.02281069
Policy mu Std                0.61205655
Policy mu Max                3.0175169
Policy mu Min                -2.835216
Policy log std Mean          -1.0945718
Policy log std Std           0.29419273
Policy log std Max           -0.19449359
Policy log std Min           -2.8826241
Z mean eval                  1.1242311
Z variance eval              0.010002458
total_rewards                [4018.45281676  469.4324333  4115.52880076 4297.76314385   42.7624017
 4189.04552889 3022.59318965 4053.87769811 2889.345756   3184.03204181]
total_rewards_mean           3028.2833810830657
total_rewards_std            1472.34428132441
total_rewards_max            4297.763143845812
total_rewards_min            42.76240169817065
Number of train steps total  468000
Number of env steps total    2342000
Number of rollouts total     0
Train Time (s)               28.708277623169124
(Previous) Eval Time (s)     24.937064005061984
Sample Time (s)              17.97645400231704
Epoch Time (s)               71.62179563054815
Total Train Time (s)         32289.329437914304
Epoch                        467
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:13:42.181666 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #467 | Epoch Duration: 69.64418029785156
2020-01-11 12:13:42.181953 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #467 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1235874
Z variance train             0.009992278
KL Divergence                23.393536
KL Loss                      2.3393536
QF Loss                      708.0995
VF Loss                      406.4903
Policy Loss                  -1411.7493
Q Predictions Mean           1412.3362
Q Predictions Std            207.09517
Q Predictions Max            1619.2938
Q Predictions Min            -139.44151
V Predictions Mean           1412.7078
V Predictions Std            205.07004
V Predictions Max            1615.3324
V Predictions Min            -128.01648
Log Pis Mean                 1.0306237
Log Pis Std                  2.9097133
Log Pis Max                  9.464571
Log Pis Min                  -7.006626
Policy mu Mean               -0.012437216
Policy mu Std                0.67451036
Policy mu Max                2.6208422
Policy mu Min                -2.2107174
Policy log std Mean          -1.0906285
Policy log std Std           0.28555351
Policy log std Max           -0.07527381
Policy log std Min           -2.6042466
Z mean eval                  1.0946778
Z variance eval              0.007789175
total_rewards                [1766.30643595  321.68424336   91.86827273 4061.7569365  3286.73008163
 4123.72464903 4205.87844306 3783.43158733 4110.26307275  476.02585626]
total_rewards_mean           2622.7669578604814
total_rewards_std            1669.5177155018087
total_rewards_max            4205.878443060918
total_rewards_min            91.86827273481765
Number of train steps total  469000
Number of env steps total    2347000
Number of rollouts total     0
Train Time (s)               29.66373254545033
(Previous) Eval Time (s)     22.95911307260394
Sample Time (s)              18.25801516743377
Epoch Time (s)               70.88086078548804
Total Train Time (s)         32360.204245259054
Epoch                        468
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:14:53.060792 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #468 | Epoch Duration: 70.8785891532898
2020-01-11 12:14:53.061067 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #468 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0934821
Z variance train             0.0077958903
KL Divergence                24.248405
KL Loss                      2.4248407
QF Loss                      1086.8251
VF Loss                      275.37952
Policy Loss                  -1400.8911
Q Predictions Mean           1402.1924
Q Predictions Std            274.6348
Q Predictions Max            1660.0282
Q Predictions Min            -102.07592
V Predictions Mean           1389.418
V Predictions Std            274.38004
V Predictions Max            1650.6271
V Predictions Min            -111.94751
Log Pis Mean                 0.7022408
Log Pis Std                  3.093421
Log Pis Max                  13.1786785
Log Pis Min                  -8.47232
Policy mu Mean               0.034559786
Policy mu Std                0.6413632
Policy mu Max                3.309947
Policy mu Min                -2.8976665
Policy log std Mean          -1.0838084
Policy log std Std           0.2847894
Policy log std Max           -0.16068959
Policy log std Min           -2.410006
Z mean eval                  1.063735
Z variance eval              0.010783081
total_rewards                [3117.66192203 4276.05025301 2771.11965254 1203.33631383 4220.39283909
 3968.8350746  4085.93114239 4247.38134907 4195.54690923 2851.17164037]
total_rewards_mean           3493.7427096156925
total_rewards_std            953.9080464090736
total_rewards_max            4276.050253011063
total_rewards_min            1203.3363138342586
Number of train steps total  470000
Number of env steps total    2352000
Number of rollouts total     0
Train Time (s)               29.571667273063213
(Previous) Eval Time (s)     22.95652961404994
Sample Time (s)              17.956216755788773
Epoch Time (s)               70.48441364290193
Total Train Time (s)         32431.285268584732
Epoch                        469
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:16:04.144671 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #469 | Epoch Duration: 71.08340525627136
2020-01-11 12:16:04.144880 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #469 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0622966
Z variance train             0.010798576
KL Divergence                24.000492
KL Loss                      2.4000492
QF Loss                      870.34424
VF Loss                      598.87744
Policy Loss                  -1428.9094
Q Predictions Mean           1434.3898
Q Predictions Std            212.13269
Q Predictions Max            1658.7349
Q Predictions Min            -76.28758
V Predictions Mean           1424.6606
V Predictions Std            204.83742
V Predictions Max            1646.7056
V Predictions Min            -80.713486
Log Pis Mean                 1.1026385
Log Pis Std                  2.756267
Log Pis Max                  12.588972
Log Pis Min                  -10.521227
Policy mu Mean               0.009742767
Policy mu Std                0.6600313
Policy mu Max                2.6070125
Policy mu Min                -2.410822
Policy log std Mean          -1.0985557
Policy log std Std           0.276495
Policy log std Max           -0.20539069
Policy log std Min           -2.8135936
Z mean eval                  1.0853002
Z variance eval              0.0115347635
total_rewards                [ 990.48294865 1418.45039211 4083.3591828  4335.1774251  3840.48028256
  301.76296296 4001.25418079 4022.63334261 4114.74255431 2185.88132689]
total_rewards_mean           2929.422459878297
total_rewards_std            1462.4168763824362
total_rewards_max            4335.177425097128
total_rewards_min            301.76296296442604
Number of train steps total  471000
Number of env steps total    2357000
Number of rollouts total     0
Train Time (s)               30.469227354042232
(Previous) Eval Time (s)     23.5552273937501
Sample Time (s)              18.032830588519573
Epoch Time (s)               72.0572853363119
Total Train Time (s)         32499.47510884842
Epoch                        470
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:17:12.338376 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #470 | Epoch Duration: 68.19335055351257
2020-01-11 12:17:12.338559 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #470 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0845665
Z variance train             0.011533765
KL Divergence                23.44046
KL Loss                      2.344046
QF Loss                      6976.446
VF Loss                      487.39276
Policy Loss                  -1401.5942
Q Predictions Mean           1405.3303
Q Predictions Std            263.2489
Q Predictions Max            1674.4402
Q Predictions Min            -91.67714
V Predictions Mean           1417.013
V Predictions Std            266.9129
V Predictions Max            1675.3395
V Predictions Min            -99.36669
Log Pis Mean                 1.1035302
Log Pis Std                  2.9970963
Log Pis Max                  16.609352
Log Pis Min                  -6.306489
Policy mu Mean               -0.038073175
Policy mu Std                0.64775866
Policy mu Max                3.0539281
Policy mu Min                -2.5376706
Policy log std Mean          -1.1153584
Policy log std Std           0.2851139
Policy log std Max           0.059633136
Policy log std Min           -2.238245
Z mean eval                  1.1219347
Z variance eval              0.010392066
total_rewards                [2172.84600577  346.70755587 4402.40955775   73.53992951 3799.08679793
 1389.46720616 2014.68471847 1983.07517417 4248.33564109 4197.24019003]
total_rewards_mean           2462.7392776746788
total_rewards_std            1536.152291931533
total_rewards_max            4402.409557746816
total_rewards_min            73.5399295055712
Number of train steps total  472000
Number of env steps total    2362000
Number of rollouts total     0
Train Time (s)               29.38429060904309
(Previous) Eval Time (s)     19.690999762155116
Sample Time (s)              18.728483581915498
Epoch Time (s)               67.8037739531137
Total Train Time (s)         32563.193874282762
Epoch                        471
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:18:16.060833 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #471 | Epoch Duration: 63.72212600708008
2020-01-11 12:18:16.061025 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #471 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1221114
Z variance train             0.010396204
KL Divergence                23.669386
KL Loss                      2.3669386
QF Loss                      795.57227
VF Loss                      198.34753
Policy Loss                  -1379.4523
Q Predictions Mean           1380.086
Q Predictions Std            310.6291
Q Predictions Max            1641.4038
Q Predictions Min            -102.1185
V Predictions Mean           1387.1571
V Predictions Std            313.37057
V Predictions Max            1640.4294
V Predictions Min            -116.98716
Log Pis Mean                 0.9407251
Log Pis Std                  3.3134804
Log Pis Max                  27.82128
Log Pis Min                  -8.000745
Policy mu Mean               0.004430885
Policy mu Std                0.67948794
Policy mu Max                7.119903
Policy mu Min                -3.716514
Policy log std Mean          -1.0999963
Policy log std Std           0.28186798
Policy log std Max           0.42045337
Policy log std Min           -2.7016919
Z mean eval                  1.0920125
Z variance eval              0.006665739
total_rewards                [3644.33775742 3993.82775541 -278.3320153  3762.03833595 4163.48613263
 3844.20550878 4008.98447928 1460.71264699 4118.94816663 1408.01409137]
total_rewards_mean           3012.622285915693
total_rewards_std            1482.2191824869192
total_rewards_max            4163.486132633575
total_rewards_min            -278.3320152954788
Number of train steps total  473000
Number of env steps total    2367000
Number of rollouts total     0
Train Time (s)               30.07652655802667
(Previous) Eval Time (s)     15.608975965995342
Sample Time (s)              18.661186858080328
Epoch Time (s)               64.34668938210234
Total Train Time (s)         32635.261206837837
Epoch                        472
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:19:28.133439 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #472 | Epoch Duration: 72.07226085662842
2020-01-11 12:19:28.133658 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #472 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0878656
Z variance train             0.0066564605
KL Divergence                24.571857
KL Loss                      2.4571857
QF Loss                      2463.219
VF Loss                      362.73315
Policy Loss                  -1422.3531
Q Predictions Mean           1422.1455
Q Predictions Std            228.39911
Q Predictions Max            1692.1721
Q Predictions Min            32.321552
V Predictions Mean           1426.3142
V Predictions Std            223.33736
V Predictions Max            1686.7747
V Predictions Min            31.321598
Log Pis Mean                 1.3029957
Log Pis Std                  2.9526808
Log Pis Max                  12.962264
Log Pis Min                  -5.466115
Policy mu Mean               0.007714193
Policy mu Std                0.65418756
Policy mu Max                2.3503761
Policy mu Min                -2.519532
Policy log std Mean          -1.1228838
Policy log std Std           0.29941088
Policy log std Max           -0.123006105
Policy log std Min           -3.2491474
Z mean eval                  1.0780809
Z variance eval              0.0062578097
total_rewards                [ -14.33415439 4001.45636353 4013.07295581  665.0612795    69.19659327
 1276.71731505 3879.60350199  257.29336676 2101.99644665 4352.06024796]
total_rewards_mean           2060.2123916141154
total_rewards_std            1738.5426227077298
total_rewards_max            4352.060247963646
total_rewards_min            -14.334154390531499
Number of train steps total  474000
Number of env steps total    2372000
Number of rollouts total     0
Train Time (s)               29.98587130662054
(Previous) Eval Time (s)     23.334194963797927
Sample Time (s)              18.029814942274243
Epoch Time (s)               71.34988121269271
Total Train Time (s)         32696.735208578873
Epoch                        473
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:20:29.614774 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #473 | Epoch Duration: 61.48091435432434
2020-01-11 12:20:29.615059 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #473 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.07922
Z variance train             0.0062663564
KL Divergence                24.574251
KL Loss                      2.457425
QF Loss                      834.84314
VF Loss                      196.17236
Policy Loss                  -1431.8372
Q Predictions Mean           1436.3203
Q Predictions Std            223.99417
Q Predictions Max            1666.2186
Q Predictions Min            44.85973
V Predictions Mean           1428.5935
V Predictions Std            224.23154
V Predictions Max            1662.5797
V Predictions Min            35.210777
Log Pis Mean                 1.12853
Log Pis Std                  2.94518
Log Pis Max                  14.468722
Log Pis Min                  -7.106678
Policy mu Mean               -0.022606475
Policy mu Std                0.6830027
Policy mu Max                2.6785862
Policy mu Min                -2.8962379
Policy log std Mean          -1.1076785
Policy log std Std           0.2751623
Policy log std Max           -0.048196793
Policy log std Min           -2.1653903
Z mean eval                  1.084914
Z variance eval              0.006871774
total_rewards                [4036.98362279 4378.6759957  1964.39033607 4341.64114181 4376.54018016
 4041.30437059 4187.37502703 4035.34311135 1394.2246522  4372.20241276]
total_rewards_mean           3712.8680850460623
total_rewards_std            1033.885303102672
total_rewards_max            4378.6759956964115
total_rewards_min            1394.2246522013138
Number of train steps total  475000
Number of env steps total    2377000
Number of rollouts total     0
Train Time (s)               27.82839407166466
(Previous) Eval Time (s)     13.464919872116297
Sample Time (s)              17.444556607864797
Epoch Time (s)               58.737870551645756
Total Train Time (s)         32765.40212785825
Epoch                        474
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:21:38.288003 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #474 | Epoch Duration: 68.6727294921875
2020-01-11 12:21:38.288224 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #474 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0839814
Z variance train             0.0068804086
KL Divergence                24.537899
KL Loss                      2.45379
QF Loss                      1630.2544
VF Loss                      278.75952
Policy Loss                  -1383.0516
Q Predictions Mean           1383.9409
Q Predictions Std            319.8455
Q Predictions Max            1674.2039
Q Predictions Min            -125.07517
V Predictions Mean           1384.9675
V Predictions Std            321.86948
V Predictions Max            1628.9636
V Predictions Min            -135.31985
Log Pis Mean                 0.9380474
Log Pis Std                  2.723691
Log Pis Max                  9.721958
Log Pis Min                  -9.035697
Policy mu Mean               0.07468772
Policy mu Std                0.62889
Policy mu Max                2.3404891
Policy mu Min                -2.4559824
Policy log std Mean          -1.0963851
Policy log std Std           0.3094518
Policy log std Max           -0.07606411
Policy log std Min           -2.706281
Z mean eval                  1.0794997
Z variance eval              0.009628082
total_rewards                [3979.12946503  241.27111198 3870.87085372  749.99239273 3934.88161718
 1967.74010593  287.43015623   41.3794019  3818.75980827 2451.30661386]
total_rewards_mean           2134.2761526814634
total_rewards_std            1609.9043216573646
total_rewards_max            3979.129465031735
total_rewards_min            41.37940189538802
Number of train steps total  476000
Number of env steps total    2382000
Number of rollouts total     0
Train Time (s)               30.52596286404878
(Previous) Eval Time (s)     23.399510846938938
Sample Time (s)              17.429665431380272
Epoch Time (s)               71.35513914236799
Total Train Time (s)         32829.612401483115
Epoch                        475
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:22:42.503176 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #475 | Epoch Duration: 64.21478009223938
2020-01-11 12:22:42.503385 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #475 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0789487
Z variance train             0.009589122
KL Divergence                24.436247
KL Loss                      2.4436247
QF Loss                      1333.7153
VF Loss                      244.91658
Policy Loss                  -1421.0304
Q Predictions Mean           1418.3175
Q Predictions Std            253.29588
Q Predictions Max            1643.2885
Q Predictions Min            -20.775532
V Predictions Mean           1418.3901
V Predictions Std            246.78317
V Predictions Max            1660.6302
V Predictions Min            1.9139247
Log Pis Mean                 1.1480381
Log Pis Std                  3.1793215
Log Pis Max                  13.725923
Log Pis Min                  -9.1830845
Policy mu Mean               -0.015262523
Policy mu Std                0.6303736
Policy mu Max                2.2759383
Policy mu Min                -2.990157
Policy log std Mean          -1.1508043
Policy log std Std           0.3012473
Policy log std Max           -0.15286559
Policy log std Min           -2.7816942
Z mean eval                  1.1496024
Z variance eval              0.013229905
total_rewards                [4173.51897171 1363.83310375 4036.68061907 4211.87304642 3189.69448682
 4204.98406354 4056.26855729 4330.65684077 4439.79089765  889.76442481]
total_rewards_mean           3489.7065011829136
total_rewards_std            1228.8132811546543
total_rewards_max            4439.790897654392
total_rewards_min            889.7644248062667
Number of train steps total  477000
Number of env steps total    2387000
Number of rollouts total     0
Train Time (s)               27.56529990117997
(Previous) Eval Time (s)     16.258848522324115
Sample Time (s)              17.856268452014774
Epoch Time (s)               61.68041687551886
Total Train Time (s)         32897.31525086751
Epoch                        476
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:23:50.212056 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #476 | Epoch Duration: 67.70847487449646
2020-01-11 12:23:50.212357 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #476 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1508048
Z variance train             0.013265036
KL Divergence                24.324512
KL Loss                      2.4324512
QF Loss                      822.241
VF Loss                      117.71231
Policy Loss                  -1459.4988
Q Predictions Mean           1461.0004
Q Predictions Std            218.7905
Q Predictions Max            1659.7662
Q Predictions Min            -116.89032
V Predictions Mean           1462.1172
V Predictions Std            216.87228
V Predictions Max            1658.2021
V Predictions Min            -108.34395
Log Pis Mean                 1.2392881
Log Pis Std                  2.9132156
Log Pis Max                  10.219845
Log Pis Min                  -8.160822
Policy mu Mean               0.012347225
Policy mu Std                0.68416464
Policy mu Max                3.177831
Policy mu Min                -2.3346944
Policy log std Mean          -1.1066234
Policy log std Std           0.2773788
Policy log std Max           0.16197747
Policy log std Min           -2.3120217
Z mean eval                  1.1116714
Z variance eval              0.012577449
total_rewards                [4115.72771805 3828.95292309 4029.15001834 3209.04015285 3915.30353909
 4326.39561144 4206.40831825 3920.08044376 3908.71173747 4026.9987786 ]
total_rewards_mean           3948.6769240928697
total_rewards_std            285.4011607037828
total_rewards_max            4326.395611439242
total_rewards_min            3209.0401528456773
Number of train steps total  478000
Number of env steps total    2392000
Number of rollouts total     0
Train Time (s)               30.712526015006006
(Previous) Eval Time (s)     22.286585413850844
Sample Time (s)              18.688925730995834
Epoch Time (s)               71.68803715985268
Total Train Time (s)         32973.2213122542
Epoch                        477
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:25:06.120738 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #477 | Epoch Duration: 75.90818238258362
2020-01-11 12:25:06.120888 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #477 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1128725
Z variance train             0.012609003
KL Divergence                24.360151
KL Loss                      2.4360151
QF Loss                      1241.4214
VF Loss                      224.9638
Policy Loss                  -1409.1626
Q Predictions Mean           1409.7825
Q Predictions Std            288.14713
Q Predictions Max            1675.7064
Q Predictions Min            11.047518
V Predictions Mean           1418.1345
V Predictions Std            290.35852
V Predictions Max            1673.9481
V Predictions Min            -6.043947
Log Pis Mean                 1.1353197
Log Pis Std                  2.9338226
Log Pis Max                  11.4841175
Log Pis Min                  -6.145811
Policy mu Mean               -0.019807242
Policy mu Std                0.65142304
Policy mu Max                2.9864352
Policy mu Min                -2.6917112
Policy log std Mean          -1.1243145
Policy log std Std           0.29482538
Policy log std Max           -0.22631264
Policy log std Min           -2.497013
Z mean eval                  1.1062957
Z variance eval              0.009483828
total_rewards                [1400.82702722 3745.61032419 3998.65814841 4471.54653392 2821.8789778
 4127.70691648 1537.02979698 4141.6063651   824.50285383 4573.30902711]
total_rewards_mean           3164.267597105081
total_rewards_std            1340.1978898759148
total_rewards_max            4573.309027113695
total_rewards_min            824.5028538281312
Number of train steps total  479000
Number of env steps total    2397000
Number of rollouts total     0
Train Time (s)               29.742460242006928
(Previous) Eval Time (s)     26.50644123274833
Sample Time (s)              17.993042377755046
Epoch Time (s)               74.2419438525103
Total Train Time (s)         33044.69520605309
Epoch                        478
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:26:17.602855 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #478 | Epoch Duration: 71.48179078102112
2020-01-11 12:26:17.603202 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #478 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1050433
Z variance train             0.00948892
KL Divergence                24.854753
KL Loss                      2.4854753
QF Loss                      1076.3313
VF Loss                      115.37928
Policy Loss                  -1405.6699
Q Predictions Mean           1403.182
Q Predictions Std            267.15106
Q Predictions Max            1655.8904
Q Predictions Min            -208.06055
V Predictions Mean           1408.4819
V Predictions Std            264.27597
V Predictions Max            1641.5068
V Predictions Min            -182.66353
Log Pis Mean                 0.7367197
Log Pis Std                  2.8827596
Log Pis Max                  9.90599
Log Pis Min                  -5.8599024
Policy mu Mean               0.011914157
Policy mu Std                0.6571141
Policy mu Max                2.3907983
Policy mu Min                -2.6837082
Policy log std Mean          -1.073963
Policy log std Std           0.2680504
Policy log std Max           0.07780665
Policy log std Min           -2.1740165
Z mean eval                  1.0685403
Z variance eval              0.010629169
total_rewards                [3485.89571312 3274.165699   3906.42232335 1049.03923185 3830.41143521
 2669.19430084 4160.32495934 3855.14478277 3485.2204062  3773.39007721]
total_rewards_mean           3348.920892889081
total_rewards_std            862.082719575593
total_rewards_max            4160.32495933622
total_rewards_min            1049.0392318546833
Number of train steps total  480000
Number of env steps total    2402000
Number of rollouts total     0
Train Time (s)               28.079137197695673
(Previous) Eval Time (s)     23.745963140390813
Sample Time (s)              17.63641756726429
Epoch Time (s)               69.46151790535077
Total Train Time (s)         33114.95933220629
Epoch                        479
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:27:27.869406 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #479 | Epoch Duration: 70.26598525047302
2020-01-11 12:27:27.869593 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #479 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0677938
Z variance train             0.010576499
KL Divergence                24.388144
KL Loss                      2.4388144
QF Loss                      972.0615
VF Loss                      192.36526
Policy Loss                  -1418.447
Q Predictions Mean           1415.4055
Q Predictions Std            233.56622
Q Predictions Max            1667.1727
Q Predictions Min            -57.843693
V Predictions Mean           1419.1243
V Predictions Std            235.02034
V Predictions Max            1655.2161
V Predictions Min            -88.20698
Log Pis Mean                 1.1001773
Log Pis Std                  2.867877
Log Pis Max                  11.700023
Log Pis Min                  -6.376766
Policy mu Mean               0.034458376
Policy mu Std                0.66107357
Policy mu Max                2.5332642
Policy mu Min                -2.666053
Policy log std Mean          -1.1028746
Policy log std Std           0.2854381
Policy log std Max           -0.15154845
Policy log std Min           -2.719668
Z mean eval                  1.0887096
Z variance eval              0.009955493
total_rewards                [3952.98422281 4258.54074219 3838.44168192 3925.56584543 2987.29068634
 1363.59383103 4246.32701474 4355.13788852 3985.15617094 4198.87347632]
total_rewards_mean           3711.1911560233893
total_rewards_std            864.2556570400235
total_rewards_max            4355.137888516659
total_rewards_min            1363.5938310282218
Number of train steps total  481000
Number of env steps total    2407000
Number of rollouts total     0
Train Time (s)               26.49729222524911
(Previous) Eval Time (s)     24.55016425391659
Sample Time (s)              18.52179751638323
Epoch Time (s)               69.56925399554893
Total Train Time (s)         33183.7104790858
Epoch                        480
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:28:36.625962 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #480 | Epoch Duration: 68.75623035430908
2020-01-11 12:28:36.626174 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #480 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0906904
Z variance train             0.00994402
KL Divergence                24.82131
KL Loss                      2.482131
QF Loss                      918.0179
VF Loss                      325.08197
Policy Loss                  -1430.0591
Q Predictions Mean           1432.0486
Q Predictions Std            298.88702
Q Predictions Max            1723.7794
Q Predictions Min            -128.25543
V Predictions Mean           1427.1029
V Predictions Std            301.90524
V Predictions Max            1702.1125
V Predictions Min            -151.81305
Log Pis Mean                 0.98075277
Log Pis Std                  3.2369063
Log Pis Max                  14.876493
Log Pis Min                  -8.694649
Policy mu Mean               0.022764511
Policy mu Std                0.6454744
Policy mu Max                2.3080943
Policy mu Min                -2.5615053
Policy log std Mean          -1.111938
Policy log std Std           0.28748563
Policy log std Max           -0.038089514
Policy log std Min           -2.442233
Z mean eval                  1.1183782
Z variance eval              0.006435649
total_rewards                [3967.2717273   232.09711536 2218.65227782 1705.83174177 3989.11502776
 3940.61545463 4122.54304066 2541.95989803 3927.98251242  912.53106873]
total_rewards_mean           2755.8599864472726
total_rewards_std            1372.5130571989494
total_rewards_max            4122.543040659766
total_rewards_min            232.0971153552623
Number of train steps total  482000
Number of env steps total    2412000
Number of rollouts total     0
Train Time (s)               29.513250877149403
(Previous) Eval Time (s)     23.736814276780933
Sample Time (s)              17.767781927715987
Epoch Time (s)               71.01784708164632
Total Train Time (s)         33250.05613788869
Epoch                        481
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:29:42.975129 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #481 | Epoch Duration: 66.34878993034363
2020-01-11 12:29:42.975323 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #481 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1159714
Z variance train             0.0064221127
KL Divergence                25.84747
KL Loss                      2.584747
QF Loss                      1381.8167
VF Loss                      295.0161
Policy Loss                  -1420.1799
Q Predictions Mean           1414.6956
Q Predictions Std            292.15652
Q Predictions Max            1670.9757
Q Predictions Min            -169.88379
V Predictions Mean           1416.9097
V Predictions Std            289.5729
V Predictions Max            1674.6462
V Predictions Min            -158.04213
Log Pis Mean                 0.5237353
Log Pis Std                  2.8366573
Log Pis Max                  14.817944
Log Pis Min                  -6.688136
Policy mu Mean               0.025786873
Policy mu Std                0.6056755
Policy mu Max                3.0814676
Policy mu Min                -2.22463
Policy log std Mean          -1.1188736
Policy log std Std           0.2760667
Policy log std Max           -0.09822428
Policy log std Min           -2.4632158
Z mean eval                  1.079403
Z variance eval              0.006728478
total_rewards                [1253.16718016 3803.2279973  3891.22084116 4073.23819938 4081.26967711
 4069.19775118 4154.48035797 3984.55042903 4257.6930653  4066.49292588]
total_rewards_mean           3763.45384244655
total_rewards_std            845.4459556012571
total_rewards_max            4257.693065296894
total_rewards_min            1253.1671801613886
Number of train steps total  483000
Number of env steps total    2417000
Number of rollouts total     0
Train Time (s)               29.0140719152987
(Previous) Eval Time (s)     19.06747209886089
Sample Time (s)              17.578498310409486
Epoch Time (s)               65.66004232456908
Total Train Time (s)         33321.37796348194
Epoch                        482
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:30:54.301464 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #482 | Epoch Duration: 71.32595205307007
2020-01-11 12:30:54.301682 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #482 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0802968
Z variance train             0.00670216
KL Divergence                25.40517
KL Loss                      2.540517
QF Loss                      2813.5781
VF Loss                      1438.3256
Policy Loss                  -1417.6515
Q Predictions Mean           1415.8965
Q Predictions Std            290.9385
Q Predictions Max            1711.5287
Q Predictions Min            -153.81549
V Predictions Mean           1398.355
V Predictions Std            273.19012
V Predictions Max            1656.633
V Predictions Min            -166.49287
Log Pis Mean                 1.2458309
Log Pis Std                  3.2003546
Log Pis Max                  12.814249
Log Pis Min                  -8.354951
Policy mu Mean               -0.03333135
Policy mu Std                0.6609124
Policy mu Max                2.1554234
Policy mu Min                -2.4156206
Policy log std Mean          -1.146707
Policy log std Std           0.35953853
Policy log std Max           -0.17787367
Policy log std Min           -3.2823286
Z mean eval                  1.1096561
Z variance eval              0.0136800725
total_rewards                [4208.61218553 4431.06060054 1576.26921526 4293.05063091 4244.65917788
 4050.00092131 4302.26078803 2411.40286012 4204.93994077 4144.06774329]
total_rewards_mean           3786.632406363221
total_rewards_std            920.572709272891
total_rewards_max            4431.06060053904
total_rewards_min            1576.269215259518
Number of train steps total  484000
Number of env steps total    2422000
Number of rollouts total     0
Train Time (s)               29.944017190951854
(Previous) Eval Time (s)     24.733140972908586
Sample Time (s)              17.702135547529906
Epoch Time (s)               72.37929371139035
Total Train Time (s)         33393.15673569264
Epoch                        483
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:32:06.084521 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #483 | Epoch Duration: 71.78266310691833
2020-01-11 12:32:06.084728 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #483 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1114986
Z variance train             0.013714636
KL Divergence                24.220306
KL Loss                      2.4220307
QF Loss                      1070.4568
VF Loss                      136.07944
Policy Loss                  -1438.1505
Q Predictions Mean           1438.7786
Q Predictions Std            293.5671
Q Predictions Max            1700.5991
Q Predictions Min            -155.04012
V Predictions Mean           1436.6805
V Predictions Std            295.56613
V Predictions Max            1704.8585
V Predictions Min            -173.01903
Log Pis Mean                 1.3341424
Log Pis Std                  2.6952674
Log Pis Max                  14.69828
Log Pis Min                  -6.672661
Policy mu Mean               0.031853974
Policy mu Std                0.6276978
Policy mu Max                2.4473016
Policy mu Min                -2.7921412
Policy log std Mean          -1.1418519
Policy log std Std           0.29366478
Policy log std Max           0.14551288
Policy log std Min           -2.5600498
Z mean eval                  1.1130182
Z variance eval              0.013901807
total_rewards                [ 804.42659323 3698.37576024 3966.2313157  2676.15232867 4311.33977343
 3916.5493089  4010.72357908 4077.72515747 4050.78167442 3971.45598689]
total_rewards_mean           3548.3761478050956
total_rewards_std            1006.4881881596499
total_rewards_max            4311.339773433449
total_rewards_min            804.4265932263553
Number of train steps total  485000
Number of env steps total    2427000
Number of rollouts total     0
Train Time (s)               29.412539281416684
(Previous) Eval Time (s)     24.136210462078452
Sample Time (s)              18.298324376810342
Epoch Time (s)               71.84707412030548
Total Train Time (s)         33465.16277015349
Epoch                        484
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:33:18.093612 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #484 | Epoch Duration: 72.00874137878418
2020-01-11 12:33:18.093809 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #484 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1141336
Z variance train             0.013896952
KL Divergence                24.535488
KL Loss                      2.453549
QF Loss                      9894.779
VF Loss                      166.90085
Policy Loss                  -1451.0151
Q Predictions Mean           1453.1466
Q Predictions Std            250.41092
Q Predictions Max            1703.9873
Q Predictions Min            -180.56985
V Predictions Mean           1447.6934
V Predictions Std            250.88667
V Predictions Max            1692.9551
V Predictions Min            -175.05003
Log Pis Mean                 1.3931208
Log Pis Std                  2.9386153
Log Pis Max                  14.040864
Log Pis Min                  -6.602315
Policy mu Mean               0.0574959
Policy mu Std                0.6947905
Policy mu Max                2.3787134
Policy mu Min                -2.5253036
Policy log std Mean          -1.0898321
Policy log std Std           0.30377394
Policy log std Max           -0.16034645
Policy log std Min           -2.7859464
Z mean eval                  1.1217114
Z variance eval              0.019466426
total_rewards                [ 752.25997715 3052.03078411 3203.27234122 4068.50575324 4035.00323429
 4403.20824488 4065.2804806  4103.76352232 4177.46387756 4112.97915655]
total_rewards_mean           3597.376737190396
total_rewards_std            1033.8260112682842
total_rewards_max            4403.208244876254
total_rewards_min            752.2599771494521
Number of train steps total  486000
Number of env steps total    2432000
Number of rollouts total     0
Train Time (s)               28.116910104174167
(Previous) Eval Time (s)     24.297570921014994
Sample Time (s)              19.283392790239304
Epoch Time (s)               71.69787381542847
Total Train Time (s)         33537.77947558276
Epoch                        485
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:34:30.717950 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #485 | Epoch Duration: 72.6239881515503
2020-01-11 12:34:30.718212 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #485 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1232127
Z variance train             0.019407276
KL Divergence                24.202202
KL Loss                      2.4202201
QF Loss                      1057.0497
VF Loss                      1158.6919
Policy Loss                  -1442.7122
Q Predictions Mean           1444.6566
Q Predictions Std            271.02686
Q Predictions Max            1742.3962
Q Predictions Min            -21.08833
V Predictions Mean           1441.086
V Predictions Std            255.48106
V Predictions Max            1721.53
V Predictions Min            -19.55438
Log Pis Mean                 0.9875421
Log Pis Std                  2.7649982
Log Pis Max                  12.350023
Log Pis Min                  -7.6221585
Policy mu Mean               0.012127451
Policy mu Std                0.6590996
Policy mu Max                2.3858285
Policy mu Min                -3.2104974
Policy log std Mean          -1.1245768
Policy log std Std           0.2853122
Policy log std Max           -0.24342048
Policy log std Min           -2.7419662
Z mean eval                  1.0946577
Z variance eval              0.012501514
total_rewards                [ 468.41699052  551.30603803 2643.49362351  962.98602885  677.01526646
 1257.85670175 2210.447277   1489.61637202 3505.17072883 1771.22048668]
total_rewards_mean           1553.7529513651182
total_rewards_std            941.610440637622
total_rewards_max            3505.170728831945
total_rewards_min            468.4169905175479
Number of train steps total  487000
Number of env steps total    2437000
Number of rollouts total     0
Train Time (s)               27.835128653794527
(Previous) Eval Time (s)     25.22331763105467
Sample Time (s)              17.977629062253982
Epoch Time (s)               71.03607534710318
Total Train Time (s)         33596.844768245704
Epoch                        486
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:35:29.786950 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #486 | Epoch Duration: 59.0685510635376
2020-01-11 12:35:29.787146 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #486 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0957366
Z variance train             0.012535
KL Divergence                24.916382
KL Loss                      2.4916382
QF Loss                      1325.5261
VF Loss                      320.01367
Policy Loss                  -1475.995
Q Predictions Mean           1482.0227
Q Predictions Std            167.689
Q Predictions Max            1688.6356
Q Predictions Min            -169.15152
V Predictions Mean           1481.2493
V Predictions Std            175.56625
V Predictions Max            1685.2562
V Predictions Min            -166.69162
Log Pis Mean                 1.3240993
Log Pis Std                  2.8655946
Log Pis Max                  12.349484
Log Pis Min                  -6.5922737
Policy mu Mean               0.016073518
Policy mu Std                0.64880073
Policy mu Max                2.7262232
Policy mu Min                -2.6846528
Policy log std Mean          -1.1191411
Policy log std Std           0.28709942
Policy log std Max           0.27409816
Policy log std Min           -3.0673928
Z mean eval                  1.1053767
Z variance eval              0.015446566
total_rewards                [-436.81462456 4260.32247499 4323.3137648  4497.01216327 1908.13887629
 4014.89118184 4239.99227476 4337.05721173 4218.48223976 4263.61464065]
total_rewards_mean           3562.601020353777
total_rewards_std            1511.8201527505094
total_rewards_max            4497.012163272899
total_rewards_min            -436.8146245589408
Number of train steps total  488000
Number of env steps total    2442000
Number of rollouts total     0
Train Time (s)               28.442349520977587
(Previous) Eval Time (s)     13.255476486869156
Sample Time (s)              17.37741124536842
Epoch Time (s)               59.075237253215164
Total Train Time (s)         33669.69417888485
Epoch                        487
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:36:42.640609 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #487 | Epoch Duration: 72.85332560539246
2020-01-11 12:36:42.640814 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #487 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1057508
Z variance train             0.015409015
KL Divergence                25.02864
KL Loss                      2.5028641
QF Loss                      1248.1443
VF Loss                      198.30652
Policy Loss                  -1459.2079
Q Predictions Mean           1460.3378
Q Predictions Std            259.83926
Q Predictions Max            1700.3923
Q Predictions Min            -91.866936
V Predictions Mean           1453.0314
V Predictions Std            259.41376
V Predictions Max            1682.3307
V Predictions Min            -100.61279
Log Pis Mean                 1.2841518
Log Pis Std                  2.837566
Log Pis Max                  12.6067505
Log Pis Min                  -9.545532
Policy mu Mean               0.020438377
Policy mu Std                0.60606855
Policy mu Max                2.7399116
Policy mu Min                -2.488078
Policy log std Mean          -1.1790707
Policy log std Std           0.2722815
Policy log std Max           -0.18491024
Policy log std Min           -2.4086657
Z mean eval                  1.1055573
Z variance eval              0.017757269
total_rewards                [3312.25679373 3906.79504927 4124.09105875 3937.01149705 3919.46774582
 4178.0131431  4366.89242756  662.48185541 4420.95131881 4305.04732166]
total_rewards_mean           3713.3008211160327
total_rewards_std            1061.185434052765
total_rewards_max            4420.951318811538
total_rewards_min            662.4818554089431
Number of train steps total  489000
Number of env steps total    2447000
Number of rollouts total     0
Train Time (s)               28.901309906039387
(Previous) Eval Time (s)     27.033226512372494
Sample Time (s)              18.370590719394386
Epoch Time (s)               74.30512713780627
Total Train Time (s)         33741.66654687701
Epoch                        488
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:37:54.617027 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #488 | Epoch Duration: 71.97605276107788
2020-01-11 12:37:54.617224 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #488 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1040742
Z variance train             0.017813776
KL Divergence                24.577076
KL Loss                      2.4577076
QF Loss                      2269.0188
VF Loss                      4164.1904
Policy Loss                  -1431.8256
Q Predictions Mean           1438.1992
Q Predictions Std            254.82487
Q Predictions Max            1670.6847
Q Predictions Min            -81.22055
V Predictions Mean           1441.9033
V Predictions Std            248.83348
V Predictions Max            1679.3672
V Predictions Min            -97.64046
Log Pis Mean                 1.3888221
Log Pis Std                  2.7849426
Log Pis Max                  13.410122
Log Pis Min                  -5.0145836
Policy mu Mean               -0.017878374
Policy mu Std                0.62945235
Policy mu Max                2.4925718
Policy mu Min                -2.9662433
Policy log std Mean          -1.1650801
Policy log std Std           0.31618568
Policy log std Max           -0.24219388
Policy log std Min           -3.014251
Z mean eval                  1.1133326
Z variance eval              0.010957731
total_rewards                [3276.27806276 4415.43609024 4127.65900312 3984.71721426 4141.03714755
 4229.6033337  4171.19069618 4246.98679689 4183.32067589 4203.66186459]
total_rewards_mean           4097.9890885180785
total_rewards_std            292.38243498463066
total_rewards_max            4415.436090240758
total_rewards_min            3276.278062760594
Number of train steps total  490000
Number of env steps total    2452000
Number of rollouts total     0
Train Time (s)               27.05145596107468
(Previous) Eval Time (s)     24.703821287024766
Sample Time (s)              18.60927166696638
Epoch Time (s)               70.36454891506582
Total Train Time (s)         33813.634041879326
Epoch                        489
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:39:06.591093 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #489 | Epoch Duration: 71.97371006011963
2020-01-11 12:39:06.591374 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #489 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1150217
Z variance train             0.010946744
KL Divergence                25.305567
KL Loss                      2.5305567
QF Loss                      1280.8934
VF Loss                      311.98245
Policy Loss                  -1435.8699
Q Predictions Mean           1439.2888
Q Predictions Std            282.64246
Q Predictions Max            1689.3673
Q Predictions Min            -145.71794
V Predictions Mean           1443.7751
V Predictions Std            280.8516
V Predictions Max            1691.7933
V Predictions Min            -158.51271
Log Pis Mean                 1.3685973
Log Pis Std                  3.478603
Log Pis Max                  14.360147
Log Pis Min                  -6.961455
Policy mu Mean               0.0039899885
Policy mu Std                0.679891
Policy mu Max                3.7421637
Policy mu Min                -2.9594142
Policy log std Mean          -1.133788
Policy log std Std           0.32833862
Policy log std Max           -0.15967977
Policy log std Min           -3.6450353
Z mean eval                  1.0661113
Z variance eval              0.015726838
total_rewards                [  59.48381614  183.24519295  324.38468251 4174.23465273 1408.36302088
 1573.48193138 4400.15258745 4415.43008036 4352.29920341 2177.2537547 ]
total_rewards_mean           2306.832892251047
total_rewards_std            1770.633705721388
total_rewards_max            4415.430080355292
total_rewards_min            59.48381614172621
Number of train steps total  491000
Number of env steps total    2457000
Number of rollouts total     0
Train Time (s)               27.687461069319397
(Previous) Eval Time (s)     26.312673488166183
Sample Time (s)              17.78615897987038
Epoch Time (s)               71.78629353735596
Total Train Time (s)         33873.713576219976
Epoch                        490
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:40:06.675408 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #490 | Epoch Duration: 60.08383131027222
2020-01-11 12:40:06.675624 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #490 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0609003
Z variance train             0.0156971
KL Divergence                24.842596
KL Loss                      2.4842596
QF Loss                      5029.1987
VF Loss                      327.20206
Policy Loss                  -1442.7211
Q Predictions Mean           1441.009
Q Predictions Std            291.07266
Q Predictions Max            1739.5938
Q Predictions Min            -178.76244
V Predictions Mean           1433.8422
V Predictions Std            278.7975
V Predictions Max            1723.3503
V Predictions Min            -181.58476
Log Pis Mean                 1.0694364
Log Pis Std                  3.1314178
Log Pis Max                  10.334375
Log Pis Min                  -9.830943
Policy mu Mean               0.008243624
Policy mu Std                0.68818647
Policy mu Max                2.3631663
Policy mu Min                -2.524964
Policy log std Mean          -1.0911014
Policy log std Std           0.30494276
Policy log std Max           -0.14406204
Policy log std Min           -2.9145875
Z mean eval                  1.0869224
Z variance eval              0.015996803
total_rewards                [-256.43604516 4089.31431488 4287.74213106 4240.48141303 1882.95631387
 4080.28949846 4319.16449125 4356.67586645 4122.61355438 3878.96195623]
total_rewards_mean           3500.1763494450083
total_rewards_std            1432.29547200609
total_rewards_max            4356.675866453765
total_rewards_min            -256.4360451555361
Number of train steps total  492000
Number of env steps total    2462000
Number of rollouts total     0
Train Time (s)               29.393980970606208
(Previous) Eval Time (s)     14.609940426889807
Sample Time (s)              18.542811776977032
Epoch Time (s)               62.54673317447305
Total Train Time (s)         33947.05913821235
Epoch                        491
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:41:20.027274 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #491 | Epoch Duration: 73.35148310661316
2020-01-11 12:41:20.027486 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #491 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0855248
Z variance train             0.015994256
KL Divergence                24.639996
KL Loss                      2.4639995
QF Loss                      3696.1345
VF Loss                      602.2471
Policy Loss                  -1448.6556
Q Predictions Mean           1454.0519
Q Predictions Std            221.72644
Q Predictions Max            1714.1698
Q Predictions Min            -110.86534
V Predictions Mean           1457.3813
V Predictions Std            223.85513
V Predictions Max            1725.4843
V Predictions Min            -102.958984
Log Pis Mean                 1.3229294
Log Pis Std                  3.1352637
Log Pis Max                  16.007627
Log Pis Min                  -8.317493
Policy mu Mean               -0.011960284
Policy mu Std                0.6413033
Policy mu Max                2.6377783
Policy mu Min                -2.7738397
Policy log std Mean          -1.1644664
Policy log std Std           0.3044484
Policy log std Max           -0.20914733
Policy log std Min           -3.2473183
Z mean eval                  1.1286333
Z variance eval              0.014574741
total_rewards                [2920.06344242 2149.39719477  257.92974434  909.90350657 1765.96472982
 4176.26377767 4301.55240915 4112.05871818 4323.3074955  3509.83268175]
total_rewards_mean           2842.6273700170573
total_rewards_std            1421.8977128428157
total_rewards_max            4323.307495504567
total_rewards_min            257.92974433506186
Number of train steps total  493000
Number of env steps total    2467000
Number of rollouts total     0
Train Time (s)               30.095478967297822
(Previous) Eval Time (s)     25.41437919717282
Sample Time (s)              18.45961653534323
Epoch Time (s)               73.96947469981387
Total Train Time (s)         34014.689897655975
Epoch                        492
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:42:27.662353 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #492 | Epoch Duration: 67.63468885421753
2020-01-11 12:42:27.662573 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #492 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1323432
Z variance train             0.01460751
KL Divergence                24.074871
KL Loss                      2.4074872
QF Loss                      1165.4233
VF Loss                      812.247
Policy Loss                  -1430.3955
Q Predictions Mean           1440.1211
Q Predictions Std            277.05148
Q Predictions Max            1696.2183
Q Predictions Min            -102.284035
V Predictions Mean           1452.9312
V Predictions Std            278.64417
V Predictions Max            1716.7242
V Predictions Min            -120.56452
Log Pis Mean                 1.7050464
Log Pis Std                  3.3117464
Log Pis Max                  11.06378
Log Pis Min                  -7.005249
Policy mu Mean               0.03083559
Policy mu Std                0.6853119
Policy mu Max                2.9885352
Policy mu Min                -2.6564445
Policy log std Mean          -1.1327145
Policy log std Std           0.3026009
Policy log std Max           -0.07936418
Policy log std Min           -2.8049047
Z mean eval                  1.1144571
Z variance eval              0.015373772
total_rewards                [  66.96758692 1446.21327899 4248.66114199 3999.10949942 4062.94347384
 4023.49663504 4000.46035233 4002.71364806  388.93667657  113.55727902]
total_rewards_mean           2635.3059572172233
total_rewards_std            1776.9986586680286
total_rewards_max            4248.661141987236
total_rewards_min            66.96758691736474
Number of train steps total  494000
Number of env steps total    2472000
Number of rollouts total     0
Train Time (s)               27.271153992041945
(Previous) Eval Time (s)     19.079284687992185
Sample Time (s)              18.135179007425904
Epoch Time (s)               64.48561768746004
Total Train Time (s)         34079.70595659455
Epoch                        493
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:43:32.685250 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #493 | Epoch Duration: 65.02249455451965
2020-01-11 12:43:32.685515 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #493 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1146961
Z variance train             0.015422797
KL Divergence                24.466633
KL Loss                      2.4466634
QF Loss                      1573.8463
VF Loss                      181.706
Policy Loss                  -1474.2594
Q Predictions Mean           1474.5181
Q Predictions Std            233.91371
Q Predictions Max            1711.9348
Q Predictions Min            -180.26508
V Predictions Mean           1469.099
V Predictions Std            232.29979
V Predictions Max            1692.1642
V Predictions Min            -187.54819
Log Pis Mean                 1.2872167
Log Pis Std                  2.8596714
Log Pis Max                  11.122182
Log Pis Min                  -11.739807
Policy mu Mean               -0.029856797
Policy mu Std                0.6813471
Policy mu Max                2.6876042
Policy mu Min                -2.6091104
Policy log std Mean          -1.1216154
Policy log std Std           0.27951136
Policy log std Max           -0.26656306
Policy log std Min           -2.753796
Z mean eval                  1.096267
Z variance eval              0.016136786
total_rewards                [4125.72144555 1982.6727573  4118.10715584 3597.41102199 4393.4622796
 3933.73895036 4278.50291422 2647.78562585  857.56330223 3848.7106521 ]
total_rewards_mean           3378.367610505783
total_rewards_std            1111.7653322578353
total_rewards_max            4393.462279599347
total_rewards_min            857.5633022335265
Number of train steps total  495000
Number of env steps total    2477000
Number of rollouts total     0
Train Time (s)               29.08241142798215
(Previous) Eval Time (s)     19.615814849734306
Sample Time (s)              18.28069697925821
Epoch Time (s)               66.97892325697467
Total Train Time (s)         34150.35591925867
Epoch                        494
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:44:43.338808 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #494 | Epoch Duration: 70.65308833122253
2020-01-11 12:44:43.338989 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #494 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0953944
Z variance train             0.01613817
KL Divergence                23.657768
KL Loss                      2.3657768
QF Loss                      4141.289
VF Loss                      306.1309
Policy Loss                  -1449.1353
Q Predictions Mean           1449.2781
Q Predictions Std            279.42792
Q Predictions Max            1717.3751
Q Predictions Min            -148.0887
V Predictions Mean           1453.9048
V Predictions Std            271.47906
V Predictions Max            1714.1295
V Predictions Min            -160.08961
Log Pis Mean                 1.3426652
Log Pis Std                  3.104988
Log Pis Max                  15.601167
Log Pis Min                  -6.5120053
Policy mu Mean               0.031179521
Policy mu Std                0.6874385
Policy mu Max                2.526304
Policy mu Min                -2.5346053
Policy log std Mean          -1.1232705
Policy log std Std           0.32412195
Policy log std Max           -0.0070174932
Policy log std Min           -3.4105883
Z mean eval                  1.1064596
Z variance eval              0.013880497
total_rewards                [1639.86458838 3754.71821429  705.72784727 4357.77981184  377.58213034
 3998.62679941  452.91382553 1993.88618653 2822.78415352  756.1319642 ]
total_rewards_mean           2086.001552131019
total_rewards_std            1470.1523796485696
total_rewards_max            4357.77981183523
total_rewards_min            377.58213033579636
Number of train steps total  496000
Number of env steps total    2482000
Number of rollouts total     0
Train Time (s)               29.31776504823938
(Previous) Eval Time (s)     23.28965786099434
Sample Time (s)              17.360641956329346
Epoch Time (s)               69.96806486556306
Total Train Time (s)         34212.23774310341
Epoch                        495
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:45:45.223632 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #495 | Epoch Duration: 61.88451814651489
2020-01-11 12:45:45.223825 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #495 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1032937
Z variance train             0.013884759
KL Divergence                23.264475
KL Loss                      2.3264475
QF Loss                      681.54034
VF Loss                      298.12137
Policy Loss                  -1452.1669
Q Predictions Mean           1454.565
Q Predictions Std            306.93744
Q Predictions Max            1758.0676
Q Predictions Min            -156.40187
V Predictions Mean           1458.2385
V Predictions Std            310.82037
V Predictions Max            1757.5481
V Predictions Min            -177.04648
Log Pis Mean                 0.8984075
Log Pis Std                  3.0739744
Log Pis Max                  22.380634
Log Pis Min                  -9.804909
Policy mu Mean               0.01914366
Policy mu Std                0.62419915
Policy mu Max                3.7415545
Policy mu Min                -3.6855998
Policy log std Mean          -1.1202481
Policy log std Std           0.27146268
Policy log std Max           -0.015740514
Policy log std Min           -2.374764
Z mean eval                  1.0825357
Z variance eval              0.011485802
total_rewards                [4202.5817434  3982.82571725 4318.47184146 4232.70817713 2992.67371408
  496.62525447 4360.73221024 4278.57960162 3830.72028499 4278.47607175]
total_rewards_mean           3697.439461639099
total_rewards_std            1135.066634819487
total_rewards_max            4360.732210244198
total_rewards_min            496.6252544738023
Number of train steps total  497000
Number of env steps total    2487000
Number of rollouts total     0
Train Time (s)               28.453459286130965
(Previous) Eval Time (s)     15.205836148001254
Sample Time (s)              17.568538256455213
Epoch Time (s)               61.22783369058743
Total Train Time (s)         34282.396210735664
Epoch                        496
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:46:55.387880 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #496 | Epoch Duration: 70.16389036178589
2020-01-11 12:46:55.388096 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #496 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0818151
Z variance train             0.011491814
KL Divergence                23.42836
KL Loss                      2.3428361
QF Loss                      961.81274
VF Loss                      294.57678
Policy Loss                  -1448.4924
Q Predictions Mean           1449.841
Q Predictions Std            314.95374
Q Predictions Max            1700.3704
Q Predictions Min            -186.17683
V Predictions Mean           1437.8342
V Predictions Std            311.00812
V Predictions Max            1688.1814
V Predictions Min            -183.1864
Log Pis Mean                 1.1721553
Log Pis Std                  2.876304
Log Pis Max                  12.098468
Log Pis Min                  -6.491576
Policy mu Mean               -0.015779713
Policy mu Std                0.6615643
Policy mu Max                2.3823256
Policy mu Min                -2.928328
Policy log std Mean          -1.1262548
Policy log std Std           0.3084362
Policy log std Max           0.18565094
Policy log std Min           -2.9071143
Z mean eval                  1.0732399
Z variance eval              0.0135027915
total_rewards                [2021.50367744 3687.86773493 4442.33245658 3935.32984139 1546.24478928
 1203.02544088 4269.40423461 4061.50701354 4284.51274715 3962.10072086]
total_rewards_mean           3341.382865666129
total_rewards_std            1177.9930439507443
total_rewards_max            4442.332456580016
total_rewards_min            1203.0254408822818
Number of train steps total  498000
Number of env steps total    2492000
Number of rollouts total     0
Train Time (s)               30.265296548139304
(Previous) Eval Time (s)     24.141571772750467
Sample Time (s)              18.53913795016706
Epoch Time (s)               72.94600627105683
Total Train Time (s)         34353.31686219899
Epoch                        497
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:48:06.316140 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #497 | Epoch Duration: 70.9278495311737
2020-01-11 12:48:06.316447 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #497 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0737077
Z variance train             0.013550131
KL Divergence                23.210188
KL Loss                      2.321019
QF Loss                      3396.574
VF Loss                      344.02045
Policy Loss                  -1480.9948
Q Predictions Mean           1476.8563
Q Predictions Std            236.56741
Q Predictions Max            1717.7396
Q Predictions Min            -57.84755
V Predictions Mean           1488.6455
V Predictions Std            236.4618
V Predictions Max            1721.7397
V Predictions Min            -50.752785
Log Pis Mean                 1.1311063
Log Pis Std                  2.691512
Log Pis Max                  13.751603
Log Pis Min                  -6.0352316
Policy mu Mean               0.04538966
Policy mu Std                0.6391178
Policy mu Max                2.471516
Policy mu Min                -2.1431699
Policy log std Mean          -1.1173544
Policy log std Std           0.27723876
Policy log std Max           -0.07681805
Policy log std Min           -2.582728
Z mean eval                  1.1090715
Z variance eval              0.0136579005
total_rewards                [4120.36526797  338.2086358    51.565036   4442.38049794 4286.84924655
 4355.77260933 4023.5185045  2013.08553919 1443.520258   2897.08960279]
total_rewards_mean           2797.2355198082305
total_rewards_std            1632.5396737708086
total_rewards_max            4442.380497939565
total_rewards_min            51.565036004265295
Number of train steps total  499000
Number of env steps total    2497000
Number of rollouts total     0
Train Time (s)               28.477032056078315
(Previous) Eval Time (s)     22.123059257864952
Sample Time (s)              18.409235399216413
Epoch Time (s)               69.00932671315968
Total Train Time (s)         34417.90384353185
Epoch                        498
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:49:10.906408 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #498 | Epoch Duration: 64.58974361419678
2020-01-11 12:49:10.906605 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #498 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1098732
Z variance train             0.013690946
KL Divergence                23.417347
KL Loss                      2.3417346
QF Loss                      1243.1134
VF Loss                      443.50027
Policy Loss                  -1442.0519
Q Predictions Mean           1444.4299
Q Predictions Std            312.15576
Q Predictions Max            1702.4149
Q Predictions Min            -173.77846
V Predictions Mean           1444.3555
V Predictions Std            312.5458
V Predictions Max            1687.3232
V Predictions Min            -152.64632
Log Pis Mean                 1.1355234
Log Pis Std                  3.0862954
Log Pis Max                  19.582691
Log Pis Min                  -5.8629146
Policy mu Mean               0.030488227
Policy mu Std                0.677351
Policy mu Max                2.688716
Policy mu Min                -3.8824525
Policy log std Mean          -1.1297982
Policy log std Std           0.29843125
Policy log std Max           0.03255385
Policy log std Min           -2.3824143
Z mean eval                  1.0654815
Z variance eval              0.015748149
total_rewards                [4031.39987836 4172.4372509  4184.69555434 1718.77408503 4360.29541029
 4007.55896226 4263.67121723 4603.97948086  273.0495862  4243.55285882]
total_rewards_mean           3585.941428429932
total_rewards_std            1344.1741219233897
total_rewards_max            4603.9794808550105
total_rewards_min            273.0495862022335
Number of train steps total  500000
Number of env steps total    2502000
Number of rollouts total     0
Train Time (s)               30.99252194399014
(Previous) Eval Time (s)     17.70316989487037
Sample Time (s)              18.501530637033284
Epoch Time (s)               67.1972224758938
Total Train Time (s)         34492.88838833338
Epoch                        499
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:50:25.898525 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #499 | Epoch Duration: 74.99175214767456
2020-01-11 12:50:25.898810 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #499 | Started Training: True
2020-01-11 12:50:26.519091 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Variant:
2020-01-11 12:50:26.519463 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] {
  "env_name": "Hopper-v2",
  "n_train_tasks": 1,
  "n_eval_tasks": 1,
  "latent_size": 5,
  "net_size": 300,
  "path_to_weights": null,
  "env_params": {
    "n_tasks": 2,
    "randomize_tasks": true
  },
  "algo_params": {
    "meta_batch": 1,
    "num_iterations": 500,
    "num_initial_steps": 2000,
    "num_tasks_sample": 5,
    "num_steps_prior": 400,
    "num_steps_posterior": 0,
    "num_extra_rl_steps_posterior": 600,
    "num_train_steps_per_itr": 1000,
    "num_evals": 2,
    "num_steps_per_eval": 600,
    "batch_size": 256,
    "embedding_batch_size": 20,
    "embedding_mini_batch_size": 20,
    "max_path_length": 200,
    "discount": 0.99,
    "soft_target_tau": 0.005,
    "policy_lr": 0.0003,
    "qf_lr": 0.0003,
    "vf_lr": 0.0003,
    "context_lr": 0.0003,
    "reward_scale": 5.0,
    "sparse_rewards": false,
    "kl_lambda": 0.1,
    "use_information_bottleneck": true,
    "use_next_obs_in_context": false,
    "update_post_train": 1,
    "num_exp_traj_eval": 2,
    "recurrent": true,
    "dump_eval_paths": false
  },
  "util_params": {
    "base_log_dir": "./test/train1000/H-20",
    "use_gpu": true,
    "gpu_id": 0,
    "debug": false,
    "docker": false,
    "num_iterations": 1000
  }
}
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0019376408
Z variance train             0.693145
KL Divergence                0.14916778
KL Loss                      0.014916778
QF Loss                      70.34567
VF Loss                      4.4341574
Policy Loss                  -2.079393
Q Predictions Mean           -0.0023045375
Q Predictions Std            0.0010986081
Q Predictions Max            0.0017850115
Q Predictions Min            -0.0054990025
V Predictions Mean           0.00880776
V Predictions Std            0.0014018345
V Predictions Max            0.013202997
V Predictions Min            0.0060151126
Log Pis Mean                 -2.0737145
Log Pis Std                  0.3831366
Log Pis Max                  -0.82241416
Log Pis Min                  -3.171927
Policy mu Mean               3.8408183e-05
Policy mu Std                0.0009007452
Policy mu Max                0.001969648
Policy mu Min                -0.00234535
Policy log std Mean          -0.0005568333
Policy log std Std           0.0011438006
Policy log std Max           0.001831908
Policy log std Min           -0.0030535706
Z mean eval                  0.005756306
Z variance eval              0.674224
total_rewards                [ 61.38693623 113.01327395 116.02390092  78.44867491  73.2734333
 150.57021339  74.81610569  67.92799259 137.92069701  73.75640018]
total_rewards_mean           94.71376281701069
total_rewards_std            30.270942841517652
total_rewards_max            150.5702133908658
total_rewards_min            61.38693623112616
Number of train steps total  1000
Number of env steps total    7000
Number of rollouts total     0
Train Time (s)               23.39730157610029
(Previous) Eval Time (s)     0
Sample Time (s)              15.17737470054999
Epoch Time (s)               38.57467627665028
Total Train Time (s)         39.968701692763716
Epoch                        0
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:51:06.575276 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #0 | Epoch Duration: 39.97466492652893
2020-01-11 12:51:06.575542 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #0 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0069435285
Z variance train             0.67628586
KL Divergence                0.16881907
KL Loss                      0.016881907
QF Loss                      85.0119
VF Loss                      1.4627635
Policy Loss                  -10.905362
Q Predictions Mean           10.007549
Q Predictions Std            8.671779
Q Predictions Max            34.86257
Q Predictions Min            -6.73171
V Predictions Mean           11.5984535
V Predictions Std            8.22942
V Predictions Max            35.272766
V Predictions Min            -3.3859167
Log Pis Mean                 -1.920514
Log Pis Std                  0.50672823
Log Pis Max                  -0.3085872
Log Pis Min                  -3.628249
Policy mu Mean               0.117926694
Policy mu Std                0.2027278
Policy mu Max                0.4952334
Policy mu Min                -0.24866314
Policy log std Mean          -0.16378818
Policy log std Std           0.025983334
Policy log std Max           -0.101779826
Policy log std Min           -0.23183076
Z mean eval                  0.092427224
Z variance eval              0.22269996
total_rewards                [ 88.31661483 160.34940943 199.30750984  95.68465525 175.6756274
 112.24698586 136.9068843   55.84862928  52.47216383  77.45470909]
total_rewards_mean           115.42631891163653
total_rewards_std            48.202572036849375
total_rewards_max            199.30750984122517
total_rewards_min            52.47216383346039
Number of train steps total  2000
Number of env steps total    12000
Number of rollouts total     0
Train Time (s)               25.518305903766304
(Previous) Eval Time (s)     1.3997573098167777
Sample Time (s)              11.710441849660128
Epoch Time (s)               38.62850506324321
Total Train Time (s)         78.6954736080952
Epoch                        1
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:51:45.304851 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #1 | Epoch Duration: 38.72908687591553
2020-01-11 12:51:45.305136 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #1 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0934286
Z variance train             0.22231428
KL Divergence                1.8811272
KL Loss                      0.18811272
QF Loss                      36.145943
VF Loss                      3.5269725
Policy Loss                  -17.406351
Q Predictions Mean           15.449587
Q Predictions Std            16.395124
Q Predictions Max            67.51149
Q Predictions Min            -5.86962
V Predictions Mean           18.184551
V Predictions Std            16.13917
V Predictions Max            68.73525
V Predictions Min            -1.3462957
Log Pis Mean                 -1.8057686
Log Pis Std                  0.76702154
Log Pis Max                  1.3376659
Log Pis Min                  -3.7438653
Policy mu Mean               0.12421521
Policy mu Std                0.31657064
Policy mu Max                1.3321635
Policy mu Min                -0.33710226
Policy log std Mean          -0.1883903
Policy log std Std           0.10197929
Policy log std Max           -0.09061712
Policy log std Min           -0.5328781
Z mean eval                  0.060991425
Z variance eval              0.08260755
total_rewards                [198.45948536 203.83292039 187.31556748 197.42140996 187.39513631
 197.72362659 189.36371706 189.8156448  210.07286065 192.93700859]
total_rewards_mean           195.43373771996409
total_rewards_std            7.129974377300457
total_rewards_max            210.0728606465592
total_rewards_min            187.31556748001643
Number of train steps total  3000
Number of env steps total    17000
Number of rollouts total     0
Train Time (s)               25.6551773683168
(Previous) Eval Time (s)     1.500083340331912
Sample Time (s)              11.460345430765301
Epoch Time (s)               38.61560613941401
Total Train Time (s)         117.88746403809637
Epoch                        2
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:52:24.495236 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #2 | Epoch Duration: 39.18991160392761
2020-01-11 12:52:24.495435 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #2 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06522969
Z variance train             0.07827815
KL Divergence                4.0949674
KL Loss                      0.40949675
QF Loss                      41.060658
VF Loss                      30.66106
Policy Loss                  -24.804773
Q Predictions Mean           22.588032
Q Predictions Std            28.951641
Q Predictions Max            106.101166
Q Predictions Min            -2.1414497
V Predictions Mean           26.636106
V Predictions Std            32.089897
V Predictions Max            126.92295
V Predictions Min            -0.38471577
Log Pis Mean                 -1.7094694
Log Pis Std                  0.88051796
Log Pis Max                  2.426793
Log Pis Min                  -3.8710275
Policy mu Mean               0.021276304
Policy mu Std                0.36924258
Policy mu Max                1.6513544
Policy mu Min                -1.6084194
Policy log std Mean          -0.21116179
Policy log std Std           0.13883194
Policy log std Max           -0.0946959
Policy log std Min           -0.5879069
Z mean eval                  0.032008044
Z variance eval              0.03112787
total_rewards                [180.78277111 189.04334453 204.47166565 188.49249267 192.99342232
 188.41003375 200.60154835 190.37501448 197.51156167 195.99486851]
total_rewards_mean           192.86767230346985
total_rewards_std            6.570561461927455
total_rewards_max            204.4716656525169
total_rewards_min            180.78277110732273
Number of train steps total  4000
Number of env steps total    22000
Number of rollouts total     0
Train Time (s)               27.21719363378361
(Previous) Eval Time (s)     2.0741261886432767
Sample Time (s)              12.083760148379952
Epoch Time (s)               41.37507997080684
Total Train Time (s)         159.18084556423128
Epoch                        3
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:53:05.788779 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #3 | Epoch Duration: 41.293190479278564
2020-01-11 12:53:05.788970 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #3 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030359143
Z variance train             0.030940836
KL Divergence                6.3432026
KL Loss                      0.63432026
QF Loss                      30.265991
VF Loss                      9.992334
Policy Loss                  -42.422386
Q Predictions Mean           40.724205
Q Predictions Std            53.15372
Q Predictions Max            156.76782
Q Predictions Min            -4.8803844
V Predictions Mean           42.86013
V Predictions Std            53.4645
V Predictions Max            155.05243
V Predictions Min            -3.3447578
Log Pis Mean                 -1.4440154
Log Pis Std                  1.2674633
Log Pis Max                  4.5372353
Log Pis Min                  -3.9453616
Policy mu Mean               0.102510355
Policy mu Std                0.45624965
Policy mu Max                1.8393766
Policy mu Min                -1.8420365
Policy log std Mean          -0.26759928
Policy log std Std           0.20277216
Policy log std Max           -0.09863521
Policy log std Min           -0.70077074
Z mean eval                  0.031311277
Z variance eval              0.022602836
total_rewards                [192.82131874 196.90224099 199.67523725 189.05397271 198.24569968
 198.60206488 200.44821929 198.44775624 203.69860915 198.32021479]
total_rewards_mean           197.6215333708532
total_rewards_std            3.855166224528826
total_rewards_max            203.69860914767688
total_rewards_min            189.0539727062519
Number of train steps total  5000
Number of env steps total    27000
Number of rollouts total     0
Train Time (s)               28.47028563497588
(Previous) Eval Time (s)     1.991987959947437
Sample Time (s)              11.839425818994641
Epoch Time (s)               42.30169941391796
Total Train Time (s)         201.6900160573423
Epoch                        4
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:53:48.298723 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #4 | Epoch Duration: 42.509634017944336
2020-01-11 12:53:48.298891 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #4 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032603692
Z variance train             0.023442317
KL Divergence                7.02439
KL Loss                      0.702439
QF Loss                      74.19501
VF Loss                      12.818774
Policy Loss                  -61.690372
Q Predictions Mean           57.907906
Q Predictions Std            76.58031
Q Predictions Max            212.05153
Q Predictions Min            -3.6894991
V Predictions Mean           62.38302
V Predictions Std            77.89921
V Predictions Max            217.8136
V Predictions Min            -0.5535821
Log Pis Mean                 -1.3470914
Log Pis Std                  1.4546258
Log Pis Max                  6.6066985
Log Pis Min                  -3.5449965
Policy mu Mean               0.16581637
Policy mu Std                0.5069017
Policy mu Max                1.9460552
Policy mu Min                -2.256291
Policy log std Mean          -0.25565633
Policy log std Std           0.18732595
Policy log std Max           -0.10720019
Policy log std Min           -0.7820875
Z mean eval                  0.02878862
Z variance eval              0.0120406505
total_rewards                [294.78041485 304.08688073 312.75780315 299.14772629 310.14076885
 291.44787437 272.73195521 310.42914091 299.13162923 320.99124901]
total_rewards_mean           301.5645442612796
total_rewards_std            12.85546764143108
total_rewards_max            320.9912490149272
total_rewards_min            272.7319552136012
Number of train steps total  6000
Number of env steps total    32000
Number of rollouts total     0
Train Time (s)               27.70890953578055
(Previous) Eval Time (s)     2.1996500520035625
Sample Time (s)              13.135116294026375
Epoch Time (s)               43.043675881810486
Total Train Time (s)         246.08506594831124
Epoch                        5
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:54:32.695850 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #5 | Epoch Duration: 44.39677286148071
2020-01-11 12:54:32.696105 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #5 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028875506
Z variance train             0.012045466
KL Divergence                8.691999
KL Loss                      0.86919993
QF Loss                      61.950325
VF Loss                      22.923607
Policy Loss                  -85.095345
Q Predictions Mean           81.8862
Q Predictions Std            103.764244
Q Predictions Max            294.81274
Q Predictions Min            -5.376377
V Predictions Mean           86.883446
V Predictions Std            105.73498
V Predictions Max            298.95236
V Predictions Min            -1.424462
Log Pis Mean                 -1.4129854
Log Pis Std                  1.2774708
Log Pis Max                  5.8679495
Log Pis Min                  -4.5652566
Policy mu Mean               0.06769366
Policy mu Std                0.5012553
Policy mu Max                1.9583457
Policy mu Min                -2.1375446
Policy log std Mean          -0.2719567
Policy log std Std           0.20646518
Policy log std Max           -0.0152181685
Policy log std Min           -0.8507292
Z mean eval                  0.016350104
Z variance eval              0.007268662
total_rewards                [264.79057149 245.25071421 266.49339144 268.61445574 238.48052616
 263.84042937 261.13604042 254.1292542  255.26481632 260.27773127]
total_rewards_mean           257.8277930612465
total_rewards_std            9.196581714246058
total_rewards_max            268.61445573958133
total_rewards_min            238.48052615707937
Number of train steps total  7000
Number of env steps total    37000
Number of rollouts total     0
Train Time (s)               27.022027054335922
(Previous) Eval Time (s)     3.5524652749300003
Sample Time (s)              13.672847895883024
Epoch Time (s)               44.247340225148946
Total Train Time (s)         289.5073096798733
Epoch                        6
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:55:16.120486 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #6 | Epoch Duration: 43.42418098449707
2020-01-11 12:55:16.120768 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #6 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017883731
Z variance train             0.007342607
KL Divergence                9.9297905
KL Loss                      0.99297905
QF Loss                      313.59778
VF Loss                      34.392918
Policy Loss                  -107.3454
Q Predictions Mean           105.57936
Q Predictions Std            125.3626
Q Predictions Max            351.0733
Q Predictions Min            -7.1255717
V Predictions Mean           108.820854
V Predictions Std            125.48909
V Predictions Max            357.94427
V Predictions Min            -3.7286282
Log Pis Mean                 -1.2299261
Log Pis Std                  1.6994617
Log Pis Max                  7.6023884
Log Pis Min                  -4.8734956
Policy mu Mean               0.15871647
Policy mu Std                0.6014847
Policy mu Max                2.3599117
Policy mu Min                -2.0919447
Policy log std Mean          -0.31076297
Policy log std Std           0.24562816
Policy log std Max           -0.08538943
Policy log std Min           -1.1078196
Z mean eval                  0.028499087
Z variance eval              0.0055544935
total_rewards                [324.68602163 174.67681749 312.25923955 145.70039464 138.62284355
 198.39934765 137.0604313  322.55080727 297.44093724 333.31404467]
total_rewards_mean           238.47108849965116
total_rewards_std            81.82626895759033
total_rewards_max            333.31404467155454
total_rewards_min            137.0604313028823
Number of train steps total  8000
Number of env steps total    42000
Number of rollouts total     0
Train Time (s)               25.87000434473157
(Previous) Eval Time (s)     2.7290414650924504
Sample Time (s)              12.576032475568354
Epoch Time (s)               41.175078285392374
Total Train Time (s)         330.7518015606329
Epoch                        7
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:55:57.365924 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #7 | Epoch Duration: 41.244962215423584
2020-01-11 12:55:57.366102 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #7 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028020913
Z variance train             0.005487039
KL Divergence                10.596031
KL Loss                      1.0596031
QF Loss                      222.27383
VF Loss                      37.397354
Policy Loss                  -140.43898
Q Predictions Mean           141.57083
Q Predictions Std            149.77396
Q Predictions Max            431.63727
Q Predictions Min            -0.67681545
V Predictions Mean           138.8659
V Predictions Std            147.24893
V Predictions Max            423.73248
V Predictions Min            -0.69425374
Log Pis Mean                 -1.2059188
Log Pis Std                  1.7882757
Log Pis Max                  7.4660044
Log Pis Min                  -4.926438
Policy mu Mean               0.023681687
Policy mu Std                0.60924757
Policy mu Max                2.35797
Policy mu Min                -2.3924654
Policy log std Mean          -0.2933195
Policy log std Std           0.22172678
Policy log std Max           -0.065642536
Policy log std Min           -1.0818189
Z mean eval                  0.007943086
Z variance eval              0.0059326543
total_rewards                [340.25028009 344.83227967 316.41688581 321.73731293 322.85579613
 328.35697086 334.28665042 316.81886798 305.62254649 334.84827184]
total_rewards_mean           326.6025862213001
total_rewards_std            11.51536509804525
total_rewards_max            344.8322796705376
total_rewards_min            305.62254649047435
Number of train steps total  9000
Number of env steps total    47000
Number of rollouts total     0
Train Time (s)               25.415896309074014
(Previous) Eval Time (s)     2.7986742318607867
Sample Time (s)              12.883698219899088
Epoch Time (s)               41.09826876083389
Total Train Time (s)         372.08485841425136
Epoch                        8
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:56:38.698595 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #8 | Epoch Duration: 41.33233428001404
2020-01-11 12:56:38.698778 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #8 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0075393147
Z variance train             0.0058042263
KL Divergence                10.471015
KL Loss                      1.0471015
QF Loss                      434.64252
VF Loss                      36.76709
Policy Loss                  -170.07004
Q Predictions Mean           167.89148
Q Predictions Std            176.01837
Q Predictions Max            503.6988
Q Predictions Min            -5.044222
V Predictions Mean           170.50015
V Predictions Std            175.33011
V Predictions Max            502.67456
V Predictions Min            -3.8211603
Log Pis Mean                 -0.8425698
Log Pis Std                  1.8661742
Log Pis Max                  8.7835045
Log Pis Min                  -5.0919714
Policy mu Mean               0.1724419
Policy mu Std                0.6770782
Policy mu Max                2.7686133
Policy mu Min                -2.4612434
Policy log std Mean          -0.34372023
Policy log std Std           0.27189848
Policy log std Max           0.0067336336
Policy log std Min           -1.2197025
Z mean eval                  0.024420632
Z variance eval              0.0041689575
total_rewards                [301.09530432 337.6539805  303.56933047 280.90464274 317.51690505
 309.24326464 315.02968424 297.71174285 287.77312745 322.92234761]
total_rewards_mean           307.3420329873287
total_rewards_std            15.986488387127428
total_rewards_max            337.65398050284915
total_rewards_min            280.904642737178
Number of train steps total  10000
Number of env steps total    52000
Number of rollouts total     0
Train Time (s)               26.01996268099174
(Previous) Eval Time (s)     3.032453211955726
Sample Time (s)              12.985331521369517
Epoch Time (s)               42.03774741431698
Total Train Time (s)         414.1886532185599
Epoch                        9
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:57:20.804976 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #9 | Epoch Duration: 42.10604119300842
2020-01-11 12:57:20.805241 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #9 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02646622
Z variance train             0.00429978
KL Divergence                11.278105
KL Loss                      1.1278105
QF Loss                      73.95313
VF Loss                      14.119717
Policy Loss                  -165.16595
Q Predictions Mean           162.84343
Q Predictions Std            196.89377
Q Predictions Max            556.08344
Q Predictions Min            -4.5224214
V Predictions Mean           165.51758
V Predictions Std            197.91855
V Predictions Max            554.9185
V Predictions Min            -2.7175517
Log Pis Mean                 -1.0839729
Log Pis Std                  1.8196534
Log Pis Max                  9.703669
Log Pis Min                  -4.9922843
Policy mu Mean               0.028578533
Policy mu Std                0.59767014
Policy mu Max                2.679599
Policy mu Min                -2.5968673
Policy log std Mean          -0.3289263
Policy log std Std           0.2956758
Policy log std Max           -0.07970582
Policy log std Min           -1.370024
Z mean eval                  0.022232821
Z variance eval              0.0050627626
total_rewards                [301.56803375 308.3058364  291.86503133 275.14735524 284.64206346
 272.42313943 298.7009673  300.48605335 301.676092   305.27750757]
total_rewards_mean           294.0092079816226
total_rewards_std            11.938659822323112
total_rewards_max            308.30583640419593
total_rewards_min            272.4231394252992
Number of train steps total  11000
Number of env steps total    57000
Number of rollouts total     0
Train Time (s)               27.519884943030775
(Previous) Eval Time (s)     3.100476913154125
Sample Time (s)              13.157905467785895
Epoch Time (s)               43.778267323970795
Total Train Time (s)         457.70025158673525
Epoch                        10
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:58:04.317506 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #10 | Epoch Duration: 43.51204514503479
2020-01-11 12:58:04.317783 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #10 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024770185
Z variance train             0.005125423
KL Divergence                10.936361
KL Loss                      1.0936362
QF Loss                      295.73624
VF Loss                      26.168478
Policy Loss                  -201.3032
Q Predictions Mean           198.75148
Q Predictions Std            221.5504
Q Predictions Max            603.8952
Q Predictions Min            -6.3986573
V Predictions Mean           202.28491
V Predictions Std            222.77635
V Predictions Max            606.84247
V Predictions Min            -1.870068
Log Pis Mean                 -0.9997534
Log Pis Std                  1.6487101
Log Pis Max                  7.6677823
Log Pis Min                  -4.604624
Policy mu Mean               0.07650706
Policy mu Std                0.6019019
Policy mu Max                2.4174798
Policy mu Min                -2.8293886
Policy log std Mean          -0.35265258
Policy log std Std           0.30026853
Policy log std Max           0.07793287
Policy log std Min           -1.4116803
Z mean eval                  0.015652541
Z variance eval              0.005267519
total_rewards                [263.23380598 290.85230591 300.81964797 305.66319087 311.25661696
 282.0179303  296.88414964 273.23049351 307.62041785 292.90927204]
total_rewards_mean           292.4487831032951
total_rewards_std            14.773958730472446
total_rewards_max            311.2566169584714
total_rewards_min            263.2338059810577
Number of train steps total  12000
Number of env steps total    62000
Number of rollouts total     0
Train Time (s)               26.681740988977253
(Previous) Eval Time (s)     2.8339848471805453
Sample Time (s)              12.85430706338957
Epoch Time (s)               42.37003289954737
Total Train Time (s)         500.04698431445286
Epoch                        11
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:58:46.664871 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #11 | Epoch Duration: 42.34686255455017
2020-01-11 12:58:46.665104 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #11 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017202562
Z variance train             0.004865533
KL Divergence                11.002914
KL Loss                      1.1002915
QF Loss                      181.07234
VF Loss                      52.17975
Policy Loss                  -248.92714
Q Predictions Mean           245.00754
Q Predictions Std            245.6705
Q Predictions Max            662.5687
Q Predictions Min            -3.016951
V Predictions Mean           249.83835
V Predictions Std            246.93062
V Predictions Max            665.2566
V Predictions Min            -2.1041462
Log Pis Mean                 -0.774643
Log Pis Std                  1.8096651
Log Pis Max                  5.764523
Log Pis Min                  -4.814332
Policy mu Mean               0.185661
Policy mu Std                0.6644957
Policy mu Max                2.9382272
Policy mu Min                -2.1911383
Policy log std Mean          -0.36604786
Policy log std Std           0.28500217
Policy log std Max           0.08274603
Policy log std Min           -1.5257007
Z mean eval                  0.0148001285
Z variance eval              0.0052176416
total_rewards                [315.80193262 319.1162798  332.11650264 338.59017701 322.87048972
 316.22365896 334.25938578 331.94133847 335.77609556 338.08035707]
total_rewards_mean           328.4776217641104
total_rewards_std            8.580902948580936
total_rewards_max            338.59017701182074
total_rewards_min            315.80193261782637
Number of train steps total  13000
Number of env steps total    67000
Number of rollouts total     0
Train Time (s)               26.98285420006141
(Previous) Eval Time (s)     2.810535743832588
Sample Time (s)              13.544519854243845
Epoch Time (s)               43.337909798137844
Total Train Time (s)         543.4323657322675
Epoch                        12
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:59:30.049865 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #12 | Epoch Duration: 43.38459086418152
2020-01-11 12:59:30.050062 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #12 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014926562
Z variance train             0.00524496
KL Divergence                10.699949
KL Loss                      1.0699949
QF Loss                      265.7166
VF Loss                      61.28228
Policy Loss                  -258.06573
Q Predictions Mean           254.49438
Q Predictions Std            256.76083
Q Predictions Max            715.4876
Q Predictions Min            -1.3253379
V Predictions Mean           258.3325
V Predictions Std            257.37897
V Predictions Max            716.49335
V Predictions Min            -1.0958868
Log Pis Mean                 -0.9442928
Log Pis Std                  1.9438498
Log Pis Max                  7.921427
Log Pis Min                  -6.0506687
Policy mu Mean               0.048888493
Policy mu Std                0.70031065
Policy mu Max                2.8512623
Policy mu Min                -2.8321984
Policy log std Mean          -0.3788602
Policy log std Std           0.30704036
Policy log std Max           0.10775741
Policy log std Min           -1.7137343
Z mean eval                  0.029839326
Z variance eval              0.0053322827
total_rewards                [305.84743871 303.52871035 289.46504642 286.88144831 298.10187167
 284.37588975 280.12378248 286.1204261  291.85685653 298.09972152]
total_rewards_mean           292.4401191847412
total_rewards_std            8.14587105667993
total_rewards_max            305.8474387126886
total_rewards_min            280.1237824837426
Number of train steps total  14000
Number of env steps total    72000
Number of rollouts total     0
Train Time (s)               28.758478636853397
(Previous) Eval Time (s)     2.8569374782964587
Sample Time (s)              12.891096551902592
Epoch Time (s)               44.50651266705245
Total Train Time (s)         588.0653962534852
Epoch                        13
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:00:14.688431 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #13 | Epoch Duration: 44.638150215148926
2020-01-11 13:00:14.688773 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #13 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034245513
Z variance train             0.005297721
KL Divergence                10.659327
KL Loss                      1.0659326
QF Loss                      409.09558
VF Loss                      120.770355
Policy Loss                  -288.8505
Q Predictions Mean           283.13284
Q Predictions Std            279.66516
Q Predictions Max            755.8578
Q Predictions Min            -1.309652
V Predictions Mean           284.04657
V Predictions Std            277.7728
V Predictions Max            748.7658
V Predictions Min            -3.1427734
Log Pis Mean                 -0.6500893
Log Pis Std                  2.0287135
Log Pis Max                  8.4333315
Log Pis Min                  -6.6981454
Policy mu Mean               0.17819655
Policy mu Std                0.7385257
Policy mu Max                2.5760183
Policy mu Min                -2.7626138
Policy log std Mean          -0.38996825
Policy log std Std           0.29402006
Policy log std Max           0.07920103
Policy log std Min           -1.4692183
Z mean eval                  0.017868534
Z variance eval              0.004895323
total_rewards                [287.79326598 286.18283502 282.10209828 302.6775806  286.93192028
 278.67573386 287.71825528 281.85149321 278.10198471 279.57571844]
total_rewards_mean           285.16108856501006
total_rewards_std            6.840122357244287
total_rewards_max            302.6775805964505
total_rewards_min            278.1019847138413
Number of train steps total  15000
Number of env steps total    77000
Number of rollouts total     0
Train Time (s)               27.353071324992925
(Previous) Eval Time (s)     2.988294509705156
Sample Time (s)              13.610101957805455
Epoch Time (s)               43.951467792503536
Total Train Time (s)         631.5487938793376
Epoch                        14
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:00:58.171722 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #14 | Epoch Duration: 43.48271441459656
2020-01-11 13:00:58.171991 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #14 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017735012
Z variance train             0.004842176
KL Divergence                10.861052
KL Loss                      1.0861052
QF Loss                      278.8469
VF Loss                      98.97631
Policy Loss                  -250.65028
Q Predictions Mean           243.76315
Q Predictions Std            294.3006
Q Predictions Max            787.65955
Q Predictions Min            -9.744161
V Predictions Mean           252.67236
V Predictions Std            297.1654
V Predictions Max            802.03076
V Predictions Min            -8.565884
Log Pis Mean                 -0.7203664
Log Pis Std                  2.3904102
Log Pis Max                  13.491255
Log Pis Min                  -6.149107
Policy mu Mean               -0.023322454
Policy mu Std                0.7269004
Policy mu Max                2.6874213
Policy mu Min                -3.5207741
Policy log std Mean          -0.34617892
Policy log std Std           0.29688898
Policy log std Max           0.10735212
Policy log std Min           -1.6867508
Z mean eval                  0.016543983
Z variance eval              0.0047692684
total_rewards                [259.16347044 278.61242767 264.5536226  308.80801179 285.06491553
 262.4264823  279.68886253 296.98827703 266.55106717 278.59480663]
total_rewards_mean           278.0451943678251
total_rewards_std            15.074463201988229
total_rewards_max            308.80801178844075
total_rewards_min            259.1634704351494
Number of train steps total  16000
Number of env steps total    82000
Number of rollouts total     0
Train Time (s)               25.6920235469006
(Previous) Eval Time (s)     2.5192888299934566
Sample Time (s)              13.525228187907487
Epoch Time (s)               41.736540564801544
Total Train Time (s)         673.4962778198533
Epoch                        15
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:01:40.118654 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #15 | Epoch Duration: 41.946497201919556
2020-01-11 13:01:40.118806 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #15 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019408679
Z variance train             0.0047343187
KL Divergence                11.01398
KL Loss                      1.101398
QF Loss                      431.44366
VF Loss                      86.79666
Policy Loss                  -302.8077
Q Predictions Mean           296.873
Q Predictions Std            318.31573
Q Predictions Max            841.4767
Q Predictions Min            -6.799603
V Predictions Mean           300.3539
V Predictions Std            319.07706
V Predictions Max            850.0561
V Predictions Min            -4.9259877
Log Pis Mean                 -0.6664418
Log Pis Std                  1.9944844
Log Pis Max                  6.8548307
Log Pis Min                  -4.485857
Policy mu Mean               0.17554073
Policy mu Std                0.7427897
Policy mu Max                2.4492145
Policy mu Min                -2.7264948
Policy log std Mean          -0.39728817
Policy log std Std           0.31370053
Policy log std Max           0.036729224
Policy log std Min           -1.6720581
Z mean eval                  0.024265166
Z variance eval              0.0036865235
total_rewards                [286.71808674 290.9265508  298.56932278 268.78803955 342.19368946
 280.575141   300.15445992 300.70548829 290.26451723 341.70318684]
total_rewards_mean           300.0598482612112
total_rewards_std            22.862685234706607
total_rewards_max            342.1936894643089
total_rewards_min            268.78803954913303
Number of train steps total  17000
Number of env steps total    87000
Number of rollouts total     0
Train Time (s)               28.9319730498828
(Previous) Eval Time (s)     2.7289704671129584
Sample Time (s)              13.003757130354643
Epoch Time (s)               44.6647006473504
Total Train Time (s)         718.4887787993066
Epoch                        16
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:02:25.112110 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #16 | Epoch Duration: 44.99315047264099
2020-01-11 13:02:25.112309 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #16 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012826358
Z variance train             0.004156931
KL Divergence                11.552478
KL Loss                      1.1552478
QF Loss                      169.92691
VF Loss                      53.98797
Policy Loss                  -304.37158
Q Predictions Mean           299.9809
Q Predictions Std            321.44632
Q Predictions Max            885.4269
Q Predictions Min            -10.295655
V Predictions Mean           304.60956
V Predictions Std            320.62115
V Predictions Max            882.0562
V Predictions Min            0.18302876
Log Pis Mean                 -0.69500095
Log Pis Std                  1.7983378
Log Pis Max                  4.878118
Log Pis Min                  -7.5382595
Policy mu Mean               0.1433
Policy mu Std                0.72084486
Policy mu Max                2.3842416
Policy mu Min                -1.8988975
Policy log std Mean          -0.38823292
Policy log std Std           0.3070469
Policy log std Max           -0.032324918
Policy log std Min           -1.7396206
Z mean eval                  0.027338928
Z variance eval              0.0030665018
total_rewards                [280.07160029 249.5137855  277.10317104 314.90387581 272.89276356
 231.36277369 391.60446434 265.42814757 291.8043917  310.94758697]
total_rewards_mean           288.5632560458772
total_rewards_std            41.95697530076263
total_rewards_max            391.6044643407084
total_rewards_min            231.3627736867868
Number of train steps total  18000
Number of env steps total    92000
Number of rollouts total     0
Train Time (s)               26.16897400887683
(Previous) Eval Time (s)     3.057125468272716
Sample Time (s)              13.062044305726886
Epoch Time (s)               42.28814378287643
Total Train Time (s)         760.7763812541962
Epoch                        17
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:03:07.403874 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #17 | Epoch Duration: 42.29138255119324
2020-01-11 13:03:07.404158 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #17 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026848176
Z variance train             0.00306456
KL Divergence                12.276491
KL Loss                      1.2276491
QF Loss                      785.99976
VF Loss                      111.00566
Policy Loss                  -311.727
Q Predictions Mean           306.89636
Q Predictions Std            343.04355
Q Predictions Max            889.534
Q Predictions Min            -1.7269917
V Predictions Mean           308.83362
V Predictions Std            341.4034
V Predictions Max            888.31354
V Predictions Min            -2.698635
Log Pis Mean                 -0.6048809
Log Pis Std                  2.1523929
Log Pis Max                  8.921375
Log Pis Min                  -4.9406433
Policy mu Mean               0.010189795
Policy mu Std                0.8104257
Policy mu Max                2.6413598
Policy mu Min                -3.745624
Policy log std Mean          -0.3672398
Policy log std Std           0.27716634
Policy log std Max           0.074034095
Policy log std Min           -1.6216937
Z mean eval                  0.061852038
Z variance eval              0.002842093
total_rewards                [307.23247423 227.72623223 244.38140237 284.73971189 252.07115757
 231.81977491 242.13469929 253.64418222 266.75825984 239.95093254]
total_rewards_mean           255.04588270907752
total_rewards_std            23.552622068881476
total_rewards_max            307.23247423369526
total_rewards_min            227.72623222704664
Number of train steps total  19000
Number of env steps total    97000
Number of rollouts total     0
Train Time (s)               27.984274834860116
(Previous) Eval Time (s)     3.0600656997412443
Sample Time (s)              13.484332480002195
Epoch Time (s)               44.528673014603555
Total Train Time (s)         804.9761488540098
Epoch                        18
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:03:51.604245 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #18 | Epoch Duration: 44.19985818862915
2020-01-11 13:03:51.604528 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #18 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04909357
Z variance train             0.0019705826
KL Divergence                13.377094
KL Loss                      1.3377094
QF Loss                      265.0214
VF Loss                      130.58322
Policy Loss                  -306.8528
Q Predictions Mean           305.212
Q Predictions Std            342.80182
Q Predictions Max            958.12506
Q Predictions Min            -5.9291034
V Predictions Mean           312.5827
V Predictions Std            347.34378
V Predictions Max            970.6338
V Predictions Min            -4.371536
Log Pis Mean                 -0.45198244
Log Pis Std                  2.361471
Log Pis Max                  14.201766
Log Pis Min                  -3.4282153
Policy mu Mean               0.06978422
Policy mu Std                0.84315765
Policy mu Max                2.848539
Policy mu Min                -3.6156855
Policy log std Mean          -0.37655532
Policy log std Std           0.29750246
Policy log std Max           0.12699051
Policy log std Min           -1.5003128
Z mean eval                  0.032551955
Z variance eval              0.0023884312
total_rewards                [229.59976767 252.11726177 314.66253153 310.1411363  296.67004475
 311.79687717 223.08720538 320.0566634  229.4070158  259.32839416]
total_rewards_mean           274.6866897915763
total_rewards_std            37.76876573073495
total_rewards_max            320.0566633995989
total_rewards_min            223.08720537972485
Number of train steps total  20000
Number of env steps total    102000
Number of rollouts total     0
Train Time (s)               29.03593271691352
(Previous) Eval Time (s)     2.730958143249154
Sample Time (s)              13.010860747192055
Epoch Time (s)               44.77775160735473
Total Train Time (s)         850.054338642396
Epoch                        19
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:04:36.682599 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #19 | Epoch Duration: 45.07783389091492
2020-01-11 13:04:36.682927 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #19 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035602063
Z variance train             0.0024167045
KL Divergence                12.784178
KL Loss                      1.2784178
QF Loss                      692.8074
VF Loss                      57.885433
Policy Loss                  -320.45477
Q Predictions Mean           317.82422
Q Predictions Std            361.00085
Q Predictions Max            1017.2798
Q Predictions Min            -10.095617
V Predictions Mean           322.92346
V Predictions Std            362.23184
V Predictions Max            1021.9833
V Predictions Min            -6.0927887
Log Pis Mean                 -0.529155
Log Pis Std                  2.0769544
Log Pis Max                  7.918576
Log Pis Min                  -3.4868479
Policy mu Mean               0.16604418
Policy mu Std                0.77026176
Policy mu Max                2.4124887
Policy mu Min                -2.69885
Policy log std Mean          -0.41185126
Policy log std Std           0.332315
Policy log std Max           -0.034288123
Policy log std Min           -1.6310999
Z mean eval                  0.028429937
Z variance eval              0.0015821023
total_rewards                [359.90797637 397.50861844 350.53738241 307.23506261 422.24478604
 397.0734668  403.72526283 429.04803256 453.53165351 378.29415298]
total_rewards_mean           389.9106394560139
total_rewards_std            40.42938551379035
total_rewards_max            453.53165351180894
total_rewards_min            307.23506261023164
Number of train steps total  21000
Number of env steps total    107000
Number of rollouts total     0
Train Time (s)               25.97846653405577
(Previous) Eval Time (s)     3.030778472777456
Sample Time (s)              13.107301436830312
Epoch Time (s)               42.11654644366354
Total Train Time (s)         892.9637104491703
Epoch                        20
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:05:19.594108 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #20 | Epoch Duration: 42.910919189453125
2020-01-11 13:05:19.594416 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #20 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0131801125
Z variance train             0.00145547
KL Divergence                14.103607
KL Loss                      1.4103607
QF Loss                      213.44232
VF Loss                      46.81124
Policy Loss                  -363.33057
Q Predictions Mean           360.2741
Q Predictions Std            376.52155
Q Predictions Max            1025.1687
Q Predictions Min            -4.4116025
V Predictions Mean           363.04623
V Predictions Std            377.66635
V Predictions Max            1013.9024
V Predictions Min            -2.172397
Log Pis Mean                 -0.642649
Log Pis Std                  2.0666792
Log Pis Max                  9.714956
Log Pis Min                  -5.2287564
Policy mu Mean               0.006653484
Policy mu Std                0.7835911
Policy mu Max                2.6177874
Policy mu Min                -2.7577028
Policy log std Mean          -0.41435716
Policy log std Std           0.339225
Policy log std Max           0.16936746
Policy log std Min           -1.4961437
Z mean eval                  0.016211245
Z variance eval              0.0019518979
total_rewards                [381.70742756 396.98047642 394.02079063 390.87203211 439.94660362
 405.07513825 406.65967094 389.76137714 389.82789419 407.50312566]
total_rewards_mean           400.2354536522396
total_rewards_std            15.468320860047761
total_rewards_max            439.9466036172197
total_rewards_min            381.7074275615538
Number of train steps total  22000
Number of env steps total    112000
Number of rollouts total     0
Train Time (s)               25.24387700110674
(Previous) Eval Time (s)     3.8248661351390183
Sample Time (s)              13.727970531210303
Epoch Time (s)               42.79671366745606
Total Train Time (s)         935.660970161669
Epoch                        21
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:06:02.290041 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #21 | Epoch Duration: 42.69540810585022
2020-01-11 13:06:02.290205 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #21 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02966624
Z variance train             0.0021563394
KL Divergence                13.241825
KL Loss                      1.3241825
QF Loss                      180.02373
VF Loss                      54.55162
Policy Loss                  -375.80896
Q Predictions Mean           371.59125
Q Predictions Std            397.37744
Q Predictions Max            1032.819
Q Predictions Min            -8.794551
V Predictions Mean           377.06165
V Predictions Std            399.97034
V Predictions Max            1024.7158
V Predictions Min            -0.75126624
Log Pis Mean                 -0.5353912
Log Pis Std                  2.0798564
Log Pis Max                  7.6666894
Log Pis Min                  -5.1779675
Policy mu Mean               0.10783839
Policy mu Std                0.83395123
Policy mu Max                2.8468683
Policy mu Min                -2.6395855
Policy log std Mean          -0.38594317
Policy log std Std           0.29998636
Policy log std Max           0.014181465
Policy log std Min           -1.5055356
Z mean eval                  0.021659968
Z variance eval              0.00258008
total_rewards                [189.41315298 187.15664612 382.15430205 193.58525399 208.25155179
 195.67557439 446.17192004 449.63432253 242.35154597 398.35030619]
total_rewards_mean           289.27445760550074
total_rewards_std            108.60031278189629
total_rewards_max            449.63432253369666
total_rewards_min            187.15664612486543
Number of train steps total  23000
Number of env steps total    117000
Number of rollouts total     0
Train Time (s)               26.9258065498434
(Previous) Eval Time (s)     3.7233209861442447
Sample Time (s)              14.221943406388164
Epoch Time (s)               44.87107094237581
Total Train Time (s)         979.6713189501315
Epoch                        22
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:06:46.304441 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #22 | Epoch Duration: 44.01405668258667
2020-01-11 13:06:46.304744 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #22 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023783162
Z variance train             0.0031657952
KL Divergence                12.3429985
KL Loss                      1.2342999
QF Loss                      322.06335
VF Loss                      99.9649
Policy Loss                  -384.3465
Q Predictions Mean           379.66156
Q Predictions Std            396.3462
Q Predictions Max            1095.1401
Q Predictions Min            -8.678114
V Predictions Mean           380.94943
V Predictions Std            393.4533
V Predictions Max            1099.2142
V Predictions Min            0.6983266
Log Pis Mean                 -0.14323518
Log Pis Std                  2.256481
Log Pis Max                  7.5280504
Log Pis Min                  -4.308327
Policy mu Mean               -0.0155652175
Policy mu Std                0.87308496
Policy mu Max                2.955018
Policy mu Min                -2.8195434
Policy log std Mean          -0.45718512
Policy log std Std           0.35639915
Policy log std Max           -0.03354229
Policy log std Min           -1.660883
Z mean eval                  0.01013872
Z variance eval              0.0037015039
total_rewards                [485.21488956 441.43792771 475.43153246 375.51760576 397.05457901
 437.34324544 264.67343081 278.68000786 451.7006364  485.9107145 ]
total_rewards_mean           409.2964569514247
total_rewards_std            76.74135966207751
total_rewards_max            485.91071450355787
total_rewards_min            264.67343081492174
Number of train steps total  24000
Number of env steps total    122000
Number of rollouts total     0
Train Time (s)               25.761256170924753
(Previous) Eval Time (s)     2.8659618669189513
Sample Time (s)              13.49283909238875
Epoch Time (s)               42.12005713023245
Total Train Time (s)         1023.0091504384764
Epoch                        23
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:07:29.644504 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #23 | Epoch Duration: 43.33953237533569
2020-01-11 13:07:29.644772 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #23 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014051551
Z variance train             0.0031679422
KL Divergence                12.129549
KL Loss                      1.2129549
QF Loss                      325.2149
VF Loss                      102.777115
Policy Loss                  -418.06052
Q Predictions Mean           414.45218
Q Predictions Std            415.25665
Q Predictions Max            1135.9943
Q Predictions Min            -2.3129935
V Predictions Mean           416.83582
V Predictions Std            417.38696
V Predictions Max            1134.7812
V Predictions Min            -1.424007
Log Pis Mean                 0.011192933
Log Pis Std                  2.4713197
Log Pis Max                  8.606705
Log Pis Min                  -3.471467
Policy mu Mean               0.1428458
Policy mu Std                0.9314835
Policy mu Max                2.622358
Policy mu Min                -2.8447485
Policy log std Mean          -0.4497211
Policy log std Std           0.35308692
Policy log std Max           0.20044456
Policy log std Min           -1.8652624
Z mean eval                  0.035847142
Z variance eval              0.002973244
total_rewards                [412.42310335 292.73986884 415.02652339 424.58517589 488.33923322
 434.53569571 481.19536013 454.13288659 454.5544152  492.94652385]
total_rewards_mean           435.0478786181002
total_rewards_std            55.082292430456086
total_rewards_max            492.94652385425377
total_rewards_min            292.73986883512936
Number of train steps total  25000
Number of env steps total    127000
Number of rollouts total     0
Train Time (s)               27.344634288921952
(Previous) Eval Time (s)     4.085182229988277
Sample Time (s)              14.44962946139276
Epoch Time (s)               45.87944598030299
Total Train Time (s)         1068.8794096778147
Epoch                        24
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:08:15.517103 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #24 | Epoch Duration: 45.87209701538086
2020-01-11 13:08:15.517399 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #24 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028866794
Z variance train             0.0026620238
KL Divergence                12.626535
KL Loss                      1.2626536
QF Loss                      302.90125
VF Loss                      104.17258
Policy Loss                  -418.07535
Q Predictions Mean           417.80072
Q Predictions Std            425.34628
Q Predictions Max            1142.8862
Q Predictions Min            -3.5029252
V Predictions Mean           420.8396
V Predictions Std            426.66052
V Predictions Max            1144.0044
V Predictions Min            -2.6834755
Log Pis Mean                 -0.12952906
Log Pis Std                  2.495735
Log Pis Max                  8.489162
Log Pis Min                  -6.271227
Policy mu Mean               0.123733126
Policy mu Std                0.935847
Policy mu Max                2.937101
Policy mu Min                -2.6373858
Policy log std Mean          -0.4151806
Policy log std Std           0.34521705
Policy log std Max           0.026608273
Policy log std Min           -1.8963623
Z mean eval                  0.026491841
Z variance eval              0.0029971413
total_rewards                [323.91488207 441.19055695 436.23891715 510.89046534 538.62799241
 367.85954807 378.54348041 388.52653895 490.19254286 292.59147114]
total_rewards_mean           416.8576395357192
total_rewards_std            76.6601590108277
total_rewards_max            538.627992410678
total_rewards_min            292.5914711433811
Number of train steps total  26000
Number of env steps total    132000
Number of rollouts total     0
Train Time (s)               28.732640233822167
(Previous) Eval Time (s)     4.077575876843184
Sample Time (s)              14.60029983241111
Epoch Time (s)               47.41051594307646
Total Train Time (s)         1116.2920385063626
Epoch                        25
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:09:02.929282 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #25 | Epoch Duration: 47.41166424751282
2020-01-11 13:09:02.929482 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #25 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025184939
Z variance train             0.002761394
KL Divergence                12.510846
KL Loss                      1.2510847
QF Loss                      271.78195
VF Loss                      186.71962
Policy Loss                  -420.95444
Q Predictions Mean           416.15952
Q Predictions Std            425.74136
Q Predictions Max            1160.7803
Q Predictions Min            -2.8319514
V Predictions Mean           416.07452
V Predictions Std            427.49347
V Predictions Max            1169.7275
V Predictions Min            -2.1866875
Log Pis Mean                 0.43747795
Log Pis Std                  2.7410274
Log Pis Max                  9.955855
Log Pis Min                  -4.377689
Policy mu Mean               0.020199962
Policy mu Std                1.0356315
Policy mu Max                2.964546
Policy mu Min                -2.640071
Policy log std Mean          -0.4783528
Policy log std Std           0.3781115
Policy log std Max           -0.0032541752
Policy log std Min           -2.0046253
Z mean eval                  0.02694326
Z variance eval              0.0028904458
total_rewards                [288.87709281 310.68846854 447.64043081 283.08849752 298.682763
 317.53122367 519.01855478 307.73968218 301.34684038 540.27316151]
total_rewards_mean           361.4886715198163
total_rewards_std            95.17573532847778
total_rewards_max            540.2731615090534
total_rewards_min            283.0884975192184
Number of train steps total  27000
Number of env steps total    137000
Number of rollouts total     0
Train Time (s)               25.84621139196679
(Previous) Eval Time (s)     4.078456501010805
Sample Time (s)              13.975061425939202
Epoch Time (s)               43.8997293189168
Total Train Time (s)         1159.6137187369168
Epoch                        26
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:09:46.251494 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #26 | Epoch Duration: 43.321837425231934
2020-01-11 13:09:46.251695 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #26 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036034774
Z variance train             0.003061121
KL Divergence                12.22676
KL Loss                      1.222676
QF Loss                      1505.104
VF Loss                      130.27061
Policy Loss                  -468.06525
Q Predictions Mean           460.70425
Q Predictions Std            458.08734
Q Predictions Max            1257.3331
Q Predictions Min            -0.58698964
V Predictions Mean           464.43546
V Predictions Std            459.70526
V Predictions Max            1256.7776
V Predictions Min            -8.557641
Log Pis Mean                 0.6284655
Log Pis Std                  3.087498
Log Pis Max                  10.939497
Log Pis Min                  -5.9614773
Policy mu Mean               -0.07390814
Policy mu Std                1.1144462
Policy mu Max                3.0222447
Policy mu Min                -3.4201126
Policy log std Mean          -0.46530595
Policy log std Std           0.35047063
Policy log std Max           -0.0912116
Policy log std Min           -1.8455901
Z mean eval                  0.055180263
Z variance eval              0.0020371783
total_rewards                [459.49868185 549.38909226 386.80683831 409.78220097 315.56632808
 387.40320291 401.43986782 487.27098208 383.53438488 410.83553108]
total_rewards_mean           419.15271102435224
total_rewards_std            61.44365598141152
total_rewards_max            549.3890922641725
total_rewards_min            315.56632807862445
Number of train steps total  28000
Number of env steps total    142000
Number of rollouts total     0
Train Time (s)               26.344206786248833
(Previous) Eval Time (s)     3.500315035227686
Sample Time (s)              13.699444547761232
Epoch Time (s)               43.54396636923775
Total Train Time (s)         1203.3170140138827
Epoch                        27
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:10:29.956835 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #27 | Epoch Duration: 43.704957485198975
2020-01-11 13:10:29.957029 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #27 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012850856
Z variance train             0.002078609
KL Divergence                13.014717
KL Loss                      1.3014717
QF Loss                      503.40115
VF Loss                      193.3071
Policy Loss                  -497.66885
Q Predictions Mean           489.3649
Q Predictions Std            460.66983
Q Predictions Max            1308.1028
Q Predictions Min            -3.807507
V Predictions Mean           490.25998
V Predictions Std            460.5629
V Predictions Max            1305.8947
V Predictions Min            -1.0062952
Log Pis Mean                 0.29993632
Log Pis Std                  2.4716413
Log Pis Max                  11.40276
Log Pis Min                  -3.6597877
Policy mu Mean               -0.112412214
Policy mu Std                0.99785644
Policy mu Max                2.6913042
Policy mu Min                -2.8485994
Policy log std Mean          -0.44356546
Policy log std Std           0.3306295
Policy log std Max           -0.06285056
Policy log std Min           -1.6305707
Z mean eval                  0.0077746883
Z variance eval              0.0016220752
total_rewards                [465.86796645 437.78376461 387.79869889 459.7113705  451.195643
 532.31198741 447.67778323 409.33115117 451.09795333 382.61854136]
total_rewards_mean           442.5394859945818
total_rewards_std            40.96981316731252
total_rewards_max            532.3119874057277
total_rewards_min            382.61854136206125
Number of train steps total  29000
Number of env steps total    147000
Number of rollouts total     0
Train Time (s)               28.31896388484165
(Previous) Eval Time (s)     3.6610762630589306
Sample Time (s)              14.07119760895148
Epoch Time (s)               46.05123775685206
Total Train Time (s)         1249.453625710681
Epoch                        28
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:11:16.092489 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #28 | Epoch Duration: 46.13531255722046
2020-01-11 13:11:16.092653 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #28 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008634341
Z variance train             0.0015317093
KL Divergence                13.837461
KL Loss                      1.3837461
QF Loss                      380.9655
VF Loss                      77.44176
Policy Loss                  -484.24942
Q Predictions Mean           479.00995
Q Predictions Std            475.6788
Q Predictions Max            1312.8416
Q Predictions Min            -6.9235334
V Predictions Mean           485.3715
V Predictions Std            480.01352
V Predictions Max            1351.8522
V Predictions Min            -3.4814966
Log Pis Mean                 0.0739788
Log Pis Std                  2.3493538
Log Pis Max                  11.169815
Log Pis Min                  -4.45555
Policy mu Mean               0.026036054
Policy mu Std                0.93832016
Policy mu Max                2.6313546
Policy mu Min                -2.8339243
Policy log std Mean          -0.48197982
Policy log std Std           0.3713602
Policy log std Max           -0.08946999
Policy log std Min           -1.8907413
Z mean eval                  0.038437948
Z variance eval              0.0021964344
total_rewards                [278.79714469 573.35359657 407.95782178 501.54948001 448.64784929
 456.4233972  369.67420605 531.33677024 517.44134523 452.33171416]
total_rewards_mean           453.7513325209958
total_rewards_std            81.53248419179998
total_rewards_max            573.3535965719005
total_rewards_min            278.79714468634745
Number of train steps total  30000
Number of env steps total    152000
Number of rollouts total     0
Train Time (s)               27.116965042892843
(Previous) Eval Time (s)     3.74489339068532
Sample Time (s)              14.060370961669832
Epoch Time (s)               44.922229395247996
Total Train Time (s)         1294.362741889432
Epoch                        29
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:12:01.006678 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #29 | Epoch Duration: 44.91384482383728
2020-01-11 13:12:01.006969 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #29 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037064575
Z variance train             0.00218954
KL Divergence                12.978675
KL Loss                      1.2978675
QF Loss                      1055.0471
VF Loss                      190.95793
Policy Loss                  -465.48444
Q Predictions Mean           468.38455
Q Predictions Std            472.93936
Q Predictions Max            1352.0895
Q Predictions Min            -15.300528
V Predictions Mean           466.88016
V Predictions Std            469.198
V Predictions Max            1350.7434
V Predictions Min            -2.885346
Log Pis Mean                 0.11674349
Log Pis Std                  2.5184312
Log Pis Max                  8.135425
Log Pis Min                  -4.766385
Policy mu Mean               -0.10150671
Policy mu Std                0.9640639
Policy mu Max                2.4565396
Policy mu Min                -2.7191756
Policy log std Mean          -0.47512683
Policy log std Std           0.356667
Policy log std Max           0.039265558
Policy log std Min           -1.7330028
Z mean eval                  0.01662395
Z variance eval              0.008971082
total_rewards                [466.96679405 475.61489669 409.65942695 414.52617366 417.53978115
 410.95747292 464.82345057 459.98978074 450.63681688 453.12122541]
total_rewards_mean           442.383581903672
total_rewards_std            24.813934983934107
total_rewards_max            475.61489668863965
total_rewards_min            409.6594269540095
Number of train steps total  31000
Number of env steps total    157000
Number of rollouts total     0
Train Time (s)               28.46138303494081
(Previous) Eval Time (s)     3.736237217672169
Sample Time (s)              14.738916301168501
Epoch Time (s)               46.93653655378148
Total Train Time (s)         1341.5989631265402
Epoch                        30
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:12:48.242717 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #30 | Epoch Duration: 47.23549461364746
2020-01-11 13:12:48.242998 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #30 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023321202
Z variance train             0.0048621846
KL Divergence                10.898432
KL Loss                      1.0898432
QF Loss                      572.102
VF Loss                      143.09
Policy Loss                  -490.04318
Q Predictions Mean           486.0548
Q Predictions Std            488.73032
Q Predictions Max            1434.5762
Q Predictions Min            -4.513134
V Predictions Mean           487.84747
V Predictions Std            488.73108
V Predictions Max            1427.4701
V Predictions Min            -0.16421926
Log Pis Mean                 -0.14118859
Log Pis Std                  2.3945127
Log Pis Max                  7.06086
Log Pis Min                  -4.249814
Policy mu Mean               0.019764572
Policy mu Std                0.9285854
Policy mu Max                3.1089263
Policy mu Min                -3.026549
Policy log std Mean          -0.44187632
Policy log std Std           0.3244678
Policy log std Max           0.16797046
Policy log std Min           -1.7018704
Z mean eval                  0.027504444
Z variance eval              0.003322777
total_rewards                [569.16081679 560.73674209 602.59949283 545.89986509 575.21703071
 574.68854984 604.99823862 588.71426023 636.19971378 587.51198965]
total_rewards_mean           584.5726699620267
total_rewards_std            24.330640250494483
total_rewards_max            636.1997137766397
total_rewards_min            545.8998650889084
Number of train steps total  32000
Number of env steps total    162000
Number of rollouts total     0
Train Time (s)               27.851302972063422
(Previous) Eval Time (s)     4.034929053392261
Sample Time (s)              14.320357601158321
Epoch Time (s)               46.206589626614004
Total Train Time (s)         1388.3827348658815
Epoch                        31
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:13:35.028371 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #31 | Epoch Duration: 46.78511691093445
2020-01-11 13:13:35.028685 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #31 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028115904
Z variance train             0.0032979038
KL Divergence                11.925158
KL Loss                      1.1925157
QF Loss                      2438.6672
VF Loss                      90.40698
Policy Loss                  -529.61707
Q Predictions Mean           527.6529
Q Predictions Std            485.47855
Q Predictions Max            1420.0397
Q Predictions Min            0.75420386
V Predictions Mean           529.1121
V Predictions Std            486.2328
V Predictions Max            1435.6826
V Predictions Min            1.3568108
Log Pis Mean                 -0.13457507
Log Pis Std                  2.3257184
Log Pis Max                  7.2289
Log Pis Min                  -3.8216012
Policy mu Mean               -0.025249846
Policy mu Std                0.9114778
Policy mu Max                2.6297312
Policy mu Min                -3.351066
Policy log std Mean          -0.42880294
Policy log std Std           0.31418636
Policy log std Max           0.18684293
Policy log std Min           -1.438113
Z mean eval                  0.023242855
Z variance eval              0.0033805943
total_rewards                [579.06711945 565.46891865 570.77944339 530.53292068 505.44749427
 583.38668885 490.27273921 595.55321276 495.35721957 522.4677034 ]
total_rewards_mean           543.8333460220763
total_rewards_std            37.417321593738095
total_rewards_max            595.5532127562102
total_rewards_min            490.2727392093328
Number of train steps total  33000
Number of env steps total    167000
Number of rollouts total     0
Train Time (s)               27.88914395403117
(Previous) Eval Time (s)     4.613156035076827
Sample Time (s)              15.290813599713147
Epoch Time (s)               47.79311358882114
Total Train Time (s)         1435.8336076107807
Epoch                        32
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:14:22.477881 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #32 | Epoch Duration: 47.44896697998047
2020-01-11 13:14:22.478083 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #32 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023370128
Z variance train             0.0033848598
KL Divergence                11.92062
KL Loss                      1.192062
QF Loss                      439.05768
VF Loss                      93.60521
Policy Loss                  -517.95795
Q Predictions Mean           517.5522
Q Predictions Std            479.75037
Q Predictions Max            1408.6149
Q Predictions Min            -1.4733632
V Predictions Mean           519.6797
V Predictions Std            478.14343
V Predictions Max            1401.0028
V Predictions Min            -1.353454
Log Pis Mean                 -0.13203532
Log Pis Std                  2.3721309
Log Pis Max                  8.436514
Log Pis Min                  -8.480138
Policy mu Mean               0.03234349
Policy mu Std                0.88291585
Policy mu Max                2.5594065
Policy mu Min                -3.0887172
Policy log std Mean          -0.4939328
Policy log std Std           0.36006775
Policy log std Max           0.07632786
Policy log std Min           -1.9891741
Z mean eval                  0.034168635
Z variance eval              0.0041574547
total_rewards                [494.21826042 585.20252424 495.35588832 488.5537814  591.63356025
 543.36563508 544.39785696 576.37419316 546.36943493 522.31427151]
total_rewards_mean           538.7785406292955
total_rewards_std            36.24535304438596
total_rewards_max            591.6335602486108
total_rewards_min            488.5537814029403
Number of train steps total  34000
Number of env steps total    172000
Number of rollouts total     0
Train Time (s)               25.98423590697348
(Previous) Eval Time (s)     4.268728481605649
Sample Time (s)              14.798188443761319
Epoch Time (s)               45.05115283234045
Total Train Time (s)         1480.5828813565895
Epoch                        33
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:15:07.231276 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #33 | Epoch Duration: 44.753018617630005
2020-01-11 13:15:07.231521 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #33 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033557296
Z variance train             0.004155421
KL Divergence                11.371932
KL Loss                      1.1371932
QF Loss                      390.07874
VF Loss                      160.9448
Policy Loss                  -519.5617
Q Predictions Mean           520.59985
Q Predictions Std            495.22574
Q Predictions Max            1414.1788
Q Predictions Min            2.9517992
V Predictions Mean           522.6564
V Predictions Std            494.58508
V Predictions Max            1418.241
V Predictions Min            1.3037977
Log Pis Mean                 0.15239947
Log Pis Std                  2.63717
Log Pis Max                  8.756683
Log Pis Min                  -4.650184
Policy mu Mean               0.10008844
Policy mu Std                0.988865
Policy mu Max                3.348257
Policy mu Min                -3.135351
Policy log std Mean          -0.4622122
Policy log std Std           0.31372714
Policy log std Max           0.25171983
Policy log std Min           -1.5460846
Z mean eval                  0.01281474
Z variance eval              0.004071056
total_rewards                [585.0978726  604.6464912  559.8824098  628.11434418 533.44542528
 559.08934898 573.96785295 532.70578648 554.1279401  566.31769255]
total_rewards_mean           569.7395164128328
total_rewards_std            28.345462342006808
total_rewards_max            628.1143441771289
total_rewards_min            532.7057864843389
Number of train steps total  35000
Number of env steps total    177000
Number of rollouts total     0
Train Time (s)               27.893071432132274
(Previous) Eval Time (s)     3.9703202680684626
Sample Time (s)              14.595870247110724
Epoch Time (s)               46.45926194731146
Total Train Time (s)         1527.1209403104149
Epoch                        34
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:15:53.768562 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #34 | Epoch Duration: 46.536837339401245
2020-01-11 13:15:53.768749 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #34 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014432535
Z variance train             0.0040643644
KL Divergence                11.311966
KL Loss                      1.1311966
QF Loss                      597.3484
VF Loss                      267.66644
Policy Loss                  -510.9062
Q Predictions Mean           507.46097
Q Predictions Std            483.04742
Q Predictions Max            1350.6487
Q Predictions Min            -17.294813
V Predictions Mean           510.07153
V Predictions Std            483.50195
V Predictions Max            1348.3734
V Predictions Min            -16.895695
Log Pis Mean                 -0.16625094
Log Pis Std                  2.3825514
Log Pis Max                  9.238575
Log Pis Min                  -4.698095
Policy mu Mean               0.09368058
Policy mu Std                0.85889953
Policy mu Max                3.6176672
Policy mu Min                -2.887853
Policy log std Mean          -0.47843495
Policy log std Std           0.3394715
Policy log std Max           0.23913395
Policy log std Min           -1.5488743
Z mean eval                  0.021307167
Z variance eval              0.0041198255
total_rewards                [494.76814946 484.69828352 585.58506676 579.61594988 517.80398238
 624.41407791 528.30098516 472.27787354 612.79172586 572.49275679]
total_rewards_mean           547.2748851265757
total_rewards_std            51.88289709887493
total_rewards_max            624.414077910271
total_rewards_min            472.27787354312505
Number of train steps total  36000
Number of env steps total    182000
Number of rollouts total     0
Train Time (s)               26.131383549422026
(Previous) Eval Time (s)     4.0476192510686815
Sample Time (s)              15.197633587755263
Epoch Time (s)               45.37663638824597
Total Train Time (s)         1572.859065681696
Epoch                        35
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:16:39.507551 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #35 | Epoch Duration: 45.73866605758667
2020-01-11 13:16:39.507735 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #35 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021000773
Z variance train             0.0041219033
KL Divergence                11.251633
KL Loss                      1.1251633
QF Loss                      763.9186
VF Loss                      532.12683
Policy Loss                  -595.70856
Q Predictions Mean           589.8623
Q Predictions Std            478.44553
Q Predictions Max            1342.0907
Q Predictions Min            -1.8343524
V Predictions Mean           599.0412
V Predictions Std            481.62515
V Predictions Max            1340.7057
V Predictions Min            -1.1121916
Log Pis Mean                 0.21934888
Log Pis Std                  2.4039617
Log Pis Max                  10.365986
Log Pis Min                  -3.984906
Policy mu Mean               0.09980184
Policy mu Std                0.9643656
Policy mu Max                2.7131484
Policy mu Min                -3.4103935
Policy log std Mean          -0.5138587
Policy log std Std           0.32911798
Policy log std Max           -0.047321767
Policy log std Min           -1.5618036
Z mean eval                  0.090470135
Z variance eval              0.0035901815
total_rewards                [545.3278321  440.23148985 390.63740118 455.00862074 487.32827615
 384.90929181 320.7463865  459.17569614 620.25875068 388.14332311]
total_rewards_mean           449.1767068259993
total_rewards_std            82.43799295311018
total_rewards_max            620.2587506755044
total_rewards_min            320.746386496249
Number of train steps total  37000
Number of env steps total    187000
Number of rollouts total     0
Train Time (s)               28.027905622962862
(Previous) Eval Time (s)     4.409385928884149
Sample Time (s)              14.480240107979625
Epoch Time (s)               46.917531659826636
Total Train Time (s)         1619.3480082508177
Epoch                        36
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:17:25.996723 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #36 | Epoch Duration: 46.48878860473633
2020-01-11 13:17:25.996899 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #36 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09236379
Z variance train             0.0035692782
KL Divergence                12.055751
KL Loss                      1.2055751
QF Loss                      555.5335
VF Loss                      81.344986
Policy Loss                  -560.7245
Q Predictions Mean           561.0303
Q Predictions Std            504.24197
Q Predictions Max            1412.8945
Q Predictions Min            0.27267772
V Predictions Mean           561.54736
V Predictions Std            504.58395
V Predictions Max            1407.0508
V Predictions Min            -3.7067316
Log Pis Mean                 -0.106391266
Log Pis Std                  2.1844819
Log Pis Max                  5.8438673
Log Pis Min                  -4.4212284
Policy mu Mean               0.012656282
Policy mu Std                0.88072115
Policy mu Max                2.6034734
Policy mu Min                -2.474374
Policy log std Mean          -0.4769772
Policy log std Std           0.3134988
Policy log std Max           0.10926212
Policy log std Min           -1.52477
Z mean eval                  0.03618317
Z variance eval              0.002759031
total_rewards                [606.22363691 635.89011096 622.24465032 609.31210375 629.42319876
 651.74039132 607.69891563 635.01935373 635.45405759 647.93697352]
total_rewards_mean           628.0943392488349
total_rewards_std            15.488122139140517
total_rewards_max            651.740391324938
total_rewards_min            606.2236369086104
Number of train steps total  38000
Number of env steps total    192000
Number of rollouts total     0
Train Time (s)               29.56445282883942
(Previous) Eval Time (s)     3.9803637582808733
Sample Time (s)              14.502237536944449
Epoch Time (s)               48.04705412406474
Total Train Time (s)         1668.295399365481
Epoch                        37
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:18:14.948043 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #37 | Epoch Duration: 48.95096778869629
2020-01-11 13:18:14.948341 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #37 | Started Training: True
